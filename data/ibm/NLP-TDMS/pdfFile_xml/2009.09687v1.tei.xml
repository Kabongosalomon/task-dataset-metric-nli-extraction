<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contrastive Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfan</forename><surname>Li</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Hu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zitao</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dezhong</forename><surname>Peng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joey</forename><forename type="middle">Tianyi</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
						</author>
						<title level="a" type="main">Contrastive Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-clustering</term>
					<term>unsupervised learning</term>
					<term>contrastive learning !</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a one-stage online clustering method called Contrastive Clustering (CC) which explicitly performs the instance-and cluster-level contrastive learning. To be specific, for a given dataset, the positive and negative instance pairs are constructed through data augmentations and then projected into a feature space. Therein, the instance-and cluster-level contrastive learning are respectively conducted in the row and column space by maximizing the similarities of positive pairs while minimizing those of negative ones. Our key observation is that the rows of the feature matrix could be regarded as soft labels of instances, and accordingly the columns could be further regarded as cluster representations. By simultaneously optimizing the instance-and cluster-level contrastive loss, the model jointly learns representations and cluster assignments in an end-to-end manner. Extensive experimental results show that CC remarkably outperforms 17 competitive clustering methods on six challenging image benchmarks. In particular, CC achieves an NMI of 0.705 (0.431) on the CIFAR-10 (CIFAR-100) dataset, which is an up to 19% (39%) performance improvement compared with the best baseline.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>A S one of the most fundamental tools in unsupervised learning, clustering could group data into different clusters without any label. Although some promising results have been achieved recently <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, most of the algorithms would produce inferior results on complex datasets due to insufficient representability. To solve the problem, deep clustering <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref> utilizes neural networks to extract representative information from images for facilitating the downstream clustering tasks. In very recent, the focus of the community has shifted to how to learn representation and perform clustering in an end-to-end fashion. For example, JULE <ref type="bibr" target="#b34">[35]</ref> progressively merges data points and takes the clustering results as supervisory signals to learn a more discriminative representation by a neural network. Deep-Clustering <ref type="bibr" target="#b2">[3]</ref> iteratively groups the features with k-means and uses the subsequent assignments to update the deep network. This kind of alternation-learning method would suffer from the error accumulated during the alternation between the stages of representation learning and clustering, which results in suboptimal clustering performance. Moreover, the aforementioned methods can only deal with offline tasks, i.e., the clustering is based on the whole dataset, which limits their application on large-scale online learning scenarios.</p><p>To conquer the aforementioned offline limitation, this paper proposes a one-stage online deep clustering method called Contrastive Clustering (CC). Our idea comes from the observations shown in <ref type="figure">Fig. 1</ref>. For a given dataset, we use a deep network to learn the feature matrix whose rows and columns correspond to the instance and cluster representations, respectively. In other words, we treat the label as a special representation by projecting input instances into a <ref type="figure">Fig. 1</ref>. The key observation. By regarding the rows of the feature matrix as the soft labels of instances (i.e., P (c j |x i ) denotes the probability of sample i belonging to cluster j), the columns could accordingly be interpreted as cluster representations distributed over the dataset. As a result, the instance-and cluster-level contrastive learning could be conducted in the row and column space of the feature matrix, respectively.</p><p>subspace with a dimensionality of the cluster number. In this sense, the rows of the feature matrix could be interpreted as the cluster assignment probabilities (i.e., instance soft labels), and the columns could then be regarded as the cluster distributions over instances (i.e., cluster representations). Owing to the observation of "label as representation", it is feasible to perform online clustering since the clustering prediction is now recast as a special representation learning task that is "independent" of other instances.</p><p>With the above observations, we propose a novel dual arXiv:2009.09687v1 [cs.</p><p>LG] 21 Sep 2020 contrastive learning framework to learn instance and cluster representations. Specifically, CC first learns the feature matrix of data pairs constructed through a variety of data augmentations such as random crop and blurring. After that, the instance-and cluster-level contrastive learning are conducted in the row and column space of the feature matrix by gathering the positive pairs and scattering the negatives. By considering the instance-and cluster-level similarity under our dual contrastive learning framework, CC is able to simultaneously learn discriminative features and perform online clustering in a one-stage and end-toend manner. To summarize, the major contributions of our work are as follows:</p><p>• We provide a novel insight to the community, i.e., the instance representation and clustering prediction correspond to the row and column of a learnable feature matrix, respectively. Hence, deep clustering could be elegantly unified into the framework of representation learning;</p><p>• To the best of our knowledge, this could be the first work of clustering-specified contrastive learning. Different from existing studies in contrastive learning, the proposed method conducts contrastive learning at not only the instance-level but also the cluster-level. Such a dual contrastive learning framework could produce clustering-favorite representations as proved in our experiments;</p><p>• The proposed model works in a one-stage and endto-end fashion, which only needs batch-wise optimization and thus can be applied to large-scale online scenarios.</p><p>The proposed method shows superior performance on six challenging image datasets, including CIFAR-10/100, STL-10, ImageNet-10/Dogs, and Tiny-ImageNet. It significantly outperforms state-of-the-art methods on all six datasets. In particular, it achieves an up to 39% performance improvement in terms of NMI on the CIFAR-100 dataset compared with the most competitive baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>In this section, we briefly introduce some recent developments in two related topics, namely, contrastive learning and deep clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Contrastive Learning</head><p>As a promising paradigm of unsupervised learning, contrastive learning has lately achieved state-of-the-art performance in representation learning <ref type="bibr" target="#b11">[12]</ref>. The basic idea of contrastive learning is to map the original data to a feature space wherein the similarities of positive pairs are maximized while those of negative pairs are minimized <ref type="bibr" target="#b14">[15]</ref>. In early works, the positive and negative pairs are known as prior. Recently, various works have shown that large quantities of data pairs are crucial to the performance of contrastive models <ref type="bibr" target="#b16">[17]</ref> and they could be constructed using the following two strategies under the unsupervised setting. One is to use clustering results as pseudo labels to guide the pair construction <ref type="bibr" target="#b30">[31]</ref>. The other, which is more direct and commonly used, is to treat each instance as a class represented by a feature vector and data pairs are constructed through data augmentations <ref type="bibr" target="#b8">[9]</ref>. To be specific, the positive pair composes of two augmented views of the same instance, and the other pairs are defined to be negative. Given the data pairs, several loss functions have been proposed for contrastive learning. For example, triplet loss <ref type="bibr" target="#b29">[30]</ref> minimizes the distance between an anchor and a positive, while maximizing the distance between the anchor and a negative, NCE <ref type="bibr" target="#b13">[14]</ref> performs nonlinear logistic regression to discriminate between the observed data and some artificially generated noise, and SimCLR <ref type="bibr" target="#b6">[7]</ref> adopts the normalized temperature-scaled cross-entropy loss (NT-Xent) to identify positive pairs across the dataset.</p><p>The differences between our method and existing contrastive learning methods are addressed below. On the one hand, the existing works only perform contrastive learning at the instance level, whereas our method simultaneously conducts contrastive learning at both the instance-and cluster-level following the observation of "label as representation". On the other hand, the existing works aim to learn a general representation, which is off-the-shelf for the downstream tasks. On the contrary, our method is specifically designed for clustering, which could be the first successful attempt of task-specified contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Deep Clustering</head><p>Although promising results have been achieved, traditional clustering algorithms give discouraging results on largescale complex datasets due to the inferior capability of representation learning. Benefit from the powerful representative ability of deep neural networks, deep clustering <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b33">[34]</ref> has shown promising performance on complex datasets. For example, JULE <ref type="bibr" target="#b34">[35]</ref> performs agglomerative clustering by iteratively learning the data representations and cluster assignments. Analogously, DeepClustering <ref type="bibr" target="#b2">[3]</ref> groups the features using k-means and updates the deep network according to the cluster assignments in turn. Though this kind of two-stage methods could jointly learn representations and perform clustering, their performance might be hurt by the errors accumulated during the alternation. Besides, the entire dataset is needed to perform clustering, which limits their application in large-scale and online scenarios. Recently, some online clustering methods have been proposed <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b27">[28]</ref>. For example, IIC <ref type="bibr" target="#b19">[20]</ref> discovers clusters by maximizing mutual information between the cluster assignments of data pairs. PICA <ref type="bibr" target="#b18">[19]</ref> learns the most semantically plausible data separation by maximizing the partition confidence of the clustering solution. Though grounded in theory, these works rely heavily on the auxiliary over-clustering trick which is hard to explain. Different from the above deep clustering methods, we treat the label as a special representation so that the instance-and cluster-level representation learning could be conducted in the row and column space, respectively. Besides, former works mainly utilize the representative capability of deep neural networks for clustering, whereas our method dually utilizes contrastive samples to facilitate clustering under a unified framework. Such a clusteringoriented contrastive learning paradigm helps the model to minimize the inter-cluster similarities to separate different clusters. To the best of our knowledge, this could be one of the first successful attempts to promote clustering through contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>As illustrated in <ref type="figure" target="#fig_0">Fig. 2</ref>, our method consists of three jointly learned components, namely, a pair construction backbone (PCB), an instance-level contrastive head (ICH), and a cluster-level contrastive head (CCH). In brief, PCB constructs data pairs through data augmentations and extracts features from augmented samples, after that ICH and CCH respectively apply contrastive learning in the row and column space of the feature matrix. After training, the cluster assignments can be easily obtained through the soft labels predicted by CCH. Notably, although our basic idea indicates that the dual contrastive learning could be directly conducted on the feature matrix, we experimentally find that the clustering performance could be improved by decoupling the instance-and cluster-level contrastive learning into two independent subspaces (see more details in the supplementary materials). The possible reason is that such a decoupling strategy could improve the representability of ICH and CCH. In the following, we will elaborate on the three components in turn and introduce the proposed objective function at the end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pair Construction Backbone</head><p>Inspired by the recent progress in contrastive learning <ref type="bibr" target="#b6">[7]</ref>, CC uses data augmentations to construct data pairs. Specifically, given a data instance x i , two stochastic data transformations T a , T b sampled from the same family of augmentations T are applied to it, resulting in two correlated samples denoted as x a i = T a (x i ) and</p><formula xml:id="formula_0">x b i = T b (x i ).</formula><p>The previous works have suggested that a proper choice of augmentation strategy is essential to achieve a good performance in downstream tasks. In this work, five types of data augmentation methods are used, including ResizedCrop, ColorJitter, Grayscale, HorizontalFlip, and GaussianBlur. For a given image, each augmentation is applied independently with a certain probability following the setting in SimCLR <ref type="bibr" target="#b6">[7]</ref>. Specifically, ResizedCrop crops an image to a random size and resize the crop to the original size; ColorJitter changes the brightness, contrast, and saturation of an image; Grayscale converts an image to grayscale; HorizontalFlip horizontally flip an image and GaussianBlur blurs an image by a Gaussian function.</p><p>One shared deep neural network f (·) is used to extracted features from the augmented samples via h a i = f (x a i ) and</p><formula xml:id="formula_1">h b i = f (x b i ).</formula><p>As for the architecture of the network, theoretically, our method does not depend on a specific network. Here, we simply adopt ResNet34 <ref type="bibr" target="#b17">[18]</ref> as the backbone for fair comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Instance-level Contrastive Head</head><p>Contrastive learning aims to maximize the similarities of positive pairs while minimizing those of negative ones. The characteristics of pairs can be defined by different criteria. For example, one can define pairs of within-class samples to be positive and leave the others negative. In this work, since no prior label is available on the clustering task, the positive and negative pairs are constructed at the instance-level according to pseudo-labels generated by data augmentations. More specifically, the positive pairs consist of samples augmented from the same instance, and the negative pairs otherwise.</p><p>Formally, given a mini-batch of size N , CC performs two types of data augmentations on each instance   To alleviate the information loss induced by contrastive loss, we do not directly conduct contrastive learning on the feature matrix. Instead, we stack a two-layer nonlinear MLP g I (·) to map the feature matrix to a subspace via z a i = g I (h a i ) where the instance-level contrastive loss is applied. The pair-wise similarity is measured by cosine distance, i.e.,</p><formula xml:id="formula_2">h a i = f (T a (x i )), h b i = f (T b (x i )) z a i = g I (h a i ), z b i = g I (h b i ) y a i = g C (h a i ),ỹ b i = g C (h b i ) compute instance-level</formula><formula xml:id="formula_3">s(z k1 i , z k2 j ) = (z k1 i )(z k2 j ) z k1 i z k2 j ,<label>(1)</label></formula><p>where k 1 , k 2 ∈ {a, b} and i, j ∈ [1, N ]. To optimize pairwise similarities, without loss of generality, the loss for a given sample x a i is in the form of</p><formula xml:id="formula_4">a i = − log exp(s(z a i , z b i )/τ I ) N j=1 [exp(s(z a i , z a j )/τ I ) + exp(s(z a i , z b j )/τ I )] ,<label>(2)</label></formula><p>where τ I is the instance-level temperature parameter. Since we hope to identify all positive pairs across the dataset, the instance-level contrastive loss is computed over every augmented samples, namely,</p><formula xml:id="formula_5">L ins = 1 2N N i=1 ( a i + b i ).<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cluster-level Contrastive Head</head><p>Following the idea of "label as representation", when projecting a data sample into a space whose dimensionality equals to the number of clusters, the i-th element of its feature can be interpreted as its probability of belonging to the i-th cluster, and the feature vector denotes its soft label accordingly.</p><p>Formally, let Y a ∈ R N ×M be the output of CCH for a mini-batch under the first augmentation (and Y b for the second augmentation), and then Y a n,m can be interpreted as the probability of sample n being assigned to cluster m, where N is the batch size and M equals to the number of clusters. Since each sample belongs to only one cluster, ideally, the rows of Y a tends to be one-hot. In this sense, the i-th column of Y a can be seen as a representation of the i-th cluster and all columns should differ from each other.</p><p>Similar to g I (·) used in the instance-level contrastive head, we use another two-layer MLP g C (·) to project the feature matrix into an M -dimensional space viaỹ a i = g C (h a i ), whereỹ a i denotes the soft label of sample x a i (the i-th row of Y a ). For clarity, let y a i be the i-the column of Y a , namely, the representation of cluster i under the first data augmentation, and we combine it with y b i to form a positive cluster pair {y a i , y b i }, while leaving other 2M − 2 pairs to be negative, where y b i denotes the second augmented representation of cluster i. Again, we use cosine distance to measure the similarity between cluster pairs, that is</p><formula xml:id="formula_6">s(y k1 i , y k2 j ) = (y k1 i ) (y k2 j ) y k1 i y k2 j ,<label>(4)</label></formula><p>where k 1 , k 2 ∈ {a, b} and i, j ∈ [1, M ]. Without loss of generality, the following loss function is adopted to distinguish cluster y a i from all other clusters except y b i , i.e.,</p><formula xml:id="formula_7">a i = − log exp(s(y a i , y b i )/τ C ) M j=1 [exp(s(y a i , y a j )/τ C ) + exp(s(y a i , y b j )/τ C )] ,<label>(5)</label></formula><p>where τ C is the cluster-level temperature parameter. By traversing all clusters, the cluster-level contrastive loss is finally computed by</p><formula xml:id="formula_8">L clu = 1 2M M i=1 (ˆ a i +ˆ b i ) − H(Y ),<label>(6)</label></formula><p>where</p><formula xml:id="formula_9">H(Y ) = M i=1 [P (y a i ) log P (y a i ) + P (y b i ) log P (y b i )</formula><p>] is the entropy of cluster assignment probabilities P (y k i ) = N j=1 Y k ji / Y 1 , k ∈ {a, b} within a mini-batch under each data augmentation. This term helps to avoid the trivial solution that most instances are assigned to the same cluster.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Objective Function</head><p>The optimization of ICH and CCH is a one-stage and end-toend process. Two heads are simultaneously optimized and the overall objective function consists of the instance-level and cluster-level contrastive loss, i.e.,</p><formula xml:id="formula_10">L = L ins + L clu .<label>(7)</label></formula><p>Generally, a dynamic weight parameter could be applied to balance the two losses across the training process <ref type="bibr" target="#b11">[12]</ref>, but in practice, we find a simple addition of the two losses already works well. The full training and test process of the model is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, we conduct experiments to verify the effectiveness of the proposed CC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Configurations</head><p>We first introduce the used datasets, implementations, and the used performance metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Datasets</head><p>We evaluate the proposed method on six challenging image datasets. A brief description of these datasets is summarized in <ref type="table" target="#tab_0">Table 1</ref>. Both the training and test set are used for CIFAR-10, CIFAR-100 <ref type="bibr" target="#b21">[22]</ref>, and STL-10 <ref type="bibr" target="#b7">[8]</ref>, while only the training set is used for ImageNet-10, ImageNet-Dogs <ref type="bibr" target="#b4">[5]</ref>, and Tiny-ImageNet <ref type="bibr" target="#b22">[23]</ref>. For CIFAR-100, its 20 super-classes rather than 100 classes are taken as the ground-truth. For STL-10, its 100,000 unlabeled samples are additionally used to train the instance-level contrastive head. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Implementation Details</head><p>For a fair comparison with previous works <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, we adopt ResNet34 as the backbone network. As ResNet is designed for images of size 224 × 224, some previous works modified the standard ResNet and used some tricks (e.g., the Sobel layer used in PICA) to help the network to handle small-sized inputs (e.g., CIFAR-10). However, these specialized modifications and tricks should vary with images of different sizes, which brings difficulty in model selection. In this work, we simply resize all input images to the size of 224 × 224, and no modification is applied to the standard ResNet. Notably, as up-scaling already leads to blurred images, we leave the GaussianBlur augmentation out for the small image collections including CIFAR-10, CIFAR-100, STL-10, and Tiny-ImageNet. For the instance-level contrastive head, the dimensionality of the row space is set to 128 to keep more information of images, and the instance-level temperature parameter τ I is fixed to 0.5 in all experiments. For the choice of the dimensionality of the row space, we conduct additional analysis in the supplementary material. As for the clusterlevel contrastive head, the dimensionality of the column space is naturally set to the number of clusters, and the cluster-level temperature parameter τ C = 1.0 is used for all datasets.</p><p>The Adam optimizer with an initial learning rate of 0.0003 is adopted to simultaneously optimize the two contrastive heads and the backbone network. No weight decay or scheduler is used. The batch size is set to 256 due to the memory limitation, and we train the model from scratch for 1,000 epochs to compensate for the performance loss caused by small batch size as suggested in SimCLR <ref type="bibr" target="#b6">[7]</ref>. The experiments are carried out on Nvidia TITAN RTX 24G and it takes about 70 gpu-hours to train the model on CIFAR-10, 90 gpu-hours for CIFAR-100, 160 gpu-hours on STL-10, 20 gpu-hours on ImageNet-10, 30 gpu-hours on ImageNetdogs, and 130 gpu-hours on Tiny-ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Evaluation Metrics</head><p>Three widely-used clustering metrics including Normalized Mutual Information (NMI), Accuracy (ACC), and Adjusted Rand Index (ARI) are utilized to evaluate our method. Higher values of these metrics indicate better clustering performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Comparisons with State of the Arts</head><p>We evaluate the proposed CC on six challenging image benchmarks and compare it with 17 representative stateof-the-art clustering approaches, including k-means <ref type="bibr" target="#b26">[27]</ref>, SC <ref type="bibr" target="#b36">[37]</ref>, AC <ref type="bibr" target="#b10">[11]</ref>, NMF <ref type="bibr" target="#b1">[2]</ref>, AE <ref type="bibr" target="#b0">[1]</ref>, DAE <ref type="bibr" target="#b31">[32]</ref>, DCGAN <ref type="bibr" target="#b28">[29]</ref>, DeCNN <ref type="bibr" target="#b35">[36]</ref>, VAE <ref type="bibr" target="#b20">[21]</ref>, JULE <ref type="bibr" target="#b34">[35]</ref>, DEC <ref type="bibr" target="#b33">[34]</ref>, DAC <ref type="bibr" target="#b5">[6]</ref>, ADC <ref type="bibr" target="#b15">[16]</ref>, DDC <ref type="bibr" target="#b3">[4]</ref>, DCCM <ref type="bibr" target="#b32">[33]</ref>, IIC <ref type="bibr" target="#b19">[20]</ref> and PICA <ref type="bibr" target="#b18">[19]</ref>. For SC, NMF, AE, DAE, DCGAN, DeCNN, and VAE, clustering results are obtained via k-means on the features extracted from images.</p><p>According to the results shown in <ref type="table" target="#tab_3">Table 2</ref>, CC significantly outperforms these state-of-the-art baselines by a large margin on all six datasets. In particular, CC surpasses the closest competitor PICA by 0.114 on CIFAR-10, 0.121 on CIFAR-100, and 0.153 on STL-10 in terms of NMI. Moreover, CC achieves more than 50% performance improvements on the best baseline on CIFAR-100 and Tiny-ImageNet in terms of ARI. The remarkable results demonstrate the powerful clustering ability of CC, which benefits from the incorporation of the instance-and cluster-level contrastive learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Qualitative Study</head><p>We carry out two experiments to analyze the pair-wise similarity across the training process and the evolution of the learned instance representation and cluster assignments on ImageNet-10.  <ref type="table">Metrics  NMI  ACC  ARI  NMI  ACC  ARI  NMI  ACC  ARI  NMI  ACC  ARI  NMI  ACC  ARI  NMI  ACC</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Analysis on Pair-wise Similarity</head><p>To provide an intuitive understanding of how contrastive clustering works, we visualize the changes of both the instance-and cluster-level pair-wise similarities w.r.t. the training epoch. As shown in <ref type="figure" target="#fig_2">Fig. 3</ref>, the similarities of positive instance/cluster pairs grows as the training process goes while the similarity of negative instance/cluster pairs stay at a low level. In addition, the similarity interval between the positive and negative is comparatively large at both the instance-and cluster-level, which explains the success of our model. Note that the variances of positive instance and negative cluster pairs are much lower than those of negative instance pairs and positive cluster pairs due to the following two reasons. On the one hand, the large variance of negative instance pairs could be attributed to the fact that some pairs consist of samples of different instances but the same class, which should be treated as positive theoretically. On the other hand, the variance of positive cluster pairs comes from the inconsistent cluster assignments of samples under different augmentations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Evolution of Instance Feature and Cluster Assignments</head><p>By simultaneously optimizing the instance-and cluster-level contrastive head, the model ought to learn discriminative representations and desirable cluster assignments at the same time. To see how our model converges to the goal, we perform t-SNE in the row space at four different timestamps throughout the training process. The results are shown in <ref type="figure" target="#fig_3">Fig. 4</ref>, where different colors indicated different labels predicted by the cluster-level contrastive head. The result shows that, at the beginning, features are all mixed and most instances are assigned to a few clusters. As the training process goes, cluster assignments become more reasonable, and features scatter and gather more distinctly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study</head><p>Three ablation studies are carried out to further understand the importance of data augmentation, the effect of two contrastive heads, and the reliance on the backbone network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Importance of Data Augmentation</head><p>Some existing works have shown that the performance of contrastive learning heavily relies on the proper strategy of data augmentation <ref type="bibr" target="#b6">[7]</ref>. To verify the significance of data augmentation, we test our model on CIFAR-10 and ImageNet-10 by removing one and both of the two augmentations. When data augmentations are removed, the raw image is directly used as the input. <ref type="table" target="#tab_4">Table 3</ref> shows that data augmentations could enhance the performance of CC, especially on more complicated datasets, i.e., CIFAR-10. When no data augmentation is applied, every positive pair consists of two same samples/clusters and thus only negative pairs take part in model optimization, which leads to pretty poor results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Effect of Contrastive Head</head><p>To prove the effectiveness of the instance-and cluster-level contrastive head, we conduct ablation studies on CIFAR-10 and ImageNet-10 by removing one of the two heads. Since the cluster assignments can no longer be directly obtained when the cluster-level contrastive head is removed, we perform k-means in the instance space instead. The results are shown in <ref type="table" target="#tab_5">Table 4</ref>. Interestingly, ICH shows comparable performance on CIFAR-10 while CCH performs better on ImageNet-10, which suggests the joint effects of the two heads to some extent. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.3">Reliance on Backbone Network</head><p>In our framework, any feature extractor could be adopted as the backbone network. To examine how much our model relies on the structure of the backbone network, we test three ResNets of different depths and report the results in <ref type="table" target="#tab_6">Table 5</ref>.</p><p>The results suggest that the representability of the backbone network contributes to the clustering performance. On relatively simple datasets like ImageNet-10, ResNet18 is sufficiently powerful to extract discriminative features. In addition, the performance of ResNet50 is worse than ResNet34 on CIFAR-10, which suggests a deeper network does not promise better performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>Based on the observation that the rows and columns of the feature matrix could be respectively realized as the representation of instances and clusters, we proposed the Contrastive Clustering (CC) method which dually conducts contrastive learning at the instance-and cluster-level under a unified framework. The proposed CC shows its promising performance in clustering. In the future, we plan to extend it to other tasks and applications such as semi-supervised learning and transfer learning.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>The framework of Contrastive Clustering. We construct data pairs using two data augmentations. Given data pairs, one shared deep neural network is used to extract features from different augmentations. Two separate MLPs (σ denotes the ReLU activation and ∼ denotes the Softmax operation to produce soft labels) are used to project the features into the row and column space wherein the instance-and cluster-level contrastive learning are conducted respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>x i and results in 2N data samples {x a 1 , . . . , x a N , x b 1 , . . . , x b N }. For a specific sample x a i , there are 2N − 1 pairs in total, among which we choose its corresponding augmented sample x b i to form a positive pair {x a i , x b i } and leave other 2N − 2 pairs to be negative.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Instance-level and cluster-level pair-wise similarities across the training process on ImageNet-10. The colored areas denote the variances.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>0 epoch (NMI = 0.183) (b) 20 epoch (NMI = 0.472) (c) 50 epoch (NMI = 0.628) (d) 100 epoch (NMI = 0.737) The evolution of instance features and cluster assignments across the training process on ImageNet-10. The colors indicate the cluster assignment obtained from CCH and the features for t-SNE are computed from ICH.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>Contrastive Clustering Input: dataset X ; training epochs E; batch size N ; temperature parameter τ I and τ C ; cluster number M ; structure of T , f , g I , and g C . Output: cluster assignments. // training for epoch = 1 to E do sample a mini-batch {x i } N i=1 from X sample two augmentations T a , T b ∼ T compute instance and cluster representations by</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 1 A</head><label>1</label><figDesc>summary of datasets used for evaluations.</figDesc><table><row><cell>Dataset</cell><cell>Split</cell><cell cols="2">Samples Classes</cell></row><row><cell>CIFAR-10</cell><cell>Train+Test</cell><cell>60,000</cell><cell>10</cell></row><row><cell>CIFAR-100</cell><cell>Train+Test</cell><cell>60,000</cell><cell>20</cell></row><row><cell>STL-10</cell><cell>Train+Test</cell><cell>13,000</cell><cell>10</cell></row><row><cell>ImageNet-10</cell><cell>Train</cell><cell>13,000</cell><cell>10</cell></row><row><cell>ImageNet-Dogs</cell><cell>Train</cell><cell>19,500</cell><cell>15</cell></row><row><cell>Tiny-ImageNet</cell><cell>Train</cell><cell>100,000</cell><cell>200</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 2</head><label>2</label><figDesc>The clustering performance on six challenging object image benchmarks. The best results are shown in boldface.</figDesc><table><row><cell>Dataset</cell><cell>CIFAR-10</cell><cell>CIFAR-100</cell><cell>STL-10</cell><cell>ImageNet-10</cell><cell>ImageNet-Dogs</cell><cell>Tiny-ImageNet</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 3</head><label>3</label><figDesc>Importance of data augmentation.</figDesc><table><row><cell>Dataset</cell><cell>Augmentation</cell><cell>NMI</cell><cell>ACC</cell><cell>ARI</cell></row><row><cell>CIFAR-10</cell><cell>T a (x) + T b (x) T a (x) + x</cell><cell cols="3">0.705 0.790 0.637 0.630 0.690 0.533</cell></row><row><cell></cell><cell>x + x</cell><cell cols="3">0.045 0.169 0.022</cell></row><row><cell>ImageNet-10</cell><cell>T a (x) + T b (x) T a (x) + x</cell><cell cols="3">0.859 0.893 0.822 0.852 0.892 0.817</cell></row><row><cell></cell><cell>x + x</cell><cell cols="3">0.063 0.177 0.030</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4</head><label>4</label><figDesc>Effect of two contrastive heads.</figDesc><table><row><cell>Dataset</cell><cell>Contrastive Head</cell><cell>NMI</cell><cell>ACC</cell><cell>ARI</cell></row><row><cell></cell><cell>ICH + CCH</cell><cell cols="3">0.705 0.790 0.637</cell></row><row><cell>CIFAR-10</cell><cell>ICH Only</cell><cell cols="3">0.699 0.782 0.616</cell></row><row><cell></cell><cell>CCH Only</cell><cell cols="3">0.592 0.657 0.499</cell></row><row><cell></cell><cell>ICH + CCH</cell><cell cols="3">0.859 0.893 0.822</cell></row><row><cell>ImageNet-10</cell><cell>ICH Only</cell><cell cols="3">0.838 0.888 0.780</cell></row><row><cell></cell><cell>CCH Only</cell><cell cols="3">0.850 0.892 0.816</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 5</head><label>5</label><figDesc>Reliance on backbone network.</figDesc><table><row><cell>Dataset</cell><cell>Backbone</cell><cell>NMI</cell><cell>ACC</cell><cell>ARI</cell></row><row><cell></cell><cell>ResNet18</cell><cell cols="3">0.650 0.736 0.569</cell></row><row><cell>CIFAR-10</cell><cell>ResNet34</cell><cell cols="3">0.705 0.790 0.637</cell></row><row><cell></cell><cell>ResNet50</cell><cell cols="3">0.663 0.747 0.585</cell></row><row><cell></cell><cell>ResNet18</cell><cell cols="3">0.851 0.889 0.816</cell></row><row><cell>ImageNet-10</cell><cell>ResNet34</cell><cell cols="3">0.859 0.893 0.822</cell></row><row><cell></cell><cell>ResNet50</cell><cell cols="3">0.859 0.895 0.823</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Locality preserving nonnegative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1010" to="1015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="132" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01681</idno>
		<title level="m">Deep Discriminative Clustering Analysis</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep adaptive image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5879" to="5887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep adaptive image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5879" to="5887" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An analysis of singlelayer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="766" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ghasedi Dizaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5736" to="5745" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Agglomerative clustering using the concept of mutual nearest neighbourhood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Altché</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">D</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Azar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07733</idno>
		<title level="m">Bootstrap your own latent: A new approach to selfsupervised learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep clustering with convolutional autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on neural information processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="373" to="382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyvärinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Associative deep clustering: Training a classification network with no labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Plapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">German Conference on Pattern Recognition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep Semantic Clustering by Partition Confidence Maximisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9865" to="9874" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tiny imagenet visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CS</title>
		<imprint>
			<biblScope unit="volume">231</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Autoencoder Constrained Clustering With Adaptive Neighbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Sparse Embedded k-Means Clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3319" to="3327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multiple kernel k-means clustering with matrix-induced regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirtieth AAAI conference on artificial intelligence</title>
		<meeting>the thirtieth AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1888" to="1894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fifth Berkeley symposium on mathematical statistics and probability</title>
		<meeting>the fifth Berkeley symposium on mathematical statistics and probability<address><addrLine>Oakland, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Robust subspace clustering via thresholding ridge regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="3827" to="3833" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Sarfraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.02195</idno>
		<title level="m">Clustering based Contrastive Learning for Improving Face Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lajoie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep comprehensive correlation mining for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8150" to="8159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5147" to="5156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deconvolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE Computer Society Conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2528" to="2535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Self-tuning spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
