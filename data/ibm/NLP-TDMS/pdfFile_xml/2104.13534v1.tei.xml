<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PAFNet: An Efficient Anchor-Free Object Detector Guidance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Xin</surname></persName>
							<email>xinying@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanzhong</forename><surname>Wang</surname></persName>
							<email>wangguanzhong@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyuan</forename><surname>Mao</surname></persName>
							<email>vmaomingyuan@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Feng</surname></persName>
							<email>fengyuan01@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingqing</forename><surname>Dang</surname></persName>
							<email>dangqingqing@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanjun</forename><surname>Ma</surname></persName>
							<email>mayanjun02@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Errui</forename><surname>Ding</surname></persName>
							<email>dingerrui@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shumin</forename><surname>Han</surname></persName>
							<email>hanshumin@baidu.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Baidu Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PAFNet: An Efficient Anchor-Free Object Detector Guidance</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Object detection is a basic but challenging task in computer vision, which plays a key role in a variety of industrial applications. However, object detectors based on deep learning usually require greater storage requirements and longer inference time, which hinders its practicality seriously. Therefore, a trade-off between effectiveness and efficiency is necessary in practical scenarios. Considering that without constraint of pre-defined anchors, anchorfree detectors can achieve acceptable accuracy and inference speed simultaneously. In this paper, we start from an anchor-free detector called TTFNet, modify the structure of TTFNet and introduce multiple existing tricks to realize effective server and mobile solutions respectively. Since all experiments in this paper are conducted based on PaddlePaddle, we call the model as PAFNet(Paddle Anchor Free Network). For server side, PAFNet can achieve a better balance between effectiveness (42.2% mAP) and efficiency (67.15 FPS) on a single V100 GPU. For moblie side, PAFNet-lite can achieve a better accuracy of (23.9% mAP) and 26.00 ms on Kirin 990 ARM CPU, outperforming the existing state-of-the-art anchor-free detectors by significant margins. Source code is at https://github. com/PaddlePaddle/PaddleDetection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The performance of object detectors has been dramatically improved due to the unprecedented representation capacity of convolutional neural networks (CNNs) <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b18">19]</ref>. In <ref type="bibr" target="#b27">[28]</ref>, existing object detectors are generally based on anchors, which are categorized into two-stage <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b2">3]</ref> and one-stage methods <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b28">29]</ref>. Specifically, twostage methods have two main networks in their pipeline. One is designed to generate rough locations of target objects, called region proposals, the other is to fine-tune the * Both authors contributed equally to this work. locations and generate the corresponding category labels. By contrast, one-stage methods directly predict the locations and categories of the targets, which achieve end-toend detection. One-stage methods are widely adopted in most practical scenarios because of its advantages in terms of storage requirements and inference speed. It's worth noting that one-stage methods rely on a set of pre-defined anchor boxes, which has long been believed as the key for networks to converge. Nevertheless, large amounts of anchors hamper the generalization ability of detector, and increase the amount of computation and memory significantly.</p><p>Anchor-free detectors <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b29">30]</ref> are proposed to address these issues by removing pre-defined anchors and regressing the locations directly, which can achieve higher efficiency. Among anchor-free detectors, the performance of TTFNet <ref type="bibr" target="#b29">[30]</ref> achieves good balance between accuracy and efficiency.</p><p>In this paper, we try to explore how to appropriately introduce effective existing strategies to TTFNet <ref type="bibr" target="#b29">[30]</ref> without sacrifying the efficiency, and acquire a detector for both server and mobile side that meet practical requirements of industrial applications. For server side, in detail, we use ResNet50-vd as the backbone and implement SSLD, a semi-Supervised learning method to do knowledge distillation. On the detector head, we introduce a specially designed attention module (AGS), which proves to be pretty effective. For data augmentation, we finally choose CutMix <ref type="bibr" target="#b46">[47]</ref> according to the experimental results of various augmentation methods. Besides, we try 1x, 4x and 10x training schedule, and implement EMA strategy during training. For mobile side, we choose MobileNetV3-Large <ref type="bibr" target="#b15">[16]</ref> as the backbone, aiming to reduce the computation cost and memory. Similar to the server side, we also implement SSLD for backbone and introduce lite structure to the head. For data augmentation, we implement Cut-Mix <ref type="bibr" target="#b46">[47]</ref>, GridMask <ref type="bibr" target="#b4">[5]</ref> and refer to methods from PP-YOLO <ref type="bibr" target="#b31">[32]</ref> such as Random-Expand and Random-Crop to improve detector performance. Besides, we try 1x and 20x training schedule during training. <ref type="figure">Figure 1</ref>. The architecture of PAFNet. The overall network is composed of a backbone, an up-sampling module, an AGS module, a localization branch and a regression branch. Specifically, we choose ResNet50-vd <ref type="bibr" target="#b14">[15]</ref> as the backbone for server side, and MobileNetV3 <ref type="bibr" target="#b15">[16]</ref> for mobile side. Besides, for mobile side, we replace traditional convolution layers with lite convoluation operations as shown in <ref type="figure" target="#fig_4">Fig. 4</ref> According to the experiments, PAFNet model for server side improves the mAP on MSCOCO 2017 <ref type="bibr" target="#b26">[27]</ref> validation set from 34.3 % to 42.2% with 67.15 FPS, meanwhile PAFNet-lite for mobile side achieves a better accuracy of 23.9% mAP and 26.00 ms on Kirin 990 ARM CPU. The code and models are released in the PaddleDetection code-base (https://github.com/ PaddlePaddle/PaddleDetection).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Object detection methods based on deep learning can be roughly divided into anchor-based <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b32">33]</ref>, and anchor-free detectors <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b29">30]</ref>. Anchor-based detectors mainly consist of two-stage and one-stage object detection methods, while anchor-free detectors consist of center-based and keypoint-based object detection methods.</p><p>Anchor-based detectors adopt anchor boxes as predefined proposals for bounding box regression, which have been the mainstream in object detection field for a long time. However, anchor-based detectors suffer several drawbacks. First of all, the utilization of pre-defined anchors introduce additional hyper-parameters and large amounts of computation, which slow down the training and inference speed. Besides, most anchors are actually only backgrounds, leading to the class imbalance problem. Finally, the use of anchor impair its generalization ability to other datasets. In recent years, anchor-free methods such as Fove-aBox <ref type="bibr" target="#b17">[18]</ref>, CornerNet <ref type="bibr" target="#b19">[20]</ref>, CenterNet <ref type="bibr" target="#b8">[9]</ref>, and FCOS <ref type="bibr" target="#b43">[44]</ref> are proposed to solve aforementioned problems, which show greater potential than the SOTA anchor-based detec-tors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">CenterNet</head><p>To accelerate the inference stage, CenterNet represents objects by a single point at their bounding box center. Other properties, such as object size, dimension, 3D extent, orientation, and pose are then regressed directly from image features at the center location, and thus converting detection tasks to a standard keypoint estimation problem. The center point of objects are acquired in the format of a heatmap generated by the network, and the peaks of the heatmap are regarded as the center points of the targets. Such strategy is a single network forward-pass and abandon the tedious post-processing procedure <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b40">41]</ref>, which greatly shorten the inference time. However, Cen-terNet merely focuses on the object center for size regression, loses the opportunity to utilize the information near the object center, which slows down the network convergence. CenterNet needs 140-epochs training on public dataset MSCOCO <ref type="bibr" target="#b26">[27]</ref>. In contrast, the other types of network usually requires 12 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">TTFNet</head><p>From the aspect of practical application, TTFNet <ref type="bibr" target="#b29">[30]</ref> further improves CenterNet and achieves better balance between accuracy and efficiency. Aiming to shorten the training time, TTFNet proposes a novel approach using Gaussian kernels to encode training samples for both localization and regression. Specifically, Gaussian probabilities are treated as the weights of the regression samples to empha-size those samples near the object center. It allows networks to make use of much more positive samples and thus converge faster with larger learning rate. Together with the light-head, single-stage, and anchor free designs, TTFNet achieves a good balance among training time, inference speed, and accuracy.</p><p>Based on TTFNet, we experiment on various effective tricks to achieve better performance in terms of mAP without sacrifice on inference time both for server side and mobile side.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In this section, we first introduce details of the proposed network structure for server side and mobile side, respectively. Next, we briefly describe the existing methods to implement an effective and efficient detector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Architecture</head><p>PAFNet for server side. The overall network architecture of PAFNet is shown in <ref type="figure">Fig. 1</ref>. It is a simple and efficient network consisting of backbone, up-sampling module, AGS module, localization branch and regression branch.</p><p>The backbone is responsible for extracting feature over an input image with the shape H × W × 3. We adopt ResNet50-vd <ref type="bibr" target="#b31">[32]</ref> as the backbone, which has better performance than ResNet50 <ref type="bibr" target="#b42">[43]</ref> on ImageNet <ref type="bibr" target="#b6">[7]</ref> dataset and maintains nearly the same inference speed. Different from ResNet50, ResNet50-vd add a 2 × 2 average pooling layer at each residual module (see <ref type="figure" target="#fig_0">Fig. 2</ref>.) The feature maps at layer i = 2, 3, 4, 5 of a backbone is denoted as F i . By using a decoupling operation, the features are up-sampled to a 1/4 resolution of input image size. To improve the accuracy of small objects, the shortcut connections are added between the feature F i , i = 2, 3, 4, and corresponding up-sampling network. After that, by adopting three convolutional layers after up-sampling module, the detection head transforms the features for localization and regression task, respectively.</p><p>Localization branch generates feature map F L with the shape of H/4 × W/4 × C, where C presents classes of the dataset. For Ground Truth box G m belongs to class C m , we map G m to the size of the feature map F l , called G m . Then we use a 2D Gaussian kernel e −((x−x0) 2 +(y−y0) 2 ) to generate a heatmap for G m . The peak of the Gaussian distribution is treated as a positive target, while any other pixel is treated as a negative target. We calculate a modified version Focal Loss <ref type="bibr" target="#b24">[25]</ref>L loc for Ground Truth heatmap G m and F l at the corresponding C m channel to supervise the training of the localization branch.</p><p>Regression branch gets a feature map F R with the shape of H/4 × W/4 × 4. We also calculate a Gaussian distribution G m for the Ground Truth box. We need to calculate giou <ref type="bibr" target="#b39">[40]</ref> between all the points with in the Gaussian kernel and the feature map F R . Then we use a GIoU loss L reg related to response of the Gaussian distribution G m . Besides, inspired by TTFNet, we also introduce a sample weight ω g for each sample according to their area to balance the contribution of objects with different size. So the formula of the regression loss for a sample can be described as follow:</p><formula xml:id="formula_0">l reg = (1 − giou) × ω g .<label>(1)</label></formula><p>where l reg belongs to L reg , ω g is the sample weight. The total loss of the network is defined as follows:</p><formula xml:id="formula_1">L = ω loc L loc + ω reg L reg .<label>(2)</label></formula><p>Where L loc is modified by Focal Loss, L reg is modified by GIoU loss, ω loc is equal to 1.0 and ω reg is equal to 5.0 in our work. We also introduce AGS module to emphasize on how to calculate a probability distribution map unrelated to category differences in the localization branch and use it on regression branch adaptively. In detail, the regression loss of PAFNet is a weighted sum of size regression losses of all pixels in one target area, where the weights are provided by Gaussian kernel corresponding to the target area. The AGS module is introduced to change those weights in order to keep the training process of localization branch and regression branch consistent. To obtain the significance characteristics without category differences, a max-reduce operation is utilized to find the most significant feature value along the channel dimension, and compresses the original feature map into a matrix with only a single channel. After that, the softmax is used to calculate a response on the matrix, where the larger the response value, the greater probability of the object. Finally, as the regression branch only regress for the samples in an elliptic Gaussian distribution, we mask the softmax response by the Gaussian Kernel corresponding to the current target area.</p><p>Traditionally, the size regression loss is calculated by giou. Now under the guidance of the AGS, we reweight the giou to giou as shown in Eq 3:</p><formula xml:id="formula_2">giou = 1 − ((1 − λ) + λ × S ags ) × giou,<label>(3)</label></formula><p>where giou is modified by giou, λ is a trade-off parameter that ranges from 0 to 1, and S ags denotes the probability distribution map from the AGS module. According to the experimental results, AGS module can effectively improve the precision of our network with very limited extra memory and calculations. In addition, AGS module is only used at the stage of training which will not influence the inference speed.  PAFNet-lite for mobile side. On the mobile side, we focus more on lighter architecture and higher inference speed. Firstly, we use MobileNetV3 as backbone network, which is widely used for the models on mobile devices. Then we introduce a lite structure, shown as <ref type="figure" target="#fig_4">Fig 4 .</ref> It consists of four convolutional layers and each of them is followed by a batch-norm layer. The kernel size of these convolutional layers is 5,1,1,5, where the first and the last layers are depthwise convolutional layer, while the second and the third are point-wise convolutional layers. The lite structure is used in up-sampling network and detection head. The number of channels on detection head is reduced from 128 to 48.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Selection of Trick</head><p>In this section, we focus on how to combine the existing tricks <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b47">48]</ref> for server side and mobile side to implement an effective and efficient detector. Considering many tricks are proposed for classification and thus can-not be applied directly, we do some modification to appropriately integrate them into the detection network.</p><p>Better Pretrain Model Using a better pretrain model with higher classification accuracy can help get a better  detector. In our work, we use the distilled ResNet50vd model, denoted as ResNet50-vd-ssld, as the pretrain model for server side, the classification accuracy of which is 83.0%. It is obvious that the pretrain model will not affect the efficiency of the detectors. Similarly, we use distilled MobileNetV3 model as the pretrain model for mobile side.</p><p>EMA Exponential moving average (EMA) is a type of moving average (MA) that gives more weight and importance to the most recent data points. It considers more information and thus becomes robust to noise to a certain extent. Exponential moving average performs well in detection tasks. Specifically, each parameter W is optimized as:</p><formula xml:id="formula_3">W EM A = λW EM A + (1 − λ)W,<label>(4)</label></formula><p>CutMix CutMix <ref type="bibr" target="#b47">[48]</ref> is an improved version of MixUp <ref type="bibr" target="#b48">[49]</ref> for classification. MixUp is an operation that can mix two random samples proportionally, the category of the sample is distributed proportionally as well. The formula is shown as follows:</p><formula xml:id="formula_4">x n = λx i + (1 − λ)x j , y n = λy i + (1 − λ)y j .<label>(5)</label></formula><p>Where (x n , y n ) is the new data generated by interpolation, and (x i , y i ) and (x j , y j ) are data randomly selected from the training set. The value of λ satisfies beta distribution <ref type="bibr" target="#b13">[14]</ref>, and the value range is between 0 and 1. By contrast, according to CutMix, patches are cut and pasted among training images where the ground truth labels are also mixed proportionally to the area of the patches. By making efficient use of training pixels and retaining the regularization effect of regional dropout, CutMix usually helps achieve better performance in classification and detection. The formula is shown as follows: Where M is a binary mask to place filled areas, is element-wise multiplication, λ belongs to the beta distribution like MixUp.</p><formula xml:id="formula_5">x n = M x i + (1 − M ) x j , y n = λy i + (1 − λ)y j .<label>(6)</label></formula><p>GridMask GridMask <ref type="bibr" target="#b3">[4]</ref> uses information deletion to enhance data. This method is implemented by randomly discarding a region on the image, which is equivalent to adding a regular term to the network to avoid network overfitting.</p><p>DCN Since the geometric structure of the module used to construct the convolutional neural network (CNN) is fixed, its geometric transformation modeling ability is essentially limited. Two new modules are introduced to improve the modeling capability of the convolutional neural network (CNN), including deformable convolution and deformable ROI pooling <ref type="bibr" target="#b5">[6]</ref>. Both of them are based on the idea of further displacement adjustment of spatial sampled position information in the module, which can be learned from the object task and does not require additional monitoring signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment</head><p>Our experiments are carried out on MS COCO dataset <ref type="bibr" target="#b25">[26]</ref> included 80 categories. Following the previous practice <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17]</ref>, we use the trainval35k split containing about 115K images for training and report our main results on the test-dev split containing about 20K images by uploading our results to the codalab.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Implementation Details</head><p>Training Details For server side, we use ResNet50vd <ref type="bibr" target="#b45">[46]</ref> as the backbone network for our ablation study, which is initialized with the weights distilled on Ima-geNet <ref type="bibr" target="#b6">[7]</ref> dataset and performs better than ResNet50 <ref type="bibr" target="#b0">[1]</ref>. To speed up training and inference, we resize images to 512 × 512, which is slightly different from the common setting. In the multi-task loss function, we set the weight of localization loss as 1.0 and the regression loss as 5.0 to balance the training of two branches. What's more, the network is trained with synchronized SGD for 15K iterations with initial learning rate as 0.015 and a minibatch of 12 images distributed on 8 GPUs. The learning rate is divided by 10 at iteration 11.25K and 13.75K, respectively. Weight decay is set as 0.0004, and momentum is set as 0.9.</p><p>For mobile side, we adopt MobileNetV3 as the backbone, which is distilled on ImageNet dataset as well. The size of input image is 320 × 320 and the other settings are similar to the server side.</p><p>Inference Details At the stage of inference, we resize the input image in the same way as the training stage, and then forward it through the whole network to obtain the predicted bounding boxes with a predicted class. Since postprocessing is the same as TTFNet <ref type="bibr" target="#b30">[31]</ref>, we adopt the postprocessing hyper-parameters of TTFNet directly. We hypothesize that the performance of our detector may be further improved if we carefully adjust the hyper-parameters. Detection results are evaluated with the standard COCO metric, which average mAP of IoUs across 0.5 to 0.95. Besides, the infer time of server side model is tested on a single V100 GPU with batch size = 1, and the latency of mobile side is tested on 4x Core Kirin 990 ARM CPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Study</head><p>In this section, we gradually join tricks both in server side and mobile side. It's worth noting that the tricks are not completely independent, some of which work well when Method Backbone image size AP AP 50 AP 75 AP S AP M AP L V100 FPS without TRT CornerNet-lite <ref type="bibr" target="#b20">[21]</ref>  applied alone, but not effective when combined together. Therefore, we present how to improve the performance of the object detector step by step in the order of our exploration and discovering the effectiveness of tricks. Results are shown in <ref type="table" target="#tab_0">Table 1</ref> and <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Ablation Study for Server Side</head><p>A → B First of all, we follow the TTFNet with DarkNet53 as the backbone and get a basic version(A), the mAP of the model reached 32.9%. Because the ResNet series is widely used, we replace the original backbone Darknet53 with ResNet50-vd and apply AGS module on head. In this way, we get modified TTFNet(B) with the mAP of 34.3%, which is higher than the original model (No.A in Tabel 1), while its parameters and FLOPs are much smaller than the original TTFNet model. B → C Replacing the pre-trained model is a very common approach to improve model accuracy. Therefore, we use the distilled ResNet50-vd-ssld model for backbone initialization. For fair comparison, this distillation model still uses ImageNet for pre-training. The mAP of model C can be further improved by 1.8% than the model B. In fact, using other detection datasets for pre-training can also greatly improve the performance of the model, but this is beyond the scope of this paper.</p><p>C → D We try to optimize the training strategy. Considering that the number of training rounds of 1x scheduler could not make the model fully convergent, we train the model with 4x scheduler and get the mAP of 36.5%.</p><p>D → E We try several data augmentation methods such as Mixup, Cutout <ref type="bibr" target="#b7">[8]</ref> and CutMix, and the experiment results shows that CutMix get the best results. Besides, When training a model, it is often beneficial to maintain mov-ing averages of the trained parameters. The Exponential Moving Average (EMA) compute the moving averages of trained parameters using exponential decay, for each parameter W, we maintain an shadow parameter as the Equ. 4. The data augmentation Cutmix and EMA policy help improve the mAP by 0.4%.</p><p>E → F Considering that the number of parameters and FLOPs of ResNet50-vd are much smaller than those of Darknet53, we replace the 3×3 convolutional layer at the last stage of ResNet50-vd with deformable convolution layer and predict head branch. In this way, we get the model(No. F in <ref type="table" target="#tab_0">Table 1</ref>) with a mAP of 39.8%.</p><p>F → G Following model D, we implement 10x learning scheduler and achieve the highest mAP of 42.2%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Ablation Study for Mobile Side</head><p>Similar to the server-side model, we also build a basic version of network(A) with backbone MobilenetV3-large, the mAP of which is 16.3%. Then we replace the backbone by a distilled MobilenetV3 model (B) and get a mAP of 18.0%. In order to make the model converge enough, 20x is trained on the model and the mAP is improved by 1.8%. The Cut-Mix, GridMask and other data augmentation modules are also used on the mobile side and get a mAP of 23.9% and the latency on Kirin 990 ARM CPU of 26.00 ms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with Other State-of-The-Art Detectors</head><p>We compare our PAFNet with other state-of-the-art anchor-free object detectors on the test-dev split of MS COCO benchmark in <ref type="table" target="#tab_1">Table 3</ref>. The FPS results of PAFNet and other methods are all tested on V100 with batch size = 1, results marked by '+' are updated results from the corresponding official code-base.</p><p>As shown in <ref type="table" target="#tab_1">Table 3</ref>, our PAFNet with the backbone ResNet50-vd achieves 42.2% in AP and 67.15 FPS in speed. Compared with other state-of-the art anchor-free methods, both key-point methods and center-based methods, such as FCOS and EfficentNet, our PAFNet has certain advantages in speed and accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we introduce a new implementation of anchor-free detector both for server side and mobile side. For server side, PAFNet outperforms other state-of-the-art anchor-free detectors in both accuracy and speed. Besides, we have optimized the framework of PAFNet-lite for mobile side. We conduct lots of experiments to figure out what tricks work on PAFNet for server and mobile side, respectively. Finally, we develop an useful anchor-free detector with good balance between accuracy and efficiency. We hope this paper can provide developers useful experimental results and detection models, and thus help them achieve better performance in practical applications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>The architecture of ResNet-vd module. The blue part represents the extra average pooling layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>The architecture of AGS Module. Output feature map of localization branch with the shape of H/4 × W/4 × C is adopted as the input of AGS module. Through a series of operations including max-reduce, softmax and mask, the map is transformed to a probability distribution with the shape of H/4 × W/4 × 1. The output of AGS module is used to reweight the contribution of giou in regression branch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>The architecture of lite convolution used in up-samping network and detection head. (best viewd in color)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>This work was supported by the National Key Research and Development Project of China (2020AAA0103500).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>No. Method image size AP AP 50 AP 75 AP S AP M AP L Params GFLOPS Infer Time FPS A TTFNet-DarkNet 512 32.9 50.4 35.2 16.8 36.5 44.6 43.00M 134.97 9.79ms 102.14 B TTFNet+ResNet50vd+AGS* 512 34.3 52.2 36.6 17.1 37.9 46.8 27.74M 104.44 11.72ms 85.42 C B + Better Pretrain 512 36.1 54.7 38.5 18.8 39.8 49.6 27.74M 104.44 11.72ms 85.42 D C + 4x Scheduler 512 36.5 54.2 38.7 19.2 39.8 50.1 27.74M 104.44 11.72ms 85.The ablation study of tricks on the MS COCO test-dev for server side. AP AP 50 AP 75 AP S AP M AP L</figDesc><table><row><cell>42</cell></row></table><note>Table 2. The ablation study of tricks on the MS COCO test-dev for mobile side on Kirin 990 ARM CPU .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>PAFNet vs. other state-of-the-art anchor-based or anchor-free detectors in single-model and single-scale results for server side.</figDesc><table><row><cell></cell><cell>hourglass104 [23]</cell><cell>512</cell><cell>34.4 -</cell><cell>-</cell><cell cols="3">14.8 36.9 35.50</cell><cell>35.50</cell></row><row><cell>EfficentDet-D0 [42]</cell><cell>Efficient-B0</cell><cell>512</cell><cell cols="5">33.8 52.2 35.8 12.0 38.3 51.2</cell><cell>98 +</cell></row><row><cell>EfficentDet-D1 [42]</cell><cell>Efficient-B1</cell><cell>640</cell><cell cols="5">39.6 58.6 42.3 17.9 44.3 56.0</cell><cell>74.1 +</cell></row><row><cell>EfficentDet-D2 [42]</cell><cell>Efficient-B2</cell><cell>768</cell><cell cols="5">43.0 62.3 46.2 22.5 47.0 58.4</cell><cell>56.5 +</cell></row><row><cell>EfficentDet-D3 [42]</cell><cell>Efficient-B3</cell><cell>896</cell><cell cols="5">45.8 65.0 49.3 26.6 49.4 59.8</cell><cell>34.5 +</cell></row><row><cell>RetinaNet [25]</cell><cell>ResNet50</cell><cell>640</cell><cell>37.0 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>37</cell></row><row><cell>RetinaNet [25]</cell><cell>ResNet101</cell><cell>640</cell><cell>37.9 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>29.4</cell></row><row><cell>RetinaNet [25]</cell><cell>ResNet50</cell><cell>1024</cell><cell>40.1 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>19.6</cell></row><row><cell>RetinaNet [25]</cell><cell>ResNet101</cell><cell>1024</cell><cell>41.1 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>15.4</cell></row><row><cell>FCOS-imprv [44]</cell><cell>ResNet50</cell><cell>800</cell><cell>38.7 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>22</cell></row><row><cell>FCOS-imprv+DCN [44]</cell><cell>ResNet50</cell><cell>800</cell><cell>44.4 -</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>13.36</cell></row><row><cell cols="2">CenterNet(Objects) [10] DLA-34 [45]</cell><cell>512</cell><cell cols="2">37.4 55.1 40.8</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>55.9</cell></row><row><cell>CenterNet(Objects) [10]</cell><cell>ResNet18</cell><cell>512</cell><cell cols="2">28.1 44.9 29.6</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>153.75</cell></row><row><cell>TTFNet [31]</cell><cell>Darknet</cell><cell>512</cell><cell cols="5">32.9 50.4 35.2 16.8 36.5 44.6</cell><cell>102.14</cell></row><row><cell>PAFNet</cell><cell>ResNet50-vd</cell><cell>512</cell><cell cols="5">42.2 59.8 45.3 22.8 45.8 59.2</cell><cell>67.15</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Akiba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukuda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.04325</idno>
		<title level="m">Extremely large minibatch sgd: Training resnet-50 on imagenet in 15 minutes</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improving object detection with one line of code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bodla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cascade r-cnn: Delving into high quality object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6154" to="6162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.04086</idno>
		<title level="m">Gridmask data augmentation</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Gridmask data augmentation. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="764" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved regularization of convolutional neural networks with cutout</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Centernet: Object detection with keypoint triplets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.08189</idno>
		<title level="m">Centernet: Object detection with keypoint triplets</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rich feature hierarchies for accurate object detection and semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="580" to="587" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Handbook of beta distribution and its applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nadarajah</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<title level="m">Searching for mobilenetv3</title>
		<imprint>
			<date type="published" when="1905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Foveabox: Beyond anchor-based object detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03797</idno>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arxiv 2019. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Foveabox: Beyond anchor-based object detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03797</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="84" to="90" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cornernet: Detecting objects as paired keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="765" to="781" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Cornernet: Detecting objects as paired keypoints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Law</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="734" to="750" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An exponential movingaverage sequence and point process (ema1)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lawrance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Probability</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="98" to="113" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Contextual hourglass network for semantic segmentation of high resolution aerial imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schultz-Fellenz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.12813</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Survey of convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2508" to="2515" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep learning for generic object detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fieguth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comp. Vis</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SSD: single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Training-time-friendly network for real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Training-time-friendly network for real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Ppyolo: An effective and efficient implementation of object detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ding</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.12099</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">iffDetector: Inference-aware feature filtering for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
		<idno type="arXiv">arXivpreprintarXiv:2006.12708</idno>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Efficient non-maximum suppression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neubeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="850" to="855" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Inception single shot multibox detector for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICMEW</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">You only look once: Unified, real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Divvala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="779" to="788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">YOLO9000: better, faster, stronger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6517" to="6525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.02767</idno>
		<title level="m">Yolov3: An incremental improvement</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Generalized intersection over union: A metric and a loss for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Weighted boxes fusion: ensembling boxes for object detection models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Solovyev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gabruseva</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Polyp segmentation in colonoscopy images using ensembles of u-nets with efficientnet and asymmetric similarity loss function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Thanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Long</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 RIVF International Conference on Computing and Communication Technologies (RIVF)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Detecting affect states using vgg16, resnet50 and se-resnet50 networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Theckedath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sedamkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SN Computer Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Fcos: Fully convolutional one-stage object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="9627" to="9636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Deep layer aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2403" to="2412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.07506</idno>
		<title level="m">The 1st tiny object detection challenge: Methods and results</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6023" to="6032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Cad: Scale invariant framework for real-time object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCVW</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
