<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dense Steerable Filter CNNs for Exploiting Rotational Symmetry in Histology Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Graham</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Epstein</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasir</forename><surname>Rajpoot</surname></persName>
						</author>
						<title level="a" type="main">Dense Steerable Filter CNNs for Exploiting Rotational Symmetry in Histology Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T21:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Rotation-equivariance</term>
					<term>steerable filters</term>
					<term>deep learning</term>
					<term>computational pathology</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Histology images are inherently symmetric under rotation, where each orientation is equally as likely to appear. However, this rotational symmetry is not widely utilised as prior knowledge in modern Convolutional Neural Networks (CNNs), resulting in data hungry models that learn independent features at each orientation. Allowing CNNs to be rotation-equivariant removes the necessity to learn this set of transformations from the data and instead frees up model capacity, allowing more discriminative features to be learned. This reduction in the number of required parameters also reduces the risk of overfitting. In this paper, we propose Dense Steerable Filter CNNs (DSF-CNNs) that use group convolutions with multiple rotated copies of each filter in a densely connected framework. Each filter is defined as a linear combination of steerable basis filters, enabling exact rotation and decreasing the number of trainable parameters compared to standard filters. We also provide the first in-depth comparison of different rotation-equivariant CNNs for histology image analysis and demonstrate the advantage of encoding rotational symmetry into modern architectures. We show that DSF-CNNs achieve state-of-the-art performance, with significantly fewer parameters, when applied to three different tasks in the area of computational pathology: breast tumour classification, colon gland segmentation and multi-tissue nuclear segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Index</head><p>Terms-Rotation-equivariance, steerable filters, deep learning, computational pathology. • A Dense Steerable Filter CNN that achieves rotationequivariance by integrating steerable filter group convo-arXiv:2004.03037v2 [eess.IV]</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>T HE recent advances in the analysis of Haematoxylin &amp; Eosin (H&amp;E) stained whole-slide images (WSIs) can largely be attributed to the rise of digital slide scanning <ref type="bibr" target="#b0">[1]</ref>. In particular, Convolutional Neural Networks (CNNs) leverage the prior knowledge that images have translational symmetry and utilise a weight sharing strategy, which guarantees that a translation of the input will result in a proportional translation of the features. This property, known as translation equivariance, is an inherent property of the CNN and removes the need to learn features at all spatial locations, significantly reducing the number of learnable parameters. In certain image analysis applications, where there is no global orientation, it is desirable to extend this property of equivariance beyond translation to also rotation. One such example is the field of computational pathology (CPath) where important image features can appear at any orientation ( <ref type="figure" target="#fig_0">Fig. 1</ref>). Therefore, we should be able to learn those features, regardless of their orientation. In the absence of rotation-equivariance, data S. <ref type="bibr">Graham</ref>  All image regions are equally as likely to appear augmentation is typically used, where multiple rotated copies of the WSI patches are usually introduced to the network during the training process. However, the augmentation strategy requires many more parameters in order to learn weights of different orientations. Instead, encoding rotational symmetry as a prior knowledge into current deep learning architectures by enforcing rotation-equivariance requires fewer parameters and leads to an overall superior discriminative ability. Also, rotation-equivariant CNNs typically converge quicker because the network does not need to spend time learning different filter orientations. CPath is ripe ground for the utilisation of rotationequivariant models, yet most models fail to incorporate this prior knowledge into the CNN architectures. Inspired by recent developments in the study of rotation-equivariant CNNs <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, we propose Dense Steerable Filter based CNNs (DSF-CNNs) that integrate steerable filters <ref type="bibr" target="#b5">[6]</ref> with group convolution <ref type="bibr" target="#b1">[2]</ref> and a densely connected framework <ref type="bibr" target="#b6">[7]</ref>. Dense connectivity enables efficient gradient propagation, encourages feature re-use and consequently leads to superior performance. Each filter is defined as a linear combination of circular harmonic basis filters, enabling exact rotation and significantly reducing the number of parameters compared to standard filters. The main contributions of this work are listed as follows: lutions within a densely connected network. • The first thorough comparison of multiple rotationequivariant for CPath. <ref type="bibr">•</ref> We demonstrate state-of-the art performance across multiple histology image datasets with far fewer parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK A. CNNs for translation equivariance</head><p>Images can contain numerous symmetries and therefore patterns may appear at various spatial positions and orientations. Recent methods <ref type="bibr" target="#b7">[8]</ref> have shown that these symmetries can be detected, yet in this work we focus on how symmetries can be leveraged as a prior knowledge to increase the performance of image recognition algorithms. Pioneered by LeCun et al. in 1994 <ref type="bibr" target="#b8">[9]</ref>, CNNs inherently incorporate translation symmetry in images and achieve translation equivariance by re-using filters at all spatial locations. Therefore, a shift of the input leads to a proportional shift of the filter responses. This design drastically reduces the number of required parameters because features do not need to be learned independently at each location. Since the increase in computing power and the development of algorithms that assist network optimisation <ref type="bibr" target="#b9">[10]</ref> CNNs have become deeper <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b6">[7]</ref>, leading to current state-of-the-art performance in numerous image recognition tasks <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. As a result of the success of deep learning, CNNs have since been widely used in CPath for various tasks including: gland segmentation <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>; nucleus segmentation <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>; mitosis detection <ref type="bibr" target="#b18">[19]</ref>; cancer type prediction <ref type="bibr" target="#b19">[20]</ref> and cancer grading <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. Yet, unlike translation, CNNs do not behave well with respect to rotation because this symmetry is not built into the network architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Exploiting rotational symmetry</head><p>Rotating the data: It is well known that histology images have no global orientation and therefore standard practice is to apply rotation augmentation to the training data <ref type="bibr" target="#b22">[23]</ref>. This improves performance, but requires many parameters and is therefore prone to overfitting. Also, there is no guarantee that CNNs trained with rotation augmentation will learn an equivariant representation and generalise to data with small rotations <ref type="bibr" target="#b23">[24]</ref>. To reduce the variance of predictions of multiple orientations, test-time augmentation (TTA) can be used <ref type="bibr" target="#b24">[25]</ref>. However, with TTA inference time scales linearly with the number of augmented copies. TI-Pooling <ref type="bibr" target="#b25">[26]</ref> utilises multiple rotated copies of the input in a twin network architecture, where a pooling operation over orientations is performed to find the optimal canonical instance of the input images for training. However, like TTA, TI-Pooling is computationally expensive.</p><p>Rotating the filters: Cohen &amp; Welling <ref type="bibr" target="#b1">[2]</ref> pioneered group equivariant CNNs (G-CNNs), where the convolution was generalised to share weights over additional symmetry groups beyond translation. However, they limited the filter transformation to 90 • rotations and horizontal/vertical flips to ensure exact transformations on the 2D pixel grid. Veeling et al. <ref type="bibr" target="#b26">[27]</ref> showed that these G-CNNs can be used to improve the performance of metastasis detection in breast histology images. Furthermore, Linmans et al. <ref type="bibr" target="#b27">[28]</ref> and Graham et al. <ref type="bibr" target="#b28">[29]</ref> extended the application of the G-CNNs proposed by Cohen &amp; Welling to pixel-based segmentation in histology images, highlighting an improved performance over conventional CNNs. The symmetries of a square grid are limited to integer translations extended by the dihedral group of order 8 (4 reflections and 4 rotations). To counter the limitation of working wih square grids in the G-CNN, Hoogeboom et al. <ref type="bibr" target="#b29">[30]</ref> used hexagonal filters. However, this strategy requires images to be resampled on a hexagonal lattice, which is an additional overhead. Instead of using exact filter rotations, Bekkers et al. <ref type="bibr" target="#b30">[31]</ref> and Lafarge et al. <ref type="bibr" target="#b4">[5]</ref> applied G-CNNs to several medical imaging tasks by rotating filters with bilinear interpolation. Therefore, this method was not restricted to rotations by multiples of 90 • , but may introduce interpolation artefacts. Oriented response networks <ref type="bibr" target="#b31">[32]</ref> use active rotating filters during the convolution that explicitly encodes location and orientation information within the feature maps.</p><p>The aforementioned methods carry forward the feature maps for each orientation throughout the network. Instead, Marcos et al. <ref type="bibr" target="#b3">[4]</ref> converted the output of multiple convolutions with rotated filter copies to a vector field by considering the magnitude and angle of the highest scoring orientation at every spatial location, leading to more compact models. To help overcome the issue of inexact filter rotation, the method only considered parameters at the centre of each filter and therefore required larger filters and consequently more parameters.</p><p>Rotating the feature maps: Dieleman et al. proposed a method similar to the G-CNN, but instead of rotating the filters, the feature maps were rotated. This design choice has no effect on the equivariance, yet any rotation that is not a multiple of 90 • may suffer from interpolation artefacts.</p><p>Steerable filters: CNNs that encode rotation-equivariance are typically only equivariant to discrete rotations. Cohen &amp; Welling <ref type="bibr" target="#b32">[33]</ref> first proposed steerable CNNs and described a general mathematical theory that applies to both continuous and discrete groups. To achieve full 360 • equivariance, Worrall et al. <ref type="bibr" target="#b33">[34]</ref> used the concept of steerable filters <ref type="bibr" target="#b5">[6]</ref> and constrained the weights to be complex circular harmonics. Cheng et al. <ref type="bibr" target="#b34">[35]</ref> propose a rotation-equivariant CNN, named RotDCF, that decomposes filters over joint steerable bases across the space and the group geometry simultaneously. Weiler et al. <ref type="bibr" target="#b2">[3]</ref> learned steerable filters as a linear combination of atomic basis filters, which enabled exact filter rotation within G-CNNs. Then, these steerable filters were used within the group convolution to enable the network to be equivariant to rotation. Weiler &amp; Cesa <ref type="bibr" target="#b35">[36]</ref> then performed an extensive comparison of rotation equivariant models using steerable filters. Our method builds on the approach proposed by Weiler et al. <ref type="bibr" target="#b2">[3]</ref>, by incorporating steerable filter group convolutions into a densely connected framework for superior performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. MATHEMATICAL FRAMEWORK</head><p>In this section we present the key mathematical concepts used in our framework. We first describe images, filters and feature maps as functions. We introduce steerable filters and describe the group-convolution (G-convolution) operation with these filters. This operation leads to G-equivariance. Below, we deal with a single filter at a time, although the method actually needs a whole filter bank to be used. We follow the method described by Weiler et al. <ref type="bibr" target="#b2">[3]</ref>, but we use a slightly different formulation. We encourage readers to read both approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Images and feature maps as functions</head><p>We model an image as a map f : C ∼ = R 2 → R with compact support 1 . Let F be the vector space over R of all f : C → R, with compact support, and let F C be the vector space over C of all functions f : C → C with compact support.</p><p>We denote by SE(2) the group of isometries of the plane, omitting reflections. Each element of SE(2) can be written in the form z → e iθ z+b, where z, b ∈ C and θ ∈ R. If g ∈ SE(2) and f ∈ F, we define g.f ∈ F by:</p><formula xml:id="formula_0">(g.f )(z) = f (g −1 (z)) for z ∈ C.<label>(1)</label></formula><p>The same definition is used for g.f :</p><formula xml:id="formula_1">C → C when f ∈ F C .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Steerable functions and filters:</head><p>The additive group of real numbers R acts on C by rotations keeping 0 fixed. By (1), it acts linearly on F (and on F C ):</p><formula xml:id="formula_2">f θ (z) = f (e −iθ z) for f ∈ F, θ ∈ R.</formula><p>We define V (f ) ⊂ F C to be the complex vector subspace spanned by the orbit f θ | θ ∈ R . If V (f ) is a finite dimensional vector space, we say that f is steerable.</p><p>Theorem: A necessary and sufficient condition for ψ ∈ F C to be steerable is that there should exist an integer A ≥ 0, and radial profile functions R k : [0, ∞) → C for k ∈ Z and −A ≤ k ≤ A, such that, in polar coordinates:</p><formula xml:id="formula_3">ψ(r, ϕ) = A k=−A R k (r)e ikϕ ,<label>(2)</label></formula><p>where some or all of the radial profile functions R k may be identically zero. To ensure that ψ has compact support, each R k is assumed to have compact support. If ψ satisfies (2), then V (ψ) is clearly finite dimensional. The reverse implication takes a bit longer to argue, but easily follows from standard theorems in Group Representation Theory 2 . <ref type="figure" target="#fig_1">Fig. 2</ref> is a graphical representation of basis harmonic filters that appear in <ref type="bibr" target="#b1">(2)</ref>.</p><p>Real Version: In practice we will work with steerable realvalued filters. Since a real-valued steerable filter ψ is also a complex-valued steerable filter, we can apply (2) to obtain, in the same notation:</p><formula xml:id="formula_4">ψ(r, ϕ) = Re A k=−A R k (r)e ikϕ . 1</formula><p>The support of f is the smallest closed subset of C containing {z ∈ C | f (z) = 0}.</p><p>2 For full mathematical rigour, the theorem requires the additional hypothesis that, for each r, ψ is a continuous function of ϕ. See also <ref type="bibr" target="#b36">[37]</ref> for more technical details. Now Re(z) = (z +z)/2. It follows that we can write instead (but the radial profiles change):</p><formula xml:id="formula_5">ψ(r, ϕ) = Re A k=0 R k (r)e ikϕ<label>(3)</label></formula><p>where</p><formula xml:id="formula_6">R 0 : [0, ∞) → R and, for k &gt; 0, R k : [0, ∞) → C.</formula><p>C. Feature maps modelled on a group:</p><p>Following the pioneering work of Cohen and Welling [2] and of Weiler et al. <ref type="bibr" target="#b2">[3]</ref>, we explain the changes to the architecture of CNNs, required to express rotation equivariance.</p><p>We fix an integer n &gt; 0. We use the symbol ρ u,θ to denote the euclidean transformation given by</p><formula xml:id="formula_7">ρ u,θ (z) = e iθ z + u,<label>(4)</label></formula><p>where u ∈ C and θ = 2πs/n, for some integer s with 0 ≤ s &lt; n. Let G ⊂ E(2) be the subgroup of all such transformations. Let U be a group, with two subgroups U 1 and U 2 . U is said to be a semidirect product of U 1 with U 2 , denoted by U 1 U 2 , if there are projections p 1 : U → U 1 and U → U 2 -this means that p 1 |U 1 and p 2 |U 2 are both identity maps-such that p 2 is a homomorphism with kernel U 1 , and p 1 × p 2 : U → U 1 × U 2 is an bijection, but, in general, not an isomorphism of groups. The importance of this concept in the study of equivariant CNNs was first pointed out in <ref type="bibr" target="#b1">[2]</ref>, and there is a systematic study <ref type="bibr" target="#b35">[36]</ref>.</p><p>G has two important subgroups, namely</p><formula xml:id="formula_8">C n = {ρ 0,θ | θ = 2πs/n, 0 ≤ s &lt; n},<label>(5)</label></formula><p>a cyclic subgroup of order n consisting of all rotations in G keeping 0 ∈ C fixed and</p><formula xml:id="formula_9">T = {ρ u,0 | u ∈ C} ∼ = C,</formula><p>consisting of all translations of C. We define the group</p><formula xml:id="formula_10">C n = {θ | θ = 2πs/n, 0 ≤ s &lt; n},<label>(6)</label></formula><p>with group law addition mod 2π. Clearly, C n ∼ = C n . We also use {e} ∼ = C 1 to denote the trivial group with one element. The bijection</p><formula xml:id="formula_11">Π : G → C × C n defined by Π(ρ u,θ ) = (u, θ)<label>(7)</label></formula><p>gives G the semidirect product structure G = T C n . We impose on C×C n a product metric that is the same as the usual Euclidean metric on C, and is any convenient fixed metric on the finite discrete space C n . The bijection Π is then used to impose a metric on G, so that Π becomes an isometry. Π does not preserve the group structure, unless n = 1.. As a metric space G is the disjoint union of the n right cosets</p><formula xml:id="formula_12">C θ = T ρ 0,θ = {ρ u,θ | u ∈ C} ⊂ G for θ ∈ C n ,<label>(8)</label></formula><p>such that each coset is isometric to C.</p><p>A G-feature map is defined to be a function f : G → R, with compact support.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. G-convolutions:</head><p>We generalize the concept of a convolution to a Gconvolution, that maps one G-feature map to another.</p><p>We give the definition of G-convolution, where G 3 is a group with a measure µ G -this means that, given f : G → R, we can form the integral denoted by g∈G f (g) dµ G or g∈G f (g) dg.</p><p>We will stick to the unimodular case, which is general enough for all cases of interest in this paper. The word unimodular means that we can change the dummy variable g in the integral to g −1 , or gh or hg (h ∈ G constant), without changing the value of the integral.</p><p>Given maps f : G → R and ψ : G → R, we define their</p><formula xml:id="formula_13">G-convolution (f * G ψ) : G → R by (f * G ψ)(g) = h∈G f (gh −1 )ψ(h) dh (9) = h∈G f (h)ψ(h −1 g) dh for g ∈ G.</formula><p>The first equality is a definition, whereas the second follows by a change of variable. G-convolution is automatically G-equivariant. To see this, note that, for any α ∈ G,</p><formula xml:id="formula_14">(ρ α (f ) * G ψ)(g) = f (α −1 gh −1 )ψ(h) dh = (f * G ψ)(α −1 g) = (ρ α (f * G ψ))(g).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It follows that</head><formula xml:id="formula_15">ρ α (f ) * G ψ = ρ α (f * G ψ).<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Hidden layer G-convolutions and G-filters</head><p>By a G-filter, we mean a function G → R. Formally this is the same as a G-feature map. However, in an implementation of these ideas, a G-feature map will turn out to be a discrete object, specified by a collection of matrices, whereas a G-filter retains its identity as a function. This is what enables exact rotation of a G-filter by an arbitrary angle.</p><p>In order to define G-convolutions, we need a measure on the space G, as described for G in Subsection III-D. The measure µ G on G is given by using the usual euclidean (area) measure on each C θ ∼ = C. Note that (G, µ G ) is unimodular (term defined in Subsection III-D) because rotation is measure preserving on the plane. Integration of a function f : G → R, with respect to µ G , is carried out by first integrating each of the n functions f |C θ ∼ = C → R and adding the n resulting terms.</p><p>We now define an "atomic steerable planar filter", which is not learned, but defined and does not change during training (see <ref type="bibr" target="#b12">(13)</ref>). Instead our network learns the complex coefficients used in a complex linear combination of the atomic steerable planar filters.</p><p>For each non-negative integer j, we define τ j : [0, ∞) → R to be a Gaussian, with mode at j, as</p><formula xml:id="formula_16">τ j (r) = exp(−|r − j| 2 /2σ 2 ) for j ≥ 0, r ≥ 0.<label>(11)</label></formula><p>Let j and k be non-negative integers. By a atomic steerable planar filter, we mean a map ψ jk : C → C defined by</p><formula xml:id="formula_17">ψ jk (u) = τ j (|u|)e ik arg(u) .<label>(12)</label></formula><p>If, in addition, λ ∈ C n , we define the atomic steerable G-filter</p><formula xml:id="formula_18">ψ jkλ : G → R by ψ jkλ (ρ u,θ ) = 0 if λ = θ τ j (|u|)e ik(arg(u)−θ) if λ = θ.<label>(13)</label></formula><p>From (12)</p><formula xml:id="formula_19">ψ jkλ (ρ u,θ ) = e −ikθ ψ jk (u) if θ = λ,<label>(14)</label></formula><p>which is ψ jk rotated by angle θ. Any finite complex linear combination of atomic steerable G-filters, j,k,λ w jkλ ψ jkλ , is again a steerable G-filter. In our framework, we plan to convolve each G-feature map with the real part of such a sum. By (9) the result of such a convolution is another G-feature map. The complex numbers w jkλ are weights in the network, determined by the network during training and each w jkλ gives rise to two real weights. We will initially restrict to a single term in the finite sum, in order to keep the formulas uncluttered, and then add them together.</p><p>Let f : G → R be a G-feature map. From (9), we have the formula</p><formula xml:id="formula_20">(f * G Re(w jkλ ψ jkλ )) (ρ z,θ ) = ρu,ϕ∈G f (ρ u,ϕ ) · Re(w jkλ ψ jkλ (ρ v,β )) dµ G ,<label>(15)</label></formula><p>where ρ v,β = ρ −1 u,ϕ ρ z,θ , so that v = e −iϕ (z−u) and β = θ−ϕ. From <ref type="bibr" target="#b11">(12)</ref> and <ref type="formula" target="#formula_0">(13)</ref>,</p><formula xml:id="formula_21">ψ jkλ (ρ v,β ) = 0 if λ = β = θ − ϕ e −ikϕ · ψ jk (z − u) if λ = β = θ − ϕ.<label>(16)</label></formula><p>Writing f ϕ (u) = f (ρ u,ϕ ), we obtain from <ref type="formula" target="#formula_0">(15)</ref> and (16)</p><formula xml:id="formula_22">(f * G Re(w jkλ ψ jkλ )) (ρ z,θ ) = Re w jkλ · e −ik(θ−λ) · (f θ−λ * ψ jk ) (z) = f θ−λ * Re(w jkλ · e −ik(θ−λ) ψ jk ) (z).<label>(17)</label></formula><p>If we add over λ ∈ C n , then we can substitute ϕ = θ − λ and add over ϕ ∈ C n , since θ is fixed in <ref type="bibr" target="#b16">(17)</ref>. Adding over j, k and ϕ, we obtain</p><formula xml:id="formula_23">  f * G Re( jkλ w jkλ ψ jkλ )   (ρ z,θ ) = jkϕ f ϕ * Re w jk(θ−ϕ) · e −ikϕ ψ jk (z)<label>(18)</label></formula><p>which recovers the same result as (10) in <ref type="bibr" target="#b2">[3]</ref>. We have ignored the fact that there are normally many channels (G-feature maps) in the domain and many channels in the range. Each pair (channel in domain, channel in base) needs its own Gfilter, so each such pair gives rise to different weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. The input layer G-convolution</head><p>The input to network is an image that can be thought of as a map f : C → R, which we compose with P : G → C given by P (ρ u,θ ) = u, to obtain f • P : G → R. By <ref type="formula" target="#formula_0">(17)</ref>, we have</p><formula xml:id="formula_24">((f • P ) * G Re(wψ jkλ )) (ρ z,θ ) = Re((w jkλ · e ikλ ) · e −ikθ · (f * ψ jk )(z)</formula><p>Since w jkλ is a complex scalar that the network has to estimate, λ adds no new information and we dispense with it. We then sum over all terms, obtaining a simplified version of <ref type="bibr" target="#b17">(18)</ref>.</p><p></p><formula xml:id="formula_25"> (f • P ) * G Re   jk w jk ψ jk     (ρ z,θ ) =   f * Re   jk w jk · e −ikθ · ψ jk     (z).<label>(19)</label></formula><p>This gives a principled derivation of Equation <ref type="formula" target="#formula_12">(8)</ref> in <ref type="bibr" target="#b2">[3]</ref>. In particular, our proof of G-equivariance (see <ref type="formula" target="#formula_0">(10)</ref>) works equally well for input layer and hidden layer G-convolutions. See <ref type="figure">Fig. 3</ref>(b) for a graphical illustration of the method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Sampling and the discrete case</head><p>The above formulas assume that the functions involved are continuous. But a computer is a finite machine, so we need to work with discrete data, and this involves sampling. Sampling planar steerable filters: In the computer, a planar feature map is represented by a matrix, not by a continuous function. According to <ref type="bibr" target="#b17">(18)</ref> and <ref type="formula" target="#formula_0">(19)</ref>, we need to convolve this matrix with the real part of a complex linear combination of atomic planar filters, ψ jk . Now ψ jk is a function, not a matrix-this is exactly what allows rotation of the filter through an arbitrary angle. On the other hand, convolution with a matrix requires a matrix, not a function. We therefore have to sample the atomic filters ψ jk , and their rotations through angles 2πs/n for 0 ≤ s &lt; n, at the integer points a + ib, where a and b are integers. We then perform a weighted linear combination of the sampled filters and apply <ref type="bibr" target="#b17">(18)</ref> or <ref type="bibr" target="#b18">(19)</ref>. As the Nyquist Sampling Theorem suggests, for a fixed size of steerable filter, aliasing may occur unless one bounds the frequencies used from above. In line with Weiler &amp; Cesa <ref type="bibr" target="#b35">[36]</ref>, we use frequencies up to k = 0, 2, 3, 2 for j = 0, 1, 2, 3 in all 77 steerable basis filters. Using larger filters enables higher frequencies before aliasing, yet leads to an increase in computation time and may lead to overfitting. Sampling G-filters: As in the case of planar convolution just discussed, our formulas need to be reinterpreted when the various component pieces of a hidden layer G-convolution are formulated as arrays of dimension 3 or higher, rather than as functions. For example a G-feature map has been defined as a function G → R, and we need to explain how a function on the continuous group G is represented in the computer by n matrices.</p><p>As shown in <ref type="formula" target="#formula_12">(8)</ref>, G as a metric space is the disjoint union θ∈C n C θ of n copies of C, with its usual euclidean metric. For each θ ∈ C n (see <ref type="formula" target="#formula_12">(8)</ref>) we define</p><formula xml:id="formula_26">Z θ = {ρ a+ib,θ | a, b ∈ Z} ⊂ C θ .<label>(20)</label></formula><p>Each point of C θ is within a distance 1/ √ 2 of some point in the lattice Z θ . It is therefore reasonable to use, as a G-feature map, f :</p><formula xml:id="formula_27">θ∈C n Z θ → R.<label>(21)</label></formula><p>Analogously to the notation just before <ref type="formula" target="#formula_0">(17)</ref>, we write f θ = f |Z θ . The domain is infinite, but since f is assumed to have compact support, we need only record the values of f at a finite number of elements of G. In this way, a G-feature map is replaced by n real matrices all of the same size.</p><p>We have also defined a G-filter as a function G → R. This is also sampled on θ∈C n Z θ . When learning the complex coefficients w jkλ that appear in <ref type="bibr" target="#b14">(15)</ref>, the values of j and k are limited for the reasons just explained for the planar situation, namely to avoid aliasing and overfitting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DENSE STEERABLE FILTER CNN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Network architecture</head><p>The main building blocks of our proposed rotationequivariant DSF-CNN 4 are: an input layer G-convolution layer; steerable filter G-dense-blocks and a G-pooling layer. Below, we build on the theoretical explanation in Section III to describe the separate components of our proposed approach.</p><p>Input Layer G-convolution: Up to the G-pooling operation, all convolutions within our network are steerable Gconvolutions, as described in Section III-E. Therefore, we predefine a set of circular harmonic basis filters using (2) and sample the filters on the square grid, as can be seen in <ref type="figure" target="#fig_1">Fig.  2</ref>. Then, we learn how to linearly combine these atomic basis filters to generate steerable filters and consider only the real part for our convolution filter, as shown in <ref type="formula" target="#formula_5">(3)</ref>. This can be visualised in <ref type="figure">Fig. 3a</ref>. The input layer steerable G-convolution maps an image f :</p><formula xml:id="formula_28">C → R to some G-feature map h : G → R.</formula><p>Each G-feature map is determined by its restriction h θ to each coset C θ ∼ = C. Specifically, we create n rotated copies of each steerable filter and independently convolve the filters with the input to produce n feature maps (or a single G-feature map). Planar rotation of each filter is performed using <ref type="bibr" target="#b13">(14)</ref> and can observed in <ref type="figure">Fig. 3d</ref>. The input layer G-convolution is demonstrated in <ref type="figure">Fig. 3b</ref>, where the convolution between the input and the steerable filter bordered in red produces the output also bordered in red. Now, when the input is rotated by an angle 2πs n , with integers 0 ≤ s &lt; n, and the input layer Gconvolution is performed, the feature maps undergo a planar rotation by angle 2πs n , but in addition shift s positions. G-dense-blocks: To enable efficient gradient propagation, encourage feature re-use and to improve overall performance, we use dense connectivity <ref type="bibr" target="#b6">[7]</ref> between G-convolutions in hidden layers of the network. Each hidden layer steerable G-convolution maps a G-feature map f : G → R to some Gfeature map h : G → R. We can explain this mapping in terms of the restrictions of f and h to cosets. Because the input to the hidden layer G-convolution is now a function on G, we must similarly ensure that our filters give a function on G. We rotate each G-filter to give n rotated copies and perform a convolution between the input G-feature map f and each filter orientation to produce n feature maps (or a single G-feature map h). When rotating these G-filters, an additional position shift must be performed, in line with the associated group action. In <ref type="figure">Fig. 3c</ref>, n = 8 steerable planar filters are generated as shown by the red circle, forming a single G-filter. This Gfilter is convolved with the input G-feature map to generate the output with the red border. We can see that each G-filter, consists of 8 planar filters that individually rotate and shift position as the entire G-filter is rotated. This rotation can be seen in <ref type="figure">Fig. 3e</ref>, where the arrows show the orientation of each planar filter and the coloured borders are used to help visualise the position of each planar filter in the G-filter.</p><p>For each G-dense-block, the feature-maps of all preceding layers are concatenated to the input before performing the G-convolution. This increases the number of connections between layers, strengthening feature propagation. Specifically, each G-dense-block consists of k units. Each unit contains a 7×7 G-convolution followed by a 5×5 G-convolution that produce 14 and 6 orientation dependent feature maps respectively. After k units, the G-dense-block concludes by applying a final 5×5 G-convolution. G-pooling: At the output of the network, we transform each G-feature map f to a planar feature map, by taking the pointwise maximum of the n planar feature maps f θ that constitute f. This operation ensures that the output of Gpooling is invariant to rotation of the input.</p><p>G-Batch-Normalisation: Batch normalisation (BN) involves two trainable parameters that scale and shift the normalised output. Standard BN is applied to the output of all feature maps and therefore learned BN parameters are typically different for each planar feature map in the group G. However, when the input is rotated, BN parameters will not transform in accordance with the input and therefore standard BN is not rotation-equivariant. Instead, after each Gconvolution, we use a group-equivariant batch normalisation that aggregates moments per group rather than spatial feature map. This is essential to ensure rotation-equivariance throughout the network.</p><p>Classification: For our classification DSF-CNN, we initially perform the input layer steerable G-convolution followed by a hidden layer G-convolution. We then use 4 G-dense-blocks, where each block consists of 3,4,5 and 6 dense units. After every G-convolution layer we use a group-equivariant batch normalisation that aggregates moments per group rather than spatial feature map and ReLU non-linearity. Before every G-dense-block, we perform spatial max-pooling to decrease the dimensions of the feature maps. After the final G-denseblock, we perform G-pooling and then apply 3 1×1 classical convolution operations to get the final output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Segmentation:</head><p>We extend our DSF-CNN to the task of segmentation by up-sampling feature maps after the final Gdense-block in the aforementioned classification CNN. Specifically, we up-sample by a factor of 2 with bilinear interpolation and then utilise a G-dense-block. This is repeated until the spatial dimensions of the original image are regained. From the deepest layer of the up-sampling branch, each dense-block contain 4, 3 and 2 units. In line with U-Net <ref type="bibr" target="#b37">[38]</ref>, we also use skip connections to propagate information from the encoder to the decoder. After the feature maps have been up-sampled, we use a single hidden layer G-convolution, which is followed by G-pooling such that the resulting feature map is a function on C. Finally we use 2 1×1 classical convolutions to obtain the output, where we segment both the object and the contour to help separate touching instances. For nuclear segmentation, we additionally predict the eroded nuclei masks which are used as markers in marker-controlled watershed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental overview</head><p>Recently, there has been a growing number of proposed CNNs that achieve rotation-equivariance <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b33">[34]</ref>, yet there is lack of comprehensive evaluation of the various methods for the analysis of histopathology images. We perform a thorough comparison of various rotation-equivariant CNNs and demonstrate the effectiveness of the proposed model. Specifically, we compare a baseline CNN with H-Nets <ref type="bibr" target="#b33">[34]</ref>, VF-CNNs <ref type="bibr" target="#b3">[4]</ref>, G-CNNs with standard filters <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b30">[31]</ref> and G-CNNs with steerable filters <ref type="bibr" target="#b2">[3]</ref> and assess the impact of increasing the number of filter rotations in each model. For a thorough analysis, each method is applied to the task of breast tumour classification and then the best performing models are applied to the tasks of nucleus and gland segmentation. After gaining an insight into the performance of the different rotation-equivariant models, we then compare our proposed Dense Steerable Filter CNN with the state-of-the-art methods on each of the three datasets used in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The three datasets</head><p>We use the following three publicly available histology image datasets: Breast tumour classification: PCam <ref type="bibr" target="#b26">[27]</ref> is a dataset of 327K image patches of size 96×96 pixels at 10× extracted from the Camelyon16 dataset <ref type="bibr" target="#b38">[39]</ref>, containing 400 H&amp;E stained breast WSIs. Each image patch was labelled as tumour if the central region (32×32) contained at least one tumour pixel as given by the original annotation <ref type="bibr" target="#b38">[39]</ref>. Multi-tissue nucleus segmentation: The Kumar <ref type="bibr" target="#b17">[18]</ref> dataset contains 30 1,000×1,000 image tiles from seven organs (6 breast, 6 liver, 6 kidney, 6 prostate, 2 bladder, 2 colon and 2 stomach) of The Cancer Genome Atlas (TCGA) database acquired at 40× magnification. Within each image, the boundary of each nucleus is fully annotated. Colorectal gland segmentation: The CRAG dataset <ref type="bibr" target="#b13">[14]</ref> consists of 213 H&amp;E images mostly of size 1,512×1,516 pixels taken from 38 WSIs acquired at 20× of colorectal adenocarcinoma (CRA) patients. It is split into 173 training images and 40 test images with different cancer grades with pixel-based gland annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation metrics</head><p>Here we describe the metrics used for evaluation. For tumour classification, we calculated the area under the receiver operating characteristic curve (AUC) to assess the binary classification performance. For gland segmentation, we employed the same quantitative measures that were used in the GlaS challenge <ref type="bibr" target="#b39">[40]</ref>. These metrics consist of F 1 , DICE and Hausdorff distance at the object level and assess the quality of instance segmentation. For nuclear segmentation, we report the binary DICE and panoptic quality (PQ). Here, the binary DICE assesses the ability of the method to distinguish nuclei from the background, whereas PQ provides insight into the quality of instance segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nuclear Segmentation -Kumar Dataset</head><p>Gland Segmentation-CRAG Dataset Tumour Classification-PCam Dataset <ref type="figure">Fig. 4</ref>. Image regions from the three datasets. For nuclear segmentation, gland segmentation and tumour classification, we use the Kumar <ref type="bibr" target="#b17">[18]</ref>, CRAG <ref type="bibr" target="#b13">[14]</ref> and PCam <ref type="bibr" target="#b26">[27]</ref> datasets. Yellow boundaries show the pathologist annotation, while green and red borders denote non-tumour and tumour image patches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Comparative analysis of rotation-equivariant models</head><p>Baseline models: For the task of breast tumour classification, we implement a baseline CNN for comparison with the aforementioned rotation-equivariant models. The model consists of a series of convolution, batch normalisation, nonlinear and spatial pooling operations, which are then followed by three 1×1 convolutions to obtain the final output, denoting the probability of an input patch being tumour.</p><p>For the tasks of gland and nuclear segmentation we leverage the fully convolutional neural network architecture, which allows us to use the same model architecture, irrespective of the input size. The encoder of the baseline segmentation model uses the same architecture as the baseline classification CNN. Then a series of up-sampling and convolution operations are used to regain the spatial dimensions of the original image. In line with U-Net, we use skip connections to incorporate features from the encoder, but utilise summation as opposed to concatenation. In line with our proposed model described in Subsection IV-A, at the output of the network we perform segmentation of the object and the contour and additionally predict the eroded masks for nuclear segmentation.</p><p>Rotation-equivariant models: To assess the performance of various rotation-equivariant approaches, we modify the baseline models, but keep the fundamental architecture the same. The main difference between different models is how the filters are rotated, how many filter orientations are considered and how the convolution operation is performed.</p><p>Aside from H-Nets, each rotation-equivariant model considers 4, 8 and 12 filter orientations. H-Nets encode full 360 • equivariance within the model and therefore filters do not need to be explicitly rotated. When applying rotation to a filter with an angle that is a multiple of π 2 , the rotation is exact because the output can still be represented on the square grid. However, any other rotation may give interpolation artefacts and therefore may have negative implications for rotationequivariance. Therefore, in line with Marcos et al. <ref type="bibr" target="#b3">[4]</ref> and Lafarge et al. <ref type="bibr" target="#b4">[5]</ref>, for both the VF-CNN and standard G-CNN, we apply circular masking to the filters when using the groups C 8 and C 12 . However, this masking still leads to inevitable interpolation artefacts in the centre of the filter. Steerable filters as defined by (2) do not suffer from interpolation artefacts and, therefore, circular masking is not needed.</p><p>In all comparative experiments for rotation-equivariance, we fix each filter to be of size 7×7. We used a larger filter than typically used in modern CNNs because this size ensures that we can construct a good basis set for steerable filter generation, with reasonable frequency content and reduced aliasing.</p><p>For fair comparison, we ensure that the number of parameters is similar between different models. For both standard and steerable G-CNNs, the number of parameters increases with the size of the group, if we fix the number of filters in each layer. This is because one feature map is produced per orientation of the filter, which increases the number of required filters in the subsequent layer. To maintain the same number of parameters as the baseline CNN, we divide the number of filters in each layer of the standard G-CNN by √ n, where n is the number of orientations in the group. Steerable G-CNNs learn k parameters (or k/2 complex parameters) for each filter, where typically k &lt; K 2 . Therefore, the number of filters in each layer of a steerable G-CNN should be divided by k √ n K 2 . Instead of carrying forward all orientations throughout the network, VF-CNNs collapse the orientation dependent feature maps to two feature maps, representing magnitude and angle. Therefore, the VF-CNN requires more filters in the next layer, but the number of parameters stays constant irrespective of the size of the group. To ensure the same number of parameters as the baseline CNN, for all group sizes we divide the number of filters in each layer of VF-CNNs by <ref type="bibr">4 3</ref> . Each H-Net filter is constrained to be a complex circular harmonic, parameterised by N radial terms and a single phase offset term. Also, the number of parameters is dependent on the maximum frequency m of the filters. Specifically, in H-Nets frequencies in the range [−m, m] are considered, equating to a total of M = 2m + 1 frequency terms. Therefore, to ensure a similar number of parameters as the standard CNN, we multiply the number of filters in each layer of a H-Net by</p><formula xml:id="formula_29">K 2 M ·(N +1) .</formula><p>In all models, we down-sample with max-pooling, but for VF-CNNs and H-Nets we use a modified pooling strategy, based on the magnitude of the feature maps. Similarly, when using both VF-CNNs amd H-Nets, we do not incorporate the angle information when using batch normalisation (BN) and non-linear activation functions; otherwise the angles may change important information about relative and global orientations. For G-CNNs, we use a modified BN that aggregates moments per group rather than spatial feature map.</p><p>To verify our implementations of the various rotationequivariant networks, we cross-checked the performance of each model against reported benchmarks on the rotated MNIST dataset <ref type="bibr" target="#b40">[41]</ref> before applying them to the histology datasets. These results are summarised in <ref type="table" target="#tab_6">Table A2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Quantitative results</head><p>Tumour classification: We report comparative results of different rotation-equivariant models on the PCam dataset at the top of <ref type="table" target="#tab_1">Table I</ref>. We observe that H-Nets do not perform as well as the baseline CNN for the task of tumour classification. Despite this, we observe that we are able to increase the performance when incorporating higher frequency filters in the network, but the performance is still not comparable to conventional CNNs. This may suggest that constraining the filters in this way may not be optimal for detecting complex features in histology. VF-CNNs marginally outperform the conventional CNN, where we observe that increasing the number of filter rotations leads to a slight improvement in performance. When we utilise the group convolution, with filter rotation as performed by Bekkers et al. <ref type="bibr" target="#b30">[31]</ref> and Lafarge et al. <ref type="bibr" target="#b4">[5]</ref>, we see an improved performance when using up to 8 filter orientations. This gain in performance can be attributed to incorporating our prior knowledge of rotational symmetry into the network. To ensure that we maintain a similar number of parameters, we need to reduce the number of feature maps at each layer when the size of the group is increased. This may explain the drop in performance when using 12 filter orientations. When using steerable filters, but with no filter rotation, we observe an improved performance over conventional CNNs, highlighting the benefit of learning a linear combination of basis filters, rather than standard filters. Then, as we increase the size of the group to 4 and 8 orientations we see an improvement in the performance. We also observe that using steerable filters rather than standard filters within the G-convolution gives a better result.</p><p>At the bottom of <ref type="table" target="#tab_1">Table I</ref> we compare the performance of our proposed DSF-CNN with the p4m-DenseNet <ref type="bibr" target="#b26">[27]</ref>, which is the top performing method that was proposed with the introduction of the PCam dataset. This approach integrates the use of G-convolutions on, as proposed by Cohen &amp; Welling <ref type="bibr" target="#b1">[2]</ref>, into a densely connected CNN <ref type="bibr" target="#b6">[7]</ref>. Here, the network uses filter rotations by multiples of 90 • and also uses reflections. This is denoted by D 4 , which is the dihedral group containing 4 rotation and 4 reflection symmetries. In addition, we compare results to the commonly used ResNet-34 <ref type="bibr" target="#b10">[11]</ref>, ResNet-50 <ref type="bibr" target="#b10">[11]</ref>, DenseNet-121 <ref type="bibr" target="#b6">[7]</ref> and DenseNet-169 <ref type="bibr" target="#b6">[7]</ref>. Despite the small amount of parameters, we observe that our method achieves the best performance with an AUC of 0.975, which is a promising improvement over the previous state-of-the-art.</p><p>Gland segmentation: We compare the performance of the different rotation-equivariant models for gland segmentation on the CRAG dataset in the top part of <ref type="table" target="#tab_1">Table II</ref>. For this experiment, when comparing different rotation-equivariant approaches, we choose to only assess the performance of conventional CNNs, standard G-CNNs and steerable G-CNNs. This is because our previous experiment on breast tumour classification indicates that G-CNNs are capable of achieving a superior result over competing rotation-equivariant approaches. Similar to our observations for breast tumour classification, we see that increasing the group size within the group convolution leads to an increase in performance, but the best performance is achieved when using 8 filter orientations. For this task, using steerable filters in the group convolution led to the best performance. In the bottom part of <ref type="table" target="#tab_1">Table II</ref>, we compare our proposed approach with MILD-Net <ref type="bibr" target="#b13">[14]</ref> and Rota-Net <ref type="bibr" target="#b28">[29]</ref>, which are top-performing gland segmentation methods and therefore can be appropriately used for performance benchmarking. Like the p4m-DenseNet, Rota-Net makes use of the standard Gconvolution, but is limited to only 90 • filter rotations. In addition, we compare with FCN8 and U-Net as they are two widely used CNNs for segmentation. We observe that our DSF-CNN achieves the best performance with a fraction of the parameter budget. Notably, our model has around 20 times fewer parameters than Rota-Net and MILD-Net.   Nuclear segmentation: We report the comparative results of different rotation-equivariance methods for nuclear segmentation on the Kumar dataset in the top part of <ref type="table" target="#tab_1">Table III</ref>. Similar to above, we compare conventional CNNs with both standard and steerable G-CNNs. Here, we see that all rotationequivariant approaches show a significant improvement over standard CNNs and we see an improvement when increasing the number of filter orientations to 12 in all models. Once again, we observe that the steerable G-CNNs for segmentation  <ref type="bibr" target="#b42">[43]</ref> {e} 29.4M 0.811 0.407 U-Net <ref type="bibr" target="#b37">[38]</ref> {e} 37.0M 0.758 0.478 Mask-RCNN <ref type="bibr" target="#b43">[44]</ref> {e} 40.1M 0.760 0.509 DIST <ref type="bibr" target="#b16">[17]</ref> {e} 9.2M 0.789 0.443 Micro-Net <ref type="bibr" target="#b44">[45]</ref> {e} 192.6M 0.797 0.519 CIA-Net <ref type="bibr" target="#b45">[46]</ref> {e} 22.0M 0.818 0.577 HoVer-Net <ref type="bibr" target="#b15">[16]</ref> {e} 54.7M 0.826 0.597 DSF-CNN (Ours) C 8 3.7M 0.826 0.600 of nuclei are superior to standard G-CNNs that use bilinear interpolation during filter rotation. We evaluate the performance of our proposed method with several state-of-the-art approaches in the bottom part of <ref type="table" target="#tab_1">Table  III</ref>. In particular, HoVer-Net <ref type="bibr" target="#b15">[16]</ref>, CIA-Net <ref type="bibr" target="#b45">[46]</ref>, Micro-Net <ref type="bibr" target="#b44">[45]</ref> and DIST <ref type="bibr" target="#b16">[17]</ref> have been purpose-built for the task of Ground Truth nuclear segmentation and, therefore, provide a competitive benchmark. The proposed DSF-CNN once again achieves the best performance compared to other methods for both binary DICE and panoptic quality, on par with the state-of-the-art HoVer-Net method, while requiring a fraction of the parameter count.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DSF-CNN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nuclear Segmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Visual results</head><p>In <ref type="figure" target="#fig_3">Fig. 5</ref> we visualise the features and the corresponding outputs as we rotate the input with angle increments of π 4 (8 in total) for both the baseline CNN and C 8 -steerable G-CNN. Specifically, we analyse the properties of both CNNs trained for the tasks of gland and nuclear segmentation. To observe the feature map transformation with rotation of the input, we analyse two sets of feature maps in both CNNs: Feature Map A at the output of the 2nd convolution and Feature Map B at the output of the convolution after the final up-sampling operation. Similarly, we observe how the output probability map transforms when the input is rotated.</p><p>To analyse this, we feed each image orientation into the network to obtain a set of feature maps and output probability maps. Then, after rotating features and probability maps back to their original orientation, we compute the pixel-wise variance map of the features and the output to see how they change with rotation of the input. G-CNN feature maps are a function on G and therefore we visualise a single planar feature map within the group. For the rotation-equivariant model, we observe that there is a near-negligible variance between the features of each input orientation. On the other hand, there is much higher variance between the features of standard CNNs after input rotation. This implies that the rotation-equivariant CNN successfully learns an equivariant feature representation. Also, there is a lower variance between the predictions of multiple input orientations for the rotation-equivariant CNN as compared to the standard CNN. Thus, the rotation-equivariant CNN behaves as expected with rotation of the input, which is a particularly desirable property when training CNNs with histology image data. It must be noted that features learned by conventional CNNs are highly complex and it is very difficult to infer the relationship between learned features and input rotation. Nonetheless, we demonstrate that rotation-equivariant CNNs have a predictable transformation with input rotation, making them more stable than conventional CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Implementation and training details</head><p>We implemented our framework with the open source software library TensorFlow version 1.12.0 [47] on a workstation equipped with two NVIDIA GeForce 1080 Ti GPUs. During training, data augmentation including flip, rotation, Gaussian blur and median blur was applied. For breast tumour classification, we fed the original patches of size 96×96 into the network. For gland and nuclear segmentation, we used patches of size 448×448 and 256×256 respectively. For tumour classification, we trained our model using a batch size of 32 and then used a batch size of 8 for both gland and nucleus segmentation. We used cross-entropy loss for all tumour classification and gland segmentation models, whereas we used a combination of weighted cross-entropy and dice loss for nuclear segmentation. For all models, we trained using Adam optimisation with an initial learning rate of 10 −3 , that was reduced as training progressed. The network was trained with an RGB input, normalised between 0 and 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground Truth</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DSF-CNN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Gland Segmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. DISCUSSION AND CONCLUSIONS</head><p>Conventional CNNs do not behave as expected with rotation of the input, which is a particularly undesirable property in the field of computational pathology, where important features in histology images can appear at any orientation. Instead, rotation-equivariant CNNs build this prior knowledge of rotational symmetry within the network, such that features rotate in accordance with the input without explicitly learning features at various orientations. In this paper, we proposed a densely connected steerable filter CNN that achieves state-of-the-art performance on the three datasets used in our experiments with a fraction of the parameter budget of recent top-performing models. We conducted a thorough comparative analysis of various rotation-equivariant CNNs applied to the tasks of breast tumour classification, gland segmentation and nuclear segmentation. We showed that steerable filter group convolutions gave the best quantitative results on all three tasks, where 8 filter orientations consistently gave a strong performance. We visualised features within a rotation-equivariant model to demonstrate that they rotate with the input and therefore have a higher degree of feature map interpretability. Finally, we showed that rotation-equivariant models give more stable predictions with input rotation than regular CNNs do. In future work, we will consider incorporating additional symmetries into the group convolution, such as mirror and scale symmetries. This will further increase the interpretability of feature maps and may lead to an improvement in performance and help direct future research in computational pathology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. VERIFICATION OF BASELINE MODELS</head><p>In order to verify our self implemented approaches, we report the performance of each rotation-equivariant model on the rotated MNIST dataset <ref type="bibr" target="#b40">[41]</ref> in <ref type="table" target="#tab_6">Table A2</ref>, which is typically used for performance benchmarking in this domain.</p><p>In particular, we report the performance of a conventional CNN, H-Nets, standard G-CNNs, VF-CNNs and steerable G-CNNs. This was primarily to ensure that we were able to achieve a comparable performance with the reported results in the original papers. In our experiments all CNNs have the same base-level architecture, where we ensured that the models had the same number of layers, the same filter size and a similar number of parameters. Therefore our experiments are not only used for verification, but also to perform a fair head-to-head comparison between models. To maintain a similar number of parameters, we followed the same strategy as described in Section V-D. In line with our experiments in the paper, for H-Net we apply spatial max-pooling based on the magnitudes, as opposed to average-pooling, which is used in the original paper. We observe that all rotation-equivariant CNNs achieve a greater performance than the conventional CNN, where the best performance is achieved by the C 12 steerable G-CNN. Interestingly, we observe a significant boost in performance for our C 4 G-CNN and H-Net implementations, compared to the originally published results. These models have the same number of layers as the original implementations, but are wider to ensure a similar number of parameters between competing models. Note, we also add 2 1×1 convolutions after obtaining the invariant map (after G-pooling or computing the magnitude of the complex feature maps), which may have also contributed to the increase in performance. If we use the same architecture used by Weiler et al. for the C 12 steerable G-CNN, then we obtain an error of 0.709, which is very close to the original result. However, this implementation uses around 3.3M parameters, which is nearly 8× the amount that we use in our comparative experiments in <ref type="table" target="#tab_6">Table A2</ref>. Trivial group containing only the identity on page 3 n A positive integer, fixed throughout this paper Dn</p><p>Dihedral group of n rotations of C, fixing 0 and flips Cn Cyclic group of n rotations of C, fixing 0 C n {2πs/n | 0 ≤ s &lt; n} group law is addition mod 2π G An arbitrary group G Group as defined in Subsection III-C r radius in polar coordinates ψ a filter λ, β, θ usually elements of C n , sometimes arbitrary angles R k Radial profile of atomic steerable filters</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Cropped circular regions from a whole-slide image. Each orientation is equally as likely to appear.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Example circular harmonic basis filters sampled on the 11×11 square grid. Red and blue borders denote the real and imaginary parts respectively. Each pair of images comes from a single term R k (r)e ikθ in<ref type="bibr" target="#b1">(2)</ref>. In thisFig.,the particular radial profile functions R k are all Gaussians, as they are in our proposed model. These Gaussians have mean/mode/max at j. The integer k specifies the frequency.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Function on ℤ 2 FunctionFig. 3 .</head><label>23</label><figDesc>Overview of the two types of G-convolution used in our approach. with 8 filter orientations-best viewed in colour. a) Generation of steerable filters by linearly combining a series of atomic basis filters. b) Illustration of the input layer G-convolution, mapping an image f : C → R to a G-feature map h : G → R. A single steerable planar filter, learned by the network, is rotated n times and each rotated filter is convolved with the planar input f . This gives n planar feature maps, which combine to give a single G-feature map h. The image f is convolved with the red bordered planar filter to give the red bordered planar feature map in the stack on the right. c) Illustration of the hidden layer G-convolution, mapping a G-feature map f : G → R to a G-feature map h : G → R. The network learns a single steerable G-filter, which consists of n planar filters, displayed by placing them all in the same circle. Then, a single G-filter is rotated n times and each rotated G-filter is convolved with the input G-feature map f to generate a total of n planar feature maps or a single G-feature map. The convolution between the input f and the red circled G-filter gives the red bordered planar feature map on the right. d) demonstrates rotation of a planar filter, as used in the input layer G-convolution and e) demonstrates rotation of a G-filter, used in the hidden layer G-convolution. It can be seen from e) that G-filters undergo an additional position shift, in line with the group action. In both d) and e), θ = π 4 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 5 .</head><label>5</label><figDesc>Variance between the predictions and features for multiple orientations of the input. The original image is rotated with steps of π 4 to give 8 orientations and each copy is passed through the network to enable variance calculation. Features A and B are located at the beginning and end of the network respectively. The rotation-equivariant CNN we compare with is the C 8 steerable G-CNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 6 .</head><label>6</label><figDesc>Visual results for nuclear segmentation on the Kumar dataset [18] using our proposed DSF-CNN. Yellow boundaries highlight the nuclear borders as annotated by pathologists or predicted by our algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 7 .</head><label>7</label><figDesc>Visual results for gland segmentation on the CRAG dataset<ref type="bibr" target="#b13">[14]</ref> using our proposed DSF-CNN. Yellow boundaries highlight the glandular borders as annotated by pathologists or predicted by our algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and N.Rajpoot are with the Department of Computer Science, University of Warwick, UK.</figDesc><table><row><cell>Original</cell><cell>45°rotation</cell><cell>90°rotation</cell></row><row><cell>180°rotation</cell><cell>225°rotation</cell><cell>270°rotation</cell></row></table><note>S.Graham is also with the Mathematics for Real-World Systems Centre for Doctoral Training, University of Warwick, UK. D.Epstein is with the Mathematics Institute, University of Warwick, UK.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I TUMOUR</head><label>I</label><figDesc>CLASSIFICATION RESULTS ON THE PCAM DATASET [27]. TOP: COMPARISON OF DIFFERENT ROTATION-EQUIVARIANT MODELS WITH A SIMILAR PARAMETER BUDGET. BOTTOM: COMPARISON OF PROPOSED APPROACH WITH STATE-OF-THE-ART. THE SUPERSCRIPT ASSOCIATED WITH H-NET DENOTES THE MAXIMUM FREQUENCY USED.</figDesc><table><row><cell>Method</cell><cell cols="3">Group Parameters AUC</cell></row><row><cell>CNN</cell><cell>{e}</cell><cell>564K</cell><cell>0.947</cell></row><row><cell>H-Net 1 [34]</cell><cell>SO(2)</cell><cell>553K</cell><cell>0.934</cell></row><row><cell>H-Net 2 [34]</cell><cell>SO(2)</cell><cell>542K</cell><cell>0.939</cell></row><row><cell>VF-CNN [4]</cell><cell>C 4</cell><cell>556K</cell><cell>0.949</cell></row><row><cell>VF-CNN [4]</cell><cell>C 8</cell><cell>556K</cell><cell>0.951</cell></row><row><cell>VF-CNN [4]</cell><cell>C 12</cell><cell>556K</cell><cell>0.953</cell></row><row><cell>G-CNN [2]</cell><cell>C 4</cell><cell>561K</cell><cell>0.964</cell></row><row><cell>G-CNN [31], [5]</cell><cell>C 8</cell><cell>557K</cell><cell>0.968</cell></row><row><cell>G-CNN [31], [5]</cell><cell>C 12</cell><cell>557K</cell><cell>0.962</cell></row><row><cell cols="2">Steerable G-CNN [3] {e}</cell><cell>553K</cell><cell>0.963</cell></row><row><cell>Steerable G-CNN [3]</cell><cell>C 4</cell><cell>546K</cell><cell>0.969</cell></row><row><cell>Steerable G-CNN [3]</cell><cell>C 8</cell><cell>565K</cell><cell>0.971</cell></row><row><cell cols="2">Steerable G-CNN [3] C 12</cell><cell>545K</cell><cell>0.969</cell></row><row><cell>ResNet-34 [11]</cell><cell>{e}</cell><cell>21.3M</cell><cell>0.942</cell></row><row><cell>ResNet-50 [11]</cell><cell>{e}</cell><cell>23.5M</cell><cell>0.948</cell></row><row><cell>DenseNet-121 [7]</cell><cell>{e}</cell><cell>7.8M</cell><cell>0.921</cell></row><row><cell>DenseNet-169 [7]</cell><cell>{e}</cell><cell>13.3M</cell><cell>0.920</cell></row><row><cell>p4m-DenseNet  *  [27]</cell><cell>D 4</cell><cell>119K</cell><cell>0.963</cell></row><row><cell>DSF-CNN (Ours)</cell><cell>C 8</cell><cell>2.2M</cell><cell>0.975</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II GLAND</head><label>II</label><figDesc>SEGMENTATION RESULTS ON THE CRAG [14] DATASET. TOP: COMPARISON OF DIFFERENT ROTATION-EQUIVARIANT MODELS WITH A SIMILAR PARAMETER BUDGET. BOTTOM: COMPARISON OF PROPOSED APPROACH WITH STATE-OF-THE-ART.</figDesc><table><row><cell>Method</cell><cell cols="5">Group Params Obj F 1 Obj Dice Obj Haus ↓</cell></row><row><cell>CNN</cell><cell>{e}</cell><cell>984K</cell><cell>0.793</cell><cell>0.809</cell><cell>246.0</cell></row><row><cell>G-CNN [2]</cell><cell>C 4</cell><cell>982K</cell><cell>0.833</cell><cell>0.856</cell><cell>170.4</cell></row><row><cell>G-CNN [31], [5]</cell><cell>C 8</cell><cell>988K</cell><cell>0.837</cell><cell>0.866</cell><cell>157.4</cell></row><row><cell>G-CNN [31], [5]</cell><cell>C 12</cell><cell>979K</cell><cell>0.818</cell><cell>0.834</cell><cell>192.2</cell></row><row><cell cols="2">Steerable G-CNN [3] {e}</cell><cell>981K</cell><cell>0.811</cell><cell>0.848</cell><cell>175.9</cell></row><row><cell cols="2">Steerable G-CNN [3] C 4</cell><cell>984K</cell><cell>0.837</cell><cell>0.869</cell><cell>164.8</cell></row><row><cell cols="2">Steerable G-CNN [3] C 8</cell><cell>989K</cell><cell>0.861</cell><cell>0.888</cell><cell>139.5</cell></row><row><cell cols="2">Steerable G-CNN [3] C 12</cell><cell>976K</cell><cell>0.855</cell><cell>0.870</cell><cell>156.2</cell></row><row><cell>FCN8 [38]</cell><cell cols="3">{e} 134.3M 0.796</cell><cell>0.835</cell><cell>199.5</cell></row><row><cell>U-Net [38]</cell><cell cols="3">{e} 37.0M 0.827</cell><cell>0.844</cell><cell>196.9</cell></row><row><cell>MILD-Net [14]</cell><cell cols="3">{e} 83.3M 0.869</cell><cell>0.883</cell><cell>146.2</cell></row><row><cell>Rota-Net [29]</cell><cell>C 4</cell><cell cols="2">71.3M 0.869</cell><cell>0.887</cell><cell>144.2</cell></row><row><cell>DSF-CNN (Ours)</cell><cell>C 8</cell><cell>3.7M</cell><cell>0.874</cell><cell>0.891</cell><cell>138.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE III NUCLEAR</head><label>III</label><figDesc>SEGMENTATION RESULTS ON THE KUMAR [18] DATASET. TOP: COMPARISON OF DIFFERENT ROTATION-EQUIVARIANT MODELS WITH A SIMILAR PARAMETER BUDGET. BOTTOM: COMPARISON OF PROPOSED APPROACH WITH STATE-OF-THE-ART.</figDesc><table><row><cell>Method</cell><cell cols="2">Group Params B-Dice PQ</cell></row><row><cell>CNN</cell><cell>{e}</cell><cell>984K 0.767 0.447</cell></row><row><cell>G-CNN [2]</cell><cell>C 4</cell><cell>982K 0.793 0.490</cell></row><row><cell>G-CNN [31], [5]</cell><cell>C 8</cell><cell>988K 0.811 0.519</cell></row><row><cell>G-CNN [31], [5]</cell><cell>C 12</cell><cell>979K 0.814 0.534</cell></row><row><cell cols="2">Steerable G-CNN [3] {e}</cell><cell>981K 0.791 0.510</cell></row><row><cell cols="2">Steerable G-CNN [3] C 4</cell><cell>984K 0.809 0.542</cell></row><row><cell cols="2">Steerable G-CNN [3] C 8</cell><cell>989K 0.818 0.543</cell></row><row><cell cols="2">Steerable G-CNN [3] C 12</cell><cell>976K 0.820 0.558</cell></row><row><cell>FCN8 [42]</cell><cell cols="2">{e} 134.3M 0.797 0.312</cell></row><row><cell>SegNet</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE A1 PERFORMANCE</head><label>A1</label><figDesc>OF OUR BASELINE MODELS ON ROTATED MNIST DATASET [41]. THE SUPERSCRIPT ASSOCIATED WITH H-NET DENOTES THE MAXIMUM FREQUENCY USED.</figDesc><table><row><cell>Method</cell><cell cols="3">Group Parameters Error</cell></row><row><cell>CNN</cell><cell>{e}</cell><cell>416K</cell><cell>2.001</cell></row><row><cell>H-Net 1 [34]</cell><cell>SO(2)</cell><cell>418K</cell><cell>1.371</cell></row><row><cell>H-Net 2 [34]</cell><cell>SO(2)</cell><cell>414K</cell><cell>1.352</cell></row><row><cell>G-CNN [2]</cell><cell>C 4</cell><cell>413K</cell><cell>0.976</cell></row><row><cell>G-CNN [31], [5]</cell><cell>C 8</cell><cell>407K</cell><cell>0.962</cell></row><row><cell>G-CNN [31], [5]</cell><cell>C 12</cell><cell>411K</cell><cell>0.940</cell></row><row><cell>VF-CNN [4]</cell><cell>C 8</cell><cell>418K</cell><cell>1.202</cell></row><row><cell>VF-CNN [4]</cell><cell>C 12</cell><cell>418K</cell><cell>1.172</cell></row><row><cell>Steerable G-CNN [3]</cell><cell>C 8</cell><cell>416K</cell><cell>0.820</cell></row><row><cell cols="2">Steerable G-CNN [3] C 12</cell><cell>424K</cell><cell>0.809</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE A2 DESCRIPTION</head><label>A2</label><figDesc>OF MATHEMATICAL SYMBOLS USED THROUGHOUT THE PAPER.</figDesc><table><row><cell>Symbol</cell><cell>Description</cell></row><row><cell>R</cell><cell>Set of real numbers</cell></row><row><cell>C</cell><cell>Set of complex numbers</cell></row><row><cell>Z</cell><cell>Set of integers</cell></row><row><cell>F</cell><cell>Real vector space of functions C → R</cell></row><row><cell>F C</cell><cell>Complex vector space of functions C → C</cell></row><row><cell>Re</cell><cell>Real part of complex number</cell></row><row><cell>E(2)</cell><cell>Euclidean group</cell></row><row><cell>SE(2)</cell><cell>Special euclidean group (no reflections)</cell></row><row><cell>SO(2)</cell><cell>Special orthogonal group (no reflections)</cell></row><row><cell>{e}</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We use G instead of G because we have reserved the name G for the particular group defined in Subsection III-C and G denotes an arbitrary group.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Model code: https://github.com/simongraham/dsf-cnn</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Validation of digital pathology imaging for primary histopathological diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Snead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Meskiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Kimani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Crossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Rajpoot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blessing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Matthews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Histopathology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1063" to="1072" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Group equivariant convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2990" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning steerable filters for rotation equivariant cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Storath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rotation equivariant vector field networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tuia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5048" to="5057" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Roto-translation equivariant convolutional networks: Application to histopathology image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.08725</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The design and use of steerable filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="891" to="906" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Densely Connected Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.06993</idno>
		<imprint>
			<date type="published" when="2016-08" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Srn: side-output residual network for object symmetry detection in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1068" to="1076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Mild-net: Minimal information loss dilated network for gland instance segmentation in colon histology images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gamper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Snead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="199" to="211" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dcan: deep contour-aware networks for accurate gland segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2487" to="2496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hover-net: Simultaneous segmentation and classification of nuclei in multi-tissue histology images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">D</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E A</forename><surname>Raza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Azam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page">101563</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Segmentation of nuclei in histopathology images by deep regression of the distance map</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Naylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Laé</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Reyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Walter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="448" to="459" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A dataset and a technique for generalized nuclear segmentation for computational pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vahadane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sethi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Leveraging unlabeled whole-slide-images for mitosis detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">U</forename><surname>Akram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Heikkilä</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Pathology and Ophthalmic Medical Image Analysis</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="69" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Classification of lung cancer histology images using patchlevel summary statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Koohbanani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Khurram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Society for Optics and Photonics</title>
		<imprint>
			<biblScope unit="volume">10581</biblScope>
			<biblScope unit="page">1058119</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Digital Pathology</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Automated gleason grading of prostate cancer tissue microarrays via deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arvaniti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Fricker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moret</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rupp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hermanns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fankhauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Wild</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Rueschoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Claassen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Context-aware convolutional neural network for grading of colorectal cancer histology images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Awan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Fraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Azam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Snead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Quantifying the effects of data augmentation and stain color normalization in convolutional neural networks for computational pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tellez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bulten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-M</forename><surname>Bokhorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ciompi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Der Laak</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.06543</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Why do deep convolutional networks generalize so poorly to small image transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Azulay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.12177</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Test-time augmentation for deep learning-based cell segmentation on microscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Moshkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mathe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kertesz-Farkas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hollandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Horvath</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">814962</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Ti-pooling: transformation-invariant pooling for feature learning in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Savinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Buhmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Rotation equivariant cnns for digital pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Veeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Linmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winkens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="210" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Sample efficient semantic segmentation using rotation equivariant convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Linmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Winkens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">S</forename><surname>Veeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.00583</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Rota-net: Rotation equivariant network for simultaneous gland and lumen segmentation in colon histology images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rajpoot</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Hexaconv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02108</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Roto-translation covariant convolutional networks for medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Eppenhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Duits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="440" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Oriented response networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="519" to="528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Steerable cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.08498</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Harmonic networks: Deep translation and rotation equivariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Garbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Turmukhambetov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5028" to="5037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Rotdcf: Decomposition of convolutional filters for rotation-equivariant deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Calderbank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations 2019 (ICLR&apos;19)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">General e (2)-equivariant steerable cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cesa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Every measurable homomorphism from R n to C * is exponential</title>
		<idno>version: 2013-07-13</idno>
		<ptr target="https://math.stackexchange.com/q/442980" />
	</analytic>
	<monogr>
		<title level="m">Mathematics Stack Exchange</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Diagnostic assessment of deep learning algorithms for detection of lymph node metastases in women with breast cancer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Bejnordi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Veta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Van Diest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Ginneken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karssemeijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Litjens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Van Der Laak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hermsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">F</forename><surname>Manson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balkenhol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Jama</title>
		<imprint>
			<biblScope unit="volume">318</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2199" to="2210" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Gland segmentation in colon histology images: The glas challenge contest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sirinukunwattana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">B</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Matuszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bruni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Sanchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="489" to="502" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An empirical evaluation of deep architectures on problems with many factors of variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.06870</idno>
	</analytic>
	<monogr>
		<title level="j">Mask R-CNN</title>
		<imprint>
			<date type="published" when="2017-03" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Micro-net: A unified model for segmentation of various objects in microscopy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E A</forename><surname>Raza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pelengaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Rajpoot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical image analysis</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="160" to="173" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Cia-net: Robust nuclei instance segmentation with contour-aware information aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">F</forename><surname>Onder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tsougenis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.05358</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
