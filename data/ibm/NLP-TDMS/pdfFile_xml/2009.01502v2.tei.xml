<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS 1 DRLE: Decentralized Reinforcement Learning at the Edge for Traffic Light Control in the IoV</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Pengyuan</forename><surname>Zhou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Xianfu</forename><surname>Chen</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Senior member, IEEE</roleName><forename type="first">Zhi</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Tristan</forename><surname>Braud</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE, Jussi Kangasharju Member, IEEE</roleName><forename type="first">Pan</forename><surname>Hui</surname></persName>
						</author>
						<title level="a" type="main">IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS 1 DRLE: Decentralized Reinforcement Learning at the Edge for Traffic Light Control in the IoV</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Edge Computing</term>
					<term>Multi-agent Deep Reinforce- ment learning</term>
					<term>Internet of Vehicles</term>
					<term>Traffic Light Control</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Internet of Vehicles (IoV) enables real-time data exchange among vehicles and roadside units and thus provides a promising solution to alleviate traffic jams in the urban area. Meanwhile, better traffic management via efficient traffic light control can benefit the IoV as well by enabling a better communication environment and decreasing the network load. As such, IoV and efficient traffic light control can formulate a virtuous cycle. Edge computing, an emerging technology to provide low-latency computation capabilities at the edge of the network, can further improve the performance of this cycle. However, while the collected information is valuable, an efficient solution for better utilization and faster feedback has yet to be developed for edge-empowered IoV. To this end, we propose a Decentralized Reinforcement Learning at the Edge for traffic light control in the IoV (DRLE). DRLE exploits the ubiquity of the IoV to accelerate traffic data collection and interpretation towards better traffic light control and congestion alleviation. Operating within the coverage of the edge servers, DRLE aggregates data from neighboring edge servers for cityscale traffic light control. DRLE decomposes the highly complex problem of large area control into a decentralized multi-agent problem. We prove its global optima with concrete mathematical reasoning and demonstrate its superiority over several state-ofthe-art algorithms via extensive evaluations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>The Internet of Vehicles (IoV) <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref> allows data exchange among vehicles (V2V), roadside units (RSUs) (V2I), and other commutable devices on roads or remote resources distributed over the Internet. It can facilitate and enable a wide variety of applications such as driving habit monitoring, driving operation recommendation, and emergency notification <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b5">[6]</ref>. The IoV leverages an ever-increasing number of vehicles connected to the Internet and has a significant potential to alleviate the continuously rising traffic congestion, which has dramatic consequences on the environment as well as the well-being of citizens. Thanks to its high-speed wireless connectivity, the IoV enables data collection from vehicles in real time <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>.</p><p>On a related note, edge computing <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref> has emerged as a solution in recent years to extend the capacity of remote cloud services towards nearby end users. Edge computing is at the core of most future networking paradigms as its characteristics make it an ideal candidate for time-sensitive and highly mobile applications such as those encountered in the IoV <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b13">[14]</ref>. Co-located with base stations or RSUs, edge computing nodes can provide processing of the IoV data and response to traffic jams and anomalies. By connecting traffic signals 1 to the IoV, it becomes possible to empower signal timing plans with realtime traffic information and exploit the intelligence at the edge to react to unforeseen congestion. However, while the collected information at the edge is valuable, an efficient solution for better utilization and faster feedback has yet to be developed for large-scale edge-empowered IoV.</p><p>Most of the related solutions follow one of the two directions: 1) utilize linear programming at intersections for fast adaption of the signal plan <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref>, 2) deploy machine learning to directly control the traffic lights or adapt the phase duration <ref type="bibr" target="#b17">[18]</ref>- <ref type="bibr" target="#b19">[20]</ref>. The first direction lacks exploration or learning abilities and strongly depends on the availability of accurate objective functions and constraints, hence lots of research efforts are put on the second direction, including single-agent <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref> and multi-agent systems <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b22">[23]</ref>- <ref type="bibr" target="#b24">[25]</ref>. Single-agent solutions suffer from huge state space and huge action space. On the other hand, multi-agent solutions can decrease the state and action spaces. Nevertheless, we notice three major concerns regarding the works in this direction as follows.</p><p>1) Lack of practical solutions to bridge the technology gap between machine learning algorithms and deployabilities in real-life smart city scenarios. 2) Lack of solid theoretical analysis to prove the optimal performances of decentralized training. 3) Lack of extensive tests with credible simulator platforms to show the benefit of decentralized learning in traffic light control with reusable results. In this work, we propose Decentralized Reinforcement Learning at the Edge for traffic light control in the IoV (DRLE). Following a similar hierarchy with our previous works <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, we build a new system model with a focus on multi-agent training with rich IoV data. This integrated framework leverages the real-time data collection from connected vehicles to optimize traffic light control from the perspective of hierarchical levels. Each level optimizes its coverage with edge servers running a level-specific algorithm, of which one or several key parameters are tuned by the upper level's algorithm in real time. The decentralized architecture of DRLE relies on a pervasive deployment of edge servers, including signal control units at intersections and edge servers co-located with base stations and aggregation points. DRLE decomposes the highly complex problem of large area control into a decentralized multi-agent problem. We prove its global optima with concrete mathematical reasoning ( §IV). We build our algorithm with credible open-sourced platforms <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref> and reinforcement learning library <ref type="bibr" target="#b29">[30]</ref> ( §V). We conduct extensive evaluations and demonstrate the superiority of this approach over several state-of-the-art algorithms ( §VI). Specifically, DRLE decreases convergence time by 65.66% compared to Proximal Policy Optimization and training steps by 79.44% compared to Augmented Random Search and Evolutionary Strategies. Besides, DRLE exponentially reduces the action space and provides comparable traffic control performance within only 1/4 of the training time compared to its centralized counterpart.</p><p>The rest of the paper is structured as follows. We give an overview of related works in §II. In §III we present the system design and traffic model. We describe the theoretical details of our algorithm in §IV and show our evaluation setup and results in §V and §VI, respectively. Finally, §VII concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Researchers have put a lot of effort into optimizing traffic light control. Major solutions include linear programming and machine learning. Meanwhile, recent proposals have started to look at the potential of rich IoV data for traffic management. In this section, we give an overview of related works. IoV. Powered by fast-developing vehicular networking techniques, researchers have proposed solutions to utilize rich IoV data for traffic control <ref type="bibr" target="#b30">[31]</ref>, <ref type="bibr" target="#b31">[32]</ref>. <ref type="bibr">Kumar et al. proposed</ref> to apply ant colony algorithms to help vehicles find the optimal routes <ref type="bibr" target="#b32">[33]</ref>. Darwish et al. focused on real-time big data analytics in the IoV environment powered by fog computing <ref type="bibr" target="#b33">[34]</ref>. Chen et al. targeted enhancing transportation safety and network security by mining effective information from both physical and network data space <ref type="bibr" target="#b34">[35]</ref>. However, the potential of utilizing rich IoV data specifically for traffic light control has not been fully explored. Liner programming. Researchers have proposed traffic light control solutions based on traffic models (microscopic, mesoscopic and macroscopic) <ref type="bibr" target="#b35">[36]</ref>- <ref type="bibr" target="#b37">[38]</ref>. These solutions utilize linear programming to solve the objective functions <ref type="bibr" target="#b14">[15]</ref>- <ref type="bibr" target="#b16">[17]</ref>. Although linear programming is straightforward and has low latency, it depends on accurate objective function and constraints. Moreover, it lacks exploration or learning abilities to scale to large-area optimization and complicated scenarios. Reinforcement Learning. Instead of trying to build explicit traffic flow models, machine learning proposals learn the traffic patterns and achieve optimal policies by iteratively adapting actions with the goal of maximizing the cumulative reward <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b22">[23]</ref>. Many proposals have applied single-agent or multi-agent reinforcement learning to optimize traffic light control. Single-agent solutions have large state and action spaces thus require large capacity to calculate optimal signal phases <ref type="bibr" target="#b17">[18]</ref>. Therefore, nowadays researchers tend to use multi-agent algorithms to divide larger problems into smaller sub-problems. For example, Chu et al. proposed in <ref type="bibr" target="#b38">[39]</ref> to reduce action space by dynamically partitioning the traffic grid into smaller regions and deploying a local agent in each region. They applied multi-agent reinforcement learning to A2C for large-scale traffic light control in <ref type="bibr" target="#b18">[19]</ref>. Li et al. used deep Q-learning (DQL) to control traffic lights and proposed deploying the deep stacked autoencoders (SAE) neural network to reduce the huge state space brought by the tabular Q learning method <ref type="bibr" target="#b19">[20]</ref>. Balaji et al. proposed to control traffic lights with distributed agents at each intersection <ref type="bibr" target="#b17">[18]</ref>. El-Tantawy et al. explored coordinated agents to let intersections conduct signal control actions in cooperation with neighbors <ref type="bibr" target="#b39">[40]</ref>. Based on <ref type="bibr" target="#b38">[39]</ref>, Tan et al. further proposed to concatenate the latent states of local agents to form the global action-value function <ref type="bibr" target="#b40">[41]</ref>.</p><p>Overall, we find the existing solutions fall short in the following aspects and propose DRLE to improve those aspects.</p><p>• Optima proof. Rarely we find multi-agent approaches for traffic light control mathematically prove the optima of multi-agent reinforcement learning. • The gap between technique and reality. Most multi-agent learning approaches do not provide deployable solutions to apply the algorithms to real-life smart cities. • Extensive tests with open-source platforms. Many related works have conducted simulations with vehicular traffic simulators and self-developed machine learning scripts limited to the proposals. We find those results hard to be reused due to lack of credible open-sourced platforms. In this work, we address those shortages by proposing a deployable decentralized solution and prove its optima with mathematical reasoning and extensive reusable tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. SYSTEM</head><p>In this section, we first present the design of DRLE and the communication mechanism. Then, we describe the traffic model as the basis of the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. System Design</head><p>DRLE revolves around the device layer and the edge layer, as shown in <ref type="figure" target="#fig_1">Fig. 1</ref> in detail and <ref type="figure" target="#fig_2">Fig. 2</ref> from high level. The device layer includes the vehicles, traffic signals, pedestrian devices, RSUs and other devices involved in the IoV. In the rest of this paper, we assume each traffic signal is connected with a control unit. Each control unit employs video cameras facing all directions to collect real-time traffic data and transmits it via wireless network to a nearby edge server. The edge layer hosts the edge servers in two tiers. The first tier servers (ES 1 ) are colocated with the base stations at the radio access network. The second tier servers (ES 2 ) are co-located with the aggregation points in the core network. This scheme agrees with the Multiaccess Edge Computing standard proposed by the European Telecommunications Standards Institute. Please refer to <ref type="bibr" target="#b25">[26]</ref> for the detailed edge server deployment strategy. Each ES 2 collects data from nearby ES 1 and provides a larger scale of service and sends backup to the cloud data center. Next, we briefly describe the communication mechanism and overhead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ES 1</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Traffic light control unit</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MEC ES 1</head><p>Inter-ES C-V2X system  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Device Layer</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RSU</head><p>Vehicle Pedestrian</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Base Station</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Edge Layer</head><p>Cloud (Data Backup)  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Communications</head><p>Each ES 1 feeds the collected data into local reinforcement learning and sends the actions to the signal control units in real time. An ES 1 collects the data by communicating with the devices (connected vehicles, signal control units and RSUs) via Cellular vehicle-to-Everything (C-V2X) <ref type="bibr" target="#b41">[42]</ref> and operates within a coverage defined by the range of its co-located base station. For simplicity, we do not consider RSUs and pedestrians in the rest of the paper.</p><p>Actions are primarily changing lights commands which can be encapsulated in small data packets. These packets are sent only to a limited number of signals, hence the majority of data transmission is between the connected vehicles and ES 1 via Vehicle-to-Network (V2N). As suggested by the 3GPP standard <ref type="bibr" target="#b42">[43]</ref>, each message should be sent at a frequency between 0.1 Hz and 1 Hz with a payload between 50 bytes and 300 bytes. We assume a message frequency of 1 Hz to align with the agent learning rate in the evaluation (see §V). We assume that each message has a size of maximum transmission unit (1500 bytes), which is sufficient to contain the required data (speed, location, and direction of travel of the vehicle). Note that other transmissions mechanisms such as V2V and V2I are performed via a different radio (e.g. ITS 5.9 GHz) than V2N (licensed mobile bands, e.g. 700 MHz) and are not necessary for DRLE.</p><p>Since the transmissions between the vehicles and the ES 1 base stations are only one-hop and unidirectional (uplink), the communications require a small networking capacity. Hence, it has a limited overhead and impact on the overall C-V2X environment. We present a preliminary evaluation in §VI-D and show that the end-to-end delay consisting of vehicle-to-ES 1 transmission delay and ES 1 -to-signal transmission delay is much smaller than a training step duration (1 second). <ref type="bibr" target="#b1">2</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Traffic Model and Problem</head><p>We assume the traffic lights in the urban area pertain to a common signal timing plan characterized by a fixed cycle containing a fixed number of phases. A phase refers to the time duration of the green lights for a given direction. Let L be the set of links in a signalized urban area. Then, L (in) (L (out) ) is the set of input (output) links of the area. To allow smooth driving experience, we introduce two parameters, i.e, the number of halting vehicles and speed-lag. A vehicle moves at speeds slower than 0.1 m/s is considered halting. Speed-lag is defined as the speed difference between the actual driving speed and the maximum speed permitted by statute. We use speed-lag instead of the commonly used speed to address the maximum speed limit in reality. We formulate the problem as to minimize the overall number of halting vehicles and speed-lag in the area over the whole optimization horizon. As for the coverage of an ES 1 , the objective of the optimization problem can be formulated as follows,</p><formula xml:id="formula_0">P = lim K→∞ E 1 K K k=1 m∈L (in) \L (out) −w 1 · H k m − w 2 · V k m ,<label>(1)</label></formula><p>which can also be approximated as</p><formula xml:id="formula_1">P = E (1 − γ) · ∞ k=1 (γ) k−1 · m∈L (in) \L (out) −w 1 · H k m − w 2 · V k m ,<label>(2)</label></formula><p>if the discount factor γ ∈ [0, 1) approaches 1. Herein, H k m is the number of halting vehicles and V k m is the average speedlag of the vehicles in lane m at the beginning of the kth cycle. w 1 and w 2 are two positive weighting constants. Although the model describes the problem from a global view, each internal intersection can have a varied impact on the optimization. Therefore, it is better to disassemble the optimization objective of multiple intersections, namely,</p><formula xml:id="formula_2">P = E (1 − γ) · ∞ k=1 (γ) k−1 · C c=1 m∈L c (in) \L c (out) (3) −w 1 · H k m − w 2 · V k m .</formula><p>where c is an intersection index, C refers to the total number of intersections in the area, L c (in) (L c (out) ) represents the set of input (output) links of intersection c. In this work, we propose to decompose the optimization problem and solve it with a decentralized reinforcement learning algorithm as described in §IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. ALGORITHM</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Hierarchical Algorithm</head><p>The system includes three parallel and interactive algorithms running in three levels, i.e., Intersection, Intra-ES and Inter-ES, performed by signal control units, ES 1 and ES 2 , respectively ( <ref type="figure" target="#fig_1">Fig. 1)</ref>. At Intersection level, each signal adapts its phases with a threshold-based algorithm. The threshold can be the average queuing length or the average space headaway. At Intra-ES level, each ES 1 runs a multi-agent reinforcement learning algorithm to participate in the traffic light switching directly. At Inter-ES level, an ES 2 runs a threshold-based algorithm to optimize the urban traffic by tuning the reinforcement learning rate in each ES 1 . We briefly describe Intersection level and Intra-ES level and detail the decomposed reinforcement learning algorithm at Intra-ES level. Intersection level. The control unit of each intersection signal runs a threshold-based algorithm similar with <ref type="bibr" target="#b43">[44]</ref>. Each control unit employs cameras to capture the traffic jam and adapts the phase duration based on predefined parameters. When the parameters surpass the thresholds, the control unit extends the phase of the green lights for the more jammed direction (e.g., with longer queues or smaller space headway), and decreases a equivalent length of the green phases for the other direction. Inter-ES level. An ES 2 tunes the urban traffic by adapting the reinforcement learning rate in each ES 1 based on a thresholdbased algorithm similar to <ref type="bibr" target="#b43">[44]</ref>. Intra-ES level. Each ES 1 optimizes the internal traffic within its coverage defined by the co-located base station by switching the traffic lights directly. We adopt DQL to provide an adaptive algorithm to respond to the dynamically changing traffic condition. The advantage of Q-learning for traffic light control is described in more detail in a study by Abdulhai et al. <ref type="bibr" target="#b22">[23]</ref>, including not requiring a prespecified model of the environment and being adaptive and unsupervised. We define the state s k , action a k and reward R k as follows.</p><p>• s k is the state at the kth cycle, including the number of halting vehicles H k = {H k m |m = 1, · · · , M }, the speedlag of the vehicles V k = { V k m |m = 1, · · · , M }, and the traffic light states θ k = {θ k c |c = 1, · · · , C}, where M is the total number of the lanes in the area. • a k is the action operated by the agents after observing s k . More specifically, a k = {a k c |c = 1, · · · , C}, where a k c ∈ {0, 1} represents the decision of switching the traffic light. • R k is the reward defined as the additive inverse of the average speed-lag and number of halting vehicles, namely,</p><formula xml:id="formula_3">R k = M m=1 (−w 1 · H k m − w 2 · V k m )</formula><p>. Agent Goal. The overall goal of DRLE is to optimize the light control to smooth the traffic. To do so, the agents of an ES 1 need to find a control policy π that maximizes</p><formula xml:id="formula_4">Q π (s, a) = (1 − γ) · E ∞ k=1 (γ) k−1 · R k |s 1 = s, a 1 = a ,<label>(4)</label></formula><p>which is also termed a Q-function. A control policy π can be defined as a mapping by a = π(s). To put it another way, the goal is to solve π * = arg max π Q π (s, π(s)), ∀s.</p><p>For notational convenience, we denote Q(s, a) = Q π * (s, a), ∀(s, a). Using the state-action-reward-state-action (SARSA) algorithm <ref type="bibr" target="#b44">[45]</ref>, the optimal Q-function can be found in an iterative on-policy manner. The centralized decision making at a cycle is executed at the signals independently, based on which we linearly decompose the Q-function,</p><formula xml:id="formula_6">Q(s, a) = C c=1 Q c (s, a c ),<label>(6)</label></formula><p>where Q c (s, a c ) is defined to be the per-signal Q-function given by</p><formula xml:id="formula_7">Q c (s, a c ) = (1 − γ) · E ∞ k=1 (γ) k−1 · R k c |s 1 = s, a 1 c = a c .<label>(7)</label></formula><p>Herein, a k c and R k c are, respectively, the joint action and the reward for the agent at the intersection c at the cycle k. We emphasize that the decision makings across the cycles are performed at each signal in accordance with the optimal control policy implemented by the ES 1 . In other words, ∀s, π * (s) = arg max a=(ac:c=1,··· ,C)</p><formula xml:id="formula_8">C c=1 Q c (s, a c ).<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Optimization and Convergence Guarantee</head><p>Theorem 1 (Optimization Guarantee). The linear Q-function decomposition approach as in Eq. (6) asserts the expected optimal long-term performance.</p><p>Proof. For the Q-function of a centralized decision making a under a global network state s, we have</p><formula xml:id="formula_9">Q(s, a) = (1 − γ) · E ∞ k=1 (γ) k−1 · R k |s 1 = s, a 1 = a = (1 − γ) · E ∞ k=1 (γ) k−1 · C c=1 R k c |s 1 = s, a 1 = a = C c=1 (1 − γ) · E ∞ k=1 (γ) k−1 · R k c |s 1 = s, a 1 = a = C c=1 Q c (s, a c ),<label>(9)</label></formula><p>which completes the proof. Therefore, instead of learning the Q-function, the SARSA updating rule is slightly adapted for each lane to</p><formula xml:id="formula_10">Q k+1 c (s, a c ) = 1 − α k · Q k c (s, a c ) + α k · (1 − γ) · R k c + γ · Q k c (s , a c ) ,<label>(10)</label></formula><p>where α k ∈ [0, 1) is the learning rate. Theorem 2 ensures the convergence of the decentralized learning process. Proof. Since the per-signal Q-functions are learned simultaneously, we consider monolithic updates during the decentralized learning process. That is, the iterative rule in Eq. (10) can then be encapsulated as</p><formula xml:id="formula_11">C c=1 Q k+1 c (s, a c ) = 1 − α k · C c=1 Q k c (s, a c ) + α k · (1 − γ) · C c=1 R c + γ · C c=1 Q k c (s , a c ) .<label>(11)</label></formula><p>From both sides of Eq. (11), subtracting the sum of per-signal Q-functions leads to</p><formula xml:id="formula_12">C c=1 Q k+1 c (s, a c ) − C c=1 Q c (s, a c ) = 1 − α k · C c=1 Q k c (s, a c ) − C c=1 Q c (s, a c ) + α k · T k (s, a c ),<label>(12)</label></formula><p>where</p><formula xml:id="formula_13">T k (s, a c ) = (1 − γ) · C c=1 R c (13) + γ · max a C c=1 Q k c (s , a c ) − C c=1 Q c (s, a c )) + γ · C c=1 Q k c (s , a c ) − max a C c=1 Q k c (s , a c ) .</formula><p>We let ∆ k denote the history for the first k cycles during the decentralized learning process. The per-signal Q-functions are ∆ kmeasurable, thus both (</p><formula xml:id="formula_14">C c=1 Q k+1 c (s, a c ) − C c=1 Q c (s, a c )</formula><p>) and T k (s, a c ) are ∆ k -measurable. We then attain Eq. <ref type="formula" target="#formula_0">(14)</ref>, where · ∞ is the maximum norm of a vector and (a) is due to the convergence property of the standard Q-learning. We are now left with verifying that</p><formula xml:id="formula_15">E[γ · ( C c=1 Q k c (s , a c ) − max a C c=1 Q k c (s , a c ))</formula><p>|∆ k ] ∞ converges to zero, which establishes the following: i) an -greedy policy is deployed for the exploration-exploitation trade-off during decision-making; ii) the per-signal Q-function values are upper bounded; and iii) both the global network state and the decision-making spaces are finite. Thus the convergence of the decentralized learning is ensured.</p><p>Takeaway. The core contribution of the algorithm, i.e. decentralization, lies in the action selection process, during which the algorithm selects the optimal joint action that maximizes the sum of Q-values of all agents, thus ensuring global optima (Theorem 1 and Theorem 2). The major advantage in comparison with traditional centralized reinforcement learning, is that the number of joint actions grows linearly instead of exponentially as the number of involved agents (i.e., the traffic signals) increases. It is noteworthy that the training is done in a centralized fashion to allow efficient cooperative training across the multiple agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENT SETUP</head><p>We conduct the training and the tests on a MSI GS65 Stealth 8SG equipped with a 6-core I7-8750H CPU, 32GB of memory, and an Nvidia RTX 2080 Max-Q GPU. We build the learning algorithms (open sourced at <ref type="bibr" target="#b51">[52]</ref>) based on RLlib <ref type="bibr" target="#b29">[30]</ref>, an open-sourced library for reinforcement learning that can easily be scaled by increasing the number of workers <ref type="bibr" target="#b45">[46]</ref>. We use its underlayer Ray framework <ref type="bibr" target="#b28">[29]</ref> to accelerate the decentralized algorithm training.</p><p>Besides Deep Q-Network (DQN), we also build and test distributional DQN (dDQN) proposed by Bellemare et al. in 2017 <ref type="bibr" target="#b46">[47]</ref>, which learns a categorical distribution of discounted returns instead of estimating the mean. To provide better performance, we leverage the values of several parameters explored by the well-acknowledged work, Rainbow <ref type="bibr" target="#b47">[48]</ref>, including learning rate, epsilon, and softmax cross entropy for dDQN. We define and evaluate the algorithms and policies utilizing Flow <ref type="bibr" target="#b27">[28]</ref>, a Python library that provides the interface between RLlib and SUMO <ref type="bibr" target="#b48">[49]</ref>, a microscopic simulator for traffic and vehicle dynamics. Next we describe the detailed settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Simulation Setup</head><p>To extensively test our proposal, we evaluate sets of tests with different algorithms and policies in different scenarios. Map. Most related works on traffic light control do experiments on grid-like maps such as the urban Manhattan grid scenario used by 3GPP <ref type="bibr" target="#b49">[50]</ref>. We also follow this setup and deploy the tests on n × n grid road maps that consist of n × n typical four-way, traffic-light-controlled intersections. Each intersection allows vehicles to flow either horizontally or vertically. If the light is green, it transitions to yellow for two seconds before switching to red for the purpose of safety. Each lane has one signal only, and the signal phases of an intersection in clockwise order consist of GrGr, yryr, rGrG, and ryry, of which G, y, r refer to green, yellow and red, respectively. The traffic lights can be switched only after 3 seconds to prevent flickering. Scale. In this work, each ES 1 collects data and control the traffic lights within the coverage defined by its co-located base station. To be more realistic, we investigate the coverage range of LTE cell towers via a crowdsourced cellular tower and coverage mapping service <ref type="bibr" target="#b2">3</ref> . It shows that the coverage range of an LTE cell tower on B7 (2600MHz) is typically around 5 to 10 blocks and 10 to 20 intersections in a European city center area (Helsinki, Finland). Therefore, we focus the simulation at the scale of of 5 × 5 intersections to cover common scenarios. For the completeness of the work, we also test larger scales such as 10 × 10 and 15 × 15. Traffic. Vehicles enter the map from all outer edges at a predefined rate, i.e., 360 vehicle/hour/edge. At such a rate, 7200 vehicles enter a 5 × 5 grid map from the 20 outer edges in an hour. To simplify the problem, vehicles travel straight on their paths. Each vehicle is driven following a basic SUMO-builtin car following model, of which the minimum gap between successive vehicles, maximum speed limit and deceleration ability are set to 2.5 m, 60 m/s and 7.5 m/s 2 , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Training Configurations</head><p>We test the learning algorithms utilizing single-and multiagent training. We use multi-agent DQN and dDQN as the targeting algorithms to prove our mathematical reasoning in §IV. Considering intersections with different centralities may have influences on the traffic performance, we define two kinds of policies with corresponding reward definitions as follows. Policy. We test the system with two policies, i.e., SharedPolicy and MultiPolicy, to address the different centralities of the intersections. We call the signals with higher centralities "central nodes", as indicated by the blue squares residing in the central area of <ref type="figure">Fig. 3</ref>. We call the others "edge nodes", as indicated by the black circles. SharedPolicy lets the agents at all intersections share the same policy. MultiPolicy lets the agents at "central nodes" share a central policy while the other agents share a edge policy. Reward. We define the reward based on the average speedlag and the number of halting vehicles ( §III). Specifically, the reward of SharedPolicy is defined as</p><formula xml:id="formula_16">R = −w 1 · H − w 2 · V<label>(15)</label></formula><p>where R, H, V indicate the reward, number of halting vehicles, and average speed-lag, respectively. The rewards of <ref type="figure">Fig. 3</ref>: Central (blue squares) and edge (black circles) intersections.</p><formula xml:id="formula_17">3 https://www.cellmapper.net/ E T k (s, a c )|∆ k ∞ (14) ≤ E (1 − γ) · C c=1 R c + γ · max a C c=1 Q k c (s , a c ) − C c=1 Q c (s, a c )|∆ k ∞ + E γ · C c=1 Q k c (s , a c ) − max a C c=1 Q k c (s , a c ) |∆ k ∞ (a) ≤ γ · C c=1 Q k c (s, a c ) − C c=1 Q c (s, a c ) ∞ + E γ · C c=1 Q k c (s , a c ) − max a C c=1 Q k c (s , a c ) |∆ k ∞</formula><p>MultiPolicy for the agents at "central nodes" and "edge nodes" are defined as</p><formula xml:id="formula_18">R central = −w c 1 · H − w c 2 · V (16) R edge = −w e 1 · H − w e 2 · V<label>(17)</label></formula><p>where w c 1 , w c 2 , w e 1 , w e 2 denote the weights to differentiate the penalties that central and edge nodes receive. In this paper, we set w c 1 &gt; w e 1 , w c 2 &gt; w e 2 , to give central nodes higher penalties for poor performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Benchmarks</head><p>We compare the performance of DQN and dDQN with multiple algorithms as follows.</p><p>• Static simply lets traffic lights deploy pre-defined static phases. • Actuated is a common light control scheme in Germany.</p><p>It works by either prolonging traffic phases upon detecting a continuous traffic stream, or switching to the next phase upon detecting a sufficient time gap between successive vehicles <ref type="bibr" target="#b50">[51]</ref>. We also test dDQN using all parameter values deployed in Rainbow <ref type="bibr" target="#b47">[48]</ref> to see whether it applies to our use case. <ref type="table" target="#tab_1">Table I</ref> shows the hyper-parameters of the benchmark algorithms, DQN and dDQN. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. TEST RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Training Results</head><p>We conduct the training over iterations, each of which consists of numerous rollouts. <ref type="bibr" target="#b3">4</ref> As shown in <ref type="figure">Fig. 4</ref> to <ref type="figure" target="#fig_6">Fig. 6</ref>, the interval consists of 100 iterations, each of which consists of 30 rollouts. Each rollout has 1000 steps. A step maps to one second in real life. As such, the interval consists of 3 million steps.</p><p>Since SharedPolicy and MultiPolicy have different reward definitions, their reward performances are not strictly comparable. Therefore, we plot them separately. As shown in <ref type="figure">Fig. 4</ref> to <ref type="figure" target="#fig_6">Fig. 6</ref>, dDQN and DQN show similar curves and the former performs slightly better than the latter. PPO is always outperformed by dDQN and DQN in the beginning of the training and climbs to a similar level after around 2M steps. Rainbow setup provides the worst performance out of all algorithms. It indicates that the values of the parameters discovered in Rainbow does not fit our use case. Single-agent algorithms take a lot longer to reach a similar level of performance, thus we exclude their curves from the figures. For instance, the training time of single-agent DQN is 4 times the training time of its multi-agent counterpart. This is because the action space dimension for each agent in multi-agent algorithms is 2 while single-agent DQN has an action space of 2 25 , and thus requires a much longer training time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Traffic Results</head><p>We replay the policies with SUMO to compare the traffic control performances and show the summarized results in <ref type="table" target="#tab_1">Table II</ref>. Halting vehicles refer to the average number of the  As shown, the Static algorithm presents the worst performance. Meanwhile, we find that all machine learning algorithms provide very limited improvement for the average vehicle speed compared to the Actuated algorithm. However, they all decrease the number of halting vehicles and queuing time significantly (except Rainbow algorithms which is most likely due to unfeasible parameter values). It indicates that with the agent-controlled signals, vehicles have much less start/stop waves and waiting time in queues, thus gaining considerable improvements in driving experience.</p><p>Multi-agent SharedPolicy-PPO, SharedPolicy-DQN and MultiPolicy-DQN provide the smoothest traffic control. Their performances show the smallest numbers of halting vehicles and shortest queuing time and lengths while allowing higher driving speeds than others. The performance of single-agent DQN is fairly good. However it requires exponentially higher capacity and four times as long as the training period of its multi-agent counterparts. ARS and ES also show competitive performances, although presenting either slightly slower speeds or more halting vehicles. Nevertheless, ARS and ES currently only support single-agent training, thus also require much longer training time. For example, to achieve the performance  <ref type="figure">Fig. 4</ref> and <ref type="figure">Fig. 5</ref>. Overall, the training and traffic results align with Theorem 1 and 2 proposed in §IV, showing that decentralized multi-agent DQN can achieve similar optima with centralized single-agent DQN. Surprisingly, MultiPolicy has not provided observable benefits compared to SharedPolicy. We will explore more varieties of MultiPolicy setups in future works. Meanwhile, decentralized multi-agent DQN outperforms centralized singleagent DQN in the following aspects: 1) It requires only 1/4 of the training time centralized DQN needs. 2) It requires exponentially less computation and memory capacity than centralized DQN.</p><p>Next, we evaluate the scalability of DRLE by conducting tests on different scales of maps. Thereafter we evaluate the communication overhead with a preliminary simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Scalability</head><p>To illustrate the system scalability, we apply multi-agent SharedPolicy-DQN on various map scales. <ref type="figure">Fig. 7</ref> shows the training performances of SharedPolicy-DQN on maps with 5 × 5, 10 × 10, and 15 × 15 intersections. Because of the fixed vehicle inflow rate (see §V-A), each intersection has less nearby vehicles in larger maps, resulting in shorter queue lengths and vehicle delay, which, in turn, leads to a higher reward. As such, the average reward per agent increases as the map scale increases. The traffic control performance summarized in <ref type="table" target="#tab_1">Table III</ref> mostly confirms this reasoning. It is important to note that when we increase the size of the map, the number of halting vehicles per intersection decreases. Overall, DRLE performs well on different map scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Communication Overhead</head><p>DRLE leverages the ubiquity of the IoV and the foreseeable edge facilities in the near future to run the algorithms. In this subsection, we provide a preliminary evaluation of the communication overhead brought by this system architecture.</p><p>We deploy a map consisting of 5×5 intersections as shown in <ref type="figure">Fig. 3</ref> in NS-3, a packet-level discrete-event network simulator for internet systems. Because the mobility trace files generated from the training tests are not compatible with NS-3, we use the trace files instead to estimate the average number of active vehicles per step in the considered map, i.e., 230. Then we simulate 230 vehicles in NS-3 with the same parameters (speed and acceleration etc.) with the training tests. As such, we argue that the transmission delay performance, albeit not identical to the performance in an integrated test, should be very similar from a statistical perspective. As described in Subsection III-B, each vehicle sends 1500 B-packets to a tri-sector eNB at the center of the map at 1 Hz via C-V2X (LTE) (table IV). For a period of 1000 seconds (the default training period in training   tests), the transmission delay result shows that uplink (vehicleto-ES 1 ) plus downlink (ES 1 -to-signal) delay is less than 240 ms per packet <ref type="table" target="#tab_5">(Table V)</ref>. As such, the transmission delay during each step is much smaller than the step duration 5 thus does not impact on DRLE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. CONCLUSION AND FUTURE WORK</head><p>In this work, we present DRLE, an integrated edge computing framework leveraging the ubiquity of the IoV for alleviating traffic congestion in real time at city scale. We decompose the highly complex centralized problem of large area traffic light control to a multi-agent decentralized problem and prove its global optima with concrete mathematical reasoning. DRLE exploits the low latency of edge servers to provide fast DQN training and control feedback. Thanks to its layered architecture and hierarchical algorithm, DRLE runs optimization at the Intersection, Intra-ES and Inter-ES levels that allows for traffic light control on different scales. We present numerous comparisons to evaluate the traffic improvement brought by DRLE and show that, compared to the state-of-the-art baseline works, DRLE decreases the convergence time by 65.66% compared to PPO and training steps by 79.44% compared to ARS and ES. Besides, DRLE provides comparable traffic control performance with its centralized counterpart while requiring only 1/4 of the training time.</p><p>This paper explores the performance of algorithm on Intra-ES level. In future work, we will explore the Inter-ES algorithm and its impact on the performance of DRLE. We are also looking forward to investigating the potential of tuning the threshold parameter value in the Intersection level algorithm instead of directly switching the traffic lights, to further decrease the action space and extend the scalability. <ref type="bibr" target="#b4">5</ref> See footnote 2.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 :</head><label>1</label><figDesc>System overview. In each Intra-ES subsystem, an ES 1 (MEC) uses decentralized multi-agent learning to train the collected IoV data and sends commands to control the traffic lights. ES 2 tunes the parameters of the multi-agent algorithms running in each ES 1 (Intra-ES subsystem).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>System layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Theorem 2 (</head><label>2</label><figDesc>Convergence Guarantee). The sequence {(Q k c (s, a c ) : ∀(s, a c ), ∀c ∈ {1, · · · , C}) : k} by Eq. (10) surely converges to the per-signal Q-functions (Q c (s, a c ) : ∀(s, a c ), ∀c ∈ {1, · · · , C}), if and only if for each signal c ∈ {1, · · · , C}, the (s, a c )-pairs are visited for an infinite number of times.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>•</head><label></label><figDesc>Augmented Random Search (ARS) is an improved version of Basic Random Search (BRS), proposed by Mania et al. in 2018 [53]. • Evolutionary Strategies (ES) is one of the OpenAI solutions proposed by Salimans et al. in 2017 [54]. • Proximal Policy Optimization (PPO) is a popular gradientbased policy optimization algorithm proposed by Schulman et al. in 2017 [55]. It uses multiple epochs of minibatch updates, and an MLP with tanh non-linearity to compute a value function baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Average reward per agent for edge policy (reward defined in Eq.(17)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 :</head><label>6</label><figDesc>Average reward per agent. halting vehicles per step (speed &lt; 0.1 m/s). Queuing time indicates the average waiting time of vehicles due to queuing per step. Queuing length refers to the average length of the queues per step. The end of the queue is defined as the last vehicle with a speed of &lt; 5 km/h. Speed refers to the average speed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Hyper-parameters.</figDesc><table><row><cell>Algorithm</cell><cell>Selected Hyper-parameters</cell></row><row><cell>Augmented Random Search</cell><cell>SGD step size = 0.2</cell></row><row><cell></cell><cell>Noise standard deviation = 0.2</cell></row><row><cell>Evolutionary Strategies</cell><cell>Adam step size = 0.02</cell></row><row><cell></cell><cell>Noise standard deviation = 0.02</cell></row><row><cell>Proximal Policy Optimization</cell><cell>λ(GAE) = 0.3</cell></row><row><cell></cell><cell>Clipping = 0.3</cell></row><row><cell></cell><cell>Adam step size = 5 × 10 −5</cell></row><row><cell></cell><cell>Minibatch size = 128</cell></row><row><cell></cell><cell>Hiddens [100, 50, 25]</cell></row><row><cell></cell><cell>γ(Discount) = 0.999</cell></row><row><cell>Deep Q-Network</cell><cell>Adam = 1.5 × 10 −4</cell></row><row><cell></cell><cell>Learning rate α = 6.25 × 10 −5</cell></row><row><cell></cell><cell>Hiddens [256,256]</cell></row><row><cell></cell><cell>Dimension = 84</cell></row><row><cell></cell><cell>Train batch size = 1000</cell></row><row><cell>Distributed DQN</cell><cell>Number of atoms = 51</cell></row><row><cell></cell><cell>Min/max values: [−10, 10]</cell></row><row><cell></cell><cell>Target network update freq. = 8000</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II :</head><label>II</label><figDesc>Traffic performance and required training time. N: Non-ML, S: SingleAgent-ML, M: Multiagent-ML Average reward per agent for SharedPolicy-DQN on different scales. in Table II, ARS and ES need around 800K steps (approximately 253 minutes) while multi-agent DQN and dDQN only need around 240K steps (approximately 52 minutes). Similarly, PPO has much longer convergence time compared to multi-agent DQN algorithms as shown in</figDesc><table><row><cell>Num agents</cell><cell>Algorithm</cell><cell cols="3">Halting vehicles Queue time (s) Queue length (m)</cell><cell>Speed (m/s)</cell></row><row><cell>N</cell><cell>Static</cell><cell>95 ±40</cell><cell>14.23 ±10.25</cell><cell cols="2">19.82 ±12.17 13.39 ±3.20</cell></row><row><cell></cell><cell>SharedPolicy-DQN-5x5 SharedPolicy-DQN-10x10 SharedPolicy-DQN-15x15</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fig. 7:</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III :</head><label>III</label><figDesc>Performance of SharedPolicy-dDQN on different map scales. × 5 2.24 ±1.48 0.27 ±0.00 7.44 ±0.21 18.06 ±0.44 10.22 10 × 10 7.54 ±2.97 0.24 ±0.00 7.27 ±0.19 17.21 ±0.30 35.50 15 × 15 13.61 ±5.93 0.22 ±0.00 7.25 ±0.22 16.91 ±0.22 86.31</figDesc><table><row><cell>Scale</cell><cell>Halting vehicles Queue time (s) Queue length (m)</cell><cell>Speed (m/s)</cell><cell>Training time/rollout (s)</cell></row><row><cell>5</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE IV :</head><label>IV</label><figDesc>Communication parameters.</figDesc><table><row><cell>Model</cell><cell>Protocol</cell><cell>Packet</cell><cell cols="2">Frequency Hops</cell></row><row><cell>V2N [43]</cell><cell>UDP</cell><cell>1500 B</cell><cell>1 Hz</cell><cell>1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE V</head><label>V</label><figDesc></figDesc><table><row><cell cols="3">: Transmission delays. (MAD: Median Absolute</cell></row><row><cell>Deviation)</cell><cell></cell><cell></cell></row><row><cell>Direction</cell><cell cols="2">Mean (ms) MAD (ms)</cell></row><row><cell>Uplink (vehicle-to-ES 1 )</cell><cell>110.82</cell><cell>17.68</cell></row><row><cell>Downlink (ES 1 -to-signal)</cell><cell>106.23</cell><cell>0</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In this work, we use traffic signal and traffic light interchangeably. arXiv:2009.01502v2 [cs.MA] 5 Jan 2021</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">A training step is the period over which one gradient update happens. We define each step as a 1-second period. However, the delay of each gradient update is at the millisecond level. In other words, each gradient update takes several milliseconds then waits until the next second to conduct the next update.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Rollout, or playout, is a term often used in machine learning that is defined by Monte Carlo. In each rollout, an agent takes actions until reaching predefined max steps.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="formula">16)</ref><p>).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Internet of vehicles: architecture, protocols, and security</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Contreras-Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zeadally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Guerrero-Ibañez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3701" to="3709" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Integrating licensed and unlicensed spectrum in the internet of vehicles with mobile edge computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yoshinaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="48" to="53" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Artificial intelligence empowered edge computing and caching for internet of vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maharjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Wireless Communications</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="18" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Safedrive: online driving anomaly detection from large-scale vehicle data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z A</forename><surname>Bhuiyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Industrial Informatics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2087" to="2096" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">i-car system: A lora-based low power wide area networks vehicle diagnostic system for driving safety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-T</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International Conference on Applied System Innovation (ICASI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="789" to="791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ARVE: Augmented reality applications in vehicle to edge networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Braud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kangasharju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Workshop on Mobile Edge Communications</title>
		<meeting>the 2018 Workshop on Mobile Edge Communications</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="25" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Connected vehicles: Solutions and challenges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE internet of things journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="289" to="299" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Collaborative learning of communication routes in edge-enabled multi-access vehicular environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yoshinaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cognitive Communications and Networking</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">AVE: Autonomous vehicular edge computing framework with ACO-based scheduling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="10" to="660" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Mobile edge computing: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Taherkordi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Skeie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="450" to="465" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Distributed vehicular computing at the dawn of 5g: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alhilal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Braud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hui</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.07077</idno>
		<imprint/>
	</monogr>
	<note type="report_type">2020. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Artificial intelligence inspired transmission scheduling in cognitive vehicular communications and networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maharjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1987" to="1997" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep learning empowered task offloading for mobile edge computing in urban informatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maharjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="7635" to="7647" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Edge intelligence and blockchain empowered 5g beyond for the industrial internet of things</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maharjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Network</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="12" to="19" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A macroscopic traffic model for realtime optimization of signalized urban areas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barisone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Giglio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">41st IEEE Conference on Decision and Control</title>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="900" to="903" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A signal timing plan formulation for urban traffic control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dotoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Fanti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meloni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Control engineering practice</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1297" to="1311" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A linear programming approach for adaptive synchronization of traffic signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Factorovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loiseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gómez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Transactions in Operational Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="667" to="679" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Urban traffic signal control using reinforcement learning agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>German</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Intelligent Transport Systems</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="177" to="188" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-agent deep reinforcement learning for large-scale traffic signal control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Codecà</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1086" to="1095" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Traffic signal timing via deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-Y.</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/CAA Journal of Automatica Sinica</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="247" to="254" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Asynchronous stochastic approximation and q-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="185" to="202" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Reinforcement learning in neurofuzzy traffic signal control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">European Journal of Operational Research</title>
		<imprint>
			<biblScope unit="volume">131</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="232" to="241" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Reinforcement learning for true adaptive traffic signal control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Abdulhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pringle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Karakoulas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Transportation Engineering</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="278" to="285" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reinforcement learning based control of traffic lights in non-stationary environments: A case study in a microscopic simulator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Bazzan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">W</forename><surname>Basso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Nunes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rossetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lamb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EUMAS</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multiagent traffic management: A reservationbased intersection control mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dresner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third International Joint Conference on Autonomous Agents and Multiagent Systems</title>
		<meeting>the Third International Joint Conference on Autonomous Agents and Multiagent Systems</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="530" to="537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Enhanced augmented reality applications in vehicle-to-edge networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Braud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kangasharju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 22nd Conference on Innovation in Clouds, Internet and Networks and Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="167" to="174" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">ERL: Edge based reinforcement learning for optimized urban traffic light control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Braud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alhilal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kangasharju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE International Conference on Pervasive Computing and Communications Workshops</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="849" to="854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Flow: Architecture and benchmarking for reinforcement learning in traffic control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kreidieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Parvate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vinitsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bayen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.05465</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ray: A distributed framework for emerging AI applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tumanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elibol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">13th USENIX Symposium on Operating Systems Design and Implementation)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="561" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nishihara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Y</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Stoica</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09381</idno>
		<title level="m">Ray rllib: A composable and scalable reinforcement learning library</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Wireless machine-to-machine communication for intelligent transportation systems: Internet of vehicles and vehicle to grid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Moloisane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Malekian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">Capeska</forename><surname>Bogatinoska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 40th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="411" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Internet of vehicles: From intelligent grid to autonomous cars and vehicular clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gerla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE world forum on internet of things (WF-IoT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="241" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Ant colony optimization algorithm with internet of vehicles for intelligent traffic control system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Manogaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sundarasekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chilamkurti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Varatharajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Networks</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="page" from="154" to="162" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Fog based intelligent transportation big data analytics in the internet of vehicles environment: motivations, architecture, challenges, and critical issues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Darwish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Bakar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="15" to="679" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Cognitive internet of vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fortino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Humar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Communications</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="58" to="70" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A review of the mathematical models for traffic flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Darbha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rajagopal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Advances in Engineering Sciences and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="68" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">State-of-the-art of vehicular traffic flow modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Hoogendoorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Bovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the Institution of Mechanical Engineers, Part I: Journal of Systems and Control Engineering</title>
		<imprint>
			<biblScope unit="volume">215</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="283" to="303" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Vehicle-based modelling of traffic. Theory and application to environmental impact modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Eissfeldt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
		<respStmt>
			<orgName>Universität zu Köln</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Doctoral dissertation</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Large-scale traffic grid signal control with regional reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 American Control Conference (ACC). IEEE</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="815" to="820" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Multiagent reinforcement learning for integrated network of adaptive traffic signal controllers (marlin-atsc): methodology and large-scale application on downtown toronto</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>El-Tantawy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Abdulhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Abdelgawad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1140" to="1150" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Cooperative deep reinforcement learning for large-scale traffic grid signal control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2687" to="2700" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Cellular v2x as the essential enabler of superior global connected transportation services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Papathanassiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khoryaev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE 5G Tech Focus</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Study on LTE support for vehicle-to-everything (v2x) services</title>
		<idno>(TR) 22.885</idno>
	</analytic>
	<monogr>
		<title level="m">3rd Generation Partnership Project (3GPP)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>version 14.0.0</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Simulation of modern traffic lights control systems using the open source traffic simulation SUMO</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krajzewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brockfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mikat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ringel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rossel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tuchscheerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wosler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Industrial Simulation Conference</title>
		<meeting>the 3rd Industrial Simulation Conference<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="229" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Reinforcement learning: an introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Playing atari with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5602</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A distributional perspective on reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning, ICML&apos;17. JMLR.org</title>
		<meeting>the 34th International Conference on Machine Learning, ICML&apos;17. JMLR.org</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="449" to="458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Rainbow: Combining improvements in deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Modayil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Van Hasselt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schaul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ostrovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Horgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">32 AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Recent development and applications of SUMO -Simulation of Urban MObility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krajzewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Erdmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Behrisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bieker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal On Advances in Systems and Measurements</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3&amp;4</biblScope>
			<biblScope unit="page" from="128" to="138" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Study on lte-based v2x services</title>
		<idno>(TR) 36.885, version 14.0.0</idno>
	</analytic>
	<monogr>
		<title level="m">3rd Generation Partnership Project (3GPP)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Simulation/traffic lights</title>
		<ptr target="https://sumo.dlr.de/docs/Simulation/TrafficLights.html" />
	</analytic>
	<monogr>
		<title level="m">SUMO</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Multi-agent DQN control traffic lights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Multi-agent-RL-traffic-light-control</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Simple random search provides a competitive approach to reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Guy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<idno>abs/1803.07055</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Evolution strategies as a scalable alternative to reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sidor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.03864</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Proximal policy optimization algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
