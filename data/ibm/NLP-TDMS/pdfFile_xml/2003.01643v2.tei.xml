<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Single-exposure absorption imaging of ultracold atoms using deep learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Ness</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Physics Department and Solid State Institute</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasiya</forename><surname>Vainbaum</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Physics Department and Solid State Institute</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantine</forename><surname>Shkedrov</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Physics Department and Solid State Institute</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanay</forename><surname>Florshaim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Physics Department and Solid State Institute</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Sagi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Physics Department and Solid State Institute</orgName>
								<orgName type="institution">Technion -Israel Institute of Technology</orgName>
								<address>
									<postCode>32000</postCode>
									<settlement>Haifa</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Single-exposure absorption imaging of ultracold atoms using deep learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">(Dated: April 9, 2020)</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Absorption imaging is the most common probing technique in experiments with ultracold atoms. The standard procedure involves the division of two frames acquired at successive exposures, one with the atomic absorption signal and one without. A well-known problem is the presence of residual structured noise in the final image, due to small differences between the imaging light in the two exposures. Here we solve this problem by performing absorption imaging with only a single exposure, where instead of a second exposure the reference frame is generated by an unsupervised image-completion autoencoder neural network. The network is trained on images without absorption signal such that it can infer the noise overlaying the atomic signal based only on the information in the region encircling the signal. We demonstrate our approach on data captured with a quantum degenerate Fermi gas. The average residual noise in the resulting images is below that of the standard double-shot technique. Our method simplifies the experimental sequence, reduces the hardware requirements, and can improve the accuracy of extracted physical observables. The trained network and its generating scripts are available as an open-source repository (absDL.github.io).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Ultracold atomic gases are unique systems that allow studying few-and many-body physics in a highly precise and tunable manner. The atomic ensembles are exquisitely isolated from the surroundings as they are held in an ultra-high vacuum environment; therefore, probing them is almost always restricted to the analysis of their optical response. The most widely used probing technique is absorption imaging, where a collimated resonant laser beam is passed through the cloud, and the shadow cast by the atoms is recorded by a digital camera <ref type="bibr" target="#b0">[1]</ref>. The spatial atomic distribution is then extracted from the position-dependent absorption coefficient. The coherence length of the probe beam is typically much longer than the distances between optical interfaces in the experiment, hence, unwanted reflections interfere and generate a characteristic patterns of stripes and Newton's rings in the recorded image. These patterns pose a problem in distinguishing between the signal and the non-uniform background.</p><p>The standard solution is to employ a double-exposure scheme: the first exposure is performed while the atoms are present, while the second reference exposure is performed shortly after and without the atoms. The exposure without atoms can be done either by waiting for the atoms to move out of the frame or by optically pumping them into a dark state. The line-of-sight integrated optical density (OD) image is formed by subtracting the logarithms of the pixel counts in the two frames, with and without the atoms. However, due to acoustic noises and other dynamical processes, the noise patterns in the two images are typically not identical. This results in a residual structured noise pattern in the final image <ref type="figure" target="#fig_0">(Fig. 1a</ref>). The lower signal to noise ratio afflicted by the fringes is * Electronic address: yoavsagi@technion.ac.il particularly problematic in low-OD images. Linear approaches for background completion were recently suggested <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, but, as we show, they are sensitive to small changes in the noise pattern that evolve over time.</p><p>In this work, we tackle the noisy background problem using machine learning, a term describing a set of algorithms that effectively perform a specific tasks relying on patterns and inference. Among these, deep learning refers to a class of models which involves information propagation via multiple structures, enabling the translation of a given input to a certain prediction. The use of deep learning has become widespread in recent years for problems where an analytic mapping does not exist or when numeric solutions are intractable <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>. Image completion is an excellent example of such an application, particularly in a scenario where there are typical recurrent but varying patterns in the image. Machine learning techniques were also used for the optimization of ultracold atoms cooling sequences <ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref><ref type="bibr" target="#b11">[12]</ref> and to execute related numerical calculations <ref type="bibr" target="#b12">[13]</ref>. They were also suggested <ref type="bibr" target="#b13">[14]</ref> and demonstrated <ref type="bibr" target="#b14">[15]</ref> to be useful for fluorescence detection of pinned atoms and ions.</p><p>Here we report on a new approach for absorption imaging that uses a deep neural network (DNN) to generate an ideal reference frame from a single image that includes the atomic absorption signal. The reference image is constructed by masking out the part of the image containing the atomic shadow and using the network for image completion of the background. We demonstrate the new method with data acquired with ultracold 40 K gas and show that the images captured by the single exposure technique feature lower noise levels and therefore allow for a more accurate extraction of physical observables. In addition to the improvement in the data quality, our single-shot approach simplifies the experimental sequence and eases the hardware requirements from the camera. The DNN model successfully adapts to both short and long time variations, and therefore it constitutes a robust solution.</p><p>arXiv:2003.01643v2 [cond-mat.quant-gas] 8 Apr 2020 </p><formula xml:id="formula_0">(a) Input (b) Prediction (c) Ground truth (d) Difference</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. METHODS</head><p>Experimental apparatus. The experiments are conducted with a quantum degenerate Fermi gas of 40 K atoms with an equal mixture of the two lowest energy states in the F = 9/2 manifold at a magnetic field of 185G. Our experimental system and cooling procedure are the same as described in Refs. <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>. The frames without atoms were captured deliberately along seven months to test the DNN in realistic conditions. We acquired data with atomic clouds at different conditions by modifying the evaporation cooling sequence. For training and validation of the DNN, we also acquired images without atoms. To this end, we set the initial position of the optical transfer trap to about 2cm away from their location at the magnetic trap, hence no atoms are shuttled to the position where the images are recorded. In all cases, the first exposure was taken between 12ms − 18ms after the optical dipole trap was turned off abruptly.</p><p>The images are taken with a laser tuned to the cycling transition F = 9/2, m F = −9/2 → F = 11/2, m F = −11/2 in the D 2 manifold, at a wavelength of ∼ 766.7nm. The laser linewidth is about 100kHz, much narrower than the D 2 natural linewidth of ∼ 2π × 6MHz. The illumination is pulsed for 80µs and recorded by a 14 bit CCD camera <ref type="bibr" target="#b17">[18]</ref>. The reference frame (for the conventional absorption imaging) is recorded with a second pulse given after 50ms, when the atoms already moved out of the camera field of view. We also capture "dark frames" without illumination at all that serve as the zero references. The dark images don't have to be taken often since they only account for any remaining light which is not due to the probe beam and for electronic noise in the camera. Prior to analyzing the two images in the conventional absorption imaging technique, we correct for small differences which may exist between the intensity of the illumination in both exposures. These differences are typ-ically of few percents. The second exposure is taken only in order to compare our technique with the conventional method and is neither required for the application of the DNN nor for its training.</p><p>Two physical observables that are commonly used in ultracold atomic experiments are the temperature and number of atoms. In the presented results, the number of atoms in the cloud and its temperature are controlled by changing the final trap depth in the optical evaporation. We extract the observables from the momentum distribution, which is measured after 15ms of a ballistic expansion. To extract the observables, we fit the OD images with <ref type="bibr" target="#b0">[1]</ref> OD (x, y) = OD peak</p><formula xml:id="formula_1">Li 2 −ze − (x−x 0 ) 2 2σ 2 x − (y−y 0 ) 2 2σ 2 y Li 2 (−z) + B ,<label>(1)</label></formula><p>where Li n (z) denotes the Jonquière's polylogarithm function, z = e µ/k B T is the fugacity, and B accounts for any remaining constant background in the OD image. From the fugacity, we extract the relative temper-</p><formula xml:id="formula_2">ature T /T F = [−6Li 3 (−z)] −1/3 , with T F = (6N ) 1/3hω</formula><p>being the Fermi temperature, andω is the geometricallyaveraged trapping frequency, which we measure and rescale according to the trapping laser power. The number of atoms, N , is obtained by integrating over the fitted momentum distribution. DNN architecture and training. DNNs establish a pipeline where the input (the information in the masked OD image, in our case) undergoes multiple convolutional transformations and dimensional variations. These transformations distill the features of the underlying spatial pattern, and their result is the prediction of the DNN. The network is trained to optimally recover the structure of the illumination in the region where the atomic signal appears. The training phase is performed using images captured without atoms, and constitute therefore the "ground truth" for the unsupervised reconstruction. At each optimization step, the prediction of the network is compared to the ground truth values in the masked area, and the weights of the model are varied to minimize the loss, i.e., the mean squared error (L 2 norm) between the ground truth and the prediction. At the end of the training, we obtain an optimized model ready for prediction (inference) on new images with atoms. The network produces an ideal reference regardless of whether atoms appeared in the original image or not, because the relevant region is masked out. Since the involved convolutions are relatively simple, the evaluation of the model for inference on new inputs is rapid, and therefore the integration of a trained network into the infrastructure of another calculation is extremely facile.</p><p>From the raw images we subtract the dark frames, and then take the logarithm of their pixel values. The convolutional network is an autoencoder of a U-net architecture <ref type="bibr" target="#b18">[19]</ref>. The input to the network is the OD image cropped to 476 × 476 pixels around the position of the atoms, from which we mask out the central circle with a diameter of 190 pixels <ref type="bibr" target="#b19">[20]</ref> that may include an absorption signal if atoms are present. This mask diameter is larger by at least a factor of two relative to the size of the typical atomic cloud, to ensure that there is no absorption signal in the region used by the DNN to predict the background. For training, we use a generator to riffle through the stored TIFF images, apply the mask on the input, and feed the DNN input with 8 frames batches <ref type="bibr" target="#b20">[21]</ref>. To evaluate the DNN on an atomic frame, we store the model inference as binary file and subtract the input frame to obtain the atomic OD. By minimizing the loss over the square circumscribing the masked region (dashed cyan square in <ref type="figure" target="#fig_0">Fig. 1a</ref>), we ensure continuity at the corners, where the background is unmasked. Effectively 1 − π 4 of the loss is dedicated to image duplication rather than completion, in order to eliminate any offset between the input and output frames, which might be translated into an error in the number of atoms.</p><p>The feed-forward network consists of about 20 · 10 6 parameters arranged in 27 layers. These parameters were optimized by running over ∼ 30 · 10 3 frames captured without atoms, with additional ∼ 7 · 10 3 images for loss validation, comparing the network output to the original central part of each image, and minimizing the mean squared error loss function. We used ADAM optimizer <ref type="bibr" target="#b21">[22]</ref> and Glorot initialization <ref type="bibr" target="#b22">[23]</ref> for the parameters optimization, applying 99% batch normalization <ref type="bibr" target="#b23">[24]</ref>. For this application, labeling of the input frames is unnecessary as the network output is compared directly against its input before masking. The only prior knowledge is the absence of atoms in the peripheral region and, only for the training set, also in the central area. Notably, generative adversarial networks <ref type="bibr" target="#b24">[25]</ref>, which were found very successful in natural-scene image competition tasks, might be destructive for this study case, as there is a given unique ground truth. . Lower values mean better performance. The purple curve represents the residual loss of the training set, which is minimized in the optimization process. The black curve is the residual error on the validation set, which was not used for training. The dashed red line designates the mean residual noise in the standard doubleshot scheme, multiplied by π/4 to correctly compare with the residual noise of the DNN prediction in the central circle (see <ref type="figure" target="#fig_0">Fig. 1d</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. RESULTS</head><p>DNN performance on the validation set. First, we examine the residual noise in inferences on the validation set, which was not used for training and does not include atomic signal. The convergence of the model is depicted in <ref type="figure" target="#fig_1">Fig. 2</ref>, where we present the decay of the residual loss during the training process for both the training (purple) and validation (black) datasets. The decay in both datasets on a log-log scale is sub-power-law. It exceeds the reference level, set by the average double-shot residual noise (dashed red line), after approximately 100 training epochs, which mainly points to a reliable extraction of the bias, but noise features still exist. In principle, the training should continue as long as the validation loss decreases. In practice, the loss decay slows dramatically after few hundreds of epochs, and we therefore cease the training after 1133 epochs. An example for image completion without atoms is displayed in <ref type="figure" target="#fig_0">Fig. 1</ref>, with the DNN input (1a) and the corresponding prediction of the network (1b), which closely resembles the original data (1c). Notably, there are no significant spatial correlations in the difference between the desired and the predicted frame (1d).</p><p>The lowest residual error is 0.0681 optical-depth root mean squared error (ODRMSE), for the whole validation dataset captured intermittently along seven months. As most of the residual error resulted from the inner circle of the square output image (see <ref type="figure" target="#fig_0">Fig. 1d</ref>), a fair comparison  <ref type="bibr" target="#b1">[2]</ref>. The PCA vectors set was extracted from the 300 significant components out of 600 random images taken from the DNN training set. Different colors distinguish the validation set constituent frames by date, counting from the first partial set.</p><p>for the loss is against π/4 of the averaged-double-shot error, indicated by a dashed red line in <ref type="figure" target="#fig_1">Fig. 2</ref>. This reference value is 0.0745 (ODRMSE), 9.4% higher than the minimal validation loss obtained during the first 1139 epochs.</p><p>In <ref type="figure" target="#fig_2">Fig. 3</ref> we compare the histograms of the residual loss on the validation set using the DNN-based singleshot technique (upper panel), the conventional doubleexposure technique (middle panel), and background completion using principal component analysis (PCA) technique (lower panel) <ref type="bibr" target="#b1">[2]</ref>. The histogram for the DNN technique exhibits a single narrow peak, while for the two other approaches it is markedly wider and multistructured. To illustrate the source of this behavior, we color the histograms based on the elapsed time when taking the corresponding dataset, relative to the first set. We find that the double-peak structure of the conventional double-shot technique is correlated to time variations, probably due to slow drifts in the probe light intensity. An exacerbation of this variation is observable in the PCA results. We substantiate that it directly emerges from the variations in the set from which the PCA basis is taken by repeating the PCA analysis but with the basis taken over 600 frames all from the first day of image acquisition. In this case, we find that the PCA approach yields excellent results for same-day frames, 0.08(2) ODRMSE. Nonetheless, its performance dramatically deteriorates with long-term drifts -we find distinct date-dependent peaks in the histogram (not shown in the <ref type="figure">figure)</ref>, and for the 206 − 210 days datasets the error distribution lies at 0.42(1) ODRMSE. We can conclude that in order for the PCA approach to maintain adequate performance, recurrent dataset accumulation and analysis is needed, almost on a daily basis. In contrast, the DNN technique is robust and insensitive to these variations. It derives its robustness from the variance in the substantially broader dataset, which is tractable due to the sequential training of the network.</p><p>The results on the validation set show that the DNN single-exposure approach achieves lower residual noise levels and deals better with variations in the imaging conditions when compared to the conventional double-shot scheme or linear algorithms. The residual noise of the DNN technique can, in principle, be further reduced by additional training. To assess the usefulness of the time invested in such prolonged training, one should take into account whether it has a measurable effect on physical observables, as we describe in the next section.</p><p>Single-shot imaging evaluation. In this section we present single-shot absorption images of a quantum degenerate fermionic potassium gas at different conditions. A typical analysis of a low-OD image following a ballistic expansion from a ∼ 80nK-deep trap is shown in <ref type="figure">Fig. 4</ref>. In panel (4a), we present the inner square part of the input log image. In this example, there are approximately 30 · 10 3 atoms, hence the atomic signal is hardly discernible from the background to the naked eye. When it is subtracted from the network prediction in (4b), a clean OD image is obtained (4c). As a comparison, panel (4d) shows the conventional absorption image obtained from two exposures in the same experiment. Evidently, the single-shot approach eliminates the remaining fringe pattern and yields an overall better OD image. More examples for different trap depths are presented in the upper panel of <ref type="figure">Fig. 5</ref>, and show the same behaviour regardless of the atomic conditions.</p><p>Effect on physical observables. In <ref type="figure" target="#fig_4">Fig. 6</ref> we plot the number of atoms and temperature for different trap depths as extracted by the single-shot (purple diamonds) and the two-exposures (black circles) techniques. Importantly, the new technique does not introduce any systematic error in extraction of these important observables. The errorbars represent the 1σ shot-to-shot variation in the experimental conditions combined with the fitting extraction error. Since both of these terms are of a similar magnitude, it is hard to observe the improvement in the single-exposure technique. To emphasize this improve- , 55(7) · 10 3 , 45(9) · 10 3 , 37(9) · 10 3 , and 28(7) · 10 3 ; and they were released respectively from 190, 117, 89, 76, and 57nK-deep traps. All examples displayed in the same color scale as in <ref type="figure">Fig. 4d</ref>. ment, we present in the insets only the fitting extraction relative error averaged over the 10 experimental realizations in each trap depth. We find that the extraction uncertainty of both observables is smaller by ∼ 17% using the single-exposure technique.</p><formula xml:id="formula_3">(a) Input (b) Prediction (c) Difference (d) Reference</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. SUMMARY AND OUTLOOK</head><p>We have demonstrated a single-shot absorption imaging based on a deep convolutional network background completion. We have shown that this approach can accurately reconstruct atomic density profiles and yield smaller errors on the extracted physical quantities, com-pared to the standard double-exposure technique. The single-shot imaging lifts the need for fast cameras and facilitates multi-framed acquisitions. The corresponding simplification directly enables simpler and cleaner designs for new cold atomic systems. We have also demonstrated the ability of the DNN to adapt to variations in the working condition that develop through time.</p><p>Our network can be improved in several aspects. First, the masked area can be enlarged to achieve even better robustness. Also, by training the network over random patches in the uncropped OD image, the positiondependency of the result can be further reduced. Another interesting direction is the implementation of an online learning scheme, where images are routinely added to the dataset and the model is continuously updated between inferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DATA AVAILABILITY</head><p>The trained network and its generating scripts are publicly available as an open-source Python software package [26] to facilitate their deployment by other experimental groups. Using the provided repository, single-shot imaging can be realized on any imaging apparatus, following local parameters training. k</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIG. 1 .</head><label>1</label><figDesc>Completion of a background frame by the neural net -an example of network evaluation of a typical image without atoms from the validation set. (a) The input log image with its central part masked. The network task is to complete the image in the central cyan square. (b) The network prediction for the central square. (c) The original central part of the image ("ground truth"). (d) The difference between the network prediction and the ground truth, multiplied by 5 to enhance the contrast. The residual OD root mean squared error of this example is 0.061 for both the single-exposure and double-exposure techniques.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>FIG. 2 .</head><label>2</label><figDesc>Minimization of the residual error along the DNN training. Optical-density root mean squared error between the model prediction and the ground truth as a function of the number of training iterations (epochs)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIG. 3 .</head><label>3</label><figDesc>Residual error distribution of the difference images in the validation set. The upper histogram indicates the opticaldensity root mean squared error of the DNN single-exposure technique following 1133 training epochs. The middle histogram represents the residual error in the standard doubleexposure technique, after correction for probe intensity fluctuations. The lower histogram depicts the residual error of PCA-based reference generation images</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIG. 4 .FIG. 5 .</head><label>45</label><figDesc>Reconstruction of a single-shot image with atoms, exemplified with a cloud of ∼ 30 · 10 3 atoms. (a) The central square of a single-shot log image, including the masked area (dotted white circle). (b) The network prediction. (c) The difference between prediction and input, multiplied by 5, resulting in a fringes-free single-shot absorption image. (d) The result of the conventional two-exposures technique in the same experiment, where the second exposure is taken 50ms after the first one (also multiplied by 5). Additional examples of inferences of the neural network on images with atoms (upper panel) for different conditions of the atomic cloud. Lower panel presents the correlative results using the standard double-shot technique. The numbers of atoms in these examples are, from left to right, 99(11) · 10 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>FIG. 6 .</head><label>6</label><figDesc>Characterization of resulted images -number of atoms and temperature extracted by fitting a Fermi-Dirac distribution to the data. The conditions of the atomic clouds are controlled by the final trap depth in the optical evaporation. Black circles mark the results of the conventional double-exposure technique, while purple diamonds mark the results with the single-shot DNN approach. Errorbars combine extraction uncertainty with shot-to-shot variation over 10 experimental realizations. The insets show the average fit extraction error. The single-exposure technique achieves a better accuracy in both observables.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Making, probing and understanding ultracold fermi gases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Zwierlein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ketterle</surname></persName>
		</author>
		<idno type="DOI">10.1393/ncr/i2008-10033-1</idno>
	</analytic>
	<monogr>
		<title level="j">La Rivista del Nuovo Cimento</title>
		<imprint>
			<biblScope unit="page" from="247" to="422" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optimized fringe removal algorithm for absorption images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linxiao</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinxin</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuzong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoji</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.5040669</idno>
	</analytic>
	<monogr>
		<title level="j">Applied Physics Letters</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page">144103</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Effective statistical fringe removal algorithm for high-sensitivity imaging of ultracold atoms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengdong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zejian</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Entong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeongwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyu-Boong</forename><surname>Jo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature14539</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Quantum machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Biamonte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Wittek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Pancotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Rebentrost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Wiebe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seth</forename><surname>Lloyd</surname></persName>
		</author>
		<idno type="DOI">10.1038/nature23474</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">549</biblScope>
			<biblScope unit="page" from="195" to="202" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A high-bias, low-variance introduction to machine learning for physicists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marin</forename><surname>Bukov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><forename type="middle">G R</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clint</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><forename type="middle">K</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Schwab</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.physrep.2019.03.001</idno>
	</analytic>
	<monogr>
		<title level="j">Physics Reports</title>
		<imprint>
			<biblScope unit="volume">810</biblScope>
			<biblScope unit="page" from="1" to="124" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Machine learning and the physical sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><surname>Carleo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ignacio</forename><surname>Cirac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Cranmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Daudet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Schuld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naftali</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leslie</forename><surname>Vogt-Maranto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lenka</forename><surname>Zdeborová</surname></persName>
		</author>
		<idno type="DOI">10.1103/revmodphys.91.045002</idno>
	</analytic>
	<monogr>
		<title level="j">Reviews of Modern Physics</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">A survey of deep learning for scientific discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maithra</forename><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Schmidt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fast machine-learning online optimization of ultra-cold-atom experiments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Wigley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Everitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Hengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Bastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Sooriyabandara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Hardman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Quinlivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Manju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C N</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">R</forename><surname>Petersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Luiten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Hope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Robins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Hush</surname></persName>
		</author>
		<idno type="DOI">10.1038/srep25890</idno>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multiparameter optimisation of a magneto-optical trap using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Tranter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Slatyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Hush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Everett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">V</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaz-Gris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Buchler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Campbell</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-018-06847-1</idno>
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Nonstandard trajectories found by machine learning for evaporative cooling of 87rb atoms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ippei</forename><surname>Nakamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsunori</forename><surname>Kanemura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takumi</forename><surname>Nakaso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryuta</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeshi</forename><surname>Fukuhara</surname></persName>
		</author>
		<idno type="DOI">10.1364/oe.27.020435</idno>
	</analytic>
	<monogr>
		<title level="j">Optics Express</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page">20435</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Applying machine learning optimization methods to the production of a quantum gas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A J</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Style</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luksch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sunami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Foot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bentine</surname></persName>
		</author>
		<idno type="DOI">10.1088/2632-2153/ab6432</idno>
	</analytic>
	<monogr>
		<title level="j">Machine Learning: Science and Technology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">15007</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Supervised machine learning of ultracold atoms with speckle disorder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pilati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pieri</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-019-42125-w</idno>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deep learning-assisted classification of site-resolved quantum gas microscope images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R B</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><forename type="middle">J</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rick</forename><surname>Ferlaino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Bijnen</surname></persName>
		</author>
		<idno type="DOI">10.1088/1361-6501/ab44d8</idno>
	</analytic>
	<monogr>
		<title level="j">Measurement Science and Technology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">25201</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Fast highfidelity readout of a single trapped-ion qubit via machinelearning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Ming</forename><surname>Zi-Han Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Feng</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan-Feng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang-Can</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guo</surname></persName>
		</author>
		<idno type="DOI">10.1103/physrevapplied.12.014038</idno>
	</analytic>
	<monogr>
		<title level="j">Physical Review Applied</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">High-sensitivity rf spectroscopy of a strongly interacting fermi gas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantine</forename><surname>Shkedrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanay</forename><surname>Florshaim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Ness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Gandman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Sagi</surname></persName>
		</author>
		<idno type="DOI">10.1103/physrevlett.121.093402</idno>
	</analytic>
	<monogr>
		<title level="j">Physical Review Letters</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Realistic shortcuts to adiabaticity in optical transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Ness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Constantine</forename><surname>Shkedrov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanay</forename><surname>Florshaim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Sagi</surname></persName>
		</author>
		<idno type="DOI">10.1088/1367-2630/aadcc1</idno>
	</analytic>
	<monogr>
		<title level="j">New Journal of Physics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">95002</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<title level="m">PCO pixelfly usb (ICX285AL CCD)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-24574-4_28</idno>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="234" to="241" />
			<date type="published" when="2015" />
			<publisher>Springer International Publishing</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The imaging system translates the mask diameter of 190 pixels into 626µm at the atoms plane</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Keras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno>1412.6980v9</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>1502.03167v3</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Z. Ghahramani, M. Welling, C. Cortes, N. D</editor>
		<imprint>
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Curran Associates, Inc</publisher>
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
