<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-supervised GAN: Analysis and Improvement with Multi-class Minimax Game</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Trung</forename><surname>Tran</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design (SUTD)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viet-Hung</forename><surname>Tran</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design (SUTD)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Bao</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design (SUTD)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linxiao</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design (SUTD)</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Cheung</surname></persName>
							<email>&lt;ngaiman_cheung@sutd.edu.sg&gt;</email>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design (SUTD)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Self-supervised GAN: Analysis and Improvement with Multi-class Minimax Game</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Corresponding author: Ngai-Man Cheung</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Self-supervised (SS) learning is a powerful approach for representation learning using unlabeled data. Recently, it has been applied to Generative Adversarial Networks (GAN) training. Specifically, SS tasks were proposed to address the catastrophic forgetting issue in the GAN discriminator. In this work, we perform an in-depth analysis to understand how SS tasks interact with learning of generator. From the analysis, we identify issues of SS tasks which allow a severely mode-collapsed generator to excel the SS tasks. To address the issues, we propose new SS tasks based on a multi-class minimax game. The competition between our proposed SS tasks in the game encourages the generator to learn the data distribution and generate diverse samples. We provide both theoretical and empirical analysis to support that our proposed SS tasks have better convergence property.</p><p>We conduct experiments to incorporate our proposed SS tasks into two different GAN baseline models. Our approach establishes state-of-the-art FID scores on CIFAR-10, CIFAR-100, STL-10, CelebA, Imagenet 32 × 32 and Stacked-MNIST datasets, outperforming existing works by considerable margins in some cases. Our unconditional GAN model approaches performance of conditional GAN without using labeled data. Our code: https://github.com/tntrung/msgan</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>task is referred as the self-supervised task. This simple method is able to close the gap between supervised and unsupervised image classification <ref type="bibr" target="#b9">[10]</ref>.</p><p>Self-supervised Learning for GAN. Recently, self-supervised learning has been applied to GAN training <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b43">44]</ref>. These works propose auxiliary self-supervised classification tasks to assist the main GAN task <ref type="figure" target="#fig_3">(Figure 1</ref>). In particular, their objective functions for learning discriminator D and generator G are multi-task loss as shown in <ref type="bibr" target="#b0">(1)</ref> and <ref type="bibr" target="#b1">(2)</ref> respectively:</p><formula xml:id="formula_0">max D,C V D (D, C, G) = V(D, G) + λ d Ψ(G, C) (1) min G V G (D, C, G) = V(D, G) − λ g Φ(G, C) (2) V(D, G) = E x∼P d log D(x) + E x∼Pg log 1 − D(x)<label>(3)</label></formula><p>Here, V(D, G) in (3) is the GAN task, which is the original value function proposed in Goodfellow et al. <ref type="bibr" target="#b11">[12]</ref>. P d is true data distribution, P g is the distribution induced by the generator mapping. Ψ(G, C) and Φ(G, C) are the self-supervised (SS) tasks for discriminator and generator learning, respectively (details to be discussed). C is the classifier for the self-supervised task, e.g. rotation classifier as discussed <ref type="bibr" target="#b9">[10]</ref>. Based on this framework, Chen et al. <ref type="bibr" target="#b3">[4]</ref> apply self-supervised task to help discriminator counter catastrophic forgetting. Empirically, they have shown that self-supervised task enables discriminator to learn more stable and improved representation. Tran et al. <ref type="bibr" target="#b43">[44]</ref> propose to improve self-supervised learning with adversarial training.</p><p>Despite the encouraging empirical results, in-depth analysis of the interaction between SS tasks (Ψ(.) and Φ(.)) and GAN task (V(D, G)) has not been done before. On one hand, the application of SS task for discriminator learning is reasonable: the goal of discriminator is to classify real/fake image; an additional SS classification task Ψ(G, C) could assist feature learning and enhance the GAN task.</p><p>On the other hand, the motivation and design of SS task for generator learning is rather subtle: the goal of generator learning is to capture the data distribution in G, and it is unclear exactly how an additional SS classification task Φ(G, C) could help.</p><p>In this work, we conduct in-depth empirical and theoretical analysis to understand the interaction between self-supervised tasks (Ψ(.) and Φ(.)) and learning of generator G. Interestingly, from our analysis, we reveal issues of existing works. Specifically, the SS tasks of existing works have "loophole" that, during generator learning, G could exploit to maximize Φ(G, C) without truly learning the data distribution. We show that analytically and empirically that a severely modecollapsed generator can excel Φ(G, C). To address this issue, we propose new SS tasks based on a multi-class minimax game. Our proposed new SS tasks of discriminator and generator compete with each other to reach the equilibrium point. Through this competition, our proposed SS tasks are able to support the GAN task better. Specifically, our analysis shows that our proposed SS tasks enhance matching between P d and P g by leveraging the transformed samples used in the SS classification (rotated images when <ref type="bibr" target="#b9">[10]</ref> is applied). In addition, our design couples GAN task and SS task. To validate our design, we provide theoretical analysis on the convergence property of our proposed SS tasks. Training a GAN with our proposed self-supervised tasks based on multi-class minimax game significantly improves baseline models. Overall, our system establishes state-of-the-art Fréchet Inception Distance (FID) scores. In summary, our contributions are:</p><p>• We conduct in-depth empirical and theoretical analysis to understand the issues of selfsupervised tasks in existing works. • Based on the analysis, we propose new self-supervised tasks based on a multi-class minimax game. • We conduct extensive experiments to validate our proposed self-supervised tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related works</head><p>While training GAN with conditional signals (e.g., ground-truth labels of classes) has made good progress <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b1">2]</ref>, training GAN in the unconditional setting is still very challenging. In the original GAN <ref type="bibr" target="#b11">[12]</ref>, the single signal (real or fake) of samples is provided to train discriminator and the generator. With these signals, the generator or discriminator may fall into ill-pose settings, and they  <ref type="figure" target="#fig_3">Figure 1</ref>: The model of (a) SSGAN <ref type="bibr" target="#b3">[4]</ref> and (b) our approach. Here, Ψ(C) and Φ(G, C) are the self-supervised value functions in training discriminator and generator, respectively, as proposed in <ref type="bibr" target="#b3">[4]</ref>. Ψ + (G, C) and Φ + (G, C) are the self-supervised value functions proposed in this work. may get stuck at bad local minimums though still satisfying the signal constraints. To overcome the problems, many regularizations have been proposed. One of the most popular approaches is to enforce (towards) Lipschitz condition of the discriminator. These methods include weight-clipping <ref type="bibr" target="#b0">[1]</ref>, gradient penalty constraints <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b26">27]</ref> and spectral norm <ref type="bibr" target="#b30">[31]</ref>. Constraining the discriminator mitigates gradients vanishing and avoids sharp decision boundary between the real and fake classes.</p><p>Using Lipschitz constraints improve the stability of GAN. However, the challenging optimization problem still remains when using a single supervisory signal, similar to the original GAN <ref type="bibr" target="#b11">[12]</ref>. In particular, the learning of discriminator is highly dependent on generated samples. If the generator collapses to some particular modes of data distribution, it is only able to create samples around these modes. There is no competition to train the discriminator around other modes. As a result, the gradients of these modes may vanish, and it is impossible for the generator to model well the entire data distribution. Using additional supervisory signals helps the optimization process. For example, using self-supervised learning in the form of auto-encoder has been proposed. AAE <ref type="bibr" target="#b28">[29]</ref> guides the generator towards resembling realistic samples. However, an issue with using auto-encoder is that pixel-wise reconstruction with 2 -norm causes blurry artifacts. VAE/GAN <ref type="bibr" target="#b21">[22]</ref>, which combining VAE <ref type="bibr" target="#b18">[19]</ref> and GAN, is an improved solution: while the discriminator of GAN enables the usage of feature-wise reconstruction to overcome the blur, the VAE constrains the generator to mitigate mode collapse. In ALI <ref type="bibr" target="#b7">[8]</ref> and BiGAN <ref type="bibr" target="#b6">[7]</ref>, they jointly train the data/latent samples in the GAN framework. InfoGAN <ref type="bibr" target="#b4">[5]</ref> infers the disentangled latent representation by maximizing the mutual information. In <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43]</ref>, they combine two different types of supervisory signals: real/fake signals and self-supervised signal in the form of auto-encoder. In addition, Auto-encoder based methods, including <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>, can be considered as an approach to mitigate catastrophic forgetting because they regularize the generator to resemble the real ones. It is similar to EWC <ref type="bibr" target="#b19">[20]</ref> or IS <ref type="bibr" target="#b47">[48]</ref> but the regularization is achieved via the output, not the parameter itself. Although using feature-wise distance in auto-encoder could reconstruct sharper images, it is still challenging to produce very realistic detail of textures or shapes.</p><p>Several different types of supervisory signal have been proposed. Instead of using only one discriminator or generator, they propose ensemble models, such as multiple discriminators <ref type="bibr" target="#b31">[32]</ref>, mixture of generators <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b8">9]</ref> or applying an attacker as a new player for GAN training <ref type="bibr" target="#b27">[28]</ref>. Recently, training model with auxiliary self-supervised constraints <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b43">44]</ref> via multi pseudo-classes <ref type="bibr" target="#b9">[10]</ref> helps improve stability of the optimization process. This approach is appealing: it is simple to implement and does not require more parameters in the networks (except a small head for the classifier). Recent work applies InfoMax principle to improve GAN <ref type="bibr" target="#b23">[24]</ref>. Variational Autoencoder is another important approach to learn generative models <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b45">46]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">GAN with Auxiliary Self-Supervised tasks</head><p>In <ref type="bibr" target="#b3">[4]</ref>, self-supervised (SS) value function (also referred as "self-supervised task") was proposed for GAN <ref type="bibr" target="#b11">[12]</ref> via image rotation prediction <ref type="bibr" target="#b9">[10]</ref>. In their work, they showed that the SS task was useful to mitigate catastrophic forgetting problem of GAN discriminator. The objectives of the discriminator and generator in <ref type="bibr" target="#b3">[4]</ref> are shown in Eq. 4 and 5. Essentially, the SS task of the discriminator (denoted by Ψ(C)) is to train the classifier C that maximizes the performance of predicting the rotation applied to the real samples. Given this classifier C, the SS task of the generator (denoted by Φ(G, C)) is to train the generator G to produce fake samples for maximizing classification performance. The discriminator and classifier are the same (shared parameters), except the last layer in order to implement two different heads: the last fully-connected layer which returns a one-dimensional output (real or fake) for the discriminator, and the other which returns a K-dimensional softmax of pseudo-classes for the classifier. λ d and λ g are constants.</p><formula xml:id="formula_1">max D,C V(D, C, G) = V(D, G) + λ d E x∼P T d E T k ∼T log C k (x) Ψ(C) (4) min G V(D, C, G) = V(D, G) − λ g E x∼P T g E T k ∼T log C k (x) Φ(G,C)<label>(5)</label></formula><p>Here, the GAN value function V(D, G) (also referred as "GAN task") can be the original minimax GAN objective <ref type="bibr" target="#b11">[12]</ref> or other improved versions. T is the set of transformation, T k ∈ T is the k-th transformation. The rotation SS task proposed in <ref type="bibr" target="#b9">[10]</ref> is applied, and T 1 , T 2 , T 3 , T 4 are the 0, 90, 180, 270 degree image rotation, respectively. P d , P g are the distributions of real and fake data samples, respectively. P T d , P T g are the mixture distribution of rotated real and fake data samples (by T k ∈ T ), respectively. Let C k (x) be the k-th softmax output of classifier C, and we have</p><formula xml:id="formula_2">K k=1 C k (x) = 1, ∀x.</formula><p>The models are shown in <ref type="figure" target="#fig_3">Fig. 1a</ref>. In <ref type="bibr" target="#b3">[4]</ref>, empirical evidence of improvements has been provided.</p><p>Note that, the goal of Φ(G, C) is to encourage the generator to produce realistic images. It is because classifier C is trained with real images and captures features that allow detection of rotation. However, the interaction of Φ(G, C) with the GAN task V(D, G) has not been adequately analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis on Auxiliary Self-supervised Tasks</head><p>We analyze the SS tasks in <ref type="bibr" target="#b3">[4]</ref>  <ref type="figure" target="#fig_3">(Figure 1a</ref>). We assume that all networks D, G, C have enough capacity <ref type="bibr" target="#b11">[12]</ref>. Refer to the Appendix A for full derivation. Let D * and C * be the optimal discriminator and optimal classifier respectively at an equilibrium point. We assume that we have an optimal D * of the GAN task. We focus on C * of SS task. Let p T k (x) be the probability of sample x under transformation by T k <ref type="figure">(Figure 2</ref></p><formula xml:id="formula_3">). p T k d (x), p T k g (x) denotes the probability p T k (x) of data sample (x ∼ P T d ) or generated sample (x ∼ P T g ) respectively.</formula><p>Proposition 1 The optimal classifier C * of Eq. 4 is:</p><formula xml:id="formula_4">C * k (x) = p T k d (x) K k=1 p T k d (x)<label>(6)</label></formula><p>Proof. Refer to our proof in Appendix A for optimal C * .</p><p>Theorem 1 Given optimal classifier C * for SS task Ψ(C), at the equilibrium point, maximizing SS task Φ(G, C * ) of Eq. 5 is equal to maximizing: <ref type="figure">Figure 2</ref>: The probability distribution p T k d (x). Here, samples from P d are rotated by T k . The distribution of rotated sample is p T k (x). Some rotated samples resemble the original samples, e.g. those on the right of x 2 . On the other hand, for some image, there is no rotated image resembling it, e.g. x 1 (p Tj d (x 1 ) = 0, j = 1). The generator can learn to generate these images e.g. x 1 to achieve maximum of Φ(G, C * ), without actually learning the entire P d .</p><formula xml:id="formula_5">Φ(G, C * ) = 1 K K k=1 E x∼P T k g log p T k d (x) K k=1 p T k d (x) = 1 K K k=1 V T k Φ (x)<label>(7)</label></formula><formula xml:id="formula_6">P d P d T 1(x) P d T 2(x) P d T 3(x) P d T 4(x) x 1 x 2 p d T 1(x 1 ) p d T 1(x 2 ) T k</formula><p>Proof. Refer to our proof in Appendix A.</p><p>Theorem 1 depicts learning of generator G given the optimal C * : selecting G (hence P g ) to maximize Φ(G, C * ). As C * is trained on real data, Φ(G, C * ) encourages G to learn to generate realistic samples. However, we argue that G can maximize Φ(G, C * ) without actually learning data distribution P d . In particular, it is sufficient for G to maximize Φ(G, C * ) by simply learning to produce images which rotated version is rare (near zero probability). Some example images are shown in <ref type="figure">Figure 3a</ref>. Intuitively, for these images, rotation can be easily recognized.</p><p>The argument can be developed from Theorem 1. From <ref type="bibr" target="#b6">(7)</ref>, it can be shown that</p><formula xml:id="formula_7">V T k Φ (x) ≤ 0 (p T k g (x) &gt;= 0 and p T k d (x) K k=1 p T k d (x)</formula><p>≤ 1). One way for G to achieve the maximum is to generate x such that p T1 d (x) = 0 and p Tj d (x) = 0, j = 1. For these x, the maximum V T k Φ (x) = 0 is attained. Note that T 1 corresponds to 0 degree rotation, i.e., no rotation. Recall that p T k d (x) is the probability distribution of transformed data by T k . Therefore the condition p T1 d (x) = 0 and p Tj d (x) = 0, j = 1 means that there is no other rotated image resembling x, or equivalently, rotated x does not resemble any other images ( <ref type="figure">Figure 2</ref>). Therefore, the generator can exploit this "loophole" to maximize Φ(G, C * ) without actually learning the data distribution. In particular, even a mode-collapsed generator can achieve the maximum of Φ(G, C * ) by generating such images.</p><p>Empirical evidence. Empirically, our experiments (in Appendix B.2.1) show that the FID of the models when using Φ(G, C) is poor except for very small λ g . We further illustrate this issue by a toy empirical example using CIFAR-10. We augment the training images x with transformation data T k (x) to train the classifier C to predict the rotation applied to x. This is the SS task of discriminator in <ref type="figure" target="#fig_3">Figure 1a</ref>. Given this classifier C, we simulate the SS task of generator learning as follows. To simulate the output of a good generator G good which generates diverse realistic samples, we choose the full test set of CIFAR-10 (10 classes) images and compute the cross-entropy loss, i.e. −Φ(G, C), when they are fed into C. To simulate the output of a mode-collapsed generator G collapsed , we select samples from one class, e.g. "horse", and compute the cross-entropy loss when they are fed into C. <ref type="figure">Fig. 3b</ref> show that some G collapsed can outperform G good and achieve a smaller −Φ(G, C). E.g. a G collapsed that produces only "horse" samples outperform G good under Φ(G, C). This example illustrates that, while Φ(G, C) may help the generator to create more realistic samples, it does not help the generator to prevent mode collapse. In fact, as part of the multi-task loss (see <ref type="bibr" target="#b4">(5)</ref>), Φ(G, C) would undermine the learning of synthesizing diverse samples in the GAN task V(D, G).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Proposed method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Auxiliary Self-Supervised Tasks with Multi-class Minimax Game</head><p>In this section, we propose improved SS tasks to address the issue <ref type="figure" target="#fig_3">(Fig. 1b</ref>). Based on a multi-class minimax game, our classifier learns to distinguish the rotated samples from real data versus those from generated data. Our proposed SS tasks are Ψ + (G, C) and Φ + (G, C) in <ref type="formula" target="#formula_8">(8)</ref> and <ref type="formula">(9)</ref> respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ggood Gairplane Gautomobile Gbird Gcat</head><p>Gdog Gdeer Gfrog Ghorse Gship Gtruck 0.0 2.5 5.0 7.5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ggood Gairplane Gautomobile Gbird</head><p>Gcat Gdog Gdeer Gfrog Ghorse Gship Gtruck 0 10 20 Loss <ref type="figure">Figure 3</ref>: (a) Left: Example images that achieve minimal loss (or maximal Φ(G, C)). For these images, rotation can be easily recognized: an image with a 90 degree rotated horse is likely due to applying T 2 rather than an original one. (b) Right (Top): the loss of original SS task, i.e. −Φ(G, C) computed over a good generator (red) and collapsed generators (green, yellow). Some collapsed generators (e.g. one that generates only "horse") have smaller loss than the good generator under −Φ(G, C). (c) Right (Bottom): the loss of proposed MS task, −Φ + (G, C), of a good generator (red) and collapsed generators (green). The good generator has the smallest loss under −Φ + (G, C).</p><p>Our discriminator objective is:</p><formula xml:id="formula_8">max D,C V(D, C, G) = V(D, G)+λ d E x∼P T d E T k ∼T log C k (x) + E x∼P T g E T k ∼T log C K+1 (x) Ψ + (G,C)<label>(8)</label></formula><p>Eq. 8 means that we simultaneously distinguish generated samples, as the (K + 1)-th class, from the rotated real sample classes. Here, C K+1 (x) is the (K + 1)-th output for the fake class of classifier C.</p><p>While rotated real samples are fixed samples that help prevent the classifier (discriminator) from forgetting, the class K + 1 serves as the connecting point between generator and classifier, and the generator can directly challenge the classifier. Our technique resembles the original GAN by Goodfellow et al. <ref type="bibr" target="#b11">[12]</ref>, but we generalize it for multi-class minimax game. Our generator objective is:</p><formula xml:id="formula_9">min G V(D, C, G) = V(D, G)−λ g E x∼P T g E T k ∼T log C k (x) − E x∼P T g E T k ∼T log C K+1 (x) Φ + (G,C) (9) Ψ + (G, C) and Φ + (G, C)</formula><p>form a multi-class minimax game. Note that, when we mention multi-class minimax game (or multi-class adversarial training), we refer to the SS tasks. The game for GAN task is the original by Goodfellow et al. <ref type="bibr" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Theoretical Analysis</head><p>Proposition 2 For fixed generator G, the optimal solution C * under Eq. 8 is:</p><formula xml:id="formula_10">C * k (x) = p T d (x) p T g (x) p T k d (x) K k=1 p T k d (x) C * K+1 (x)<label>(10)</label></formula><p>where p T d (x) and p T g (x) are probability of sample x in the mixture distributions P T d and P T g respectively.</p><p>Proof. Refer to our proof in Appendix A for optimal C * . Theorem 2 Given optimal classifier C * obtained from multi-class minimax training Ψ + (G, C), at the equilibrium point, maximizing Φ + (G, C * ) is equal to maximizing Eq. 11:</p><formula xml:id="formula_11">Φ + (G, C * ) = − 1 K K k=1 KL(P T k g ||P T k d ) + 1 K K k=1 E x∼P T k g log p T k d (x) K k=1 p T k d (x)<label>(11)</label></formula><p>Proof. Refer to our proof in Appendix A.</p><p>Note that proposed SS task objective <ref type="formula" target="#formula_11">(11)</ref> is different from the original SS task objective <ref type="formula" target="#formula_5">(7)</ref> with the KL divergence term. Furthermore, note that KL(P T k g ||P T k d ) = KL(P g ||P d ), as rotation T k is an affine transform and KL divergence is invariant under affine transform (our proof in Appendix A). Therefore, the improvement is clear: Proposed SS tasks Ψ + (.), Φ + (.) work together to improve the matching of P g and P d by leveraging the rotated samples. For a given P g , feedbacks are computed from not only KL(P g ||P d ) but also KL(P T k g ||P T k d ) via the rotated samples. Therefore, G has more feedbacks to improve P g . We investigate the improvement of our method on toy dataset as in Section 4. The setup is the same, except that now we replace models/cost functions of −Φ(G, C) with our proposed ones −Φ + (G, C) (the design of G good and G collapsed are the same). The loss now is shown in <ref type="figure">Fig. 3c</ref>. Comparing <ref type="figure">Fig. 3c</ref> and <ref type="figure">Fig. 3b</ref>, the improvement using our proposed model can be observed: G good has the lowest loss under our proposed model. Note that, since optimizing KL divergence is not easy because it is asymmetric and could be biased to one direction <ref type="bibr" target="#b31">[32]</ref>, in our implementation, we use a slightly modified version as described in the Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments</head><p>We measure the diversity and quality of generated samples via the Fréchet Inception Distance (FID) <ref type="bibr" target="#b13">[14]</ref>. FID is computed with 10K real samples and 5K generated samples exactly as in <ref type="bibr" target="#b30">[31]</ref> if not precisely mentioned. We report the best FID attained in 300K iterations as in <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b46">47]</ref>. We integrate our proposed techniques into two baseline models (SSGAN <ref type="bibr" target="#b3">[4]</ref> and Dist-GAN <ref type="bibr" target="#b41">[42]</ref>). We conduct experiments mainly on CIFAR-10 and STL-10 (resized into 48 × 48 as in <ref type="bibr" target="#b30">[31]</ref>). We also provide additional experiments of CIFAR-100, Imagenet 32 × 32 and Stacked-MNIST.</p><p>For Dist-GAN <ref type="bibr" target="#b41">[42]</ref>, we evaluate three versions implemented with different network architectures: DCGAN architecture <ref type="bibr" target="#b36">[37]</ref>, CNN architectures of SN-GAN <ref type="bibr" target="#b30">[31]</ref> (referred as SN-GAN architecture) and ResNet architecture <ref type="bibr" target="#b12">[13]</ref>. We recall these network architectures in Appendix C. We use ResNet architecture <ref type="bibr" target="#b12">[13]</ref> for experiments of CIFAR-100, Imagenet 32 × 32, and tiny K/4, K/2 architectures <ref type="bibr" target="#b29">[30]</ref> for Stacked MNIST. We keep all parameters suggested in the original work and focus to understand the contribution of our proposed techniques. For SSGAN <ref type="bibr" target="#b3">[4]</ref>, we use the ResNet architecture as implemented in the official code 1 .</p><p>In our experiments, we use SS to denote the original self-supervised tasks proposed in <ref type="bibr" target="#b3">[4]</ref>, and we use MS to denote our proposed self-supervised tasks "Multi-class mini-max game based Self-supervised tasks". Details of the experimental setup and network parameters are discussed in Appendix B.</p><p>We have conducted extensive experiments. Setup and results are discussed in Appendix B. In this section, we highlight the main results:</p><p>• Comparison between SS and our proposed MS using the same baseline.</p><p>• Comparison between our proposed baseline + MS and other state-of-the-art unconditional and conditional GAN. We emphasize that our proposed baseline + MS is unconditional and does not use any label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Comparison between SS and our proposed MS using the same baseline</head><p>Results are shown in <ref type="figure" target="#fig_1">Fig. 4</ref> using Dist-GAN <ref type="bibr" target="#b41">[42]</ref> as the baseline. For each experiment and for each approach (SS or MS), we obtain the best λ g and λ d using extensive search (see Appendix B.4 for details), and we use the best λ g and λ d in the comparison depicted in <ref type="figure" target="#fig_1">Fig. 4</ref>. In our experiments, we observe that Dist-GAN has stable convergence. Therefore, we use it in these experiments. As shown in <ref type="figure" target="#fig_1">Fig. 4</ref>, our proposed MS outperforms the original SS consistently. More details can be found in Appendix B.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Comparison between our proposed method with other state-of-the-art GAN</head><p>Main results are shown in <ref type="table">Table 1</ref>. Details of this comparison can be found in Appendix B.4. The best λ g and λ d as in <ref type="figure" target="#fig_1">Figure 4</ref> are used in this comparison. The best FID attained in 300K iterations  <ref type="bibr" target="#b3">[4]</ref>) and MS (our proposed Multi-class minimax game based Self-supervised tasks). The baseline is Dist-GAN <ref type="bibr" target="#b41">[42]</ref>, implemented with SN-GAN networks (CNN architectures in <ref type="bibr" target="#b30">[31]</ref>) and ResNet. Two datasets are used, CIFAR-10 and STL-10.</p><p>For each experiment, we use the best λ d , λ g for the models, obtained through extensive search (Appendix B.4). Note that λ g = 0 is the best for "Baseline + SS" in all experiments. The results suggest consistent improvement using our proposed self-supervised tasks. <ref type="table">Table 1</ref>: Comparison with other state-of-the-art GAN on CIFAR-10 and STL-10 datasets. We report the best FID of the methods. Two network architectures are used: SN-GAN networks (CNN architectures in <ref type="bibr" target="#b30">[31]</ref>) and ResNet. The FID scores are extracted from the respective papers when available. SS denotes the original SS tasks proposed in <ref type="bibr" target="#b3">[4]</ref>. MS denotes our proposed self-supervised tasks. '*': FID is computed with 10K-10K samples as in <ref type="bibr" target="#b3">[4]</ref>. All compared GAN are unconditional, except SAGAN and BigGAN. SSGAN + is SS-GAN in <ref type="bibr" target="#b3">[4]</ref> but using the best parameters we have obtained. In SSGAN + + MS, we replace the original SS in author's code with our proposed MS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SN-GAN ResNet</head><p>Methods CIFAR-10 STL-10 CIFAR-10 STL-10 CIFAR-10 * are reported as in <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b46">47]</ref>. Note that SN-GAN method <ref type="bibr" target="#b30">[31]</ref> attains the best FID at about 100K iterations with ResNet and it diverges afterward. Similar observation is also discussed in <ref type="bibr" target="#b3">[4]</ref>.</p><p>As shown in <ref type="table">Table 1</ref>, our method (Dist-GAN + MS) consistently outperforms the baseline Dist-GAN and other state-of-the-art GAN. These results confirm the effectiveness of our proposed self-supervised tasks based on multi-class minimax game.</p><p>We have also extracted the FID reported in <ref type="bibr" target="#b3">[4]</ref>, i.e. SSGAN with the original SS tasks proposed there. In this case, we follow exactly their settings and compute FID using 10K real samples and 10K fake samples. Our model achieves better FID score than SSGAN with exactly the same ResNet architecture on CIFAR-10 dataset. See results under the column CIFAR-10 * in <ref type="table">Table 1</ref>.</p><p>Note that we have tried to reproduce the results of SSGAN using its published code, but we were unable to achieve similar results as reported in the original paper <ref type="bibr" target="#b3">[4]</ref>. We have performed extensive search and we use the obtained best parameter to report the results as SSGAN + in <ref type="table">Table 1</ref> (i.e., SSGAN + uses the published code and the best parameters we obtained). We use this code and setup to compare SS and MS, i.e. we replace the SS code in the system with MS code, and obtain "SSGAN + + MS". As shown in <ref type="table">Table 1</ref>, our "SSGAN + + MS" achieves better FID than SSGAN + . The improvement is consistent with <ref type="figure" target="#fig_1">Figure 4</ref> when Dist-GAN is used as the baseline. More detailed experiments can be found in the Appendix. We have also compared SSGAN + and our system (SSGAN + + MS) on CelebA (64 × 64). In this experiment, we use a small DCGAN architecture provided in the authors' code. Our proposed MS outperforms the original SS, with FID improved from 35.03 to 33.47. This experiment again confirms the effectiveness of our proposed MS.  <ref type="table">Table 3</ref>: Comparing to state-of-the-art methods on Stacked MNIST with tiny K/4 and K/2 architectures <ref type="bibr" target="#b29">[30]</ref>. We also follow the same experiment setup of <ref type="bibr" target="#b29">[30]</ref>. We conduct additional experiments on CIFAR-100 and ImageNet 32×32 to compare SS and MS with Dist-GAN baseline. We use the same ResNet architecture as Section B.4 on CIFAR-10 for this study, and we use the best parameters λ d and λ g selected in Section B.4 for ResNet architecture. Experimental results in <ref type="table" target="#tab_1">Table 2</ref> show that our MS consistently outperform SS for all benchmark datasets. For ImageNet 32×32 we report the best FID for SS because the model suffers serious mode collapse at the end of training. Our MS achieves the best performance at the end of training.</p><p>We also evaluate the diversity of our generator on Stacked MNIST <ref type="bibr" target="#b29">[30]</ref>. Each image of this dataset is synthesized by stacking any three random MNIST digits. We follow exactly the same experiment setup with tiny architectures K/4, K/2 and evaluation protocol of <ref type="bibr" target="#b29">[30]</ref>. We measure the quality of methods by the number of covered modes (higher is better) and KL divergence (lower is better). Refer to <ref type="bibr" target="#b29">[30]</ref> for more details. <ref type="table">Table.</ref> 3 shows that our proposed MS outperforms SS for both mode number and KL divergence. Our approach significantly outperforms state-of-the-art <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b16">17]</ref>. Finally, in <ref type="table">Table 1</ref>, we compare our FID to SAGAN <ref type="bibr" target="#b48">[49]</ref> (a state-of-the-art conditional GAN) and BigGAN <ref type="bibr" target="#b1">[2]</ref>. We perform the experiments under the same conditions using ResNet architecture on the CIFAR-10 dataset. We report the best FID that SAGAN can achieve. As SAGAN paper does not have CIFAR-10 results <ref type="bibr" target="#b48">[49]</ref>, we run the published SAGAN code and select the best parameters to obtain the results for CIFAR-10. For BigGAN, we extract best FID from original paper. Although our method is unconditional, our best FID is very close to that of these state-of-the-art conditional GAN. This validates the effectiveness of our design. Generated images using our system can be found in <ref type="figure" target="#fig_4">Figures 5 and 6</ref> of Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We provide theoretical and empirical analysis on auxiliary self-supervised task for GAN. Our analysis reveals the limitation of the existing work. To address the limitation, we propose multi-class minimax game based self-supervised tasks. Our proposed self-supervised tasks leverage the rotated samples to provide better feedback in matching the data and generator distributions. Our theoretical and empirical analysis support improved convergence of our design. Our proposed SS tasks can be easily incorporated into existing GAN models. Experiment results suggest that they help boost the performance of baseline implemented with various network architectures on the CIFAR-10, CIFAR-100, STL-10, CelebA, Imagenet 32 × 32, and Stacked-MNIST datasets. The best version of our proposed method establishes state-of-the-art FID scores on all these benchmark datasets.</p><p>In our paper, we perform an in-depth analysis to understand how SS tasks interact with the learning of the generator. We analyze the issues of SS tasks and propose to improve it with a multi-class minimax game. In this Appendix section, we provide detail information about our proofs, discussion, ablation study, network parameters and network architectures of models.</p><p>A Appendix: Proofs for Sections 4 and 5</p><p>Proposition 1 (Proof.)</p><p>Let T k be the k-th type of transformation, and let P T d be the distribution of the transformed real sample. This section shows the proof for optimal C * . C k (.) is the k-th soft-max output of C, hence K k=1 C k (x) = 1, ∀x. Ψ(C) can be re-written as:</p><formula xml:id="formula_12">Ψ(C) = p T d (x) K k=1 p(T k |x) log C k (x) dx<label>(12)</label></formula><p>where p(T k |x) is the probability that x belongs to class T k , which can be considered as the the k-th output of "ground-truth" classifier on sample x we expect the classifier C to predict. Assume that Ψ(C) has first-order derivative with respective to C k (x). The optimal solution of C k (x) can be obtained via setting this derivative equal to zero:</p><formula xml:id="formula_13">∂Ψ(C) ∂C k (x) = ∂ ∂C k (x) p T d (x) K k=1 p(T k |x) log C k (x) dx = ∂ ∂C k (x) p T d (x) p(T 1 |x) log C 1 (x) + K k=2 p(T k |x) log C k (x) dx = ∂ ∂C k (x) p T d (x) p(T 1 |x) log 1 − K k=2 C k (x) + K k=2 p(T k |x) log C k (x) dx = p T d (x) p(T k |x) C k (x) − p(T 1 |x) C 1 (x)<label>(13)</label></formula><p>For any k ∈ {2, . . . , K}, setting ∂Ψ ∂C k (x) = 0, and the value of optimal C * k has the following form:</p><formula xml:id="formula_14">p(T 1 |x) C * 1 (x) = p(T 2 |x) C * 2 (x) = · · · = p(T k |x) C * K (x)<label>(14)</label></formula><p>Note that .</p><p>That concludes our proof.</p><p>Theorem 1 (Proof.) Substitute C * obtained above into Φ(G, C):</p><formula xml:id="formula_15">Φ(G, C * ) = p T g (x) K k=1 p(T k |x) log C * k (x)<label>(15)</label></formula><p>Substitute C * into (15) we have:</p><formula xml:id="formula_16">Φ(G, C * ) = p T g (x) K k=1 p(T k |x) log C * k (x) dx = p T g (x) K k=1 p(T k |x) log p T k d (x) K k=1 p T k d (x) dx = K k=1 p T g (x)p(T k |x) log p T k d (x) K k=1 p T k d (x) dx = K k=1 1 K p T k g (x) log p T k d (x) K k=1 p T k d (x) dx = 1 K K k=1 p T k g (x) log p T k d (x) K k=1 p T k d (x) dx = 1 K K k=1 E x∼P T k g log p T k d (x) K k=1 p T k d (x)<label>(16)</label></formula><p>That concludes our proof.</p><p>Proposition 2 (Proof.) Training self-supervised task Ψ + (G, C) with minimax game is similar to previous objective, except the additional term of fake class as below:</p><formula xml:id="formula_17">Ψ + (G, C) = E x∼P T d E T k ∼T log C k (x) + E x∼P T g E T k ∼T log C K+1 (x) = p T d (x) K i=1 p(T k |x) log C k (x) + p T g (x) K i=1 p(T k |x) log C K+1 (x) dx<label>(17)</label></formula><p>Assume that Ψ + (G, C) has first-order derivative with respective to C k (x). The optimal C * k (x) can be derived via setting derivative of Ψ + (G, C) equal to zero as follows:</p><formula xml:id="formula_18">∂Ψ + (G, C) ∂C k (x) = ∂ ∂C k (x) p T d (x) K i=1 p(T k |x) log C k (x) + p T g (x) K i=1 p(T k |x) log C K+1 (x) dx = ∂ ∂C k (x) p T d (x)p(T 1 |x) log 1 − K k=1 C k (x) − C K+1 (x) + p T d (x) K k=2 p(T k |x) log C k (x) + p T g (x) K k=1 p(T k |x) log C K+1 (x) dx<label>(18)</label></formula><p>Similar to above, for any k ∈ {2, . . . , K}, we have the derivative ∂Ψ + (G,C) ∂C k (x) :</p><formula xml:id="formula_19">∂Ψ + (G, C) ∂C k (x) = p T d (x) p(T 1 |x) C * 1 (x) − p(T k |x) C * k (x)<label>(19)</label></formula><p>Setting ∂Ψ ∂C k (x) = 0, and we get optimal C * k , k ∈ {1, . . . , K}:</p><formula xml:id="formula_20">p T d (x)p(T 1 |x) C * 1 (x) = p T d (x)p T2 (x) C * 2 (x) = · · · = p T d (x)p(T k |x) C * K (x) = p T d (x) K k=1 p(T k |x) K k=1 C * k (x)<label>(20)</label></formula><p>With k = K + 1, we obtain the derivative of ∂Ψ + (G,C) ∂C K+1 (x) :</p><formula xml:id="formula_21">∂Ψ + (G, C) ∂C K+1 (x) = p T d (x) p(T 1 |x) C * 1 (x) − p T g (x) k=1 Kp(T k |x) C * K+1 (x)<label>(21)</label></formula><p>Setting ∂Ψ ∂C K+1 (x) = 0, and finally we get optimal C * k , k ∈ {1, . . . , K + 1}:</p><formula xml:id="formula_22">p T d (x)p(T 1 |x) C * 1 (x) = · · · = p T d (x)p(T k |x) C * K (x) = p T d (x) K k=1 p(T k |x) K k=1 C * k (x) = p T g (x) K k=1 p(T k |x) C * K+1 (x)<label>(22)</label></formula><p>Because K k=1 C * k (x) + C * K+1 (x) = 1, we finally obtain the optimal C * k (x) from Eq. 20:</p><formula xml:id="formula_23">C * k (x) = p T d (x) p T g (x) p(T k |x) K k=1 p(T k |x) C * K+1 (x) = p T d (x) p T g (x) p T k d (x) K k=1 p T k d (x) C * K+1 (x)</formula><p>. That concludes the proof.</p><p>Theorem 2 (Proof.) Substitute optimal C * obtained above into Φ + (G, C):</p><formula xml:id="formula_24">Φ + (G, C * ) = E x∼P T g K k=1 p(T k |x) log C * k (x) − E x∼P T g K k=1 p(T k |x) log C * K+1 (x)<label>(23)</label></formula><p>The first term can be written as:</p><formula xml:id="formula_25">E x∼P T g K k=1 p(T k |x) log(C * k (x)) = E x∼P T g K k=1 p(T k |x) log p T d (x) p T g (x) p(T k |x) K k=1 p(T k |x) C * K+1 (x) = E x∼P T g K k=1 p(T k |x) log C * K+1 (x) + log p T d (x) p T g (x) + log p(T k |x) K k=1 p(T k |x) = E x∼P T g K k=1 p(T k |x) log C * K+1 (x) + E x∼P T g K k=1 p(T k |x) log p T d (x) p T g (x) + E x∼P T g K k=1 p(T k |x) log p(T k |x) K k=1 p(T k |x) = E x∼P T g K k=1 p(T k |x) log C * K+1 (x) + 1 K K k=1 p T k g (x) log p T k d (x) p T k g (x) dx + E x∼P T g K k=1 p(T k |x) log p(T k |x) * p T d (x) K k=1 p(T k |x) * p T d (x) = E x∼P T g K k=1 p(T k |x) log C * K+1 (x) − 1 K K k=1 KL(P T k g ||P T k d ) + 1 K K k=1 E x∼P T k g log p T k d (x) K k=1 p T k d (x)<label>(24)</label></formula><p>With the note that</p><formula xml:id="formula_26">p T d (x) * p(T k |x) = p(T k ) * p T k d (x) = 1 K p T k d (x) and p T g (x) * p(T k |x) = p(T k ) * p T k g (x) = 1 K p T k g (x)</formula><p>. Moving the first term of Eq. 24 from the right side to left side, it concludes the proof.</p><p>Theorem 3 KL divergence is invariant to affine transform.</p><p>Proofs. Let x ∈ R n×1 be a random variable. p x (x) is a distribution defined on x. Let T be an affine transform, i.e., T (x) = Ax + b, where A ∈ R n×n is a full rank matrix and b ∈ R n×1 . Then for a random variable y = T (x) = Ax + b, p y (y) = |J |p x T −1 (y) , where J is the Jacobian matrix, with its (i, j)-th entry defined as:</p><formula xml:id="formula_27">J i,j = ∂x i ∂y j<label>(25)</label></formula><p>Obviously, J = A −1 . Then we have p y (y) = |A −1 |p x T −1 (y) .</p><p>Let p x1 (x) and p x2 (x) are two distributions defined on x. Then let p y1 (y) and p y2 (y) be the corresponding distributions defined on y. Then we have p y1 (y) = |A −1 |p x1 T −1 (y) and</p><formula xml:id="formula_28">p y2 (y) = |A −1 |p x2 T −1 (y) .</formula><p>Using the definition of the KL divergence between p y1 and p y2 , we have:</p><formula xml:id="formula_29">KL(p y1 ||p y2 ) = p y1 (y) log p y1 (y) p y2 (y) dy (26) = |A −1 |p x1 T −1 (y) log |A −1 |p x1 (T −1 (y)) |A −1 |p x2 T −1 (y) dy (27) = |A −1 |p x1 T −1 (y) log p x1 T −1 (y) p x2 T −1 (y) dy<label>(28)</label></formula><p>As x = T −1 (y), then we have:</p><formula xml:id="formula_30">KL(p y1 ||p y2 ) = |A −1 |p x1 T −1 (y) log p x1 T −1 (y) p x2 T −1 (y) dy (29) = |A −1 |p x1 (x) log p x1 (x) p x2 (x) dy<label>(30)</label></formula><p>According to the property of multiple integral, we have:</p><formula xml:id="formula_31">KL(p y1 ||p y2 ) = |A −1 |p x1 (x) log p x1 (x) p x2 (x) |A|dx (31) = p x1 (x) log p x1 (x) p x2 (x) dx (32) = KL(p x1 ||p x2 )<label>(33)</label></formula><p>It concludes our proof.</p><p>Corollary 1 KL divergence between real and fake distributions is equal to that of rotated real and rotated fake distributions by T k :</p><formula xml:id="formula_32">KL(P T k g ||P T k d ) = KL(P g ||P d ), k ∈ [1 : K]</formula><p>Note that we apply the above theorem of invariance of KL, with p x1 , p x2 being P g , P d respectively, and image rotation T k as the transform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Implementation</head><p>Here, we discuss details of our implementation. For the SS tasks, we follow the geometric transformation of <ref type="bibr" target="#b9">[10]</ref> to argument images and compute pseudo labels. It is simple yet effective and currently the state-of-the-art in self-supervised tasks. In particular, we train discriminator to recognize the 2D rotations which were applied to the input image. We rotate the input image with K = 4 rotations (0 • , 90 • , 180 • , 270 • ) and assign them the pseudo-labels from 1 to K.</p><p>To implement our model, the GAN objectives for discriminator and generator can be the ones in original GAN by Goodfellow et al. <ref type="bibr" target="#b11">[12]</ref>, or other variants. In our work, we conduct experiments to show improvements with two baseline models: original SSGAN <ref type="bibr" target="#b3">[4]</ref> and DistGAN <ref type="bibr" target="#b41">[42]</ref>.</p><p>We integrate SS tasks into Dist-GAN <ref type="bibr" target="#b41">[42]</ref> and conduct study with this baseline. In our experiments, we observe that Dist-GAN has good convergence property and this is important for our ablation study.</p><formula xml:id="formula_33">min G V(D, C, G) = V(D, G) +λ g E x∼P T g E T k ∼T log C k (x) − E x∼P T g E T k ∼T log C K+1 (x) − E x∼P T d E T k ∼T log C k (x) − E x∼P T d E T k ∼T log C K+1 (x)<label>(34)</label></formula><p>Second, in practice, achieving equilibrium point for optimal D, G, C is difficult. Therefore, inspired by <ref type="bibr" target="#b41">[42]</ref>, we propose the new generator objective to improve Eq. 9 as written in Eq. 34. It couples the convergence of Φ + (G, C) and Ψ + (G, C) that allows the learning is more stable. Our intuition is that if generator distribution is similar to the real distribution, the classification performance on its transformed fake samples should be similar to that of those from real samples. Therefore, we propose to match the self-supervised tasks of real and fake samples to train the generator. In other words, if real and fake samples are from similar distributions, the same tasks applied for real and fake samples should have resulted in similar behaviors. In particular, given the cross-entropy loss computed on real samples, we train the generator to create samples that are able to match this loss. Here, we use 1 -norm for the Φ + (G, C) and V(D, G) is the objective of GAN task <ref type="bibr" target="#b41">[42]</ref>. In our implementation, we randomly select a geometric transformation T k for each data sample when training the discriminator. And the same T k are applied for generated samples when matching the self-supervised tasks to train the generator.</p><p>For this objective of generator, similar to Eq. 24, we have:</p><formula xml:id="formula_34">E x∼P T d K k=1 p(T k |x) log C * k (x) = E x∼P T d K k=1 p(T k |x) log C * K+1 (x) + K k=1 KL(P T k d ||P T k g ) + K k=1 E x∼P T k d log p T k d (x) K k=1 p T k d (x)<label>(35)</label></formula><p>The objective of Eq. 34 can be re-written as:</p><formula xml:id="formula_35">* = K k=1 KL(P T k d ||P T k g ) + KL(P T k g ||P T k d ) + K k=1 E x∼P T k g log p T k d (x) K k=1 p T k d (x) − K k=1 E x∼P T k d log p T k d (x) K k=1 p T k d (x) ≥ 0<label>(36)</label></formula><p>P g = P d is the solution that minimizes Eq. 36. In practice, we found that this is stable. It is due to the stability of symmetric KL divergence (forward KL and inverse KL). In our experiments, FID is computed every 10K iterations in training and visualized with the smoothening windows of 5. The latent dimension is d z = 128 and mini-batch size is 64 for our all experiments. We visualize losses and FID scores in several figures. In these figures, the horizontal axis is the number of training iterations, and the vertical axis is either the loss and FID score. We compute the negative discriminator/classifier value function for the visualization. We investigate the improvements of our proposed techniques on two baseline models:</p><p>Dist-GAN <ref type="bibr" target="#b41">[42]</ref>: We use Dist-GAN implemented with three network architectures: DCGAN, CNN in SN-GAN and ResNet. We use standard "log" loss for DCGAN architecture, and with "hinge" loss SN-GAN (the CNN network as in SN-GAN <ref type="bibr" target="#b30">[31]</ref>) and ResNet architectures. We use "hinge" loss for SN-GAN and ResNet because it attains better performance than standard "log" loss as shown in <ref type="bibr" target="#b30">[31]</ref>. We train models using Adam optimizer with learning rate lr = 0.0002, β 1 = 0.5, β 2 = 0.9 for DCGAN and SN-GAN architectures and β 1 = 0.0, β 2 = 0.9 for ResNet architecture <ref type="bibr" target="#b12">[13]</ref>. If not precisely mentioned, it means Dist-GAN is used for the experiments. SSGAN: We were unable to reproduce results as reported in the original paper with this code 2 , although we have followed the best parameter settings of the paper and communicated with authors of SSGAN regarding the issues. We achieve best results with another setting (spectral norm, λ = 0, d iter = 10, β 1 = 0.5, β 2 = 0.999). We use this setting as the baseline and compare to the one using our proposed SS tasks instead of the original SS tasks.</p><p>B.2 Ablation study SS in Discriminator and Generator Learning for the original SS proposed in <ref type="bibr" target="#b3">[4]</ref> In this experiment, we analyze original SS tasks proposed in <ref type="bibr" target="#b3">[4]</ref> to understand the effect of selfsupervised tasks. We aim to provide empirical observation of how the Ψ(C) contributes to the discriminator via changing λ d with fixed λ g = 0. Experiments are on CIFAR-10 dataset using small DCGAN architecture. For implementation, they are integrated into the discriminator of the baseline model, Dist-GAN <ref type="bibr" target="#b41">[42]</ref> as mentioned above. Through the experiment, we confirm that the contribution of Ψ(C) is important in Dist-GAN model. We should set the λ d attain the good trade-off between GAN task and SS task because increasing λ d is not helpful. The SS task with λ d = 1.0 is good for Dist-GAN model, which is also discussed in <ref type="bibr" target="#b3">[4]</ref> with SN-GAN model <ref type="bibr" target="#b30">[31]</ref>. The results in <ref type="figure" target="#fig_6">Fig. 7</ref> illustrate the effects of Ψ(C) to GAN with different values of λ d . <ref type="figure" target="#fig_6">Fig. 7a</ref> represents the losses of the SS task of the discriminator. It shows that in most cases, the larger λ d lead to faster Ψ(C) loss converges. However, when λ d &gt; 1.0, the FID is not improved. We observe that once λ d is higher, the loss of GAN task is dominated by the SS tasks. When λ d is too high, (e.g., λ d = 7.0), GAN loss is almost unchanged about first 10K iterations <ref type="figure" target="#fig_6">(Fig. 7b)</ref> in early iterations and the model gets collapsed. This can be explained as follows. When the discriminator improvement is slow due to the strong dominance of Ψ(C), the learning of the generator faster. This serious unbalance easily leads to the collapsed generator and the learning of generator gets stuck thereafter. When the GAN loss is strongly dominated by SS loss, the loss of GAN is saturated.</p><p>To understand deeper, we evaluate the representation qualities of the intermediate layers of the discriminator as in <ref type="bibr" target="#b3">[4]</ref> in this experiment. Given the above pre-trained discriminators, we compute features of train and test sets of CIFAR-10 via its last convolution layer. We evaluate the classification performance as training logistic regression on these features and measure with top-1 accuracy. We follow the experimental setup of parameters as in <ref type="bibr" target="#b3">[4]</ref>. The result <ref type="figure" target="#fig_6">(Fig. 7c</ref>) that as λ d &gt;= 1.0, the accuracy is also similar, except for the case λ = 7.0, the quality of feature is slightly worse but not too significant (although the GAN model is collapsed). It means increasing λ d does not necessarily improve the feature representation quality of the discriminator.</p><p>Overall, with Dist-GAN as baseline, we observe that using the original SS tasks with λ d = 1.0 provide considerable improvement, and the results suggest that λ d should not be too high, but instead the one that provides a good trade-off between GAN and SS tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.1 SS task in Generator Learning</head><p>We continue to investigate the effects of λ g with fixed λ d = 1.0 for the SS tasks proposed in <ref type="bibr" target="#b3">[4]</ref>. The experimental setup is similar to the previous one. The result represented in <ref type="figure">Fig. 8a</ref> show that λ g &gt; 0 still improves the baseline model, but higher than the case of λ g = 0. Note that <ref type="bibr" target="#b3">[4]</ref> does not report result with λ g = 0.0.</p><p>Following our discussion on Theorem 1, applying Φ(G, C) as proposed in <ref type="bibr" target="#b3">[4]</ref> does not support the matching between the generator and data distributions. From these experiments, we observe that the generator and discriminator are unable to reach optimal points, and using large λ g degrades the quality of GAN task, and even leads to mode collapse. For example, as λ g increases (eg. λ g = 0.3), it seriously hurts the quality of GAN task of the generator.</p><p>In addition, we verify with original code of SSGAN <ref type="bibr" target="#b3">[4]</ref> on CIFAR-10 using our best setting mentioned above. <ref type="figure">Fig. 8a</ref> confirms that with our best setting λ g = 0.01 and λ g = 0.2 achieve similar FID and increasing λ g = 0.5 degrades its performance, which is consistent to our analysis. In the same figure, when we use our proposed MS, FID is improved.</p><p>B.3 Ablation study (λ d , λ g ) with DCGAN for our proposed method</p><p>We first change the λ g according λ d = 1.0 <ref type="figure">(Fig. 9a</ref>). With minimax game, the result suggests that λ g = 0.1 is the best for DCGAN architecture. Then, we seek λ d with this λ g = 0.1 as shown in <ref type="figure">Fig.  9b</ref>. Interestingly, now the best λ d = 4.0, which is higher than λ d = 1.0 of the original SS (the best with the original SS; <ref type="figure" target="#fig_6">Fig. 7d</ref>). This suggests that using our proposed mini-max game based SS enable larger range of λ d with stable performance. Our DCGAN architecture, which is used for ablation studies on CIFAR-10, are presented in <ref type="table">Table.</ref> 4. <ref type="table">Table 4</ref>: Our DCGAN architecture is similar to <ref type="bibr" target="#b36">[37]</ref> but the smaller number of feature maps (D = 64) to be more efficient for our ablation study on CIFAR-10. The Encoder is the mirror of the Generator. Slopes of lReLU functions are set to 0.2. U(0, 1) is the uniform distribution. Two heads for the real/fake discriminator and multi-class classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 SNGAN architecture</head><p>Our SN-GAN architecture referred as CNN architectures of <ref type="bibr" target="#b30">[31]</ref> for CIFAR-10 and STL-10 datasets are presented in <ref type="table">Table.</ref> 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 ResNet architecture</head><p>Our ResNet architectures for CIFAR-10 and STL-10 are presented in <ref type="table">Table. 6 and Table.</ref> 7. <ref type="table">Table 5</ref>: Encoder, generator, and discriminator of standard CNN architectures for CIFAR-10 and STL-10 used in our experiments. We use similar architectures as ones in <ref type="bibr" target="#b30">[31]</ref>. The Encoder is the mirror of the Generator. Slopes of lReLU functions are set to 0.1. U(0, 1) is the uniform distribution. <ref type="bibr">RGB</ref>  3×3, stride=1 conv 64 lReLU 4×4, stride=2 conv 64 lReLU 3×3, stride=1 conv 128 lReLU 4×4, stride=2 conv 128 lReLU 3×3, stride=1 conv 256 lReLU 4×4, stride=2 conv 256 lReLU 3×3, stride=1 conv. 512 lReLU dense → 1, dense → 5 (two heads) (c) Discriminator, M = 32 for CIFAR-10, and M = 48 for STL-10. Two heads for the real/fake discriminator and multi-class classifier. <ref type="table">Table 6</ref>: ResNet architecture for CIFAR10 dataset. The Encoder is the mirror of the Generator. We use similar architectures and ResBlock to the ones used in <ref type="bibr" target="#b30">[31]</ref>. U(0, 1) is the uniform distribution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>( d = 1.0) Baseline + MS ( d = 1.0, d = 0.01) Compare SS (original SS tasks proposed in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>The means and standard deviations of MS and SS are computed from eight runs (we re-train our GAN model from the scratch for each run). The results are reported with best (λ d , λ g ) of MS: (0.5, 0.2) for K/4 architecture and (1.0, 1.0) for K/2 architecture. Similarly, best (λ d , λ g ) of SS: (0.5, 0.0) for K/4 architecture and (1.0, 0.0) for K/2 architecture.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>K k=1 C * k (x) = 1 ,</head><label>1</label><figDesc>according to Bayes' theorem p T d (x) * p(T k |x) = p(T k ) * p T k d (x), and p(T i ) = p(T j ) = 1 K , i, j ∈ [1, K](the probability we apply the transformations T k for sample x are equal), We finally obtain the optimal C * k (x) from Eq. 14: C * k (x) = p(T k |x)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>From left to right: Real samples, argument real samples by rotation, mixed argument real and fake samples, and generated images of CIFAR-10. B Appendix: Experiments B.1 Details of experiment setup</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 :</head><label>6</label><figDesc>From left to right: Real samples, argument real samples by rotation, mixed argument real and fake samples, and generated images of STL-10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 7 :</head><label>7</label><figDesc>( d = 1.0) Baseline + SS ( d = 2.0) Baseline + SS ( d = 3.0) Baseline + SS ( d = 5.0) Baseline + SS ( d = 7.0) The ablation study of SS task Ψ(C) as proposed in [4]. We analyze its effect via λ d fine-tuning, λ g = 0.0. (a) The discriminator losses of SS task, (b) The discriminator losses of GAN task, (c) the feature representation quality and (d) FID scores. With λ d = 7.0 for SS task, the model becomes seriously collapsed with FID &gt; 100. Experiments are conducted with the baseline model, Dist-GAN. (Best view in color).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 8 :Figure 9 :</head><label>89</label><figDesc>The ablation studies with (a) SSGAN + using λ g and ours (SSGAN + + MS) (b) Dist-GAN with Φ(C) and Ψ(G, C) as fine-tuning λ g , fixed λ d = 1.0. (c) Our model (Dist-GAN + MS) with Ψ + (G, C) and Φ + (G, C) with λ g = 0.1 and λ d = 1.0. Experiments are with CIFAR-10 dataset. (Best view in color) ( d = 1.0, g = 0.00) Baseline + MS ( d = 1.0, g = 0.01) Baseline + MS ( d = 1.0, g = 0.05) Baseline + MS ( d = 1.0, g = 0.10) Baseline + MS ( d = 1.0, g = 0.20) ( d = 1.0, g = 0.1) Baseline + MS ( d = 2.0, g = 0.1) Baseline + MS ( d = 3.0, g = 0.1) Baseline + MS ( d = 4.0, g = 0.1) Baseline + MS ( d = 5.0, g = 0.1) Our model (Dist-GAN + MS) with (a) with fine-tuning λ g , fixed λ d = 1.0. (b) fine-tuning λ d , fixed λ g = 0.1. The baseline is Dist-GAN model, and we use DCGAN architecture. (Best view in color)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 10 :</head><label>10</label><figDesc>Understanding the effects of MS tasks (our proposed self-supervised tasks), by fine-tuning λ g (first row) λ d (second row) for CIFAR-10 and STL-10 with other architectures. From left to right: SN-GAN for CIFAR-10, ResNet for CIFAR-10, SN-GAN for STL-10 and ResNet for STL-10. SN-GAN architecture referred as CNN architectures used in SN-GAN<ref type="bibr" target="#b30">[31]</ref>.B.4 Ablation study of our proposed method with SN-GAN and ResNet architecturesThe detail of the ablation study of λ d and λ g for our proposed SS tasks using SN-GAN and ResNet architectures are shown inFig. 10.C Appendix: Network architectures C.1 DCGAN architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>RGB image x ∈ R M ×M ×3 5×5, stride=2 conv. 1 × D ReLU 5×5, stride=2 conv. BN 2 × D ReLU 5×5, stride=2 conv. BN 4 × D ReLU 5×5, stride=2 conv. BN 8 × D ReLU dense → 128 (a) Encoder, M = 32 for CIFAR-10 z ∈ R 128 ∼ U (0, 1) dense → 2 × 2 × 8 × D 5×5, stride=2 deconv. BN 4 × D ReLU 5×5, stride=2 deconv. BN 2 × D ReLU 5×5, stride=2 deconv. BN 1 × D ReLU5×5, stride=2 deconv. 3 Sigmoid (b) Generator for CIFAR-10 RGB image x ∈ R M ×M ×3 5×5, stride=2 conv. 1 × D lReLU 5×5, stride=2 conv. BN 2 × D lReLU 5×5, stride=2 conv. BN 4 × D lReLU 5×5, stride=2 conv. BN 8 × D lReLU dense → 1, dense → 5 (two heads) (c) Discriminator, M = 32 for CIFAR-10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>± .29 27.98 ± .38 12.37 Ours(Dist-GAN + MS) 18.88 27.95 13.90 ± .22 27.10 ± .34 11.40</figDesc><table><row><cell>GAN-GP [31]</cell><cell>37.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>WGAN-GP [31]</cell><cell>40.2</cell><cell>55.1</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SN-GAN [31]</cell><cell>25.5</cell><cell>43.2</cell><cell cols="3">21.70 ± .21 40.10 ± .50 19.73</cell></row><row><cell>SS-GAN [4]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>15.65</cell></row><row><cell>Dist-GAN [42]</cell><cell>22.95</cell><cell>36.19</cell><cell cols="3">17.61 ± .30 28.50 ± .49 13.01</cell></row><row><cell>GN-GAN [43]</cell><cell>21.70</cell><cell>30.80</cell><cell cols="2">16.47 ± .28 -</cell><cell>-</cell></row><row><cell>SAGAN [49] (cond.)</cell><cell>-</cell><cell>-</cell><cell>13.4 (best)</cell><cell>-</cell><cell>-</cell></row><row><cell>BigGAN [2] (cond.)</cell><cell>-</cell><cell>-</cell><cell>14.73</cell><cell>-</cell><cell>-</cell></row><row><cell>SSGAN +</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>20.47</cell></row><row><cell>Ours(SSGAN + + MS)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>19.89</cell></row><row><cell>Dist-GAN + SS</cell><cell>21.40</cell><cell>29.79</cell><cell>14.97</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Results on CIFAR-100 and ImageNet 32×32. We use baseline model Dist-GAN with ResNet architecture. We follow the same experiment setup as above. SS: proposed in<ref type="bibr" target="#b3">[4]</ref>; MS: this work.</figDesc><table><row><cell>Datasets</cell><cell>SS</cell><cell>MS</cell></row><row><cell>CIFAR-100 (10K-5K FID)</cell><cell cols="2">21.02 19.74</cell></row><row><cell>ImageNet 32×32 (10K-10K FID)</cell><cell>17.1</cell><cell>12.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Baseline model: Dist-GAN. SS: proposed in<ref type="bibr" target="#b3">[4]</ref>; MS: this work. Our method MS achieves the best results for this dataset with both architectures, outperforming state-of-the-art<ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b16">17]</ref> by a significant margin.</figDesc><table><row><cell>Arch</cell><cell>Unrolled GAN [30]</cell><cell>WGAN-GP [13]</cell><cell>Dist-GAN [42]</cell><cell>Pro-GAN [17]</cell><cell>[42]+SS</cell><cell>Ours([42]+MS)</cell></row><row><cell>K/4, #</cell><cell>372.2 ± 20.7</cell><cell>640.1 ± 136.3</cell><cell>859.5 ± 68.7</cell><cell>859.5 ± 36.2</cell><cell>906.75 ± 26.15</cell><cell>926.75 ± 32.65</cell></row><row><cell>K/4, KL</cell><cell>4.66 ± 0.46</cell><cell>1.97 ± 0.70</cell><cell>1.04 ± 0.29</cell><cell>1.05 ± 0.09</cell><cell>0.90 ± 0.13</cell><cell>0.78 ± 0.13</cell></row><row><cell>K/2, #</cell><cell>817.4 ± 39.9</cell><cell>772.4 ± 146.5</cell><cell>917.9 ± 69.6</cell><cell>919.8 ± 35.1</cell><cell>957.50 ± 31.23</cell><cell>976.00 ± 10.04</cell></row><row><cell>K/2, KL</cell><cell>1.43 ± 0.12</cell><cell>1.35 ± 0.55</cell><cell>1.06 ± 0.23</cell><cell>0.82 ± 0.13</cell><cell>0.61 ± 0.15</cell><cell>0.52 ± 0.07</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>image x ∈ R M ×M ×3 3×3, stride=1 conv. 64 4×4, stride=2 conv. BN 128 ReLU 4×4, stride=2 conv. BN 256 ReLU 4×4, stride=2 conv. BN 512 ReLU dense → 128 (a) Encoder, M = 32 for CIFAR-10, and M = 48 for STL-10 z ∈ R 128 ∼ U (0, 1) dense → Mg × Mg × 512 4×4, stride=2 deconv. BN 256 ReLU 4×4, stride=2 deconv. BN 128 ReLU 4×4, stride=2 deconv. BN 64 ReLU 3×3, stride=1 conv. 3 Sigmoid (b) Generator, Mg = 4 for CIFAR-10, and Mg = 6 for STL-10 RGB image x ∈ R M ×M ×3</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/google/compare_gan</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://github.com/google/compare_gan</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by ST Electronics and the National Research Foundation(NRF), Prime Minister's Office, Singapore under Corporate Laboratory @ University Scheme (Programme Title: STEE Infosec -SUTD Corporate Laboratory). This research was also supported by the National Research Foundation Singapore under its AI Singapore Programme [Award Number: AISG-100E-2018-005]. This research was also supported in part by the Energy Market Authority (EP award no. NRF2017EWT-EP003-061). This project was also supported by SUTD project PIE-SGP-AI-2018-01.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>(c) Discriminator. Two heads for the real/fake discriminator and multiclass classifier. <ref type="table">Table 7</ref>: ResNet architecture for STL-10 dataset. The Encoder is the mirror of the Generator. We use similar architectures and ResBlock to the ones used in <ref type="bibr" target="#b30">[31]</ref>. U(0, 1) is the uniform distribution. (c) Discriminator. Two heads for the real/fake discriminator and multiclass classifier.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.04862</idno>
		<title level="m">Towards principled methods for training generative adversarial networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.11096</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Mode regularized generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanran</forename><surname>Tong Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Self-supervised gans via auxiliary rotation loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marvin</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2172" to="2180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09782</idno>
		<title level="m">Adversarial feature learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishmael</forename><surname>Vincent Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Mastropietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00704</idno>
		<title level="m">Adversarially learned inference</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-agent diverse generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viveka</forename><surname>Kulharia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vinay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Namboodiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Puneet K</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dokania</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.00160</idno>
		<title level="m">Nips 2016 tutorial: Generative adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5767" to="5777" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hubert</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Mgan: Training generative adversarial nets with multiple generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung</forename><surname>Tu Dinh Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Phung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Image-to-image translation with conditional adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tinghui</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaakko</forename><surname>Lehtinen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.10196</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Overcoming catastrophic forgetting in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Veness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Desjardins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kieran</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiago</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Grabska-Barwinska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Kodali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Abernethy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07215</idno>
		<title level="m">On convergence and stability of gans</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Autoencoding beyond pixels using a learned similarity metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Boesen Lindbo Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Søren</forename><forename type="middle">Kaae</forename><surname>Sønderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ole</forename><surname>Winther</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.09300</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Photo-realistic single image superresolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ferenc</forename><surname>Huszár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Infomax-gan: Mutual information maximization for improved adversarial image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Trung</forename><surname>Kwot Sin Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS 2019 Workshop on Information Theory and Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Mmd gan: Towards deeper understanding of moment matching network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Cheng</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnabás</forename><surname>Póczos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Doping: Generative data augmentation for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swee Kiat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Trung</forename><surname>Loo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuval</forename><surname>Roig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Elovici</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of IEEE International Conference on Data Mining (ICDM)</title>
		<meeting>eeding of IEEE International Conference on Data Mining (ICDM)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Varying k-lipschitz constraint for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kanglin</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.06107</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Rob-gan: Generator, discriminator and adversarial attacker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuanqing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cho-Jui</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Adversarial autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeru</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshiki</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masanori</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuichi</forename><surname>Yoshida</surname></persName>
		</author>
		<title level="m">Spectral normalization for generative adversarial networks. ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dual discriminator generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tu</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trung</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinh</forename><surname>Phung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Representation learning by learning to count</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Conditional image synthesis with auxiliary classifier GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Olah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asja</forename><surname>Henning Petzka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lukovnicov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.08894</idno>
		<title level="m">On the regularization of wasserstein gans</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeynep</forename><surname>Akata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchen</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lajanugen</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.05396</idno>
		<title level="m">Generative adversarial text to image synthesis</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Stabilizing training of generative adversarial networks through regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Lucchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Unsupervised anomaly detection with generative adversarial networks to guide marker discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Seeböck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><forename type="middle">M</forename><surname>Waldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ursula</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Langs</surname></persName>
		</author>
		<idno>abs/1703.05921</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dist-gan: An improved gan using distance constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Trung</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Anh</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Improving gan with neighbors embedding and gradient matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Trung</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuan-Anh</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Cheung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">An improved selfsupervised gan via adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Trung</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viet-Hung</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc-Bao</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Cheung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05469</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">On the effects of batch and weight normalization in generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sitao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03971</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep clustering by gaussian mixture variational autoencoders with graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linxiao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngai-Man</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaying</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasin</forename><surname>Yazıcı</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan-Sheng</forename><surname>Foo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Winkler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim-Hui</forename><surname>Yap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Piliouras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.04498</idno>
		<title level="m">The unusual effectiveness of averaging in gan training</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Friedemann</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.04200</idno>
		<title level="m">Continual learning through synaptic intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08318</idno>
		<title level="m">Dimitris Metaxas, and Augustus Odena. Self-attention generative adversarial networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Split-brain autoencoders: Unsupervised learning by cross-channel prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Unpaired image-to-image translation using cycle-consistent adversarial networkss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesung</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
