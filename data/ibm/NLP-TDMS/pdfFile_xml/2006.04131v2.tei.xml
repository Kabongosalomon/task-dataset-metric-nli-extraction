<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Graph Contrastive Representation Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
							<email>yanqiao.zhu@cripac.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Research on Intelligent Perception and Computing Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Xu</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Research on Intelligent Perception and Computing Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Liu</surname></persName>
							<email>qiang.liu@realai.ai</email>
							<affiliation key="aff3">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Wu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Research on Intelligent Perception and Computing Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
							<email>wangliang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Research on Intelligent Perception and Computing Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Artificial Intelligence</orgName>
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Deep Graph Contrastive Representation Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Graph representation learning nowadays becomes fundamental in analyzing graphstructured data. Inspired by recent success of contrastive methods, in this paper, we propose a novel framework for unsupervised graph representation learning by leveraging a contrastive objective at the node level. Specifically, we generate two graph views by corruption and learn node representations by maximizing the agreement of node representations in these two views. To provide diverse node contexts for the contrastive objective, we propose a hybrid scheme for generating graph views on both structure and attribute levels. Besides, we provide theoretical justification behind our motivation from two perspectives, mutual information and the classical triplet loss. We perform empirical experiments on both transductive and inductive learning tasks using a variety of real-world datasets. Experimental experiments demonstrate that despite its simplicity, our proposed method consistently outperforms existing state-of-the-art methods by large margins. Moreover, our unsupervised method even surpasses its supervised counterparts on transductive tasks, demonstrating its great potential in real-world applications.</p><p>Recently, graph representation learning using Graph Neural Networks (GNN) has received considerable attention. Along with its prosperous development, however, there is an increasing concern over the label availability when training the model. Nevertheless, existing GNN models are mostly established in a supervised manner <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref>, which require abundant labeled nodes for training. Albeit with some attempts connecting previous unsupervised objectives (i.e., matrix reconstruction) to GNN models [9, 10], these methods still heavily rely on the preset graph proximity matrix. * The first two authors contributed equally to this work. † This work is done during his internship at CRIPAC, CASIA. Preprint. Under review. arXiv:2006.04131v2 [cs.LG] 13 Jul 2020 Algorithm 1: GRACE training algorithm 1 for epoch ← 1, 2, · · · do 2 Generate two graph views G 1 and G 2 by performing corruption on G 3 Obtain node embeddings U of G 1 using the encoder f 4 Obtain node embeddings V of G 2 using the encoder f 5 Compute the contrastive objective J with Eq. (2) 6</p><p>Update parameters by applying stochastic gradient ascent to maximize J</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the past few years, graph representation learning has emerged as a powerful strategy for analyzing graph-structured data. Graph representation learning aims to learn an encoding function that transforms nodes to low-dimensional dense embeddings that preserve graph attributive and structural features. Traditional unsupervised graph representation learning approaches, such as DeepWalk <ref type="bibr" target="#b0">[1]</ref> and node2vec <ref type="bibr" target="#b1">[2]</ref>, follow a contrastive framework originated in the skip-gram model <ref type="bibr" target="#b2">[3]</ref>. Specifically, they first sample short random walks and then enforce neighboring nodes on the same walk to share similar embeddings by contrasting them with other nodes. However, DeepWalkbased methods can be seen as reconstructing the graph proximity matrix, such as high-order adjacent matrix <ref type="bibr" target="#b3">[4]</ref>, which excessively emphasize proximity information defined on the network structure <ref type="bibr" target="#b4">[5]</ref>.  Instead of optimizing the reconstruction objective, visual representation learning leads to revitalization of the classical information maximization (InfoMax) principle <ref type="bibr" target="#b10">[11]</ref>. A series of contrastive learning methods have been proposed so far <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref>, which seek to maximize the Mutual Information (MI) between the input (i.e., images) and its representations (i.e., image embeddings) by contrasting positive pairs with negative-sampled counterparts. Inspired by previous success of the Deep InfoMax (DIM) method <ref type="bibr" target="#b14">[15]</ref> in visual representation learning, Deep Graph InfoMax (DGI) <ref type="bibr" target="#b17">[18]</ref> proposes an alternative objective based on MI maximization in the graph domain. DGI firstly employs GNN to learn node embeddings and obtains a global summary embedding (i.e., the graph embedding), via a readout function. The objective used in DGI is then to maximize the MI between node embeddings and the graph embedding by discriminating nodes in the original graph from nodes in a corrupted graph.</p><p>However, we argue that the local-global MI maximization framework in DGI is still in its infancy. Its objective is proved to be equivalent to maximizing the MI between input node features and high-level node embeddings under some conditions. Specifically, to implement the InfoMax objective, DGI requires an injective readout function to produce the global graph embedding, where the injective property is too restrictive to fulfill. For the mean-pooling readout function employed in DGI, it is not guaranteed that the graph embedding can distill useful information from nodes, as it is insufficient to preserve distinctive features from node-level embeddings. Moreover, DGI proposes to use feature shuffling to generate corrupted views of graphs. Nevertheless, this scheme considers corrupting node features at a coarse-grained level when generating negative node samples. When the feature matrix is sparse, performing feature shuffling only is insufficient to generate different neighborhoods (i.e., contexts) for nodes in the corrupted graph, leading to difficulty in learning of the contrastive objective.</p><p>In this paper, we introduce a simple yet powerful contrastive framework for unsupervised graph representation learning <ref type="figure" target="#fig_1">(Figure 1</ref>), which we refer to as deep GRAph Contrastive rEpresentation learning (GRACE) <ref type="bibr" target="#b2">3</ref> , motivated by a traditional self-organizing network <ref type="bibr" target="#b18">[19]</ref> and its recent renaissance in visual representation learning <ref type="bibr" target="#b16">[17]</ref>. Rather than contrasting node-level embeddings to global ones, we primarily focus on contrasting embeddings at the node level and our work makes no assumptions on injective readout functions for generating the graph embedding. In GRACE, we first generate two correlated graph views by randomly performing corruption. Then, we train the model using a contrastive loss to maximize the agreement between node embeddings in these two views. Unlike visual data, where abundant image transformation techniques are available, how to perform corruption to generate views for graphs is still an open problem. In our work, we jointly consider corruption at both topology and node attribute levels, namely removing edges and masking features, to provide diverse contexts for nodes in different views, so as to boost optimization of the contrastive objective. Last, we provide theoretical analysis that reveals the connections from our contrastive objective to mutual information and the classical triplet loss.</p><p>Our contribution is summarized as follows. Firstly, we propose a general contrastive framework for unsupervised graph representation learning. The proposed GRACE framework simplifies previous work and works by maximizing the agreement of node embeddings between two graph views. Secondly, we propose two specific schemes, removing edges and masking features, to generate views of graphs. Finally, we conduct comprehensive empirical studies using six popular public benchmark datasets on both transductive and inductive node classification under the commonly-used linear evaluation protocol. GRACE consistently outperforms existing methods and our unsupervised method even surpasses its supervised counterparts on transductive tasks, demonstrating its great potential in real-world applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Contrastive learning of visual representations. Being popular in self-supervised visual representation learning, contrastive methods aim to learn discriminative representations by contrasting positive and negative samples. For visual data, negative samples can be generated using image augmentation techniques such as cropping, rotation <ref type="bibr" target="#b19">[20]</ref>, color distortion <ref type="bibr" target="#b20">[21]</ref>, etc. Existing work <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref> employs a memory bank for storing negative samples. Other work <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref> explores in-batch negative samples. For an image patch as the anchor, these methods usually find a global summary vector <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b14">15]</ref> or patches in neighboring views <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref> as the positive sample, and contrast them with negative-sampled counterparts, such as patches of other images within the same batch <ref type="bibr" target="#b21">[22]</ref>.</p><p>Theoretical analysis sheds light on the reasons behind their success <ref type="bibr" target="#b24">[25]</ref>. Objectives used in these methods can be seen as maximizing the lower bounds of MI between input features and their representations <ref type="bibr" target="#b10">[11]</ref>. However, recent work <ref type="bibr" target="#b25">[26]</ref> reveals that downstream performance in evaluating the quality of representations may strongly depend on the bias that is encoded not only in the convolutional architectures but also in the specific estimator of the InfoMax objective.</p><p>Graph representation learning. Many traditional methods on unsupervised graph representation learning employ the contrastive paradigm as well <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b26">27]</ref>. Prior work on unsupervised graph representation learning focuses on local contrastive patterns, which forces neighboring nodes to have similar embeddings. Positive samples under this circumstance are nodes appearing in the same random walk <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. For example, the pioneering work DeepWalk <ref type="bibr" target="#b0">[1]</ref> models probabilities of node co-occurrence pairs using noise-contrastive estimation <ref type="bibr" target="#b27">[28]</ref>. These random-walk-based methods are proved to be equivalent to factorizing some forms of graph proximity (e.g., transformation of the adjacent matrix) <ref type="bibr" target="#b3">[4]</ref>, which overly emphasize on the structural information encoded in these graph proximities and also face severe scaling problem with large-scale datasets. Also, these methods are known to be error-prone with inappropriate hyperparameter tuning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>.</p><p>Recent work on graph neural networks (GNN) employs more powerful graph convolutional encoders over conventional methods. Among them, considerable literature has grown up around the theme of supervised GNN <ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b28">29]</ref>, which requires labeled datasets that may not be accessible in realworld applications. Along the other line of development, unsupervised GNNs receive little attention. Representative methods include GraphSAGE <ref type="bibr" target="#b9">[10]</ref>, which incorporates DeepWalk-like objectives as well. Recent work DGI <ref type="bibr" target="#b17">[18]</ref> marries the power of GNN and contrastive learning, which focuses on maximizing MI between global graph embeddings and local node embeddings. However, it is hard to fulfill the injective requirement of the graph readout function such that the graph embedding may be deteriorated. In contrast to DGI, our work does not rely on an explicit graph embedding. Instead, we focus on maximizing the agreement of node embeddings across two corrupted views of the graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Deep Graph Contrastive Representation Learning</head><p>In this section, we present our proposed GRACE framework in detail, starting with the overall framework of contrastive objectives, followed by specific graph view generation methods. At the end of this section, we provide theoretical justification behind our framework from two perspectives, i.e., connection to the InfoMax principle and the classical triplet loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminaries</head><p>In unsupervised graph representation learning, let G = (V, E) denote a graph, where V = {v 1 , v 2 , · · · , v N }, E ⊆ V × V represent the node set and the edge set respectively. We denote the feature matrix and the adjacency matrix as X ∈ R N ×F and A ∈ {0,</p><formula xml:id="formula_0">1} N ×N , where x i ∈ R F is the feature of v i , and A ij = 1 iff (v i , v j ) ∈ E.</formula><p>There is no given class information of nodes in G during training. Our objective is to learn a GNN encoder f (X, A) ∈ R N ×F receiving the graph features and structure as input, that produces node embeddings in low dimensionality, i.e., F F .</p><p>We denote H = f (X, A) as the learned representations of nodes, where h i is the embedding of node v i . These representations can be used in downstream tasks, such as node classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Contrastive Learning of Node Representations</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">The Contrastive Learning Framework</head><p>Contrary to previous work that learns representations by utilizing local-global relationships, in GRACE, we learn embeddings by directly maximizing node-level agreement between embeddings.</p><p>To be specific, we first generate two graph views by randomly corrupting the original graph. Then, we employ a contrastive objective that enforces the encoded embeddings of each node in the two different views agree with each other and can be distinguished from embeddings of other nodes.</p><p>In our GRACE model, at each iteration, we generate two graph views, denoted as G 1 and G 2 , and denote node embeddings in the two generated views as</p><formula xml:id="formula_1">U = f ( X 1 , A 1 ) and V = f ( X 2 , A 2 ),</formula><p>where X * and A * are the feature matrices and adjacent matrices of the views. Details on the generation of graph views will be discussed later in Section 3.2.2.</p><p>Then, we employ a contrastive objective (i.e., a discriminator) that distinguishes the embeddings of the same node in these two different views from other node embeddings. For any node v i , its embedding generated in one view, u i , is treated as the anchor, the embedding of it generated in the other view, v i , forms the positive sample, and embeddings of nodes other than v i in the two views are naturally regarded as negative samples. Formally, we define the critic θ(u, v) = s(g(u), g(v)), where s is the cosine similarity and g is a non-linear projection to enhance the expression power of the critic <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b25">26]</ref>. The projection g is implemented with a two-layer multilayer perceptron (MLP). We define the pairwise objective for each positive pair (u i , v i ) as </p><formula xml:id="formula_2">(u i , v i ) = log e θ(</formula><p>where 1 [k =i] ∈ {0, 1} is an indication function that equals to 1 iff k = i, and τ is a temperature parameter. Please note that, in our work, we do not sample negative nodes explicitly. Instead, given a positive pair, we naturally define negative samples as all other nodes in the two views. Therefore, negative samples come from two sources, inter-view or intra-view nodes, corresponding to the second and the third term in the denominator, respectively. Since two views are symmetric, the loss for another view is defined similarly for (v i , u i ). The overall objective to be maximized is then defined as the average over all positive pairs, formally given by</p><formula xml:id="formula_4">J = 1 2N N i=1 [ (u i , v i ) + (v i , u i )] .<label>(2)</label></formula><p>To sum up, at each training epoch, GRACE first generates two graph views G 1 and G 2 of graph G. Then, we obtain node representations U and V of G 1 and G 2 using a GNN encoder f . Finally, the parameters of f and g is updated by maximizing the objective in Eq. (2). The learning algorithm is summarized in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Graph View Generation</head><p>Generating views is a key component of contrastive learning methods. In the graph domain, different views of a graph provide different contexts for each node. Considering contrastive approaches that rely on contrasting between node embeddings in different views, we propose to corrupt the original graph at both structure and attribute levels, which constructs diverse node contexts for the model to contrast with. In GRACE, we design two methods for graph corruption, removing edges for topology and masking features for node attributes. How to perform graph corruption is still an open problem <ref type="bibr" target="#b17">[18]</ref>. It is flexible to adopt other alternative mechanisms of corruption methods in our framework.</p><p>Removing edges (RE). We randomly remove a portion of edges in the original graph. Formally, since we only remove existing edges, we first sample a random masking matrix R ∈ {0, 1} N ×N , whose entry is drawn from a Bernoulli distribution R ij ∼ B(1 − p r ) if A ij = 1 for the original graph and R ij = 0 otherwise. Here p r is the probability of each edge being removed. The resulting adjacency matrix can be computed as</p><formula xml:id="formula_5">A = A • R, (3) where (x • y) i = x i y i is Hadamard product.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Masking node features (MF).</head><p>Apart from removing edges, we randomly mask a fraction of dimensions with zeros in node features. Formally, we first sample a random vector m ∈ {0, 1} F where each dimension of it independently is drawn from a Bernoulli distribution with probability 1 − p m , i.e., m i ∼ B(1 − p m ), ∀i. Then, the generated node features X is computed by</p><formula xml:id="formula_6">X = [x 1 • m; x 2 • m; · · · ; x N • m] .<label>(4)</label></formula><p>Here [·; ·] is the concatenation operator.</p><p>Please kindly note that although our proposed RE and MF schemes are technically similar to Dropout <ref type="bibr" target="#b29">[30]</ref> and DropEdge <ref type="bibr" target="#b30">[31]</ref>, our GRACE model and the two referred methods are proposed for fundamentally different purposes. Dropout is a general technique that randomly masks neurons during training to prevent over-fitting of large-scale models. In the graph domain, DropEdge is proposed to prevent over-fitting and alleviate over-smoothing when the GNN architecture is too deep. However, our GRACE framework randomly applies RE and MF to produce different graph views for contrastive learning at both graph topology and node feature levels. Moreover, the employed GNN encoder in GRACE is a rather shallow model, usually consisting of only two or three layers.</p><p>In our implementation, we jointly leverage these two methods to generate graph views. The generation of G 1 and G 2 are controlled by two hyperparameters p r and p m . To provide different contexts in the two views, the generation process of the two views uses two different sets of hyperparameters p r,1 , p m,1 and p r,2 , p m,2 . Experiments demonstrate that our model is not sensitive to the choice of p r and p m under mild conditions such that the original graph is not overly corrupted, e.g., p r ≤ 0.8 and p m ≤ 0.8. We refer readers to the sensitivity analysis presented in Appendix C.1 for empirical results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Theoretical Justification</head><p>In this section, we provide theoretical justification behind our model from two perspectives, i.e., the mutual information maximization and the triplet loss. Detailed proofs can be found in Appendix D.</p><p>Connections to the mutual information. Firstly, we reveal the connection between our loss and mutual information maximization between node features and the embeddings in the two views, which has been widely applied in the representation learning literature <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref>. MI quantifies the amount of information obtained about one random variable by observing the other random variable. Theorem 1. Let X i = {x k } k∈N (i) be the neighborhood of node v i that collectively maps to its output embedding, where N (i) denotes the set of neighbors of node v i specified by GNN architectures, and X be the corresponding random variable with a uniform distribution p(X i ) = 1 N . Given two random variables U, V ∈ R F being the embedding in the two views, with their joint distribution denoted as p(U, V), our objective J is a lower bound of MI between encoder input X and node representations in two graph views U, V. Formally,</p><formula xml:id="formula_7">J ≤ I(X; U, V).<label>(5)</label></formula><p>Proof sketch. We first observe that our objective J is a lower bound of the InfoNCE objective <ref type="bibr" target="#b22">[23]</ref>, which is defined as <ref type="bibr" target="#b24">[25]</ref>. According to <ref type="bibr" target="#b22">[23]</ref>, the InfoNCE estimator is a lower bound of the true MI. Therefore, the theorem directly follows from the application of data processing inequality, which states that I(U; V) ≤ I(X; U, V).</p><formula xml:id="formula_8">I NCE (U; V) E i p(ui,vi) 1 N N i=1 log e θ(u i ,v i ) 1 N N j=1 e θ(u i ,v j )</formula><p>Remark. From Theorem 1, it reveals that maximizing J is equivalent to maximizing a lower bound of the mutual information I(X; U, V) between input node features and learned node representations. Counterintuitively, recent work further provides empirical evidence that optimizing a stricter bound of MI may not lead to better downstream performance on visual representation learning <ref type="bibr" target="#b25">[26]</ref>, which highlights the importance of the encoder design. In Appendix C.3, we also compare our objective with the InfoNCE loss, which is a stricter estimator of MI, to further demonstrate the superiority of the GRACE model.</p><p>Connections to the triplet loss. Alternatively, we may view the optimization problem in Eq. (2) as a classical triplet loss, commonly used in deep metric learning. Theorem 2. When the projection function g is the identity function and we measure embedding similarity by simply taking inner product, i.e., s(u, v) = u v, and further assuming that positive pairs are far more aligned than negative pairs, minimizing the pairwise objective (u i , v i ) coincides with maximizing the triplet loss, as given in the sequel</p><formula xml:id="formula_9">− (u i , v i ) ∝ 4N τ + N j=1 1 [j =i] u i − v i 2 − u i − v j 2 + u i − v i 2 − u i − u j 2 .</formula><p>(6) Remark. Theorem 2 draws connection between the objective and the classical triplet loss. In other words, we may regard the problem in Eq. (2) as learning graph convolutional encoders to encourage positive samples being further away from negative samples in the embedding space. Moreover, by viewing the objective from the metric learning perspective, we highlight the importance of appropriately choosing negative samples, which is often neglected in previous InfoMax-based methods. Last, the contrastive objective is cheap to optimize since we do not have to generate negative samples explicitly and all computation can be performed in parallel. In contrast, the triplet loss is known to be computationally expensive <ref type="bibr" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we empirically evaluate the quality of produced node embeddings on node classification using six public benchmark datasets. We refer readers of interest to the supplementary material on details of experiments, including dataset configurations (Appendix A), implementation and hyperparameters (Appendix B), and additional experiments (Appendix C).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>For comprehensive comparison, we use six widely-used datasets to study the performance of both transductive and inductive node classification. Specifically, we use three kinds of datasets: (1) citation networks including Cora, Citeseer, Pubmed, and DBLP <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref> for transductive node classification, (2) social networks from Reddit posts for inductive learning on large-scale graphs <ref type="bibr" target="#b9">[10]</ref>, and (3) biological protein-protein interaction (PPI) networks <ref type="bibr" target="#b34">[35]</ref> for inductive node classification on multiple graphs. Details of these datasets can be found in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experimental Setup</head><p>For every experiment, we follow the linear evaluation scheme as in <ref type="bibr" target="#b17">[18]</ref>, where each model is firstly trained in an unsupervised manner. The resulting embeddings are used to train and test a simple 2regularized logistic regression classifier. We train the model for twenty runs and report the averaged performance on each dataset. Moreover, we measure performance using micro-averaged F1-score on inductive tasks and accuracy on transductive tasks. Please kindly note that for inductive learning tasks, tests are conducted on unseen or untrained nodes and graphs, while for transductive learning tasks, we use the features of all data, but the labels of the test set are masked during training.</p><p>Transductive learning. In transductive learning tasks, we employ a two-layer GCN <ref type="bibr" target="#b5">[6]</ref> as the encoder. Our encoder architecture is formally given by</p><formula xml:id="formula_10">GC i (X, A) = σ D − 1 2ÂD − 1 2 XW i ,<label>(7)</label></formula><p>f (X, A) = GC 2 (GC 1 (X, A), A).</p><p>whereÂ = A + I is the adjacency matrix with self-loops,D = iÂ i is the degree matrix, σ(·) is a nonlinear activation function, e.g., ReLU(·) = max(0, ·), and W i is a trainable weight matrix.</p><p>We consider the following two categories of representative algorithms as baselines, including (1) traditional methods DeepWalk <ref type="bibr" target="#b0">[1]</ref> and node2vec <ref type="bibr" target="#b1">[2]</ref>, and (2) deep learning methods GAE, VGAE <ref type="bibr" target="#b8">[9]</ref>, and DGI <ref type="bibr" target="#b17">[18]</ref>. Furthermore, we report performance obtained using a logistic regression classifier on raw node features and DeepWalk with embeddings concatenated with input node features. For direct comparison with supervised counterparts, we also report the performance of two representative models SGC <ref type="bibr" target="#b28">[29]</ref> and GCN <ref type="bibr" target="#b5">[6]</ref>, where they are trained in an end-to-end fashion.</p><p>Inductive learning on large graphs. Considering the large scale of the Reddit data, we closely follow <ref type="bibr" target="#b17">[18]</ref> and employ a three-layer GraphSAGE-GCN <ref type="bibr" target="#b9">[10]</ref> with residual connections <ref type="bibr" target="#b35">[36]</ref> as the encoder, which is formulated as</p><formula xml:id="formula_12">MP i (X, A) = σ([D −1Â X; X]W i ),<label>(9)</label></formula><formula xml:id="formula_13">f (X, A) = MP 3 ( MP 2 ( MP 1 (X, A), A), A).<label>(10)</label></formula><p>Here we use the mean-pooling propagation rule, asD −1 averages over node features. Due to the large scale of Reddit, it cannot fit into GPU memory entirely. Therefore, we apply the subsampling method proposed in <ref type="bibr" target="#b9">[10]</ref>, where we first randomly select a minibatch of nodes, then a subgraph centered around each selected node is obtained by sampling node neighbors with replacement. To be specific, we sample 30, 25, 20 neighbors at the first-, second-, and third-hop respectively. For generating graph views under such sampling-based settings, both RE and MF can be adapted to sampled subgraphs effortlessly.</p><p>Inductive learning on multiple graphs. For inductive learning on multiple graphs PPI, we stack three mean-pooling layer with skip connections, similar to DGI <ref type="bibr" target="#b17">[18]</ref>. The graph convolutional encoder can be formulated as</p><formula xml:id="formula_14">H 1 = MP 1 (X, A),<label>(11)</label></formula><formula xml:id="formula_15">H 2 = MP 2 (XW skip + H 1 , A),<label>(12)</label></formula><formula xml:id="formula_16">f (X, A) = H 3 = MP 3 (XW skip + H 1 + H 2 , A),<label>(13)</label></formula><p>where W skip and W skip are two projection matrices, and MP i is defined in Eq. <ref type="bibr" target="#b8">(9)</ref>. Despite that the PPI dataset consists of multiple graphs, we only compute negative samples for one anchor node as other nodes within the same graph, due to efficiency considerations.</p><p>Baselines in both large graphs and multiple graphs settings are selected similarly to transductive tasks. We consider (1) traditional methods DeepWalk 4 <ref type="bibr" target="#b0">[1]</ref>, and (2) deep learning methods GraphSAGE <ref type="bibr" target="#b9">[10]</ref> and DGI <ref type="bibr" target="#b17">[18]</ref>. Additionally, we report the performance of using raw features and DeepWalk + features under the same settings as in transductive tasks. We further provide the performance of two representative supervised methods, including FastGCN <ref type="bibr" target="#b36">[37]</ref> and GaAN-mean <ref type="bibr" target="#b37">[38]</ref> for reference. In the table, results of baselines are reported in accordance with performance in their original papers. For GraphSAGE, we reuse the unsupervised results for fair comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Results and Analysis</head><p>The empirical performance is summarized in <ref type="table" target="#tab_0">Table 1</ref>. Overall, from the table, we can see that our proposed model shows strong performance across all six datasets. GRACE consistently performs better than unsupervised baselines by considerable margins on both transductive and inductive tasks. The strong performance verifies the superiority of the proposed contrastive learning framework. We We make other observations as follows. Firstly, GRACE achieves considerable improvement over another competitive contrastive learning method DGI on PPI. We believe that this is due to the extreme sparsity of node features (over 40% nodes having all-zero features <ref type="bibr" target="#b9">[10]</ref>), which emphasizes the importance of considering topological information when choosing negative samples. For datasets like PPI, extreme feature sparsity prevents DGI from discriminating samples in the original graph from the corrupted graph, generated via shuffling node features, since shuffling node features makes no effect for the contrastive objective. Contrarily, the RE scheme used in GRACE does not rely on node features and acts as a remedy under such circumstances, which can explain the gain of GRACE on PPI compared with DGI. Also, we note that there is still a huge gap between our method with supervised models. These supervised models benefit another merit from labels, which provide other auxiliary information for model learning. Considering the sparse nature of real-world datasets, we perform another experiment to verify that our method is robust to sparse node features (Appendix C.4). Results show that by randomly removing node features, our still outperforms existing baselines.</p><p>Secondly, the performance of traditional contrastive learning methods like DeepWalk is inferior to the naive classifier that only uses raw features on some datasets (Citeseer, Pubmed, and Reddit), which suggests that these methods may be ineffective in utilizing node features. Unlike traditional work, we see that GCN-based methods, e.g., GraphSAGE and GAE, are capable of incorporating node features when learning embeddings. However, we note that on certain datasets (Pubmed), their performance is still worse than DeepWalk + feature, which we believe can be attributed to their naive method of selecting negative samples that simply chooses contrastive pairs based on edges. This fact further demonstrates the important role of selecting negative samples in contrastive representation learning. The superior performance of GRACE compared to GAEs also once again verifies the effectiveness of our proposed GRACE framework that contrasts nodes across graph views.</p><p>Additionally, we perform sensitivity analysis on critical hyperparameters p r and p m (Appendix C.1) as well as ablation studies on our hybrid scheme on generating graph views (Appendix C.2). Results show that our method is stable to perturbation of these parameters and verify the necessity of corruption at both graph topology and node feature levels. We also compare the classical InfoNCE loss (Appendix C.3), verifying the efficacy of our design choice. Details of these extra experiments can be found in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we have developed a novel graph contrastive representation learning framework based on maximizing the agreement at the node level. Our model learns representations by first generating graph views using two proposed schemes, removing edges and masking node features, and then applying a contrastive loss to maximize the agreement of node embeddings in these two views. Theoretical analysis reveals the connections from our contrastive objective to mutual information maximization and the classical triplet loss, which justifies our motivation. We have conducted comprehensive experiments using various real-world datasets under transductive and inductive settings. Experimental results demonstrate that our proposed method can consistently outperform existing state-of-the-art methods by large margins and even surpass supervised counterparts on transductive tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussions on Broader Impact</head><p>Our proposed self-supervised graph representation learning techniques help alleviate the label scarcity issue when deploying machine learning applications in real-world, which saves a lot of efforts on human annotating. For example, our GRACE framework can be plugged into existing recommender systems and produces high-quality embeddings for users and commodities to resolve the cold start problem. Moreover, from the empirical results, our work outperforms existing baselines on protein function prediction by significant margins, which demonstrate its great potential in drug discovery and treatment, given the COVID-19 crisis at this critical juncture. Note that our work mainly serves as a plug-in for existing machine learning models, it does not bring new ethical concerns. However, the GRACE model may still give biased outputs (e.g., gender bias, ethnicity bias), as the provided data itself may be strongly biased during the processes of the data collection, graph construction, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Dataset Details</head><p>Transductive learning. We utilize four widely-used citation networks, Cora, Citeseer, Pubmed, and DBLP, for predicting article subject categories. In these datasets, graphs are constructed from computer science article citation links. Specifically, nodes correspond to articles and undirected edges to citation links between articles. Furthermore, each node has a sparse bag-of-words feature and a corresponding label of article types. The former three networks are provided by <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b38">39]</ref> and the latter DBLP dataset is provided by <ref type="bibr" target="#b33">[34]</ref>. On these citation networks, we randomly select 10% of the nodes as the training set, 10% nodes as the validation set, and leave the rest nodes as the test set.</p><p>Inductive learning on large graphs. We then predict community structures of a large-scale social network, collected from Reddit. The dataset, preprocessed by <ref type="bibr" target="#b9">[10]</ref>, contains Reddit posts created in September 2014, where posts belong to different communities (subreddit). In the dataset, nodes correspond to posts, and edges connect posts if the same user has commented on both. Node features are constructed from post title, content, and comments, using off-the-shelf GloVe word embeddings <ref type="bibr" target="#b39">[40]</ref>, along with other metrics such as post score and the number of comments. Following the inductive setting of <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b17">18]</ref>, on the Reddit dataset, we choose posts in the first 20 days for training, including 151,708 nodes, and the remaining for testing (with 30% data including 23,699 nodes for validation).</p><p>Inductive learning on multiple graphs. Last, we predict protein roles, in terms of their cellular functions from gene ontology, within the protein-protein interaction (PPI) networks <ref type="bibr" target="#b34">[35]</ref> to evaluate the generalization ability of the proposed method across multiple graphs. The PPI dataset contains multiple graphs, with each corresponding to a human tissue. The graphs are constructed by <ref type="bibr" target="#b9">[10]</ref>, where each node has multiple labels that is a subset of gene ontology sets (121 in total), and node features include positional gene sets, motif gene sets, and immunological signatures (50 in total). Following <ref type="bibr" target="#b9">[10]</ref>, we select twenty graphs consisting of 44,906 nodes as the training set, two graphs containing 6,514 nodes as the validation, and the rest four graphs containing 12,038 nodes as the test set.</p><p>The statistics of datasets are summarized in <ref type="table" target="#tab_1">Table 2</ref>; download links are included in <ref type="table" target="#tab_2">Table 3</ref>. For transductive tasks, similar to <ref type="bibr" target="#b5">[6]</ref>, during the training phase, all node features are visible but node labels are masked. In the inductive setting, we closely follow <ref type="bibr" target="#b9">[10]</ref>; during training, nodes for evaluation are completely invisible; evaluation is then conducted on unseen or untrained nodes and graphs.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Implementation</head><p>Computing infrastructures. All models are implemented using PyTorch Geometric 1.5.0 <ref type="bibr" target="#b40">[41]</ref> and PyTorch 1.4.0 <ref type="bibr" target="#b41">[42]</ref>. All datasets used throughout experiments are available in PyTorch Geometric libraries. For node classification, we use the existing implementation of logistic regression with 2 regularization from Scikit-learn <ref type="bibr" target="#b42">[43]</ref>. All experiments are conducted on a computer server with eight NVIDIA Titan Xp GPUs (12GB memory each) and fourteen Intel Xeon E5-2660 v4 CPUs.</p><p>Hyperparameters. All models are initialized with Glorot initialization <ref type="bibr" target="#b43">[44]</ref>, and trained using Adam SGD optimizer <ref type="bibr" target="#b44">[45]</ref> on all datasets. The initial learning rate is set to 0.001 with an exception to 0.0005 on Cora and 10 −5 on Reddit. The 2 weight decay factor is set to 10 −5 on all datasets. On both transductive and inductive tasks, we train the model for a fixed number of epochs, specifically 200, 200, 1500, 1000 epochs for Cora, Citeseer, Pubmed and DBLP, respectively, 40 for Reddit and 200 for PPI. The probability parameters controlling the sampling process, p r,1 , p m,1 for the first view and p r,2 , p m,2 for the second view, are all selected between 0.0 and 0.4, since the original graph will be overly corrupted when the probability is set too large. Note that to generate different contexts for nodes in the two views, p r,1 and p r,2 should be distinct, and the same holds for p m,1 and p m,2 . All dataset-specific hyperparameters are summarized in <ref type="table" target="#tab_3">Table 4</ref>. In this section, we perform sensitivity analysis on critical hyperparameters in GRACE, namely four probabilities p m,1 , p r,1 , p m,2 , p r,2 that determine the generation of graph views to show the model stability under the perturbation of these hyperparameters. We conduct trasductive node classification by varying these parameters from 0.1 to 0.9. For sake of visualization brevity, we set p 1 = p r,1 = p m,1  and p 2 = p r,2 = p m,2 . In other words, p 1 and p 2 control the generation of the two graph views. Note that we only change these four parameters in the sensitivity analysis, other parameters remain the same as previously described.</p><p>The results on the Citeseer dataset is shown are <ref type="figure" target="#fig_4">Figure 2</ref>. From the figure, it can be observed that the performance of node classification in terms of Micro-F1 is relatively stable when the parameters are not too large, as shown in the plateau in the figure. We thus conclude that overall, our model is insensitive to these probabilities, demonstrating the robustness to hyperparameter tuning. If the probability is set too large (e.g., &gt; 0.5), the original graph will be heavily undermined. For example, when p r = 0.9, almost every existing edge has been removed, leading to isolated nodes in the generated graph views. Then, under such circumstance, the graph convolutional network is hard to learn useful information from node neighborhoods. Therefore, the learnt node embeddings in the two graph views are not distinctive enough, which will result in difficulty of optimizing the contrastive objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Ablation Studies</head><p>In this section, we perform ablation studies on the two schemes for generating graph views, removing edge (RE) and masking node features (MF), to verify the effectiveness of the proposed hybrid scheme. We denote GRACE (-RE) as the model without removing edges and GRACE (-MF) as the model without masking node features. We report the performance of GRACE (-RE), GRACE (-MF) and the original model GRACE on transductive node classification under the identical settings as previous, except for different enabled schemes. The results are presented in <ref type="table" target="#tab_4">Table 5</ref>.</p><p>It is seen that our hybrid approach that jointly applies RE and MF significantly outperform two downgraded models that only use one standalone method RE or MF. These results verify the effectiveness of our proposed scheme for graph corruption, and further show the necessity of jointly considering corruption at both graph topology and node feature levels. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Comparison with InfoNCE Loss</head><p>In this section, we consider another widely-used objective, the InfoNCE loss <ref type="bibr" target="#b22">[23]</ref> , in contrastive methods. For fair comparison, we measure the node similarities between two graph views using the InfoNCE objective, which is defined as</p><formula xml:id="formula_17">J NCE = 1 2 [ NCE (V , U ) + NCE (V , U )] ,<label>(14)</label></formula><p>where the pairwise objective is defined by <ref type="bibr">NCE</ref> </p><formula xml:id="formula_18">(U , V ) 1 N N i=1 log e θ(u i ,v i ) 1 N N j=1 e θ(u i ,v j ) . NCE (V , U )</formula><p>can be defined symmetrically. The modified model is denoted as GRACE-NCE hereafter. We report the performance of GRACE-NCE on transductive node classification under identical settings as with the original model GRACE. The results are summarized in <ref type="table" target="#tab_5">Table 6</ref>.</p><p>From the table, we can clearly see that the performance of the variant model GRACE-NCE is inferior to that of the original model GRACE on all four datasets. The results empirically demonstrate that, although InfoNCE is a stricter estimator of the mutual information, our objective is more effective and shows better downstream performance, which is consistent with previous observations in visual representation learning <ref type="bibr" target="#b25">[26]</ref>. We believe that the superior performance of our objective compared to InfoNCE can be attributed to the inclusion of more negative samples. Specifically, we take intra-view negative pairs into consideration in our objective, which can be viewed as a regularization against the smoothing problem brought by graph convolution operators. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 Robustness to Sparse Features</head><p>As discussed before, for existing work DGI, it is relatively easy to generate negative samples for nodes having dense features using the feature shuffling scheme. However, when node features are sparse, feature shuffling may not be sufficient to generate different neighborhoods for nodes, which motivates our hybrid scheme that corrupts the original graph at both topology and attribute levels.</p><p>In this section, we conduct experiments with randomly contaminating the training data by masking a certain portion of the node features to zeros. Specifically, we vary the contamination rate of node features from 0.5 to 0.9 on four citation networks. We conduct experiments on transductive node classification with all other parameters being the same as previously described. The performance in terms of accuracy is plotted in <ref type="figure" target="#fig_5">Figure 3</ref>.</p><p>From the figures, we can see that GRACE consistently outperforms DGI with large margins under different contamination rates, demonstrating the robustness of our proposed GRACE model to sparse features. We attribute the robustness of GRACE to the superiority of our proposed RE method for graph corruption at topology level, since RE is capable of constructing different topology context for nodes without dependence on node features. These results once again verify the necessity of considering graph corruption at both topology and attribute levels. Note that, when a large portion of node features are masked, e.g., 90% features are masked, both GRACE and DGI perform poorly. This may be explained from the fact that, when the node features are overly contaminated, nodes are highly sparse such that the GNN model is ineffective to extract useful information from nodes, leading to performance deterioration.  Theorem 1. Let X i = {x k } k∈N (i) be the neighborhood of node v i that collectively maps to its output embedding, where N (i) denotes the set of neighbors of node v i specified by GNN architectures, and X be the corresponding random variable with a uniform distribution p(X i ) = 1 N . Given two random variables U, V ∈ R F being the embedding in the two views, with their joint distribution denoted as p(U, V), our objective J is a lower bound of MI between encoder input X and node representations in two graph views U, V. Formally, J ≤ I(X; U, V).</p><p>Proof. We first show the connection between our objective J and the InfoNCE objective <ref type="bibr" target="#b22">[23]</ref> , which can be defined as <ref type="bibr" target="#b24">[25]</ref> I , where the critic function is defined as θ(x, y) = s(g(x), g(y)). We further define ρ r (u i ) = N j=1 1 [i =j] exp(θ(u i , u j )/τ ), ρ c (u i ) = N j=1 exp(θ(u i , v j )/τ ) for convenience of notation. Note that ρ r (v i ) and ρ c (v i ) can be defined symmetrically. Then, our objective J can be rewritten as</p><formula xml:id="formula_20">J = E i p(ui,vi) 1 N N i=1 log exp(θ(u i , v i )/τ ) (ρ c (u i ) + ρ r (u i )) (ρ c (v i ) + ρ r (v i )) .<label>(16)</label></formula><p>Using the notation of ρ c , the InfoNCE estimator I NCE can be written as</p><formula xml:id="formula_21">I NCE (U, V) = E i p(ui,vi) 1 N N i=1 log exp(θ(u i , v i )/τ ) ρ c (u i ) .<label>(17)</label></formula><p>Therefore,</p><formula xml:id="formula_22">2J = I NCE (U, V) − E i p(ui,vi) 1 N N i=1 log 1 + ρ r (u i ) ρ c (u i ) + I NCE (V, U) − E i p(ui,vi) 1 N N i=1 log 1 + ρ r (v i ) ρ c (v i ) ≤ I NCE (U, V) + I NCE (V, U).<label>(18)</label></formula><p>According to <ref type="bibr" target="#b24">[25]</ref>, the InfoNCE estimator is a lower bound of the true MI, i.e.</p><formula xml:id="formula_23">I NCE (U, V) ≤ I(U; V).<label>(19)</label></formula><p>Thus, we arrive at 2J ≤ I(U; V) + I(V; U) = 2I(U; V), </p><p>According to the data processing inequality, which states that, for all random variables X, Y, Z satisfying the Markov relation X → Y → Z, the inequality I(X; Z) ≤ I(X; Y) holds. Then, we observe that X, U, V satisfy the relation U ← X → V. Since, U and V are conditionally independent after observing X, the relation is Markov equivalent to U → X → V, which leads to I(U; V) ≤ I(U; X). We further notice that the relation X → (U, V) → U holds, and hence it follows that I(X; U) ≤ I(X; U, V). Combining the two inequalities yields the required inequality I(U; V) ≤ I(X; U, V).</p><p>Following Eq. (21) and Eq. <ref type="formula" target="#formula_4">(22)</ref>, we finally arrive at inequality J ≤ I(X; U, V),</p><p>which concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2 Proof of Theorem 2</head><p>Theorem 2. When the projection function g is the identity function and we measure embedding similarity by simply taking inner product, i.e. s(u, v) = u v, and further assuming that positive pairs are far more aligned than negative pairs, minimizing the pairwise objective (u i , v i ) coincides with maximizing the triplet loss, as given in the sequel</p><formula xml:id="formula_28">− (u i , v i ) ∝ 4N τ + N j=1 1 [j =i] u i − v i 2 − u i − v j 2 + u i − v i 2 − u i − u j 2 .<label>(24)</label></formula><p>Proof. Based on the assumptions, we can rearrange the pairwise objective as</p><formula xml:id="formula_29">− (u i , v i ) = − log exp u i v i /τ N k=1 exp u i v k /τ + N k=1 1 [k =i] exp u i u k /τ = log 1 + N k=1 1 [k =i] exp u i v k − u i v i τ + N k=1 1 [k =i] exp u i u k − u i v i τ .</formula><p>(25) By Taylor expansion of first order,</p><formula xml:id="formula_30">− (u i , v i ) ≈ N k=1 1 [k =i] exp u i v k − u i v i τ + N k=1 1 [k =i] exp u i u k − u i v i τ ≈ 2 + 1 τ N k=1 1 [k =i] (u i v k − u i v i ) + N k=1 1 [k =i] (u i u k − u i v i ) = 2 − 1 2τ N k=1 1 [k =i] u i − v k 2 − u i − v i 2 + u i − u k 2 − u i − v i 2 ∝ 4N τ + N k=1 1 [k =i] u i − v i 2 − u i − v k 2 + u i − v i 2 − u i − u k 2 ,<label>(26)</label></formula><p>which concludes the proof.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Our proposed deep GRAph Contrastive rEpresentation learning (GRACE) model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>1 [k=1 1 [</head><label>11</label><figDesc>k =i] e θ(ui,v k )/τ inter-view negative pairs + N k =i] e θ(ui,u k )/τ intra-view negative pairs ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>The performance of GRACE with varying different hyperparameters in transductive node classification on the Citeseer dataset in terms of Micro-F1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>The performance of GRACE and DGI in transductive node classification in terms of Micro-F1 on four citation datasets with a portion of node features masked under different masking rates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>NCE (U; V) E i p(ui,vi)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>which leads to the inequality J ≤ I(U; V).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Summary of performance on node classification in terms of accuracy in percentage (on transductive tasks) or micro-averaged F1 score (on inductive tasks) with standard deviation. Available data for each method during the training phase is shown in the second column, where X, A, Y correspond to node features, the adjacency matrix, and labels respectively. The highest performance of unsupervised models is highlighted in boldface.</figDesc><table><row><cell></cell><cell cols="3">(a) Transductive</cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="2">Training Data</cell><cell>Cora</cell><cell cols="2">Citeseer Pubmed</cell><cell>DBLP</cell></row><row><cell>Raw features</cell><cell>X</cell><cell></cell><cell>64.8</cell><cell>64.6</cell><cell>84.8</cell><cell>71.6</cell></row><row><cell>node2vec</cell><cell>A</cell><cell></cell><cell>74.8</cell><cell>52.3</cell><cell>80.3</cell><cell>78.8</cell></row><row><cell>DeepWalk</cell><cell>A</cell><cell></cell><cell>75.7</cell><cell>50.5</cell><cell>80.5</cell><cell>75.9</cell></row><row><cell>DeepWalk + features</cell><cell>X, A</cell><cell></cell><cell>73.1</cell><cell>47.6</cell><cell>83.7</cell><cell>78.1</cell></row><row><cell>GAE</cell><cell>X, A</cell><cell></cell><cell>76.9</cell><cell>60.6</cell><cell>82.9</cell><cell>81.2</cell></row><row><cell>VGAE</cell><cell>X, A</cell><cell></cell><cell>78.9</cell><cell>61.2</cell><cell>83.0</cell><cell>81.7</cell></row><row><cell>DGI</cell><cell>X, A</cell><cell></cell><cell cols="4">82.6±0.4 68.8±0.7 86.0±0.1 83.2±0.1</cell></row><row><cell>GRACE</cell><cell>X, A</cell><cell></cell><cell cols="4">83.3±0.4 72.1±0.5 86.7±0.1 84.2±0.1</cell></row><row><cell>SGC</cell><cell>X, A, Y</cell><cell></cell><cell>80.6</cell><cell>69.1</cell><cell>84.8</cell><cell>81.7</cell></row><row><cell>GCN</cell><cell>X, A, Y</cell><cell></cell><cell>82.8</cell><cell>72.0</cell><cell>84.9</cell><cell>82.7</cell></row><row><cell></cell><cell></cell><cell cols="2">(b) Inductive</cell><cell></cell><cell></cell></row><row><cell cols="2">Method</cell><cell cols="2">Training Data</cell><cell>Reddit</cell><cell>PPI</cell></row><row><cell cols="2">Raw features</cell><cell></cell><cell>X</cell><cell>58.5</cell><cell>42.2</cell></row><row><cell cols="2">DeepWalk</cell><cell></cell><cell>A</cell><cell>32.4</cell><cell>-</cell></row><row><cell cols="2">DeepWalk + features</cell><cell></cell><cell>X, A</cell><cell>69.1</cell><cell>-</cell></row><row><cell cols="2">GraphSAGE-GCN</cell><cell></cell><cell>X, A</cell><cell>90.8</cell><cell>46.5</cell></row><row><cell cols="2">GraphSAGE-mean</cell><cell></cell><cell>X, A</cell><cell>89.7</cell><cell>48.6</cell></row><row><cell cols="2">GraphSAGE-LSTM</cell><cell></cell><cell>X, A</cell><cell>90.7</cell><cell>48.2</cell></row><row><cell cols="2">GraphSAGE-pool</cell><cell></cell><cell>X, A</cell><cell>89.2</cell><cell>50.2</cell></row><row><cell cols="2">DGI</cell><cell></cell><cell>X, A</cell><cell cols="2">94.0±0.1 63.8±0.2</cell></row><row><cell cols="2">GRACE</cell><cell></cell><cell>X, A</cell><cell cols="2">94.2±0.0 66.2±0.1</cell></row><row><cell cols="2">FastGCN</cell><cell cols="2">X, A, Y</cell><cell>93.7</cell><cell>-</cell></row><row><cell cols="2">GaAN-mean</cell><cell cols="2">X, A, Y</cell><cell cols="2">95.8±0.1 96.9±0.2</cell></row></table><note>particularly note that GRACE is competitive with models trained with label supervision on all four transductive datasets and inductive dataset Reddit.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Statistics of datasets used in experiments.</figDesc><table><row><cell>Dataset</cell><cell>Type</cell><cell>#Nodes</cell><cell>#Edges</cell><cell>#Features</cell><cell>#Classes</cell></row><row><cell>Cora</cell><cell>Transductive</cell><cell>2,708</cell><cell>5,429</cell><cell>1,433</cell><cell>7</cell></row><row><cell cols="2">Citeseer Transductive</cell><cell>3,327</cell><cell>4,732</cell><cell>3,703</cell><cell>6</cell></row><row><cell cols="2">Pubmed Transductive</cell><cell>19,717</cell><cell>44,338</cell><cell>500</cell><cell>3</cell></row><row><cell>DBLP</cell><cell>Transductive</cell><cell>17,716</cell><cell>105,734</cell><cell>1,639</cell><cell>4</cell></row><row><cell>Reddit</cell><cell>Inductive</cell><cell>231,443</cell><cell>11,606,919</cell><cell>602</cell><cell>41</cell></row><row><cell>PPI</cell><cell>Inductive</cell><cell>56,944 (24 graphs)</cell><cell>818,716</cell><cell>50</cell><cell>121 (multilabel)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Dataset download links.</figDesc><table><row><cell cols="2">Dataset Download link</cell></row><row><cell>Cora</cell><cell>https://github.com/kimiyoung/planetoid/raw/master/data</cell></row><row><cell cols="2">Citeseer https://github.com/kimiyoung/planetoid/raw/master/data</cell></row><row><cell cols="2">Pubmed https://github.com/kimiyoung/planetoid/raw/master/data</cell></row><row><cell>DBLP</cell><cell></cell></row></table><note>https://github.com/abojchevski/graph2gauss/raw/master/data/dblp.npz Reddit https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/reddit.zip PPI https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/ppi.zip</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Hypeparameter specifications.</figDesc><table><row><cell cols="5">Dataset pm,1 pm,2 pr,1 pr,2</cell><cell>Learning rate</cell><cell>Weight decay</cell><cell>Training epochs</cell><cell>Hidden dimension</cell><cell>Activation function</cell></row><row><cell>Cora</cell><cell>0.3</cell><cell>0.4</cell><cell>0.2</cell><cell>0.4</cell><cell>0.005</cell><cell>10 −5</cell><cell>200</cell><cell>128</cell><cell>ReLU</cell></row><row><cell>Citeseer</cell><cell>0.3</cell><cell>0.2</cell><cell>0.2</cell><cell>0.0</cell><cell>0.001</cell><cell>10 −5</cell><cell>200</cell><cell>256</cell><cell>PReLU</cell></row><row><cell>Pubmed</cell><cell>0.0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.1</cell><cell>0.001</cell><cell>10 −5</cell><cell>1,500</cell><cell>256</cell><cell>ReLU</cell></row><row><cell>DBLP</cell><cell>0.1</cell><cell>0.0</cell><cell>0.1</cell><cell>0.4</cell><cell>0.001</cell><cell>10 −5</cell><cell>1,000</cell><cell>256</cell><cell>ReLU</cell></row><row><cell>Reddit</cell><cell>0.3</cell><cell>0.2</cell><cell>0.1</cell><cell>0.2</cell><cell>0.00001</cell><cell>10 −5</cell><cell>40</cell><cell>512</cell><cell>ELU</cell></row><row><cell>PPI</cell><cell>0.1</cell><cell>0.0</cell><cell>0.3</cell><cell>0.4</cell><cell>0.001</cell><cell>10 −5</cell><cell>500</cell><cell>512</cell><cell>RReLU</cell></row><row><cell cols="5">C Additional Experiments</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">C.1 Sensitivity Analysis</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>The performance of model variants along with the original GRACE model in the ablation study in terms of accuracy of node classification. GRACE (-RE) and GRACE (-MF) denote the model without removing edges and masking node features respectively.</figDesc><table><row><cell>Method</cell><cell>Cora</cell><cell>Citeseer Pubmed</cell><cell>DBLP</cell></row><row><cell>GRACE</cell><cell cols="3">83.2±0.5 72.1±0.5 86.7±0.1 84.2±0.1</cell></row><row><cell cols="4">GRACE (-RE) 82.3±0.4 72.0±0.4 84.8±0.2 83.6±0.2</cell></row><row><cell cols="4">GRACE (-MF) 81.6±0.4 69.9±0.6 85.7±0.1 83.5±0.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>The performance of GRACE and GRACE-NCE in transductive node classification on four citation datasets. 2±0.5 72.1±0.5 86.7±0.1 84.2±0.1 GRACE-NCE 82.1±0.4 70.9±0.6 85.0±0.1 82.1±0.1</figDesc><table><row><cell>Method</cell><cell>Cora</cell><cell>Citeseer Pubmed</cell><cell>DBLP</cell></row><row><cell>GRACE</cell><cell>83.</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Code is made publicly available at https://github.com/CRIPAC-DIG/GRACE.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">DeepWalk is not applicable to the multi-graph experiments, since the embedding spaces produced by DeepWalk may be arbitrarily rotated with respect to different disjoint graphs<ref type="bibr" target="#b9">[10]</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors would like to thank Tao Sun and Sirui Lu for insightful discussions. This work is jointly supported by National Key Research and Development Program (2018YFB1402600, 2016YFB1001000) and National Natural Science Foundation of China (U19B2038, 61772528).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">DeepWalk: Online Learning of Social Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">node2vec: Scalable Feature Learning for Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiezhong</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiao</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuansan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WSDM</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonardo Filipe Rodrigues</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">H P</forename><surname>Saverese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">R</forename><surname>Figueiredo</surname></persName>
		</author>
		<title level="m">struc2vec: Learning Node Representations from Structural Identity. In KDD</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Graph Attention Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hierarchical Graph Convolutional Networks for Semi-supervised Node Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fenyu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqiao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tieniu</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Variational Graph Auto-Encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BDL@NIPS</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Inductive Representation Learning on Large Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Self-Organization in a Perceptual Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Linsker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised Feature Learning via Non-Parametric Instance Discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<title level="m">Contrastive Multiview Coding. arXiv.org</title>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Momentum Contrast for Unsupervised Visual Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning Representations by Maximizing Mutual Information Across Views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Buchwalter</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Unsupervised Embedding Learning via Invariant and Spreading Instance Feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Fu</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Simple Framework for Contrastive Learning of Visual Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">arXiv.org</title>
		<imprint>
			<date type="published" when="2020-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Devon</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Deep Graph Infomax. In ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Self-Organizing Neural Network That Discovers Surfaces in Random-Dot Stereograms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanna</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">355</biblScope>
			<biblScope unit="issue">6356</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised Representation Learning by Predicting Image Rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveer</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Colorization as a Proxy Task for Visual Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustav</forename><surname>Larsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Shakhnarovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning Deep Representations by Mutual Information Estimation and Maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karan</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aäron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<title level="m">Representation Learning with Contrastive Predictive Coding. arXiv.org</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Olivier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aravind</forename><surname>Hénaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">De</forename><surname>Srinivas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Fauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Razavi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Ali Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den Oord</surname></persName>
		</author>
		<title level="m">Data-Efficient Image Recognition with Contrastive Predictive Coding. arXiv.org</title>
		<imprint>
			<date type="published" when="2019-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On Variational Bounds of Mutual Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aäron</forename><surname>Van Den</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">On Mutual Information Maximization for Representation Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Tschannen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josip</forename><surname>Djolonga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">K</forename><surname>Rubenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Lucic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Representation Learning on Graphs: Methods and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rex</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>IEEE Data Eng. Bull</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Noise-Contrastive Estimation of Unnormalized Statistical Models, with Applications to Natural Image Statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>JMLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Simplifying Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amauri</forename><surname>Holanda De Souza</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Fifty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dropout: A Simple Way to Prevent Neural Networks From Overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">DropEdge: Towards Deep Graph Convolutional Networks on Node Classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tingyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junzhou</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">FaceNet: A Unified Embedding for Face Recognition and Clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prithviraj</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Galileo</forename><surname>Namata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mustafa</forename><surname>Bilgic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lise</forename><surname>Getoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Eliassi-Rad</surname></persName>
		</author>
		<title level="m">Collective Classification in Network Data. AI Magazine</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Günnemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Predicting Multicellular Function Through Multi-layer Tissue Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marinka</forename><surname>Zitnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cao</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiani</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjian</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwin</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dit-Yan</forename><surname>Yeung</surname></persName>
		</author>
		<title level="m">GaAN: Gated Attention Networks for Learning on Large and Spatiotemporal Graphs. In UAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Revisiting Semi-Supervised Learning with Graph Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">GloVe: Global Vectors for Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Fast Graph Representation Learning with PyTorch Geometric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Fey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><forename type="middle">Eric</forename><surname>Lenssen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RLGM@ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">PyTorch: An Imperative Style, High-Performance Deep Learning Library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaël</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bertrand</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Prettenhofer</surname></persName>
		</author>
		<title level="m">Matthieu Brucher, Matthieu Perrot, and Edouard Duchesnay. Scikit-learn: Machine Learning in Python. JMLR</title>
		<meeting><address><addrLine>Ron Weiss, Vincent Dubourg, Jake VanderPlas, Alexandre Passos, David Cournapeau</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Understanding the Difficulty of Training Deep Feedforward Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
