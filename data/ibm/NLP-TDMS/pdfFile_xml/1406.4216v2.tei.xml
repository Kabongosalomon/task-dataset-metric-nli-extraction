<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Person Re-identification by Local Maximal Occurrence Representation and Metric Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2015-06">June 2015</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengcai</forename><surname>Liao</surname></persName>
							<email>scliao@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Biometrics and Security Research</orgName>
								<orgName type="institution" key="instit1">National Laboratory of Pattern Recognition Institute of Automation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>95 Zhongguancun East Road</addrLine>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Biometrics and Security Research</orgName>
								<orgName type="institution" key="instit1">National Laboratory of Pattern Recognition Institute of Automation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>95 Zhongguancun East Road</addrLine>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhu</surname></persName>
							<email>xiangyu.zhu@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Biometrics and Security Research</orgName>
								<orgName type="institution" key="instit1">National Laboratory of Pattern Recognition Institute of Automation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>95 Zhongguancun East Road</addrLine>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
							<email>szli@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Center for Biometrics and Security Research</orgName>
								<orgName type="institution" key="instit1">National Laboratory of Pattern Recognition Institute of Automation</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>95 Zhongguancun East Road</addrLine>
									<postCode>100190</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Person Re-identification by Local Maximal Occurrence Representation and Metric Learning</title>
					</analytic>
					<monogr>
						<title level="m">the IEEE International Conference on Computer Vision and Pattern Recognition (CVPR 2015)</title>
						<meeting> <address><addrLine>Boston, USA</addrLine></address>
						</meeting>
						<imprint>
							<date type="published" when="2015-06">June 2015</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Person re-identification is an important technique towards automatic search of a person's presence in a surveillance video. Two fundamental problems are critical for person re-identification, feature representation and metric learning. An effective feature representation should be robust to illumination and viewpoint changes, and a discriminant metric should be learned to match various person images. In this paper, we propose an effective feature representation called Local Maximal Occurrence (LOMO), and a subspace and metric learning method called Cross-view Quadratic Discriminant Analysis (XQDA). The LOMO feature analyzes the horizontal occurrence of local features, and maximizes the occurrence to make a stable representation against viewpoint changes. Besides, to handle illumination variations, we apply the Retinex transform and a scale invariant texture operator. To learn a discriminant metric, we propose to learn a discriminant low dimensional subspace by cross-view quadratic discriminant analysis, and simultaneously, a QDA metric is learned on the derived subspace. We also present a practical computation method for XQDA, as well as its regularization. Experiments on four challenging person re-identification databases, VIPeR, QMUL GRID, CUHK Campus, and CUHK03, show that the proposed method improves the state-of-the-art rank-1 identification rates by 2.2%, 4.88%, 28.91%, and 31.55% on the four databases, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Person re-identification is a problem of finding a person from a gallery who has the same identity to the probe. This is a challenging problem because of big intra-class variations in illumination, pose or viewpoint, and occlusion. Many approaches have been proposed for person reidentification <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b7">8]</ref>, which greatly advance this field.</p><p>Two fundamental problems are critical for person re-identification, feature representation and metric learning. An effective feature representation should be robust to illumination and viewpoint changes, and a discriminant metric should be learned to match various person images. Many efforts have been made along the two directions to tackle the challenge of person re-identification. For feature representation, several effective approaches have been proposed, for example, the ensemble of local features (ELF) <ref type="bibr" target="#b9">[10]</ref>, SDALF <ref type="bibr" target="#b1">[2]</ref>, kBiCov <ref type="bibr" target="#b32">[33]</ref>, fisher vectors (LDFV) <ref type="bibr" target="#b31">[32]</ref>, salience match <ref type="bibr" target="#b45">[46]</ref>, and mid-level filter <ref type="bibr" target="#b47">[48]</ref>. These handcrafted or learning based descriptors have made impressive improvements over robust feature representation, and advanced the person re-identification research. However, how to design or learn a robust feature for the person reidentification challenge still remains an open problem. Another aspect of person re-identification is how to learn a robust distance or similarity function to deal with the complex matching problem. Many metric learning algorithms have been proposed considering this aspect <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b23">24]</ref>. In practice, many previous metric learning methods <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b37">38]</ref> show a two-stage processing for metric learning, that is, the Principle Component Analysis (PCA) is first applied for dimension reduction, then metric learning is performed on the PCA subspace. However, this two-stage processing may not be optimal for metric learning in low dimensional space, because samples of different classes may already be cluttered after the first stage.</p><p>In this paper, we propose an efficient feature representation called Local Maximal Occurrence (LOMO), and a subspace and metric learning method called Cross-view Quadratic Discriminant Analysis (XQDA). The LOMO feature analyzes the horizontal occurrence of local features, and maximizes the occurrence to make a stable representation against viewpoint changes. Besides, we find that applying the Retinex transform is useful to handle illumination variations in person re-identification. To learn a discriminant metric, we propose to learn a discriminant low dimensional subspace by cross-view quadratic discriminant analysis, and simultaneously, a QDA metric is learned on the derived subspace. We show that the problem can be formulated as a Generalized Rayleigh Quotient, and a closedform solution can be obtained by the generalized eigenvalue decomposition. We also present a practical computation method for XQDA, as well as its regularization and dimension selection. The proposed method is shown to be effective and efficient through person re-identification experiments on four public databases, and we also demonstrate how the proposed components lead to improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Many existing person re-identification approaches try to build a robust feature representation which is both distinctive and robust for describing a person's appearance under various conditions <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b2">3]</ref>. Gray and Tao <ref type="bibr" target="#b9">[10]</ref> proposed to use AdaBoost to select good features out of a set of color and texture features. Farenzena et al. <ref type="bibr" target="#b5">[6]</ref> proposed the Symmetry-Driven Accumulation of Local Features (SDALF) method, where the symmetry and asymmetry property is considered to handle viewpoint variations. Ma et al. <ref type="bibr" target="#b31">[32]</ref> turned local descriptors into the Fisher Vector to produce a global representation of an image. Cheng et al. <ref type="bibr" target="#b2">[3]</ref> utilized the Pictorial Structures where part-based color information and color displacement were considered for person re-identification. Recently, saliency information has been investigated for person re-identification <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b28">29]</ref>, leading to a novel feature representation. In <ref type="bibr" target="#b41">[42]</ref>, a method called regionlets is proposed, which picks a maximum bin from three random regions for object detection under deformation. In contrast, we propose to maximize the occurrence of each local pattern among all horizontal sub-windows to tackle viewpoint changes.</p><p>Besides robust features, metric learning has been widely applied for person re-identification <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b23">24]</ref>. Zheng et al. <ref type="bibr" target="#b48">[49]</ref> proposed the PRDC algorithm, which optimizes the relative distance comparison. Hirzer et al. <ref type="bibr" target="#b13">[14]</ref> proposed to relax the PSD constraint required in Mahalanobis metric learning, and obtained a simplified formulation that still showed promising performance. Li at al. <ref type="bibr" target="#b23">[24]</ref> proposed the learning of Locally-Adaptive Decision Functions (LADF) for person verification, which can be viewed as a joint model of a distance metric and a locally adapted thresholding rule. Prosser et al. <ref type="bibr" target="#b38">[39]</ref> formulated the person re-identification problem as a ranking problem, and applied the RankSVM to learn a subspace. In <ref type="bibr" target="#b20">[21]</ref>, local experts were considered to learn a common feature space for person re-identification across views.</p><p>Except a novel feature representation, the proposed XQDA algorithm is mostly related to Bayesian face <ref type="bibr" target="#b35">[36]</ref>, KISSME <ref type="bibr" target="#b17">[18]</ref>, Linear Discriminant Analysis (LDA) <ref type="bibr" target="#b12">[13]</ref>, local fisher discriminant analysis (LF) <ref type="bibr" target="#b37">[38]</ref>, and CFML <ref type="bibr" target="#b0">[1]</ref>. XQDA can be seen as an extension of Bayesian face and KISSME, in that a discriminant subspace is further learned together with a metric. The LF method applies FDA together with PCA and LPP to derive a low dimensional yet discriminant subspace. The CFML algorithm aims at a different problem though learns a similar subspace to XQDA. However, both LF and CFML use the Euclidean distance on the derived subspace, while the proposed method considers a discriminant subspace as well as an integrated metric. For the traditional LDA method, though XQDA shares a similar generalized Rayleigh quotient formulation, they are essentially not equivalent, which is explained in <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Local Maximal Occurrence Feature</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Dealing with Illumination Variations</head><p>Color is an important feature for describing person images. However, the illumination conditions across cameras can be very different, and the camera settings might also be different from camera to camera. Therefore, the perceived colors of the same person may vary largely from different camera views. For example, <ref type="figure" target="#fig_0">Fig. 1</ref> (a) shows some sample images from the VIPeR database <ref type="bibr" target="#b8">[9]</ref>. It can be seen that images of the same person across the two camera views have a large difference in illumination and color appearance.</p><p>In this paper, we propose to apply the Retinex algorithm <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b15">16]</ref> to preprocess person images. Retinex considers human lightness and color perception. It aims at producing a color image that is consistent to human observation of the scene. The restored image usually contains vivid color information, especially enhanced details in shadowed regions.</p><p>We implement the multiscale Retinex algorithm according to <ref type="bibr" target="#b15">[16]</ref>, which combines the small-scale Retinex for dynamic range compression and the large-scale Retinex for tonal rendition simultaneously. As a result, the algorithm handles both the color constancy and dynamic range compression automatically, achieving a good approximation to human visual perception. Specifically, we use two scales of center/surround Retinex, with σ = 5 and σ = 20. Besides, we automatically compute the gain/offset parameters so that the resulting intensities linearly stretches in [0,255]. <ref type="figure" target="#fig_0">Fig. 1 (b)</ref> shows some examples of the processed images by our implementation of Retinex. Comparing to <ref type="figure" target="#fig_0">Fig. 1 (a)</ref>, it can be observed that the Retinex images of the same person across cameras have a better consistency in lighting and color. This makes person re-identification easier than using the original images. With the Retinex images, we apply the HSV color histogram to extract color features. In addition to color description, we also apply the Scale Invariant Local Ternary Pattern (SILTP) <ref type="bibr" target="#b25">[26]</ref> descriptor for illumination invariant texture description. SILTP is an improved operator over the well-known Local Binary Pattern (LBP) <ref type="bibr" target="#b36">[37]</ref>. In fact, LBP has a nice invariant property under monotonic gray-scale transforms, but it is not robust to image noises. SILTP improves LBP by introducing a scale invariant local comparison tolerance, achieving invariance to intensity scale changes and robustness to image noises.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Dealing with Viewpoint Changes</head><p>Pedestrians under different cameras usually appear in different viewpoint. For example, a person with frontal view in a camera may appear in back view under another camera. Therefore, matching persons in different viewpoints is also difficult. To address this, <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b48">49]</ref> proposed to equally divide a person image into six horizontal stripes, and a single histogram is computed in each stripe. This feature has made a success in viewpoint invariant person representation <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b26">27]</ref>. However, it may also lose spatial details within a stripe, thus affecting its discriminative power.</p><p>We propose to use sliding windows to describe local details of a person image. Specifically, we use a subwindow size of 10×10, with an overlapping step of 5 pixels to locate local patches in 128 × 48 images. Within each subwindow, we extract two scales of SILTP histograms (SILTP 0.3 4,3 and SILTP 0.3 4,5 ), and an 8 × 8 × 8-bin joint HSV histogram. Each histogram bin represents the occurrence probability of one pattern in a subwindow. To address viewpoint changes, we check all subwindows at the same horizontal location, and maximize the local occurrence of each pattern (i.e. the same histogram bin) among these subwindows. The resulting histogram achieves some invariance to viewpoint changes, and at the same time captures local region characteristics of a person. <ref type="figure" target="#fig_1">Fig. 2</ref> shows the procedure of the proposed LOMO feature extraction.</p><p>To further consider the multi-scale information, we build a three-scale pyramid representation, which downsamples the original 128 × 48 image by two 2 × 2 local average pooling operations, and repeats the above feature extraction procedure. By concatenating all the computed local maximal occurrences, our final descriptor has (8 * 8 * 8 color bins + 3 4 * 2 SILTP bins ) * (24 + 11 + 5 horizontal groups ) = 26, 960 dimensions. Finally, we apply a log transform to suppress large bin values, and normalize both HSV and SILTP features to unit length. Since we only use simple HSV and SILTP features, the proposed feature extraction method is efficient to compute (see Section 5.5.4). <ref type="bibr" target="#b35">[36]</ref>. Accordingly, two classes of variations can be defined: the intrapersonal variations Ω I and the extrapersonal variations Ω E . Therefore, in this way the multi-class classification problem can be solved by distinguishing the above two classes. Moghaddam et al. <ref type="bibr" target="#b35">[36]</ref> proposed to model each of the two classes with a multivariate Gaussian distribution. This corresponds to a QDA model with the defined Ω I and Ω E as two classes. Furthermore, it was noticed in <ref type="bibr" target="#b35">[36]</ref> that both Ω I and Ω E have zero mean. The resulting algorithm is called Bayesian face applied to face recognition. Interestingly, in <ref type="bibr" target="#b17">[18]</ref>, Köstinger et al. also derived a similar approach called KISSME via the log likelihood ratio test of the two Gaussian distributions, and applied it to person reidentification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Cross-view Quadratic Discriminant Analysis 4.1. Bayesian Face and KISSME Revisit</head><formula xml:id="formula_0">Consider a sample difference ∆ = x i − x j . ∆ is called the intrapersonal difference if y i = y j , while it is called the extrapersonal difference if y i = y j</formula><p>Formally, the Bayesian face and the KISSME algorithms are formulated as follows. Under the zero-mean Gaussian distribution, the likelihoods of observing ∆ in Ω I and Ω E are defined as</p><formula xml:id="formula_1">P (∆|Ω I ) = 1 (2π) d/2 |Σ I | 1/2 e − 1 2 ∆ T Σ −1 I ∆ ,<label>(1)</label></formula><formula xml:id="formula_2">P (∆|Ω E ) = 1 (2π) d/2 |Σ E | 1/2 e − 1 2 ∆ T Σ −1 E ∆ ,<label>(2)</label></formula><p>where Σ I and Σ E are the covariance matrices of Ω I and Ω E , respectively, and n I and n E denotes the number of samples in the two classes. By applying the Bayesian rule and the log-likelihood ratio test, the decision function can be simplified as</p><formula xml:id="formula_3">f (∆) = ∆ T (Σ −1 I − Σ −1 E )∆,<label>(3)</label></formula><p>and so the derived distance function between x i and x j is Therefore, learning the distance function corresponds to estimating the covariant matrices Σ I and Σ E .</p><formula xml:id="formula_4">d(x i , x j ) = (x i − x j ) T (Σ −1 I − Σ −1 E )(x i − x j ).<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">XQDA</head><p>Usually, the original feature dimensions d is large, and a low dimensional space R r (r &lt; d) is preferred for classification. <ref type="bibr" target="#b35">[36]</ref> suggested to decompose Σ I and Σ E separately to reduce the dimensions. In <ref type="bibr" target="#b17">[18]</ref>, PCA was applied, then Σ I and Σ E were estimated in the PCA subspace. However, both methods are not optimal because the dimension reduction does not consider the distance metric learning.</p><p>In this paper, we extend the Bayesian face and KISSME approaches to cross-view metric learning, where we consider to learn a subspace W = (w 1 , w 2 , . . . , w r ) ∈ R d×r with cross-view data, and at the same time learn a distance function in the r dimensional subspace for the cross-view similarity measure. Suppose we have a cross-view training set {X, Z} of c classes, where X = (x 1 , x 2 , . . . , x n ) ∈ R d×n contains n samples in a d-dimensional space from one view, Z = (z 1 , z 2 , . . . , z m ) ∈ R d×m contains m samples in the same d-dimensional space but from the other view. The cross-view matching problem arises from many applications, like heterogeneous face recognition <ref type="bibr" target="#b24">[25]</ref> and viewpoint invariant person re-identification <ref type="bibr" target="#b9">[10]</ref>. Note that Z is the same with X in the single-view matching scenario.</p><p>Considering a subspace W , the distance function Eq. (4) in the r dimensional subspace is computed as</p><formula xml:id="formula_5">d W (x, z) = (x − z) T W (Σ −1 I − Σ −1 E )W T (x − z),<label>(5)</label></formula><p>where</p><formula xml:id="formula_6">Σ I = W T Σ I W and Σ E = W T Σ E W . Therefore, we needs to learn a kernel matrix M (W ) = W (Σ −1 I − Σ −1 E )W T . However, directly optimizing d W is difficult be- cause W is contained in two inverse matrices.</formula><p>Recall that Ω I and Ω E have zero mean, then given a basis w, the projected samples of the two classes will still center at zero, but may have different variances, as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. In this case, the traditional Fisher criterion used to derive LDA is no longer suitable because the two classes have the same mean. However, the variances σ I and σ E can still be used to distinguish the two classes. Therefore, we can optimize the projection direction w such that</p><formula xml:id="formula_7">σ E (w)/σ I (w) is maximized. Notice that σ I (w) = w T Σ I w and σ E (w) = w T Σ E w, therefore, the objective σ E (w)/σ I (w) corresponds to the Generalized Rayleigh Quotient J(w) = w T Σ E w w T Σ I w .<label>(6)</label></formula><p>The maximization of J(w) is equivalent to</p><formula xml:id="formula_8">max w w T Σ E w, s.t. w T Σ I w = 1,<label>(7)</label></formula><p>which can be solved by the generalized eigenvalue decomposition problem as similar in LDA. That is, the largest eigenvalue of Σ −1 I Σ E is the maximum value of J(w), and the corresponding eigenvector w 1 is the solution. Furthermore, the solution orthogonal to w 1 and corresponding to the second largest value of J(w) is the eigenvector of the second largest eigenvalue of Σ −1 I Σ E , and so on. Therefore, with W = (w 1 , w 2 , . . . , w r ) we learn a discriminant subspace, as well as a distance function in the learned subspace, as defined in Eq. <ref type="bibr" target="#b4">(5)</ref>. We call the derived algorithm Crossview Quadratic Discriminant Analysis (XQDA) to reflect its connection to QDA and the output of a cross-view metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Practical Computation</head><p>The computation of the two covariance matrices Σ I and Σ E require O(N kd 2 ) and O(nmd 2 ) multiplication operations, respectively, where N = max(m, n), and k represents the average number of images in each class. To reduce the computation, we show that</p><formula xml:id="formula_9">n I Σ I = X X T + Z Z T − SR T − RS T ,<label>(8)</label></formula><p>where</p><formula xml:id="formula_10">X = ( √ m 1 x 1 , √ m 1 x 2 , . . . , √ m 1 x n1 , . . . , √ m c x n ), Z = ( √ n 1 z 1 , √ n 1 z 2 , . . . , √ n 1 z m1 , . . . , √ n c z m ), S = ( yi=1 x i , yi=2 x i , . . . , yi=c x i ), R = ( lj =1 z j , lj =2 z j , .</formula><p>. . , lj =c z j ), y i and l j are class labels, n k is the number of samples in class k of X, and m k is the number of samples in class k of Z. Besides,</p><formula xml:id="formula_11">n E Σ E = mXX T + nZZ T − sr T − rs T − n I Σ I ,<label>(9)</label></formula><p>where s = n i=1 x i and r = m j=1 z j . The above simplification shows that the computations of Σ I and Σ E are both reduced to O(N d 2 ). It can be observed that, Σ I and Σ E can be computed directly from sample mean and covariance of each class and all classes, so there is no need to actually compute the mn pairs of sample differences required in many other metric learning algorithms.</p><p>Another practical issue is that, Σ I may be singular, resulting that Σ −1 I cannot be computed. Therefore, it is useful to add a small regularizer to the diagonal elements of Σ I , as usually done in similar problems like LDA. This will make the estimation of Σ I more smooth and robust. Empirically we find that, when all samples are normalized to unit length, a value of 0.001 as a regularizer can be commonly applied to improve the result.</p><p>Finally, there is a remaining issue of selecting the dimensionality of the derived XQDA subspace. In real applications, there should be a consideration to have a low dimensional subspace to ensure the processing speed. Beyond this consideration, we find that having the selected eigenvalues of Σ −1 I Σ E larger than 1 is a useful signature to determine the dimensions. This is because the eigenvalue of Σ −1 I Σ E corresponds to σ E /σ I in <ref type="figure" target="#fig_2">Fig. 3</ref>, and σ E &lt; σ I may not provide useful discriminant information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experiments on VIPeR</head><p>VIPeR <ref type="bibr" target="#b8">[9]</ref> is a challenging person re-identification database that has been widely used for benchmark evaluation. It contains 632 pairs of person images, captured by a pair of cameras in an outdoor environment. Images in VIPeR contains large variations in background, illumination, and viewpoint. <ref type="figure" target="#fig_0">Fig. 1 (a)</ref> shows some example pairs of images from the VIPeR database. All images are scaled to 128 × 48 pixels. The widely adopted experimental protocol on this database is to randomly divide the 632 pairs of images into half for training and the other half for testing, and repeat the procedure 10 times to get an average performance. We followed this procedure in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Comparison of Metric Learning Algorithms</head><p>We evaluated the proposed XQDA algorithm and several metric learning algorithms, including Euclidean distance, Mahalanobis distance trained with genuine pairs <ref type="bibr" target="#b17">[18]</ref>, LMNN v2.5 <ref type="bibr" target="#b42">[43]</ref>, ITML <ref type="bibr" target="#b3">[4]</ref>, KISSME <ref type="bibr" target="#b17">[18]</ref>, and RLDA <ref type="bibr" target="#b44">[45]</ref>, with the same LOMO feature. For the compared algorithms, PCA was first applied to reduce the feature dimensionality to 100.The proposed XQDA algorithm and RLDA also learned a 100-dimensional subspace. The resulting Cumulative Matching Characteristic (CMC) curves are shown in <ref type="figure" target="#fig_3">Fig. 4 (a)</ref>. It can be seen that the proposed method is better than the compared metric learning algorithms. This indicates that XQDA successfully learns a discriminant subspace as well as an effective metric. Besides, we also investigate how the performance varies with different subspace dimensions, as shown in <ref type="figure" target="#fig_3">Fig. 4 (b)</ref>. It can be observed that XQDA consistently performs the best with all dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Comparison of Features</head><p>Next, we compared the proposed LOMO feature with other three available person re-identification features. The first feature is called Ensemble of Local Features (ELF), proposed in <ref type="bibr" target="#b9">[10]</ref>, and later modified by <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b48">49]</ref>. We used the implementation in <ref type="bibr" target="#b49">[50]</ref>, denoted by ELF6, which is computed from histograms in six equally divided horizontal stripes. Eight color channels (RGB, HSV, and YCbCr)   . CMC curves and rank-1 identification rates on the VIPeR database <ref type="bibr" target="#b8">[9]</ref> (P=316), by comparing the proposed LOMO feature to three available features, ELF6 <ref type="bibr" target="#b49">[50]</ref>, HSV+Lab+LBP <ref type="bibr" target="#b17">[18]</ref>, and gBiCov <ref type="bibr" target="#b32">[33]</ref>. and 21 texture filters (8 Gabor filters and 13 Schmid filters) are used for the histogram representation. The other feature is proposed in <ref type="bibr" target="#b17">[18]</ref>, which applied the HSV, and Lab color feature, as well as a texture feature extracted by LBP. The third feature called gBiCov 1 <ref type="bibr" target="#b32">[33]</ref> is a combination of Biologically Inspired Features (BIF) and Covariance descriptors. We applied both the direct Cosine similarity measure and the XQDA algorithm to compare the four different kinds of features, resulting in the CMC curves shown in <ref type="figure">Fig.  5</ref>. For consistency, in the following experiments we determined the subspace dimensions of XQDA automatically by accepting all eigenvalues of Σ −1 I Σ E that are larger than 1, as discussed earlier. From <ref type="figure">Fig. 5 (a)</ref> it can be seen that the raw LOMO feature outperforms the other existing features. What's more, <ref type="figure">Fig. 5 (b)</ref> shows that the performance improvement is more significant with the help of XQDA. Since these kinds of features are similar in fusing color and texture information, the improvement made by the proposed LOMO feature is mainly due to the specific consideration of handling illumination and viewpoint changes.   <ref type="figure">Figure 6</ref>. CMC curves and rank-1 identification rates on the VIPeR database <ref type="bibr" target="#b8">[9]</ref> (P=316) by comparing the proposed LOMO+XQDA method to other state of the art algorithms.  <ref type="bibr" target="#b23">[24]</ref>. Fusing different methods generally improves the performance. In fact, we also tried to fuse our method with LADF, and got a 50.32% rank-1 identification rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Comparison to the State of the Art</head><p>Finally, we compare the performance of the proposed approach to the state-of-the-art results reported on the VIPeR database, which are summarized in <ref type="figure">Fig. 6</ref> and <ref type="table" target="#tab_2">Table 1</ref>. Four methods, the SCNCD <ref type="bibr" target="#b43">[44]</ref>, kBiCov <ref type="bibr" target="#b32">[33]</ref>, LADF <ref type="bibr" target="#b23">[24]</ref>, and SalMatch <ref type="bibr" target="#b45">[46]</ref> report the best performances on the VIPeR dataset to date, which exceed 30% at rank 1. From <ref type="table" target="#tab_2">Table  1</ref> it can be observed that the proposed algorithm achieves the new state of the art, 40% at rank 1, outperforming the second best one SCNCD by 2.2%. <ref type="figure">Figure 7</ref>. Example pairs of images from the GRID database <ref type="bibr" target="#b30">[31]</ref>. Images in the same column represent the same person. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Experiments on QMUL GRID</head><p>The QMUL underGround Re-IDentification (GRID) dataset <ref type="bibr" target="#b30">[31]</ref> is another challenging person re-identification test bed but have not been largely noticed. The GRID dataset was captured from 8 disjoint camera views in a underground station. It contains 250 pedestrian image pairs, with each pair contains two images of the same person from different camera views. Besides, there are 775 additional images that do not belong to the 250 persons which can be used to enlarge the gallery set. Sample images from GRID can be found in <ref type="figure">Fig. 7</ref>. It can be seen that these images have poor image quality and low resolutions, and contain large variations of illumination and viewpoint.</p><p>An experimental setting of 10 random trials is provided for the GRID dataset. For each trial, 125 image pairs are used for training, and the remaining 125 image pairs, as well as the 775 background images are used for test. The ELF6 feature set described in <ref type="bibr" target="#b26">[27]</ref> is provided for developing machine learning algorithms.</p><p>We first applied the proposed method on the provided feature set of GRID. This leads to results of "ELF6+XQDA" listed in <ref type="table" target="#tab_3">Table 2</ref>. We compared available results from <ref type="bibr" target="#b29">[30]</ref> where the same feature set was used. Results shown in Table 2 indicates that the proposed joint dimension reduction and metric learning approach outperforms other distance learning algorithms such as RankSVM <ref type="bibr" target="#b38">[39]</ref>, PRDC <ref type="bibr" target="#b48">[49]</ref>, and MRank <ref type="bibr" target="#b29">[30]</ref>, except that the rank-1 accuracy of XQDA is slightly worse than MRank-RankSVM.</p><p>We also tried the proposed feature extraction method, and applied the same XQDA algorithm for metric learning. This corresponds to the results of the last row in <ref type="table" target="#tab_3">Table 2</ref>.</p><p>The comparison shows that the new feature improves the performance at rank 1-10. Especially, a 4.32% performance gain can be obtained for the rank-1 accuracy. This indicates that the new feature helps to reduce intra-class variations, so that the same person can be recognized at a higher rank. Note that the above methods all trained a general model independent of camera views. A research in <ref type="bibr" target="#b33">[34]</ref> show that the performance can be improved by utilizing the camera network information. Namely, their method MtMCML trained various metrics, each for a given camera view pair. We also followed this approach and trained several metrics depending on known camera pairs. Results listed in <ref type="table" target="#tab_4">Table 3</ref> show that, while with the ELF6 feature the proposed method only improves the rank-1 accuracy over MtMCML, with the new LOMO feature the proposed method is clearly better than MtMCML. However, in practice we do not suggest this way of training because the camera views under evaluation are usually unseen, and it is not easy to label data for new camera views to retrain the algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experiments on CUHK Campus</head><p>The CUHK Campus dataset was captured with two camera views in a campus environment. Different from the above datasets, images in this dataset are of higher resolution. The CUHK Campus dataset contains 971 persons, and each person has two images in each camera view. Camera A captures the frontal view or back view of pedestrians, while camera B captures the side views. All images were scaled to 160 × 60 pixels. The persons were split to 485 for training and 486 for test (multi-shot). The results are shown in <ref type="figure">Fig. 8</ref>. Our method largely outperforms existing state of the art methods. The best rank-1 identification rate reported to date is 34.30% <ref type="bibr" target="#b47">[48]</ref>, while we has achieved 63.21%, with an improvement of 28.91%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Experiments on CUHK03</head><p>The CUHK03 dataset <ref type="bibr" target="#b22">[23]</ref> includes 13,164 images of 1,360 pedestrians. It is currently the largest publicly available person re-identification dataset. The CUHK03 dataset was captured with six surveillance cameras over months, with each person observed by two disjoint camera views and having an average of 4.8 images in each view. In addition to manually cropped pedestrian images, samples detected  <ref type="figure">Figure 8</ref>. Multi-shot CMC curves and rank-1 identification rates on the CUHK Campus database <ref type="bibr" target="#b21">[22]</ref> (P=486, M=2). The compared results are from <ref type="bibr" target="#b47">[48]</ref>. <ref type="table">Table 4</ref>. Comparison of state-of-the-art rank-1 identification rates (%) on the CUHK03 database <ref type="bibr" target="#b22">[23]</ref> with both labeled and detected setting (P=100). The compared results are from <ref type="bibr" target="#b22">[23]</ref>.</p><p>Labeled Detected LOMO+XQDA 52.20 <ref type="bibr">46.25 DeepReID [23]</ref> 20.65 19.89 KISSME <ref type="bibr" target="#b17">[18]</ref> 14.17 11.70 LDML <ref type="bibr" target="#b10">[11]</ref> 13.51 10.92 eSDC <ref type="bibr" target="#b46">[47]</ref> 8.76 7.68 LMNN <ref type="bibr" target="#b42">[43]</ref> 7.29 6.25 ITML <ref type="bibr" target="#b3">[4]</ref> 5.53 5.14 SDALF <ref type="bibr" target="#b1">[2]</ref> 5.60 4.87</p><p>with a state-of-the-art pedestrian detector is also provided. This is a more realistic setting considering misalignment, occlusions and body part missing.</p><p>We run our algorithm with the same setting of <ref type="bibr" target="#b22">[23]</ref>. That is, the dataset was partitioned into a training set of 1,160 persons and a test set of 100 persons. The experiments were conducted with 20 random splits and all the CMC curves were computed with the single-shot setting. The rank-1 identification rates of various algorithms in both labeled and detected setting are shown in <ref type="table">Table 4</ref>. The proposed method achieved 52.20% and 46.25% rank-1 identification rates with the labeled bounding boxes and the automatically detected bounding boxes, respectively, which clearly outperform the state-of-the-art method DeepReID <ref type="bibr" target="#b22">[23]</ref>, with an improvement of 31.55% for the labelled setting, and 26.36% for the detected setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.">Analysis of the Proposed Method</head><p>To better understand the proposed method, we analyze it in several aspects: role of Retinex, role of the local maximal occurrence operation, influence of subspace dimensions, and the running time. The analysis was performed on the VIPeR database, by randomly sampling a training set of 316 persons, and a test set of the remaining persons. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.1">Role of Retinex</head><p>We compared the proposed LOMO feature with and without the Retinex preprocessing, with results shown in <ref type="figure" target="#fig_6">Fig. 9</ref> (a) and (b). This comparison was done by using the direct Cosine similarity measure and the XQDA algorithm, respectively. From <ref type="figure" target="#fig_6">Fig. 9</ref> (a) we can see that, for direct matching, the performance can be obviously improved by applying the Retinex transform, with rank-1 accuracy being 12.97% without Retinex, and 20.25% with Retinex. This result indicates that Retinex helps to derive a consistent color representation across different camera views, as can also be observed from <ref type="figure" target="#fig_0">Fig. 1 (b)</ref>. However, From <ref type="figure" target="#fig_6">Fig. 9 (b)</ref> it can be seen that the two features are boosted by XQDA to a similar performance. This may indicate that XQDA is able to learn a robust metric against illumination variations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.2">Role of Local Maximal Occurrence</head><p>The person re-identification performance is largely affected by viewpoint changes, which should be addressed in feature design or classifier learning. The proposed local maximal occurrence feature extraction is a strategy towards pose or viewpoint robust feature representation. By comparing the proposed feature with and without the local maximal occurrence operation, we find that this operation does largely improve the performance of cross-view person reidentification, as shown in <ref type="figure" target="#fig_6">Fig. 9 (a)</ref> and (b). Without the local maximal occurrence operation, the rank-1 accuracy by applying the Cosine similarity measure ( <ref type="figure" target="#fig_6">Fig. 9 (a)</ref>) is 11.39%, while applying this strategy, the rank-1 accuracy is improved to 20.25%. When further applying XQDA ( <ref type="figure" target="#fig_6">Fig. 9  (b)</ref>), the performance gap is reduced, but the proposed feature still performs quite better with the local maximal occurrence operation than without it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.3">Subspace Dimensions</head><p>For the proposed XQDA algorithm, the dimension of the learned subspace has an influence in performance. This influence is shown in <ref type="figure" target="#fig_6">Fig. 9 (c)</ref>, obtained by applying XQDA with different subspace dimensions on the VIPeR dataset. Roughly, the performance is increasing with increasing dimensions, but it becomes stable after 100 dimensions. Therefore, it is not too difficult to determine a proper number of subspace dimensionality. We use an automatic way as specified by accepting all eigenvalues of Σ −1 I Σ E that are larger than 1, which works quite well in all the experiments. However, one can also select a small value considering the computational complexity. As can be observed from <ref type="figure" target="#fig_6">Fig. 9 (c)</ref>, the rank-1 accuracy is consistently larger than 30% when the subspace dimensions are larger than 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5.4">Running Time</head><p>The training time comparison of metric learning algorithms is shown in <ref type="table" target="#tab_6">Table 5</ref> (including subspace learning time). The training time was averaged over 10 random trials on the VIPeR dataset. All algorithms are implemented in MAT-LAB. The LMNN algorithm has MEX functions implemented in C or C++ to accelerate the computation. The training was performed on a desktop PC with an Intel i5-2400 @3.10GHz CPU. <ref type="table" target="#tab_6">Table 5</ref> shows that the KISSME, RLDA, and XQDA algorithms, which have closed-form solutions, are very efficient, while ITML and LMNN, which require iterative optimizations, are time consuming.</p><p>Besides, we also evaluated the running time of the proposed feature extractor. In processing 128 × 48 person images, the LOMO feature extractor requires 0.012 seconds per image on average, which is very efficient. This code is also implemented in MATLAB, with a MEX function implemented for Retinex. Considering the effectiveness and efficiency of both the proposed LOMO feature and XQDA algorithm, we release both codes 2 for future research and benchmark on person re-identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Summary and Future Work</head><p>In this paper, we have presented an efficient and effective method for person re-identification. We have proposed an efficient descriptor called LOMO, which is shown to be robust against viewpoint changes and illumination variations. We have also proposed a subspace and metric learning approach called XQDA, which is formulated as a Generalized Rayleigh Quotient, and a closed-form solution can be obtained by the generalized eigenvalue decomposition. Practical computation issues for XQDA have been discussed, including the simplified computation, the regularization, and the dimension selection. Experiments on four challenging person re-identification databases, VIPeR, QMUL GRID, CUHK Campus, and CUHK03, show that the proposed method improves the state-of-the-art rank-1 identification rates by 2.2%, 4.88%, 28.91%, and 31.55% on the four databases, respectively. Due to the promising performance of the LOMO feature, it would be interesting to study other local features (e.g. Gabor, other color descriptors, etc.) or feature coding approaches with the same LOMO idea for person re-identification. It is also interesting to see the application of XQDA to other cross-view matching problems, such as the heterogeneous face recognition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>(a) Example pairs of images from the VIPeR database [9]. (b) Processed images in (a) by Retinex. Images in the same column represent the same person.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of the LOMO feature extraction method.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Distributions of ΩI and ΩE in one projected dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Comparison of metric learning algorithms with the same LOMO feature on the VIPeR database [9] (P=316). (a) CMC curves with feature reduced to 100 dimensions. (b) Rank-1 identification rates with varying subspace dimensions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 5. CMC curves and rank-1 identification rates on the VIPeR database [9] (P=316), by comparing the proposed LOMO feature to three available features, ELF6 [50], HSV+Lab+LBP [18], and gBiCov [33].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>CMC curves comparing the proposed feature with and without Retinex and the local maximal occurrence operation ((a) Cosine and (b) XQDA). (c) Rank-1 accuracy with varying subspace dimensions for the XQDA algorithm with LOMO feature.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>40.00%, LOMO+XQDA 31.11%, kBiCov 30.22%, LADF 30.16%, SalMatch 29.11%, Mid−level Filter 28.83%, MtMCML 27.00%, RPLM 25.60%, SSCDL 24.21%, ColorInv 24.18%, LF 19.87%, SDALF 19.60%, KISSME 19.27%, PCCA 16.14%, WELF6+PRDC 15.66%, PRDC 12.00%, ELF</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Comparison of state-of-the-art results reported with the VIPeR database (P=316). The cumulative matching scores (%) at rank 1, 10, and 20 are listed.</figDesc><table><row><cell>Method</cell><cell>rank=1rank=10rank=20</cell><cell>Reference</cell></row><row><cell cols="2">LOMO+XQDA 40.00 80.51 91.08</cell><cell>Proposed</cell></row><row><cell>SCNCD</cell><cell cols="2">37.80 81.20 90.40 2014 ECCV [44]</cell></row><row><cell>kBiCov</cell><cell>31.11 70.71 82.45</cell><cell>2014 IVC [33]</cell></row><row><cell>LADF</cell><cell cols="2">30.22 78.92 90.44 2013 CVPR [24]</cell></row><row><cell>SalMatch</cell><cell cols="2">30.16 65.54 79.15 2013 ICCV [46]</cell></row><row><cell cols="3">Mid-level Filter  *  29.11 65.95 79.87 2014 CVPR [48]</cell></row><row><cell>MtMCML</cell><cell>28.83 75.82 88.51</cell><cell>2014 TIP [34]</cell></row><row><cell>RPLM</cell><cell cols="2">27.00 69.00 83.00 2012 ECCV [14]</cell></row><row><cell>LDFV</cell><cell cols="2">26.53 70.88 84.63 2012 ECCVW [32]</cell></row><row><cell>SSCDL</cell><cell cols="2">25.60 68.10 83.60 2014 CVPR [28]</cell></row><row><cell>ColorInv</cell><cell cols="2">24.21 57.09 69.65 2013 TPAMI [19]</cell></row><row><cell>LF</cell><cell cols="2">24.18 67.12 82.00 2013 CVPR [38]</cell></row><row><cell>SDALF</cell><cell>19.87 49.37 65.73</cell><cell>2013 CVIU [2]</cell></row><row><cell>KISSME</cell><cell cols="2">19.60 62.20 77.00 2012 CVPR [18]</cell></row><row><cell>PCCA</cell><cell cols="2">19.27 64.91 80.28 2012 CVPR [35]</cell></row><row><cell cols="3">WELF6+PRDC 16.14 50.98 65.95 2012 ECCVW [27]</cell></row><row><cell>PRDC</cell><cell cols="2">15.66 53.86 70.09 2013 TPAMI [50]</cell></row><row><cell>ELF</cell><cell cols="2">12.00 44.00 61.00 2008 ECCV [10]</cell></row><row><cell></cell><cell></cell><cell></cell></row></table><note>* Note that [48] reports a 43.39% rank-1 accuracy by fusing their method with LADF</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Comparison of state-of-the-art results on the GRID database (P=900) without camera network information. Red and blue numbers are the best and second best results, respectively.</figDesc><table><row><cell>Method</cell><cell>rank=1rank=10rank=20</cell></row><row><cell>ELF6 + L1-norm [30]</cell><cell>4.40 16.24 24.80</cell></row><row><cell>ELF6 + RankSVM [39]</cell><cell>10.24 33.28 43.68</cell></row><row><cell>ELF6 + PRDC [50]</cell><cell>9.68 32.96 44.32</cell></row><row><cell cols="2">ELF6 + MRank-RankSVM [30] 12.24 36.32 46.56</cell></row><row><cell cols="2">ELF6 + MRank-PRDC [30] 11.12 35.76 46.56</cell></row><row><cell>ELF6 + XQDA</cell><cell>10.48 38.64 52.56</cell></row><row><cell>LOMO + XQDA</cell><cell>16.56 41.84 52.40</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Comparison of state-of-the-art results on the GRID database (P=900) with camera network information. Red and blue numbers are the best and second best results, respectively.</figDesc><table><row><cell>Method</cell><cell>rank=1rank=10rank=20</cell></row><row><cell cols="2">ELF6 + MtMCML [34] 14.08 45.84 59.84</cell></row><row><cell>ELF6 + XQDA</cell><cell>16.32 40.72 51.76</cell></row><row><cell>LOMO + XQDA</cell><cell>18.96 52.56 62.24</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Training time (seconds) of metric learning algorithms.</figDesc><table><row><cell></cell><cell cols="4">XQDA KISSME RLDA ITML LMNN</cell></row><row><cell>Time</cell><cell>1.86</cell><cell>1.34</cell><cell>1.53</cell><cell>36.78 265.28</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We used the author's implementation (available in http://vipl. ict.ac.cn/members/bpma) and the default parameters, which may not reflect the best status.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://www.cbsr.ia.ac.cn/users/scliao/ projects/lomo_xqda/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was supported by the Chinese National Natural Science Foundation Projects #61203267, #61375037, #61473291, National Science and Technology Support Program #2013BAK02B01, Chinese Academy of Sciences Project No. KGZD-EW-102-2, and AuthenMetric R&amp;D Funds.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Distance metric learning vs. fisher discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Alipanahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Biggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghodsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on Artificial intelligence</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Symmetry-driven accumulation of local features for human characterization and re-identification. Computer Vision and Image Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Custom pictorial structures for re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stoppa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Information-theoretic metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="209" to="216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Pedestrian recognition with a learned metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dikmen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Akbas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ACCV 2010</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="501" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Person re-identification by symmetry-driven accumulation of local features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farenzena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2360" to="2367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Person reidentification using spatiotemporal appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gheissari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hartley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1528" to="1535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Person Re-Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Evaluating appearance models for recognition, reacquisition, and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brennan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International workshop on performance evaluation of tracking and surveillance</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Viewpoint invariant pedestrian recognition with an ensemble of localized features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Is that you? metric learning approaches for face identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Person re-identification in multi-camera system by signature based on interest point descriptors collected on short video sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hamdoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moutarde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stanciulescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDSC</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<title level="m">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Relaxed pairwise learned metric for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Köstinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision. 2012. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Exploring structural information and fusing multiple features for person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A multiscale retinex for bridging the gap between color images and the human observation of scenes. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Jobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-U</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Woodell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="965" to="976" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Properties and performance of a center/surround retinex. Image Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Jobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-U</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Woodell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="451" to="462" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Large scale metric learning from equivalence constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kostinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wohlhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Color invariants for person reidentification. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kviatkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rivlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1622" to="1634" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Lightness and retinex theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Land</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mccann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JOSA</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Locally aligned feature transforms across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Human reidentification with transferred metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Assian Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">DeepReID: Deep filter pairing neural network for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning locally-adaptive decision functions for person verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Heterogeneous face recognition from local structures of normalized appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Biometrics</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Modeling pixel process with scale invariant local patterns for background subtraction in complex scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kellokumpu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Computer Society Conference on Computer Vision and Pattern Recognition<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-06" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Person reidentification: what features are important?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2012. Workshops and Demonstrations</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Semi-supervised coupled dictionary learning for person reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Person re-identification based on visual saliency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Intelligent Systems Design and Applications (ISDA), 2012 12th International Conference on</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="884" to="889" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Person re-identification by manifold ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-camera activity correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1988" to="1995" />
		</imprint>
	</monogr>
	<note>CVPR 2009. IEEE Conference on</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Local descriptors encoded by fisher vectors for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision Workshops</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Covariance descriptor based on bio-inspired features for person re-identification and face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="379" to="390" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Person re-identification over camera networks using multi-task distance metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pcca: A new approach for distance learning from sparse pairwise constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Bayesian face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moghaddam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A comparative study of texture measures with classification based on feature distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Harwood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="59" />
			<date type="published" when="1996-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Local fisher discriminant analysis for pedestrian re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pedagadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Orwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Velastin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boghossian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Person re-identification by support vector ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Prosser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Mary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">People reidentification in surveillance and forensics: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vezzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baltieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">29</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Shape and appearance context modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rittscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Regionlets for generic object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Distance metric learning for large margin nearest neighbor classification. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Saul</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Salient color names for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Efficient model selection for regularized linear discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Janardan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cherkassky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kambhamettu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM Conference on Information and Knowledge Management</title>
		<meeting>the ACM Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Person re-identification by salience matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Unsupervised salience learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning mid-level filters for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Person re-identification by probabilistic relative distance comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="649" to="656" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Reidentification by relative distance comparison. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
