<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Face Alignment Across Large Poses: A 3D Solution</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhu</surname></persName>
							<email>xiangyu.zhu@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lei</surname></persName>
							<email>zlei@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Michigan State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hailin</forename><surname>Shi</surname></persName>
							<email>hailin.shi@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
							<email>szli@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Face Alignment Across Large Poses: A 3D Solution</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Face alignment, which fits a face model to an image and extracts the semantic meanings of facial pixels, has been an important topic in CV community. However, most algorithms are designed for faces in small to medium poses (below 45 • ), lacking the ability to align faces in large poses up to 90 • . The challenges are three-fold: Firstly, the commonly used landmark-based face model assumes that all the landmarks are visible and is therefore not suitable for profile views. Secondly, the face appearance varies more dramatically across large poses, ranging from frontal view to profile view. Thirdly, labelling landmarks in large poses is extremely challenging since the invisible landmarks have to be guessed. In this paper, we propose a solution to the three problems in an new alignment framework, called 3D Dense Face Alignment (3DDFA), in which a dense 3D face model is fitted to the image via convolutional neutral network (CNN). We also propose a method to synthesize large-scale training samples in profile views to solve the third problem of data labelling. Experiments on the challenging AFLW database show that our approach achieves significant improvements over state-of-the-art methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Traditional face alignment aims to locate face fiducial points like "eye corner", "nose tip" and "chin center", based on which the face image can be normalized. It is an essential preprocessing step for many face analysis tasks, e.g., face recognition <ref type="bibr" target="#b40">[41]</ref>, expression recognition <ref type="bibr" target="#b4">[5]</ref> and inverse rendering <ref type="bibr" target="#b0">[1]</ref>. The researches in face alignment can be divided into two categories: the analysis-by-synthesis based <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b14">15]</ref> and regression based <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b44">45]</ref>. The former simulates the process of image generation and achieves alignment by minimizing the difference between model appearance and input image. The latter extracts features around key points and regresses it to the ground truth landmarks. With the development in the last decade, face alignment across medium poses, where the yaw angle is less than 45 • and all the landmarks are visible, has been well addressed <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b53">54]</ref>. However, face alignment across large poses (±90 • ) is still a challenging problem without much attention and achievements. There are three main challenges: <ref type="figure">Figure 1</ref>. Fitting results of 3DDFA. For each pair of the four results, on the left is the rendering of the fitted 3D shape with the mean texture, which is made transparent to demonstrate the fitting accuracy. On the right is the landmarks overlayed on the 3D face model, in which the blue/red ones indicate visible/invisible landmarks. The visibility is directly computed from the fitted dense model by <ref type="bibr" target="#b20">[21]</ref>. More results are demonstrated in supplemental material.</p><p>Modelling: Landmark shape model <ref type="bibr" target="#b12">[13]</ref> implicitly assumes that each landmark can be robustly detected based on its distinctive visual patterns. However, when faces deviate from the frontal view, some landmarks become invisible due to self-occlusion <ref type="bibr" target="#b52">[53]</ref>. In medium poses, this problem can be addressed by changing the semantic positions of face contour landmarks to the silhouette, which is termed landmark marching <ref type="bibr" target="#b54">[55]</ref>. However, in large poses where half of face is occluded, some landmarks are inevitably invisible and have no image data. As a result, the landmark shape model no longer works well.</p><p>Fitting: Face alignment across large poses is more challenging than medium poses due to the dramatic appearance variations when close to the profile views. The cascaded linear regression <ref type="bibr" target="#b44">[45]</ref> or traditional nonlinear models <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b9">10]</ref> are not sophisticated enough to cover such complicated patterns in a unified way. The view-based framework, which adopts different landmark configurations and fitting models for each view category <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b37">38]</ref>, may significantly increase computation cost since every view has to be tested.</p><p>Data Labelling: The most serious problem comes from the data. Manual labelling landmarks on large-pose faces is a very tedious task. Firstly, no algorithm can provide a good initialization to reduce the workload. Secondly, the occluded landmarks have to be "guessed" which is impossible for most of people. As a result, almost all public face alignment databases such as AFW <ref type="bibr" target="#b55">[56]</ref>, LFPW <ref type="bibr" target="#b21">[22]</ref>, HELEN <ref type="bibr" target="#b25">[26]</ref> and IBUG <ref type="bibr" target="#b34">[35]</ref> are collected in medium poses. Existing large-pose databases such as AFLW <ref type="bibr" target="#b24">[25]</ref> only contains visible landmarks, which could be ambiguous in invisible landmarks and hard to train a unified face alignment model.</p><p>In this paper, we address all the three challenges with the goal of improving the face alignment performance across large poses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">To address the problem of invisible landmarks in large</head><p>poses, we propose to fit the 3D dense face model rather than the sparse landmark shape model to the image. By incorporating 3D information, the appearance variations and self-occlusion caused by 3D transformations can be inherently addressed. We call this method 3D Dense Face Alignment (3DDFA). Some results are shown in <ref type="figure">Fig. 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.</head><p>To resolve the fitting process in 3DDFA, we propose a cascaded convolutional neutral network (CNN) based regression method. CNN has been proved of excellent capability to extract useful information from images with large variations in object detection <ref type="bibr" target="#b47">[48]</ref> and image classification <ref type="bibr" target="#b39">[40]</ref>. In this work, we adopt CNN to fit the 3D face model with a specifically designed feature, namely Projected Normalized Coordinate Code (PNCC). Besides, Weighted Parameter Distance Cost (WPDC) is proposed as the cost function. To the best of our knowledge, this is the first attempt to solve the 3D face alignment with CNN.</p><p>3. To enable the training of the 3DDFA, we construct a face database containing pairs of 2D face images and 3D face models. We further propose a face profiling algorithm to synthesize 60k+ training samples across large poses. The synthesized samples well simulate the face appearances in large poses and boost the performance of both prior and our proposed face alignment algorithms.</p><p>The database, face profiling code and 3DDFA code are released at http://www.cbsr.ia.ac.cn/users/ xiangyuzhu/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Generic Face Alignment: Face alignment in 2D aims at locating a sparse set of fiducial facial landmarks. A number of achievements have been made including the classic Active Appearance Model (AAM) <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b41">42]</ref> and Constrained Local Model (CLM) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b1">2]</ref>. Recently, the regression based method, which maps the discriminative features around landmarks to the desired landmark positions <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b26">27]</ref>, has been proposed. By utilizing the feedback characteristic that the the output (landmark positions) of the regression has an influence on the input (features at landmarks), the cascaded regression <ref type="bibr" target="#b16">[17]</ref> cascades a list of weak regressors to reduce the alignment error progressively and reaches the state of the art <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b53">54]</ref>.</p><p>Besides traditional models, convolutional neutral network (CNN) has also been employed in face alignment recently. Sun et al. <ref type="bibr" target="#b38">[39]</ref> firstly use CNN to regress landmark locations with the raw face image. Liang et al. <ref type="bibr" target="#b27">[28]</ref> improve the flexibility by estimating the landmark response map. Zhang et al. <ref type="bibr" target="#b50">[51]</ref> further combine face alignment with attribute analysis through multi-task CNN to boost the performance of both tasks. Although with considerable achievements, most CNN methods only detect a sparse set of landmarks (5 points in <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b27">28]</ref>) with limited descriptive power of face shape.</p><p>Large Pose Face Alignment: Despite the great attentions on face alignment, literature on large-pose scenario is rather limited. The most common method is the multiview framework <ref type="bibr" target="#b13">[14]</ref>, which uses different landmark configurations for different views. For example, TSPM <ref type="bibr" target="#b55">[56]</ref> and CDM <ref type="bibr" target="#b48">[49]</ref> employ DPM-like <ref type="bibr" target="#b17">[18]</ref> method to align faces with different shape models, among which the highest possibility is chosen as the final result. However, since every view has to be tested, the computation cost of multi-view method is always high.</p><p>Besides 2D methods, 3D face alignment <ref type="bibr" target="#b18">[19]</ref>, which aims to fit a 3D morphable model (3DMM) <ref type="bibr" target="#b5">[6]</ref> from a 2D image, also has the potential to deal with large poses. It models the 3D face shape with a linear subspace (PCA <ref type="bibr" target="#b5">[6]</ref> or Tensor <ref type="bibr" target="#b7">[8]</ref>) and achieves fitting by minimizing the difference between image and model appearance. 3DMM can cover arbitrary poses <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b32">33]</ref> but suffers from the oneminute-per-image computation cost. Recently, regression based 3DMM fitting, which estimates the model parameters by regressing the features at landmark positions <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b22">23]</ref>, has been proposed to improve the efficiency. However, since the features at landmarks may be self-occluded as in 2D methods, the fitting algorithm is no longer poseinvariant and suffers from the three problems in Section 1. A relevant but different problem is the 3D face reconstruction <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b19">20]</ref>, which recovers a 3D face from given 2D landmarks. Interestingly, based on that 2D/3D face alignment results can be mutually transformed, where 3D to 2D is made by selecting x, y coordinates of landmark vertexes and 2D to 3D is made by 3D face reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">3D Dense Face Alignment (3DDFA)</head><p>In this section we introduce the 3D Dense Face Alignment (3DDFA) which fits 3D morphable model with cascaded CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">3D Morphable Model</head><p>Blanz et al. <ref type="bibr" target="#b5">[6]</ref> propose the 3D morphable model (3DMM) which describes the 3D face space with PCA:</p><formula xml:id="formula_0">S = S + A id α id + A exp α exp ,<label>(1)</label></formula><p>where S is a 3D face, S is the mean shape, A id is the principle axes trained on the 3D face scans with neutral expression and α id is the shape parameter, A exp is the principle axes trained on the offsets between expression scans and neutral scans and α exp is the expression parameter. In this work, the A id and A exp come from BFM <ref type="bibr" target="#b30">[31]</ref> and Face-Warehouse <ref type="bibr" target="#b8">[9]</ref> respectively. The 3D face is then projected onto the image plane with Weak Perspective Projection:</p><formula xml:id="formula_1">V (p) = f * Pr * R * (S+A id α id +A exp α exp )+t 2d ,<label>(2)</label></formula><p>where V (p) is the model construction and projection function, leading to the 2D positions of model vertexes, f is the scale factor, Pr is the orthographic projection matrix 1 0 0 0 1 0 , R is the rotation matrix constructed from rotation angles pitch, yaw, roll and t 2d is the translation vector. The collection of all the model parameters is p = [f, pitch, yaw, roll, t 2d , α id , α exp ] T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Network Structure</head><p>The purpose of 3D face alignment is estimating p from a single face image I. Unlike existing CNN methods <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b27">28]</ref> which apply different networks for different fitting stages, 3DDFA employ a unified network structure across the cascade. In general, at iteration k (k = 0, 1, ..., K), given an initial parameter p k , we construct a specially designed feature PNCC with p k and train a convolutional neutral network Net k to predict the parameter update ∆p k :</p><formula xml:id="formula_2">∆p k = Net k (I, PNCC(p k )).<label>(3)</label></formula><p>Afterwards, a better medium parameter p k+1 = p k + ∆p k becomes the input of the next network Net k+1 which has the same structure as Net k . <ref type="figure">Fig. 2</ref> shows the network structure. The input is the 100 × 100 × 3 color image stacked by PNCC. The network contains four convolution layers, three pooling layers and two fully connected layers. The first two convolution layers share weights to extract low-level features. The last two convolution layers do not share weights to extract location sensitive features, which is further regressed to a 256-dimensional feature vector. The output is a 234-dimensional parameter update including 6-dimensional pose parameters [f, pitch, yaw, roll, t 2dx , t 2dy ], 199-dimensional shape parameters α id and 29-dimensional expression parameters α exp .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Projected Normalized Coordinate Code</head><p>The special structure of the cascaded CNN has three requirements of its input feature: Firstly, the feedback property requires that the input feature should depend on the CNN output to enable the cascade manner. Secondly, the convergence property requires that the input feature should reflect the fitting accuracy to make the cascade converge after some iterations <ref type="bibr" target="#b56">[57]</ref>. Finally, the convolvable property requires that the convolution on the input feature should make sense. Based on the three properties, we design our features as follows: Firstly, the 3D mean face is normalized to 0 − 1 in x, y, z axis as Equ. 4. The unique 3D coordinate of each vertex is called its Normalized Coordinate Code (NCC), see <ref type="figure" target="#fig_0">Fig. 3</ref>(a).</p><formula xml:id="formula_3">NCC d = S d − min(S d ) max(S d ) − min(S d ) (d = x, y, z),<label>(4)</label></formula><p>where the S is the mean shape of 3DMM in Equ. 1. Since NCC has three channels as RGB, we also show the mean face with NCC as its texture. Secondly, with a model parameter p, we adopt the Z-Buffer to render the projected 3D face colored by NCC as in Equ. 5, which is called the Projected Normalized Coordinate Code (PNCC), see </p><formula xml:id="formula_4">PNCC = Z-Buffer(V 3d (p), NCC) V 3d (p) = f * R * S + [t 2d , 0] T<label>(5)</label></formula><formula xml:id="formula_5">S = S + A id α id + A exp α exp ,</formula><p>where Z-Buffer(ν, τ ) renders an image from the 3D mesh ν colored by τ and V 3d (p) is the current 3D face. Afterwards, <ref type="figure">Figure 2</ref>. An overview of 3DDFA. At kth iteration, Net k takes a medium parameter p k as input, constructs the projected normalized coordinate code (PNCC), stacks it with the input image and sends it into CNN to predict the parameter update ∆p k .</p><p>PNCC is stacked with the input image and transferred to CNN. Regarding the three properties, PNCC fulfills the feedback property since in Equ. 5, p is the output of CNN and NCC is a constant. Secondly, PNCC provides the 2D locations of visible 3D vertexes on the image plane. When CNN detects that each NCC superposes its corresponding image pattern during testing, the cascade will converge. PNCC fulfills the convergence property. Note that the invisible region is automatically ignored by Z-Buffer. Finally, PNCC is smooth in 2D space, the convolution indicates the linear combination of NCCs on a local patch. It fulfills the convolvable property.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Cost Function</head><p>The performance of CNN can be greatly impacted by the cost function, which is difficult to design in 3DDFA since each dimension of the CNN output (model parameter) has different influence on the 3DDFA result (fitted 3D face). In this work, we discuss two baselines and propose a novel cost function. Since the parameter range varies significantly, we conduct z-score normalization before training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Parameter Distance Cost (PDC)</head><p>Take the first iteration as an example. The purpose of CNN is predicting the parameter update ∆p to move the initial parameter p 0 closer to the ground truth p g . Intuitively, we can minimize the distance between the ground truth and the current parameter with the Parameter Distance Cost (PDC):</p><formula xml:id="formula_6">E pdc = ∆p − (p g − p 0 ) 2 .<label>(6)</label></formula><p>Even though PDC has been used in 3D face alignment <ref type="bibr" target="#b56">[57]</ref>, there is a problem that each dimension in p has different influence on the resultant 3D face. For example, with the same deviation, the yaw angle will bring a larger alignment error than a shape PCA coefficient, while PDC optimizes them equally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Vertex Distance Cost (VDC)</head><p>Since 3DDFA aims to morph the 3DMM to the ground truth 3D face, we can optimize ∆p by minimizing the vertex distances between the fitted and the ground truth 3D face:</p><formula xml:id="formula_7">E vdc = V (p 0 + ∆p) − V (p g ) 2 ,<label>(7)</label></formula><p>where V (·) is the face construction and weak perspective projection as Equ. 2. This cost is called the Vertex Distance Cost (VDC) and the derivative is provided in supplemental material. Compared with PDC, VDC better models the fitting error by explicitly considering the semantics of each parameter. However, we observe that VDC exhibits pathological curvature <ref type="bibr" target="#b28">[29]</ref>. The directions of pose parameters always exhibit much higher curvatures than the PCA coefficients. As a result, optimizing VDC with gradient descend converges very slowly due to the "zig-zagging" problem. Second-order optimizations are preferred but they are expensive and hard to be implemented on GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Weighted Parameter Distance Cost (WPDC)</head><p>In this work, we propose a simple but effective cost function Weighted Parameter Distance Cost (WPDC). The basic idea is explicitly modeling the importance of each parameter:</p><formula xml:id="formula_8">E wpdc = (∆p − (p g − p 0 )) T W(∆p − (p g − p 0 )) where W = diag(w 1 ,w 2 , ..., w n ) w i = V (p d (i))−V (p g ) / w i p d (i) i = (p 0 + ∆p) i p d (i) j = p g j , j ∈ {1, . . . , i − 1, i + 1, . . . , n},<label>(8)</label></formula><p>where W is the importance matrix whose diagonal is the weight of each parameter, p d (i) is the i-deteriorated parameter whose ith component comes from the predicted parameter (p 0 + ∆p) and the others come from the ground truth parameter p g , V (p d (i)) − V (p g ) models the alignment error brought by miss-predicting the ith model parameter, which is indicative of its importance. For simplicity, W is considered as a constant when computing the derivative. In the training process, CNN firstly concentrate on the parameters with larger V (p d (i)) − V (p g ) such as scale, rotation and translation. As p d (i) is closer to p g , the weights of these parameters begin to shrink and CNN will optimize less important parameters but at the same time keep the high-priority parameters sufficiently good. Compared with VDC, the WPDC remedies the pathological curvature issue and is easier to implement without the derivative of V (·).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Face Profiling</head><p>All the discriminative models rely on the training data, especially for CNN which has thousands of parameters to train. Therefore, massive labelled faces across large poses are crucial for 3DDFA. However, few of released face alignment database contains large-pose samples <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b34">35]</ref> since labelling standardized landmarks on profile is very challenging. In this section, we demonstrate that labelled profile faces can be well simulated from existing training samples with the help of 3D information. Inspired by the recent breakthrough in face frontalization <ref type="bibr" target="#b54">[55,</ref><ref type="bibr" target="#b20">21]</ref> which generates the frontal view of faces, we propose to invert this process to generate the profile view of faces from mediumpose samples, which is called face profiling. The basic idea is predicting the depth of face image and generating the profile views with 3D rotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">3D Image Meshing</head><p>The depth estimation of a face image can be conducted on the face region and external region respectively, with different requirements of accuracy. On the face region, we fit a 3DMM through the Multi-Features Framework <ref type="bibr" target="#b32">[33]</ref> (MFF), see <ref type="figure" target="#fig_2">Fig. 4(b)</ref>. With the ground truth landmarks as a solid constraint throughout the fitting process, the MFF can always converge to a very good result. Few failed samples can be easily adjusted manually. On the external region, we follow the 3D meshing method proposed by Zhu et al. <ref type="bibr" target="#b54">[55]</ref> to mark some anchors beyond the face region and estimate their depth, see <ref type="figure" target="#fig_2">Fig. 4(c)</ref>. Afterwards the whole image is tuned into a 3D object through triangulation, see <ref type="figure" target="#fig_2">Fig. 4</ref>(c)4(d). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">3D Image Rotation</head><p>When the depth information is estimated, the face image can be rotated in 3D space to generate the appearances in larger poses <ref type="figure" target="#fig_3">(Fig. 5</ref>). It can be seen that the external face region is necessary for a realistic profile image. Different from face frontalization, with larger rotation angles the self-occluded region can only be expanded. As a result, we avoid the troubling invisible region filling which may produce large artifacts <ref type="bibr" target="#b54">[55]</ref>. In this work, we enlarge the yaw of the depth image at the step of 5 • until 90 • . Through face profiling, we not only obtain the face appearances in large poses and but also augment the dataset to a large scale, which means the CNN can be well trained even given a small database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implementation Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Initialization Regeneration</head><p>With a huge number of parameters, CNN tends to overfit the training set and the networks at deeper cascade might receive training samples with almost zero errors. Therefore we cannot directly adopt the cascade framework as in 2D face alignment. Asthana et al. <ref type="bibr" target="#b2">[3]</ref> demonstrates that the initializations at each iteration can be well simulated with statistics. In this paper, we also regenerate the p k but with a more sophisticated method. We observe that the fitting error highly depends on the ground truth face posture (FP). For example, the error of a profile face is mostly caused by a small yaw angle and the error of an open-mouth face is always caused by a close-mouth expression parameter. As a result, it is reasonable to model the perturbation of a training sample with a set of similar-FP samples. In this paper, we define the face posture as the ground truth 2D landmarks without scale and translation: FP = Pr * R g * (S + A id α g id + A exp α g exp ) landmark , (9) where R g , α g id , α g exp represent the ground truth pose, shape and expression respectively and the subscript landmark means only landmark points are selected. Before training, we select two folds of samples as the validation set. For each training sample, we construct a validation subset {v 1 , ..., v m } whose members share similar FP with the training sample. At iteration k, we regenerate the initial parameter by:</p><formula xml:id="formula_9">p k = p g − (p g vi − p k vi ),<label>(10)</label></formula><p>where p k and p g are the initial and ground truth parameter of a training sample, p k vi and p g vi come from a validation sample v i which is randomly chosen from the corresponding validation subset. Note that v i is never used in training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Landmark Refinement</head><p>Dense face alignment method fits all the vertexes of the face model by estimating the model parameters. If we are only interested in a sparse set of points such as landmarks, the error can be further reduced by relaxing the PCA constraint. In the 2D face alignment task, after 3DDFA we extract HOG features at landmarks and train a linear regressor to refine the landmark locations. In fact, 3DDFA can team with any 2D face alignment methods. In the experiment, we also report the results refined by SDM <ref type="bibr" target="#b44">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Experiments</head><p>In this section, we evaluate the performance of 3DDFA in three common face alignment tasks in the wild, i.e., medium-pose face alignment, large-pose face alignment and 3D face alignment. Due to the space constraint, qualitative alignment results are shown in supplemental material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Datasets</head><p>Evaluations are conducted with three databases, 300W <ref type="bibr" target="#b33">[34]</ref>, AFLW <ref type="bibr" target="#b24">[25]</ref> and a specifically constructed AFLW2000-3D database.</p><p>300W-LP: 300W <ref type="bibr" target="#b33">[34]</ref> standardises multiple alignment databases with 68 landmarks, including AFW <ref type="bibr" target="#b55">[56]</ref>, LFPW <ref type="bibr" target="#b3">[4]</ref>, HELEN <ref type="bibr" target="#b51">[52]</ref>, IBUG <ref type="bibr" target="#b33">[34]</ref> and XM2VTS <ref type="bibr" target="#b29">[30]</ref>. With 300W, we adopt the proposed face profiling to generate 61,225 samples across large poses (1,786 from IBUG, 5,207 from AFW, 16,556 from LFPW and 37,676 from HELEN, XM2VTS is not used), which is further expanded to 122,450 samples with flipping. We call the database as the 300W across Large Poses (300W-LP) AFLW: AFLW [25] contains 21,080 in-the-wild faces with large-pose variations (yaw from −90 • to 90 • ). Each image is annotated with up to 21 visible landmarks. The dataset is very suitable for evaluating face alignment performance across large poses.</p><p>AFLW2000-3D: Evaluating 3D face alignment in the wild is difficult due to the lack of pairs of 2D image and 3D model in unconstrained environment. Considering the recent achievements in 3D face reconstruction which can construct a 3D face from 2D landmarks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b54">55]</ref>, we assume that a 3D model can be accurately fitted if sufficient 2D landmarks are provided. Therefore 3D evaluation can be degraded to 2D evaluation which also makes it possible to compare 3DDFA with other 2D face alignment methods. However, AFLW is not suitable for evaluating this task since only visible landmarks lead to serious ambiguity in 3D shape, as reflected by the fake good alignment phenomenon in <ref type="figure">Fig. 6</ref>. In this work, we construct a database called AFLW2000-3D for 3D face alignment evaluation, which contains the ground truth 3D faces and the corresponding 68 landmarks of the first 2,000 AFLW samples. Construction details are provided in supplemental material. <ref type="figure">Figure 6</ref>. Fake good alignment in AFLW. For each sample, the first shows the visible 21 landmarks and the second shows all the 68 landmarks. The Normalized Mean Error (NME) reflects their accuracy. It can be seen that only evaluating visible landmarks cannot well reflect the fitting accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Performance Analysis</head><p>Error Reduction in Cascade: To analyze the error reduction process in cascade and evaluate the effect of initialization regeneration. We divide 300W-LP into 97,967 samples for training and 24,483 samples for testing, without identity overlapping. <ref type="figure" target="#fig_4">Fig. 7</ref> shows the training and testing errors at each iteration, with and without initialization regeneration. As observed, the testing error is reduced due to initialization regeneration. In the generic cascade process the training and testing errors converge fast after 2 iterations. While with initialization regeneration, the training error is updated at the beginning of each iteration and the testing error continues to descend.</p><p>During testing, 3DDFA takes 25.24ms for each iteration, 17.49ms for PNCC construction on 3.40GHZ CPU and 7.75ms for CNN on GTX TITAN Black GPU. Note that the computing time of PNCC can be greatly reduced if Z-Buffer is conducted on GPU. Considering both effectiveness and efficiency we choose 3 iterations in 3DDFA.</p><p>Performance with Different Costs: In this experiment, we demonstrate the performance with different costs including PDC, VDC and WPDC. <ref type="figure" target="#fig_5">Fig. 8</ref> demonstrates the testing errors at each iteration. All the networks are trained until convergence. It is shown that PDC cannot well model the fitting error and converges to an unsatisfied result. VDC is better than PDC, but the pathological curvature problem makes it only concentrate on a small set of parameters, which limits its performance. WPDC explicitly models the priority of each parameter and adaptively optimizes them with the parameter weights, leading to the best result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Comparison Experiments</head><p>In this paper, we test the performance of 3DDFA on three different tasks, including the large-pose face alignment on AFLW, 3D face alignment on AFLW2000-3D and mediumpose face alignment on 300W.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.1">Large Pose Face Alignment in AFLW</head><p>Protocol: In this experiment, we regard 300W and 300W-LP as the training set respectively and the whole AFLW as the testing set. The bounding boxes provided by AFLW are used for initialization (which are not the ground truth). During training, for 2D methods we use the projected 3D landmarks as the ground truth and for 3DDFA we directly regress the 3DMM parameters. During testing, we divide the testing set into 3 subsets according to their absolute yaw angles: [0 • , 30 • ], [30 • , 60 • ], and [60 • , 90 • ] with 11,596, 5,457 and 4,027 samples respectively. The alignment accuracy is evaluated by the Normalized Mean Error (NME), which is the average of visible landmark error normalised by the bounding box size <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b48">49]</ref>. Note that the metric only considers visible landmarks and is normalized by the bounding box size instead of the common inter-pupil distance. Besides, we also report the standard deviation across testing subsets which is a good measure of pose robustness.</p><p>Methods: Since little experiment has been conducted on AFLW, we choose some baseline methods with released codes, including CDM <ref type="bibr" target="#b48">[49]</ref>, RCPR <ref type="bibr" target="#b6">[7]</ref>, ESR <ref type="bibr" target="#b9">[10]</ref> and SDM <ref type="bibr" target="#b46">[47]</ref>. Among them ESR and SDM are popular face alignment methods in recent years. CDM is the first one claimed to perform pose-free face alignment. RCPR is a occlusion-robust method with the potential to deal with selfocclusion and we train it with landmark visibility labels computed by <ref type="bibr" target="#b20">[21]</ref>. <ref type="table">Table.</ref> 1 demonstrates the comparison results and <ref type="figure" target="#fig_6">Fig. 9</ref> shows the corresponding CED curves. Each method is trained on 300W and 300W-LP respectively to demonstrate the boost from face profiling. If a trained model is provided in the code, we also demonstrate its performance. Since CDM only contains testing code, we just report its performance with the provided alignment model. For 3DDFA which depends on large scales of data, we only report its performance trained on 300W-LP, with the network structure in <ref type="figure">Fig. 2</ref>. Results: Firstly, the results indicate that all the methods benefits substantially from face profiling when dealing with large poses. The improvements in [60 • , 90 • ] are 44.06% for RCPR, 40.36% for ESR and 42.10% for SDM. This is especially impressive since the alignment models are trained on the synthesized data and tested on real samples. Thus the fidelity of the face profiling method can be well demonstrated. Secondly, 3DDFA reaches the state of the art above all the 2D methods especially beyond medium poses. The minimum standard deviation of 3DDFA also demonstrates its robustness to pose variations. Finally, the performance of 3DDFA can be further improved with the SDM landmark refinement in Section 5.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.2">3D Face Alignment in AFLW2000-3D</head><p>As described in Section 6.1, 3D face alignment evaluation can be degraded to all-landmark evaluation considering both visible and invisible ones. Using AFLW2000-3D as  <ref type="table">Table.</ref> 1 and the CED curves are plot in <ref type="figure" target="#fig_7">Fig. 10</ref>. We do not report the performance of provided CDM and RCPR models since they do not detect invisible landmarks. Compared with the results in AFLW, we can see the defect of barely evaluating visible landmarks. For all the methods, despite with ground truth bounding boxes the performance in [60 • , 90 • ] and the standard deviation are obviously reduced when considering all the landmarks. We think for 3D face alignment which depends on both visible and invisible landmarks <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b22">23]</ref>, evaluating all the landmarks are necessary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.3">Medium Pose Face Alignment</head><p>Even though not aimed at advancing face alignment in medium poses, we are also interested in the performance of 3DDFA in this popular task. The experiments are conducted on 300W following the common protocol in <ref type="bibr" target="#b53">[54]</ref>, where we use the training part of LFPW, HELEN and the whole AFW for training <ref type="bibr" target="#b2">(3,</ref><ref type="bibr">148</ref> images and 50,521 after augmentation), and perform testing on three parts: the test samples from LFPW and HELEN as the common subset, the 135-image IBUG as the challenging subset, and the union of them as the full set (689 images in total). The alignment accuracy are evaluated by standard landmark mean error normalised by the inter-pupil distance (NME). It can be seen in Tabel. 2 <ref type="table">Table 2</ref>. The NME(%) of face alignment results on 300W, with the first and the second best results highlighted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Common Challenging Full TSPM <ref type="bibr" target="#b55">[56]</ref> 8 that even as a generic face alignment algorithm, 3DDFA still demonstrates competitive performance on the common set and state-of-the-art performance on the challenging set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>In this paper, we propose a novel method, 3D Dense Face Alignment (3DDFA), which well solves the problem of face alignment across large poses. Different from the traditional landmark detection framework, 3DDFA fits a dense 3D morphable model with cascaded CNN to solve the selfocclusion in modelling and the high nonlinearity in fitting in large poses. We also propose a face profiling algorithm to synthesize face appearances in profile view, which can provide abundant samples for training. Experiments show the state-of-the-art performance in AFLW, AFLW2000-3D and 300W. In future work, we believe that 3DDFA can be further improved with more complicated network architecture, like larger input size and deeper network.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>The Normalized Coordinate Code (NCC) and the Projected Normalized Coordinate Code (PNCC). (a) The normalized mean face, which is also demonstrated with NCC as its texture (NCCx = R, NCCy = G, NCCz = B). (b) The generation of PNCC: The projected 3D face is rendered by Z-Buffer with NCC as its colormap.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 (</head><label>3</label><figDesc>b):</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>3D Image Meshing. (a) The input image. (b) The fitted 3D face through MFF. (c) The depth image from 3D meshing. (d) A different view of the depth image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 .</head><label>5</label><figDesc>2D and 3D view of the image rotation. (a) The original yaw angle yaw0. (b) yaw0+20 • . (c) yaw0+30 • . (d) yaw0+40 • .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>The training and testing errors with (a) and without (b) initialization regeneration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>The testing errors with different cost function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Comparisons of cumulative errors distribution (CED) curves on AFLW. To balance the pose distribution, we plot the CED curves with a subset of 12,081 samples whose absolute yaw angles within [0 • , 30 • ], [30 • , 60 • ] and [60 • , 90 • ] are 1/3 each.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 10 .</head><label>10</label><figDesc>Comparisons of cumulative errors distribution (CED) curves on AFLW2000. To balance the pose distribution, we plot the CED curves with a subset of 696 samples whose absolute yaw angles within [0 • , 30 • ], [30 • , 60 • ] and [60 • , 90 • ] are 1/3 each.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>The NME(%) of face alignment results on AFLW and AFLW2000-3D with the first and the second best results highlighted. The bracket shows the training set. The results of provided alignment models are marked with their references.•, 30 • ], 462 samples in [30 • , 60 • ] and 232 samples in [60</figDesc><table><row><cell></cell><cell></cell><cell cols="3">AFLW Dataset (21 pts)</cell><cell></cell><cell></cell><cell cols="3">AFLW2000-3D Dataset (68 pts)</cell><cell></cell></row><row><cell>Method</cell><cell>[0, 30]</cell><cell>[30, 60]</cell><cell>[60, 90]</cell><cell>Mean</cell><cell>Std</cell><cell>[0, 30]</cell><cell>[30, 60]</cell><cell>[60, 90]</cell><cell>Mean</cell><cell>Std</cell></row><row><cell>CDM [49]</cell><cell>8.15</cell><cell>13.02</cell><cell>16.17</cell><cell>12.44</cell><cell>4.04</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>RCPR [7]</cell><cell>6.16</cell><cell>18.67</cell><cell>34.82</cell><cell>19.88</cell><cell>14.36</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>RCPR(300W)</cell><cell>5.40</cell><cell>9.80</cell><cell>20.61</cell><cell>11.94</cell><cell>7.83</cell><cell>4.16</cell><cell>9.88</cell><cell>22.58</cell><cell>12.21</cell><cell>9.43</cell></row><row><cell>RCPR(300W-LP)</cell><cell>5.43</cell><cell>6.58</cell><cell>11.53</cell><cell>7.85</cell><cell>3.24</cell><cell>4.26</cell><cell>5.96</cell><cell>13.18</cell><cell>7.80</cell><cell>4.74</cell></row><row><cell>ESR(300W)</cell><cell>5.58</cell><cell>10.62</cell><cell>20.02</cell><cell>12.07</cell><cell>7.33</cell><cell>4.38</cell><cell>10.47</cell><cell>20.31</cell><cell>11.72</cell><cell>8.04</cell></row><row><cell>ESR(300W-LP)</cell><cell>5.66</cell><cell>7.12</cell><cell>11.94</cell><cell>8.24</cell><cell>3.29</cell><cell>4.60</cell><cell>6.70</cell><cell>12.67</cell><cell>7.99</cell><cell>4.19</cell></row><row><cell>SDM(300W)</cell><cell>4.67</cell><cell>6.78</cell><cell>16.13</cell><cell>9.19</cell><cell>6.10</cell><cell>3.56</cell><cell>7.08</cell><cell>17.48</cell><cell>9.37</cell><cell>7.23</cell></row><row><cell>SDM(300W-LP)</cell><cell>4.75</cell><cell>5.55</cell><cell>9.34</cell><cell>6.55</cell><cell>2.45</cell><cell>3.67</cell><cell>4.94</cell><cell>9.76</cell><cell>6.12</cell><cell>3.21</cell></row><row><cell>3DDFA</cell><cell>5.00</cell><cell>5.06</cell><cell>6.74</cell><cell>5.60</cell><cell>0.99</cell><cell>3.78</cell><cell>4.54</cell><cell>7.93</cell><cell>5.42</cell><cell>2.21</cell></row><row><cell>3DDFA+SDM</cell><cell>4.75</cell><cell>4.83</cell><cell>6.38</cell><cell>5.32</cell><cell>0.92</cell><cell>3.43</cell><cell>4.24</cell><cell>7.17</cell><cell>4.94</cell><cell>1.97</cell></row><row><cell cols="5">the testing set, this experiment follows the same protocol</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">as AFLW, except 1) Instead of the visible 21 landmarks, all</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">the MultiPIE-68 landmarks [34] in AFLW2000-3D are used</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">for evaluation. 2) With the ground truth 3D models, the</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">ground truth bounding boxes enclosing all the landmarks</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">are provided for initialization. There are 1,306 samples</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>in [0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>• , 90 • ]. The results are demonstrates in</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Inverse rendering of faces with a 3D morphable model. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Aldrian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1080" to="1093" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Robust discriminative response map fitting with constrained local models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asthana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3444" to="3451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Incremental face alignment in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Asthana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1859" to="1866" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Localizing parts of faces using a consensus of exemplars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kriegman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2011 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="545" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Face expression recognition and analysis: the state of the art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bettadapura</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1203.6722</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Face recognition based on fitting a 3D morphable model. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Robust face landmark estimation under occlusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">P</forename><surname>Burgos-Artizzu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2013 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1513" to="1520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Displaced dynamic expression regression for real-time facial tracking and animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">43</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Facewarehouse: a 3d facial expression database for visual computing. Visualization and Computer Graphics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="413" to="425" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Face alignment by explicit shape regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="2887" to="2894" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A comparative evaluation of active appearance model algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">98</biblScope>
			<biblScope unit="page" from="680" to="689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Active appearance models. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="681" to="685" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Active shape models-their training and application. Computer vision and image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="38" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">View-based active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">V</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and vision computing</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="657" to="664" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Automatic feature localisation with constrained local models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cristinacce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cootes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3054" to="3067" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Feature detection and tracking with constrained local models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cristinacce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Cootes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="929" to="938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cascaded pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1078" to="1085" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained partbased models. Pattern Analysis and Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">3D alignment of face in a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1305" to="1312" />
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Viewing real-world faces in 3D</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2013 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3607" to="3614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Effective face frontalization in unconstrained images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Paz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Enbar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Guided unsupervised learning of mode specific models for facial point detection in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jaiswal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Almaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Valstar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision Workshops (IC-CVW), 2013 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dense 3D face alignment from 2D videos in real-time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Jeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automatic Face &amp; Gesture Recognition, 2015. FG&apos;15. 11th IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Pose-invariant 3D face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jourabloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2015 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Annotated facial landmarks in the wild: A large-scale, realworld database for facial landmark localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Köstinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wohlhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="2144" to="2151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Interactive facial feature localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Face alignment using cascade gaussian process regression trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4204" to="4212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Unconstrained facial landmark localization with backbone-branches fullyconvolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1507.03409</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Deep learning via Hessian-free optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Machine Learning (ICML-10)</title>
		<meeting>the 27th International Conference on Machine Learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">XM2VTSDB: The extended M2VTS database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Messer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luettin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Maitre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Second international conference on audio and video-based biometric person authentication</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">964</biblScope>
			<biblScope unit="page" from="965" to="966" />
		</imprint>
	</monogr>
	<note>Citeseer</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A 3D face model for pose and illumination invariant face recognition. In Advanced Video and Signal Based Surveillance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paysan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Knothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Amberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Romdhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="296" to="301" />
		</imprint>
	</monogr>
	<note>AVSS&apos;09</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Face alignment at 3000 FPS via regressing local binary features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1685" to="1692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Estimating 3D shape and texture using pixel intensity, edges, specular highlights, texture constraints and a prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Romdhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2005 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">300 faces in-the-wild challenge: The first facial landmark localization challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision Workshops (IC-CVW), 2013 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="397" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A semi-automatic methodology for facial landmark annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition Workshops (CVPRW), 2013 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A nonlinear discriminative approach to AAM fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Saragih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goecke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 11th International Conference on</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deformable model fitting by regularized landmark mean-shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Saragih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="200" to="215" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Nonparametric context modeling of local appearance for pose-and expression-robust facial landmark localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1741" to="1748" />
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Deep convolutional network cascade for facial point detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Deepface: Closing the gap to human-level performance in face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Taigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1701" to="1708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Optimization problems for fast AAM fitting in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tzimiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2013 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="593" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Facial point detection using boosted regression and graph models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Valstar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Binefa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pantic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2729" to="2736" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Real-time combined 2D+3D active appearance models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="535" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Supervised descent method and its applications to face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2013 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Global supervised descent method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>De La</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torre</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2664" to="2673" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learn to combine multiple hypotheses for accurate face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision Workshops (ICCVW), 2013 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="392" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Object detection by labeling superpixels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="5107" to="5116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Pose-free facial landmark fitting via optimized part mixtures and cascaded deformable shape model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision (ICCV), 2013 IEEE International Conference on</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1944" to="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Coarse-to-fine autoencoder networks (CFAN) for real-time face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Facial landmark detection by deep multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2014</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="94" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Extensive facial landmark localization with coarse-to-fine convolutional network cascade</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision Workshops (ICCVW), 2013 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="386" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A Bayesian mixture model for multi-view face alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition, 2005. CVPR 2005. IEEE Computer Society Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="741" to="746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Face alignment by coarse-to-fine shape searching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="4998" to="5006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">High-fidelity pose and expression normalization for face recognition in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="787" to="796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Face detection, pose estimation, and landmark localization in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2879" to="2886" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Discriminative 3D morphable model fitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th IEEE International Conference and Workshops on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note>Automatic Face and Gesture Recognition (FG)</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
