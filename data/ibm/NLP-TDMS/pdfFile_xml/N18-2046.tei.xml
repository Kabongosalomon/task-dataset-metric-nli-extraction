<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /Users/yhou/git/grobid-0.5.3/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.3" ident="GROBID" when="2019-02-07T08:44+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Near Human-Level Performance in Grammatical Error Correction with Hybrid Machine Translation</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Association for Computational Linguistics</publisher>
				<availability status="unknown"><p>Copyright Association for Computational Linguistics</p>
				</availability>
				<date>June 1 -6, 2018. 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Edinburgh</orgName>
								<address>
									<addrLine>10 Crichton St</addrLine>
									<postCode>EH8 9AB</postCode>
									<settlement>Edinburgh</settlement>
									<country key="GB">Scotland</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
							<email>marcinjd@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Redmond</orgName>
								<address>
									<postCode>98052</postCode>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Near Human-Level Performance in Grammatical Error Correction with Hybrid Machine Translation</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of NAACL-HLT 2018</title>
						<meeting>NAACL-HLT 2018 <address><addrLine>New Orleans, Louisiana</addrLine></address>
						</meeting>
						<imprint>
							<publisher>Association for Computational Linguistics</publisher>
							<biblScope unit="page" from="284" to="290"/>
							<date type="published">June 1 -6, 2018. 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We combine two of the most popular approaches to automated Grammatical Error Correction (GEC): GEC based on Statistical Machine Translation (SMT) and GEC based on Neural Machine Translation (NMT). The hybrid system achieves new state-of-the-art results on the CoNLL-2014 and JFLEG benchmarks. This GEC system preserves the accuracy of SMT output and, at the same time, generates more fluent sentences as it typical for NMT. Our analysis shows that the created systems are closer to reaching human-level performance than any other GEC system reported so far.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Currently, the most effective GEC systems are based on phrase-based statistical machine translation ( <ref type="bibr" target="#b14">Rozovskaya and Roth, 2016;</ref><ref type="bibr" target="#b3">Junczys- Dowmunt and Grundkiewicz, 2016;</ref><ref type="bibr">Chollampatt and Ng, 2017)</ref>. Systems that rely on neural machine translation <ref type="bibr" target="#b22">(Yuan and Briscoe, 2016;</ref><ref type="bibr" target="#b20">Xie et al., 2016;</ref><ref type="bibr" target="#b16">Schmaltz et al., 2017;</ref><ref type="bibr">Ji et al., 2017)</ref> are not yet able to achieve as high performance as SMT systems according to automatic evaluation metrics (see <ref type="table">Table 1</ref> for comparison on the CoNLL-2014 test set). However, it has been shown that the neural approach can produce more fluent output, which might be desirable by human evaluators ( <ref type="bibr" target="#b9">Napoles et al., 2017)</ref>. In this work, we combine both MT flavors within a hybrid GEC system. Such a GEC system preserves the accuracy of SMT output and at the same time generates more fluent sentences achieving new state-of-the-art results on two different benchmarks: the annotationbased CoNLL-2014 and the fluency-based JFLEG benchmark. Moreover, comparison with human gold standards shows that the created systems are closer to reaching human-level performance than any other GEC system described in the literature so far. Using consistent training data and preprocessing ( § 2), we first create strong SMT ( § 3) and NMT ( § 4) baseline systems. Then, we experiment with system combinations through pipelining and reranking ( § 5). Finally, we compare the performance with human annotations and identify issues with current state-of-the-art systems ( § 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and preprocessing</head><p>Our main training data is NUCLE ( <ref type="bibr">Dahlmeier et al., 2013)</ref>. English sentences from the publicly available Lang-8 Corpora ( <ref type="bibr" target="#b7">Mizumoto et al., 2012</ref>) serve as additional training data.</p><p>We use official test sets from two CoNLL shared tasks from <ref type="bibr" target="#b12">2013</ref><ref type="bibr" target="#b12">(Ng et al., 2013</ref><ref type="bibr" target="#b11">, 2014</ref>) as development and test data, and evaluate using M 2 <ref type="bibr">(Dahlmeier and Ng, 2012</ref>). We also report results on JFLEG ( <ref type="bibr" target="#b9">Napoles et al., 2017</ref>) with the  <ref type="table" target="#tab_1">Tokens   NUCLE  57,151  1,162K  Lang-8 NAIST  1,943,901 25,026K  CoNLL-2013 (dev)  1,381  29K  CoNLL-2014 (test)  1,312  30K  JFLEG Dev  754  14K  JFLEG Test  747  13K   Table 1</ref>: Statistics for training and testing data sets.</p><p>GLEU metric ( <ref type="bibr" target="#b8">Napoles et al., 2015)</ref>. The data set is provided with a development and test set split. All data sets are listed in <ref type="table">Table 1</ref>.</p><p>We preprocess Lang-8 with the NLTK tokenizer ( <ref type="bibr" target="#b0">Bird and Loper, 2004</ref>) and preserve the original tokenization in NUCLE and JFLEG. Sentences are truecased with scripts from Moses ( <ref type="bibr" target="#b6">Koehn et al., 2007)</ref>. For dealing with out-of-vocabulary words, we split tokens into 50k subword units using Byte Pair Encoding (BPE) by <ref type="bibr" target="#b19">Sennrich et al. (2016b)</ref>. BPE codes are extracted only from correct sentences from Lang-8 and NUCLE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SMT systems</head><p>For our SMT-based systems, we follow recipes proposed by <ref type="bibr" target="#b3">Junczys-Dowmunt and Grundkiewicz (2016)</ref>, and use a phrase-based SMT system with a log-linear combination of task-specific features. We use word-level Levenshtein distance and edit operation counts as dense features (Dense), and correction patterns on words with one word left/right context on Word Classes (WC) as sparse features (Sparse). We also experiment with additional character-level dense features (Char. ops). All systems use a 5-gram Language Model (LM) and OSM <ref type="bibr">(Durrani et al., 2011</ref>) both estimated from the target side of the training data, and a 5-gram LM and 9-gram WCLM trained on Common Crawl data ( <ref type="bibr" target="#b2">Buck et al., 2014</ref>).</p><p>Experiment settings Translation models are trained with Moses ( <ref type="bibr" target="#b6">Koehn et al., 2007)</ref>, wordalignment models are produced with MGIZA++ ( <ref type="bibr">Gao and Vogel, 2008)</ref>, and no reordering models are used. Language models are built using KenLM <ref type="bibr">(Heafield, 2011)</ref>, while word classes are trained with word2vec <ref type="bibr">1</ref> .</p><p>We tune the systems separately for M 2 and GLEU metrics. MERT <ref type="bibr" target="#b13">(Och, 2003</ref>  we follow the 4-fold cross-validation on NUCLE with adapted error rate recommended by JunczysDowmunt and <ref type="bibr" target="#b3">Grundkiewicz (2016)</ref>. Models evaluated on GLEU are optimized on JFLEG Dev using the GLEU scorer, which we added to Moses. We report results for models using feature weights averaged over 4 tuning runs.</p><p>Results Other things being equal, using the original tokenization, applying subword units, and extending edit-based features result in a similar system to Junczys-Dowmunt and Grundkiewicz (2016): 49.82 vs 49.49 M 2 ( <ref type="table" target="#tab_1">Table 2)</ref>.</p><p>The phrase-based SMT systems do not deal well with orthographic errors ( <ref type="bibr" target="#b9">Napoles et al., 2017</ref>) -if a source word has not been seen in the training corpus, it is likely copied as a target word. Subword units can help to solve this problem partially. Adding features based on character-level edit counts increases the results on both test sets.</p><p>A result of 55.79 GLEU on JFLEG Test is already 2 points better than the GLEU-tuned NMT system of  and only 1 point worse than the best reported result by Chollampatt and Ng (2017) with their M 2 -tuned SMT system, even though no additional spelling correction has been used at this point. We experiment with specialized spell-checking methods in later sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">NMT systems</head><p>The model architecture we choose for our NMTbased systems is an attentional encoder-decoder model with a bidirectional single-layer encoder and decoder, both using GRUs as their RNN variants ( <ref type="bibr" target="#b17">Sennrich et al., 2017)</ref>. A similar architecture has been already tested for the GEC task by , but we use different hyperparameters.</p><p>To improve the performance of our NMT models, similarly to <ref type="bibr" target="#b20">Xie et al. (2016)</ref> and <ref type="bibr">Ji et al. (2017)</ref>, we combine them with an additional large-scale language model. In contrast to previous studies, which use an n-gram probabilistic LM, we build a 2-layer Recurrent Neural Network Language Model (RNN  LM) with GRU cells which we train again on English Common Crawl data <ref type="bibr" target="#b2">(Buck et al., 2014</ref>).</p><p>Experimental settings We train with the Marian toolkit (Junczys-Dowmunt et al., 2018) on the same data we used for the SMT baselines, i.e. NUCLE and Lang-8. The RNN hidden state size is set to 1024, embedding size to 512. Source and target vocabularies as well as subword units are the same.</p><p>Optimization is performed with Adam ( <ref type="bibr" target="#b5">Kingma and Ba, 2014</ref>) and the mini-batch size fitted into 4GB of GPU memory. We regularize the model with scaling dropout ( <ref type="bibr">Gal and Ghahramani, 2016</ref>) with a dropout probability of 0.2 on all RNN inputs and states. Apart from that we dropout entire source and target words with probabilities of 0.2 and 0.1 respectively. We use early stopping with a patience of 10 based on the cross-entropy cost on the CoNLL-2013 test set. Models are validated and saved every 10,000 mini-batches. As final models we choose the one with the best performance on the development set among the last ten model check-points based on the M 2 or GLEU metrics.</p><p>Size of RNN hidden state and embeddings, target vocabulary, and optimization options for the RNN LM are identical to those used for our NMT models. Decoding is done by beam search with a beam size of 12. We normalize scores for each hypothesis by sentence length.</p><p>Results A single NMT model achieves lower performance than the SMT baselines <ref type="table" target="#tab_3">(Table 3)</ref>. However, the M 2 score of 42.76 for CoNLL-2014 is already higher than the best published result of 41.53 M 2 for a strictly neural GEC system of Ji and thus boosts the results significantly on both test sets (+5.8 M 2 and +5.96 GLEU).</p><p>An ensemble of four independently trained models 3 (NMT×4), on the other hand, increases precision at the expense of recall, which may even lead to a performance drop. Adding the RNN LM to that ensemble balances this negative effect, resulting in 50.19 M 2 . These are by far the highest results reported on both benchmarks for pure neural GEC systems.</p><p>Comparison to SMT systems With model ensembling, the neural systems achieve performance similar to SMT baselines <ref type="figure" target="#fig_2">(Figure 2)</ref>. A strippeddown SMT system without CCLM, quite surprisingly gives better results on JFLEG than the NMT system, and the opposite is true for CoNLL-2014. The reason for the lower performance on JFLEG might be a large amount of spelling errors, which are more efficiently corrected by the SMT system using subword units.</p><p>If both systems are enhanced by a large-scale language model, the neural system outperforms the SMT system on JFLEG and it is competitive with SMT systems on CoNLL-2014. However, it is not known if the results would preserve if the NMT model is combined with a probabilistic ngram LM instead as it has been proposed in the previous works <ref type="bibr" target="#b20">(Xie et al., 2016;</ref><ref type="bibr">Ji et al., 2017</ref>  <ref type="table">Table 4</ref>: Results for hybrid SMT-NMT systems on the CoNLL-2014 (M 2 ) and JFLEG Test (GLEU) sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Hybrid SMT-NMT systems</head><p>We experiment with pipelining and rescoring methods in order to combine our best SMT and NMT GEC systems 4 .</p><p>SMT-NMT pipelines The output corrected by an SMT system is passed as an input to the NMT ensemble with or without RNN LM 5 . In this case the NMT system serves as an automatic post-editing system. Pipelining improves the results on both test sets by increasing recall <ref type="table">(Table 4)</ref>. As the performance of the NMT system without a RNN LM is much lower than the performance of the SMT system alone, this implies that both approaches produce complementary corrections.</p><p>Rescoring with NMT Rescoring of an n-best list obtained from one system by another is a commonly used technique in GEC, which allows to combine multiple different systems or even different approaches <ref type="bibr">(Hoang et al., 2016;</ref><ref type="bibr" target="#b21">Yannakoudakis et al., 2017;</ref><ref type="bibr">Chollampatt and Ng, 2017;</ref><ref type="bibr">Ji et al., 2017)</ref>. In our experiments, we generate a 1000 n-best list with the SMT system and add separate scores from each neural component. Scores of NMT models and the RNN LM are added in the form of probabilities in negative log space. The re-scored weights are obtained from a single run of the Batch Mira algorithm (Cherry and Foster, 2012) on the development set.</p><p>As opposed to pipelining, rescoring improves precision at the expense of recall and is more effective for the CoNLL data resulting in up to 54.95 M 2 . On JFLEG, rescoring only with the RNN LM <ref type="bibr">4</ref> The best system combinations are chosen again based on the development sets, i.e. CoNLL-2013 and JFLEG Dev. We omit these results as they are highly overestimated. <ref type="bibr">5</ref> We did not observed any improvements if the order of the systems is reversed.  produces similar results as rescoring with the NMT ensemble. However, the best result for rescoring is lower than for pipelining on that test set. It seems the SMT system is not able to produce as diversified corrections in an n-best list as those generated by the NMT ensemble.</p><p>Spelling correction and final results Pipelining the NMT-rescored SMT system and the NMT system leads to further improvement. We believe this can be explained by different contributions to precision and recall trade-offs for the two methods, similar to effects observed for the combination of the NMT ensemble and our RNN LM.</p><p>On top of our final hybrid system we add a spellchecking component, which is run before pipelining. We use a character-level SMT system following Chollampatt and Ng (2017) which they deploy for unknown words in their word-based SMT system. As our BPE-based SMT does not really suffer from unknown words, we run the spell-checking component on words that would have been segmented by the BPE algorithm. This last system achieves the best results reported in this paper: 56.25 M 2 on CoNLL-2014 and 61.50 GLEU on JFLEG Test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Example Source but now every thing is change , the life becom more dificullty .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best SMT</head><p>But now everything is changed , the life becom more dificullty .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best NMT</head><p>But now everything is changing , the life becomes more difficult . Pipeline But now everything is changed , the life becomes more difficult .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rescoring</head><p>But now everything has changed , the life becom more dificullty . + Pipeline But now everything has changed , the life becomes more difficult .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference 1</head><p>Now everything has changed , and life becomes more difficult .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference 2</head><p>Everything has changed now and life has become more difficult .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference 3</head><p>But now that everything changes , life becomes more difficult .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reference 4</head><p>But now that everything is changing , life becomes more difficult . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Analysis and future work</head><p>For both benchmarks our systems are close to automatic evaluation results that have been claimed to correspond to human-level performance on the CoNLL-2014 test set and on JFLEG Test.</p><p>Example outputs <ref type="table" target="#tab_6">Table 5</ref> shows system outputs for an example source sentence from the JFLEG Test corpus that illustrate the complementarity of the statistical and neural approaches. The SMT and NMT systems produce different corrections. Rescoring is able to generate a unique correction (is change→has changed), but it fails in generating some corrections from the neural system, e.g. misspellings (becom and dificullty). Pipelining, on the other hand, may not improve a local correction made by the SMT system (is changed). The combination of the two methods produces output, which is most similar to the references.</p><p>Comparison with human annotations <ref type="bibr" target="#b1">Bryant and Ng (2015)</ref> created an extension of the CoNLL-2014 test set with 10 annotators in total, JFLEG already incorporates corrections from 4 annotators. Human-level results for M 2 and GLEU were calculated by averaging the scores for each annotator with regard to the remaining 9 (CoNLL) or 3 (JF-LEG) annotators, respectively. <ref type="figure" target="#fig_3">Figure 3</ref> contains human level scores, our results, and previously best reported results by <ref type="bibr">Chollampatt and Ng (2017)</ref>. Our best system reaches nearly 100% of the average human score according to M 2 and nearly 99% for GLEU being much closer to that bound than previous works <ref type="bibr">6</ref> .</p><p>Further inspection reveals, however, that the precision/recall trade-off for the automatic system indicates lower coverage compared to human corrections -lower recall is compensated with high precision <ref type="bibr">7</ref> . Automatic systems might, for example, miss some obvious error corrections and therefore easily be distinguishable from human references. Future work would require a human evaluation effort to draw more conclusions.</p><p>Colin Cherry and George Foster. 2012. Batch tuning strategies for statistical machine translation. In Proceedings of the 2012 Conference of the North Amer- Jianshu Ji, Qinlong Wang, Kristina Toutanova, Yongen Gong, Steven Truong, and Jianfeng Gao. 2017. A nested attention neural hybrid model for grammatical error correction. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, pages 753-762.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Comparison of SMT, NMT and hybrid GEC systems on the CoNLL-2014 test set (M 2 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Contribution of a language model (LM) for SMT and NMT GEC systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Comparison with human annotators. The figure presents average M 2 and GLEU scores with standard deviations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 : Results for SMT baseline systems on the</head><label>2</label><figDesc></figDesc><table>CoNLL-2014 (M 2 ) and JFLEG Test (GLEU) sets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>285</head><label>285</label><figDesc></figDesc><table>CoNLL 

JFLEG 
System 
P 
R 
M 2 
GLEU 

NMT 
66.61 17.58 42.76 50.08 
NMT + RNN-LM 
61.05 26.71 48.56 56.04 
NMT×4 
71.10 15.42 41.29 50.30 
NMT×4 + RNN-LM 60.27 30.08 50.19 56.74 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table>Results for NMT systems on the CoNLL-2014 
(M 2 ) and JFLEG Test (GLEU) sets. 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" validated="false"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table>System outputs for the example source sentence from the JFLEG Test set. 

</table></figure>

			<note place="foot" n="6"> During the camera-ready preparation, Chollampatt and Ng (2018) have published a GEC system based on a multilayer convolutional encoder-decoder neural network with a character-based spell-checking module improving the previous best result to 54.79 M 2 on CoNLL-2014 and 57.47 GLEU on JFLEG Test.</note>

			<note place="foot" n="7"> A similar imbalance between precision and recall is visible on JFLEG when the M 2 metric is used.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This work was partially funded by Facebook. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of Facebook.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">NLTK: the natural language toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Loper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACL 2004 on Interactive poster and demonstration sessions</title>
		<meeting>the ACL 2004 on Interactive poster and demonstration sessions</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How far are we from fully automatic high quality grammatical error correction?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Bryant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Ng</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P15-1068" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="697" to="707" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">N-gram counts and language models from the Common Crawl</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Buck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bas</forename><surname>Van Ooyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Language Resources and Evaluation Conference</title>
		<meeting>the Language Resources and Evaluation Conference<address><addrLine>Reykjavík, Iceland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3579" to="3584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Phrase-based machine translation is stateof-the-art for automatic grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Dowmunt</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/D16-1161" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1546" to="1556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Grundkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Dwojak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Neckermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulrich</forename><surname>Germann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.00344</idno>
		<ptr target="https://arxiv.org/abs/1804.00344" />
		<title level="m">Marian: Fast neural machine translation in C++</title>
		<editor>Alham Fikri Aji, Nikolay Bogoychev, André F. T. Martins, and Alexandra Birch</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Learning Representations (ICLR)</title>
		<meeting>the 3rd International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Bojar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Herbst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics. The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The effect of learner corpus size in grammatical error correction of ESL writings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoya</forename><surname>Mizumoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuta</forename><surname>Hayashibe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mamoru</forename><surname>Komachi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Matsumoto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2012</title>
		<meeting>COLING 2012</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="863" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Ground truth for grammatical error correction metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P15-2097" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="588" to="593" />
		</imprint>
	</monogr>
	<note>Short Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">JFLEG: A fluency corpus and benchmark for grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Courtney</forename><surname>Napoles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Tetreault</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1702.04066" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2017 Conference of the European Chapter of the Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Siew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Briscoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">Hendy</forename><surname>Hadiwinoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Susanto</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">289</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The CoNLL-2014 shared task on grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Bryant</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W14-1701" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth Conference on Computational Natural Language Learning: Shared Task</title>
		<meeting>the Eighteenth Conference on Computational Natural Language Learning: Shared Task<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The CoNLL-2013 shared task on grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwee Tou Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mei</forename><surname>Siew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanbin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Hadiwinoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tetreault</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W13-3601" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning: Shared Task. Association for Computational Linguistics</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning: Shared Task. Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franz Josef</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics<address><addrLine>Stroudsburg, USA, ACL &apos;03</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Grammatical error correction: Machine translation and classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alla</forename><surname>Rozovskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P16-1208" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2205" to="2215" />
		</imprint>
	</monogr>
	<note>Long Papers). Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Grammatical error correction with neural reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keisuke</forename><surname>Sakaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Post</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Van Durme</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/I17-2062" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="366" to="372" />
		</imprint>
	</monogr>
	<note>Short Papers). Asian Federation of Natural Language Processing</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adapting sequence models for sentence correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allen</forename><surname>Schmaltz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Shieber</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2807" to="2813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Nematus: a toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Läubli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Valerio Miceli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barone</surname></persName>
		</author>
		<ptr target="http://aclweb.org/anthology/E17-3017" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics</title>
		<meeting>the Software Demonstrations of the 15th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics<address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="65" to="68" />
		</imprint>
	</monogr>
	<note>Jozef Mokry, and Maria Nadejde</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Edinburgh neural machine translation systems for WMT 16</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/W/W16/W16-" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Conference on Machine Translation</title>
		<meeting>the First Conference on Machine Translation<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="371" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P16-1162" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Long Papers)</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziang</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anand</forename><surname>Avati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naveen</forename><surname>Arivazhagan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Ng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.09727</idno>
		<title level="m">Neural language correction with character-based attention</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Neural sequencelabelling models for grammatical error correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helen</forename><surname>Yannakoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Rei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Øistein</forename><forename type="middle">E</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1296" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2785" to="2796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Grammatical error correction using neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ted</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="380" to="386" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
