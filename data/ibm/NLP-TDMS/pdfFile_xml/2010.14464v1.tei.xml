<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Dynamic Boundary Time Warping for Sub-sequence Matching with Few Examples</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Borchmann</surname></persName>
							<email>lukasz.borchmann@applica.ai</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawid</forename><surname>Jurkiewicz</surname></persName>
							<email>dawid.jurkiewicz@applica.ai</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Graliński</surname></persName>
							<email>filip.gralinski@applica.ai</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Applica</forename><surname>Ai</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Górecki</surname></persName>
							<email>tomasz.gorecki@amu.edu.pl</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Applica.ai Warsaw</orgName>
								<address>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Applica.ai Warsaw</orgName>
								<address>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<address>
									<settlement>Warsaw</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Adam Mickiewicz University</orgName>
								<address>
									<settlement>Poznań</settlement>
									<country key="PL">Poland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Dynamic Boundary Time Warping for Sub-sequence Matching with Few Examples</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper presents a novel method of finding a fragment in a long temporal sequence similar to the set of shorter sequences. We are the first to propose an algorithm for such a search that does not rely on computing the average sequence from query examples. Instead, we use query examples as is, utilizing all of them simultaneously. The introduced method based on the Dynamic Time Warping (DTW) technique is suited explicitly for few-shot queryby-example retrieval tasks. We evaluate it on two different few-shot problems from the field of Natural Language Processing. The results show it either outperforms baselines and previous approaches or achieves comparable results when a low number of examples is available. k s=1 c(x is , y js ) D Accumulated cost matrix of size n× m calculated from X , Y D Accumulated cost matrix of size n× m calculated from X , Y</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This work bridges Information Retrieval, Natural Language Processing, Dynamic Programming, and Machine Learning, introducing a novel approach to identifying text spans with semantic matching. Although the method can retrieve any sequential information from an untrimmed stream, this paper demonstrates application to diverse problems involving text in natural language.</p><p>Let us start by observing that a substantial proportion of retrieval, detection, and sequence labeling tasks can be solved using sub-sequence matching. However, so far, no mainstream methods tackle the problem this way.</p><p>Consider the case of Named Entity Recognition (also referred to as entity identification, entity * Equal contribution. chunking or entity extraction, NER) -a task of locating and classifying spans of text associated with real-world objects, such as person names, organizations, and locations, as well as with abstract temporal and numerical expressions such as dates <ref type="bibr" target="#b81">(Yadav and Bethard, 2018;</ref>.</p><p>The problem is commonly solved with trained models for structured prediction <ref type="bibr" target="#b29">(Huang et al., 2015;</ref><ref type="bibr" target="#b34">Lample et al., 2016)</ref>. In contrast, we propose to solve it in a previously not recognized way: to use word embeddings (see Section 5.2.1) directly, performing semantic sub-sequence matching. In other words, determine a sentence span similar to named entities provided in the train set, with no training required beforehand. In some cases, for instance, when few-shot scenarios are considered (where only a few examples are available), this approach may be beneficial (problem was investigated in Section 6.2).</p><p>Other examples can be found in the field of Information Retrieval <ref type="bibr">(IR)</ref>. When text documents are considered, the typical IR scenario is a provision of ranked search results for a given text query entered by a user. Search results can be either full documents or spans of texts, and each of the mentioned scenarios poses different challenges <ref type="bibr" target="#b43">(Mitra and Craswell, 2018)</ref>.</p><p>Many modern approaches to Information Retrieval rely on a straightforward comparison of dense embeddings representing query documents and candidate documents, determining optimal results using k-nearest neighbor search <ref type="bibr">(Schmidt arXiv:2010.14464v1 [cs.DS]</ref> 27 Oct 2020 Sequence Sequence Sequence Sequence ... <ref type="figure">Figure 1</ref>: The problem considered is to align multiple sequences (here X 1 , X 2 , X 3 ) optimally within the target sequence Y, assuming all have to be matched to the same sub-sequence of Y. Optimal alignment is one that minimizes the cost over all possible alignments. An example from Natural Language Processing is to locate a named entity within the sentence, given a few examples of other named entities. <ref type="bibr" target="#b8">Boytsov et al., 2016;</ref><ref type="bibr" target="#b9">Brokos et al., 2016;</ref><ref type="bibr" target="#b31">Kim et al., 2017;</ref><ref type="bibr" target="#b22">Gysel et al., 2018)</ref>. When such end-to-end retrieval systems are considered, the main question becomes how to determine reliable representations of documents <ref type="bibr" target="#b18">(Gillick et al., 2018)</ref>.</p><p>To take the approach to Information Retrieval described above, one has to already know the boundaries of units to be returned, e.g., assume sentences or paragraphs should be considered as possible results. A more challenging problem arises when we do not search for a predefined text fragment (e.g., entire document or whole sentence) but are expected to return any possible and adequate subsequence in a document (e.g., few sentences, several words, or even one word). This is the case for many real-world scenarios, where documents lack accessible formal structure, and one is expected to determine spans in natural language streams <ref type="bibr" target="#b74">(Vanderbeck et al., 2011;</ref><ref type="bibr" target="#b7">Borchmann et al., 2020)</ref>. Take an example of a lawyer or researcher searching for crucial parts of legal documents to determine whether they contain fairness policies and how these policies look like <ref type="bibr" target="#b47">(Nagpal et al., 2018)</ref>.</p><p>As shown later, it is possible to tackle the problem with a proper sub-sequence matching strategy, which can incorporate all given examples to retrieve suitable text span (Section 6.1).</p><p>We solve the problems stated above with unconventionally used Dynamic Programming algorithms and propose their modifications. In particular, the well-known DTW Barycenter Averaging heuristic is evaluated in a new scenario, where word embeddings are used to determine document spans. More importantly, a new subsequence matching method is introduced, performing a search by multiple examples simultaneously. This matching method maximizes gain from the availability of a few semantically similar text span 0 10 20 0 10 0 10 examples. Because of the relation of the newly introduced method to the Dynamic Time Warping algorithm, it is referred to as the Dynamic Boundary Time Warping (DBTW).</p><p>The rest of this paper is organized as follows. Section 3 describes the problem we are dealing with. Section 4 introduces the Dynamic Time Warping algorithm and its derivatives. In Section 5, we present our Dynamic Boundary Time Warping algorithm together with complexity study and its adaptation to NLP problems. Section 6 reports evaluation results on two different NLP tasks. Section 2 summarizes related works in the areas of Information Retrieval, Natural Language Processing, and time-series mining. Finally, Section 7 concludes the paper and outlines future research directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Dynamic Boundary Time Warping with maximum distance limit can be considered a binary nonparametric classifier <ref type="bibr" target="#b5">(Boiman et al., 2008)</ref> over all possible document sub-sequences because it determines which of them represents the same class as positive examples. In such a sense, its application to few-shot semantic retrieval is related to the widely studied problem of one-and few-shot learning (e.g., <ref type="bibr" target="#b36">Li Fei-Fei et al. (2006)</ref>; <ref type="bibr" target="#b2">Bart and Ullman (2005)</ref>; <ref type="bibr" target="#b32">Koch et al. (2015)</ref>; <ref type="bibr" target="#b69">Snell et al. (2017)</ref>; <ref type="bibr" target="#b70">Sung et al. (2017)</ref>). However, these approaches are not directly comparable because, in contrast to DBTW, knowledge obtained during training for previous categories is used.</p><p>Many time-series mining problems require subsequence similarity search as a subroutine. While this can be performed with any distance measure, and dozens of distance measures have been proposed in the last years, there is increasing evidence that DTW is the best measure across a wide range of domains <ref type="bibr" target="#b14">(Ding et al., 2008)</ref>. Subsequence DTW (S-DTW) is a variant of the DTW technique <ref type="bibr" target="#b45">(Müller, 2007)</ref>, which is designed to find multiple similar subsequences between two templates. One of the most cited methods is SPRING <ref type="bibr" target="#b63">(Sakurai et al., 2007)</ref>, where a query time series is searched in a larger streaming time series. Examples of subsequence matching applications are sensor network monitoring <ref type="bibr" target="#b63">(Sakurai et al., 2007)</ref>, spoken keyword spotting <ref type="bibr" target="#b21">(Guo et al., 2012)</ref>, sensor-based gait analysis <ref type="bibr" target="#b3">(Barth et al., 2015)</ref>, acoustic <ref type="bibr" target="#b61">(Rosa et al., 2017)</ref>, motion capture <ref type="bibr" target="#b11">(Chen et al., 2009)</ref>, or human action recognition in video <ref type="bibr" target="#b26">(Hoai et al., 2011)</ref>. Additionally, to speed up computations, some hardware implementations of S-DTW-based algorithms were proposed, using GPUs and FPGAs <ref type="bibr" target="#b59">(Rakthanmanon et al., 2013;</ref><ref type="bibr" target="#b28">Huang et al., 2013;</ref><ref type="bibr" target="#b64">Sart et al., 2010)</ref>. Further optimizations could be achieved, e.g., by learning a kernel approximating DTW as proposed by <ref type="bibr" target="#b10">Candelieri et al. (2019)</ref> or replacing DTW with PrunedDTW <ref type="bibr" target="#b68">(Silva and Batista, 2016)</ref>, an exact algorithm for speeding up DTW matrix calculation.</p><p>There have been a few attempts to utilize Dynamic Time Warping in Natural Language Processing. <ref type="bibr" target="#b40">Matuschek et al. (2008)</ref> explored the earlier idea of <ref type="bibr" target="#b60">Ratanamahatana and Keogh (2004)</ref> to treat texts as bit streams for the purposes of measuring text similarity. <ref type="bibr" target="#b37">Liu et al. (2007)</ref> utilized DTW with WordNet-based word similarity to decide the semantic similarity of sentences. <ref type="bibr" target="#b83">Zhu et al. (2017)</ref> used DTW with word embeddings distances to determine the similarity between paragraphs of text to decide the similarity between whole documents. Although sub-sequence DTW was successfully applied to query-by-example tasks of spoken term detection (e.g., <ref type="bibr" target="#b25">Hazen et al. (2009);</ref><ref type="bibr" target="#b49">Parada et al. (2009))</ref>, to the best of our knowledge, we are the first to apply it to plain-text query-by-example tasks. Moreover, we are unaware of any existing adaptations of sub-sequence DTW for querying by multiple examples simultaneously. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>List of Symbols</head><formula xml:id="formula_0">S := {X 1 ,· · · , X h } X Time-dependent sequence to align within target sequence Y; X := (x 1 ,· · · , x n ) X Reversed sequence of X; X := (x n ,· · · , x 1 ) = (x 1 ,· · · , x n ) Y Time-dependent target sequence; Y := (y 1 ,· · · , y m ) Y Reversed sequence of Y ;</formula><p>Y := (y m ,· · · , y 1 ) = (y 1 ,· · · , y m ) Z Consensus sequence at the current iteration; Z := (z 1 , ..., z q ) Index of the beginning of optimal sub-sequence alignment in Y ;</p><formula xml:id="formula_1">Z * Final</formula><formula xml:id="formula_2">j * 1 = m − j * k + 1 j * k Index of the end of optimal sub- sequence alignment in Y ; j * k = m − j * 1 + 1 k Length of warping path p l Index of lth element of set S m Length of sequence Y n</formula><p>Length of sequence X n l Length of sequence X l p Warping path; p := (p 1 ,· · · , p s ,· · · , p k ) p * Optimal warping path; p * := arg min p∈P (C p (X , Y)) p * 1 First element of optimal warping path in D; p * 1 = (1, j * 1 ) p * k Last element of optimal warping path in D; p * k = (n, j * k ) p * 1 First element of optimal warping path in D ; p * 1 = (1, j * 1 ) p * k Last element of optimal warping path in D ; p * k = (n, j * k ) q</p><p>Length of sequence Z r Length of the u sub-sequence s Index of sth element of warping path p t i ith token corresponding to ith element of X u Sub-sequence from Y similar to sequences from set S; u := (u 1 ,· · · , u r ) u * Sub-sequence from Y most similar to sequences from set S w Additional weight factor applied to the DTW equation</p><p>x i , y j Domain-specific objects e.g., word embeddings</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Statement</head><p>The general problem considered is to align multiple sequences of possibly different lengths from the set S optimally within some target sequence Y, assuming all have to be matched to the same subsequence of Y (see <ref type="figure">Figure 1</ref>). The total cost of alignment between sequences from S and sub-sequence of the Y sequence is the sum of distances between all pairs of matched elements. Distance between two elements is some domain-specific measure, such as the absolute difference between scalars associated with these elements. Optimal alignment is one that finds such sub-sequence of Y that the cost of aligning all S within this sub-sequence is minimized over all possible sub-sequences of Y. Sections 4.1 and 4.2 provide a formal definition of the mentioned objective under additional requirements of monotonicity and continuity.</p><p>An example real-word problem from Natural Language Processing is Named Entity Recognition, which may be considered under this paradigm, when one has to locate a named entity within the sentence, given a few examples of other named entities ( <ref type="figure">Figure 3</ref>). Another case is semantic retrieval of legal clauses from unstructured documents, given examples of clauses covering the same topic of interest from other documents.</p><p>Note that the problem mentioned above is a generalization of every problem previously considered as a sub-sequence matching to the cases when multiple examples are available instead of a single one. Problems outside the NLP to be con-(...) on Friday morning he had few kind words for President Bush 's economic policy -making Friday morning last night eight fifty in the morning three in the afternoon <ref type="figure">Figure 3</ref>: The DBTW matching using the semantic distance between word embeddings applied to the Named Entity Recognition problem. Here, the three examples of time expressions were matched to the Friday morning sub-sequence. sidered under this framework include spoken term detection or temporal activity detection in continuous, untrimmed video streams, which resembles the mentioned approach to semantic retrieval if one realizes it is in principle possible to perform sub-sequence matching on video frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Dynamic Time Warping</head><p>Let us start with an introduction of a widely used Dynamic Time Warping algorithm since evaluated methods either directly use one of its variants or propose its generalization to multiple alignment scenarios. DTW is a classical and well-established distance measure well suited to the task of comparing time series <ref type="bibr" target="#b4">(Berndt and Clifford, 1994)</ref> and was proposed by Vintsyuk (1968).</p><p>In general, DTW is based on the calculation of an optimal match between two given sequences, assuming one sequence is a time-warped version of another, that is, the target sequence is either stretched (one-to-many alignment), condensed (many-to-one alignment), or not warped (one-toone alignment) concerning the source sequence ( <ref type="figure" target="#fig_0">Figure 2</ref>). The optimal match is the one with the lowest cost computed as the sum of (predominantly Euclidean) distances for each matched pair of points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Algorithm</head><p>Classic DTW algorithm compares sequences assuming the first elements, and the last elements in both sequences are to be matched. In the case of natural language, this means that given two sentences (or documents), in every case, the first words of these will be linked with each other, as well as the last words. Although this variant is of no use in problems we consider in the present paper (see Section 1), there is a need to introduce it before going further.</p><p>The process of determining the optimal match between two time-dependent sequences X := <ref type="figure">Figure 4</ref>: The problem of determining the optimal match between sequences considered on n × m unit grid.</p><p>(x 1 ,· · · , x n ) and Y := (y 1 ,· · · , y m ) (where x 1 ,· · · , x n , y 1 ,· · · , y m are domain-specific objects, e.g., word embeddings) can be conducted on the n × m unit grid ( <ref type="figure">Figure 4</ref>). The path through the grid p = (p 1 ,· · · , p s ,· · · , p k ) where p s = (i s , j s ) is referred to as the warping path, whereas the total cost of the warping path p between X and Y is given by the sum of the local cost measures for the underlying grid nodes:</p><formula xml:id="formula_3">C p (X , Y) := k s=1 c(x is , y js ).</formula><p>where c is a local cost measure as defined by <ref type="bibr" target="#b45">Müller (2007)</ref>. <ref type="bibr">1</ref> It can be further normalized with division by n + m, leading to the time-normalized cost.</p><p>Let P denote an exponentially explosive set of all possible warping paths through the grid. The Dynamic Time Warping algorithm determines the best alignment path (optimal warping path)</p><formula xml:id="formula_4">p * = arg min p∈P (C p (X , Y))</formula><p>in O(nm) time, assuming:</p><p>• the alignment path has to start at the bottom left of the grid (i 1 = 1 and j 1 = 1), that is the first points in both sequences are matched,</p><p>• monotonicity (i s−1 ≤ i s and j s−1 ≤ j s ), that is moves to the left (back in time) on the grid are not allowed,</p><formula xml:id="formula_5">• continuity (i s − i s−1 ≤ 1 and j s − j s−1 ≤ 1)</formula><p>that is no node on a path can be skipped,</p><p>• the alignment path ends at the top right of the grid (i k = n and j k = m), that is the last points in both sequences are matched,</p><p>• optional conditions regarding the warping window or slope constraint that can be applied in order to improve performance <ref type="bibr" target="#b62">(Sakoe and Chiba, 1990)</ref>.</p><p>Let D denote the n × m matrix referred to as the accumulated cost matrix. The problem stated can be solved with the following initial conditions:</p><formula xml:id="formula_6">D i,1 := n i=1 c(x i , y 1 ), for i ∈ {1,· · · , n}, D 1,j := m j=1 c(x 1 , y j ), for j ∈ {1,· · · , m}.</formula><p>(1) and the following dynamic programming equation, calculated recursively in ascending order:</p><formula xml:id="formula_7">D i,j := c(x i , y j ) + min    D i,j−1 , D i−1,j−1 , D i−1,j .</formula><p>The value of D n,m (accumulated cost after reaching the top-right of the grid) is the total cost of the best alignment path:</p><formula xml:id="formula_8">DTW(X , Y) := C p * (X , Y).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Sub-sequence DTW</head><p>Mining scenarios considered in the introduction (such as Named Entity Recognition or Information Retrieval from untrimmed text streams) require slightly different behavior, offered by DTW operating on sub-sequences. It was initially introduced for problems such as the detection of spoken terms in audio recording.</p><p>In the case of sub-sequence DTW, the constraints on admissible paths are relaxed. Boundary conditions j 1 = 1 and j k = m are withdrawn, so the <ref type="figure">Figure 5</ref>: The problem of determining the optimal match between sequences X 1 , X 2 , Y considered on the rectangular cuboid. Computing the optimal match would have O(n 1 n 2 m) time complexity.</p><p>remaining i 1 = 1 and i k = n guarantee that the shorter sequence X will be matched entirely within Y, but not necessarily starting from the beginning of Y (and not obligatorily ending at the end of it). This behavior is achieved by a modification of the initial conditions described by Equation <ref type="formula">(1)</ref>. Before recursively calculating the remaining values of D the first row and first column, are being set to <ref type="bibr" target="#b45">(Müller, 2007)</ref>:</p><formula xml:id="formula_9">D i,1 := n i=1 c(x i , y 1 ), for i ∈ {1,· · · , n}, D 1,j := c(x 1 , y j ),</formula><p>for j ∈ {1,· · · , m}.</p><p>(2)</p><p>Minimal value from the mth row of D is the total cost of the best alignment path sDTW(X , Y), whereas its index points to the i k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Multi-sequence DTW</head><p>What if one has to determine a single sub-sequence warping path for a set of short sequences? This is the case we want to consider in the present paper because this applies to few-shot semantic retrieval tasks and Named Entity Recognition. For example, it is expected to align multiple sub-sequences (named entities from train set) optimally within the target sequence (sentence or document to detect new named entities in).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Exact Solution</head><p>Unfortunately, it is impossible to provide an exact solution due to practical reasons resulting from computational complexity.</p><p>As shown by <ref type="bibr" target="#b78">Wang and Jiang (1994)</ref>, multiple sequence alignment with the sum of all pairs score 2 is an NP-complete problem. In particular, the problem of aligning h sequences can be solved by applying DTW on the h-dimensional cuboid (see <ref type="bibr">Figure 5)</ref>. Assuming sequences are of the lengths n 1 ,· · · , n h , the algorithm would take Θ( h l=1 n l ) operations and would require an exponential space, meaning that calculating it for larger h is not possible in most cases <ref type="bibr" target="#b54">(Petitjean et al., 2011)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Barycenter Averaging</head><p>A reference heuristic for aligning multiple subsequences within the target sequence relies on the construction of an average, consensus sequence, representative for a given set of sentences. The term consensus sequence refers to a sequence which represents the most commonly encountered pattern in the set of sequences <ref type="bibr" target="#b55">(Pierce, 2017)</ref>. To approximate the optimal solution to the problem with multiple sequences, one can compute subsequence DTW between such consensus sequence and target sequence. <ref type="bibr" target="#b54">Petitjean et al. (2011)</ref> proposed the DTW Barycenter Averaging (DBA), the method for constructing consensus sequence inspired by computational biology. According to the authors, it builds an average sequence around significant states of the data, which is truly representative of the underlying phenomenon.</p><p>The algorithm assumes the iterative computation of an averaged sequence (See lines 2-7 from Algorithm 1). Let Z = (z 1 ,· · · , z q ) denote the consensus sequence at the current iteration. First, the initial Z is set (e.g., as a randomly selected element of S). Then, during each iteration:</p><p>• for each X ∈ S, DTW(X , Z) is calculated and underlying associations 3 resulting from the optimal warping path are stored,</p><p>• Z is updated as an average of the associated sequence's members, e.g., word embeddings.</p><p>During this process, the initial averaging is being refined since the new Z is closer to the sequences it averages concerning the total cost. The process Algorithm 1 DTW Barycenter Averaging based solution for aligning set of sequences S within target sequence Y. DBA is the Algorithm 5 from <ref type="bibr" target="#b54">Petitjean et al. (2011)</ref>.</p><formula xml:id="formula_10">1: procedure MATCHUSINGDBA(S, Y) 2: Z new ← random element from set S 3: do 4: Z old ← Z new 5: Z new ← DBA(Z old , S) 6: while Z old ≈ Z new 7: Z * ← Z new 8:</formula><p>return sDTW(Z * , Y) 9: end procedure finishes when a new consensus sequence Z new is almost equal to the previous consensus sequence Z old or when the maximum number of iterations 4 is reached. For a thorough, detailed description of DBA, please refer to Algoritm 5 from <ref type="bibr" target="#b54">Petitjean et al. (2011)</ref>.</p><p>Strictly speaking, to handle the set of sequences S = {X 1 ,· · · , X h } to be aligned within Y, one can first determine the consensus sequence Z * from S using DBA, and then utilize a standard sub-sequence DTW algorithm for two sequences (See Algorithm 1). This approach resembles the nearest centroid classifier <ref type="bibr" target="#b72">(Tibshirani et al., 2002)</ref> since one is determining class prototype and rely on distances between it and candidate sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Novel Solution: Dynamic Boundary Time Warping</head><p>Contrary to the DBA, we propose a method that does not average sub-sequences before determining the best match. Simultaneously, there is a low computational cost involved, even though a form of multi-alignment is being performed. Note that, for Information Retrieval, we are often interested only in approximating the p * 1 and p * k (more strictly the j * 1 and j * k components), 5 that is the beginning and the end of the optimal warping path concerning the set of short sequences S and long sequence Y. In other words, we want to find j 1 and j k that would minimize the sum of warping paths costs between each sequence X ∈ S and the long sequence Y:</p><formula xml:id="formula_11">j * 1 , j * k = arg min j 1 ,j k X ∈S C p (X , Y) .</formula><p>Note that the final warping paths between considered sequences have the same j * 1 , j * k . Calculating such optimal solution is more straightforward than presented in Section 4.3.1, but still too time-consuming for long sequence Y, because one would have to consider all possible j 1 and j k pairs (see Section 5.1). The situation changes when we allow either j 1 or j k to be different among examined warping paths, for instance, as it will be shown later (see Algorithm 2), we can easily find</p><formula xml:id="formula_12">j * k = arg min j k X ∈S C p (X , Y) .</formula><p>Our algorithm exploits this fact, and searches for the j k first (j 1 being unconstrained), and then for j 1 given previously determined optimal j k . We will use the name Dynamic Boundary Time Warping to highlight this difference when referring to the proposed solution.</p><p>Let us introduce the generalized DTW (or gDTW) first. We will use this term when referring to the DTW that is parameterized by the preinitialized accumulated cost matrix D. For example, for D initialized from Equation <ref type="formula">(1)</ref>:</p><formula xml:id="formula_13">gDTW(X , Y, D (1) ) = DT W (X , Y)</formula><p>and for D initialized from Equation <ref type="formula">(2)</ref>:</p><formula xml:id="formula_14">gDTW(X , Y, D (2) ) = sDT W (X , Y).</formula><p>DBTW degenerates to sDTW in the case of |S| = 1, that is when only one example is available. The complete computation when multiple examples are given is detailed in Algorithm 2 and Algorithm 3. We propose to handle the problem as follows:</p><p>• Initialize the accumulated cost matrix D from Equation <ref type="formula">(2)</ref> for each of the S elements independently.</p><p>• Calculate sDTW for each of the S elements independently, time-normalize underlying accumulated cost matrices, and sum their m-th rows. The result can be used to determine p * k = (i * k , j * k ) analogously to the conventional sub-sequence DTW.</p><p>Algorithm 2 Approximation of optimal j k for the multiple sub-sequences DTW problem.</p><formula xml:id="formula_15">1: procedure MULTIWARPINGEND(S, Y, equation) 2:</formula><p>sum ← (0,· · · , 0) 3:</p><p>for l ← 1, |S| do 4:</p><p>D l ← D l from equation 5:</p><p>gDTW(X l , Y, D l ) 6:</p><p>sum ← sum + D l n, * 7: end for 8: j k ← arg min i ( sumi) 9:</p><p>return j k 10: end procedure Algorithm 3 Approximation of optimal j 1 and j k for the multiple sub-sequences DTW problem.</p><p>1: procedure REV(X ) Sequence (x1,· · · , xn) 2:</p><p>return (xn, xn−1,· · · , x1) 3: end procedure 4:</p><formula xml:id="formula_16">5: procedure MATCHUSINGDBTW(S, Y) 6: j k ← MULTIWARPINGEND(S, Y, Equation (2)) 7: Y ← REV(Y) 8: S ← {REV(X ) : X ∈ S} 9: j k ← MULTIWARPINGEND(S , Y , Equation (3)) 10: j1 ← m − j k + 1 11:</formula><p>return j1, j k 12: end procedure • Reverse Y, as well as all sequences in S, and initialize D for each reversed sequence from S:</p><formula xml:id="formula_17">D i,1 := n i=1 c(x i , y 1 ) for i ∈ {1, . . . , n}, D 1,j := ∞ for j ∈ {1, . . . , m} \ j * 1 , D 1,j * 1 := c(x 1 , y j * 1 ), (3) where j * 1 = m − j * k + 1.</formula><p>• Calculate gDTW (using D ) on reversed sequences with the constraint that it should start with p * 1 = (1, m − j * k + 1), that is p * k after reversal. In this way p * k is determined, which gives p * 1 = (1, m − j * k + 1), that is p * k after reversal.</p><p>Note that DBTW first finds an optimal, common j * k for all sequences in S (starting indexes could be different). Then, all sequences are reversed, and j * k is determined by forcing the algorithm to start from j * 1 . This way, such j * 1 and j * k are found that approximate an optimal solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Complexity Study</head><p>Let us assume that the set of short sequences S consists of h sequences of length n, and long sequence Y is of length m.</p><p>DBA based solution from Algorithm 1 consists of two parts: (1) calculation of consensus sequence using DBA, and (2) calculation of sDTW between consensus sequence and Y sequence.</p><p>As described by <ref type="bibr" target="#b54">Petitjean et al. (2011)</ref>, the time complexity of Step 1 is equal to Θ(bn 2 h), where b refers to the number of iterations needed for DBA to converge. Since the complexity of Step 2 is Θ(nm), the complexity of all steps is equal to Θ(bn 2 h + nm).</p><p>The most costly operation for DBTW is the MULTIWARPINGEND procedure, which for each sequence in S computes gDTW with Y sequence, and it is called twice. Therefore DBTW time complexity is equal to Θ(2nmh) = Θ(nmh).</p><p>Depending on the problem setup, the time complexity of DBTW can be either smaller or higher than the complexity of the DBA solution.</p><p>Note that the optimal solution requires to compute gDTW between Y and each sequence in S for every possible j 1 and j k . Since there are m(m+1) 2 such possible unique pairs of j 1 and j k , the overall complexity is equal to Θ(nmh × m(m+1) 2 ) = Θ(nm 3 h), which is larger than the time complexity of DBTW and in most common cases larger than the DBA solution's complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Local Cost for Natural Language Processing Problems</head><p>There is a need to propose a suitable local cost function to apply any DTW-based dynamic programming algorithms to problems from the field of Natural Language Processing. We introduce a novel approach, relying on the distance between contextualized word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Contextualized Word Embeddings</head><p>Roughly speaking, the reasoning behind word embeddings is to follow the distributional hypothesis, according to which difference of meaning correlates with the difference of distribution <ref type="bibr" target="#b24">(Harris, 1954)</ref>. This means words sharing context tend to share similar meanings, and one is able to obtain semantic representations of words by optimizing some auxiliary objective in a sizeable unlabeled text corpus. A famous example is the Continuous Bag of Words (CBOW) model, where an average of vectors representing surrounding words is used as an input to log-linear classifier predicting the target (middle) word <ref type="bibr" target="#b42">(Mikolov et al., 2013)</ref>. This simple yet effective algorithm and the skip-gram model trained with the opposite objective have taken the world of word embeddings by storm <ref type="bibr" target="#b82">(Young et al., 2018)</ref>.</p><p>Representations provided using CBOW and similar models, however, are static. This means that when the pre-trained word embeddings are used in a downstream task, the representation of a given word is context-invariant: wound used as a past tense of wind share representation with wound denoting to injure.</p><p>Later approaches of <ref type="bibr" target="#b52">Peters et al. (2018a)</ref>, and <ref type="bibr" target="#b0">Akbik et al. (2018)</ref> assume the use of deep language models' internal states. These, contrary to static word embeddings, are expected to capture context-dependent word semantics. Resulting contextualized word embeddings are a function of the entire input sentence, such as for a sequence of z input tokens, an associated sequence of z vectors is returned.</p><p>Early contextualized word embeddings were sourced from language models using Recurrent Neural Networks, and they are currently being replaced by language models based on the architecture of Transformers <ref type="bibr">(Vaswani et al., 2017a)</ref> such as BERT <ref type="bibr" target="#b13">(Devlin et al., 2018)</ref>, GPT-2 <ref type="bibr" target="#b58">(Radford et al., 2019)</ref>, or RoBERTa <ref type="bibr" target="#b38">(Liu et al., 2019)</ref>. In the case of embeddings sourced from Transformer-based language models, the representation is obtained by attending to different tokens of the input sentence <ref type="bibr" target="#b15">(Ethayarajh, 2019)</ref>.</p><p>To the best of our knowledge, only <ref type="bibr" target="#b83">Zhu et al. (2017)</ref> used Dynamic Time Warping with word embeddings, and none of the previous attempts were based on contextualized word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Distance Measure</head><p>Many distance measures may be applied as local cost functions. In some domains, simple distance measures such as Euclidean distance are sufficient enough <ref type="bibr" target="#b67">(Shieh and Keogh, 2008)</ref>, whereas in other, it may be beneficial to use learned distance metric <ref type="bibr" target="#b23">(Gündogdu and Saraçlar, 2017)</ref>.</p><p>In the case of Natural Language Processing, we propose to rely on the cosine distance between contextualized word embeddings as the local cost, which is defined as: where, ||x x x|| is 2 -norm, and x x x · y y y is the dot product of the two vectors.</p><p>It is the most common metric used in NLP tasks when dissimilarity between two word vectors is considered <ref type="bibr" target="#b16">(Faruqui et al., 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3">Optional Weighting</head><p>Methods of determining document similarity tend to benefit from the inclusion of frequency or distribution information, such as in Inverse Document Frequency <ref type="bibr" target="#b41">(Metzler, 2008)</ref> or Smooth Inverse Frequency (SIF) weighting <ref type="bibr" target="#b1">(Arora et al., 2017)</ref>. We propose to further extend the algorithm with the additional weight factor w applied to the DTW equation:</p><formula xml:id="formula_18">D i,j := w i · c(x i , y j ) + min    D i,j−1 , D i−1,j−1 , D i−1,j .</formula><p>The w i is defined as the SIF of the underlying token t i :</p><formula xml:id="formula_19">w SIF i = a a + f i ,</formula><p>where f i stands for relative frequency of the token t i and a is the weight parameter, recommended to be between 10 −3 and 10 −4 <ref type="bibr" target="#b1">(Arora et al., 2017)</ref>. The intuition behind the introduction of such weighting is to capture the importance of the token when calculating an accumulated cost, in such a way that less informative (more probable) words contribute less to the final score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Implementation Details</head><p>The performance of local cost calculations is the primary factor when one is bound by time or resource restrictions in the case of DTW and similar algorithms <ref type="bibr" target="#b46">(Myers et al., 1980)</ref>. Since a cosine distance between word embeddings is used in our scenario, there is a need to calculate at least n × m distances (for the one-shot scenario) between vectors of 768 or more components, where n denote the number of words in positive example and m stands for the length of the document.</p><p>We were able to compute them efficiently with GPU and CUDA parallel computing platform. In our PyTorch-based implementation <ref type="bibr" target="#b50">(Paszke et al., 2019)</ref> for given input matrices representing embeddings of sequences to compare, a matrix of cosine distances is returned. It is further cast to NumPy array <ref type="bibr" target="#b48">(Oliphant, 2006)</ref> used in the Dynamic Programming part, which is implemented using Numba (JIT compiler translating Python and NumPy code into fast machine code, see <ref type="bibr" target="#b33">Lam et al. (2015)</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Evaluation</head><p>The introduced Dynamic Boundary Time Warping algorithm has broad applications in few-shot retrieval tasks from a variety of domains. We restricted ourselves to already established problems within the field of Natural Language Processing. For these, simple albeit specialized proof-ofconcept solutions were provided.</p><p>In each setting, an addition to DBTW has been proposed to facilitate handling the specific problem and demonstrate the algorithm's extensibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Few-shot Semantic Retrieval</head><p>The recently proposed contract discovery task <ref type="bibr" target="#b7">(Borchmann et al., 2020)</ref> aims to provide spans of requested target documents semantically similar to examples of spans from a few other documents. The mentioned dataset is intended to test the mechanisms that detect legal texts' regulations, given a few examples of other clauses regulating the same issue (query-by-multiple-examples scenario). Sample spans often vary in length, and the contained text is written using different vocabulary or syntax. Moreover, the text to search in lacks a formal structure, that is, no segmentation into distinct sections, articles, paragraphs, or points is given in advance.</p><p>For example, given two examples of text, where the parties agree on which jurisdiction the contract will be subject to:</p><p>This Agreement shall be governed by and construed under the laws of the State of California without reference to its rules of conflicts of laws. This Agreement is governed by the internal laws of the State of Florida and may be modified or waived only in writing signed by the Party against which such modification or waiver is sought to be enforced. match the following text span in another document:</p><p>Each party hereto consents to exclusive personal jurisdiction in the State of Delaware and voluntarily submits to the jurisdiction of the courts of the State of Delaware in any action or proceeding concerning this Agreement.</p><p>Because each word is represented by word embedding that reflects its meaning, and we can compute the distance between any pair of embeddings (Section 5.2), it is in principle possible to state that California is semantically quite similar to Delaware.</p><p>As a result, it is possible to attempt matching clauses such as the two shown above into the third one -word by word, embedding by embedding. Due to this fact, the problem of contract discovery is suited for the DBTW algorithm -it can be perceived as an alignment of multiple sequences (examples of desirable text spans from other legal documents) optimally within the target sequence (document in which one wants to determine a text span regulating the same issue).</p><p>Contract Discovery is evaluated with Soft F 1 metric calculated on character-level spans, as implemented in GEval tool <ref type="bibr" target="#b20">(Graliński et al., 2019)</ref>. Roughly speaking, this is the conventional F 1 measure, with precision and recall definitions altered to reflect the partial success of returning entities. As a result, identifying half of the correct span does not result in a 0 score.</p><p>Experiment. DBA and Adaptive CBOW solutions were evaluated in addition to DBTW. All utilized the same finetuned GPT-1 model, as described by <ref type="bibr" target="#b7">Borchmann et al. (2020)</ref>. We decided to utilize GPT-1 instead of GPT-2 because the authors achieved comparable results for both of them. At the same time, the latter has more parameters, larger embeddings, and more fine-grained tokenization, while all of these have a significant performance impact.</p><p>The GPT-1 Language Model we used was originally introduced by <ref type="bibr" target="#b57">Radford et al. (2018)</ref> who proposed to rely on the decoder of multi-layer Transformer <ref type="bibr">(Vaswani et al., 2017b)</ref>. The authors released a 12-layer model with 768-dimensional states and 12 attention heads. It uses a BPE vocabulary <ref type="bibr" target="#b66">(Sennrich et al., 2016)</ref> consisting of 40,000 sub-word units. <ref type="bibr" target="#b7">Borchmann et al. (2020)</ref> fine-tuned the model for 40 epochs on a corpus of legal documents, using a standard, next-word prediction objective. The authors used the initial learning rate of 5e − 5, linear learning rate decay, and Adam optimizer with decoupled weight decay <ref type="bibr" target="#b39">(Loshchilov and Hutter, 2019)</ref>. <ref type="bibr">6</ref> We used internal states from the last layer of the model as word embeddings, leading to the dimensionality of 768.</p><p>Because of the annotation assumptions made in this shared task, it is often beneficial to return the whole sentence, even though one can find the exact location of the desired clause (within the sentence). Consider an example of the following sentence:</p><p>This Agreement shall be governed by and con-6 Both model and the corpus are publicly available at ht tp://github.com/applicaai/contract-disc overy strued and enforced in accordance with the laws of the State of Georgia... ...as to all matters regardless of the laws that might otherwise govern under principles of conflicts of laws applicable thereto.</p><p>Here, DBTW selects only the first part, and it would be desirable to highlight it for an end user in the real-world application. Nevertheless, it was preferred to keep the complete sentence as an expected clause during the preparation of <ref type="bibr" target="#b7">Borchmann et al. (2020)</ref> dataset. The annotator selected an incomplete sentence only when the remaining, nonimportant part was of a greater length than the crucial one, which contains the desired information. That is the reason why we were returning results rounded in order to match the entire sentence that "clause core" was found in.</p><p>Baseline. In Algorithm 5 we introduce the Adaptive Continuous Bag of Words (ACBOW), a simple and fast algorithm, that represents a straightforward, natural approach to tackling the problem. Roughly speaking, the idea is to move with a constantly changing window over tokens from Y and determine the best sub-sequence (Algorithm 4). Embeddings for each text fragment are averaged and the resulting vectors compared with cosine similarity. In the case of multiple sequences, an average of individual similarities to the considered window is used (procedure SIM in Algorithm 4).</p><p>Note that the ACBOW for which the results were reported in <ref type="table" target="#tab_2">Table 1</ref> differs from the ACBOW Algorithm 5. The former was extended with a possibility to look into the future and check if adding more tokens would improve an overall score, even when some of them temporarily lower the similarity.</p><p>Results. <ref type="table" target="#tab_2">Table 1</ref> summarizes the Soft F 1 scores achieved. Contrary to what one might suspect, the Adaptive CBOW baseline was unable to provide satisfactory results. Scores of the sub-sequence DTW with a DBA-determined consensus sequence were substantially higher. The usage of cosine distance instead of Euclidean seems beneficial in the case of DBA used with word embeddings. DBTW performs the best, and its effectiveness can be attributed to both inverse frequency weighting and the proposed way of handling multiple sequences. The new method proposed in this paper slightly outperforms the method presented by <ref type="bibr" target="#b7">Borchmann et al. (2020)</ref> even when fICA projection 7 of embed-Algorithm 4 Finding one similar sub-sequence u = (u 1 , . . . , u r ) from Y to S sequences given starting index j.</p><formula xml:id="formula_20">1: procedure SIM(S, u) 2: E ← {MEAN(X ) : X ∈ S} 3: eu ← MEAN(u) 4:</formula><p>scores ← {c(eu, e) : e ∈ E} 5:</p><p>return MEAN(scores) 6: end procedure 7: 8: procedure FINDONE(S, Y, j) 9:</p><p>u * ← (yj) 10:</p><p>u ← () 11:</p><p>while j + 1 &lt; m and u = u * do 12:</p><p>if SIM(S, u) &lt; SIM(S, (u, yj+1)) then 13:</p><p>u ← (u, yj+1) 14:</p><p>u * ← u 15:</p><p>end if 16:</p><p>u ← (u2, . . . , ur) 17:</p><p>if SIM(S, u) &lt; SIM(S, u ) then 18:</p><p>u ← u 19:</p><p>u * ← u 20: end if 21:</p><p>end while 22:</p><p>return u * , SIM(S, u) 23: end procedure Algorithm 5 Finding most similar subsequence u = (u 1 , . . . , u r ) from Y given S sequences using ACBOW algorithm.</p><formula xml:id="formula_21">1: procedure MATCHUSINGACBOW(S, Y, overlap) 2: u * , score * ← FINDONE(S, Y, 1) 3: u ← u * 4:</formula><p>while |u| &lt; m do 5:</p><p>j ← |u| + 1 − |u * | × overlap 6:</p><p>u, score ← FINDONE(S, Y, j) 7:</p><p>if score &gt; score * then 8:</p><p>u * , score * ← u, score 9: end if 10: end while 11:</p><p>return u * , score * 12: end procedure dings was not applied. It is worth mentioning that SIF weighting does not lead to an improvement in the aforementioned paper. Results were even better when both SIF and fICA projection was used.</p><p>There are several distinguishing features the improvement over <ref type="bibr" target="#b7">Borchmann et al. (2020)</ref> can be attributed to. First of all, there is a reduction of noise that occurs in DBTW. Recall the example of the governing law clause presented at the beginning of Section. The first part of the sentence contains information required to correctly classify the clause, whereas the rest is a potential noise source. The DBTW considers all the possible sub-sentences and is not restricted to the sentence boundaries, as Analysis <ref type="bibr" target="#b30">(Hyvärinen and Oja, 2000)</ref> and observed it helps to distinguish semantically differing texts. See <ref type="table" target="#tab_2">Table 1</ref> for comparison. is the method proposed by <ref type="bibr" target="#b7">Borchmann et al. (2020)</ref>. Secondly, DBTW is not order-invariant, and thus it can easily capture key phrases and word n-grams. Thirdly, DBTW operates on word-level, whereas other methods rely on averaged representation of multiple, possibly a few hundred words. The latter results in yet additional noise and information loss. Moreover, note that <ref type="bibr" target="#b7">Borchmann et al. (2020)</ref> chose the most similar spans from the sentence n-grams. Although their approach leads to comparable results to those obtained with DBTW, it could be applied to a limited number of problems when the number of considered n-grams is low. In contrast, DBTW is not subject to such constraints and can effectively search for a very long sequence. For example, when word-level (instead of sentencelevel) sequences are considered, they often become much longer, and the n-gram based methods would be too expensive computationally.</p><p>Most of the mentioned advantages also apply to the DBA. However, one may hypothesize that information loss occurring during the consensus sequence calculation is substantial in long passages from the Contract Discovery dataset. Similarly, ACBOW shares some desired properties of DBTW (e.g., consideration of arbitrary sub-sequence on word-level) but, contrary to the DBTW, is orderinvariant and relies on noisy averaged representations of multiple word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Few-shot Named Entity Recognition</head><p>Named Entity Recognition is the task of tagging entities in text with their corresponding type. These differ depending on the dataset. In the case of the richly-annotated Ontonotes corpus <ref type="bibr" target="#b56">(Pradhan et al., 2013)</ref>, tags such as people and organization names, locations, languages, events, monetary values, and more are used.</p><p>There were several attempts to the NER problem in a few-shot scenario <ref type="bibr" target="#b17">(Fritzler et al., 2019;</ref><ref type="bibr" target="#b27">Hofer et al., 2018)</ref>. Since the mentioned setting is in line with our problem statement (Section 3), we approached it to provide another proof-of-concept from the field of NLP. As outlined in Section 1, we solve the problem of Named Entity Recognition with a new approach of semantic sub-sequence matching.</p><p>Named Entity Recognition task differs substantially from Semantic Retrieval discussed in the previous section. To tackle the problem effectively, one has to notice there is a significant variance in lengths of entities to be retrieved-they can range from one word to over a dozen words within the same class. This fact could motivate non-trivial modifications of DBTW such as:</p><p>• Normalization of accumulated costs for sequences from S in order to compensate the impact of longer sequences on the overall score (otherwise the longer individual warping path is, the higher would be its impact when choosing the approximately optimal path for the set of sequences).</p><p>• Preference for either contraction or expansion when determining the warping path for a single sequence, e.g., depending on its length in relation to average named entity length.</p><p>There are multiple normalization methods to consider in the former, whereas the latter may require the introduction of warping path bands to restrict the upper length of matched sub-sequence. We decided to take a more straightforward, which solves both problems at the same time:</p><p>• Given the set of sequences S, take the length of the longest as a target size.</p><p>• Resample shorter sequences to reach the target size using interpolation with the spline of order 1, as implemented in tslearn TimeSeries-Resampler <ref type="bibr" target="#b71">(Tavenard et al., 2017)</ref>.</p><p>After this step, no further normalization nor weights adjustments may be required to provide satisfactory results. Because the number of results to be returned for a given sentence varies from zero to few, one cannot simply return the most similar sub-sequence in the case of Named Entity Recognition. We tackle the problem by introducing a threshold and return all non-overlapping paths from the given sentence, with an accumulated cost below the assumed distance level. Given a set of training examples S, we calculate DBTW(S \ {X }, X ) for each X ∈ S. The threshold is calculated as the maximal cost of optimal warping path from such inner-train matches. The threshold for DBA is determined analogously. Experiment. We roughly followed the procedure for evaluation of a few-shot NER proposed by <ref type="bibr" target="#b17">Fritzler et al. (2019)</ref>. Authors trained models on subsamples of Ontonotes development set <ref type="bibr" target="#b56">(Pradhan et al., 2013)</ref> for each class separately. 8 For each case, h = 20 sentences containing a particular named entity were selected. Besides, sentences without considered entity had all the classes replaced with O, and part of them were added to the train set, to preserve the original distribution of the currently evaluated class. Note that h is not necessarily equal to the number of annotations available since it is common for one Ontonotes sentence to contain more than one named entity of the same type.</p><p>In our case, solutions were evaluated for h ∈ [1, 10], since we are aiming mainly at good performance for a lower number of examples available. Moreover, ten experiments with different random seeds were conducted for each class, instead of four performed by <ref type="bibr" target="#b17">Fritzler et al. (2019)</ref>.</p><p>Baseline. LSTM-CRF used as a reference is a BiLSTM-CRF model trained on ELMo and GloVe embeddings. It follows the specification of <ref type="bibr" target="#b17">Fritzler et al. (2019)</ref>, but with the difference that trained character embeddings were not used to simplify the comparison with DBTW. Note that otherwise, one had to propose a procedure of training character embeddings compatible with DBTW, which is beyond the scope of this paper. Nevertheless, we report results of LSTM-CRF with trained character-level embeddings for the sake of completeness.</p><p>The remaining LSTM-CRF baseline, DBA, and DBTW approaches rely on the same embeddings, resulting from the concatenation of the 1024- (2018b) with the original 50-dimensional GloVe embeddings <ref type="bibr" target="#b51">(Pennington et al., 2014)</ref>. Although <ref type="bibr" target="#b17">Fritzler et al. (2019)</ref> trained their baselines for 20 epochs, we found our models undertrained in this setting and decided to enlarge the value to 30 epochs.</p><p>Results. Comparison of DBTW, DBA, and LSTM-CRF with the same input embeddings is presented on <ref type="figure" target="#fig_2">Figure 6</ref>. Span F1 score refers to a commonly used F β=1 variant where exact matches of the corresponding entities are considered <ref type="bibr" target="#b73">(Tjong Kim Sang and De Meulder, 2003)</ref>. Both DBA and DBTW outperform the LSTM-CRF baseline in a few-shot setting. Noteworthy, DTW-based methods receive near-identical scores in the experiment. In order to statistically compare methods, we decided to use the permutation t-test. The implemented test corresponds to the proposal of <ref type="bibr" target="#b12">Chung and Romano (2013)</ref>. While a permutation test requires that we see all possible permutations of the data (which can become quite large), we can easily conduct "approximate permutation tests" by simply conducting a very large number of samples (we used 10,000 permutations instead of 3,628,800 possible permutations). That process should, in expectation, approximate the permutation distribution. Obtained p-values we can find in <ref type="table" target="#tab_3">Table 2 and Table 3</ref>.</p><p>From <ref type="table" target="#tab_3">Table 2</ref> we can see that it is possible to reject (α = 5%) the null hypothesis (about equality of methods DBA and DBTW) only for n = 5 (the same we can read from <ref type="figure" target="#fig_2">Figure 6</ref>). In such situations, it seems reasonable to assume that methods do not differ significantly.</p><p>Comparable results of DBTW and DBA can be potentially attributed to two factors. Firstly, named entities in ontonotes are usually short: 58% of the test set entities consist of a single word and 21%of two words. When one-word sub-sequences are to be considered, the methods are roughly equivalent. We expect DBTW to perform better in the case of long sequences because it is where noise related to the calculation of the DBA consensus sequence emerges. Secondly, we found the problem of determining the number of sub-sequences to return, which occurs in both DBA and DBTW, to play an important role. If the sentence contains a named entity of a particular type, the highestscored sub-sequence can be classified as such with high confidence. E.g., we can maximize recall by withdrawing the threshold and returning the top result. Nevertheless, precision suffers without the threshold, and the simple heuristics we experimented with are unable to provide an optimal cut-off.</p><p>LSTM-CRF with character-level embeddings seems to converge faster than the LSTM-CRF baseline. It appears that it achieves scores comparable to DBTW for five and more sentences in the train  p-value 0.0001 0.0001 0.1262 0.0025 0.0606 0.0482 0.1114 0.0693 0.0819 0.7024 set <ref type="table" target="#tab_4">(Table 3</ref>). However, due to the reasons outlined at the beginning, the methods cannot be directly compared.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Summary and Future Work</head><p>In this paper, an algorithm inspired by Dynamic Time Warping was proposed, as well as a new application of existing DBA Barycenter Averaging heuristics. It was shown how to adapt it to current problems in the field of Natural Language Processing as a result of cosine distance applied to contextualized word embeddings. Unlike its predecessors, Dynamic Boundary Time Warping can find an approximate solution for the problem of querying by multiple examples. What is crucial, the proposed approach is in some applications substantially better than calculating a consensus sequence and utilizing it to perform sub-sequence DTW search, presumably because there is no unnecessary information loss involved. Due to the inclusion of inverse frequency weighting specific to NLP problems, its effectiveness was further improved. Thus it was able to outperform methods previously proposed for Few-shot Contract Discovery with the same Language Model applied. Applications of the proposed algorithm are not limited to the cases where proof-of-concept solutions were provided, and it can be applied to other few-shot retrieval tasks. Problems outside the NLP to be considered under this framework include temporal activity detection in continuous, untrimmed video streams <ref type="bibr" target="#b44">(Montes et al., 2016;</ref><ref type="bibr" target="#b80">Xu et al., 2019)</ref>, which resembles mentioned approach to Semantic Retrieval if one realizes it is in principle possible to perform sub-sequence matching on video frame embeddings. Such can be encoded with a pretrained image classification network (i.e., ResNeXt <ref type="bibr" target="#b79">(Xie et al., 2016)</ref>) and processed analogously. Moreover, the DBTW applies to every problem previously considered as a sub-sequence matching when multiple examples are available instead of a single one.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>DTW between two time series and the optimal alignment path. The dashed line connects elements aligned between up and down time series. The plot on the right depicts which time step was aligned to which, with each off-diagonal move indicating warping.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>c(x x x, y y y) = 1 − x x x·y y y ||x x x|| ||y y y|| 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>dimensional ELMo model released by Peters et al. Performance in Named Entity Recognition as a function of the number of sentences with positive examples available. Note that LSTM-CRF (+char) model is not directly comparable because, contrary to the LSTM-CRF, DBA, and DBTW, it uses character-level embeddings in addition to ELMo and GloVe.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Item from ith row and jth column of matrix D calculated from X l , Y</figDesc><table><row><cell>D l i,j</cell><cell></cell></row><row><cell>e</cell><cell>Element of set E</cell></row><row><cell>e u</cell><cell>Embedding representing sequence</cell></row><row><cell></cell><cell>u</cell></row><row><cell>f i</cell><cell>Relative frequency of the token t i</cell></row><row><cell>h</cell><cell>Size of set S</cell></row><row><cell>i</cell><cell>Index of ith element of X</cell></row><row><cell>j</cell><cell>Index of jth element of Y</cell></row><row><cell>j  *  1</cell><cell>Index of the beginning of optimal</cell></row><row><cell></cell><cell>sub-sequence alignment in Y</cell></row><row><cell>j  *  k</cell><cell>Index of the end of optimal sub-</cell></row><row><cell></cell><cell>sequence alignment in Y</cell></row><row><cell>j  *  1</cell><cell></cell></row><row><cell></cell><cell></cell><cell>consensus sequence</cell></row><row><cell></cell><cell>a</cell><cell>Hyperparameter of the smooth in-</cell></row><row><cell></cell><cell></cell><cell>verse frequency (SIF) method</cell></row><row><cell></cell><cell>b</cell><cell>Number of iterations needed for</cell></row><row><cell></cell><cell></cell><cell>DTW Barycenter Averaging (DBA)</cell></row><row><cell></cell><cell></cell><cell>to converge</cell></row><row><cell></cell><cell cols="2">c(x i , y j ) Local cost measure for domain-</cell></row><row><cell></cell><cell></cell><cell>specific objects x i and y j e.g., co-</cell></row><row><cell></cell><cell></cell><cell>sine distance between word embed-</cell></row><row><cell></cell><cell></cell><cell>dings</cell></row><row><cell></cell><cell cols="2">C p (X , Y) Cost of the warping path p be-</cell></row><row><cell></cell><cell></cell><cell>tween X and Y; C p (X , Y) :=</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Results of solutions based on the same finetuned GPT-1 model as described by<ref type="bibr" target="#b7">Borchmann et al. (2020)</ref>, obtained on test set.</figDesc><table><row><cell>Method</cell><cell>Soft F1</cell></row><row><cell>Borchmann et al. (2020)</cell><cell></cell></row><row><cell>−fICA</cell><cell>.47</cell></row><row><cell>+fICA</cell><cell>.49</cell></row><row><cell>ACBOW</cell><cell>.35</cell></row><row><cell>DBA</cell><cell></cell></row><row><cell>Euclidean</cell><cell>.43</cell></row><row><cell>Cosine</cell><cell>.44</cell></row><row><cell>DBTW</cell><cell></cell></row><row><cell>−SIF</cell><cell>.47</cell></row><row><cell>+SIF (a = 10 −3 )</cell><cell>.50</cell></row><row><cell>+SIF +fICA</cell><cell>.51 .51 .51</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>p-values for permutation t-test comparing DBA and DBTW. 0.9339 0.3895 0.8779 0.8803 0.0038 0.4499 0.309 0.2049 0.2161 0.1727</figDesc><table><row><cell>n</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell></row><row><cell>p-value</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>p-values for permutation t-test comparing DBTW and LSTM-CRF (+char).</figDesc><table><row><cell>n</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>10</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">In Section 5.2 we propose a local cost measure specifically tailored for problems in the NLP field.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">When SP-score is considered, optimal alignment is one that minimizes the value over all possible alignments<ref type="bibr" target="#b6">(Bonizzoni and Della Vedova, 2001)</ref>.3  We mean DTW associations like in theFigure 1. For example y6 fromFigure 1is associated with 4 sequence's members x1, x2 from X1, x1 from X2 and x1 from X3. Analogously z1 from Z could also be associated with sequence's members from each X ∈ S.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">For simplicity we omitted constraint on a number of maximum iterations criterion in Algorithm 1.5  For instance, when retrieving text spans, we do not care about the alignment with the search query, but only the content (defined by j1 and j k ).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7"><ref type="bibr" target="#b7">Borchmann et al. (2020)</ref> used decomposition of contextualized word embeddings based on Independent Component</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">The original train set was used as a source of out-ofdomain data in part of scenarios, but this does not apply to methods based on DBTW. Similarly, as a baseline, we relied on an approach, which utilizes only in-domain training data. See<ref type="bibr" target="#b17">Fritzler et al. (2019)</ref> for details regarding this distinction.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The Smart Growth Operational Programme supported this research under project no. POIR.01.01.01-00-0605/19 (Disruptive adoption of Neural Language Modelling for automation of text-intensive work).</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING 2018, 27th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A simple but tough-to-beat baseline for sentence embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingyu</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Crossgeneralization: learning novel classes from a single example by feature replacement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shimon</forename><surname>Ullman</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2005.117</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="672" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Stride Segmentation During Free Walk Movements Using Multi-dimensional Subsequence Dynamic Time Warping on Inertial Sensor Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Barth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cäcilia</forename><surname>Oberndorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><forename type="middle">Federico</forename><surname>Pasluosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Schülein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heiko</forename><surname>Gaßner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Reinfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Kugler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Schuldhaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Winkler</surname></persName>
		</author>
		<idno type="DOI">10.3390/s150306419</idno>
		<idno>UnivIS-Import:2015-04- 14</idno>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="6419" to="6440" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Jochen Klucken, and Björn Eskofier. Pub.2015.tech.IMMD.IMMD5.stride</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Using dynamic time warping to find patterns in time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Berndt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Clifford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining, AAAIWS&apos;94</title>
		<meeting>the 3rd International Conference on Knowledge Discovery and Data Mining, AAAIWS&apos;94</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="359" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">In defense of nearest-neighbor based image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Boiman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The complexity of multiple sequence alignment with sp-score that is a metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paola</forename><surname>Bonizzoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianluca Della</forename><surname>Vedova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">259</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="63" to="79" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Contract discovery: Dataset and a few-shot semantic retrieval challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Borchmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawid</forename><surname>Wiśniewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrzej</forename><surname>Gretkowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Izabela</forename><surname>Kosmala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawid</forename><surname>Jurkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Szałkiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriela</forename><surname>Pałka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karol</forename><surname>Kaczmarek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agnieszka</forename><surname>Kaliska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Graliński</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>with competitive baselines</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Off the beaten path: Let&apos;s replace term-based retrieval with k-nn search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Boytsov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yury</forename><surname>Malkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<idno type="DOI">10.1145/2983323.2983815</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, CIKM &apos;16</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management, CIKM &apos;16<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1099" to="1108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Using centroids of word embeddings and word mover&apos;s distance for biomedical document retrieval in question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios-Ioannis</forename><surname>Brokos</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-2915</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Workshop on Biomedical Natural Language Processing</title>
		<meeting>the 15th Workshop on Biomedical Natural Language Processing<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="114" to="118" />
		</imprint>
	</monogr>
	<note>Prodromos Malakasiotis, and Ion Androutsopoulos. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Efficient kernel-based subsequence search for enabling health monitoring services in iotbased home setting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Candelieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincenzina</forename><surname>Messina</surname></persName>
		</author>
		<idno type="DOI">10.3390/s19235192</idno>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">5192</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Efficient processing of warping time series join of motion capture data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueguo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beng Chin</forename><surname>Ooi</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDE.2009.20</idno>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE 25th International Conference on Data Engineering</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1048" to="1059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exact and asymptotically robust permutation tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunyi</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">P</forename><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="484" to="507" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Querying and mining of time series data: Experimental comparison of representations and distance measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goce</forename><surname>Trajcevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Scheuermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eamonn</forename><surname>Keogh</surname></persName>
		</author>
		<idno type="DOI">10.14778/1454159.1454226</idno>
	</analytic>
	<monogr>
		<title level="j">Proc. VLDB Endow</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1542" to="1552" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kawin</forename><surname>Ethayarajh</surname></persName>
		</author>
		<idno>abs/1909.00512v1</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Problems with evaluation of word embeddings using word similarity tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manaal</forename><surname>Faruqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulia</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushpendre</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W16-2506</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP</title>
		<meeting>the 1st Workshop on Evaluating Vector-Space Representations for NLP<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="30" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Few-shot classification in named entity recognition task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fritzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maksim</forename><surname>Kretov</surname></persName>
		</author>
		<idno type="DOI">10.1145/3297280.3297378</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing, SAC &apos;19</title>
		<meeting>the 34th ACM/SIGAPP Symposium on Applied Computing, SAC &apos;19<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="993" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">End-to-End Retrieval in Continuous Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Gillick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Presta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaurav Singh</forename><surname>Tomar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Recent named entity recognition and classification techniques: A systematic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Archana</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Sci. Rev</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="21" to="43" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">GEval: Tool for debugging NLP datasets and models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filip</forename><surname>Graliński</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anna</forename><surname>Wróblewska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Stanisławek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamil</forename><surname>Grabowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Górecki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="254" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An algorithm for spoken keyword spotting via subsequence dtw</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongmei</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoqun</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICNIDC.2012.6418819</idno>
	</analytic>
	<monogr>
		<title level="m">2012 3rd IEEE International Conference on Network Infrastructure and Digital Content</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="573" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural vector spaces for unsupervised information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Van Gysel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
		</author>
		<idno type="DOI">10.1145/3196826</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distance metric learning for posteriorgram based keyword search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Batuhan</forename><surname>Gündogdu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murat</forename><surname>Saraçlar</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICASSP.2017.7953240</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<biblScope unit="page" from="5660" to="5664" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zellig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harris</surname></persName>
		</author>
		<idno type="DOI">10.1080/00437956.1954.11659520</idno>
		<title level="m">Distributional structure. WORD</title>
		<imprint>
			<date type="published" when="1954" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="146" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Query-by-example spoken term detection using phonetic posteriorgram templates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">J</forename><surname>Hazen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">M</forename><surname>White</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Workshop on Automatic Speech Recognition &amp; Understanding</title>
		<imprint>
			<biblScope unit="page" from="421" to="426" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Joint segmentation and classification of human actions in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh</forename><surname>Hoai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Zhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><surname>De La Torre</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2011.5995470</idno>
	</analytic>
	<monogr>
		<title level="m">CVPR 2011</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3265" to="3272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Few-shot learning for named entity recognition in medical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximilian</forename><surname>Hofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Kormilitzin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejo</forename><surname>Nevado-Holgado</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">DTW-based subsequence similarity search on amd heterogeneous computing platform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sitao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guohao</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huazhong</forename><surname>Yang</surname></persName>
		</author>
		<idno type="DOI">10.1109/HPCC.and.EUC.2013.149</idno>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 10th International Conference on High Performance Computing and Communications 2013 IEEE International Conference on Embedded and Ubiquitous Computing</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1054" to="1063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Bidirectional LSTM-CRF models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno>abs/1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Independent component analysis: algorithms and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Hyvärinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erkki</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural networks : the official journal of the International Neural Network Society</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="411" to="441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Bridging the gap: Incorporating a semantic similarity measure for effectively mapping pubmed queries to documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Fiorini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">John</forename><surname>Wilbur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbi.2017.09.014</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="122" to="127" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning<address><addrLine>Lille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Numba: A llvm-based python jit compiler</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Siu Kwan Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Pitrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Seibert</surname></persName>
		</author>
		<idno type="DOI">10.1145/2833157.2833162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC, LLVM &apos;15</title>
		<meeting>the Second Workshop on the LLVM Compiler Infrastructure in HPC, LLVM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno>abs/1603.01360</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A survey on deep learning for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aixin</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianglei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenliang</forename><surname>Li</surname></persName>
		</author>
		<idno>abs/1812.09449</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Oneshot learning of object categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2006.79</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="594" to="611" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sentence Similarity based on Dynamic Time Warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zheng</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICSC.2007.48</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Semantic Computing (ICSC 2007)</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="250" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<title level="m">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Measuring text similarity with dynamic time warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matuschek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Conrad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2008 international symposium on Database engineering &amp; applications</title>
		<meeting>the 2008 international symposium on Database engineering &amp; applications</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">299</biblScope>
			<biblScope unit="page" from="263" to="267" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Generalized Inverse Document Frequency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient estimation of word representations in vector space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1301.3781</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">An introduction to neural information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhaskar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Craswell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="126" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Temporal activity detection in untrimmed videos with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amaia</forename><surname>Salvador</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Pascual-Delapuente</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Giró I Nieto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1st NIPS Workshop on Large Scale Computer Vision Systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Dynamic Time Warping. Information Retrieval for Music and Motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meinard</forename><surname>Müller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Performance tradeoffs in dynamic time warping algorithms for isolated word recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cory</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Rabiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Rosenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="623" to="635" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Extracting fairness policies from legal documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rashmi</forename><surname>Nagpal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chetna</forename><surname>Wadhwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mallika</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samiulla</forename><surname>Shaikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameep</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikram</forename><surname>Goyal</surname></persName>
		</author>
		<idno>abs/1809.04262</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">A guide to NumPy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Travis</forename><surname>Oliphant</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Trelgol Publishing USA</publisher>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Query-by-example Spoken Term Detection For OOV terms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carolina</forename><surname>Parada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Sethy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuvana</forename><surname>Ramabhadran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Workshop on Automatic Speech Recognition &amp; Understanding</title>
		<imprint>
			<biblScope unit="page" from="404" to="409" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alché-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>In In EMNLP</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno>abs/1802.05365</idno>
		<title level="m">Deep contextualized word representations. CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Deep contextualized word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of NAACL</title>
		<meeting>of NAACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">A global averaging method for dynamic time warping, with applications to clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Petitjean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alain</forename><surname>Ketterlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Gançarski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="678" to="693" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">A Conceptual Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Pierce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<date type="published" when="2017" />
			<publisher>W. H. Freeman</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Towards robust linguistic analysis using OntoNotes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Sameer Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hwee Tou</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anders</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Björkelund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventeenth Conference on Computational Natural Language Learning</title>
		<meeting>the Seventeenth Conference on Computational Natural Language Learning<address><addrLine>Sofia, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="143" to="152" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Improving language understanding with unsupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Narasimhan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Tim Salimans, and Ilya Sutskever</note>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>OpenAI</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Addressing big data time series: Mining trillions of time series subsequences under dynamic time warping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilson</forename><surname>Thanawin Rakthanmanon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdullah</forename><surname>Campana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Mueen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Westover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesin</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eamonn</forename><surname>Zakaria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keogh</surname></persName>
		</author>
		<idno type="DOI">10.1145/2500489</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Knowl. Discov. Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Everything you know about dynamic time warping is wrong</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Chotirat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eamonn</forename><surname>Ratanamahatana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third Workshop on Mining Temporal and Sequential Data</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">An anchored dynamic timewarping for alignment and comparison of swallowing acoustic signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcelo</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elmar</forename><surname>Fugmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gisele</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Nunes</surname></persName>
		</author>
		<idno type="DOI">10.1109/EMBC.2017.8037426</idno>
	</analytic>
	<monogr>
		<title level="m">2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2749" to="2752" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Dynamic programming algorithm optimization for spoken word recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroaki</forename><surname>Sakoe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seibi</forename><surname>Chiba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings in Speech Recognition</title>
		<editor>Alex Waibel and Kai-Fu Lee</editor>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="159" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Stream monitoring under the time warping distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yasushi</forename><surname>Sakurai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Yamamuro</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDE.2007.368963</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE 23rd International Conference on Data Engineering</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1046" to="1055" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Accelerating dynamic time warping subsequence search with gpus and fpgas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doruk</forename><surname>Sart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdullah</forename><surname>Mueen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walid</forename><surname>Najjar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eamonn</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vit</forename><surname>Niennattrakul</surname></persName>
		</author>
		<idno type="DOI">10.1109/ICDM.2010.21</idno>
	</analytic>
	<monogr>
		<title level="m">2010 IEEE International Conference on Data Mining</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1001" to="1006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">SEAGLE: A platform for comparative evaluation of semantic encoders for information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">David</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Dietsche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simone</forename><forename type="middle">Paolo</forename><surname>Ponzetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goran</forename><surname>Glavaš</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-3034</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="199" to="204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1162</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">iSAX: Indexing and mining terabyte sized time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Shieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eamonn</forename><surname>Keogh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;08</title>
		<meeting>the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, KDD &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="623" to="631" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Speeding up all-pairwise dynamic time warping matrix calculation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Batista</surname></persName>
		</author>
		<idno type="DOI">10.1137/1.9781611974348.94</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 SIAM International Conference on Data Mining</title>
		<meeting>the 2016 SIAM International Conference on Data Mining<address><addrLine>Miami, Florida, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-05-05" />
			<biblScope unit="page" from="837" to="845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">tslearn: A machine learning toolkit dedicated to time-series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Tavenard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johann</forename><surname>Faouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Vandewiele</surname></persName>
		</author>
		<ptr target="https://github.com/rtavenar/tslearn" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Diagnosis of multiple cancer types by shrunken centroids of gene expression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balasubramanian</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilbert</forename><surname>Chu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="page" from="6567" to="6572" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Introduction to the conll-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien</forename><surname>De Meulder</surname></persName>
		</author>
		<idno type="DOI">10.3115/1119176.1119195</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
	<note>CONLL &apos;03</note>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">A machine learning approach to identifying sections in legal briefs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Vanderbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Bockhorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chad</forename><surname>Oldfather</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MAICS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>and Illia Polosukhin. 2017a. Attention is all you need. CoRR, abs/1706.03762</note>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>and Illia Polosukhin. 2017b. Attention is all you need</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Speech discrimination by dynamic programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Taras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vintsyuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Kibernetika</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="81" to="88" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">On the complexity of multiple sequence alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lusheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computational biology</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="337" to="348" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5987" to="5995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Twostream region convolutional 3d network for temporal activity detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huijuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abir</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="2319" to="2332" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">A survey on recent advances in named entity recognition from deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Recent trends in deep learning based natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devamanyu</forename><surname>Hazarika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="55" to="75" />
		</imprint>
	</monogr>
	<note>Soujanya Poria, and Erik Cambria. review article</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Semantic document distance measures and unsupervised document revision detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofeng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Klabjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Bless</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="947" to="956" />
		</imprint>
	</monogr>
	<note>Asian Federation of Natural Language Processing</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
