<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning Efficient, Explainable and Discriminative Representations for Pulmonary Nodules Classification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanliang</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Pulmonary and Critical Care Medicine</orgName>
								<orgName type="department" key="dep2">School of Medicine</orgName>
								<orgName type="institution" key="instit1">Sir Run Run Shaw Hospital</orgName>
								<orgName type="institution" key="instit2">Zhejiang University</orgName>
								<address>
									<postCode>310020</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuhao</forename><surname>Shen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Hangzhou Dianzi University</orgName>
								<address>
									<postCode>310018</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Gao</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Computer Science and Technology</orgName>
								<orgName type="institution">Hangzhou Dianzi University</orgName>
								<address>
									<postCode>310018</postCode>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Han</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Medical Oncology</orgName>
								<orgName type="department" key="dep2">College of Medicine</orgName>
								<orgName type="institution" key="instit1">Sir Run Run Shaw Hospital</orgName>
								<orgName type="institution" key="instit2">Zhejiang University</orgName>
								<address>
									<postCode>310016</postCode>
									<settlement>Hangzhou</settlement>
									<region>Zhejiang</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Learning Efficient, Explainable and Discriminative Representations for Pulmonary Nodules Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>pulmonary nodule classification</term>
					<term>convolutional neural network</term>
					<term>neural architecture search</term>
					<term>computer-aided diagnoses</term>
					<term>convolutional block attention module 2010 MSC: 00-01</term>
					<term>99-00</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Automatic pulmonary nodules classification is significant for early diagnosis of lung cancers. Recently, deep learning techniques have enabled remarkable progress in this field. However, these deep models are typically of high computational complexity and work in a black-box manner. To combat these challenges, in this work, we aim to build an efficient and (partially) explainable classification model. Specially, we use neural architecture search (NAS) to automatically search 3D network architectures with excellent accuracy/speed trade-off. Besides, we use the convolutional block attention module (CBAM) in the networks, which helps us understand the reasoning process. During training, we use A-Softmax loss to learn angularly discriminative representations. In the inference stage, we employ an ensemble of diverse neural networks to improve the prediction accuracy and robustness. We conduct extensive experiments on the LIDC-IDRI database. Compared with previous state-of-the-art, our model shows highly comparable performance by using less than 1/40 parameters. Besides, empirical study shows that the reasoning process of learned networks is in conformity with physicians' diagnosis. Related code and results have been released at: https://github.com/ fei-hdu/NAS-Lung.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep learning <ref type="bibr" target="#b0">[1]</ref> has witnessed striking advances in the area of Computer-Aided Diagnoses (CAD), including medical image analysis <ref type="bibr" target="#b1">[2]</ref>, medical image segmentation <ref type="bibr" target="#b2">[3]</ref>, and automatic medical reports generation <ref type="bibr" target="#b3">[4]</ref>, etc. Such deep-learning based CAD systems could help physicians by offering second opinions and flagging concerning areas in the healthcare data <ref type="bibr" target="#b4">[5]</ref>.</p><p>The diagnosis of lung cancer also benefits from recent advances in deep-learning based CAD systems. Lung cancer has caused a growing number of deaths at present in the world <ref type="bibr" target="#b5">[6]</ref>. However, due to the sheer volume of computed tomography (CT) images, it is time-consuming for doctors to diagnose. Numerous efforts have been made to develop automated pulmonary nodules detection <ref type="bibr" target="#b6">[7]</ref> and classification <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref> algorithms. Such algorithms greatly benefit early-stage lung cancer diagnosis.</p><p>In this work, we focus on the pulmonary nodules classification task, i.e. judging whether a candidate nodule is benign or malignant. Traditionally, researchers explore hand-crafted features and use a classifier to predict the category of a nodule <ref type="bibr" target="#b9">[10]</ref>. Recently, researchers are inspired to employ Convolu-tional Neural Networks (CNNs) for pulmonary nodule classification <ref type="bibr" target="#b10">[11]</ref>. Initially, researchers use 2D CNNs to classify every CT image individually <ref type="bibr" target="#b11">[12]</ref>. Recently, researchers use 3D CNNs and more complex neural architectures to improve the performance <ref type="bibr" target="#b7">[8]</ref>.</p><p>At present, the remarkable progress enabled by deep learning is mostly due to the complicated network architectures, which are manually developed by human experts. The design of neural architectures is typically time-consuming and relies heavily on experts' experiences. Besides, existing work consider little about the efficiency of networks. In practical applications, there is often a huge volume of medical data but a limited computation budget in most hospitals. It is meaningful to achieve a balance between precision and efficiency.</p><p>In addition, existing networks typically works in a black-box manner. It is significant to develop explainable models for clinical applications <ref type="bibr" target="#b12">[13]</ref>. Recently, several efforts have been made for exploring explainable CAD algorithms by using relational learning techniques <ref type="bibr" target="#b13">[14]</ref>. For example, Xu et al. <ref type="bibr" target="#b14">[15]</ref> used the medical knowledge graph to develop relational dialogue system for automatic diagnosis. Yang et al. <ref type="bibr" target="#b15">[16]</ref> used relational learning between multiple pulmonary nodules for boosting the prediction accuracy. Zhang et al. <ref type="bibr" target="#b16">[17]</ref> established a multimodal mapping between medical images and diagnostic reports, and used symptom descriptions and visualize attention to justify the network diagnosis process of pathology bladder cancer. How-ever, either knowledge graph generation or diagnostic collection is of high cost. It is still challenging to directly learn the relationships between the visual patterns in CT images and the expert knowledge in physicians' judgement, for the nodule classification task.</p><p>To combat these challenges, in this paper, we first use automatic Neural Architecture Search (NAS) technique <ref type="bibr" target="#b17">[18]</ref> to design 3D network architectures with excellent accuracy/speed trade-off. Automatic NAS is to find optimal neural architecture from a search space by using some search strategy and performance estimation strategy. Already by now, NAS methods have outperformed manually designed architectures on various tasks, including medical image diagnoses <ref type="bibr" target="#b18">[19]</ref> and 3D medical image segmentation <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>. To achieve a best balance between precision and efficiency, we use an advanced NAS method, termed Partial Order Pruning (POP) <ref type="bibr" target="#b21">[22]</ref>, in this paper.</p><p>To justify the network diagnosis process, we additionally use the convolutional based attention module (CBAM) <ref type="bibr" target="#b22">[23]</ref> in the proposed networks. The attention modules in CBAM will characterize the relationships between visual patterns and symptom descriptions. To improve the margin between the learned representations of malignant and benign lesions, we use A-Softmax loss <ref type="bibr" target="#b23">[24]</ref> to train the networks. The A-Softmax loss has shown inspiring performance in enabling CNNs to learn angularly discriminative features. In the inference stage, we employ an ensemble of divergence neural architectures to further improve the prediction robustness. Extensive experiments are conducted on the LIDC-IDRI database. The corresponding results show that our final model is highly comparable with previous state-ofthe-art (SOTA), but with less than 1/40 parameters. Besides, empirical study shows that the reasoning process is in conformity with physicians' diagnosis.</p><p>Our contributions are mainly four-fold:</p><p>• First, to our best knowledge, this is the first attempt that uses NAS for pulmonary nodules classification;</p><p>• Second, we analyse the reasoning process of the network, which is in conformity with physicians' diagnosis;</p><p>• Third, we employ A-Softmax loss to train the network for learning discriminative representations;</p><p>• Forth, our model is highly comparable with previous SOTA method but with using less than 1/40 parameters. The related code and models have been released at: https://github.com/fei-hdu/NAS-Lung.</p><p>The rest of this paper is organized as follows. Section 2 introduces related works. Section 3 details the proposed method. Experimental results and analysis are presented in section 4. Section 5 concludes this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In this section, we briefly introduce related works about pulmonary nodule classification and NAS. Please refer to <ref type="bibr" target="#b17">[18]</ref> for a comprehensive survey of NAS methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Pulmonary nodule classification</head><p>Due to the increasing threat of lung cancer, reaseachers have contribute greatly to develop automated pulmonary nodule classification algorithms <ref type="bibr" target="#b24">[25]</ref>. Like other computer vision fields, researchers traditionally use hand-crafted features, e.g. Gabor, Local Binary Patterns (LBP), and SIFT descriptor etc. <ref type="bibr" target="#b9">[10]</ref> to represent a nodule, and then use a shallow machine learning techniques, e.g. Support Vector Machine (SVM) <ref type="bibr" target="#b25">[26]</ref> and Random Forest <ref type="bibr" target="#b26">[27]</ref>, to inference the type of a nodule.</p><p>Recently, deep CNNs have achieved great success in various computer vision tasks, such as image classification, segmetnation, and enhancement. Researchers are therefore inspired to classify nodules by using CNNs. Initially, researchers treat each CT frame seperately and use 2D CNNs to learning a classifier. For example, Shen et al. proposed to use a multi-crop CNN <ref type="bibr" target="#b11">[12]</ref> to make the model robust to scales of nodules.</p><p>Since nodules are naturally 3D, Yan et al. <ref type="bibr" target="#b27">[28]</ref> explored 3D CNNs for pulmonary nodule classification. Latterly, Zhu et al. <ref type="bibr" target="#b7">[8]</ref> used 3D deep dual path networks (DPNs) and employ a number of auxiliary features to boost the diagnosis performance. Jiang et al. <ref type="bibr" target="#b8">[9]</ref> sequentially deployed a contextual attention module and a spatial attention module to 3D DPN to improve the representation ability. Besides, they employ an ensemble of different model variants to improve the prediction robustness. These works show inspiring results.</p><p>Although the aforementioned deep models show inspiring results, they are typically of high computational complexity and work in a black-box manner. In this paper, we propose to explore efficient, explainable and discriminative networks by using NAS, CBAM, and A-Softmax loss. As will shown in the experimental section, our resulting model performs competitively with previous SOTA by using less than 1/40 parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Neural Architecture Search</head><p>The success of deep learning in various tasks is accompanied by increasingly more complex neural architectures. Such architectures are manually designed by experts. The designing process is typically time-consuming, and the capacity of networks are bounded by experts' experiences. Consequently, there is a rising demand of automatic Neural Architecture Search (NAS) <ref type="bibr" target="#b17">[18]</ref>. Already by now, great efforts have been made in three dimensions: search space, search strategy, and performance estimation strategy. Besides, NAS methods have outperformed manually designed architectures on various tasks <ref type="bibr" target="#b28">[29]</ref>.</p><p>Inspired by successes of NAS, several attemps have been made to develop automatic CAD systems by using NAS methods. To name a few, Faes et al. <ref type="bibr" target="#b18">[19]</ref> used Google Cloud Au-toML to develop medical image diagnostic classifiers for five common diseases. Most NAS models show comparable performance and diagnostic properties to previous SOTA algorithms. Besides, several NAS based 3D medical image segmentation methods are proposed in <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>. Recently, Yu et al. <ref type="bibr" target="#b29">[30]</ref> proposed a coarse-to-fine neural architecture search (C2FNAS) for 3D medical image segmentation. In C2FNAS, they first search the macro-level topology of the network and then search at micro-level for operations in each cell. Zhang et al. <ref type="bibr" target="#b30">[31]</ref> explored hybrid spatio-temporal neural architecture search for fMRI data related tasks.</p><p>All the previous NAS based medical image analysis method shows inspiring and promising performance. However, the searching procedure typically cost a long time, and the searched networks are large-size. In this paper, we aim to search 3D neural networks with the best accuracy/speed trade-off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed</head><p>In this paper, we use the 3D NAS method, CBAM module, A-Softmax loss, and ensemble strategy to learn efficient, explainable and discriminative representations for pulmonary nodules classification. In this section, we will sequentially detail these techniques in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">General 3D Network Architecture</head><p>Our general 3D network architecture is as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. Stages 1 and 2 include one 3D convolutional layer, i.e. Conv1 and Conv2, respectively. The outputs of both stage 1 and stage 2 have 4 channels. Stages 3-5 include L, M, N residual blocks, respectively. The number of channels of the i-th residual block in stage s(s = 3, 4, 5) is denoted by C s i . We will learn optimal L, M, N, and C s i in the searching process by using NAS (Section 3.4). Stage stage 6 produces the final prediction with a global average pooling and a fully-connected (FC) layer. The FC layer outputs a binary label denoting whether a input nodule is benign or malignant. We expand a CBAM <ref type="bibr" target="#b22">[23]</ref> to the last layer of Stages 2-5, respectively.</p><p>As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, our residual block consists of two 3D convolution layers and a short-cut connection. In case if the size of input does not match the output, an additional 3D convolutional layer is added (as shown in the right sub-figure). Batch normalization (BN) and ReLU nonlinearity are used after all convolutional layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Convolutional Block Attention Module (CBAM)</head><p>In the general networks, we expand CBAM <ref type="bibr" target="#b22">[23]</ref> to the basic residual 3D networks, as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. CBAM includes a channel attention module and a spatial attention module. Such attention modules can help us pry into the networks and partially understand the reasoning process. Besides, as will shown in Section 4.4, CBAM boosts the classification accuracy.</p><p>As shown in <ref type="figure">Fig. 3</ref>, given a feature map F, the channel attention module infers an 1D channel attention vector M C , indicating the significance of each channel. The spatial attention model infers a 3D spatial attention map M S , indicating the significance of each location. The overall process is operated as:</p><formula xml:id="formula_0">F = M C (F) F, F = M S (F ) F ,<label>(1)</label></formula><p>where denotes element-wise multiplication. As shown in <ref type="figure">Fig. 3</ref>, the channel attention is computed by:</p><formula xml:id="formula_1">M C (F) = σ(MLP(AvgPool(F)) + MLP(MaxPool(F))),<label>(2)</label></formula><p>and the spatial attention is computed by:</p><formula xml:id="formula_2">M S (F) = σ(Conv([AvgPool(F); MaxPool(F)])).<label>(3)</label></formula><p>Here σ(·) denotes the Sigmoid function; MaxPool(·) and AvgPool(·) denotes max-pooling and average-pooling, respectively; MLP(·) denotes a multi-layer perceptron (MLP), which concludes two fully-connected layers followed with a ReLU layer, respectively; Conv(·) denotes a 3D convolutional layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">A-Softmax Loss Function</head><p>Finally, we use the angular softmax (A-Softmax) loss to train the whole network for learning angularly discriminative features <ref type="bibr" target="#b23">[24]</ref>. The A-Softmax Loss is expressed as:</p><formula xml:id="formula_3">L ang = 1 N i − log( e ||x i || cos(mθ y i ,i ) e ||x i || cos(mθ y i ,i ) + j y i e ||x i || cos(θ j,i ) ) (4) where θ j,i (0 ≤ θ j,i ≤ π)</formula><p>is the angle between vector W j and x i ; x i and y i are the i-th training sample and the corresponding ground-truth label; W j and W y i are the j-th and y i -th column of W, respectively; W denotes parameters in the last fullyconnected layer; m quantitatively controls the size of angular margin. In the implementation, we set m = 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Efficient Neural Architecture Search</head><p>In this paper, we employ the Partial Order Pruning (POP) <ref type="bibr" target="#b21">[22]</ref> algorithm to design 3D networks with excellent speed/accuracy trade-off. The basic assumption of POP is that: a narrower network is always more efficient and less accurate than a wider one. Following this assumption, Li et al. consider both accuracy and inference speed in the objective function, and use a cutting plane algorithm to solve the corresponding optimization problem.</p><p>In the implementation, we use the general 3D network architecture shown in <ref type="table">Table 1</ref> in our search space. Due to the computation budget limitation, we reduce the search space by restricting:</p><formula xml:id="formula_4">(L + M + N)/4 ≤ D ≤ (L + M + N)/2 , ∀D ∈ {L, M, N}. (5)</formula><p>Unlike the settings in <ref type="bibr" target="#b21">[22]</ref>, we aim at searching for low-latency neural architectures in this paper. In practice, we set the search space as:</p><formula xml:id="formula_5">C s i ∈ {4, 8, 16, 32, 64, 128}, 3 ≤ L + M + N ≤ 9.<label>(6)</label></formula><p>Consequently, all the candidate models would include no more than 9 residual blocks, and each residual block contains no more than 128 channels. With these settings, we significantly narrow down the search space. The searched network architecture is denoted by:</p><formula xml:id="formula_6">[[C 3 1 , ..., C 3 L ], [C 4 1 , ..., C 4 M ], [C 5 1 , ..., C 5 N ]].<label>(7)</label></formula><p>POP iteratively searches for the networks with the best accuracy/speed trade-off in the whole search space. Each time POP trains a new architecture and obtains its accuracy, and then updates the pruned search space. Here the pruned search space   includes the networks which have higher latency but lower accuracy. These architectures are unlikely to provide better speed/accuracy trade-off than the trained networks. By pruning these architectures from the search space, POP avoids unnecessary training cost and thus speeds up the architecture search process. The search process is stopped if the no change to the search space happens for several iterations. For details about the POP algorithm, please refer to the original literature <ref type="bibr" target="#b21">[22]</ref>. Note: In default, we has CBAM in our general networks and search for the best depth and width, by training each network using the A-Softmax loss. We may also use the general networks without CBAM in the search space, and first train each network using the Softmax loss. Afterwards, we select a number of networks with excellent accuracy/speed trade-off, and then expand CBAM blocks to them and train them using the A-Softmax loss. Our experimental result shows that we can obtain models with similar accuracy in both manners. However, using both CBAM and the A-Softmax loss in the search process dramatically reduces the latency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Ensemble Inference</head><p>In the inference stage, we fuse the outputs of different neural architectures to get the final prediction <ref type="bibr" target="#b31">[32]</ref>. In practice, suppose we select n networks which shows good accuracy/speed trade-off. Each network produces a probability that whether an input nodule is malignant or not. We transfer it to a binary label (i.e. {1, 0}) by using a threshold of 0.5. If more than n/2 models output a label 1 (i.e. malignant), the input nodule is estimated as malignant (i.e. positive). In the following, we refer to the full model as NASLung.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We conduct a series of experiments to verify the proposed method and empirically analyse the reasoning process. We will present the experimental settings and analyse the corresponding results below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Settings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Dataset</head><p>In the experiments, we use the LIDC-IDRI dataset <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b33">34]</ref> with the LUNA16's settings <ref type="bibr" target="#b34">[35]</ref>. Specially, the CTs with slice thickness greater than 3mm, slice spacing inconsistent or missing slices, are removed from the LIDC-IDRI dataset. There are totally 1,004 nodules left, in which 450 nodules are positive. The LUNA16 dataset explicitly gives a 10-fold cross validation split. Correspondingly, in each run, we use 9 folds (including about 900 samples) for training and the left 1 fold (including about 100 samples) for testing. Following the settings in <ref type="bibr" target="#b7">[8]</ref>, we evaluate our method on folds 1-5, and report the average performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Performance Criteria</head><p>To evaluate the pulmonary nodule classification performance, we use four widely used indices, including:</p><formula xml:id="formula_7">Accuracy = TP + TN TP + FN + TN + FP ,<label>(8)</label></formula><formula xml:id="formula_8">Sensitivity = TP TP + FN ,<label>(9)</label></formula><formula xml:id="formula_9">Specificity = TN FP + TN , and<label>(10)</label></formula><formula xml:id="formula_10">F1 Score = 2 · TP 2 2TP + FP + FN ,<label>(11)</label></formula><p>where, TP, FN, FP, and TN sequentially denote true positive, false negative, false positive, and true negative. Greater values of these criteria indicate better performance. F1 Score evaluates the trade-off between Sensitivity and Specificity. In general, the highest F1 Score indicates the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3.">Implementation Details</head><p>We implement our framework by using Pytorch and one GTX 1080Ti GPU. In the training procedure, we pad the nodules of size 32 × 32 × 32 into 36 × 36 × 36, and then randomly crop 32 × 32 × 32 from it. We use horizontal flip, vertical flip, z-axis flip for data augmentation. We use Adam optimizer with a learning rate 0.0002, and momentum parameters β 1 = 0.5 and β 2 = 0.999.</p><p>In the NAS process, we train each candidate model for 10 epochs. The search process costs about 8 hours. <ref type="figure">Fig. 4</ref> shows the accuracy and speed of neural models in the search space. Obviously, most models show inspiring accuracy and high inference speed. Some of them even achieves an accuracy over 86% but cost less than 0.4ms for each nodule. Such excellent candidates allow us to develop real-time automatic classification models. We then select a number of good models according to both accuracy and inference speed. For each selected model, further optimize it for 700 epochs by using the A-Softmax loss. Our final ensemble model concludes 9 light-weight networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison with Existing Works</head><p>We first compare our method with several existing advanced methods, including Multi-crop CNN <ref type="bibr" target="#b11">[12]</ref>, Nodule-level 2D CNN <ref type="bibr" target="#b27">[28]</ref>, Vanilla 3D CNN <ref type="bibr" target="#b27">[28]</ref>, DeepLung <ref type="bibr" target="#b7">[8]</ref>, and AEDPN <ref type="bibr" target="#b8">[9]</ref>. Here, we report the performance of our ensemble model, NASLung, in <ref type="table">Table 1</ref>.</p><p>Obviously, our NASLung achieves the highest Accuracy and Specificity, and the second best F1 Score. Both high Accuracy and F1 Score demonstrates that NASLung trades off well between Sensitivity and Specificity. In other words, NASLung can correctly classify most nodules, which would dramatically light the burden of physicians. Notably, AE-DPN <ref type="bibr" target="#b8">[9]</ref> achieves the best Sensitivity value and F1 Score. However, the model size of AE-DPN is almost 40 times of NASLung. All these results demonstrate that by using NAS, CBAM, A-Softmax, and the ensemble strategy, the proposed method achieves an excellent accuracy/efficiency trade-off.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>We then analyse the impact of the proposed techniques, i.e. CBAM, A-Softmax loss (L ang ), and the ensemble strategy. We first remove the CBAM blocks from the general architecture, and select the best 5 NAS models as bases. Afterwards, we build a number of model variants by selectively applying CBAM (i.e. NAS+CBAM), A-Softmax loss (i.e. NAS+L ang ) or both (i.e. NAS+CBAM+L ang ) to them. Besides, we conduct experiments by searching the best networks while using CBAM and the A-Softmax loss in NAS. The corresponding results are denoted by NASLung single . The averages (avg.) and standard deviations (std.) of F1 Scores of these models under each setting are reported in <ref type="table" target="#tab_2">Table 2</ref>. <ref type="table">Table 1</ref>: Comparison with existing methods across folds 1-5 on the LIDC-IDRI dataset. Accu., Sens., Spec., and para. denote Accuracy, Sensitivity, Specificity, and the number of parameters, respectively. The best and second best results in each column are shown in boldface and underline format, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accu. Sens. Spec. F1 Score para. (M)</head><p>Multi-crop CNN <ref type="bibr" target="#b11">[12]</ref> 87.14 ----Nodule-level 2D CNN <ref type="bibr" target="#b27">[28]</ref>  Obviously, using CBAM or L ang averagely improves F1 Score by about 0.1 and 0.2, respectively. Using both of them improves F1 Scores by 0.36 in average. In addition, the standard deviation of F1 Score significantly decreases when we use CBAM, L ang or both of them. These observations imply that both CBAM and L ang boost the accuracy and robustness of the original NAS models in general. Besides, the effect of CBAM and L ang are at least partially additive. Finally, NASLung single shows the best average performance with the lowest standard deviation in general. The average size of NASLung single is about 1/4 of the other models. This comparison implies that using CBAM and the A-Softmax loss in the search space dramatically reduce the latency of networks and slightly improves the accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Analysis of CBAM</head><p>Attention Visualization in CBAM. In order to understand the reasoning process, we empirically analyse the relations between the learned spatial attention maps and physicians' diagnosis. To this end, we visualize the learned spatial attention map in Stage 2 due to its small perceptual field. In other words, each attention value here presents the importance of a small region in an input CT image. For the visualization purpose, we only show a 2D slice of the 3D CT cube and the corresponding spatial attention map. <ref type="figure" target="#fig_3">Fig. 5</ref> illustrates several malignant/benign nodules and their corresponding learned attention maps.</p><p>As shown in <ref type="figure" target="#fig_3">Fig. 5</ref>, greater attention values mainly appear over the borders and inside of nodules. Coincidentally, physicians judge whether a nodule is malignant or benign lesions based on the same areas. Specially, the learned attention maps correspond with physicians' diagnosis in the following three aspects <ref type="bibr" target="#b35">[36]</ref>:</p><p>• First, malignant lesions typically have a lobular border.</p><p>Statistically, the majority of lesions with a lobular border are malignant. Lobular borders are therefore significant for diagnosis.</p><p>• Second, lobulation leads to heterogeneous growth rates within nodules. Tumour nodules generally grow like lobes (sprouting), not concentrically, so the growing nodules will not be in the center of the lesion. The red area inside a nodule (not located in the center of the lesion) coincides with such eccentric growth patterns. The red area therefore is helpful for the judgement of malignant nodules.</p><p>• Finally, because lobular borders may also appear with benign lesions, the insides of nodules are more important than borders in clinical diagnosis. Examples illustrated in the top row of <ref type="figure" target="#fig_3">Fig. 5</ref> show consistent results.</p><p>These observations indicates that the reasoning process of our model is (at least partially) in conformity with physicians' diagnosis.</p><p>Arrangement of the channel and spatial attention in CBAM. In addition, we have conducted experiments by changing the sequence of the channel attention with the spatial attention block in <ref type="figure">Figure 3</ref>. We refer to the original and switched versions of CBAM as channel-first order and spatial-first order, respectively. As shown in <ref type="table" target="#tab_3">Table 3</ref>, the channel-first order is slightly better than the spatial-first order. This comparison result is exactly the same as that shown in the original literature <ref type="bibr" target="#b22">[23]</ref>. We thus adopt the channel-first order in our final model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Analysis of the A-Softmax loss</head><p>We further analyse the impact of A-Softmax loss in representation learning. To this end, we use the Davies-Bouldin Index (DBI) to evaluate the discriminability of the learned features <ref type="bibr" target="#b36">[37]</ref>. DBI is a popular metric for evaluating clustering algorithms. Lower values of DBI indicate smaller intra-class distance and larger inter-class distance. Let X i, j denote the feature vector of the j-th sample in the i-th class. We first compute the intra-class distance by:</p><formula xml:id="formula_11">S i = 1 T i T i j=1 X i, j −X i 2 ,<label>(12)</label></formula><p>where T i is the number of samples of the i-th class,X i is the average feature vector (i.e. center) of the i-th class; i = 0 and 1 indicates the negative and positive classes, respectively. We then compute the iner-calss distance by:</p><formula xml:id="formula_12">M 0,1 = X 0 −X 1 2 .<label>(13)</label></formula><p>Afterwards, DBI is calculated by:</p><formula xml:id="formula_13">M 0,1 = S 0 + S 1 M 0,1 .<label>(14)</label></formula><p>We calculated these metrics by using the deep features learned with the Softmax loss and A-Softmax loss, respectively.    As shown in <ref type="table" target="#tab_4">Table 4</ref>, the A-Softmax loss leads to smaller intraclass distance of the negative nodules, larger inter-distance between positive and negative nodules, and smaller DBI, compared to the Softmax loss. Such dramatic superiority, especially in terms of DBI, implies the learned features by using the A-Softmax loss diverse apparently between positive and negative nodules. In other words, we can learn much more discriminable features by using the A-Softmax loss than using the Softmax loss.</p><p>In addition, we visualize the outputs of the penultimate layer in a selected 3D network. Specially, we train hte network by using the Softmax, i.e. Cross-Entropy (CE), loss and A-Softmax loss, respectively. After training, we reduce each feature vector to 2 dimension by using t-SNE <ref type="bibr" target="#b37">[38]</ref> and visualize them in <ref type="figure" target="#fig_4">Fig.  6</ref>. In <ref type="figure" target="#fig_4">Fig. 6</ref>, blue points present positive (malignant) nodules and red points present negative (benign) nodules. We use the scikit-learn toolbox <ref type="bibr" target="#b38">[39]</ref> in the implementation.</p><p>Obviously, compared with the Softmax loss, the A-Softmax loss makes the learned representations more compact intra each class. Besides, the inter-class angular margin in <ref type="figure" target="#fig_4">Fig. 6(b)</ref> is more distinct than that in <ref type="figure" target="#fig_4">Fig. 6(a)</ref>. Recall that the A-Softmax loss generally improves the classification performance, as previously shown in <ref type="table" target="#tab_2">Table 2</ref>. We can safely draw the conclusion that the A-Softmax loss enables networks to learn discriminative representations and benefit the classification performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Analysis of the Ensemble Strategy</head><p>To verify the ensemble strategy, we first randomly select n models for an ensemble prediction, with n = 1, 3, 5, 7, 9. We repeat this progress for 10 times, and calculate the average performance indices, related to each n. As shown in <ref type="figure" target="#fig_5">Fig. 7</ref>, using more models generally improves the performance. Besides, using more than 5 models gains little performance improvement.</p><p>In addition, we illustrate the performance of the best 10 searched single networks. As shown in <ref type="table">Table 5</ref>, all these single models achieves a F1-Score higher than 85 and contains no more than 5M parameters each. Remarkably, Model-1 achieves the best F1-Score over 87, by using merely 0.14M parameters. Specially, the architecture of Model-1 is <ref type="bibr">[4,4,[4, 4]</ref>, <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref>, <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b7">8]</ref>]. It is apparent that these single models perform diversely according to different criteria. Integrating all these models would <ref type="table">Table 5</ref>: Performance of the best 10 searched single networks. Accu., Sens., Spec., and para. denote Accuracy, Sensitivity, Specificity, and the number of parameters, respectively. The best and second best results in each column are shown in boldface and underline format, respectively. Accu. Sens. Spec. F1 Score para. make them complement each other. Accordingly, NASLung outperforms all these single models by a large margin in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we develop an deep pulmonary nodule classifier with excellent accuracy/speed trade-off, by incrementally using 3D NAS, CBAM, A-Softmax loss, and the ensemble strategy. All the proposed techniques are demonstrated effective. Besides, the reasoning process is partially explainable. The learned attention maps provide a fine-grained modelling of the relationships between visual content (i.e. patterns of nodules) and clinical symptoms (e.g. lobular border and heterogeneous growth rate). Based on such success, it is promising to further explore the relationships between multiple nodules, as well as the changes of nodules during a period, to further boost the diagnosis accuracy and justify the diagnosis process <ref type="bibr" target="#b15">[16]</ref>. Besides, it is critic to further explore the relational learning among mutli-modal data <ref type="bibr" target="#b39">[40]</ref>, e.g. phenomics, dialogues, and reports, for improving the precision and interpretability of CAD systems <ref type="bibr" target="#b14">[15]</ref>. Finally, most NAS algorithms need a large number of labeled samples and a long training period. In medical imaging tasks, there are typically a small number of labeled samples. It is thus significant to develop few-shot NAS algorithms, which can learn optimal neural architectures based on few number of samples.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>General 3D network architecture. Here, L, M and N are learned in the NAS algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The 3D residual blocks used throughout this paper.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Pipeline of convolutional block attention module (CBAM)<ref type="bibr" target="#b22">[23]</ref>. The accuracy and inference speed of neural models in the search space. Each model is trained for 5 epochs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Visualization of the learned spatial attention. Each example includes two images: the left one is the CT image patch; the right one is the corresponding attention map. Here, red colors indicate high attention values, and blue indicates low attention values.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Visualization of the learned features: (a) the features learned by the Softmax loss and (b) those learned by the A-Softmax Loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 :</head><label>7</label><figDesc>Performance of the proposed method while using different number of models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Statistics of performance indices related to different model variants.</figDesc><table><row><cell>avg.</cell><cell>Accu.</cell><cell>Sens.</cell><cell cols="3">Spec. F1 Score para.(M)</cell></row><row><cell>NAS (base)</cell><cell>87.58</cell><cell cols="2">84.03 90.50</cell><cell>85.74</cell><cell>7.80</cell></row><row><cell>NAS+CBAM</cell><cell>87.61</cell><cell cols="2">84.01 90.41</cell><cell>85.86</cell><cell>7.84</cell></row><row><cell>NAS+L ang</cell><cell>87.87</cell><cell cols="2">82.89 91.75</cell><cell>85.96</cell><cell>7.80</cell></row><row><cell cols="3">NAS+CBAM+L ang 87.77 84.26</cell><cell>90.60</cell><cell>86.10</cell><cell>7.84</cell></row><row><cell>NASLung single</cell><cell>88.03</cell><cell cols="2">83.39 91.73</cell><cell>86.18</cell><cell>1.90</cell></row><row><cell>std.</cell><cell>Accu.</cell><cell>Sens.</cell><cell cols="3">Spec. F1 Score para.(M)</cell></row><row><cell>NAS (base)</cell><cell>1.06</cell><cell>3.01</cell><cell>0.92</cell><cell>1.50</cell><cell>4.35</cell></row><row><cell>NAS+CBAM</cell><cell>0.74</cell><cell>2.15</cell><cell>1.17</cell><cell>1.01</cell><cell>4.37</cell></row><row><cell>NAS+L ang</cell><cell>0.62</cell><cell>2.41</cell><cell>2.18</cell><cell>0.73</cell><cell>4.35</cell></row><row><cell>NAS+CBAM+L ang</cell><cell>0.56</cell><cell>1.24</cell><cell>1.33</cell><cell>0.56</cell><cell>4.37</cell></row><row><cell>NASLung single</cell><cell>0.44</cell><cell>0.87</cell><cell>1.04</cell><cell>0.49</cell><cell>1.63</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Performance about the arrangement of the channel and spatial attention in CBAM.. Accu. Sens. Spec. F1 Score channel-first 88.03 83.39 91.63</figDesc><table><row><cell></cell><cell></cell><cell>86.18</cell></row><row><cell>spatial-first</cell><cell>87.14 80.95 92.15</cell><cell>84.90</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Evaluations of the deep features learned by using the Softmax loss and A-Softmax loss, respectively. Smaller DBI generally indicates smaller intraclass distances (i.e. S 0 and S 1 ) and larger inter-class distance (i.e. M 0,1 ).</figDesc><table><row><cell></cell><cell>S 0</cell><cell>S 1</cell><cell>M 0,1</cell><cell>DBI</cell></row><row><cell cols="5">A-Softmax loss 0.439 0.551 0.718 1.453</cell></row><row><cell>Softmax loss</cell><cell cols="4">0.565 0.515 0.470 2.298</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported in part by the National Natural Science </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Imagenet classification with deep convolutional neural networks</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for medical image analysis: Fine tuning or full training?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gurudu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Hurst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Gotway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Medical Imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1299" to="1312" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Deep learning in medical image analysis: a comparative analysis of multi-modal brain-mri segmentation with 3d deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nikolaos</surname></persName>
		</author>
		<ptr target="https://github.com/black0017/MedicalZooPytorch" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
		<respStmt>
			<orgName>University of Patras</orgName>
		</respStmt>
	</monogr>
	<note>Master&apos;s thesis</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Hybrid retrieval-generation reinforced agent for medical image report generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1530" to="1540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A guide to deep learning in healthcare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kuleshov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Depristo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="29" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D M</forename><surname>Rebecca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Siegel</surname></persName>
		</author>
		<idno type="DOI">10.3322/caac.21442</idno>
	</analytic>
	<monogr>
		<title level="j">CA Cancer J Clindoi</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Cancer statistics</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Automated pulmonary nodule detection in ct images using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="109" to="119" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deeplung: Deep 3d dual path nets for automated pulmonary nodule detection and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="673" to="681" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Attentive and ensemble 3d dual path networks for pulmonary nodules classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">398</biblScope>
			<biblScope unit="page" from="422" to="430" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Lung nodule classification with multilevel patch-based context analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Weidong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Min-Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Heng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Fulham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1155" to="1166" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Lung pattern classification for interstitial lung diseases using a deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Anthimopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Christodoulidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ebner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Christe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mougiakakou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1207" to="1216" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-crop convolutional neural networks for lung nodule malignancy suspiciousness classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="663" to="673" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A survey on explainable artificial intelligence (xai): Toward medical xai</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tjoa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guan</surname></persName>
		</author>
		<idno type="DOI">10.1109/TNNLS.2020.3027314</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Relational graph neural network for situation recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="page">107544</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end knowledge-routed relational dialogue system for automatic diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="7346" to="7353" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Relational learning between multiple pulmonary nodules via deep set attention transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1875" to="1878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Mdnet: A semantically and visually interpretable medical image diagnosis network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mcgough</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6428" to="6436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Neural architecture search: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Metzen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">55</biblScope>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Automated deep learning design for medical image classification by health-care professionals with no coding experience: a feasibility study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Faes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Korot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Ledsam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Back</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pontikos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Moraes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Balaskas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Bachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Denniston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Lancet Digital Health</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="232" to="242" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Scalable neural architecture search for 3d medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="220" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Nas-unet: Neural architecture search for medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="44247" to="44257" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Partial order pruning: For best speed/accuracy trade-off in neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9145" to="9153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">So</forename><surname>Kweon</surname></persName>
		</author>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
	<note>CBAM: Convolutional block attention module</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Using deep learning to enhance cancer diagnosis and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fakoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ladhak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automatic segmentation of lung nodules with growing neural gas and support vector machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M B</forename><surname>Netto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Nunes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gattass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1110" to="1121" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Random forest based lung nodule classification aided by clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Kouzani Azhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="535" to="542" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<title level="m">Classification of lung nodule malignancy risk on computed tomography images using convolutional neural network: A comparison between 2d and 3d strategies</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="91" to="101" />
		</imprint>
	</monogr>
	<note>Asian Conference on Computer Vision</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Aging evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">C2fnas: Coarse-to-fine neural architecture search for 3d medical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4126" to="4135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Identify hierarchical structures from task-based fmri data via hybrid spatiotemporal neural architecture search net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="745" to="753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep forest: Towards an alternative to deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3553" to="3559" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Armato</surname><genName>III</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mclennan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bidaut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mcnitt-Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Aberle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Henschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kazerooni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Macmahon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Van Beek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yankelevitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Biancardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Engelmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Laderach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Qing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Starkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Caligiuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farooqi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gladish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jude</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Petkovska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Quint</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sundaram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dodd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fenimore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Petrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Freymann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casteele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gupte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sallam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kuhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dharaiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fryd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salganicoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Anand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Shreter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vastagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Clarke</surname></persName>
		</author>
		<idno type="DOI">10.7937/K9/TCIA.2015.LO9QL9SX</idno>
		<ptr target="http://doi.org/10.7937/K9/TCIA.2015.LO9QL9SX.URLhttps://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI" />
		<title level="m">Data from LIDC-IDRI, The Cancer Imaging Archivedoi</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The lung image database consortium (LIDC) and image database resource initiative (IDRI): a completed reference database of lung nodules on ct scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Armato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mclennan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bidaut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Mcnitt-Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Reeves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Aberle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">I</forename><surname>Henschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Hoffman</surname></persName>
		</author>
		<ptr target="https://wiki.cancerimagingarchive.net/display/Public/LIDC-IDRI" />
	</analytic>
	<monogr>
		<title level="j">Medical physics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="915" to="931" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ravaut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Manek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nazir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Howe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.09435</idno>
		<title level="m">Deep learning for lung cancer detection: Tackling the kaggle data science bowl 2017 challenge</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Pulmonary hamartoma: Ct findings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Siegelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Khouri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Scott</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Leo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hamper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zerhouni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiology</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="317" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A cluster separation measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Bouldin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="1979" />
			<biblScope unit="page" from="224" to="227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Scikitlearn: Machine learning in python, the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">On exploring undetermined relationships for visual relationship detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5128" to="5137" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
