<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Complementary-Label Learning for Arbitrary Losses and Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Ishida</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
						</author>
						<title level="a" type="main">Complementary-Label Learning for Arbitrary Losses and Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In contrast to the standard classification paradigm where the true class is given to each training pattern, complementary-label learning only uses training patterns each equipped with a complementary label, which only specifies one of the classes that the pattern does not belong to. The goal of this paper is to derive a novel framework of complementary-label learning with an unbiased estimator of the classification risk, for arbitrary losses and models-all existing methods have failed to achieve this goal. Not only is this beneficial for the learning stage, it also makes model/hyper-parameter selection (through crossvalidation) possible without the need of any ordinarily labeled validation data, while using any linear/non-linear models or convex/non-convex loss functions. We further improve the risk estimator by a non-negative correction and gradient ascent trick, and demonstrate its superiority through experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Modern classification methods usually require massive data with high-quality labels, but preparing such datasets is unrealistic in many domains. To mitigate the problem, previous works have investigated ways to learn from weak supervision: semi-supervised learning <ref type="bibr" target="#b1">(Chapelle et al., 2006;</ref><ref type="bibr" target="#b23">Miyato et al., 2016;</ref><ref type="bibr" target="#b17">Kipf &amp; Welling, 2017;</ref><ref type="bibr">Sakai et al., 2017;</ref><ref type="bibr">Tarvainen &amp; Valpola, 2017;</ref><ref type="bibr" target="#b26">Oliver et al., 2018)</ref>, noisy-label learning <ref type="bibr" target="#b25">(Natarajan et al., 2013;</ref><ref type="bibr" target="#b22">Menon et al., 2015;</ref><ref type="bibr" target="#b27">Patrini et al., 2017;</ref><ref type="bibr" target="#b21">Ma et al., 2018;</ref><ref type="bibr" target="#b10">Han et al., 2018;</ref><ref type="bibr" target="#b2">Charoenphakdee et al., 2019)</ref>, positive-unlabeled learning <ref type="bibr" target="#b8">(Elkan &amp; Noto, 2008;</ref><ref type="bibr">du Plessis et al., 2014;</ref><ref type="bibr" target="#b18">Kiryo et al., 2017)</ref>, positive-confidence learning <ref type="bibr" target="#b14">(Ishida et al., 2018)</ref>, similarunlabeled learning <ref type="bibr" target="#b0">(Bao et al., 2018</ref><ref type="bibr">), unlabeled-unlabeled learning (du Plessis et al., 2013</ref><ref type="bibr" target="#b20">Lu et al., 2019)</ref>, and others.</p><p>In this paper, we consider learning from another natural type of weak supervision called complementary-label learning <ref type="bibr" target="#b13">(Ishida et al., 2017;</ref><ref type="bibr" target="#b10">Yu et al., 2018)</ref>, where the label only specifies one of the classes that the pattern does not belong to. For example, a crowdsourced worker can tell us a pattern does not belong to a certain class, instead of identifying the correct class. In contrast to the ordinary case where the true class is given to each pattern (which often needs to be chosen out of many candidate classes precisely), collecting these complementary labels is obviously much easier and less costly.</p><p>Another potential application is collecting survey data that requires extremely private questions <ref type="bibr" target="#b13">(Ishida et al., 2017)</ref>. It would be less mentally demanding, if we explain to the respondent that we will transform their provided true label to a complementary label, before the data is saved into the database. This might become common in the future where privacy concerns are increasing.</p><p>A natural question is, however, is it possible to learn from such complementary labels (without any true labels)?</p><p>The problem has previously been tackled by <ref type="bibr" target="#b13">Ishida et al. (2017)</ref>, showing that the classification risk can be recovered only from complementarily labeled data. They also gave theoretical analysis with a statistical consistency guarantee. However, they required strong restrictions on the loss functions, allowing only one-versus-all and pairwise comparison multi-class loss functions <ref type="bibr">(Zhang, 2004)</ref>, with certain non-convex binary losses. This is a severe limitation since the softmax cross-entropy loss, which cannot be expressed by the two losses above, is the most popular loss in deep learning nowadays.</p><p>Later, <ref type="bibr" target="#b10">Yu et al. (2018)</ref> proposed a different formulation for complementary labels by employing the forward loss correction technique <ref type="bibr" target="#b27">(Patrini et al., 2017)</ref> to adjust the learning objective, but limiting the loss function to softmax crossentropy loss. Their proposed risk estimator is not necessarily unbiased but the minimizer is theoretically guaranteed to be consistent with the minimizer of the risk for ordinary labels (under an implicit assumption on the model for convergence analysis). They also extended the problem setting to where complementary labels are chosen in an uneven (biased) way.</p><p>In this paper, we first derive an unbiased risk estimator arXiv:1810.04327v4 [stat.ML] 19 Nov 2019 with a general loss function, making any loss functions available for use: not only the softmax cross-entropy loss function but other convex/non-convex loss functions can also be applied. We also do not have implicit assumptions on the classifier, allowing both linear and non-linear models. We also prove that our new framework is a generalization of previous complementary-label learning <ref type="bibr" target="#b13">(Ishida et al., 2017)</ref>. <ref type="bibr" target="#b10">Yu et al. (2018)</ref> does not have an unbiased risk estimator, which means users will need clean data with true labels to calculate the error rate during the validation process. On the other hand, our proposed unbiased risk estimator can handle complementarily labeled validation data not only for our learning objective, but also for that of <ref type="bibr" target="#b10">Yu et al. (2018)</ref>. This is helpful since collecting clean data is usually much more expensive. Note that in the example of survey with extremely private questions explained earlier, it may be impossible to even collect a small number of validation data with true labels.</p><p>Finally, our proposed unbiased risk estimator has an issue that the classification risk can attain negative values after learning, leading to overfitting. We further propose a nonnegative correction to the original unbiased risk estimator to improve our estimator. The modified objective is no longer guaranteed to be an unbiased risk estimator, but the unbiased risk estimator can still be used for validation procedures for this modified learning objective. We experimentally show that our proposed method is comparable to or better than previous methods <ref type="bibr" target="#b13">(Ishida et al., 2017;</ref><ref type="bibr" target="#b10">Yu et al., 2018)</ref> in terms of classification accuracy.</p><p>A summary of our contributions is as follows:</p><p>• We propose a new unbiased risk estimator, allowing usage of any loss (convex, non-convex) and any model (parametric, non-parametric) for complementary-label learning.</p><p>• This risk can be used not only as a learning objective, but as a validation criterion even for other methods, such as <ref type="bibr" target="#b13">Ishida et al. (2017)</ref> and <ref type="bibr" target="#b10">Yu et al. (2018)</ref>.</p><p>• We further investigate correction schemes to make complementary-label learning practical and demonstrated the performance in experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Review of previous works</head><p>In this section, we introduce some notations and review the formulations of learning from ordinary labels, learning from complementary labels, learning from ordinary &amp; complementary labels, and learning from partial labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Learning from ordinary labels</head><p>Let X be an instance space and D be the joint distribution over X × <ref type="bibr">[K]</ref> for class label set [K] := {1, 2, . . . , K}, with random variables (X, Y ) ∼ D. The data at hand is sampled independently and identically from the joint distribution:</p><formula xml:id="formula_0">{(x i , y i )} n i=1 i.i.d. ∼ D.</formula><p>The joint distribution D can be either decomposed into class-conditionals {P k } K k=1 and base rate {π k } K k=1 , where P k := P(X|Y = k) and π k := P(Y = k), or the marginal M and class-probability function η : X → ∆ k , where M := P(X), η k (x) := P(Y = k|X = x) and ∆ K is the conditional probability simplex for K classes. A loss is any : [K] × R K → R + . The decision function is any g : X → R K and g k (X) is the k-th element of g(X). The risk for the decision function g with respect to loss and implicit distribution D is:</p><formula xml:id="formula_1">R(g; ) : = E (X,Y )∼D [ (Y, g(X))],<label>(1)</label></formula><p>where E denotes the expectation. Two useful equivalent expressions of classification risk (1) used in later sections are</p><formula xml:id="formula_2">R(g; ) =E X [η(x) (g(X))] = K k=1 π k E P k (k, g(X)) ,<label>(2)</label></formula><p>where, (g(X)) := [ (1, g(X)), (2, g(X)), . . . , (K, g(X))] .</p><p>The goal of classification is to learn the decision function g that minimizes the risk. In the usual classification case with ordinarily labeled data at hand, approximating the risk empirically is straightforward:</p><formula xml:id="formula_3">R(g; ) := 1 n n i=1 (y i , g(x i )).</formula><p>Some well known multi-class loss functions are one-versusall and pairwise comparison losses:</p><formula xml:id="formula_4">OVA k, g(x) = s g k (x) + 1 K − 1 k =k s − g k (x) ,<label>(3)</label></formula><formula xml:id="formula_5">PC k, g(x) = k =k s g k (x) − g k (x) ,<label>(4)</label></formula><p>where s(z) : R → R + is a binary loss function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Learning from complementary labels</head><p>Next we consider the problem of learning from complementary labels <ref type="bibr" target="#b13">(Ishida et al., 2017)</ref>. We observe patterns each equipped with a complementary label {(x i , y i )} n i =1 <ref type="table">Table 1</ref>: Comparison of two proposed complementary-label methods with previous works. We first propose a general unbiased risk estimator for complementary labels that has no restrictions on loss functions and models. We next propose a modified non-negative formulation which solves overfitting issues and leads to better experimental results. Even though the non-negative formulation is no longer an unbiased estimator as a learning objective, the unbiased estimator can be used in the validation procedure. Without any assumptions on D, it is impossible to design a suitable learning procedure. The assumption for unbiased complementary learning used in <ref type="bibr" target="#b13">Ishida et al. (2017)</ref> was</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><formula xml:id="formula_6">η(x) = T η(x),<label>(5)</label></formula><p>where T ∈ R K×K is a matrix that takes 0 on diagonals and 1 K−1 on non-diagonals. This assumption implies all other labels are chosen with uniform probability. This can be forced by designing the data collecting system to first pick up a label randomly and then ask the worker if the data belong to the label with a yes or no. When the answer is no, we will attach that label as the complementary label, and the data will follow the uniform assumption. Under this assumption, <ref type="bibr" target="#b13">Ishida et al. (2017)</ref> proved that they can recover the classification risk (1) from an alternative formulation using only complementarily labeled data when the loss function satisfies certain conditions. More specifically, usable loss functions are oneversus-all or pairwise comparison multi-class loss functions <ref type="bibr">(Zhang, 2004)</ref>:</p><formula xml:id="formula_7">OVA k, g(x) = 1 K − 1 k =k s g k (x) + s − g k (x) (6) PC k, g(x) = k =k s g k (x) − g k (x)<label>(7)</label></formula><p>each with binary loss function s(z) that satisfies s(z) + s(−z) = 1, such as ramp loss s R (z) = 1 2 max 0, min(2, 1 − z) or sigmoid loss s S (z) = 1 1+e z .</p><p>Having an unbiased risk estimator is also helpful for the validation process. Since we do not have ordinary labels in our validation set in the complementary-label learning setting, we cannot follow the usual validation procedure that uses zero-one error or accuracy. If we have an unbiased estimator of the original classification risk (which can be interpreted as zero-one error), we can use the empirical risk for (cross)-validated complementary data to select the best hyper-parameter or deploy early stopping.</p><p>An extension of the above method was considered in Yu et al.</p><p>(2018) by using a different assumption than <ref type="formula" target="#formula_6">(5)</ref>: there is some bias amongst the possible complementary labels that can be chosen, thus the non-diagonals of T is not restricted to 1 K−1 . However, one will need to estimate T beforehand, which is fairly difficult without strong assumptions. Furthermore, in this setup, it is necessary to encourage the worker to provide more difficult complementary labels, for example, by giving higher rewards to certain classes. Otherwise, the complementary label given by the worker may be too obvious and uninformative. Even though the two assumptions are mathematically similar, the data generation process may be different. In this paper we focus on the former assumption.</p><p>Unlike <ref type="bibr" target="#b13">Ishida et al. (2017)</ref>, Yu et al. (2018) did not directly provide a risk estimator, but they showed that the minimizer of their learning objective agrees with the minimizer of the original classification risk (1). Note that, in their formulation, the loss function is restricted to the softmax crossentropy loss. Furthermore, the use of a highly non-linear model is supposed for consistency guarantee in their theoretical analysis. Since the learning objective of Yu et al. <ref type="bibr">(2018)</ref> does not correspond to the classification risk, one will need clean data with true labels to calculate the error rate during the validation process. On the other hand, our proposed risk estimator in this paper can cope with complementarily labeled validation data not only for our own learning objective, but can be used to select hyper-parameters for others such as Yu et al. (2018).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Learning from ordinary &amp; complementary labels</head><p>In many practical situations, we may also have ordinarily labeled data in addition to complementarily labeled data. <ref type="bibr" target="#b13">Ishida et al. (2017)</ref> touched on the idea of crowdsourcing for an application with both types of data. For example, we may choose one of the classes randomly by following the uniform distribution, with probability 1 K−1 for each class, and ask crowdworkers whether a pattern belongs to the chosen class or not. Then the pattern is treated as ordinarily labeled if the answer is yes; otherwise, the pattern is regarded as complementarily labeled. If the true label was y for a pattern, we can naturally assume that the crowdworker will answer yes by P(Y = y|X = x) and no by 1 − P(Y = y|X = x). This way, ordinarily labeled data can be regarded as patterns from D, and complementarily labeled data from D, justifying the assumption of unbiased complementary learning (5).</p><p>In <ref type="bibr" target="#b13">Ishida et al. (2017)</ref>, they considered a convex combination of the classification risks derived from ordinarily labeled data and complementarily labeled data:</p><formula xml:id="formula_8">αR(g; ) + (1 − α)R(g; ), where R(g; ) = E (X,Y )∼D [ (Y , g(X))]</formula><p>and α ∈ [0, 1] is a hyper-parameter that interpolates between the two risks. The combined (also unbiased) risk estimator can utilize both kinds of data in order to obtain better classifiers, which was demonstrated to perform well in experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Learning from partial labels</head><p>In learning from partial labels <ref type="bibr" target="#b5">(Cour et al., 2011)</ref>, a candidate set of labels (which includes the correct class) is given to each pattern. A different way to view complementary label is a candidate set that includes every class except the complementary label. Even though the proposed method of <ref type="bibr" target="#b5">Cour et al. (2011)</ref> shows statistical consistency, it does not give an unbiased estimator of the classification risk. Further, it has different assumptions, e.g., dominance relation, while <ref type="bibr" target="#b13">Ishida et al. (2017)</ref> and this paper focus on assumption <ref type="formula" target="#formula_6">(5)</ref> with different data generation process and applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed method</head><p>As discussed in the previous section, the method by <ref type="bibr" target="#b13">Ishida et al. (2017)</ref> works well in practice, but it has restriction on the loss functions-the popular softmax cross-entropy loss is not allowed. On the other hand, the method by Yu et al.</p><p>(2018) allows us to use the softmax cross-entropy loss, but it does not directly provide an estimator of the classification risk and thus model selection is problematic in practice.</p><p>We first describe our general unbiased risk formulation in Section 3.1. Then we discuss how the estimator can be further improved in Section 3.2. Thirdly, we propose a way for our risk estimator to avoid overfitting by a non-negative risk estimator in Section 3.3. Finally, we show practical implementation of our risk estimator with stochastic optimization methods in Section 3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">General risk formulation</head><p>First, we describe our general unbiased risk formulation. We give the following theorem, which allows unbiased estimation of the classification risk from complementarily labeled patterns:</p><p>Theorem 1. For any ordinary distribution D and complementary distribution D related by (5) with decision function g, and loss , we have</p><formula xml:id="formula_9">R(g; ) = R(g; ) = E (X,Y )∼D [ (Y , g(X))], (8) for the complementary loss g(x) := − (K − 1)I K + 11 · g(x) , (9) or equivalently, k, g(x) = −(K − 1) · k, g(x) + K j=1 j, g(x) ,<label>(10)</label></formula><p>where I K is a K × K identity matrix and 1 is a Kdimensional column vector with 1 in each element.</p><p>Proof can be found in Appendix A. It is worth noting that, in the above derivation, there are no constraints on the loss function and classifier. Thus, we can use any loss (convex/non-convex) and any model (linear/non-linear, parametric/non-parametric) for complementary learning.</p><p>Next, we show the relationship between our proposed framework and previous complementary-label learning <ref type="bibr" target="#b13">(Ishida et al., 2017)</ref>.</p><p>Corollary 2. If one-versus-all loss (6) or pairwise comparison loss <ref type="formula" target="#formula_7">(7)</ref> is used with binary loss function that satisfy s(z) + s(−z) = 1, the classification risk can be written as,</p><formula xml:id="formula_10">R(g; ) = (K − 1)E D Y , g(X) − M 1 + M 2 , (11)</formula><p>where M 1 and M 2 are non-negative constants that satisfy K y=1 y, g(x) = M 1 for all x and y, g(x) + y, g(x) = M 2 for all x and y.</p><p>Proof can be found in Appendix B. Since this is equivalent to the first two Theorems in <ref type="bibr" target="#b13">Ishida et al. (2017)</ref>, our proposed version is a generalization of the previous unbiased complementary-label learning framework.</p><p>The key idea of the proof in Theorem 1 is to not rely on the condition that K k=1 k, g(x) is a constant for all x, used in <ref type="bibr" target="#b13">Ishida et al. (2017)</ref>, which is inspired by the property of binary 0-1 loss s 0−1 , where s 0−1 (z) is 1 if z &lt; 0 and 0 otherwise. Such a technique was also used when designing unbiased risk estimators for learning from positive and unlabeled data in a binary classification setup <ref type="bibr">(du Plessis et al., 2014)</ref>, but was later shown to be unnecessary <ref type="bibr" target="#b7">(du Plessis et al., 2015)</ref>. Note that Theorem 1 can be regarded as a special case of a framework proposed for learning from weak labels <ref type="bibr" target="#b3">(Cid-Sueiro et al., 2014)</ref>.</p><p>By using <ref type="formula" target="#formula_1">(10)</ref>, the classification risk can be written as</p><formula xml:id="formula_11">R(g; ) = K k=1 π k E P k − (K − 1) · k, g(X) + K j=1 j, g(X) .<label>(12)</label></formula><p>Here, we rearrange our complementarily labeled dataset as {X k } K k=1 , where X k denotes the samples complementarily labeled as class k. Then, this expression of the classification risk can be approximated by,</p><formula xml:id="formula_12">R(g; ) = K k=1 π k |X k | xi∈X k − (K − 1) · k, g(x i ) + K j=1 j, g x i ) ,<label>(13)</label></formula><p>where n k is the number of patterns complementarily labeled as the kth class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Necessity of risk correction</head><p>The original expression of the classification risk (1) includes an expectation over non-negative loss : [K] × R K → R + , so the risk and its empirical approximator are both lowerbounded by zero. On the other hand, the expression (12) derived above contains a negative element. Although <ref type="formula" target="#formula_1">(12)</ref> is still non-negative by definition, due to the negative term, its empirical estimator can go negative, leading to over-fitting.</p><p>We elaborate on this issue with an illustrative numerical example. In the left graph of <ref type="figure">Figure 1</ref>, we show an example of training a linear model trained on the handwritten digits dataset MNIST 1 , with complementary labels generated to satisfy (5). We used Adam <ref type="bibr" target="#b16">(Kingma &amp; Ba, 2015)</ref> for optimization with learning rate 5e − 5, mini-batch size of 100, and weight decay of 1e − 4 with 300 epochs. The empirical classification risk (13) is shown in black. We can see that the empirical classification risk continues decreasing and can go below zero at around 100 epochs. The test accuracy on the right graph hits the peak also at around epoch 100 and then the accuracy gradually deteriorates. 1 See http://yann.lecun.com/exdb/mnist/.</p><p>This issue stands out even more significantly when we use a flexible model. The middle graph shows the empirical classification risk for a multilayer perceptron (MLP) with one hidden layer (500 units), where ReLU <ref type="bibr" target="#b24">(Nair &amp; Hinton, 2010)</ref> was used as the activation function. The optimization setup was the same as the case of the linear model above. We can see the empirical risk decreasing much more quickly and going negative. Correspondingly, as the right graph shows, the test accuracy drops significantly after the empirical risk goes negative.</p><p>In fact, a similar issue is already implicit in the original paper by <ref type="bibr" target="#b13">Ishida et al. (2017)</ref>: According to Corollary 2 (or Theorem 1 in <ref type="bibr" target="#b13">Ishida et al. (2017)</ref>), the unbiased risk estimator includes subtraction of a positive constant term which increases with respect to the number of classes. This means that the learning objective of <ref type="bibr" target="#b13">Ishida et al. (2017)</ref> has a (negative) lower bound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Non-negative risk estimator</head><p>As we saw in Section 3.2, our risk estimator can suffer from overfitting due to the non-negative issue. Here, we propose a correction to the risk estimator to overcome this problem.</p><p>Each term in the risk with ordinary labels (right-hand side of (2)), which corresponds to each class, is non-negative. We can reformulate (12) in order to show the counterpart for each non-negative term in the right-hand side of (2) for complementarily labeled data as</p><formula xml:id="formula_13">R(g; ) = K k=1 − (K − 1)π k · E P k k, g(X) + K j=1 π j · E P j k, g(X)</formula><p>. <ref type="formula" target="#formula_1">(14)</ref> These counterparts (14) were originally non-negative when ordinary labels were used. In the left and middle graphs of <ref type="figure">Figure 1</ref>, we plot the decomposed risks with respect to each ordinary class (14) (shown in different colors). We can see that the decomposed risks for all classes become negative eventually. Based on this observation, our basic idea for correction is to enforce non-negativity for each ordinary class, with the expression based on complementary labels. More specifically, we propose a non-negative version by K k=1 max 0, − (K − 1)π k · E P k k, g(X)</p><formula xml:id="formula_14">+ K j=1 π j · E P j k, g(X)</formula><p>.</p><p>(15) is equivalent to <ref type="formula" target="#formula_1">(14)</ref>, since max{0, a} = a if a is non-negative. By using the datasets used for (13), this nonnegative risk can be naïvely approximated by the sample <ref type="figure">Figure 1</ref>:</p><p>The left and middle graphs shows the total risk (13) (in black color) and the risk decomposed into each ordinary class term <ref type="formula" target="#formula_1">(14)</ref> (in other colors) for training data with linear and MLP models, respectively. The right graph shows the corresponding test accuracy for both models.</p><p>average as</p><formula xml:id="formula_16">K k=1 max 0, − (K − 1) · π k |X k | xi∈X k (k, g(x i )) + K j=1 π j |X j | x i ∈Xj (k, g(x i )) . (16)</formula><p>The empirical version of (14) may suffer from a negative objective, but (16) is non-negative (even though their population versions are equivalent.)</p><p>Enforcing the reformulated risk to become non-negative was previously explored in <ref type="bibr" target="#b18">Kiryo et al. (2017)</ref>, in the context of binary classification from positive and unlabeled data. The positive class risk is already bounded below by zero in their case (because they have true positive labels), so there was a max operator only on the negative class risk. We follow their footsteps, but since our setting is a multi-class scenario and also differs by not having any true labels, we put a max operator on each of the K classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Approximate non-negative risk estimator</head><p>Implementation with max operator We now illustrate how to design a practical implementation under stochastic optimization for our non-negative risk estimator. An unfortunate issue is that the minimization of (16) is not point-wise due to the max-operator, thus cannot be used directly for stochastic optimization methods with mini-batch. However, an upper bound of the risk can be minimized in parallel by using mini-batch as the following, for b = 1 to B:</p><formula xml:id="formula_17">1 B N b=1 K k=1 max 0, −(K − 1)π k · E P k k, g(X) ; X b k + K j=1 π j · E P j k, g(X) ; X b j ,<label>(17)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Denote {X b j } as the b-th mini-batch for complementary class j 6:</p><formula xml:id="formula_18">Denote r b k (θ) = −(K − 1)π k · E P k [ (k, g); X b k ] + K j=1 π j · E P j [ (k, g); X b j ] 7: if min k [r b 1 (θ), . . . , r b k (θ), . . . , r b K (θ)] &gt; −β: 8: Denote L b (θ) = K k=1 r b k (θ) 9:</formula><p>Set gradient ∇ θ L b (θ);</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10:</head><p>Update θ by A with its current step size η;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>else:</p><p>12:</p><formula xml:id="formula_19">Denote L b (θ) = K k=1 min{−β, r b k (θ)} 13:</formula><p>Set gradient −∇ θ L b (θ);</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>14:</head><p>Update θ by A with a discounted step size γη;</p><p>where E is the empirical version of the expectation and B is the number of mini-batches.</p><p>Implementation with gradient ascent If the objective is negative for a certain mini-batch, the previous implementation based on the max operator will prevent the objective to further decrease. However, if the objective is already negative, that mini-batch has already started to overfit. The max operator cannot contribute to decrease the degree of overfitting. From this perspective, there is still room to improve the overfitting issue, and it would be preferable to increase itself to make this mini-batch less overfitted.  Our idea is the following. We denote the risk that corresponds to the kth ordinary class for the ith mini-batch as</p><formula xml:id="formula_20">r b k (θ) = −(K − 1)π k · E P k [ k, g(X) ; X b k ] + K j=1</formula><p>π j · E P j k, g(X) ; X b j , and the total risk as L b (θ) = K k=1 r b k (θ). When min k {r b k (θ)} K k=1 ≥ −β, we conduct gradient descent as usual with gradient ∇ θ L b (θ). On the other hand, if min k {r b k (θ)} K k=1 &lt; −β, we first squash the classdecomposed risks over −β to −β with a min operator, and then sum the results:</p><formula xml:id="formula_21">L b (θ) = K k=1 min{−β, r b k (θ)}.</formula><p>Next we set the gradient in the opposite direction with −∇ θ L b (θ). Conceptually, we are going up the gradient ∇ θ L b (θ) for only the class-decomposed risks below −β, to avoid the class-decomposed risks that are already large to further increase. Note that β is a hyper-parameter that controls the tolerance of negativity. β = 0 would mean there is zero tolerance, but in practice we can also have −β = 0 for a threshold that allows some negative (−β &lt; 0) or positive (−β &gt; 0) amount. The procedure is shown in detail in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we compare the 3 methods that we have proposed in Section 3, which are Free (Unbiased risk estimator that is loss assumption free, based on Eq. (13)), Max Operator (based on Eq. (17)), and Gradient Ascent (based on Alg.1). For Gradient Ascent, we used β = 0 and γ = 1 for simplicity. Mini-batch size was set to 256. We also compare with two baseline methods: Pairwise comparison (PC) with ramp loss from <ref type="bibr" target="#b13">Ishida et al. (2017)</ref> and Forward correction from <ref type="bibr" target="#b10">Yu et al. (2018)</ref>. For training, we used only complementarily labeled data, which was generated so that the assumption of (5) is satisfied. This is straightforward when the dataset has a uniform (ordinarily-labeled) class prior, because it reduces to just choosing a class randomly other than the true class.</p><p>In Appendix C, we explain the details of the datasets used in the experiments: MNIST, Fashion-MNIST, Kuzushiji-MNIST, and CIFAR-10. The implementation is based on Pytorch 2 and our demo code is available online 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Comparison of all epochs during training</head><p>Setup For MNIST, Fashion-MNIST, and Kuzushiji-MNIST, a linear-in-input model with a bias term and a MLP model (d − 500 − 1) was trained with softmax cross-entropy loss function (except PC) for 300 epochs. Weight decay of 1e − 4 for weight parameters and learning rate of 5e − 5 for Adam <ref type="bibr" target="#b16">(Kingma &amp; Ba, 2015)</ref> was used.</p><p>For CIFAR-10, DenseNet <ref type="bibr" target="#b12">(Huang et al., 2017)</ref> and ResNet-34 <ref type="bibr" target="#b11">(He et al., 2016)</ref> were used with weight decay of 5e − 4 and initial learning rate of 1e − 2. For optimization, stochastic gradient descent was used with the momentum set to 0.9.</p><p>Learning rate was halved every 30 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We show the accuracy for all 300 epochs on test data to demonstrate how the issues discussed in Section 3.2 appear and how different implementations in Section 3.4 are effective. In <ref type="figure" target="#fig_2">Figure 2</ref>, we show the mean and standard deviation of test accuracy for 4 trials on test data evaluated with ordinary labels.</p><p>First we compare our 3 proposed methods with each other. For linear models in MNIST, Fashion-MNIST, and Kuzushiji-MNIST, all proposed methods work similarly. However in the case of using a more flexible MLP model or using DenseNet/ResNet in CIFAR-10, we can see that Free is the worst, Max Operator is better and Gradient Ascent is the best out of the proposed three methods for most of the epochs (Free &lt; Max Operator &lt; Gradient Ascent). These results are consistent with the discussions of overfitting in Section 3.2 and the motivations for different implementations in Section 3.4.</p><p>Next, we compare with baseline methods. For linear models, all methods have similar performance. However for deep models (MLP, DenseNet, and ResNet), the superiority stands out for Gradient Ascent for all datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiments with validation process</head><p>Setup Next, we perform experiments with a train, validation, and test split. The dataset is constructed by splitting the original training data used in the previous experiments into train/validation with a 9:1 ratio. Note that the validation data only has complementary labels since it is splitted from the set of complementarily labeled training data. We use the same MLP models for MNIST, Fashion-MNIST, and Kuzushiji-MNIST. We use DenseNet for CIFAR-10.</p><p>Since Gradient Ascent (GA) seemed to work better than Free and Max Operator previously, we omit Free and Max Operator and compare GA with baseline methods <ref type="bibr">(PC and Forward(Fwd)</ref>). For the validation objective, we used the corresponding criterion for each method, which is shown in the first 3 columns with parenthesis, in <ref type="table" target="#tab_1">Table 2</ref>. We also conducted experiments using our proposed general unbiased estimator Free as the validation criterion for baseline methods (PC and Fwd), which is shown in the last 2 columns in <ref type="table" target="#tab_1">Table 2</ref>. SGD with momentum of 0.9 was used for 250 epochs. Weight-decay was fixed to 1e − 4 and learning rate candidates are {1e − 4, 5e − 4, 1e − 3, 5e − 3, 1e − 2, 5e − 2} for CIFAR-10 and {5e − 5, 1e − 4, 5e − 4, 1e − 3, 5e − 3, 1e − 2} for other datasets. For CIFAR-10, we added learning rate decay with the same settings from Section 4.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>In <ref type="table" target="#tab_1">Table 2</ref>, we showed the mean and standard deviation of test accuracy for 4 trials, with the model that gave the best validation score out of all epochs for all hyperparameter candidates. By comparing the first 3 columns, GA seems to work well. We can also observe that in most cases, PC (Free) and Fwd (Free) performs similarly or better than PC (PC) and Fwd (Fwd), respectively. This confirms the discussion in earlier sections that our general unbiased risk estimator is useful not only as a learning objective, but also useful as a validation objective for baseline methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We first proposed a general risk estimator for learning from complementary labels that does not require restrictions on the form of the loss function or the model. However, since the proposed method suffers from overfitting, we proposed a modified version to alleviate this issue in two ways and have better performance. At last, we conducted experiments to show our proposed method outperforms or is comparable to current state-of-the-art methods for various benchmark datasets and for both linear and deep models.</p><p>Recently, complementary-label learning has been applied to online learning <ref type="bibr" target="#b15">(Kaneko et al., 2019)</ref>, generative discriminative learning <ref type="bibr">(Xu et al., 2019)</ref>, and medical image segmentation <ref type="bibr" target="#b28">(Rezaei et al., 2019)</ref>. This implies applying the idea of complementary labels to other domains may be useful, which can be an interesting future direction.</p><p>Sakai, T., du Plessis, M. C., Niu, G., and Sugiyama, M. Semi-supervised classification based on classification from positive and unlabeled data. In ICML, 2017. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proof of Theorem 1</head><p>Proof. First of all,</p><formula xml:id="formula_22">P(X, Y = y) = 1 K − 1 y =y P(X, Y = y) = 1 K − 1 K y=1 P(X, Y = y) − P(X, Y = y) = 1 K − 1 P(X) − P(X, Y =ȳ) .</formula><p>The first equality holds since the marginal distribution is equivalent for D and D and we assume (5). Consequently,</p><formula xml:id="formula_23">P(Y = y|X = x) = P(X = x, Y = y) P(X = x) = 1 K − 1 · 1 − P(X, Y = y) P(X = x) = 1 K − 1 · 1 − P(Y = y|X = x) = − 1 K − 1 P(Y = y|X = x) + 1 K − 1 .</formula><p>More simply, we have η(x) = −(K − 1)η(x) + 1. Finally, we transform the classification risk,</p><formula xml:id="formula_24">R(g; ) = E (X,Y )∼D [ (Y, g(X))] = E X∼M [η (g(X))] = E X∼M − (K − 1)η + 1 g(X) = E X∼M − (K − 1)η g(X) + 1 g(X) = E (X,Y )∼D − (K − 1) · Y , g(X) + 1 E X∼M g(X) = K k=1 π k · E X∼P k − (K − 1) · k, g(X) + 1 g(X) = R(g; )</formula><p>for the complementary loss, (k, g) := −(K − 1) (k, g) + 1 (g), which concludes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Proof of Corollary 2</head><p>Proof. The second equality holds because we use (10). The third equality holds because we are using losses that satisfy j (j, g(x)) = M 1 for all x and (y, g(x))+ (y, g(x)) = M 2 for all x and y. The 4th equality rearranges terms. The 5th equality holds because M 1 − (K − 1)M 2 = −M 1 + M 2 for OVA and PC . This can be easily shown by using M 1 = K and M 2 = 2 for OVA , and M 1 = K(K − 1)/2 and M 2 = K − 1 for PC .</p><formula xml:id="formula_25">R(g; ) = E D [ (Y , g(X))] = E D [−(K − 1) (Y , g(X)) + K j=1 (j, g(X))] = E D − (K − 1)[M 2 − (Y , g(X))] + M 1 = (K − 1)E D [ (Y , g(X))] + M 1 − (K − 1)M 2 = (K − 1)E D [ (Y , g(X))] − M 1 + M 2</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Datasets</head><p>In the experiments in Section 4, we use 4 benchmark datasets explained below. The summary statistics of the four datasets are given in <ref type="table" target="#tab_3">Table 3</ref>.</p><p>• MNIST 4 <ref type="bibr" target="#b19">(Lecun et al., 1998</ref>) is a 10 class dataset of handwritten digits: 1, 2 . . . , 9 and 0. Each sample is a 28 × 28 grayscale image.</p><p>• Fashion-MNIST 5 (Xiao et al., 2017) is a 10 class dataset of fashion items: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, and Ankle boot. Each sample is a 28 × 28 grayscale image.</p><p>• Kuzushiji-MNIST 6 <ref type="bibr" target="#b4">(Clanuwat et al., 2018</ref>) is a 10 class dataset of cursive Japanese ("Kuzushiji") characters. Each sample is a 28 × 28 grayscale image.</p><p>• CIFAR-10 7 is a 10 class dataset of various objects: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. Each sample is a colored image in 32 × 32 × 3 RGB format. It is a subset of the 80 million tiny images dataset <ref type="bibr">(Torralba et al., 2008)</ref>.</p><p>Errata <ref type="bibr">(Nov. 19, 2019)</ref> We have found errors in our previous implementation for the forward method <ref type="bibr" target="#b10">(Yu et al., 2018)</ref>, and would like to report the updated results based on the fixed implementation.</p><p>In <ref type="figure" target="#fig_3">Figure 3</ref>, the forward method performs better than previously reported. This is especially true for linear models. For neural network models, the results seem to be dataset-dependent: For MNIST and Fashion-MNIST, the proposed gradient ascent method is similar to the forward method. For Kuzushiji-MNIST, the proposed gradient ascent method is still better than the forward method. For CIFAR-10, the proposed gradient ascent method with DenseNet still performs the best with around 40% accuracy. In <ref type="table" target="#tab_4">Table 4</ref>, the proposed gradient ascent method is better for CIFAR-10, but the forward method is better for MNIST and Fashion-MNIST. The two methods perform similarly for Kuzushiji-MNIST.</p><p>Addtionally, we investigate the reason behind the good performance of forward methods with a linear model. In <ref type="figure" target="#fig_4">Figure 4</ref>, we visualize the reliability diagrams <ref type="bibr" target="#b9">(Guo et al., 2017)</ref> and histograms of the softmax output of the forward method, for MNIST, Fashion-MNIST, and Kuzushiji-MNIST. We can see that the linear model is much more confidence-calibrated compared to MLP models. The forward method requires the model to be flexible in order to guarantee that the solution gives the true class posterior under the clean joint distribution, given uncountably infinite training data. In the figures, however, we can see that with finite training data, a flexible model can be over-confident (further away from the gray dotted line), while a linear model is more confidence-calibrated (more closer to the gray dotted line).   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>identically from a different joint distribution D = D. We denote random variables as (X, Y ) ∼ D. As before, we assume this distribution can be decomposed into either class-conditionals {P k } K k=1 and base rate {π} K k=1 , or marginal M and class-probability function η : X → ∆ K , where P k := P(X|Y = k), π k := P(Y = k), M := P(X), η k (x) := P(Y = k|X = x), and Y is the complementary label.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Kuzushiji-MNIST, linear (f) Kuzushiji-MNIST, MLP (g) CIFAR-10, DenseNet (h) CIFAR-10, ResNet</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Experimental results for various datasets and models. Dark colors show the mean accuracy of 5 trials and light colors show standard deviation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Updated results ofFigure 2. The forward method has been swapped with the fixed implementation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>The bottom figures show the histogram of the output of the softmax layer in the forward method, with 10 bins in the horizontal axis, for MNIST, Fashion-MNIST, and Kuzushiji-MNIST. The light blue color shows the linear model and the dark blue color shows the MLP model. The top figures show the reliability diagrams for the same datasets. The vertical axis shows the proportion of correct predictions in each bins. The gray dotted line shows the identity function as an ideal case.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Test mean and standard deviation of the classification accuracy for 4 trials. Method name outside (inside) parenthesis shows the criterion of training (validation) objective. Best is shown in bold or underline for column 2∼4 or column 2∼6, respectively. ± 3.3% 88.7 ± 0.3% 80.2 ± 2.9% 89.4 ± 0.4% Fashion 78.7 ± 1.4% 74.7 ± 1.6% 77.5 ± 1.2% 75.7 ± 1.2% 73.5 ± 5.5%</figDesc><table><row><cell>Dataset</cell><cell>GA (Free)</cell><cell>PC (PC)</cell><cell>Fwd (Fwd)</cell><cell>PC (Free)</cell><cell>Fwd (Free)</cell></row><row><cell cols="3">MNIST 79.3 Kuzushiji 88.1 ± 2.5% 63.8 ± 1.1% 56.7 ± 4.9%</cell><cell>62.0 ± 1.1%</cell><cell cols="2">56.1 ± 4.2% 65.4 ± 1.7%</cell></row><row><cell cols="3">CIFAR-10 36.8 ± 0.6% 33.4 ± 2.0%</cell><cell>30.8 ± 1.6%</cell><cell cols="2">25.9 ± 7.6% 30.8 ± 1.7%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Tarvainen, A. and Valpola, H. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In NIPS, 2017.</figDesc><table><row><cell>Torralba, A., Fergus, R., and Freeman, W. T. 80 million tiny</cell></row><row><cell>images: A large data set for nonparametric object and</cell></row><row><cell>scene recognition. In IEEE Trans. PAMI, 2008.</cell></row><row><cell>Xiao, H., Rasul, K., and Vollgraf, R. Fashion-MNIST: a</cell></row><row><cell>novel image dataset for benchmarking machine learning</cell></row><row><cell>algorithms. arXiv preprint arXiv:1708.07747, 2017.</cell></row><row><cell>Xu, Y., Gong, M., Chen, J., Liu, T., Zhang, K., and Bat-</cell></row><row><cell>manghelich, K. Generative-discriminative complemen-</cell></row><row><cell>tary learning. arXiv preprint arXiv:1904.01612, 2019.</cell></row><row><cell>Yu, X., Liu, T., Gong, M., and Tao, D. Learning with biased</cell></row><row><cell>complementary labels. In ECCV, 2018.</cell></row><row><cell>Zhang, T. Statistical analysis of some multi-category large</cell></row><row><cell>margin classification methods. Journal of Machine Learn-</cell></row><row><cell>ing Research, 5:1225-1251, 2004.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Summary statistics of benchmark datasets. In the experiments with validation dataset in Section 4.2, train data is further splitted into train/validation with a ratio of 9:1. Fashion is Fashion-MNIST and Kuzushiji is Kuzushiji-MNIST.</figDesc><table><row><cell>Name</cell><cell cols="3"># Train # Test # Dim # Classes</cell><cell>Model</cell></row><row><cell>MNIST</cell><cell>60k</cell><cell>10k 784</cell><cell>10</cell><cell>Linear, MLP</cell></row><row><cell>Fashion</cell><cell>60k</cell><cell>10k 784</cell><cell>10</cell><cell>Linear, MLP</cell></row><row><cell cols="2">Kuzushiji 60k</cell><cell>10k 784</cell><cell>10</cell><cell>Linear, MLP</cell></row><row><cell cols="2">CIFAR-10 50k</cell><cell>10k 2,048</cell><cell>10</cell><cell>DenseNet, Resnet</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Updated results of Table 2. The results in the 4th and 6th columns have been swapped with the fixed implementation. ± 3.3% 93.3 ± 0.2% 80.2 ± 2.9% 92.2 ± 0.6% Fashion 78.7 ± 1.4% 74.7 ± 1.6% 82.7 ± 0.4% 75.7 ± 1.2% 82.5 ± 0.6% Kuzushiji 63.8 ± 1.1% 56.7 ± 4.9% 64.1 ± 0.4% 56.1 ± 4.2% 63.9 ± 1.9% CIFAR-10 36.8 ± 0.6% 33.4 ± 2.0% 33.2 ± 0.9% 25.9 ± 7.6% 33.7 ± 1.1% Complementary-Label Learning for Arbitrary Losses and Models</figDesc><table><row><cell>Dataset</cell><cell>GA (Free)</cell><cell>PC (PC)</cell><cell>Fwd (Fwd)</cell><cell>PC (Free)</cell><cell>Fwd (Free)</cell></row><row><cell>MNIST</cell><cell>88.1 ± 2.5%</cell><cell>79.3</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The University of Tokyo 2 RIKEN 3 Google Research. Correspondence to: Takashi Ishida &lt;ishida@ms.k.u-tokyo.ac.jp&gt;.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://pytorch.org 3 https://github.com/takashiishida/comp</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">http://yann.lecun.com/exdb/mnist/ 5 https://github.com/zalandoresearch/ fashion-mnist 6 https://github.com/rois-codh/kmnist 7 https://www.cs.toronto.edu/˜kriz/cifar. html</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>TI was supported by Sumitomo Mitsui DS Asset Management. MS was supported by JST CREST JPMJCR1403. We thank the anonymous reviewers for the helpful suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Classification from pairwise similarity and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Semi-Supervised Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<editor>Zien, A.</editor>
		<imprint>
			<date type="published" when="2006" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On symmetric losses for learning from corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Charoenphakdee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Consistency of losses for learning from weak labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cid-Sueiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>García-García</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Santos-Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML-PKDD</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep learning for classical Japanese literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Clanuwat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bober-Irizar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kitamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Workshop on Machine Learning for Creativity and Design</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning from partial labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Taskar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1501" to="1536" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Clustering unclustered data: Unsupervised binary labeling of two datasets having different class balances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Du Plessis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">TAAI</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convex formulation for learning from positive and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Du Plessis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">; M C</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS, 2014. du Plessis</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ICML</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning classifiers from only positive and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Noto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning from complementary labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Binary classification from positive-confidence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Online multiclass classification based on prediction margin for partial feedback</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kaneko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.01056</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Positive-unlabeled learning with non-negative risk estimator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiryo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Du Plessis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Gradientbased learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the minimal supervision for training any binary classifier from only unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Dimensionalitydriven learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning from corrupted binary labels via classprobability estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Rooyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distributional smoothing with virtual adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted Boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Realistic evaluation of deep semi-supervised learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Recurrent generative adversarial network for learning imbalanced medical image semantic segmentation. Multimedia Tools and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rezaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Meinel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="20" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
