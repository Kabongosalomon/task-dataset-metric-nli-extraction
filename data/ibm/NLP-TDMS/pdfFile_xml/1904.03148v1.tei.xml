<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Image Matching and Object Discovery as Optimization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><forename type="middle">V</forename><surname>Vo</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Département d&apos;informatique de l&apos;ENS</orgName>
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">INRIA</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Bach</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Département d&apos;informatique de l&apos;ENS</orgName>
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">INRIA</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Pérez</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Ponce</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Département d&apos;informatique de l&apos;ENS</orgName>
								<orgName type="institution" key="instit1">ENS</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">PSL University</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">INRIA</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Image Matching and Object Discovery as Optimization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">3 Valeo.ai 4 POSTECH 5 University of Oxford 6 New York University</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:12+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: The proposed optimization-based method automatically discovers links between images that depict similar objects. This figure shows two image clusters that emerge as a by-product of this approach on the VOC 6x2 object recognition dataset that mixes 6 classes under two viewpoints. See text for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>Learning with complete or partial supervision is powerful but relies on ever-growing human annotation efforts. As a way to mitigate this serious problem, as well as to serve specific applications, unsupervised learning has emerged as an important field of research. In computer vision, unsupervised learning comes in various guises. We focus here on the unsupervised discovery and matching of object categories among images in a collection, following the work of Cho et al. <ref type="bibr" target="#b11">[12]</ref>. We show that the original approach can be reformulated and solved as a proper optimization problem.</p><p>Experiments on several benchmarks establish the merit of our approach.</p><p>We address here the even more challenging problem of discovering both the structure of image collections -that is, which images depict similar objects (or textures, scenes, actions, etc.), and the objects in question, in a fully unsupervised setting <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43]</ref>. Although weakly, semi, and self supervised methods may provide a</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Remarkable progress has been achieved in visual tasks such as image categorization, object detection, or semantic segmentation, typically using fully supervised algorithms and vast amount of manually annotated data (e.g., <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b39">40]</ref>). With the advent of crowd-sourcing, large corporations and, to a lesser extent, academic units can launch the corresponding massive annotation efforts for specific projects that may involve millions images <ref type="bibr" target="#b39">[40]</ref>.</p><p>But handling Internet-scale image (or video) repositories or the continuous learning scenarios associated with personal assistants or autonomous cars demands approaches less hungry for manual annotation. Several alternatives are possible, including weakly supervised approaches that rely on readily available meta-data <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b8">9]</ref> or image-level labels <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b44">45]</ref> instead of more complex annotations such as bounding boxes <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b37">38]</ref> or object masks <ref type="bibr" target="#b19">[20]</ref> as supervisory signal; semi supervised methods <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b25">26]</ref> that exploit a relatively small number of fully annotated pictures, together with a larger set of unlabelled images; and self supervised algorithms that take advantage of the internal regularities of image parts <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b36">37]</ref> or video subsequences <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b47">48]</ref> to construct image models that can be further fine-tuned in fully supervised settings. more practical foundation for large-scale visual recognition, the fully unsupervised construction of image models is a fundamental scientific problem in computer vision, and it should be studied. In addition, any reasonable solution to this problem will facilitate subsequent human labelling (by presenting discovered groups to the operator) and scaling through automatic label propagation, help interactive querybased visual search by linking ahead of time fragments of potential interest, and provide a way to learn visual models for subsequent recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">The implicit structure of image collections</head><p>Any collection of images, say, those found on the Internet, or more modestly, in a dataset such as Pascal VOC'07, admits a natural graph representation, where nodes are the pictures themselves, and edges link pairs of images with similar visual content. In supervised image categorization (e.g., <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b28">29]</ref>) or object detection (e.g., <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b37">38]</ref>) tasks, both the graph structure and the visual content are clearly defined: Annotators typically sort the images into bags, each one intended to represent some "object", "scene" or, say, "action" class ("horse", "forest", "playing tennis", etc.). Two nodes are linked by an edge when they are associated with the same bag, and each class is empirically defined by the images (or some manually-defined rectangular regions within) in the corresponding connected component of the graph. In weakly supervised cosegmentation <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b38">39]</ref> or colocalization <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b44">45]</ref> tasks, on the other hand, the graph is fully connected, and all images are supposed to contain instances of the (few) same object categories, say, "horse", "grass", "sky", "background". Manual intervention is reduced to selecting which images to put into a single bag, and the visual content, in the form of regions defined by pixel-level symbolic labels or bounding boxes associated with one of the predefined categories, is discovered using a clustering algorithm. <ref type="bibr" target="#b0">1</ref> We address in this paper the much more difficult problem of fully unsupervised image matching and object discovery, where both the graph structure and a model of visual content in the form of object bounding boxes must be extracted from the native data without any manual intervention. This problem has been addressed in various forms, e.g., clustering <ref type="bibr" target="#b15">[16]</ref> 2 , image matching <ref type="bibr" target="#b38">[39]</ref> or topic discovery <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b42">43]</ref> (see also <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b10">11]</ref>, where "pseudo-object" labels are learned in an unsupervised manner). In this presentation, we build directly on the work of Cho et al. <ref type="bibr" target="#b11">[12]</ref> (see <ref type="bibr" target="#b27">[28]</ref> for related <ref type="bibr" target="#b0">1</ref> In both the cases of supervised image categorization/object detection and weakly supervised cosegmentation/colocalization, once the graph structure and the visual content have been identified at training time, these can be used to learn a model of the different object classes and add nodes, edges, and possibly additional bounding boxes at test time. <ref type="bibr" target="#b1">2</ref> Note that plain unsupervised clustering, whether classic, spectral, discriminative or deep <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b35">36]</ref>, focuses on data partitioning and not on the discovery of subsets of matching items within a cluttered collection. work): Given an image and its neighbors, assumed to contain the same object, a robust matching technique exploits both appearance and geometric consistency constraints to assign confidence and saliency ("stand-out") scores to region proposals in this image. The overall discovery algorithm alternates between localization steps where the neighbors are fixed and the regions with top saliency scores are selected as potential objects, and retrieval steps where the confidence of the regions within potential objects are used to find the nearest neighbors of each image. After a fixed number of steps, the region with top saliency in each image is declared to be the object it contains. Empirically, this method has been shown in <ref type="bibr" target="#b11">[12]</ref> to give good results. However, it does not formulate image matching and object discovery as a proper optimization problem, and there is no guarantee that successive iterations will improve some objective measure of performance. The aim of this paper is to remedy this situation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Proposed approach 2.1. Problem statement</head><p>Let us consider a set of n images, each containing p i rectangular region proposals, with i in {1 . . . n}. We assume that the images are equipped with some implicit graph structure, where there is a link between two images when the second image contains at least one object from a category depicted in the first one, and our aim is to discover this structure, that is, find the links and the corresponding objects. To model this problem, let us define an indicator variable x k i , whose value is 1 when region number k of image i corresponds to a "foreground object" (visible in large part and from a category that occurs multiple times in the image collection), and 0 otherwise. We collect all the variables x k i associated with image i into an element x i of {0, 1} pi , and concatenate all the variables x i into an element x of {0, 1} n i=1 pi . Likewise, let us define an indicator variable e ij , whose value is 1 if image j contains an object also occurring in image i, with 1 ≤ i, j ≤ n and j = i, and 0 otherwise, collect all the variables e ij associated with image i into an element e i of {0, 1} n , and concatenate all the variables e i into an n × n matrix e with rows e T i . Note that we can use e to define a neighborhood for each image in the set: Image j is a neighbor of the image i if e ij = 1. By definition, e defines an undirected graph if e is symmetric and a directed one otherwise. Let us also denote by S kl ij the similarity between regions k and l of images i and j, and by S ij the p i × p j matrix with entries S kl ij . We propose to maximize with respect to x and e the objective function</p><formula xml:id="formula_0">S(x, e) = n i,j=1 j =i e ij 1≤k≤pi 1≤l≤pj S kl ij x k i x l j = n i,j=1 j =i x T i [e ij S ij ]x j .<label>(1)</label></formula><p>Intuitively maximizing S(x, e) encourages building edges between images i and j that contain regions k and l with a strong similarity S kl ij . Of course we would like to impose certain constraints on the x and e variables. The following cardinality constraints are rather natural:</p><p>• An image should not contain more than a prededined number of objects, say ν,</p><formula xml:id="formula_1">∀ i ∈ 1 . . . n, x i · 1 pi ≤ ν,<label>(2)</label></formula><p>where 1 pi is the element of R pi with all entries equal to one.</p><p>• An image should not match more than a predefined number of other images, say τ ,</p><formula xml:id="formula_2">∀ i ∈ 1 . . . n, e i · 1 n ≤ τ.<label>(3)</label></formula><p>Assumptions. We will suppose from now on that S ij is elementwise nonnegative, but not necessarily symmetric (the similarity model we explore in Section 3 is asymmetrical). Likewise, we will assume that the matrix e has a zero diagonal but is not necessarily symmetric. Under these assumptions, the cubic pseudo-Boolean function S is supermodular <ref type="bibr" target="#b9">[10]</ref>. Without constraints, this type of functions can be maximized in polynomial time using a max-flow algorithm <ref type="bibr" target="#b6">[7]</ref> (in the case of S(x, e), which does not involve linear and quadratic terms, the solution is of course trivial without constraints, and amounts to setting all x k i and e ij with i = j to 1). When the cardinality constraints (2-3) are added, this is not the case anymore, and we have to resort to a gradient ascent algorithm as explained next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Relaxing the problem</head><p>Let us first note that, for binary variables x k i , x l j and e ij , we have</p><formula xml:id="formula_3">S(x, e) = n i,j=1 j =i 1≤k≤pi 1≤l≤pj S kl ij min(e ij , x k i , x l j ),<label>(4)</label></formula><p>with S kl ij ≥ 0. Relaxing our problem so all variables are allowed to take values in [0, 1], our objective becomes a sum of concave functions, and thus is itself a concave function, defined over the convex set (hyperrectangle) [0, 1] N , where N is the total number of variables. This is the standard tight concave continuous relaxation of supermodular functions.</p><p>The Lagrangian associated with our relaxed problem is</p><formula xml:id="formula_4">K(x, e; λ, µ) = S(x, e)− n i=1 [λ i (x i ·1 pi −ν)+µ i (e i ·1 n −τ )],<label>(5)</label></formula><p>where λ = (λ 1 , . . . , λ n ) T and µ = (µ 1 , . . . , µ n ) T are positive Lagrange multipliers. The function S(x, e) is concave and the primal problem is strictly feasible; hence Slater's conditions <ref type="bibr" target="#b43">[44]</ref> hold, and we have the following equivalent primal and dual versions of our problem max (x,e)∈D inf λ,µ≥0 K(x, e; λ, µ), min λ,µ≥0 sup (x,e)∈D K(x, e; λ, µ),</p><p>where the domain D is the Cartesian product of [0, 1] i pi and the space of n × n matrices with entries in [0, 1] and a zero diagonal. With slight abuse we denote it D = [0, 1] N , with N = i p i + n(n − 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Solving the dual problem</head><p>We propose to solve the dual problem with a subgradient descent approach. Starting from some initial values for λ 0 and µ 0 , we use the update rule</p><formula xml:id="formula_6">λ t+1 i = [λ t i + α(x t i · 1 pi − ν)] + , µ t+1 i = [µ t i + β(e t i · 1 n − τ )] + ,<label>(7)</label></formula><p>where [·] + denotes positive part, k ≥ 0, α and β are fixed step sizes, x t i · 1 pi − ν and e t i · 1 n − τ are respectively the negative of the subgradients of the Lagrangian with respect to λ i and µ i in λ t i and µ t i , and</p><formula xml:id="formula_7">(x t , e t ) ∈ argmax (x,e)∈[0,1] N K(x, e; λ t , µ t ).<label>(8)</label></formula><p>As shown in Appendix, for fixed values of λ and µ, our Lagrangian is a supermodular pseudo-Boolean function of binary variables sets x and e. This allows us to take advantage of the following direct corollary of [3, Prop. 3.7]. Proposition 2.1. Let f denote some supermodular pseudo-Boolean function of n variables. We have</p><formula xml:id="formula_8">max x∈{0,1} n f (x) = max x∈[0,1] n f (x),<label>(9)</label></formula><p>and the set of maximizers of f (x) in [0, 1] n is the convex hull of the set of maximizers of f on {0, 1} n .</p><p>In particular, we can take</p><formula xml:id="formula_9">(x t , e t ) ∈ argmax (x,e)∈{0,1} N K(x, e; λ t , µ t ).<label>(10)</label></formula><p>As shown in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10]</ref>, the corresponding supermodular cubic pseudo-Boolean function optimization problem is equivalent to a maximum stable set problem in a bipartite conflict graph, which can itself be reduced to a maximum-flow problem. See Appendix for details. Note that the size of the min-cut/max-flow problems that have to be solved is conditioned by the number of nonzero S kl ij entries, which is upper-bounded by n 2 p 2 when the matrices S ij are dense (denoting p = max{p i }). This is prohibitively high given that, in practice, p is between 1000 and 4000. To make the computations manageable, we set all but between 100 and 1000 (depending on the dataset's size) of the largest entries in S ij to zero in our implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Solving the primal problem</head><p>Once the dual problem is solved, as argued by Nedić &amp; Ozdaglar <ref type="bibr" target="#b34">[35]</ref> and Bach <ref type="bibr" target="#b2">[3]</ref>, an approximate solution of the primal problem can be found as a running average of the primal sequence (x t , e t ) generated as a by-product of the sub-gradient method:</p><formula xml:id="formula_10">x = 1 T T −1 t=0 x t ,ê = 1 T T −1 t=0 e t<label>(11)</label></formula><p>after some number T of iterations. Note the scalarsx k i and e ij lie in [0, 1] but do not necessarily verify the constraints <ref type="formula" target="#formula_1">(2)</ref> and <ref type="formula" target="#formula_2">(3)</ref>. Theoretical guarantees on these values can be found under additional assumptions in <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b34">35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Rounding the solution and greedy ascent</head><p>Note that two problems remain to be solved: The solution (x,ê) found now belongs to [0, 1] N instead of {0, 1} N , and it may not satisfy the original constraints. Note, however, that because of the form of the function S, given some i in {1, . . . , n} and fixed values for e and all x j with j = i, the maximum value of S given the constraints is obtained by setting to 1 exactly the ν entries of x i corresponding to the ν largest entries of the vector j =i (e ij S ij + e ji S T ji )x j . Likewise, for some fixed value of x, the maximum value of S is reached by setting to 1, for all i in {1, . . . , n}, exactly the τ entries of e i corresponding to the τ largest scalars x T i S ij x j for j = i in {1 . . . n}. This suggests the following approach to rounding up the solution, where the variables x i are updated sequentially in an order specified by some random permutation σ of {1, . . . , n}, before the variables e i are updated in parallel. Given the permutation σ, the algorithm below turns the running average (x,ê) of the primal sequence into a discrete solution (x, e) that satisfies the conditions <ref type="formula" target="#formula_1">(2)</ref> and <ref type="formula" target="#formula_2">(3)</ref>:</p><formula xml:id="formula_11">Initialize x =x, e =ê. For i = 1 to n do</formula><p>Compute the indices k 1 to k ν of the ν largest elements of the vector</p><formula xml:id="formula_12">n j =σ(i) (e σ(i)j S σ(i)j + e jσ(i) S T jσ(i) )x j . x σ(i) ← 0. For t = 1 to ν do x kt σ(i) ← 1. For i = 1 to n do Compute the indices j 1 to j τ of the τ largest scalars x T i S ij x j . e i ← 0. For t = 1 to τ do e ijt ← 1. Return x, e.</formula><p>Note that there is no preferred order for the image indices. This actually suggests repeating this procedure with different random permutations until the variables x and e do not change anymore or some limit on the number of iterations is reached. This iterative procedure can be seen as a greedy ascent procedure over the discrete variables of interest. Note that by construction the terms in the left and right sides of <ref type="formula" target="#formula_1">(2)</ref> and <ref type="formula" target="#formula_2">(3)</ref> are equal at the optimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Ensemble post processing</head><p>The parameter ν can be seen from two different viewpoints: (1) as the maximum number of objects that may be depicted in an image, or (2) as an upper bound on the total number of object region candidates that are under consideration in a picture. Both viewpoints are equally valid but, following Cho et al. <ref type="bibr" target="#b11">[12]</ref>, we focus in the rest of this presentation on the second one, and present in this section a simple heuristic for selecting one final object region among these candidates. Concretely, since using random permutations during greedy ascent provides a different solution for each run of our method, we propose to apply an ensemble method to stabilize the results and boost performance in this selection process, itself viewed as a post-processing stage separate from the optimization part.</p><p>Let us suppose that after L independent executions of the greedy ascent step, we obtain L solutions (x(l), e(l)), 1 ≤ l ≤ L. We start by combining these solutions into a single discrete pair (x,ē) wherex andē satisfy</p><formula xml:id="formula_13">•x k i = 1 if ∃ l, 1 ≤ l ≤ L such that x k i (l) = 1, •ē ij = 1 if ∃ l, 1 ≤ l ≤ L such that e ij (l) = 1.</formula><p>This way of combining the individual solutions can be seen as a max pooling procedure. We have also tried average pooling but found it less effective. Note that after this intermediate step, an image might violate any of the two constraints (2-3). This is not a problem in this postprocessing stage of our method. Indeed, we next show how to usex andē to select a single object proposal for each image.</p><p>We choose a single proposal for each image out of those retained inx (proposals (i, k) s.t.x k i = 1). To this end, we rank the proposals in image i according to a score u k i defined for each proposal (i, k) as</p><formula xml:id="formula_14">u k i =x k i j∈N (i,k) max l|x l j =1 S kl ij ,<label>(12)</label></formula><p>where N (i, k) is composed of the τ images represented by the 1s inē i which have the largest similarity to (i, k) as measured by max l|x l j =1 S kl ij . Finally, we choose the proposal in image i with maximum score u k i as the final object region. Note that the graph of images corresponding to these final object regions can be retrieved by computing e that maximizes the objective function given the value of x defined by these regions as in the greedy ascent. Also, the method above can be generalized to more than one proposal per image using the defined ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Similarity model</head><p>Let us now get back to the definition of the similarity function S ij . As advocated by Cho et al. <ref type="bibr" target="#b11">[12]</ref>, a rectangular region which is a tight fit for a compact object (the foreground) should better model this object than a larger region, since it contains less background, or than a smaller region (a part) since it contains more foreground. Cho et al. <ref type="bibr" target="#b11">[12]</ref> only implement the first constraint, in the form of a stand-out score. We discuss in this section how to implement these ideas in the optimization context of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Similarity score</head><p>Following <ref type="bibr" target="#b11">[12]</ref>, the similarity score between proposal k of image i and proposal l of image j can be defined as</p><formula xml:id="formula_15">s kl ij = a kl ij o∈O g(r k i , r l j , o) 1≤k ≤pi 1≤l ≤pj g(r k i , r l j , o)a k l ij ,<label>(13)</label></formula><p>where a kl ij is a similarity term based on appearance alone, using the WHO descriptor (whiten HOG) <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b18">19]</ref> in our case, r k i and r l j denote the image rectangles associated with the two proposals, o is a discretized offset (translation plus two scale factors) taking values in O, and g(r, s, o) measures the geometric compatibility between o and the rectangles r and s. Intuitively, s kl ij scales the appearance-only score a kl ij by a geometric-consistency term akin to a generalized Hough transform <ref type="bibr" target="#b4">[5]</ref>, see <ref type="bibr" target="#b11">[12]</ref> for details.</p><p>Note that we can rewrite Eq. (13) as</p><formula xml:id="formula_16">s kl ij = b kl ij · c ij ,<label>(14)</label></formula><p>where b kl ij is the vector of dimension |O| with entries a kl ij g(r k i , r l j , o), and c ij = p k ,l =1 b k l ij . The p i p j vectors b kl ij and the vector c ij can be precomputed with time and storage cost of O(p 2 |O|). Each term s kl ij can then be computed in O(|O|) time, and the matrix S ij can thus be computed with a total time and space complexity of O(p 2 |O|).</p><p>Note that the score s kl ij defined by Eq. (13) depends on the number of region proposals per images, which may introduce a bias for edges between images that contain many region proposals. It may thus be desirable to normalize this score by defining it instead as</p><formula xml:id="formula_17">s kl ij = 1 p i p j b kl ij · c ij .<label>(15)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Stand-out score</head><p>Let us identify the region proposals contained in some image i with their index k, and define P k i as the set of regions that are parts of that region (that is, they are included, with some tolerance, within k). Let us also define B k i as the set of regions that form the background for k (that is, k is included, with some tolerance, within these regions). Let r k i denote the actual rectangular image region associated with proposal k in image i, and let A(r) denote the area of some rectangle r. A plausible definition for P k i is</p><formula xml:id="formula_18">P k i = {l : A(r k i ∩ r l i ) &gt; ρA(r l i )},<label>(16)</label></formula><p>for some reasonable value of ρ, e.g., 0.5. Likewise, a plausible definition for B k i is</p><formula xml:id="formula_19">B k i = {l : A(r k i ∩ r l i ) &gt; δA(r k i ) and A(r l i ) &gt; γA(r k i )},<label>(17)</label></formula><p>for reasonable values of δ and γ, e.g., 0.8 and 2. Following <ref type="bibr" target="#b11">[12]</ref>, we define the stand-out score of a match (k, l) as</p><formula xml:id="formula_20">S kl ij = s kl ij − v kl ij , where v kl ij = max (k ,l )∈B k i ×B l j s k l ij .<label>(18)</label></formula><p>With this definition, S kl ij may be negative. In our implementation, we threshold these scores so they are nonnegative.</p><p>When B k i and B l j are large, which is generally the case when the regions r k i and r l j are small, a brute-force computation of v kl ij may be very slow. We propose below instead a simple heuristic that greatly speeds up calculations.</p><p>Let Q ij denote the set formed by the q matches (k, l) with highest scores s kl ij , sorted in increasing order, which can be computed in O(p 2 log p). The stand-out scores can be computed efficiently by the following procedure:</p><formula xml:id="formula_21">Initialize all v kl ij to 0. For each match (k , l ) in Q ij do</formula><p>For each match (k, l) in P k i × P l j do v kl ij = s k l ij . For k = 1 to p i and l = 1 to p j do If s kl ij &gt; 0 and v kl ij = 0 then v kl ij = max</p><formula xml:id="formula_22">(k ,l )∈B k i ×B l j s k l ij .</formula><p>The idea is that relatively few high-confidence matches (k , l ) in Q ij can be used to efficiently compute many stand-out scores. There is a trade-off between the cost of this step, O( (k ,l )∈Qij |P k i | |P l j |), and the number of variables v kl ij it assigns a value to, O(| ∪ (k ,l )∈Qij P k i × P l j |). In practice, we have found that taking q = 10, 000 is a good compromise, with only about 5% of the stand-out scores being computed in a brute-force manner, and a significant speed-up factor of over 10.  For evaluation, we use the standard CorLoc measure, the percentage of images correctly localized. It is a proxy metric in the case of unsupervised discovery. An image is "correctly localized" when the intersection over union (IoU ) between one of the ground-truth regions and the predicted one is greater than 0.5. Following <ref type="bibr" target="#b11">[12]</ref>, we evaluate our algorithm in "separate" and "mixed" settings. In the former case, the class-wise performance is averaged over classes. In the latter, a single performance is computed over all classes jointly. In our experiments, we use ν = 5, τ = 10 and standout matrices with 1000 non-zero entries unless mentioned otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and results</head><p>Separate setting. We firstly evaluate different settings of our algorithm on the two smaller datasets, OD and VOC 6x2. The performance is governed by three design choices: (1) using the normalized stand-out score (NS) or its unnormalized version, (2) using continuous optimization (CO) or variables x and e with all entries equal to one to initialize the greedy ascent procedure, and (3) using the ensemble method (EM) or not. In total, we thus have eight configurations to test.</p><p>The results are shown in <ref type="table" target="#tab_1">Table 1</ref>. We have found a small bug in the publicly available code of Cho et al. <ref type="bibr" target="#b11">[12]</ref>, and report both the results from <ref type="bibr" target="#b11">[12]</ref> and those we obtained after correction. We observe that the normalized standout score always gives comparable or better results than its unnormalized counterpart, while the ensemble method also improves both the score and the stability (lower variance) of our solution. Combining the normalized standout score, the ensemble method, and the continuous optimization initialization to greedy ascent yields the best performance. Our best results outperform <ref type="bibr" target="#b11">[12]</ref> by small but statistically significant margins: 1.6% for OD and 1.8% for VOC 6x2. Finally, to assess the merit of the continuous optimization, we have  measured its duality gap on OD and VOC 6x2: it ranges from 1.5% to 8.7% of the energy, with an average of 5.2% and 3.9% on the two datasets respectively. We now evaluate our algorithm on VOC all. As the complexity of solving the max flow problem grows very fast with the number of images, for configurations with continuous optimization, we reduce the number of non-zero entries in each standout matrix such that the total number of nodes in the graph is around 2 × 10 7 . These standout matrices are then used in rounding the continuous solution, but in the greedy ascent procedure we switch to standout matrices with 1000 non-zero entries. For configurations without the continuous optimization, we always use the standout matrices with 1000 non-zero entries. Also, to reduce the memory footprint of our method, we prefilter the set of potential neighbors of each image for the class person that contains 1023 pictures. Pre-filtering is done by marking 100 nearest neighbors of each image in terms of Euclidean distance between GIST <ref type="bibr" target="#b45">[46]</ref> descriptors as potential neighbors. In the separate setting, we only apply the pre-filtering on the class person which has 1023 images. The other classes are sufficiently small for not resorting to the prefiltering procedure. <ref type="table" target="#tab_3">Table 2</ref> shows the CorLoc values obtained by our method with different configurations compared to Cho et al. It can be seen that the ensemble postprocessing and the continuous optimization are also helpful on this dataset. We obtain the best result with the configuration that includes both of them, which is 1.6% better than Cho et al. However, our performance is still inferior to state of the art in image colocalization <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b48">49]</ref> which employ deep features from convolutional neural networks trained for image classification and explicitly exploits the single-class assumption.</p><p>Mixed setting. We now compare in <ref type="table" target="#tab_5">Table 3</ref> the performance of our algorithm to Cho et al. in the mixed setting (none of the other methods is applicable to this case). It can be seen that our algorithm without the continuous optimization has the best performance among those in consideration. Compared to Cho et al., it gives a CorLoc 0.8% better on OD dataset, 4.3% better on VOC 6x2 and 2.3% better on VOC all. The decrease in performance of our method when using the continuous optimization is likely due to the fact that we use standout matrices with only 200 non-zero entries on OD, 100 non-zero entries on VOC 6x2 and 100   non-zero entries on VOC all (due to the limit on the number of nodes of the bipartite graphs) in the configuration with the continuous optimization while we use standout matrices with 1000 non-zero entries in the configuration without the continuous optimization.</p><p>Sensitivity to ν. We compare the performance of our method when using different values of ν on the VOC 6x2 dataset. <ref type="bibr" target="#b2">3</ref>  <ref type="table" target="#tab_6">Table 4</ref> shows the CorLoc obtained by different configurations of our algorithm, all with normalized standout. The performance consistently increases with the value of ν on this dataset. In all other experiments however, we set ν = 5 to ease comparisons to <ref type="bibr" target="#b11">[12]</ref>.</p><p>Using deep features. Since activations from deep neural networks trained for image classification (deep features) are known to be better image representations than handcrafted features in various tasks, we have also experimented with such descriptors. We have replaced WHO <ref type="bibr" target="#b18">[19]</ref> by activations from different layers in VGG16 <ref type="bibr" target="#b41">[42]</ref>, when computing the appearance similarity between regions. In this case, the similarity between two regions is simply the scalar product of the corresponding deep features (normalized or not). As a preliminary experiment to evaluate the effectiveness of deep features, we have run our algorithm without the continuous optimization with the standout score computed using layers conv4 3, conv5 3 and fc6 in VGG16. <ref type="table" target="#tab_8">Table 5</ref> shows the results of these experiments. Surprisingly, most of the deep features tested give worse results than WHO. This may be due to the fact that our matching task is more akin to image retrieval than classification, for which deep features are typically trained. Among those tested, only a variant of the features extracted from the layer conv5 3 of VGG16 gives an improvement (about 2%) compared to the result obtained <ref type="bibr" target="#b2">3</ref> Note that we have also tried the interpretation of ν as the maximum number of objects per image, without satisfying results so far. by using WHO.  Unsupervised initial proposals. It should be noted that, although our algorithm like that of Cho et al. <ref type="bibr" target="#b11">[12]</ref> is totally unsupervised once given the region proposals, the randomized Prim's algorithm itself is supervised <ref type="bibr" target="#b32">[33]</ref>. To study the effect of this built-in supervision, we have also tested the unsupervised selective search algorithm <ref type="bibr" target="#b46">[47]</ref> for choosing region proposals. We have conducted experiments on VOC 6x2 dataset with the three different settings of selective search (fast, medium and quality). As one might expect, the fast mode gives the smallest number of proposals and of positive ones (proposals whose IoU with one ground truth box is greater than 0.5); the quality mode outputs the largest set of proposals and of positive ones, the medium mode lies in-between. To compare with <ref type="bibr" target="#b11">[12]</ref>, we also run their public software with each mode of selective search.  The results are shown in <ref type="table" target="#tab_10">Table 6</ref>. It can be seen that the performance of both Cho et al.'s method and ours drop significantly when using selective search. This may be due to the fact that the percentage of positive proposals found by selective search is much smaller than that of RP. However, we see that with the quality mode of selective search, our method gives results quite close to those of RP, whereas the method in <ref type="bibr" target="#b11">[12]</ref> fails badly. This suggests that our method is more robust.</p><p>Visualization. In order to gain insight into the structures discovered by our approach, we derive from its output a graph of image regions and visualize its main connected components. The nodes of this graph are the image regions that have been finally retained. Two regions (i, k) and (j, l) are connected if the images containing them are neighbors in the discovered undirected image graph (e ij or e ji = 1) and the standout score between them, S kl ij , is greater than a certain threshold.</p><p>Choosing the threshold to get a sufficient number of large enough components for visualization purpose has proven difficult. We used instead an iterative procedure: the graph is first constructed with a high threshold to produce a small number of connected components of reasonable size, which are removed from the graph. On the remaining graph, a new, suitable threshold is found to get new components of sufficient size. This is repeated until a target number of components is reached.</p><p>When applied to our results in the mixed setting on VOC 6x2 dataset, this visualization procedure yields clusters that roughly match object categories. In <ref type="figure">Figure 1</ref>, we show sub-sampled graphs (for visualization purpose) of the two first components, which roughly correspond to classes bicycle and aeroplane. The third component is shown in <ref type="figure" target="#fig_0">Figure 2</ref>. Although containing also images of other classes, it is by far dominated by motorbike images. The visualization suggests that our model does extract meaningful semantic structures from the image collections and regions they contain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We have presented an optimization-based approach to fully unsupervised image matching and object discovery and demonstrated its promise on several standard benchmarks. In its current form, our algorithm is limited to relatively small datasets. We are exploring several paths for scaling up its performance, including better mechanisms based on deep features and the PHM algorithm for prefiltering image neighbors and selecting regions proposals. Future work will also be dedicated to developing effective ensemble methods for discovering multiple objects in images, further investigating a symmetric version of the proposed approach using an undirected graph, understanding why deep features do not give better results in our context, and improving our continuous optimization approach so as to handle large datasets in a mixed setting, perhaps through some form of variable clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Maximization of supermodular cubic pseudo-Boolean functions</head><p>An immediate corollary of [7, Lemma 1] is that a cubic pseudo-Boolean function with nonegative trinary coefficients and no binary terms is supermodular. For fixed λ and µ, this is obviously the case for the Lagrangian K in <ref type="bibr" target="#b4">(5)</ref>.</p><p>In addition, the unary terms in K are nonpositive, and the Langragian can thus be rewritten, up to some constant additive term, in the form</p><formula xml:id="formula_23">f (x 1 , . . . , x n ) = i∈U c ixi + (i,j,k)∈T c ijk x i x j x k ,<label>(19)</label></formula><p>wherex i = 1−x i (the complement of x i ), U ⊂ {1, . . . , n}, T ⊂ {1, . . . , n} 2 , and all coefficients c i and c ijk are positive. We specialize in the rest of this section the general maximization method of <ref type="bibr" target="#b6">[7]</ref> to functions of this form.</p><p>The conflict graph <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b9">10</ref>] G(f ) associated with such a function f has as a set of nodes X(f ) = V ∪ W , where the elements of V correspond to linear terms, those of W correspond to cubic terms, and an edge links to nodes when one of the corresponding terms contains a variable, and the other one its complement. By construction G(f ) is a bipartite graph, with edges joining only elements of V to elements of W .</p><p>As shown in <ref type="bibr" target="#b6">[7]</ref> maximizing f amounts to finding a maximum weight stable set in G(f ), where the nodes of V are assigned weights c i and the nodes of W are assigned weights c ijk , which in turn reduces to computing a maximum flow between nodes s and t in the network deducted from G(f ) by (1) adding a source node and edges with upper capacity bound c i between s and the corresponding elements of V ; (2) adding a sink node t and edges with upper capacity bound c ijk between the corresponding elements of W and t; (3) assigning to all edges (from V to W ) in G(f ) an upper capacity bound of +∞.</p><p>Let [A,Ā] denote the minimum cut obtained by computing the maximum flow in this graph, where s is an element of A and t is an element ofĀ = X(f ) \ A. The maximum weight stable set is then S = (A ∩ V ) ∪ (Ā ∩ W ). The monomialsx i and x i x j x k associated with elements of S are set to 1, from which the values of all variables are easily deduced.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Visualization of VOC 6x2 in the mixed setting. The figure shows the third component in the graph of regions, corresponding roughly to class motorbike. The two first components are shown in Fig.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Datasets, proposals and metric. For our experiments we use the same datasets (ObjectDiscovery [OD], VOC 6x2 and VOC all) and region proposals (obtained by the randomized Prim's algorithm [RP]<ref type="bibr" target="#b32">[33]</ref>) as Cho et al.<ref type="bibr" target="#b11">[12]</ref>. OD consists of pictures of three object classes (airplane, horse and car) with outliers not containing any object instance. There are 100 images per category, with 18, 7 and 11 outliers respectively (containing no object instance). VOC all</figDesc><table><row><cell></cell><cell>Method</cell><cell></cell><cell>OD</cell><cell>VOC 6x2</cell></row><row><cell></cell><cell>Cho et al.</cell><cell></cell><cell>84.2</cell><cell>67.7</cell></row><row><cell cols="3">Cho et al., our version</cell><cell>84.2</cell><cell>67.6</cell></row><row><cell>w/o EM</cell><cell>w/o CO w CO</cell><cell cols="2">w/o NS 81.9 ± 0.9 65.9 ± 1.0 w NS 83.1 ± 0.8 67.2 ± 1.0 w/o NS 82.9 ± 0.8 66.6 ± 0.7 w NS 84.4 ± 0.8 68.1 ± 0.9</cell></row><row><cell>w EM</cell><cell>w/o CO w CO</cell><cell cols="2">w/o NS 84.4 ± 0.0 68.8 ± 0.4 w NS 85.6 ± 0.3 68.7 ± 0.5 w/o NS 83.8 ± 0.2 67.4 ± 0.4 w NS 85.8 ± 0.6 69.4 ± 0.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Performance of different configurations of our algorithm compared to the results of Cho et al. on Object Discovery and VOC 6x2 datasets in the separate setting.is a subset of the PASCAL VOC2007 train+val dataset obtained by eliminating all images containing only objects marked as difficult or truncated. Finally, VOC 6x2 is a subset of VOC all containing only images of 6 classes -aeroplane, bicycle, boat, bus, horse -and motorbike from two different views, left and right.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performance on VOC all in separate setting with different configurations.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>± 0.4 60.2 ± 0.4 39.8 ± 0.2 w CO 80.8 ± 0.5 59.3 ± 0.4 38.5 ± 0.2</figDesc><table><row><cell>Method</cell><cell>OD</cell><cell>VOC 6x2</cell><cell>VOC all</cell></row><row><cell>Cho et al.</cell><cell>-</cell><cell>-</cell><cell>37.6</cell></row><row><cell>Cho et al., our execution</cell><cell>82.2</cell><cell>55.9</cell><cell>37.5</cell></row><row><cell>w/o CO</cell><cell>83.0</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc>Performance on the datasets in mixed setting.</figDesc><table><row><cell></cell><cell>Method</cell><cell>VOC 6x2</cell></row><row><cell>ν = 1</cell><cell>w/o CO w CO</cell><cell>w/o EM 63.5 ± 1.2 w EM 67.7 ± 0.8 w/o EM 65.8 ± 0.8 w EM 68.1 ± 0.7</cell></row><row><cell>ν = 5</cell><cell>w/o CO w CO</cell><cell>w/o EM 67.2 ± 1.0 w EM 68.7 ± 0.5 w/o EM 68.1 ± 0.9 w EM 69.4 ± 0.3</cell></row><row><cell>ν = 10</cell><cell>w/o CO w CO</cell><cell>w/o EM 68.6 ± 1.0 w EM 69.1 ± 0.3 w/o EM 68.9 ± 0.7 w EM 70.0 ± 0.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Performance of different configurations of our algorithm with ν = 1, ν = 5 and ν = 10.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Performance of our algorithm with deep features on VOC 6x2 in the separate setting.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Object discovery on VOC 6x2 with selective search and randomized Prim's as region proposal algorithms.</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This work was supported in part by the Inria/NYU collaboration agreement, the Louis Vuitton/ENS chair on artificial intellgence and the EPSRC Programme Grant Seebibyte EP/M013774/1. We also thank Simon Lacoste-Julien for his valuable comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to see by moving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning from narrated instruction videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lacoste-Julien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. and Machine Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2194" to="2208" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Learning with submodular functions: A convex optimization perspective. Foundations and Trends in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="145" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">DIFFRAC : a discriminative and flexible framework for clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Info. Proc. Systems</title>
		<meeting>Neural Info. . Systems</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Generalizing the Hough transform to detect arbitrary shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Regularization and semi-supervised learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Matveeva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Niyogi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLT</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Maximizing a supermodular pseudoboolean function: A polynomial algorithm for supermodular cubic functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Billionnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minoux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unsupervised learning by predicting noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Weaklysupervised alignment of video with text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lajugie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Pseudo-Boolean optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="155" to="225" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Histograms of oriented gradients for human detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Localizing objects while learning their appearance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Alexe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ferrari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Unsupervised visual representation learning by context prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Clustering by compositionunsupervised discovery of image categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Faktor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Object detection with discriminatively trained part-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. and Machine Intell</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Discriminative decorrelation for clustering and classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mask R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep clustering: Discriminative embeddings for segmentation and separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Hershey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Discriminative clustering for image co-segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient image and video co-localization with Frank-Wolfe algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Distributed cosegmentation via submodular optimization on anisotropic diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Neural Info. Proc. Systems</title>
		<meeting>Neural Info. . Systems</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised object discovery and tracking in video collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Beyond bags of features: spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Object-graphs for contextaware category discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Image colocalization by mimicking a good detector&apos;s confidence score distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hengel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Least squares quantization in PCM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on information theory</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="137" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Prime object proposals with randomized Prim&apos;s algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Manen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep multiscale video prediction beyond mean square error</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matthieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Approximate primal solutions and rate analysis for dual subgradient methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nedić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ozdaglar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="page">2106</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unsupervised Joint Object Discovery and Segmentation in Internet Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">ImageNet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Using multiple segmentations to discover objects and their extent in image collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Unsupervised discovery of visual object class hierarchies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Lagrange multipliers revisited. Cowles Commission Discussion Paper No</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Slater</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Co-localization in real-world images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Small codes and large image databases for recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Selective search for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R R</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E A</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>IJCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations using videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep descriptor transforming for image colocalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
