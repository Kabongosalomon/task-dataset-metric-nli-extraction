<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large Scale Image Segmentation with Structured Loss based Deep Learning for Connectome Reconstruction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Funke</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabian</forename><forename type="middle">David</forename><surname>Tschopp</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Grisaitis</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arlo</forename><surname>Sheridan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandan</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Saalfeld</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinivas</forename><forename type="middle">C</forename><surname>Turaga</surname></persName>
						</author>
						<title level="a" type="main">Large Scale Image Segmentation with Structured Loss based Deep Learning for Connectome Reconstruction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a method combining affinity prediction with region agglomeration, which improves significantly upon the state of the art of neuron segmentation from electron microscopy (EM) in accuracy and scalability. Our method consists of a 3D U-NET, trained to predict affinities between voxels, followed by iterative region agglomeration. We train using a structured loss based on MALIS, encouraging topologically correct segmentations obtained from affinity thresholding. Our extension consists of two parts: First, we present a quasi-linear method to compute the loss gradient, improving over the original quadratic algorithm. Second, we compute the gradient in two separate passes to avoid spurious gradient contributions in early training stages. Our predictions are accurate enough that simple learning-free percentilebased agglomeration outperforms more involved methods used earlier on inferior predictions. We present results on three diverse EM datasets, achieving relative improvements over previous results of 27%, 15%, and 250%. Our findings suggest that a single method can be applied to both nearly isotropic block-face EM data and anisotropic serial sectioned EM data. The runtime of our method scales linearly with the size of the volume and achieves a throughput of ∼ 2.6 seconds per megavoxel, qualifying our method for the processing of very large datasets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Precise reconstruction of neural connectivity is of great importance to understand the function of biological nervous systems. 3D electron microscopy (EM) is the only available imaging method with the resolution necessary to visualize and reconstruct dense neural morphology without ambiguity. At this resolution, however, even moderately small neural circuits yield image volumes that are too large for manual reconstruction. Therefore, automated methods for neuron tracing are needed to aid human analysis.</p><p>We present a method combining a structured loss for deep learning based instance separation with subsequent region agglomeration for neuron segmentation in 3D electron microscopy, which improves significantly upon state of the art in terms of accuracy and scalability. For an overview, see <ref type="figure" target="#fig_1">Fig. 1</ref>, top row. The main components of our method are: (1) Prediction of 3D affinity graphs using a 3D U-NET architecture <ref type="bibr" target="#b0">[1]</ref>, (2) a structured loss based on MALIS <ref type="bibr" target="#b1">[2]</ref> to train the U-NET to minimize topological errors, and (3) an these authors contributed equally efficient O(n) agglomeration scheme based on quantiles of predicted affinities.</p><p>The choice of using a 3D U-NET architecture to predict voxel affinities is motivated by two considerations: First, U-NETs have already shown superior performance on the segmentation of 2D <ref type="bibr" target="#b2">[3]</ref> and 3D <ref type="bibr" target="#b0">[1]</ref> biomedical image data. One of their favourable properties is the multi-scale architecture which enables computational and statistical efficiency. Second, U-NETs efficiently predict large regions. This is of particular interest in combination with training on the MALIS structured loss, for which we need affinity predictions in a region.</p><p>We train our 3D U-NET to predict affinities using an extension of the MALIS loss function <ref type="bibr" target="#b1">[2]</ref>. Like the original MALIS loss, we minimize a topological error on hypothetical thresholding and connected component analysis on the predicted affinities. We extended the original formulation to derive the gradient with respect to all predicted affinities (as opposed to sparsely sampling them), leading to denser and faster gradient computation. Furthermore, we compute the MALIS loss in two passes: In the positive pass, we constrain all predicted affinities between and outside of ground-truth regions to be 0, and in the negative pass, we constrain affinities inside regions to be 1 which avoids spurious gradients in early training stages.</p><p>Although the training is performed assuming subsequent thresholding, we found iterative agglomeration of fragments (or "supervoxels") to be more robust to small errors in the affinity predictions. To this end, we extract fragments running a watershed algorithm on the predicted affinities. The fragments are then represented in a region adjacency graph (RAG), where edges are scored to reflect the predicted affinities between adjacent fragments: edges with small scores will be merged before edges with high scores. We discretize edge scores into k evenly distributed bins, which allows us to use a bucket priority queue for sorting. This way, the agglomeration can be carried out with a worst-case linear runtime.</p><p>The resulting method (prediction of affinities, watershed, and agglomeration) scales favourably with O(n) in the size n of the volume, a crucial property for neuron segmentation from EM volumes, where volumes easily reach several  . Using a 3D U-NET (a), trained with the proposed constrained MALIS loss, we directly predict inter-voxel affinities from volumes of raw data. Affinities provide advantages especially in the case of low-resolution data (b). In the example shown here, the voxels cannot be labeled correctly as foreground/background: If A were labeled as foreground, it would necessarily merge with the regions in the previous and next section. If it were labeled as background, it would introduce a split. The labeling of affinities on edges allows B and C to separate A from adjacent sections, while maintaining connectivity inside the region. From the predicted affinities, we obtain an over-segmentation that is then merged into the final segmentation using a percentile-based agglomeration algorithm (c).</p><p>hundreds of terabytes. This is a major advantage over current state-of-the-art methods that all follow a similar pattern. First, voxel-wise predictions are made using a deep neural network. Subsequently, fragments are obtained from these predictions which are then merged using either greedy (CELIS <ref type="bibr" target="#b3">[4]</ref>, GALA <ref type="bibr" target="#b4">[5]</ref>) or globally optimal objectives (MULTICUT <ref type="bibr" target="#b5">[6]</ref> and lifted MULTICUT <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>). All these methods depend heavily on the quality of the initial fragments, which in turn depend on the quality of the boundary prediction. Despite this strong coupling, the boundary classifier is mostly trained unaware of the algorithm used to subsequently extract fragments. A noteworthy exception is a recent work <ref type="bibr" target="#b8">[9]</ref> where a boundary classifier is trained using a structured loss to fill objects with seeded watershed regions. This work demonstrates the usefulness of structured boundary prediction, similar in spirit to the method described here. Nevertheless, the majority of current efforts focuses on the merging of fragments: Both CELIS and GALA train a classifier to predict scores for hierarchical agglomeration which increases the computational complexity of agglomeration during inference. Similarly, the MULTICUT variants train a classifier to predict the connectivity of fragments that are then clustered by solving a computationally expensive combinatorial optimization problem. Our proposed fragment agglomeration method drastically reduces the computation complexity compared to previous merge methods and does not require a separate training step.</p><p>We demonstrate the efficacy of our method on three diverse datasets of EM volumes, imaged by three different 3D electron microscopy techniques: CREMI (ssTEM, Drosophila), FIB-25 (FIBSEM, Drosophila), and SEGEM (SBEM, mouse cortex). Our method significantly improves over the current state of the art in each of these datasets, outperforming in particular computationally more expensive methods without favorable worst-case runtime guarantees.</p><p>We made the source code for training 1 and agglomeration 2 publicly available, together with usage example scripts to reproduce our CREMI results 3 .</p><p>1. https://github.com/naibaf7/caffe 2. https://github.com/funkey/waterz 3. http://cremi.org/static/data/20170312 mala v2.tar.gz</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Deep multi-scale convolutional network for predicting 3D voxel affinities</head><p>We use a 3D U-NET architecture <ref type="bibr" target="#b0">[1]</ref> to predict voxel affinities on 3D volumes. We use the same architecture for all investigated datasets which we illustrate in <ref type="figure" target="#fig_1">Fig. 1a</ref>. In particular, our 3D U-NET consists of four levels of different resolutions. In each level, we perform at least one convolution pass (shown as blue arrows in <ref type="figure" target="#fig_1">Fig. 1a</ref>) consisting of two convolutions (kernel size 3×3×3) followed by rectified linear units. Between the levels, we perform max pooling on variable kernel sizes depending on the dataset resolution for the downsampling pass (yellow arrows), as well as transposed convolution of the same size for upsampling (brown arrows). The results of the upsampling pass are further concatenated with copies of the feature maps of the same level in the downsampling pass (red arrows), cropped to account for context loss in the lower levels. Details of the individual passes are shown in <ref type="figure">Fig. 6</ref>. A more detailed description of the U-NET architectures for each of the investigated datasets can be found in <ref type="figure">Fig. 5</ref>.</p><p>We chose to predict voxel affinities on edges between voxels instead of labeling voxels as foreground/background to allow our method to handle low spatial resolutions. As we illustrate in <ref type="figure" target="#fig_1">Fig. 1b</ref>, a low z resolution (common for serial section EM) renders a foreground/background labeling of voxels impossible. Affinities, on the other hand, effectively increase the expressiveness of our model and allow to obtain a correct segmentation. Furthermore, affinities easily generalize to arbitrary neighborhoods and might thus allow the prediction of longer range connectivity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training using constrained MALIS</head><p>We train our network using an extension of the MALIS loss <ref type="bibr" target="#b1">[2]</ref>. This loss, that we term constrained MALIS, is designed to minimize topological errors in a segmentation obtained by thresholding and connected component analysis. Although thresholding alone will unlikely produce accurate results, it serves as a valuable proxy for training: If the loss can be minimized for thresholding, it will in particular be minimized for agglomeration. To this end, in each training iteration, a complete affinity prediction of a 3D region is considered. Between every pair of voxels, we determine the maximin affinity edge, i.e., the highest minimal edge over all paths connecting the pair. This edge is crucial as it determines the threshold under which the two voxels in question will be merged. Naturally, for voxels that are supposed to belong to the same region, we want the maximin edge affinity to be as high as possible, and for voxels of different regions as low as possible.</p><p>Our extension consists of two parts: First, we improve the computational complexity of the MALIS loss by presenting an O(n log(n) + kn) method for the computation of the gradient, where n is the size of the volume and k the number of ground-truth objects. We thus improve over the previous method that had a complexity of O(n 2 ). Second, we compute the gradient in two separate passes, once for affinities inside ground-truth objects (positive pass), and once for affinities between and outside of ground-truth objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">The MALIS loss</head><p>Let G = (V, E, a) be an affinity graph on voxels V with edges E ⊆ V 2 and affinities a : E → [0, 1]. A maximin edge between two voxels u and v is an edge mm(u, v) ∈ E with lowest affinity on the overall highest affinity path P * u,v connecting u and v, i.e.,</p><formula xml:id="formula_0">P * u,v = arg max P ∈ P u, v min e∈P a(e) mm(u, v) = arg min e∈P * u, v a(e),<label>(1)</label></formula><p>where P u,v denotes the set of all paths between u and v. If we imagine a simple thresholding on the affinity graph, such that edges with affinities below a threshold θ are removed from G, then the affinity of the maximin edge mm(u, v) is equal to the highest threshold under which nodes u and v would still be part of the same connected component. Acknowledging the importance of maximin edges, the MALIS loss favors high maximin affinities between voxels that belong to the same ground-truth segment, and low maximin affinities between voxels that belong to different groundtruth segments. We assume that a ground-truth segmentation is given as a labelling s : V → {0, ..., k} such that each segment has a unique label in {1, ..., k} and background is</p><formula xml:id="formula_1">marked with 0. Let F ⊆ V denote all foreground voxels F = {v ∈ V | s(v)</formula><p>0} and δ(u, v) indicate whether u and v belong to the same ground-truth segment:</p><formula xml:id="formula_2">δ(u, v) = 1 if u, v ∈ F and s(u) = s(v), 0 otherwise.<label>(2)</label></formula><p>The MALIS loss L(s, a) is the sum of affinity losses over the maximin edges of every pair of voxels that do not belong to the background:</p><formula xml:id="formula_3">L(s, a) = u,v ∈F l (δ(u, v), a(mm(u, v))) .<label>(3)</label></formula><p>The affinity loss can be any continuous and differentiable function, we chose l(x, y) = (x − y) 2 for all experiments in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Quasilinear loss computation</head><p>Considering that we have O(n 2 ), n = |V |, pairs of voxels, but-in the case of grid graphs considered here-only O(n) edges, it follows that maximin edges are shared between voxel pairs. This observation generalizes to arbitrary graphs. In particular, the union of all maximin edges forms a maximal spanning tree (MST),</p><formula xml:id="formula_4">mm(u, v) | (u, v) ∈ V 2 = MST(G),<label>(4)</label></formula><p>i.e., there are always only n − 1 maximin edges in a graph. That the previous equality holds can easily be proven by contradiction: Assume that for a pair (u, v), mm(u, v) MST(G). Let P + u,v ⊆ MST(G) denote the path connecting u and v on the MST, and let mtp(u, v) denote the edge with minimal affinity on P + u,v :</p><formula xml:id="formula_5">mtp(u, v) = arg min e∈P + u, v a(e).<label>(5)</label></formula><p>Following our assumption, P + u,v does not contain mm(u, v). By definition (1), the following inequalities hold:   Given predicted affinities (blue low, red high) and a ground-truth segmentation (a), losses on maximin edges are computed in two passes: In the positive pass, (b), affinities of edges between ground-truth regions are set to zero (blue), in the negative pass (c), affinities within ground-truth regions are set to one (red). In either case, a maximal spanning tree (shown as shadow) is constructed to identify maximin edges. Note that, in this example, edge A is not a maximin edge in the positive pass since the incident voxels are already connected by a high affinity path. In contrast, edge B is the maximin edge of the bottom left voxel to any other voxel in the same region and thus contributes to the loss. Similarly, C is the maximin edge connecting voxels of different ground-truth regions and contributes during the negative pass to the loss. The resulting gradients of the loss with respect to each edge affinity is shown in (d) (positive values in red, negative in blue).</p><formula xml:id="formula_6">a(mtp(u, v)) ≤ a(mm(u, v)) ≤ a(e) ∀e ∈ P * u,v .<label>(6)</label></formula><p>We can now remove mtp(u, v) from the MST to obtain two disconnected sub-trees separating u from v. Since P * u,v connects u and v, there exists an edge e * ∈ P * u,v that will reconnect the two sub-trees. However, a(mtp(u, v)) ≤ a(e * ). If strict inequality holds, this will create a tree with a larger sum of affinities than the MST, thus contradicting our assumptions. If equality holds and a(mtp(u, v)) = a(mm(u, v)) = a(e * ), then there are more than one possible MSTs and hence mm(u, v) is contained in one of them.</p><p>Consequently, we are able to identify the maximin edge and compute its loss for each voxel pair by growing an MST on G. We use Kruskal's algorithm <ref type="bibr" target="#b9">[10]</ref> to grow an MST, which consists of two steps: First, we sort all edges by affinity in descending order. Second, we iterate over all edges and grow the MST using a union-find data structure. Whenever a new edge e merges two trees T 1 , T 2 ⊂ MST(G) during construction of the MST, we compute the positive and negative weight of this edge on the fly. The positive weight w P (e) corresponds to the number of voxel pairs of the same ground-truth segment merged by e:</p><formula xml:id="formula_7">w P (e) = |{(u, v) ∈ F 2 | δ(u, v) = 1, e = mm(u, v)}|.<label>(7)</label></formula><p>By construction, e is the maximin edge to all pairs of voxels between the two trees it merges. Therefore, w P (e) equals the product of the number of voxels having label i in either tree, summed over all i ∈ {1, . . . , k}. Let V T denote the set of voxels in T and V i T ⊆ V T the subset with ground-truth label i. The positive weight can then be rewritten as:</p><formula xml:id="formula_8">w P (e) = i ∈ {1,...,k } V i T 1 V i T 2 .<label>(8)</label></formula><p>Equivalently, the negative weight w N (e) is the number of voxel pairs of different ground-truth segments merged by e:</p><formula xml:id="formula_9">w N (e) = |{(u, v) ∈ F 2 | δ(u, v) = 0, e = mm(u, v)}| (9) = i j ∈ {1,...,k } V i T 1 V j T 2 (10) = V T 1 V T 2 − i ∈ {1,...,k } V i T 1 V i T 2 .<label>(11)</label></formula><p>We can now rewrite the MALIS loss <ref type="formula">(</ref> </p><p>and avoid the costly sum over all pairs of voxels. We keep track of the sizes of sets V T and V i T used in each tree during the construction of the MST. Consequently, the complexity of our algorithm is dominated by first sorting all edges by their affinity in O(n log(n)) and subsequently evaluating equations <ref type="bibr" target="#b7">(8)</ref> and <ref type="formula" target="#formula_0">(11)</ref> while constructing the MST in O(kn), resulting in a final complexity of O(n log(n) + kn). We thus improve over a previous method <ref type="bibr" target="#b1">[2]</ref> that required O(n 2 ) and therefore had to fall back to sparse sampling of voxel pairs. Note that this only affects the training of the network, the affinity prediction during test time scales linearly with the volume size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Constrained MALIS</head><p>We further extend previous work by computing the maximin edge losses in two passes: In the first pass we compute only the weights w P for edges within the same region (positive pass). In the second pass, we compute the weights w N for edges between different regions (negative pass). As shown in <ref type="figure" target="#fig_4">Fig. 2</ref>, in the positive pass, we assume that all edges between regions have been predicted correctly and set their affinities to zero. Consequently, only maximin edges inside a region are found and contribute to the loss. This obviates an inefficiency in a previous formulation <ref type="bibr" target="#b1">[2]</ref>, where a spurious high-affinity (i.e., false positive) path leaving and entering a region might connect two voxels inside averaged affinities threshold at 0.5 distance transform seeded watershed the same region. In this case, the maximin edge could lie outside of the considered region, resulting in an unwanted gradient contribution that would reinforce the false positive. Analogously, in the negative pass, all affinities inside the same region are set to one to avoid reinforcement of false negatives inside regions. Finally, the gradient contributions of both passes are added together. Note that, similar to the original MALIS formulation <ref type="bibr" target="#b1">[2]</ref>, the constrained version presented here does not require precise location of the boundaries. In applications where the exact location of the boundary is less relevant, a broader background region around boundaries can be given. During the negative pass, any correctly predicted cut through this background region will result in a loss of zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Hierarchical agglomeration</head><p>Our method for hierarchical agglomeration of segments from the predicted affinities consists of two steps. First, we use a heuristic to extract small fragments directly from the predicted affinities. Second, we iteratively score and merge adjacent fragments into larger objects until a predefined threshold is reached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Fragment extraction</head><p>The extraction of fragments is a crucial step for the subsequent agglomeration. Too many fragments slow down the agglomeration unnecessarily and increase its memory footprint. Too few fragments, on the other hand, are subject to undersegmentation that cannot be corrected.</p><p>Empirically, we found a seeded watershed to deliver the best trade-off between fragment size and segmentation accuracy across all investigated datasets. For the seeded watershed, we first average the predicted affinities for each voxel to obtain a volume of boundary predictions. We subsequently threshold the boundary predictions at 0.5 and perform a distance transform on the resulting mask. Every local maximum is taken as a seed, from which we grow basins Only in this case the score needs to be updated.</p><p>using a standard watershed algorithm <ref type="bibr" target="#b10">[11]</ref> on the boundary predictions. For an example, see <ref type="figure" target="#fig_6">Fig. 3</ref>. As argued above, voxel-wise predictions are not fit for anisotropic volumes with low z-resolution (see <ref type="figure" target="#fig_1">Fig. 1b</ref>). To not re-introduce a flaw that we aimed to avoid by predicting affinities instead of voxel-wise labels in the first place, we perform the extraction of fragments xy-section-wise for anisotropic volumes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Fragment agglomeration</head><p>For the agglomeration, we consider the region adjacency graph (RAG) of the extracted fragments. The RAG is an annotated graph G = (V, E, f ), with V the set of fragments, E ⊆ V × V edges between adjacent fragments, and f : E → R an edge scoring function. The edge scoring function is designed to prioritize merge operations in the RAG, i.e., the contraction of two adjacent nodes into one, such that edges with lower scores are merged earlier. Given an annotated RAG, a segmentation can be obtained by finding the edge with the lowest score, merge it, recompute the scores of edges affected by the merge, and iterate until the score of the lowest edge hits a predefined threshold θ. In the following, we will denote by G i the RAG after i iterations (and analogously by V i , E i , and f i its nodes, edges, and scores), with G 0 = G as introduced above. We will "reuse" nodes and edges, meaning V i+1 ⊂ V i and E i+1 ⊂ E i . Given that the initial fragments are indeed an oversegmentation, it is up to the design of the scoring function and the threshold θ to ensure a correct segmentation. The design of the scoring function can be broken down into the initialization of f 0 (e) for e ∈ E 0 (i.e., the initial scores) and the update of f i (e) for e ∈ E i ; i &gt; 0 after a merge of two regions a, b ∈ V i−1 . For the update, three cases can be distinguished (for an illustration see <ref type="figure" target="#fig_7">Fig. 4</ref>): (1) e was not affected by the merge, (2) e is incident to a or b but represents the same contact area between two regions as before, and (3) e results from merging two edges of E i−1 into one (the other edge will be deleted). In the first two cases, the score does not change, i.e., f i (e) = f i−1 (e), since the contact area between the nodes linked by e remains the same. In the latter case, the contact area is the union of the contact area of the merged edges, and the score needs to be updated accordingly. Acknowledging the merge hierarchy of edges (as opposed to nodes), we will refer to the leaves under a merged edge e as initial edges, denoted by E * (e) ⊆ E 0 .</p><p>In our experiments, we initialize the edge scores f (e) for e ∈ E 0 with one minus the maximum affinity between the fragments linked by e and update them using a quantile value of scores of the initial edges under e. This strategy has been found empirically over a range of possible implementations of f (see Section 3).</p><p>Implemented naively, hierarchical agglomeration has a worst-case runtime complexity of at least O(n log(n)), where n = |E 0 | is the number of edges in the initial RAG. This is due to the requirement of finding, in each iteration, the cheapest edge to merge, which implies sorting of edges based on their scores. Furthermore, the edge scoring function has to be evaluated O(n) times, once for each affected edge of a node merge (assuming nodes have a degree bounded by a constant). For the merge function suggested above, a quantile of O(n) initial edge scores has to be found in the worst case, resulting in a total worst-case runtime complexity of O(n log(n) + n 2 ).</p><p>To avoid this prohibitively high runtime complexity, we propose to discretize the initial scores f 0 into k bins, evenly spaced in the interval [0, 1]. This simple modification has two important consequences: First, a bucket priority queue for sorting edge scores can be used, providing constant time insert and pop operations. Second, the computation of quantiles can be implemented in constant time and space by using histograms of the k possible values. This way, we obtain constant-time merge iterations (pop an edge, merge nodes, update scores of affected edges), applied at most n times, thus resulting in an overall worst-case complexity of O(n). With k = 256 bins, we noticed no sacrifice of accuracy in comparison to the non-discretized variant.</p><p>The analysis above holds only if we can ensure that the update of the score of an edge e, and thus the update of the priority queue, can be performed in constant time. In particular, it is to be avoided to search for e in its respective bucket. We note that for the quantile scoring function (and many more), the new edge score f i (e) after merging an edge f ∈ E i−1 into e ∈ E i−1 is always greater than or equal to its previous score. We can therefore mark e as stale and f as deleted and proceed merging without resorting the queue or altering the graph. Whenever a stale edge is popped from the priority queue, we compute its actual score and insert it again into the queue. Not only does this ensure constant time updates of edge scores and the priority queue, it also avoids computing scores for edges that are never used for a merge. This can happen if the threshold is hit before considering the edge, or if the edge got marked as deleted as a consequence of a nearby merge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RESULTS</head><p>Datasets We present results on three different and diverse datasets: CREMI <ref type="bibr" target="#b14">[15]</ref>, FIB-25 <ref type="bibr" target="#b11">[12]</ref>, and SEGEM <ref type="bibr" target="#b15">[16]</ref>   <ref type="table">Table 1</ref>: Qualitative results of our method (U-NET MALA) compared to the respective state of the art on the testing volumes of each dataset and a baseline (U-NET). Highlighted in bold are the names of our method and the best value in each column. Measures shown are variation of information (VOI, lower is better), CREMI score (geometric mean of VOI and adapted RAND error, lower is better), and inter-error distance in µm (IED, higher is better) evaluated on traced skeletons of the test volume. The IED has been computed using the TED metric on skeletons <ref type="bibr" target="#b16">[17]</ref> with a distance threshold of 52 nm (corresponding to the thickness of two z-sections). CREMI results are reported as average over all testing samples, individual results can be found in <ref type="figure" target="#fig_16">Fig. 8</ref>. <ref type="table" target="#tab_2">Table 2</ref> for an overview). These datasets sum up to almost 15 gigavoxels of testing data, with FIB-25 alone contributing 13.8 gigavoxels, thus challenging automatic segmentation methods for their efficiency. In fact, only two methods have so far been evaluated on FIB-25 <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b11">[12]</ref>. Another challenge is posed by the CREMI dataset: Coming from serial section EM, this dataset is highly anisotropic and contains artifacts like support film folds, missing sections, and staining precipitations. Regardless of the differences in isotropy and presence of artifacts, we use the same method (3D U-NET training, prediction, and agglomeration) for all datasets. The size of the receptive field of the U-NET was set for each dataset to be approximately one µm 3 , i.e., 213×213×29 for CREMI, 89×89×89 for FIB-25, and 89×89×49 for SEGEM. For the CREMI dataset, we also pre-aligned training and testing data with an elastic alignment method <ref type="bibr" target="#b17">[18]</ref>, using the padded volumes provided by the challenge.  which we performed random rotations, transpositions and flips, as well as elastic deformations. On the anisotropic CREMI dataset, we further simulated missing sections by setting intensity values to 0 (p = 0.05) and low contrast sections by multiplying the intensity variance by 0.5 (p = 0.05).</p><p>We used the Adam optimizer <ref type="bibr" target="#b18">[19]</ref> with an initial learning rate of α = 10 −4 , β 1 = 0.95, β 2 = 0.99, and = 10 −8 .</p><p>Quantitative results On each of the investigated datasets, we see a clear improvement in accuracy using our method, compared to the current state of the art. We provide quantitative results for each of the datasets individually, where we compare our method (labeled U-NET MALA) against different other methods 4 . We also include a baseline (labeled U-NET) in our analysis, which is our method, but trained without the constrained MALIS loss. In <ref type="table">Table 1</ref>, we report the segmentation obtained on the best threshold found in the respective training datasets. In <ref type="figure" target="#fig_12">Fig. 7</ref>, we show the split/merge curve for varying thresholds of our agglomeration scheme. For SEGEM, we do not use the metric proposed by Berning et al. <ref type="bibr" target="#b15">[16]</ref>, as we found it to be problematic: The authors suggest an overlap threshold of 2 to compensate for inaccuracies in the ground-truth, however this has the unintended consequence of ignoring some neurons in the ground-truth for poor segmentations. For the SEGEM segmentation (kindly provided by the authors), 195 out of 225 ground-truth skeletons are ignored because of insufficient overlap with any segmentation label. On our segmentation, only 70 skeletons would be ignored, thus the results are not directly comparable. Therefore, we performed a new IED evaluation using TED <ref type="bibr" target="#b16">[17]</ref>, a metric that allows slight displacement of skeleton nodes (we chose 52 nm in this case) in an attempt to minimize splits and merges. This metric reveals that our segmentations (U-NET MALA) improve over both split and merge errors, over all thresholds of agglomeration, including the initial fragments (see <ref type="figure" target="#fig_12">Fig. 7c</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Qualitative results</head><p>Renderings of 11 and 23 randomly selected neurons, reconstructed using the proposed method, are shown for the test regions of CREMI and FIB-25 in <ref type="figure" target="#fig_17">Fig. 9</ref> and <ref type="figure" target="#fig_1">Fig. 10</ref>, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset (an)isotropy</head><p>Save for minor changes in the network architectures and the generation of initial fragments, our method works unchanged on both near-isotropic block-face datasets (FIB-25, SEGEM) as well as on highly anisotropic serial-section datasets (CREMI). These findings suggest that there is no need for specialized constructions like dedicated features for anisotropic volumes or separate classifiers trained for merging of fragments within or across sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Merge functions</head><p>Our method for efficient agglomeration allows using a range of different merge functions. In <ref type="table">Table 3</ref>, we show results for different choices of quantile merge functions, mean affinity, and an agglomeration baseline proposed in <ref type="bibr" target="#b19">[20]</ref> on datasets CREMI and FIB-25. Even across these very different datasets, we see best results for affinity quantiles between 50% and 75%. All initial edge scores have been set to one minus the maximum predicted affinity between the regions. Theoretically, this is the ideal choice since the MALIS training optimizes the maximin affinity between regions. Also empirically we found this initialization to perform consistently better than others (like the mean or a quantile affinity).</p><p>Throughput <ref type="table" target="#tab_5">Table 4</ref> shows the throughput of our method * * w (3, 3, 3) <ref type="figure">Figure 6</ref>: Details of the convolution (blue), max-pooling (yellow), upsampling (brown), and copy-crop operations (red). " * " denotes a convolution, " " a rectified linear unit, and "⊗" the Kronecker matrix product.  <ref type="table">Table 3</ref>: Results for different merge functions of our method compared with the agglomeration strategy proposed in <ref type="bibr" target="#b19">[20]</ref>. We show the results at the threshold achieving the best score in the respective dataset (CREMI score for CREMI, VOI for FIB-25). Note that, for this analysis, we used the available training datasets which explains deviations from the numbers shown in <ref type="table">Table 1</ref>.  for each dataset, broken down into affinity prediction (U-NET), fragment extraction (watershed), and fragment agglomeration (agglomeration). For CREMI and SEGEM, most time is spent on the prediction of affinities. The faster predictions in FIB-25 are due to less feature maps used in the network for this dataset.</p><formula xml:id="formula_11">w − 2 (3, 3, 3) w − 4 max w k x w/k x ⊗ + * w (k x , k y , k z ) w · k (1, 1, 1) w · k w w − c x conv( f 1 , f 2 ) pool(k x , k y , k z ) up(k x , k y , k z , f ) crop(c x , c y , c z )</formula><p>To empirically confirm the theoretical speedup of using a bucket queue for agglomeration, we show in <ref type="figure" target="#fig_12">Fig. 7d</ref> a speed comparison of the proposed linear-time agglomeration against a naive agglomeration scheme for volumes of different sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">DISCUSSION</head><p>A remarkable property of the MALA method is that it requires almost no tuning to operate on datasets of different characteristics, except for minor changes in the size of the receptive field of the U-NET, training data augmentation to CRunet <ref type="bibr" target="#b12">[13]</ref> LFC <ref type="bibr" target="#b13">[14]</ref> (a) VOI split/merge on CREMI (lower is better). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>U-NET</head><p>FlyEM <ref type="bibr" target="#b11">[12]</ref> CELIS <ref type="bibr" target="#b3">[4]</ref> CELIS+MC <ref type="bibr" target="#b3">[4]</ref> (b) VOI split/merge on FIB-25 (lower is better).  <ref type="bibr" target="#b15">[16]</ref> (c) IED split/merge on SEGEM (higher is better).  model dataset specific artifacts, and initial fragment generation. This suggests that there is no need for the development of dedicated algorithms for different EM modalities. Across all datasets, our results indicate that affinity predictions on voxels are sufficiently accurate to render sophisticated postprecessing obsolete.</p><p>It remains an open question whether fundamentally different approaches, like the recently reported flood-filling network <ref type="bibr" target="#b20">[21]</ref>, also generalize in a similar way. At the time of writing, neither code nor data were publicly available for a direct comparison. Furthermore, the U-NET is the only part in our method that requires training, so that all training data can (and should) be used to correctly predict affinities. This is an advantage over current state-of-the-art methods that require careful splitting of precious training data into nonoverlapping sets used to train voxel-wise predictions and an agglomeration classifier (or accepting the disadvantages of having the sets overlap).</p><p>Although linear in runtime and memory, correct parallelization of hierarchical agglomeration is not trivial and will require further research. However, as demonstrated on the FIB-25 dataset, naive block-based agglomeration followed by empirical stitching based on region overlap generates very satisfying practical results. CRunet <ref type="bibr" target="#b12">[13]</ref> LFC <ref type="bibr" target="#b13">[14]</ref> U-NET MALA LMC <ref type="bibr" target="#b7">[8]</ref> CRunet <ref type="bibr" target="#b12">[13]</ref> LFC <ref type="bibr" target="#b13">[14]</ref> 0.5 CRunet <ref type="bibr" target="#b12">[13]</ref> LFC <ref type="bibr" target="#b13">[14]</ref> U-NET MALA LMC <ref type="bibr" target="#b7">[8]</ref> CRunet <ref type="bibr" target="#b12">[13]</ref> LFC <ref type="bibr" target="#b13">[14]</ref> 0.8 CRunet <ref type="bibr" target="#b12">[13]</ref> LFC <ref type="bibr" target="#b13">[14]</ref> U-NET MALA LMC <ref type="bibr" target="#b7">[8]</ref> CRunet <ref type="bibr" target="#b12">[13]</ref> LFC Shown are (from left to right) variation of information (VOI, split and merge contribution), Rand index (RAND, split and merge contribution), and the total VOI (split and merge combined). Baseline U-NET is our method, but without MALIS training (i.e., only minimizing the Euclidean distance to the ground-truth affinities during training) For U-NET MALA, the red dot indicates the best threshold found on the training data.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3D</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>Overview of our method (top row)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Gradient of loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of the constrained MALIS loss.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>3) as L(s, a) = e∈MST(G) w P (e)l(1, a(e)) + w N (e)l(0, a(e))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :</head><label>3</label><figDesc>Illustration of the seeded watershed heuristic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>Illustration of the three different edge update cases during a merge. Case 1: The edge is not involved in the merge at all (a). Case 2: One of the edge's nodes is involved in the merge, but the boundary represented by the edge does not change (b and e). Case 3: The boundaries represented by two edges get merged (c and d).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>priority queue O(n log(n)) (d) Runtime analysis.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 7 :</head><label>7</label><figDesc>(a-c) Split merge curves of our method (lines) for different thresholds on the CREMI, FIB-25, and SEGEM datasets, compared against the best-ranking competing methods (dots). (d) Performance comparison of a naive agglomeration scheme (priority queue, O(n log(n))) versus our linear-time agglomeration (bucket queue, O(n)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 8 :</head><label>8</label><figDesc>Comparison of the proposed method against competing methods on the CREMI testing datasets A+, B+, and C+.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 9 :</head><label>9</label><figDesc>Reconstructions of 11 randomly selected neurons of the 100 largest found in the CREMI test volume C+.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 10 :</head><label>10</label><figDesc>Reconstructions of 23 randomly selected neurons of the 500 largest found in the FIB-25 test volume.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Results on FIB-25, evaluated on whole test volume.</figDesc><table><row><cell cols="2">method U-NET MALA U-NET FlyEM [12] CELIS [4] CELIS+MC [4]</cell><cell>VOI split VOI merge VOI sum 0.891 0.180 1.071 1.205 0.316 1.520 1.490 0.462 1.952 1.426 0.208 1.634 1.037 0.229 1.266</cell></row><row><cell cols="2">(a) method U-NET MALA U-NET FlyEM [12] CELIS [4] CELIS+MC [4]</cell><cell>VOI split VOI merge VOI sum 1.953 0.198 2.151 2.442 0.471 2.914 3.160 0.251 3.411 3.401 0.166 3.568 2.354 0.216 2.570</cell></row><row><cell cols="3">(b) Results on FIB-25, evaluated on synaptic sites.</cell></row><row><cell>method U-NET MALA U-NET LMC [8] CRunet [13] LFC [14]</cell><cell cols="2">VOI split VOI merge VOI sum CREMI score 0.425 0.181 0.606 0.289 0.979 0.546 1.524 0.793 0.597 0.272 0.868 0.398 1.081 0.389 1.470 0.566 1.085 0.140 1.225 0.616</cell></row><row><cell cols="3">(c) Results on CREMI (from leaderboard in [15]).</cell></row><row><cell cols="2">method U-NET MALA U-NET SegEM [16]</cell><cell>IED split IED merge IED total 6.259 21.337 4.839 6.903 1.719 1.377 2.121 3.951 1.380</cell></row><row><cell></cell><cell cols="2">(d) Results on SEGEM.</cell></row><row><cell>(see</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Overview of used datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Throughput of our method for each of the investigated datasets in seconds per megavoxel.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">. The presented results reflect the state of the CREMI challenge at the time of writing, see<ref type="bibr" target="#b14">[15]</ref>.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">3D U-Net: learning dense volumetric segmentation from sparse annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ö</forename><surname>Ç Içek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abdulkadir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Lienkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="424" to="432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Maximin affinity learning of image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Briggman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Denk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Helmstaedter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Turaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Bengio, Y., Schuurmans, D., Lafferty, J. D., Williams, C. K. I. &amp; Culotta, A.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1865" to="1873" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>U-Net</surname></persName>
		</author>
		<title level="m">Convolutional networks for biomedical image segmentation. In MICCAI</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combinatorial energy learning for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Maitin-Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Januszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1966" to="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Graph-based active learning of agglomeration (gala): a python library to segment 2d and 3d neuroimages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nunez-Iglesias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kennedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Plaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in neuroinformatics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">34</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Globally optimal closed-surface segmentation for connectomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Andres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="778" to="791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Efficient decomposition of image and mesh graphs by lifted multicuts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keuper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Multicut brings automated neurite segmentation closer to human performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Beier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Methods</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="101" to="102" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Learned watershed: End-to-end learning of seeded segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Kothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hamprecht</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On the shortest spanning subtree of a graph and the traveling salesman problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Kruskal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the American Mathematical society</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="48" to="50" />
			<date type="published" when="1956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Open source software for scriptable computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">P</forename><surname>Coelho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahotas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Open Research Software</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Synaptic circuits and their variations within different columns in the visual system of drosophila</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Takemura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="13711" to="13716" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deepem3d: approaching human-level performance on 3d anisotropic em image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2555" to="2562" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Anisotropic EM segmentation by 3d affinity learning and agglomeration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Parag</surname></persName>
		</author>
		<idno>abs/1707.08935</idno>
		<ptr target="http://arxiv.org/abs/1707.08935.1707.08935" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Funke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Perlman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Turaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saalfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cremi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leaderboard</surname></persName>
		</author>
		<idno>2017/22/09</idno>
		<ptr target="https://cremi.org/leaderboard" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Segem: efficient image analysis for high-resolution connectomics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Boergens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Helmstaedter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="1193" to="1206" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Ted: A tolerant edit distance for segmentation evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Funke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moreno-Noguer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cardona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Methods</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="119" to="127" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Elastic volume reconstruction from series of ultra-thin microscopy sections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saalfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fetter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cardona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tomancak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature methods</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="717" to="720" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<title level="m">A method for stochastic optimization</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Image segmentation by size-dependent single linkage clustering of a watershed basin graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zlateski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
		<idno>abs/1505.00249</idno>
		<ptr target="http://arxiv.org/abs/1505.00249" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Flood-filling networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Januszewski</surname></persName>
		</author>
		<idno>abs/1611.00421</idno>
		<ptr target="http://arxiv.org/abs/1611.00421" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
