<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ESPRESSO: A FAST END-TO-END NEURAL SPEECH RECOGNITION TOOLKIT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wang</surname></persName>
							<email>yiming.wang@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center of Language and Speech Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongfei</forename><surname>Chen</surname></persName>
							<email>tongfei@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center of Language and Speech Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hainan</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center of Language and Speech Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuoyang</forename><surname>Ding</surname></persName>
							<email>dings@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center of Language and Speech Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Lv</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center of Language and Speech Processing</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiwen</forename><surname>Shao</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center of Language and Speech Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanyun</forename><surname>Peng</surname></persName>
							<email>npeng@isi.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Information Sciences Institute</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xie</surname></persName>
							<email>lxie@nwpu-aslp.org</email>
							<affiliation key="aff3">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">Northwestern Polytechnical University</orgName>
								<address>
									<settlement>Xi&apos;an</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
							<email>shinjiw@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center of Language and Speech Processing</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
							<email>khudanpur@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center of Language and Speech Processing</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Human Language Technology Center of Excellence</orgName>
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ESPRESSO: A FAST END-TO-END NEURAL SPEECH RECOGNITION TOOLKIT</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T18:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-automatic speech recognition</term>
					<term>end-to-end</term>
					<term>par- allel decoding</term>
					<term>language model fusion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present ESPRESSO, an open-source, modular, extensible endto-end neural automatic speech recognition (ASR) toolkit based on the deep learning library PyTorch and the popular neural machine translation toolkit FAIRSEQ. ESPRESSO supports distributed training across GPUs and computing nodes, and features various decoding approaches commonly employed in ASR, including look-ahead word-based language model fusion, for which a fast, parallelized decoder is implemented. ESPRESSO achieves state-of-the-art ASR performance on the WSJ, LibriSpeech, and Switchboard data sets among other end-to-end systems without data augmentation, and is 4-11× faster for decoding than similar systems (e.g. ESPNET).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>Various open-source toolkits for building automatic speech recognition (ASR) systems have been created, with a notable example being Kaldi <ref type="bibr" target="#b0">[1]</ref>, a weighted finite state transducer based framework with extensive linear algebra support, that enables traditional hybrid ASR systems <ref type="bibr" target="#b1">[2]</ref>.</p><p>With advances in deep learning, recent work in ASR begun paying attention to so-called neural end-to-end systems <ref type="bibr">[3, 4, 5,</ref> inter alia], which are characterized by generally smaller code size, and greater portability and maintainability across hardware platforms and software environments. This shift is analogous to the one in the machine translation (MT) community: from feature-and syntaxbased statistical machine translation (SMT) systems (e.g. Moses <ref type="bibr" target="#b5">[6]</ref>, Joshua <ref type="bibr" target="#b6">[7]</ref>) to end-to-end neural machine translation (NMT) systems (e.g. OPENNMT <ref type="bibr" target="#b7">[8]</ref>, OPENSEQ2SEQ <ref type="bibr" target="#b8">[9]</ref>, FAIRSEQ <ref type="bibr" target="#b9">[10]</ref>). As a result, there have been a few efforts in the ASR research community to create open source neural end-to-end frameworks, most notably ESPNET <ref type="bibr" target="#b10">[11]</ref> (See also, <ref type="table" target="#tab_0">Table 1</ref>). However, ESPNET has some important shortcomings: (i) the code is not very easily extensible and has portability issues due to its mixed dependency on two deep learning frameworks PyTorch <ref type="bibr" target="#b11">[12]</ref> and Chainer <ref type="bibr" target="#b12">[13]</ref>; (ii) the decoder, which uses a simple but relatively slow beam search algorithm, is not fast enough for quick turnaround of experiments.</p><p>This work was partially supported by the IARPA MATERIAL program and by an unrestricted gift from Mobvoi. The authors also thank Ziyan Jiang for running speed tests on ESPNET.</p><p>To address these problems, we present ESPRESSO, a novel neural end-to-end system for ASR. <ref type="bibr" target="#b0">1</ref> ESPRESSO builds upon the popular NMT framework <ref type="bibr">FAIRSEQ 2</ref> , and the flexible deep learning framework PyTorch. By extending FAIRSEQ, ESPRESSO inherits its excellent extensibility: new modules can easily be plugged into the system by extending standard PyTorch interfaces. Additionally, we gain ability to perform distributed training over large data sets for ASR.</p><p>We also present the first fully parallelized decoder for end-toend ASR, with look-ahead word-based language model fusion <ref type="bibr" target="#b19">[20]</ref>, tightly integrated with the existing sets of optimized inference algorithms (e.g. beam search) inherited from FAIRSEQ and tailored to the scenario of speech recognition. Furthermore, an improved coverage mechanism is proposed to further reduce deletion and insertion errors, and is compared with related techniques such as EOS threshold <ref type="bibr" target="#b20">[21]</ref>. ESPRESSO provides recipes for a variety of benchmark ASR data sets, including WSJ <ref type="bibr" target="#b21">[22]</ref>, LibriSpeech <ref type="bibr" target="#b22">[23]</ref>, and Switchboard <ref type="bibr" target="#b23">[24]</ref>, and achieves state-of-the-art results on these data sets.</p><p>ESPRESSO, by building upon FAIRSEQ, also has the potential to integrate seamlessly with sequence generation systems from natural language processing (NLP), such as neural machine translation and dialog systems. We envision that ESPRESSO could become the foundation for unified speech + text processing systems, and pave the way for future end-to-end speech translation (ST) and text-to-speech synthesis (TTS) systems, ultimately facilitating greater synergy between the ASR and NLP research communities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">SOFTWARE ARCHITECTURE AND DESIGN CHOICES</head><p>We implement ESPRESSO with the following design goals in mind:</p><p>• Pure Python / PyTorch that enables modularity and extensibility; • Parallelization and distributed training and decoding for quick turnaround of experiments; • Compatibility with Kaldi / ESPNET data format to enable reuse of previous / proven data preparation pipelines; • Easy interoperability with the existing FAIRSEQ codebase to facilitate future joint research areas between speech and NLP.</p><p>We elaborate our technical rationale in the following sections. where &lt;UttID&gt; is the utterance ID, a key that points to any utterance in the dataset, and &lt;FeatureFile&gt; is a string interpreted as an extended filename for reading from a binary file (ARK format) storing the actual acoustic feature data, following the practice 3 in Kaldi.</p><p>In theory, any kind of acoustic feature vectors (e.g. MFCC) can be stored in the feature file. In ESPRESSO, we follow ESPNET and employ the commonly used 80-dimensional log Mel feature with the additional pitch features (in total, 83 dimensions for each frame).</p><p>In FAIRSEQ, there is a concept called "datasets", which contains a set of training samples and abstracts away details such as shuffling and bucketing. We follow this and create the following dataset classes in ESPRESSO:</p><p>• data.ScpCachedDataset: this contains the real-valued acoustic features extracted from the speech utterance. Each training batch drawn from this dataset is a real-valued tensor of shape [BatchSize × TimeFrameLength × FeatureDims] that will be fed to the neural speech encoder (Section 2.3). Since the acoustic features are large and cannot be loaded into memory all at once, we also implement sharded loading, where given the order of the incoming examples in an epoch, a bulk of features is pre-loaded once the previous bulk is consumed for training / decoding. This helps balance the file system's I/O load and the memory usage. • data.TokenTextDataset: this contains the gold speech transcripts as text. Each training batch is a integer-valued tensor of shape [BatchSize × SequenceLength], where each integer in this tensor is the index of the character / subword unit in the token dictionary (see below). • data.SpeechDataset: this is a container for the two datasets above: each sample drawn from this dataset contains two fields, source and target, that points to the speech utterance and the gold transcripts respectively. Note that in speech recognition, the token dictionary (set of all vocabulary) is different from the common practice in FAIRSEQ due to the additional special token &lt;space&gt;. For this reason, we do not directly use the data.Dictionary class from FAIRSEQ, instead, we inherit that class and create our data.TokenDictionary class for this purpose, with the extra functionality of handling &lt;space&gt;.</p><p>For speech decoding purposes rather than NMT (default in FAIRSEQ), normally the output unit for each decoding step is a subword unit instead of a word, since it is shown that for ASR using 3 https://kaldi-asr.org/doc/io.html. whole words as modeling units is only possible when large amounts of training data (at least tens of thousands of hours) is available <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>. A subword unit can either be a character or character sequence like BPE <ref type="bibr" target="#b26">[27]</ref> or a SentencePiece 4 <ref type="bibr" target="#b27">[28]</ref>. Both are supported in ESPRESSO and experimental results will follow.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Output format</head><p>ESPRESSO supports two output format: a raw format and a more detailed aligned results version that helps debugging.</p><p>The raw format just consists of space-delimited lines that follows this template:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;UttID&gt; &lt;DecodedSequence&gt;</head><p>where &lt;UttID&gt; is the original utterance ID from the SCP dataset, and the &lt;DecodedSequence&gt; is the raw output of the speech recognition system.</p><p>The aligned results provide an aligned sequence between the gold reference transcript and the predicted hypothesis. An example is shown below: Each such record consists of 5 rows: the first line is the utterance ID; REF and HYP is the reference transcript and the system output hypothsis respectively -these two are aligned using minimal edit distance. The fourth line, STP (step), contains the error the system makes at each decoding step: it could be one of S (substitution), I (insertion) and D (deletion), corresponding to the three types of errors when evaluating the word error rate (WER) commonly used to evaluate speech recognition systems. The last line is WER calculated on this utterance. Such output format facilitates easy human inspection to the different error types made by the system, rendering debugging easier for researchers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Encoder-Decoder</head><p>ESPRESSO supports common sequence generation models and techniques arisen from the research in the ASR and NLP community.</p><p>The de facto standard model, the encoder-decoder with attention <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b29">30]</ref> (also successfully pioneered by <ref type="bibr" target="#b3">[4]</ref> in the speech community), is implemented as our models.speech lstm.SpeechLSTMModel class. Owing to the modularity and extensibility of ESPRESSO, other models, e.g., Transformer <ref type="bibr" target="#b30">[31]</ref>, can be easily integrated from the underlying FAIRSEQ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN-LSTM Encoder</head><p>The default encoder we used is a 4-layer stacked 2-dimensional convolution (with batch normalization between layers), with kernel size (3, 3) on both the time frame axis and the feature axis <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b10">11]</ref>. 2×-downsampling is employed at layer 1 and 3, resulting in 1 /4 time frames after convolution. The final output channel dimensionality is 128, with the 21 downsampled frequency features, hence a total of 128 × 21 = 2688 dimensional features for each time frame.</p><p>Then 3 layers of bidirectional LSTMs <ref type="bibr" target="#b32">[33]</ref> are stacked upon the output channels yielded by the stacked convolution layers.</p><p>This architecture, with the various dimensionality, number of layers, and other hyperparameters customizable, is implemented in our models.speech lstm.SpeechLSTMEncoder class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LSTM Decoder with Attention</head><p>We use a 3-layer LSTM decoder by default, with Bahdanau attention <ref type="bibr" target="#b28">[29]</ref> on the encoded hidden states (Luong attention <ref type="bibr" target="#b29">[30]</ref> is also implemented). We follow the architecture in the Google Neural Machine Translation (GNMT) system <ref type="bibr" target="#b33">[34]</ref>, where the context vectors generated by the attention mechanism is fed to all 3 layers of the decoding LSTM. Residual connections <ref type="bibr" target="#b34">[35]</ref> are added between the decoder layers. These are implemented in the models.speech lstm.SpeechLSTMDecoder class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Training Strategies</head><p>Scheduled Sampling Scheduled sampling <ref type="bibr" target="#b35">[36]</ref> is supported by our system, with promising results in end-to-end speech recognition <ref type="bibr" target="#b36">[37]</ref>. With scheduled sampling, at each decoder step, the gold label is fed to the next step with p probability, whereas the predicted token 5 is fed with (1 − p) probability. In our implementation such mechanism will start at an intermediate epoch N in the training process: the first few epochs are always trained with gold labels. The probability p can be scheduled in the training process: later epochs might use a smaller probability to encourage the model not to rely on the gold labels.</p><p>Label Smoothing Label smoothing <ref type="bibr" target="#b37">[38]</ref> has been proposed to improve accuracy by computing the loss (i.e., cross entropy here) not with the "hard" (one-hot) targets from the dataset, but with a weighted mixture of these targets with some distribution <ref type="bibr" target="#b38">[39]</ref>. We support three kinds of these distributions in ESPRESSO:</p><p>• Uniform smoothing <ref type="bibr" target="#b37">[38]</ref>: The target is a mixture of (1 − p) probability of the one-hot target and the rest of the p probability mass uniformly distributed across the vocabulary set; • Unigram smoothing <ref type="bibr" target="#b39">[40]</ref>: Mixed with a unigram language model trained on the gold transcripts; • Temporal smoothing <ref type="bibr" target="#b40">[41]</ref>: Mixed with a distribution assigning probability mass to neighboring tokens in the transcript. Intuitively, this smoothing scheme helps the model recover from beam search errors: the network is more likely to make mistakes that simply skip a subword unit of the transcript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Selection via Validation</head><p>At the end of each training epoch, we compute the WER on the validation set using greedy-search decoding without language model fusion (see Section 3). This is different from the approach in previous frameworks such as ESPNET and FAIRSEQ, where they compute the loss function on the validation set (the gold labels are fed in) to perform model selection. We argue that our approach may be more suitable since free decoding on the validation set is a closer scenario to the final metric on test sets. Owing to efficiency concerns, we do not use full-blown language model fused beam search decoding for validation (arguably this is even better). We employ learning rate scheduling following FAIRSEQ: at the end of an epoch, if the metric on the validation set is not better than the previous epoch, the learning rate is reduced by a factor (e.g. 1 /2). Empirically we found that the reduction of the learning rate will be less frequent if using WER as the validation metric as compared to the loss value on the validation set. According to <ref type="bibr" target="#b41">[42]</ref>, a less frequent learning rate reduction generally leads to better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">LANGUAGE MODEL-FUSED DECODING</head><p>It is shown in recent research that a pure sequence-to-sequence transduction model for ASR without an external language model component (which is used in traditional hybrid ASR systems) is far from satisfactory <ref type="bibr" target="#b42">[43]</ref>. This is in contrast with neural machine translation (NMT) models, where normally no external language model is needed. This performance gap is hypothesized to be caused by the fact that the ASR model is only trained on speech-transcript pairs. The gold transcript set is not large enough to produce state-of-theart neural language models, which are typically trained on a corpus on the scale of 1 billion words.</p><p>In ESPRESSO, we employ shallow fusion <ref type="bibr" target="#b43">[44]</ref> as a language model integration technique, which is proven to be effective in speech recognition <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b44">45]</ref>. The LSTM decoder with shallow fusion computes a weighted sum of two posterior distributions over subword units: one from the end-to-end speech recognition model, the other from the external neural language model. We support 3 types of external neural language models:</p><p>• Subword-unit language model: A vanilla LSTM-based language model trained on subword units. Here subword units can either just be characters (with &lt;space&gt; as an additional special token) or trained subword units (e.g. BPE <ref type="bibr" target="#b26">[27]</ref> or SentencePiece <ref type="bibr" target="#b27">[28]</ref>); • Multi-level language model <ref type="bibr" target="#b45">[46]</ref>: This is a combination of character-based and word-based language models. Hypotheses in the beam are first scored with the character-based language model until a word boundary (&lt;space&gt;) is encountered. Known words are then re-scored using the word-based language model, while the character-based language model provides for out-ofvocabulary scores; • Look-ahead word-based language model <ref type="bibr" target="#b19">[20]</ref>: This model enables outputting characters for each decoding step with a pretrained word-based language model, by providing look-ahead word probabilities based on the word prefix (sequence of characters) decoded. This is shown in <ref type="bibr" target="#b19">[20]</ref> to be superior to the multilevel language model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Parallelization with Look-ahead Word-based LMs</head><p>The original implementation of the look-ahead word-based language model in ESPNET <ref type="bibr" target="#b10">[11]</ref> is not operating on batches, making the decoding speed slow. In ESPRESSO, we devise a fully-parallelized version of the decoding algorithm on GPUs.</p><p>In <ref type="bibr" target="#b19">[20]</ref>, a word-based language model is converted to a characterbased one via a technique using prefix trees. The prefix tree automaton T = (Σ, Q, ε, τ, V) is a finite-state automaton (see <ref type="figure" target="#fig_1">Fig. 1</ref>):</p><p>• Σ is the character set (including &lt;space&gt;);</p><p>• V ⊆ Σ * is the word vocabulary set and also the final state set;</p><formula xml:id="formula_0">• Q = {p w | w ∈ V } ⊆ Σ *</formula><p>is the set of all prefixes 6 of the words in V and also the state set;</p><p>• ε is the empty string, which also serves as the initial state;</p><p>• τ : Q×Σ → Q is the state transition function, where given a state and an input character, τ(p, c) = pc, i.e. a simple concatenation.</p><p>A look-ahead word-based LM computes the probability of the next character c ∈ Σ based on a given word history h and a word prefix p ∈ Q (i.e., a state in the prefix tree automaton):</p><formula xml:id="formula_1">P(c | p, h) = s: pcs∈V P W (pcs | h) s: ps∈V P W (ps | h) .<label>(1)</label></formula><p>where P W (w | h) is the probability of the word w predicted by the word-based LSTM language model. In Eq. (1), the numerator is the sum of the probability of all words prefixed by pc, i.e. all possible words that could be generated from pc if the state is moved from p to pc; the denominator is the sum of the probability of all possible words at the current state p (see <ref type="figure" target="#fig_1">Fig. 1</ref>). <ref type="bibr" target="#b19">[20]</ref> proposed an efficient way to compute the sum in Eq. (1). We denote p precedes q lexicographically as p ≺ q, and define the upper bound p (the lexicographically greatest element prefixed by p) and lower bound p (the greatest element lexicographically less than any word prefixed by p) as:</p><formula xml:id="formula_2">p = max w∈V,p w w; p = max w∈V,p w,w≺p w<label>(2)</label></formula><p>Given that the vocabulary set is sorted lexicographically, we can efficiently compute the sum of the probability of all words preceding or equal to a given word, using efficient routines like cumsum:</p><formula xml:id="formula_3">g(w | h) = w w P W (w | h)<label>(3)</label></formula><p>Using these definitions, Eq. (1) can be rewritten as</p><formula xml:id="formula_4">P(c | p, h) = g(pc | h) − g(pc | h) g(p | h) − g(p | h)<label>(4)</label></formula><p>This method is illustrated in <ref type="figure" target="#fig_1">Fig. 1</ref>, showing that the probability of a character given a prefix can be efficiently computed via a cumsum operation and simple arithmetics.</p><p>In our parallelized implementation, each prefix p (corresponding to a state in the automaton) is indexed as a unique integer. Hence the batch of decoding states is compactly stored as a vector of integers, each corresponding to a state on the prefix tree automaton. The automaton itself is stored as a matrix T with shape [NumberOfStates × MaxOutDegree], where the row T p contains the index of all descendants of p, logically forming an adjacency list. The index of the p and p for each state p is also precomputed and cached. In sum, the entire prefix tree automaton is vectorized.</p><p>To compute P(c | p, h) for all c ∈ Σ over batches and beam hypotheses, the following steps are executed:</p><p>(i) Update P W (w | h) for all w ∈ V from a specific decoding step of the word-based language model for those hypotheses that encounter the end-of-word (&lt;space&gt;) symbol in the batch;</p><p>(ii) Update the g(w | h) function using P W (w | h) for all w ∈ V; <ref type="bibr" target="#b5">6</ref> We denote "p is a prefix of q" as p q: e.g. "stand" "standard". (v) Compute the probability for each c ∈ Σ according to Eq. (4).</p><formula xml:id="formula_5">g(pc | h) g(pc | h) g(p | h) g(p | h) p c pc</formula><p>Note that the first step follows a batched forward computation of a neural language model; the third and the fourth steps can be computed via tensorized advanced indexing; and the second and the last steps can be executed using vectorized arithmetics. Hence we obtain a fully parallelized algorithm that runs on GPUs.</p><p>As mentioned in the first step, at a specific decoding step, some elements in the batch may encounter the end-of-word symbol, whereas others may not: running this conditional operation requires special treatment. We devise an algorithm that shares the spirit with <ref type="bibr" target="#b46">[47]</ref>, an parallelized algorithm for stack LSTM parsing: first we record the elements in the batch that has not reached the end of a word with a mask, then progress the state for one step for all of these elements, finally, for those masked states, their original states are restored, and only P W (w | h) of those not masked are updated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Improved Coverage</head><p>With language model fusion, the decoder tends to make more deletion errors when the language model weight becomes larger <ref type="bibr" target="#b47">[48]</ref>. A coverage term (a scalar value assigned to each hypothesis in the beam) is first proposed in <ref type="bibr" target="#b40">[41]</ref> to promote longer transcripts and also to prevent attentions from looping over utterance (repeating certain n-grams when decoding) when using shallow fusion:</p><formula xml:id="formula_6">coverage = j 1 i a i j &gt; τ<label>(5)</label></formula><p>where a i j is the attention weight for the decoder step i and encoder frame j, τ &gt; 0 is a tunable hyper-parameter, and 1[·] is the indicator function. This is the total number of encoder frames that has been sufficiently "attended" to. However, based on our experiments, applying the coverage term Eq. (5) is not sufficient to prevent words from being repeated. Instead we propose a modified version of the coverage term which penalizes looping attentions more aggressively:</p><formula xml:id="formula_7">coverage = j 1 i a i j &gt; τ 1 −1 i a i j &gt; τ 2 · c + i a i j − τ 2<label>(6)</label></formula><p>where τ 2 &gt; τ 1 &gt; 0, c &gt; 0 are tunable hyper-parameters. While the first term in Eq. (6) is exactly the same as Eq. <ref type="formula" target="#formula_6">(5)</ref>, the second term penalizes the hypothesis score when the accumulated attention on encoder frame j exceeds τ 2 . Specifically, if the accumulated attention weight on frame j exceeds τ 1 but not τ 2 , only the first term is activated, increasing the coverage score to encourage more attention on frame j; if the accumulated attention weight further exceeds τ 2 , the second term (with the minus sign) is also activated and its magnitude is the amount of the exceeding value plus a constant c, discouraging further attention accumulated on the same frame. Therefore, the new coverage mechanism enforces a soft constraint on the accumulated attention weight on each frame to be between τ 1 and τ 2 , leading to both less deletion errors and less repeating n-grams (shown in the WSJ part of Section 4). During beam search decoding this new coverage term as a whole is added to the hypothesis score with a weight (e.g. 0.01). In our experiments, τ 1 = 0.5, τ 2 = 1.0, c = 0.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">EOS Threshold</head><p>We implement the end-of-sentence threshold technique proposed in <ref type="bibr" target="#b20">[21]</ref> to bias the decoder away from short transcriptions when decoding with a fused language model. End-of-sentence (&lt;eos&gt;) tokens can only be emitted if its probability is greater than a specific factor of the top output token candidate during beam search:</p><formula xml:id="formula_8">log P(&lt;eos&gt; | h) &gt; γ · max t ∈V log P(t | h)<label>(7)</label></formula><p>where V is the vocabulary set. In our experiments, γ is set to 1.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">RECIPES AND RESULTS</head><p>ESPRESSO provides running recipes for a variety of well-known data sets. We elaborate the details of our recipes on Wall Street Journal <ref type="bibr" target="#b21">[22]</ref> (WSJ), an 80-hour English newspaper speech corpus, Lib-riSpeech <ref type="bibr" target="#b22">[23]</ref>, a corpus of approximately 1,000 hours of read English speech, and Switchboard <ref type="bibr" target="#b23">[24]</ref> (SWBD), a 300-hour English telephone speech corpus.</p><p>Besides the transcripts, all of these data sets have their own extra text corpus for training language models. Input and output word embeddings are tied <ref type="bibr" target="#b48">[49]</ref> to reduce model size. All the models are optimized using Adam <ref type="bibr" target="#b49">[50]</ref> with an initial learning rate 10 −3 , and then halved if the metric on the validation set at the end of an epoch does not improve over the previous epoch. The training process stops if the learning rate is less than 10 −5 . Curriculum learning <ref type="bibr" target="#b50">[51]</ref>, which is quite helpful to stabilize training with long sequences (e.g. Lib-riSpeech) and improve performance (esp. SWBD), is employed for the first 1 (LibriSpeech) or 2 (WSJ / SWBD) epochs. All the models are trained / evaluated using NVIDIA GeForce GTX 1080 Ti GPUs. If not otherwise specified, all the models throughout this paper are trained with 2 GPUs using FAIRSEQ built-in distributed data parallellism. Note that no data augmentation techniques such as speedperturbation <ref type="bibr" target="#b51">[52]</ref> or the more recent SpecAugment <ref type="bibr" target="#b41">[42]</ref> is applied.</p><p>The hyper-parameters for the recipes are listed in <ref type="table" target="#tab_1">Table 2</ref>.</p><p>WSJ We adopt the look-ahead word-based language model <ref type="bibr" target="#b19">[20]</ref> as the external language model. We report the perplexities on the validation / evaluation set: the external word-based language model achieves 72.0 perplexity on dev93 and 59.0 on eval92. For the encoder-decoder model, the vocabulary size of subword units (characters) for WSJ is 52, the same as in ESPNET. <ref type="bibr" target="#b6">7</ref> Temporal label smoothing with p = 0.05 and scheduled sampling with p = 0.5 starting at epoch 6 are adopted.  Baseline end-to-end systems are compared: Hadian et al. <ref type="bibr" target="#b14">[15]</ref>, an end-to-end 8 model with the lattice-free MMI objective <ref type="bibr" target="#b52">[53]</ref>; Baskar et al. <ref type="bibr" target="#b36">[37]</ref>, an encoder-decoder model with discriminative training in ESPNET; Zeghidour et al. <ref type="bibr" target="#b53">[54]</ref>, a pure convolutional network with ASG loss <ref type="bibr" target="#b54">[55]</ref>; Likhomanenko et al. <ref type="bibr" target="#b55">[56]</ref>, a lexicon-free decoding method with the acoustic model proposed in <ref type="bibr" target="#b53">[54]</ref>; and the last one, Deep Speech 2 <ref type="bibr" target="#b56">[57]</ref>.</p><p>We show the beam search decoding results of various configurations of ESPRESSO in <ref type="table" target="#tab_2">Table 3</ref> with beam size 50. The breakdown of the three kinds of errors is shown in <ref type="table" target="#tab_3">Table 4</ref>. The first row gives WERs where no language model fusion is applied. The second row is after integrating the look-ahead word-based language model, with its optimal LM fusion weight 0.5. Although it has already significantly reduced the overall WER, deletion errors increase. Further applying the improved coverage yields better performance by suppressing deletion errors. If we only use the first term in Eq. (6) which is equivalent to the coverage term in <ref type="bibr" target="#b40">[41]</ref>, the insertions errors will increase from 0.8 to 1.3 on dev93, and from 0.6 to 0.9 on eval92. A manual inspection of the decoded results reveals that these additional insertions are mostly repeated words. This observation validates the effectiveness of our improved coverage mechanism. Alternatively, if we apply the EOS threshold, we achieve state-of-the-art performance on WSJ among end-to-end models. LibriSpeech SentencePiece is used as the subword units in our LibriSpeech setup for both external language modeling and encoderdecoder model. We combine dev-clean and dev-other sets together as a single validation set for both language model and encoderdecoder model training.</p><p>Again, we report the perplexities on the validation / evaluation sets. ESPRESSO obtains 35.4 and 37.3 on the dev-clean and devother sets, and 37.2 and 37.2 on test-clean and test-other.</p><p>Uniform smoothing with p = 0.1 is applied throughout the entire training. No scheduled sampling is used. The vanilla shallow fusion is used without the "look-ahead" technique. The results, along with several baseline systems, are demonstrated and compared in <ref type="table">Table 5</ref>,</p><p>We can see that both the improved coverage or EOS threshold help in this setup as well, where actually deletion error reductions contribute mostly. In addition, we achieve state-of-the-art results on end-to-end models for LibriSpeech without any data augmentation.</p><p>Switchboard The vocabulary consists of 1,000 subword units segmented by SentencePiece 11 trained on both Switchboard and Fisher transcripts. As there is no official validation set, we hold out the same 4,000-example subset of the training data as in Kaldi for validation. We apply scheduled sampling starting at epoch 6 with probability from 0.9 to 0.6. Uniform smoothing is used with p = 0.1.</p><p>The language model achieves a validation perplexity of 17.3. No coverage is used during decoding. The results of our current system and 3 other competitive end-to-end baselines are shown in <ref type="table">Table 6</ref>. Again, we obtain state-of-the-art results without SpecAugment. The coverage term or EOS threshold does not help on this dataset, and we suspect it is because its optimal LM fusion weight is not as large as those for the other two datasets, resulting in less deletion errors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">TRAINING AND DECODING SPEED</head><p>In this section we compare ESPRESSO and ESPNET on the training and decoding time with single GPU, using the WSJ dataset.</p><p>For fair comparison, we create architectures in ESPRESSO (different from those in Section 4) that mimics the WSJ recipe in ESPNET as closely as possible. Data preparation and vocabulary building are identical. The neural architecture is mostly the same (e.g. number and dimension of LSTM layers), with a few minor exceptions: e.g. ESPNET's use of location-based attention (which ESPRESSO does not employ), pooling CNN layers (ESPRESSO uses strided CNN without pooling), and joint cross-entropy+CTC loss (ESPRESSO uses only cross-entropy loss). <ref type="table">Table 7</ref> gives training wall time comparisons on both the external word-based language model and the encoder-decoder model, which are averaged over 20 epochs and 15 epochs respectively. ESPRESSO is 17.9% faster than ESPNET on the language model training, and 16.0% faster on the encoder-decoder model training. We conjecture that the main reason of such speed gain for language model training is that in FAIRSEQ (and hence in ESPRESSO) training examples are sorted based on input sequence lengths before batching (i.e., bucketing; ESPNET does not use it for language modeling), so that the average sequence length in batches is smaller.</p><p>A notable advantage of ESPRESSO compared to ESPNET is the decoding speed. In order to have a more fair comparison, we enable GPU batch decoding in ESPNET <ref type="bibr" target="#b60">[61]</ref>, and make batch and beam sizes of the two systems the same. We measure the decoding time on the WSJ eval92 data set, which consists of 333 utterances. <ref type="table">Table 7</ref> shows that, without language model fusion, ESPRESSO is 3.7× faster than ESPNET. With the look-ahead language model fusion, the speedup is even more prominent-more than 10× faster-mostly due to our parallelized implementation of the look-ahead language model fusion (cf. Section 3.1), as opposed to ESPNET, where LM scores are computed iteratively over examples within a minibatch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">CONCLUSION</head><p>In this paper we present ESPRESSO, an open-source end-to-end ASR toolkit built on top of FAIRSEQ, an extensible neural machine translation toolkit. In addition to advantages inherited from FAIRSEQ, ESPRESSO supports various other features for ASR that are seam-lessly integrated with FAIRSEQ, including reading data in Kaldi format, and efficient parallelized language model-fused decoding. We also provide ASR recipes for WSJ, LibriSpeech, and Switchboard data sets, and achieve state-of-the-art performance among end-toend systems. By sharing the underlying infrastructure with FAIRSEQ, we hope ESPRESSO will facilitate future joint research in speech and natural language processing, especially in sequence transduction tasks such as speech translation and speech synthesis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>4k9c030b REF: "QUOTE AN EYE FOR AN EYE "UNQUOTE HYP: "QUOTE AN EYE FOR ANY "</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>The efficient look-ahead LM algorithm. The dark gray and light gray subtrees correspond to the probability mass spanned by prefix pc and p (numerator and denominator in Eq. (1)) respectively. These can be efficiently computed via Eq. (4) using cumsum.(iii) Get all possible successive states; (iv) Get all upper and lower bounds for all successive states;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Popular end-to-end neural ASR systems and our system.</figDesc><table><row><cell>Name</cell><cell cols="2">Language Deep Learning Framework</cell><cell>Recipes</cell><cell>Other Applications</cell></row><row><cell>EESEN [14]</cell><cell>C++</cell><cell>-</cell><cell>WSJ, LibriSpeech, SWBD, TED-LIUM, HKUST</cell><cell>-</cell></row><row><cell>ESPNET [11]</cell><cell>Python</cell><cell>Chainer &amp; PyTorch</cell><cell>various</cell><cell>TTS, ST</cell></row><row><cell>E2E LF-MMI [15]</cell><cell>C++</cell><cell>Kaldi</cell><cell>various</cell><cell>-</cell></row><row><cell>LINGVO [16]</cell><cell>Python</cell><cell>TensorFlow</cell><cell>LibriSpeech</cell><cell>NMT</cell></row><row><cell>OPENSEQ2SEQ [9]</cell><cell>Python</cell><cell>TensorFlow</cell><cell>LibriSpeech</cell><cell>NMT, TTS</cell></row><row><cell>RETURNN [17]</cell><cell>Python</cell><cell>Theano, TensorFlow</cell><cell>WSJ, LibriSpeech, SWBD, CHiME</cell><cell>NMT</cell></row><row><cell>WAV2LETTER++ [18]</cell><cell>C++</cell><cell>ArrayFire</cell><cell>WSJ, LibriSpeech, TIMIT</cell><cell>-</cell></row><row><cell>ESPRESSO</cell><cell>Python</cell><cell>PyTorch</cell><cell>WSJ, LibriSpeech, SWBD</cell><cell>NMT</cell></row><row><cell cols="2">2.1. Input format and dataset classes</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Our speech data follows the format in Kaldi, where utterances</cell><cell></cell><cell></cell></row><row><cell cols="3">are stored in the Kaldi-defined SCP format, consisting of space-</cell><cell></cell><cell></cell></row><row><cell cols="2">delimited lines that follows this template:</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">&lt;UttID&gt; &lt;FeatureFile&gt;:&lt;Offset&gt;</cell><cell></cell><cell></cell></row></table><note>1 https://github.com/freewym/espresso.2 After our submission, FAIRSEQ released their official ASR support in https://github.com/pytorch/fairseq/tree/master/examples/ speech_recognition, and a Transformer-based LibriSpeech recipe [19].To appear in Proc. ASRU 2019, December 14-18, 2019, Sentosa, Singapore c IEEE 2019</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Hyper-parameters for the three recipes.</figDesc><table><row><cell>Hyper-parameter</cell><cell cols="2">WSJ</cell><cell cols="2">LibriSpeech</cell><cell cols="2">SWBD</cell></row><row><cell></cell><cell>LM</cell><cell>ASR</cell><cell>LM</cell><cell>ASR</cell><cell>LM</cell><cell>ASR</cell></row><row><cell>Vocab. size</cell><cell>65k</cell><cell>52</cell><cell>5k</cell><cell>5k</cell><cell>1k</cell><cell>1k</cell></row><row><cell>Encoder # layers</cell><cell>-</cell><cell>3</cell><cell>-</cell><cell>4</cell><cell>-</cell><cell>4</cell></row><row><cell>Decoder # layers</cell><cell>3</cell><cell>3</cell><cell>4</cell><cell>3</cell><cell>3</cell><cell>3</cell></row><row><cell cols="2">Emb. dim. 1,200</cell><cell>48</cell><cell>800</cell><cell cols="2">1,024 1,800</cell><cell>640</cell></row><row><cell cols="2">Hidden dim. 1,200</cell><cell>320</cell><cell>800</cell><cell cols="2">1,024 1,800</cell><cell>640</cell></row><row><cell cols="3"># Params. 113M 18M</cell><cell>25M</cell><cell>174M</cell><cell>80M</cell><cell>70M</cell></row><row><cell>Dropout rate</cell><cell>0.35</cell><cell>0.4</cell><cell>0.0</cell><cell>0.3</cell><cell>0.3</cell><cell>0.5</cell></row><row><cell>Avg. batch size</cell><cell>435</cell><cell>48</cell><cell>1,733</cell><cell>34</cell><cell>1,783</cell><cell>69</cell></row><row><cell>Beam size</cell><cell>50</cell><cell></cell><cell>60</cell><cell></cell><cell>35</cell><cell></cell></row><row><cell>LM fusion weight</cell><cell>0.9</cell><cell></cell><cell cols="2">0.47</cell><cell cols="2">0.25</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>WERs (%) on the WSJ dev93 and eval92 set.</figDesc><table><row><cell>dev93 eval92</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Breakdown of the WERs (%) on WSJ.</figDesc><table><row><cell></cell><cell></cell><cell>dev93</cell><cell></cell><cell>eval92</cell></row><row><cell></cell><cell cols="4">Sub Ins Del Sub Ins Del</cell></row><row><cell>ESPRESSO LSTM</cell><cell cols="3">12.0 1.4 1.4</cell><cell>9.7 1.5 1.0</cell></row><row><cell>+Look-ahead Word LM</cell><cell>4.6</cell><cell cols="2">0.8 2.0</cell><cell>3.1 0.7 1.3</cell></row><row><cell>+Improved Coverage</cell><cell>4.3</cell><cell cols="2">0.8 0.8</cell><cell>2.7 0.6 0.3</cell></row><row><cell>+EOS Threshold</cell><cell>4.1</cell><cell cols="2">0.9 0.8</cell><cell>2.6 0.5 0.3</cell></row><row><cell cols="5">Table 5. WERs (%) on the LibriSpeech dev and test sets.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>dev</cell><cell>test</cell></row><row><cell></cell><cell></cell><cell cols="3">clean other clean other</cell></row><row><cell>Zeghidour et al. [54]</cell><cell></cell><cell cols="3">3.1 10.0 3.3 10.5</cell></row><row><cell>Hannun at al. [21]</cell><cell></cell><cell cols="3">3.0 8.9 3.3 9.8</cell></row><row><cell cols="3">Park et al. [42] (w/o SpecAugment)</cell><cell>-</cell><cell>-</cell><cell>3.2 9.8</cell></row><row><cell>Lüscher et al. [58]</cell><cell></cell><cell cols="3">2.6 8.4 2.8 9.3</cell></row><row><cell>ESPRESSO LSTM</cell><cell></cell><cell cols="3">3.8 11.5 4.0 12.0</cell></row><row><cell>+Subword LM</cell><cell></cell><cell cols="3">3.3 8.9 3.4 9.5</cell></row><row><cell>+Improved Coverage</cell><cell></cell><cell cols="3">2.9 8.8 3.2 9.0</cell></row><row><cell>+EOS Threshold</cell><cell></cell><cell cols="3">2.8 8.4 2.8 8.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 .Table 7 .</head><label>67</label><figDesc>WERs (%) on the SWBD Hub5'00 evaluation set. Training (per epoch) and decoding wall time on WSJ.</figDesc><table><row><cell>Switchboard CallHome</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/google/sentencepiece.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">This is the token with the maximum posterior probability resulting from the previous LSTM decoder step. It may not necessarily be gold.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">It includes 45 characters constituting the training transcripts, plus 3 atomic symbols: &lt;*IN*&gt;, &lt;*MR.*&gt; and &lt;NOISE&gt;, plus 4 special symbols: &lt;pad&gt;, &lt;eos&gt;, &lt;unk&gt; and &lt;space&gt;.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">This is a hybrid system. "End-to-end" here is in the sense that it does not need HMM-GMM training or tree-building steps.<ref type="bibr" target="#b8">9</ref> The result is with "full bichar" (using all possible 2-gram characters as context-dependent modeling units), data speed-perturbation, and a 3-gram word language model.<ref type="bibr" target="#b9">10</ref> It uses 12,000 hours transcribed data for acoustic model training and large crawled text for language model training, making it not comparable.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">It includes additional special tokens [laughter], [noise], and [vocalized-noise].</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The kaldi speech recognition toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnab</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gilles</forename><surname>Boulianne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Glembek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagendra</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirko</forename><surname>Hannemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Motlicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanmin</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petr</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASRU</title>
		<meeting>ASRU</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Automatic Speech Recognition: A Deep Learning Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Springer Publishing Company</publisher>
		</imprint>
	</monogr>
	<note>Incorporated</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Towards end-to-end speech recognition with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">End-to-end continuous speech recognition using attention-based recurrent NN: first results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1412.1602</idno>
	</analytic>
	<monogr>
		<title level="m">Deep Learning and Representation Learning Workshop, NeurIPS</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Listen, attend and spell: A neural network for large vocabulary conversational speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Moses: Open source toolkit for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Hoang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brooke</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wade</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL: Demo and Poster Sessions</title>
		<meeting>ACL: Demo and Poster Sessions</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Joshua: An open source toolkit for parsing-based machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juri</forename><surname>Ganitkevitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lane</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">G</forename><surname>Wren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Thornton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><forename type="middle">F</forename><surname>Weese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zaidan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Fourth Workshop on Statistical Machine Translation</title>
		<meeting>the Fourth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">OpenNMT: Open-source toolkit for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntian</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Senellart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL: System Demonstrations</title>
		<meeting>ACL: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">OpenSeq2Seq: Extensible toolkit for distributed and mixed precision training of sequence-to-sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksii</forename><surname>Kuchaiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Gitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaly</forename><surname>Lavrukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Case</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paulius</forename><surname>Micikevicius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop for NLP Open Source Software (NLP-OSS)</title>
		<meeting>Workshop for NLP Open Source Software (NLP-OSS)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">fairseq: A fast, extensible toolkit for sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NAACL-HLT: Demonstrations</title>
		<meeting>NAACL-HLT: Demonstrations</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ESPnet: End-to-end speech processing toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shigeki</forename><surname>Karita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoki</forename><surname>Hayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiro</forename><surname>Nishitoba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuya</forename><surname>Unno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nelson</forename><forename type="middle">Enrique</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yalta</forename><surname>Soplin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jahn</forename><surname>Heymann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Wiesner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanxin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adithya</forename><surname>Renduchintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsubasa</forename><surname>Ochiai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Autodiff Workshop</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Chainer: a next-generation open source framework for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiya</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenta</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohei</forename><surname>Hido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Workshop on Machine Learning Systems (LearningSys) in NeurIPS</title>
		<meeting>Workshop on Machine Learning Systems (LearningSys) in NeurIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">EESEN: end-to-end speech recognition using deep RNN models and wfst-based decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajie</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Gowayyed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Metze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASRU</title>
		<meeting>ASRU</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">End-to-end speech recognition using lattice-free MMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Hadian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Sameti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Lingvo: a modular and scalable framework for sequence-to-sequence modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<idno>abs/1902.08295</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">RE-TURNN as a generic flexible neural toolkit with application to translation and speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamer</forename><surname>Alkhouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL, System Demonstrations</title>
		<meeting>ACL, System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Wav2letter++: A fast open-source speech recognition system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineel</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Awni</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiantong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaliy</forename><surname>Liptchinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Okhonko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transformers with convolutional context for ASR</title>
		<imprint>
			<date type="published" when="1904" />
		</imprint>
	</monogr>
	<note>CoRR</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">End-to-end speech recognition with word-based RNN language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaejin</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SLT</title>
		<meeting>SLT</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sequence-to-sequence speech recognition with time-depth separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Awni</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiantong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The design for the wall street journal-based CSR corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janet</forename><forename type="middle">M</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICSLP</title>
		<meeting>ICSLP</meeting>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Librispeech: An ASR corpus based on public domain audio books</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vassil</forename><surname>Panayotov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoguo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Switchboard: Telephone speech corpus for research and development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Godfrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Holliman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Neural speech recognizer: Acoustic-to-word LSTM model for large vocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagen</forename><surname>Soltau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hank</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hasim</forename><surname>Sak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of INTERSPEECH</title>
		<meeting>of INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Building competitive direct acoustics-to-word models for english conversational speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Audhkhasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuvana</forename><surname>Ramabhadran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Saon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Picheny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Neural machine translation of rare words with subword units</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rico</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Birch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Subword regularization: Improving neural network translation models with multiple subword candidates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Effective approaches to attention-based neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hieu</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for end-to-end speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Bidirectional LSTM networks for improved phoneme classification and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Fernández</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICANN</title>
		<meeting>ICANN</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Macherey</surname></persName>
		</author>
		<idno>abs/1609.08144</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Scheduled sampling for sequence prediction with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Promising accurate prefix boosting for sequence-to-sequence ASR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukáš</forename><surname>Murali Karthick Baskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Martin Karafit, Takaaki Hori, and Jan HonzaČernocký</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">When does label smoothing help?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="1906" />
		</imprint>
	</monogr>
	<note>Hinton</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Regularizing neural networks by penalizing confident output distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR, Workshop Track</title>
		<meeting>ICLR, Workshop Track</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Towards better decoding and language model integration in sequence to sequence models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">SpecAugment: A simple data augmentation method for automatic speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Cheng</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An analysis of incorporating an external language model into a sequence-tosequence model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhijeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Prabhavalkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">On using monolingual corpora in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Orhan</forename><surname>Ç Aglar Gülçehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Loïc</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huei-Chi</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fethi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
		<idno>abs/1503.03535</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A comparison of techniques for language model integration in encoderdecoder speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubham</forename><surname>Toshniwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuli</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chung-Cheng</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tara</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SLT</title>
		<meeting>SLT</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multilevel language modeling and decoding for open vocabulary end-to-end speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">R</forename><surname>Hershey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ASRU</title>
		<meeting>ASRU</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Parallelizable stack long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuoyang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. the Third Workshop on Structured Prediction for NLP</title>
		<meeting>the Third Workshop on Structured Prediction for NLP</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">End-to-end attention-based large vocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dzmitry</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitriy</forename><surname>Serdyuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Philemon Brakel, and Yoshua Bengio</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Using the output embedding to improve language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ofir</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EACL</title>
		<meeting>EACL</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Curriculum learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérôme</forename><surname>Louradour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Audio augmentation for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Ko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijayaditya</forename><surname>Peddinti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Purely sequence-trained neural networks for ASR based on lattice-free MMI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijayaditya</forename><surname>Peddinti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Galvez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pegah</forename><surname>Ghahremani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vimal</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Na</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiming</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Fully convolutional speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Zeghidour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiantong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaliy</forename><surname>Liptchinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<idno>abs/1812.06864</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Wav2letter: an end-to-end convnet-based speech recognition system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<idno>abs/1609.03193</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Who needs words? lexicon-free speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tatiana</forename><surname>Likhomanenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deep speech 2 : End-to-end speech recognition in english and mandarin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishita</forename><surname>Sundaram Ananthanarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingliang</forename><surname>Anubhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Battenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><surname>Case</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Casper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Catanzaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">RWTH ASR systems for LibriSpeech: Hybrid vs attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lüscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuki</forename><surname>Irie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Kitza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilfried</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Improving attention-based end-to-end ASR systems with sequence-based loss functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangsen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peidong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengzhu</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SLT</title>
		<meeting>SLT</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A comprehensive analysis on attention models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Zeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Merboldt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralf</forename><surname>Schlüter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IRASL Workshop</title>
		<meeting>IRASL Workshop<address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Vectorized beam search for CTCattention-based speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Seki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinji</forename><surname>Watanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niko</forename><surname>Moritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">Le</forename><surname>Roux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
