<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">GENERATIVE MULTI-ADVERSARIAL NETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Durugkar</surname></persName>
							<email>idurugkar@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01060</postCode>
									<settlement>Amherst Amherst</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Gemp</surname></persName>
							<email>imgemp@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01060</postCode>
									<settlement>Amherst Amherst</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sridhar</forename><surname>Mahadevan</surname></persName>
							<email>mahadeva@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">College of Information and Computer Sciences</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<postCode>01060</postCode>
									<settlement>Amherst Amherst</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">GENERATIVE MULTI-ADVERSARIAL NETWORKS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Generative adversarial networks (GANs) are a framework for producing a generative model by way of a two-player minimax game. In this paper, we propose the Generative Multi-Adversarial Network (GMAN), a framework that extends GANs to multiple discriminators. In previous work, the successful training of GANs requires modifying the minimax objective to accelerate training early on. In contrast, GMAN can be reliably trained with the original, untampered objective. We explore a number of design perspectives with the discriminator role ranging from formidable adversary to forgiving teacher. Image generation tasks comparing the proposed framework to standard GANs demonstrate GMAN produces higher quality samples in a fraction of the iterations when measured by a pairwise GAM-type metric.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Generative adversarial networks <ref type="bibr" target="#b10">(Goodfellow et al. (2014)</ref>) (GANs) are a framework for producing a generative model by way of a two-player minimax game. One player, the generator, attempts to generate realistic data samples by transforming noisy samples, z, drawn from a simple distribution (e.g., z ∼ N (0, 1)) using a transformation function G θ (z) with learned weights, θ. The generator receives feedback as to how realistic its synthetic sample is from another player, the discriminator, which attempts to discern between synthetic data samples produced by the generator and samples drawn from an actual dataset using a function D ω (x) with learned weights, ω.</p><p>The GAN framework is one of the more recent successes in a line of research on adversarial training in machine learning <ref type="bibr" target="#b25">(Schmidhuber (1992)</ref>; <ref type="bibr" target="#b2">Bagnell (2005)</ref>; <ref type="bibr" target="#b1">Ajakan et al. (2014)</ref>) where games between learners are carefully crafted so that Nash equilibria coincide with some set of desired optimality criteria. Preliminary work on GANs focused on generating images (e.g., <ref type="bibr">MNIST (LeCun et al. (1998)</ref>), CIFAR <ref type="bibr" target="#b15">(Krizhevsky (2009)</ref>)), however, GANs have proven useful in a variety of application domains including learning censored representations <ref type="bibr" target="#b8">(Edwards &amp; Storkey (2015)</ref>), imitating expert policies <ref type="bibr" target="#b11">(Ho &amp; Ermon (2016)</ref>), and domain transfer <ref type="bibr" target="#b29">(Yoo et al. (2016)</ref>). Work extending GANs to semi-supervised learning ; <ref type="bibr" target="#b20">Mirza &amp; Osindero (2014)</ref>; <ref type="bibr" target="#b9">Gauthier (2014)</ref>; Springenberg (2015)), inference <ref type="bibr" target="#b19">(Makhzani et al. (2015)</ref>; <ref type="bibr" target="#b7">Dumoulin et al. (2016)</ref>), feature learning <ref type="bibr" target="#b6">(Donahue et al. (2016)</ref>), and improved image generation <ref type="bibr" target="#b12">(Im et al. (2016)</ref>; <ref type="bibr" target="#b5">Denton et al. (2015)</ref>; <ref type="bibr" target="#b22">Radford et al. (2015)</ref>) have shown promise as well.</p><p>Despite these successes, GANs are reputably difficult to train. While research is still underway to improve training techniques and heuristics <ref type="bibr" target="#b24">(Salimans et al. (2016)</ref>), most approaches have focused on understanding and generalizing GANs theoretically with the aim of exploring more tractable formulations <ref type="bibr" target="#b31">(Zhao et al. (2016)</ref>; <ref type="bibr" target="#b17">Li et al. (2015)</ref>; <ref type="bibr" target="#b28">Uehara et al. (2016)</ref>; <ref type="bibr" target="#b21">Nowozin et al. (2016)</ref>).</p><p>In this paper, we theoretically and empirically justify generalizing the GAN framework to multiple discriminators. We review GANs and summarize our extension in Section 2. In Sections 3 and 4, we present our N -discriminator extension to the GAN framework (Generative Multi-Adversarial Networks) with several variants which range the role of the discriminator from formidable adversary to forgiving teacher. Section 4.2 explains how this extension makes training with the untampered minimax objective tractable. In Section 5, we define an intuitive metric (GMAM) to quantify GMAN Published as a conference paper at ICLR 2017 performance and evaluate our framework on a variety of image generation tasks. Section 6 concludes with a summary of our contributions and directions for future research.</p><p>Contributions-To summarize, our main contributions are: i) a multi-discriminator GAN framework, GMAN, that allows training with the original, untampered minimax objective; ii) a generative multi-adversarial metric (GMAM) to perform pairwise evaluation of separately trained frameworks; iii) a particular instance of GMAN, GMAN * , that allows the generator to automatically regulate training and reach higher performance (as measured by GMAM) in a fraction of the training time required for the standard GAN model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">GENERATIVE ADVERSARIAL NETWORKS TO GMAN</head><p>The original formulation of a GAN is a minimax game between a generator, G θ (z) : z → x, and a discriminator,</p><formula xml:id="formula_0">D ω (x) : x → [0, 1], min G max D∈D V (D, G) = E x∼p data (x) log(D(x)) + E z∼pz(z) log(1 − D(G(z))) ,<label>(1)</label></formula><p>where p data (x) is the true data distribution and p z (z) is a simple (usually fixed) distribution that is easy to draw samples from (e.g., N (0, 1)). We differentiate between the function space of discriminators, D, and elements of this space, D. Let p G (x) be the distribution induced by the generator, G θ (z). We assume D, G to be deep neural networks as is typically the case.</p><p>In their original work, <ref type="bibr" target="#b10">Goodfellow et al. (2014)</ref> proved that given sufficient network capacities and an oracle providing the optimal discriminator, D * = arg max D V (D, G), gradient descent on p G (x) will recover the desired globally optimal solution, p G (x) = p data (x), so that the generator distribution exactly matches the data distribution. In practice, they replaced the second term, log(1− D(G(z))), with − log(D(G(z))) to enhance gradient signals at the start of the game; note this is no longer a zero-sum game. Part of their convergence and optimality proof involves using the oracle, D * , to reduce the minimax game to a minimization over G only:</p><formula xml:id="formula_1">min G V (D * , G) = min G C(G) = − log(4) + 2 · JSD(p data ||p G )<label>(2)</label></formula><p>where JSD denotes Jensen-Shannon divergence. Minimizing C(G) necessarily minimizes JSD, however, we rarely know D * and so we instead minimize V (D, G), which is only a lower bound.</p><p>This perspective of minimizing the distance between the distributions, p data and p G , motivated <ref type="bibr" target="#b17">Li et al. (2015)</ref> to develop a generative model that matches all moments of p G (x) with p data (x) (at optimality) by minimizing maximum mean discrepancy (MMD). Another approach, EBGAN, <ref type="bibr" target="#b31">(Zhao et al. (2016)</ref>) explores a larger class of games (non-zero-sum games) which generalize the generator and discriminator objectives to take real-valued "energies" as input instead of probabilities. <ref type="bibr" target="#b21">Nowozin et al. (2016)</ref> and then <ref type="bibr" target="#b28">Uehara et al. (2016)</ref> extended the JSD perspective on GANs to more general divergences, specifically f -divergences and then Bregman-divergences respectively.</p><p>In general, these approaches focus on exploring fundamental reformulations of V (D, G). Similarly, our work focuses on a fundamental reformulation, however, our aim is to provide a framework that accelerates training of the generator to a more robust state irrespective of the choice of V .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">GMAN: A MULTI-ADVERSARIAL EXTENSION</head><p>We propose introducing multiple discriminators, which brings with it a number of design possibilities. We explore approaches ranging between two extremes: 1) a more discriminating D (better approximating max D V (D, G)) and 2) a D better matched to the generator's capabilities. Mathematically, we reformulate G's objective as min G max F (V (D 1 , G), . . . , V (D N , G)) for different choices of F (see <ref type="figure">Figure 1</ref>). Each D i is still expected to independently maximize its own V (D i , G) (i.e. no cooperation). We sometimes abbreviate</p><formula xml:id="formula_2">V (D i , G) with V i and F (V 1 , . . . , V N ) with F G (V i ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A FORMIDABLE ADVERSARY</head><p>Here, we consider multi-discriminator variants that attempt to better approximate max D V (D, G), providing a harsher critic to the generator. <ref type="figure">Figure 1</ref>: (GMAN) The generator trains using feedback aggregated over multiple discriminators. If F := max, G trains against the best discriminator. If F := mean, G trains against an ensemble. We explore other alternatives to F in Sections 4.1 &amp; 4.4 that improve on both these options.</p><formula xml:id="formula_3">G D N D 2 D 1 V(D N ,G) V(D 2 ,G) V(D 1 ,G) F(·)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">MAXIMIZING V(D,G)</head><p>For a fixed G, maximizing F G (V i ) with F := max and N randomly instantiated copies of our discriminator is functionally equivalent to optimizing V (e.g., stochastic gradient ascent) with random restarts in parallel and then presenting max i∈{1,...,N } V (D i , G) as the loss to the generator -a very pragmatic approach to the difficulties presented by the non-convexity of V caused by the deep net. Requiring the generator to minimize the max forces G to generate high fidelity samples that must hold up under the scrutiny of all N discriminators, each potentially representing a distinct max.</p><p>In practice, max Di∈D V (D i , G) is not performed to convergence (or global optimality), so the above problem is oversimplified. Furthermore, introducing N discriminators affects the dynamics of the game which affects the trajectories of the discriminators. This prevents us from claiming max{V 1 (t), . . . , V N (t)} &gt; max{V 1 (t)} ∀t even if we initalize D 1 (0) = D 1 (0) as it is unlikely that D 1 (t) = D 1 (t) at some time t after the start of the game.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">BOOSTING</head><p>We can also consider taking the max over N discriminators as a form of boosting for the discriminator's online classification problem (online because G can produce an infinite data stream). The boosted discriminator is given a sample x t and must predict whether it came from the generator or the dataset. The booster then makes its prediction using the predictions of the N weaker D i .</p><p>There are a few differences between taking the max (case 1) and online boosting (case 2). In case 1, our booster is limited to selecting a single weak discriminator (i.e. a pure strategy), while in case 2, many boosting algorithms more generally use linear combinations of the discriminators. Moreover, in case 2, a booster must make a prediction before receiving a loss function. In case 1, we assume access to the loss function at prediction time, which allows us to compute the max.</p><p>It is possible to train the weak discriminators using boosting and then ignore the booster's prediction by instead presenting max{V i }. We explore both variants in our experiments, using the adaptive algorithm proposed in <ref type="bibr" target="#b3">Beygelzimer et al. (2015)</ref>. Unfortunately, boosting failed to produce promising results on the image generation tasks. It is possible that boosting produces too strong an adversary for learning which motivates the next section. Boosting results appear in Appendix A.7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">A FORGIVING TEACHER</head><p>The previous perspectives focus on improving the discriminator with the goal of presenting a better approximation of max D V (D, G) to the generator. Our next perspective asks the question, "Is max D V (D, G) too harsh a critic?"</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Soft-DISCRIMINATOR</head><p>In practice, training against a far superior discriminator can impede the generator's learning. This is because the generator is unlikely to generate any samples considered "realistic" by the discriminator's standards, and so the generator will receive uniformly negative feedback. This is problem-atic because the information contained in the gradient derived from negative feedback only dictates where to drive down p G (x), not specifically where to increase p G (x). Furthermore, driving down p G (x) necessarily increases p G (x) in other regions of X (to maintain X p G (x) = 1) which may or may not contain samples from the true dataset (whack-a-mole dilemma). In contrast, a generator is more likely to see positive feedback against a more lenient discriminator, which may better guide a generator towards amassing p G (x) in approximately correct regions of X .</p><p>For this reason, we explore a variety of functions that allow us to soften the max operator. We choose to focus on soft versions of the three classical Pythagorean means parameterized by λ where λ = 0 corresponds to the mean and the max is recovered as λ → ∞:</p><formula xml:id="formula_4">AM sof t (V, λ) = N i w i V i (3) GM sof t (V, λ) = − exp N i w i log(−V i ) (4) HM sof t (V, λ) = N i w i V −1 i −1 (5) where w i = e λVi /Σ j e λVj with λ ≥ 0, V i &lt; 0.</formula><p>Using a softmax also has the well known advantage of being differentiable (as opposed to subdifferentiable for max). Note that we only require continuity to guarantee that computing the softmax is actually equivalent to computing V (D, G) whereD is some convex combination of D i (see Appendix A.5).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">USING THE ORIGINAL MINIMAX OBJECTIVE</head><p>To illustrate the effect the softmax has on training, observe that the component of AM sof t (V, 0) relevant to generator training can be rewritten as</p><formula xml:id="formula_5">1 N N i E x∼pG(x) log(1 − D i (x)) = 1 N E x∼pG(x) log(z) .<label>(6)</label></formula><p>where z = N i (1 − D i (x)). Note that the generator gradient, | ∂ log(z) ∂z |, is minimized at z = 1 over z ∈ (0, 1] 1 . From this form, it is clear that z = 1 if and only if D i = 0 ∀i, so G only receives a vanishing gradient if all D i agree that the sample is fake; this is especially unlikely for large N . In other words, G only needs to fool a single D i to receive constructive feedback. This result allows the generator to successfully minimize the original generator objective, log(1 − D). This is in contrast to the more popular − log(D) introduced to artificially enhance gradients at the start of training.</p><p>At the beginning of training, when max Di V (D i , G) is likely too harsh a critic for the generator, we can set λ closer to zero to use the mean, increasing the odds of providing constructive feedback to the generator. In addition, the discriminators have the added benefit of functioning as an ensemble, reducing the variance of the feedback presented to the generator, which is especially important when the discriminators are far from optimal and are still learning a reasonable decision boundary. As training progresses and the discriminators improve, we can increase λ to become more critical of the generator for more refined training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">MAINTAINING MULTIPLE HYPOTHESES</head><p>We argue for this ensemble approach on a more fundamental level as well. Here, we draw on the density ratio estimation perspective of GANs <ref type="bibr" target="#b28">(Uehara et al. (2016)</ref>). The original GAN proof assumes we have access to p data (x), if only implicitly. In most cases of interest, the discriminator only has access to a finite dataset sampled from p data (x); therefore, when computing expectations of V (D, G), we only draw samples from our finite dataset. This is equivalent to training a GAN with p data (x) =p data which is a distribution consisting of point masses on all the data points in the dataset. For the sake of argument, let's assume we are training a discriminator and generator, each</p><formula xml:id="formula_6">1 ∇GV = − i D i z ∂D i ∂G j =i (1 − Dj) = − 1 z ∂D k ∂G for D k = 1, D =k = 0. Our argument ignores ∂D k ∂G .</formula><p>with infinite capacity. In this case, the global optimum (p G (x) =p data(x) ) fails to capture any of the interesting structure from p data (x), the true distribution we are trying to learn. Therefore, it is actually critical that we avoid this global optimum.</p><p>x p(x) <ref type="figure">Figure 2</ref>: Consider a dataset consisting of the nine 1-dimensional samples in black. Their corresponding probability mass function is given in light gray. After training GMAN, three discriminators converge to distinct local optima which implicitly define distributions over the data <ref type="bibr">(red, blue, yellow)</ref>. Each discriminator may specialize in discriminating a region of the data space (placing more diffuse mass in other regions). Averaging over the three discriminators results in the distribution in black, which we expect has higher likelihood under reasonable assumptions on the structure of the true distribution.</p><p>In practice, this degenerate result is avoided by employing learners with limited capacity and corrupting data samples with noise (i.e., dropout), but we might better accomplish this by simultaneously training a variety of limited capacity discriminators. With this approach, we might obtain a diverse set of seemingly tenable hypotheses for the true p data (x). Averaging over these multiple locally optimal discriminators increases the entropy ofp data (x) by diffusing the probability mass over the data space (see <ref type="figure">Figure 2</ref> for an example).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">AUTOMATING REGULATION</head><p>The problem of keeping the discriminator and generator in balance has been widely recognized in previous work with GANs. Issues with unstable dynamics, oscillatory behavior, and generator collapse are not uncommon. In addition, the discriminator is often times able to achieve a high degree of classification accuracy (producing a single scalar) before the generator has made sufficient progress on the arguably more difficult generative task (producing a high dimensional sample). <ref type="bibr" target="#b24">Salimans et al. (2016)</ref> suggested label smoothing to reduce the vulnerability of the generator to a relatively superior discriminator. Here, we explore an approach that enables the generator to automatically temper the performance of the discriminator when necessary, but still encourages the generator to challenge itself against more accurate adversaries. Specifically, we augment the generator objective: min</p><formula xml:id="formula_7">G,λ&gt;0 F G (V i ) − f (λ)<label>(7)</label></formula><p>where f (λ) is monotonically increasing in λ which appears in the softmax equations, (3)-(5). In experiments, we simply set f (λ) = cλ with c a constant (e.g., 0.001). The generator is incentivized to increase λ to reduce its objective at the expense of competing against the best available adversary D * (see Appendix A.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EVALUATION</head><p>Evaluating GANs is still an open problem. In their original work, <ref type="bibr" target="#b10">Goodfellow et al. (2014)</ref> report log likelihood estimates from Gaussian Parzen windows, which they admit, has high variance and is known not to perform well in high dimensions. <ref type="bibr" target="#b27">Theis et al. (2016)</ref> recommend avoiding Parzen windows and argue that generative models should be evaluated with respect to their intended application. <ref type="bibr" target="#b24">Salimans et al. (2016)</ref> suggest an Inception score, however, it assumes labels exist for the dataset. Recently, Im et al. <ref type="formula" target="#formula_0">(2016)</ref> introduced the Generative Adversarial Metric (GAM) for making pairwise comparisons between independently trained GAN models. The core idea behind their approach is given two generator, discriminator pairs (G 1 , D 1 ) and (G 2 , D 2 ), we should be able to learn their relative performance by judging each generator under the opponent's discriminator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">METRIC</head><p>In GMAN, the opponent may have multiple discriminators, which makes it unclear how to perform the swaps needed for GAM. We introduce a variant of GAM, the generative multi-adversarial metric (GMAM), that is amenable to training with multiple discriminators,</p><formula xml:id="formula_8">GMAM = log F a G b (V a i ) F a Ga (V a i ) F a Ga (V b i ) F b G b (V b i ) .<label>(8)</label></formula><p>where a and b refer to the two GMAN variants (see Section 3 for notation F G (V i )). The idea here is similar. If G 2 performs better than G 1 with respect to both D 1 and D 2 , then GMAM&gt;0 (remember V ≤0 always). If G 1 performs better in both cases, GMAM&lt;0, otherwise, the result is indeterminate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">EXPERIMENTS</head><p>We evaluate the aforementioned variations of GMAN on a variety of image generation tasks: MNIST (LeCun et al. <ref type="formula" target="#formula_0">(1998)</ref>), CIFAR-10 (Krizhevsky (2009)) and CelebA <ref type="bibr" target="#b18">(Liu et al. (2015)</ref>). We focus on rates of convergence to steady state along with quality of the steady state generator according to the GMAM metric. To summarize, loosely in order of increasing discriminator leniency, we compare</p><p>• F-boost: A single AdaBoost.OL-boosted discriminator (see Appendix A.7).</p><p>• P-boost: D i is trained according to AdaBoost.OL. A max over the weak learner losses is presented to the generator instead of the boosted prediction (see Appendix A.7).</p><p>• GMAN-max: max{V i } is presented to the generator.</p><p>• GAN: Standard GAN with a single discriminator (see Appendix A.2).</p><p>• mod-GAN: GAN with modified objective (generator minimizes − log(D(G(z))).</p><p>• GMAN-λ: GMAN with F :=arithmetic softmax with parameter λ.</p><p>• GMAN * : The arithmetic softmax is controlled by the generator through λ.</p><p>All generator and discriminator models are deep (de)convolutional networks <ref type="bibr" target="#b22">(Radford et al. (2015)</ref>), and aside from the boosted variants, all are trained with Adam <ref type="bibr" target="#b14">(Kingma &amp; Ba (2014)</ref>) and batch normalization <ref type="bibr" target="#b13">(Ioffe &amp; Szegedy (2015)</ref>). Discriminators convert the real-valued outputs of their networks to probabilities with squashed-sigmoids to prevent saturating logarithms in the minimax objective ( + 1−2 1+e −z ). See Appendix A.8 for further details. We test GMAN systems with N = {2, 5} discriminators. We maintain discriminator diversity by varying dropout and network depth. <ref type="figure" target="#fig_0">Figure 3</ref> reveals that increasing the number of discriminators reduces the number of iterations to steady-state by 2x on MNIST; increasing N (the size of the discriminator ensemble) also has the added benefit of reducing the variance the minimax objective over runs. <ref type="figure" target="#fig_1">Figure 4</ref> displays the variance of the same objective over a sliding time window, reaffirming GMAN's acceleration to steadystate. <ref type="figure" target="#fig_2">Figure 5</ref> corroborates this conclusion with recognizable digits appearing approximately an epoch before the single discriminator run; digits at steady-state appear slightly sharper as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">MNIST</head><p>Our GMAM metric (see <ref type="table" target="#tab_0">Table 1</ref>) agrees with the relative quality of images in <ref type="figure" target="#fig_2">Figure 5</ref> with GMAN * achieving the best overall performance. <ref type="figure" target="#fig_3">Figure 6</ref>      </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">CELEBA &amp; CIFAR-10</head><p>We see similar accelerated convergence behavior for the CelebA dataset in <ref type="figure" target="#fig_4">Figure 8</ref>.   We also found that GMAN is robust to mode collapse. We believe this is because the generator must appease a diverse set of discriminators in each minibatch. Emitting a single sample will score well for one discriminator at the expense of the rest of the discriminators. Current solutions (e.g., minibatch discrimination) are quadratic in batch size. GMAN, however, is linear in batch size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We introduced multiple discriminators into the GAN framework and explored discriminator roles ranging from a formidable adversary to a forgiving teacher. Allowing the generator to automatically tune its learning schedule (GMAN * ) outperformed GANs with a single discriminator on MNIST. In general, GMAN variants achieved faster convergence to a higher quality steady state on a variety of tasks as measured by a GAM-type metric (GMAM). In addition, GMAN makes using the original GAN objective possible by increasing the odds of the generator receiving constructive feedback.</p><p>In future work, we will look at more sophisticated mechanisms for letting the generator control the game as well as other ways to ensure diversity among the discriminators. Introducing multiple generators is conceptually an obvious next step, however, we expect difficulties to arise from more complex game dynamics. For this reason, game theory and game design will likely be important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A APPENDIX</head><p>A.1 ACCELERATED CONVERGENCE &amp; REDUCED VARIANCE See <ref type="figure" target="#fig_7">Figures 10, 11, 12</ref>, and 13. <ref type="figure">Figure 10</ref>: Generator objective, F , averaged over 5 training runs on CelebA. Increasing N (# of D) accelerates convergence of F to steady state (solid line) and reduces its variance, σ 2 (filled shadow ±1σ). <ref type="figure" target="#fig_7">Figure 11</ref> provides alternative evidence of GMAN-0's accelerated convergence.        <ref type="table">Table 5</ref>: Pairwise GMAM metric means for select models on CIFAR-10. For each column, a positive GMAM indicates better performance relative to the row opponent; negative implies worse. Scores are obtained by summing each column. GMAN variants were trained with five discriminators.</p><p>GMAN-1 GMAN-0 GMAN * mod-GAN Score 6.001 ± 0.194 5.957 ± 0.135 5.955 ± 0.153 5.738 ± 0.176 <ref type="table">Table 6</ref>: Inception score means with standard deviations for select models on CIFAR-10. Higher scores are better. GMAN variants were trained with five discriminators.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 SOMEWHAT RELATED WORK</head><p>A GAN framework with two discriminators appeared in <ref type="bibr" target="#b29">Yoo et al. (2016)</ref>, however, it is applicable only in a semi-supervised case where a label can be assigned to subsets of the dataset (e.g., X = {X 1 = Domain 1, X 2 = Domain 2, . . .}). In contrast, our framework applies to an unsupervised scenario where an obvious partition of the dataset is unknown. Furthermore, extending GMAN to the semi-supervised domain-adaptation scenario would suggest multiple discriminators per domain, therefore our line of research is strictly orthogonal to that of their multi-domain discriminator approach. Also, note that assigning a discriminator to each domain is akin to prescribing a new discriminator to each value of a conditional variable in conditional GANs <ref type="bibr" target="#b20">(Mirza &amp; Osindero (2014)</ref>). In this case, we interpret GMAN as introducing multiple conditional discriminators and not a discriminator for each of the possibly exponentially many conditional labels.</p><p>In Section 4.4, we describe an approach to customize adversarial training to better suit the development of the generator. An approach with similar conceptual underpinnings was described in <ref type="bibr" target="#b23">Ravanbakhsh et al. (2016)</ref>, however, similar to the above, it is only admissible in a semi-supervised scenario whereas our applies to the unsupervised case.</p><formula xml:id="formula_9">A.5 Softmax REPRESENTABILITY Let softmax(V i ) =V ∈ [min Vi , max Vi ]. Also let a = arg min i V i , b = arg max i V i , and V(t) = V ((1 − t)D a + tD b ) so that V(0) = V a and V(1) = V b .</formula><p>The softmax and minimax objective V (D i , G) are both continuous in their inputs, so by the intermediate value theorem, we have that ∃t ∈ [0, 1] s.t. V(t) =V , which implies ∃D ∈ D s.t. V (D, G) =V . This result implies that the softmax (and any other continuous substitute) can be interpreted as returning V (D, G) for somê D selected by computing an another, unknown function over the space of the discriminators. This result holds even ifD is not representable by the architecture chosen for D's neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.6 UNCONSTRAINED OPTIMIZATION</head><p>To convert GMAN * minimax formulation to an unconstrained minimax formulation, we introduce an auxiliary variable, Λ, define λ(Λ) = log(1 + e Λ ), and let the generator minimize over Λ ∈ R.</p><p>A.7 BOOSTING WITH AdaBoost.OL AdaBoost.OL <ref type="bibr" target="#b3">(Beygelzimer et al. (2015)</ref>) does not require knowledge of the weak learner's slight edge over random guessing (P (correct label) = 0.5 + γ ∈ (0, 0.5]), and in fact, allows γ &lt; 0. This is crucial because our weak learners are deep nets with unknown, possibly negative, γ's. <ref type="figure" target="#fig_3">Figure 16</ref>: Sample of pictures generated across 4 independent runs on MNIST with F-boost (similar results with P-boost).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.8 EXPERIMENTAL SETUP</head><p>All experiments were conducted using an architecture similar to DCGAN <ref type="bibr" target="#b22">(Radford et al. (2015)</ref>). We use convolutional transpose layers <ref type="bibr" target="#b30">(Zeiler et al. (2010)</ref>) for G and strided convolutions for D except for the input of G and the last layer of D. We use the single step gradient method as in <ref type="bibr" target="#b21">(Nowozin et al. (2016)</ref>), and batch normalization <ref type="bibr" target="#b13">(Ioffe &amp; Szegedy (2015)</ref>) was used in each of the generator layers. The different discriminators were trained with varying dropout rates from [0.3, 0.7]. Variations in the discriminators were effected in two ways. We varied the architecture by varying the number of filters in the discriminator layers (reduced by factors of 2, 4 and so on), as well as varying dropout rates. Secondly we also decorrelated the samples that the disriminators were training on by splitting the minibatch across the discriminators. The code was written in Tensorflow <ref type="bibr" target="#b0">(Abadi et al. (2016)</ref>) and run on Nvidia GTX 980 GPUs. Code to reproduce experiments and plots is at https://github.com/iDurugkar/GMAN. Specifics for the MNIST architecture and training are:</p><p>• Generator latent variables z ∼ U (−1, 1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>100</head><p>• Generator convolution transpose layers: (4, 4, 128) , <ref type="bibr">(8, 8, 64) , (16, 16, 32)</ref> , (32, 32, 1)</p><p>• Base Discriminator architecture: (32, 32, 1) , <ref type="bibr">(16, 16, 32) , (8, 8, 64)</ref> , (4, 4, 128).</p><p>• Variants have either convolution 3 (4, 4, 128) removed or all the filter sizes are divided by 2 or 4. That is, (32, 32, 1) , <ref type="bibr">(16, 16, 16) , (8, 8, 32)</ref> , (4, 4, 64) or (32, 32, 1) , <ref type="bibr">(16, 16, 8) , (8, 8, 16) , (4, 4, 32)</ref>.</p><p>• ReLu activations for all the hidden units. Tanh activation at the output units of the generator.</p><p>Sigmoid at the output of the Discriminator.</p><p>• Training was performed with Adam <ref type="bibr" target="#b14">(Kingma &amp; Ba (2014)</ref>) (lr = 2 × 10 −4 , β 1 = 0.5).</p><p>• MNIST was trained for 20 epochs with a minibatch of size 100.</p><p>• CelebA and CIFAR were trained over 24000 iterations with a minibatch of size 100.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Generator objective, F , averaged over 5 training runs on MNIST. Increasing the number of discriminators accelerates convergence of F to steady state (solid line) and reduces its variance, σ 2 (filled shadow ±1σ).Figure 4provides alternative evidence of GMAN * 's accelerated convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Stdev, σ, of the generator objective over a sliding window of 500 iterations. Lower values indicate a more steady-state. GMAN * with N = 5 achieves steady-state at ≈2x speed of GAN (N = 1). Note Figure 3's filled shadows reveal stdev of F over runs, while this plot shows stdev over time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Comparison of image quality across epochs for N = {1, 2, 5} using GMAN-0 on MNIST.of the game to accelerate learning.Figure 7displays the GMAM scores comparing fixed λ's to the variable λ controlled by GMAN * .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>GMAN * regulates difficulty of the game by adjusting λ. Initially, G reduces λ to ease learning and then gradually increases λ for a more challenging learning environment. stdev(GMAM) for GMAN-λ and GMAN * (λ * ) over 5 runs on MNIST.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 :</head><label>8</label><figDesc>Image quality improvement across number of generators at same number of iterations for GMAN-0 on CelebA.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 9</head><label>9</label><figDesc>displays images generated by GMAN-0 on CIFAR-10. See Appendix A.3 for more results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 :</head><label>9</label><figDesc>Images generated by GMAN-0 on the CIFAR-10 dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 :</head><label>11</label><figDesc>Stdev, σ, of the generator objective over a sliding window of 500 iterations. Lower values indicate a more steady-state. GMAN-0 with N = 5 achieves steady-state at ≈2x speed of GAN (N = 1). Note Figure 10's filled shadows reveal stdev of F over runs, while this plot shows stdev over time.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 12 :</head><label>12</label><figDesc>Generator objective, F , averaged over 5 training runs on CIFAR-10. Increasing N (# of D) accelerates convergence of F to steady state (solid line) and reduces its variance, σ 2 (filled shadow ±1σ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Figure 13provides alternative evidence of GMAN-0's accelerated convergence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 13 :</head><label>13</label><figDesc>Stdev, σ, of the generator objective over a sliding window of 500 iterations. Lower values indicate a more steady-state. GMAN-0 with N = 5 achieves steady-state at ≈2x speed of GAN (N = 1). Note Figure 12's filled shadows reveal stdev of F over runs, while this plot shows stdev over time. A.2 ADDITIONAL GMAM TABLESSee Tables 2, 3, 4, 5, 6. Increasing the number of discriminators from 2 to 5 on CIFAR-10 significantly improves scores over the standard GAN both in terms of the GMAM metric and Inception scores.A.3 GENERATED IMAGES SeeFigures 14 and 15.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 14 :</head><label>14</label><figDesc>Sample of pictures generated on CelebA cropped dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 15 :</head><label>15</label><figDesc>Sample of pictures generated by GMAN-0 on CIFAR dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>reveals GMAN * 's attempt to regulate the difficulty</figDesc><table><row><cell>Better→</cell><cell>Score 0.127 0.007 −0.034 GMAN-max 0.028 ± 0.019 Variant GMAN  *  GMAN  *  -GMAN-0 0.020 ± 0.009 −0.122 mod-GAN 0.089 ± 0.036</cell><cell>GMAN-0 −0.020 ± 0.009 −0.028 ± 0.019 −0.089 ± 0.036 GMAN-max mod-GAN -−0.013 ± 0.015 −0.018 ± 0.027 0.013 ± 0.015 -−0.011 ± 0.024 0.018 ± 0.027 0.011 ± 0.024 -</cell></row></table><note>: Pairwise GMAM metric means with stdev for select models on MNIST. For each column, a positive GMAM indicates better performance relative to the row opponent; negative implies worse. Scores are obtained by summing each variant's column.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Pairwise GMAM metric means for select models on CIFAR-10. For each column, a positive GMAM indicates better performance relative to the row opponent; negative implies worse. Scores are obtained by summing each column. GMAN variants were trained with two discriminators. Score 5.878 ± 0.193 5.765 ± 0.168 5.738 ± 0.176 5.539 ± 0.099</figDesc><table><row><cell>GMAN-0</cell><cell>GMAN-1</cell><cell>mod-GAN</cell><cell>GMAN</cell></row></table><note>*</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Inception score means with standard deviations for select models on CIFAR-10. Higher scores are better. GMAN variants were trained with two discriminators.</figDesc><table><row><cell>Better→</cell><cell>Score 0.180 0.122 0.010 −0.313 mod-GAN Variant GMAN-0 GMAN  *  GMAN-1</cell><cell>GMAN-0 GMAN  *  GMAN-1 mod-GAN -−0.008 −0.041 −0.132 0.008 -−0.038 −0.092 0.041 0.038 -−0.089 0.132 0.092 0.089 -</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We acknowledge helpful conversations with Stefan Dernbach, Archan Ray, Luke Vilnis, Ben Turtel, Stephen Giguere, Rajarshi Das, and Subhransu Maji. We also thank NVIDIA for donating a K40 GPU. This material is based upon work supported by the National Science Foundation under Grant Nos. IIS-1564032. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the NSF.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martın</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Craig</forename><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<title level="m">Large-scale machine learning on heterogeneous distributed systems</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hana</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">François</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Marchand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.4446</idno>
		<title level="m">Domain-adversarial neural networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Robust supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Bagnell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Of The National Conference On Artificial Intelligence</title>
		<meeting>Of The National Conference On Artificial Intelligence<address><addrLine>Menlo Park, CA; Cambridge, MA; London</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">714</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Optimal and adaptive algorithms for online boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alina</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Satyen</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haipeng</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.02651</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rein</forename><surname>Houthooft</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03657</idno>
		<title level="m">Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable representation learning by information maximizing generative adversarial nets</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep generative image models using a laplacian pyramid of adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Emily L Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1486" to="1494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krähenbühl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.09782</idno>
		<title level="m">Adversarial feature learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishmael</forename><surname>Vincent Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Mastropietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Courville</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00704</idno>
		<title level="m">Adversarially learned inference</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05897</idno>
		<title level="m">Censoring representations with an adversary</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Conditional generative adversarial nets for convolutional face generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Gauthier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Convolutional Neural Networks for Visual Recognition</title>
		<imprint>
			<publisher>Winter semester</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">231</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03476</idno>
		<title level="m">Generative adversarial imitation learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">Dongjoo</forename><surname>Daniel Jiwoong Im</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Memisevic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1602.05110</idno>
		<title level="m">Generating images with recurrent adversarial networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Master&apos;s Thesis</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burges</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative moment matching networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1718" to="1727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Makhzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Navdeep</forename><surname>Jaitly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.05644</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Adversarial autoencoders. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1784</idno>
		<title level="m">Conditional generative adversarial nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka. F-Gan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.00709</idno>
		<title level="m">Training generative neural samplers using variational divergence minimization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06434</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Enabling dark energy science with deep generative models of galaxy images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siamak</forename><surname>Ravanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francois</forename><surname>Lanusse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rachel</forename><surname>Mandelbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barnabas</forename><surname>Poczos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.05796</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vicki</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03498</idno>
		<title level="m">Improved techniques for training gans</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning factorial codes by predictability minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="863" to="879" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Unsupervised and semi-supervised learning with categorical generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Tobias Springenberg</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06390</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Theis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.01844v3</idno>
		<title level="m">Aäron van den Oord, and Matthias Bethge. A note on the evaluation of generative models</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Generative adversarial nets from a density ratio estimation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Uehara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masahiro</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kotaro</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><surname>Matsuo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.02920</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donggeun</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Namil</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunggyun</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Anthony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">In</forename><forename type="middle">So</forename><surname>Paek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kweon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.07442</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Pixel-level domain transfer. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deconvolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Matthew D Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2528" to="2535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Energy-based generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Mathieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.03126</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
