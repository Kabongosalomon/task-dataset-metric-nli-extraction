<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards More Accurate Automatic Sleep Staging via Deep Transfer Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-08">Aug 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huy</forename><surname>Phan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><forename type="middle">Y</forename><surname>Chén</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koch</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongqing</forename><surname>Lu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Mcloughlin</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Mertins</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>De Vos</surname></persName>
						</author>
						<title level="a" type="main">Towards More Accurate Automatic Sleep Staging via Deep Transfer Learning</title>
					</analytic>
					<monogr>
						<title level="m">THIS ARTICLE HAS BEEN PUBLISHED IN IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING 1</title>
						<imprint>
							<date type="published" when="2020-08">Aug 2020</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Automatic sleep staging</term>
					<term>sequence-to- sequence</term>
					<term>deep learning</term>
					<term>transfer learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Background: Despite recent significant progress in the development of automatic sleep staging methods, building a good model still remains a big challenge for sleep studies with a small cohort due to the data-variability and data-inefficiency issues. This work presents a deep transfer learning approach to overcome these issues and enable transferring knowledge from a large dataset to a small cohort for automatic sleep staging. Methods: We start from a generic end-to-end deep learning framework for sequence-to-sequence sleep staging and derive two networks as the means for transfer learning. The networks are first trained in the source domain (i.e. the large database). The pretrained networks are then finetuned in the target domain (i.e. the small cohort) to complete knowledge transfer. We employ the Montreal Archive of Sleep Studies (MASS) database consisting of 200 subjects as the source domain and study deep transfer learning on three different target domains: the Sleep Cassette subset and the Sleep Telemetry subset of the Sleep-EDF Expanded database, and the Surrey-cEEGrid database. The target domains are purposely adopted to cover different degrees of data mismatch to the source domains. Results: Our experimental results show significant performance improvement on automatic sleep staging on the target domains achieved with the proposed deep transfer learning approach. Conclusions: These results suggest the efficacy of the proposed approach in addressing the above-mentioned data-variability and data-inefficiency issues. Significance: As a consequence, it would enable one to improve the quality of automatic sleep staging models when the amount of data is relatively small. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>this task has been mainly performed manually by clinicians following developed guidelines <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>. Since the manual scoring is time-consuming, costly, and prone to human errors, automating the scoring process has been a long-lasting focus in the sleep research community <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b9">[10]</ref>. Automatic sleep scoring is particularly important in home-based sleep monitoring <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b13">[14]</ref>. Recent years have seen a new generation of mobile electroencephalography (EEG) devices that provide a cost-effective solution to screen a wide population for epidemiological studies and to monitor specific populations at risk of sleep disorders.</p><p>Deep learning has been successfully applied to numerous domains and has received much attention from the sleep research community. Past work has looked at various deep network architectures, such as deep neural networks (DNNs) <ref type="bibr" target="#b14">[15]</ref>, convolutional neural networks (CNNs) <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b23">[24]</ref>, and recurrent neural networks (RNNs) <ref type="bibr" target="#b24">[25]</ref>- <ref type="bibr" target="#b27">[28]</ref>, and novel ways to carry out sleep staging like sequenceto-sequence classification scheme <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Reviews of the most recent progress on deep learning for automatic sleep staging can be found in <ref type="bibr" target="#b28">[29]</ref>- <ref type="bibr" target="#b30">[31]</ref>. However, considerably less attention has been paid to make sleep staging models more robust to the challenges of sleep data variability and to make them data-efficient (i.e. using less data). Despite the fact that the performance of machine's sleep staging has been on par with manual scoring by sleep experts <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b22">[23]</ref>, we have not seen it widely adopted clinically. This is arguably due to two major technical drawbacks of the sleep staging models: data variability and data inefficiency. Data variability: PSG signals recorded in a particular recording setup are characterized by a number of parameters such as sensors' frequency response and output level, and signal processing applied to the raw signal. These factors contribute to the transfer function of the recording device and affect how the physiological signals are converted into digital PSG output. As a result, sleep data recorded in different setups may have different transfer functions due to the variations in their underlying hardware and software processing pipelines. Furthermore, discrepancies in channel layouts <ref type="bibr" target="#b7">[8]</ref> and cohort characteristics <ref type="bibr" target="#b31">[32]</ref> are also likely in different sleep studies. From the viewpoint of machine learning models, these variations and discrepancies lead to domain shift or mismatch between sleep data sources. Data mismatch across different acquisition conditions are computationally significant, degrading the accuracy of sleep staging models on unseen data with a novel recording condition. Therefore, if a sleep staging model is deployed on an unseen sleep data whose properties differ from the data used for training the model, the data mismatch can result in poor inference performance. As evidenced in our experiments (cf. Section V-C) and shown in <ref type="table" target="#tab_0">Table I</ref>, the singlechannel SeqSleepNet <ref type="bibr" target="#b3">[4]</ref> model trained on the MASS database suffers from an accuracy drop when it is evaluated out of domain (i.e. being tested on other three databases Sleep-EDF-SC, Sleep-EDF-ST, and Surrey-cEEGrid) relative to the one obtained with in-domain evaluation (i.e. via cross-validation on the MASS database itself). The performance loss depends on the level of data mismatch. Data inefficiency: Existing deep-learning based sleep staging models cannot escape from the curse of data inefficiency of the deep learning paradigm. That is, training a deep neural network generally requires a large amount of data. In fact, expert-level performance on automatic sleep staging is only obtainable with these models when the training cohort is large, i.e. hundreds or thousands of subjects <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b7">[8]</ref>. The networks' performances decline significantly when they are trained with a small cohort (e.g. ten or twenty subjects <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b32">[33]</ref>). Unfortunately, in practice, many sleep studies only have access to a small cohort, in the order of a few dozens of subjects <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b33">[34]</ref>- <ref type="bibr" target="#b36">[37]</ref>. Thus, the small data in these studies hinder deep learning models to perform well. An easy and obvious solution for the above-mentioned obstacles is to collect training data from all types of recording setups (e.g. recording devices, channel layouts, and preprocessing softwares) that will be foreseeably encountered in the deployment phase. However, this is an expensive, timeconsuming, and even infeasible solution. First, most of large sleep databases are proprietary, making those inaccessible for research purposes. Second, even if they are available, a huge effort would be required to score these data manually. Third, novel setups will likely emerge when one studies a particular sleep disorder <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b36">[37]</ref> or when one explores the feasibility of a new monitoring device <ref type="bibr" target="#b10">[11]</ref>.</p><p>In this work, we present a practical solution based on transfer learning to tackle these obstacles, to build more accurate sleep staging models when the available data is small, and to recover the performance of the models otherwise lost due to data variability. We leverage a reasonably large sleep database, which is publicly available, and use a sleep-staging deep neural network as a device to transfer knowledge from this database to improve sleep staging performance on another small cohort with a different recording setup. More specifically, the network is firstly trained with the large database (the source domain) and subsequently finetuned with the small cohort (the target domain) to complete transfer learning. In this context, finetuning means a part or the entire of the pretrained network is further trained with the target domain data. The main contributions of this work include:</p><p>• A new perspective of looking at data variability and data inefficiency in the automatic sleep staging problem, and developing a deep transfer learning approach to overcome sleep data mismatch and enable knowledge transfer to improve sleep-staging performance on small cohorts. Indepth investigation into the influence of the number of subjects on the transfer learning performance was also conducted. • The generalization of a sequence-to-sequence sleep staging framework from which two state-of-the-art models SeqSleepNet+ and DeepSleepNet+ are developed and used in the study. • A systematic study highlighting different target domains with varying data-mismatch degrees to the source domain, different transfer learning scenarios (i.e. singlechannel and multi-channel input), different finetuning strategies, and different state-of-the-art sleep staging models. Our transfer learning approach outperforms all the tested baselines and existing works in solving the automatic sleep staging on the target sleep databases. This work extends our preliminary work in <ref type="bibr" target="#b32">[33]</ref> in several aspects. First, we study transfer learning with a wider spectrum of channel combinations for the networks' input rather than a single channel. Second, the studies in <ref type="bibr" target="#b32">[33]</ref> employed SeqSleepNet <ref type="bibr" target="#b3">[4]</ref> as the transfer learning device, here the studies are carried out on two different networks inherited from SeqSleepNet <ref type="bibr" target="#b3">[4]</ref> and DeepSleepNet <ref type="bibr" target="#b5">[6]</ref>. These two stateof-the-art networks are diverging in their architectures <ref type="bibr" target="#b37">[38]</ref>; therefore, it is important to examine if these dissimilarities give rise to any difference in their performance and to explain their behaviors in transfer learning. Third, the work in <ref type="bibr" target="#b32">[33]</ref> only studied deep transfer learning on the Sleep-EDF-SC as the target domain. Here, we cover multiple target domains with varying degrees of channel mismatch. Fourth, we study in-depth the influence of the number of target subjects on the transfer learning's performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. MATERIALS A. Source Domain</head><p>We adopted the public Montreal Archive of Sleep Studies (MASS) database <ref type="bibr" target="#b38">[39]</ref> as the source domain in this study as it is sufficiently large.</p><p>MASS: This database was pooled from different hospitalbased sleep laboratories, consisting of whole-night recordings from 200 subjects (97 males and 103 females) aged between 18 and 76 years. Manual annotation was accomplished by sleep experts according to the AASM standard <ref type="bibr" target="#b0">[1]</ref> (SS1 and SS3 subsets) or the R&amp;K standard <ref type="bibr" target="#b1">[2]</ref> (SS2, SS4, and SS5 subsets). As in <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, we converted different annotations into five sleep stages {W, N1, N2, N3, and REM} and expanded 20-second epochs into 30-second ones by including 5-second segments before and after each epoch. We used the C4-A1 EEG, ROC-LOC EOG, and CHIN1-CHIN2 EMG in our experiments.  <ref type="figure">Fig. 1</ref>: Illustration of (a) the cEEGrid electrode array which was used to record the Surrey-cEEGrid database <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b39">[40]</ref> and (b) the FB(R) ("front versus back" for the right ear) derivation <ref type="bibr" target="#b10">[11]</ref> used in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Target Domains</head><p>Three different sleep databases are used as the target domains. These adopted cohorts have diverging health conditions, i.e. healthy (Sleep-EDF-SC) vs. mild sleep difficulty (Sleep-EDF-ST) <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, and channel characteristics (i.e. traditional PSG recording (Sleep-EDF-SC and Sleep-EDF-ST) vs. wearable around-the-ear EEG recordings (Surrey-cEEGrid) <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b39">[40]</ref>).</p><p>Sleep-EDF-SC: This is the Sleep Cassette (SC) subset of the Sleep-EDF Expanded dataset <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>, consisting of 20 subjects aged 25-34. Two subsequent day-night PSG recordings were collected for each subject, except for subject 13 who has only one-night data. Each 30-second PSG epoch was manually labelled into one of eight categories {W, N1, N2, N3, N4, REM, MOVEMENT, UNKNOWN} by sleep experts according to the R&amp;K standard <ref type="bibr" target="#b1">[2]</ref>. Similar to previous works <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b40">[41]</ref>, N3 and N4 stages were merged into a single stage N3 and MOVEMENT and UNKNOWN categories were excluded. Since full EMG recordings are not available, we only adopted the Fpz-Cz EEG and ROC-LOC EOG (i.e. the EOG horizontal) channels in this study. As this database has been used differently in literature, it should be stressed that only the in-bed parts (from lights off time to lights on time) of the recordings were used as recommended in <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b40">[41]</ref>- <ref type="bibr" target="#b42">[43]</ref>.</p><p>Sleep-EDF-ST: This is the Sleep Telemetry (ST) subset of the Sleep-EDF Expanded dataset <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref> which was collected for studying the temazepam effects on sleep. The subset consists of 22 Caucasian subjects (7 males and 15 females) aged 18-79 with mild difficulty falling asleep. Although the PSG signals were recorded for two nights, one after temazepam intake and one after placebo intake, only the placebo nights are available. Manual annotation was done similar to the Sleep-EDF-SC subset. Beside Fpz-Cz EEG and ROC-LOC EOG, the submental EMG channel is available and additionally adopted. Similar to the the Sleep-EDF-SC subset, only the in-bed parts of the recordings were used.</p><p>Surrey-cEEGrid: This database <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b39">[40]</ref> was recorded at the University of Surrey using the cEEGrid array <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b44">[45]</ref>, a novel lightweight flex-printed electrode strip that fits neatly behind the ear, as illustrated in <ref type="figure">Figure 1</ref>   (about 12 hours) cEEGrid data collected. The PSGs were also recorded in parallel and manual annotation based on the PSG was used as reference for the cEEGrid data <ref type="bibr" target="#b10">[11]</ref>. Besides two recordings lost due to human error, six recordings were discarded because of excessive artifacts and missing data. A cohort of 12 participants was retained. From the cEEGrid data, the FB(R) ("front versus back" for the right ear, see <ref type="figure">Figure 1</ref> (b)) EEG derivation, which was the best derivation <ref type="bibr" target="#b10">[11]</ref>, was obtained and used. We also simulated the twoand three-channel settings by adding the ROC-A2 EOG and CHIN1-CHIN3 channels from the PSG data to the cEEGrid data. Although there exist other EOG and EMG channels, the ROC-A2 EOG and CHIN1-CHIN3 channels were deliberately selected to be different from those of the source domain to maintain the severity of data mismatch. The employed databases and the adopted signals are summarized in <ref type="table" target="#tab_0">Table II</ref>. All the signals were downsampled to 100 Hz. The databases were chosen to have the data mismatch between the target domains and the source domain varying from slight level due to the difference in PSG signals used (i.e. Sleep-EDF-SC and Sleep-EDF-ST) to severe level due to completely new electrode placement (i.e. Surrey-cEEGrid).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. THE GENERIC DEEP LEARNING FRAMEWORK FOR SEQUENCE-TO-SEQUENCE SLEEP STAGING</head><p>The advent of deep learning has made astonishing progress in automatic sleep staging. First, deep networks are powerful in learning features which outperform and displace traditional handcrafted features. Second, they enable us to achieve automatic sleep stage classification in ways that are impossible for conventional machine-learning algorithms. The sequenceto-sequence sleep staging scheme <ref type="bibr" target="#b3">[4]</ref> was recently proposed to offer the ability of modelling long-term temporal dependency of sleep data epochs in a deep learning model. Intuitively, a sequence-to-sequence model processes a sequence of multiple consecutive epochs simultaneously and classifies them at once into a sequence of corresponding sleep stages. Here, we frame this scheme into a generic deep learning framework for sequence-to-sequence sleep staging. This framework also sets a potential benchmark to design new models in future work. It is worth noting beforehand that a detail explanation of the network layers and machine learning concepts encountered in the following sections, such as an RNN or a CNN, can be found in <ref type="bibr" target="#b45">[46]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. The framework</head><p>Formally, given the input sequence of L consecutive epochs denoted as (S 1 , S 2 , . . . , S L ), the sequence-to-sequence sleep staging problem <ref type="bibr" target="#b3">[4]</ref> is formulated to maximize the conditional probability p(y 1 , y 2 , . . . , (y 1 , y 2 , . . . , y L ) represents the sequence of corresponding L one-hot encoding vectors of the ground-truth output labels. The proposed framework are divided into three components, an epoch processing block (EPB), a sequence processing block (SPB), and a softmax layer, as illustrated in <ref type="figure" target="#fig_2">Fig. 2</ref>.</p><formula xml:id="formula_0">y L | S 1 , S 2 , . . . , S L ) where x ... 2 x 1 x L ... o 1 o 2 o L y 1 y 2 y L softmax EPB softmax softmax S 1 S 2 S L EPB EPB biRNN</formula><p>EPB: Each epoch in the input sequence is presented to the network in some forms of representation (e.g. raw signals <ref type="bibr" target="#b5">[6]</ref> or time-frequency features <ref type="bibr" target="#b3">[4]</ref>) and can be single-channel (e.g. EEG or EOG) or multi-channel (e.g. a combination of EEG, EOG, and EMG). The EPB plays the role of an epoch-wise feature learner and extractor. The EPB is common for the PSG epochs in the input sequence and is a sub-network that is trained jointly with other components in an end-to-end manner <ref type="bibr" target="#b3">[4]</ref>. Via the EPB, an input epoch S l , 1 ≤ l ≤ L, is transformed into an epoch-wise feature vector x l .</p><p>SPB: The SPB consists of a bidirectional recurrent layer (biRNN) that encodes the sequence of the induced epoch-wise feature vectors (x 1 , x 2 , . . . , x L ) into the sequence of output vectors (o 1 , o 2 , . . . , o L ). An RNN is a type of deep neural networks that processes an input sequence one element at a time and retain information of all the past elements of the sequence in its hidden state vector <ref type="bibr" target="#b46">[47]</ref>. A biRNN, on the other hand, consists of two RNN layers of opposite directions to the same input sequence <ref type="bibr" target="#b47">[48]</ref>. More specifically, the forward and backward recurrent layers of the biRNN iterate over the sequence (x 1 , x 2 , . . . , x L ) in opposite directions and compute their forward and backward sequences of hidden state vectors</p><formula xml:id="formula_1">H f = (h f 1 , h f 2 , . . . , h f L ) and H b = (h b 1 , h b 2 , . . . , h b L ), respectively, where h f l = H(x l , h f l−1 ),<label>(1)</label></formula><formula xml:id="formula_2">h b l = H(x l , h b l+1 ), 1 ≤ l ≤ L.<label>(2)</label></formula><p>In <ref type="formula" target="#formula_1">(1)</ref> and <ref type="formula" target="#formula_2">(2)</ref>, H denotes the hidden layer function of the biRNN and can be realized by either Long Short-Term Memory (LSTM) <ref type="bibr" target="#b48">[49]</ref> or Gated Recurrent Unit (GRU) <ref type="bibr" target="#b49">[50]</ref>, two most popular RNN variants. The sequence of output vectors  where ⊕ represents vector concatenation. In <ref type="formula" target="#formula_3">(3)</ref>, W ho denotes a learnable weight matrix and b o denotes a learnable bias. The (long-term) dependency of the input epochs are expected to be modelled by the biRNN layer and the output vectors o l , 1 ≤ l ≤ L are expected to encode sequence-level information. A residual connection can be optionally used to integrate epoch-wise features x l and sequence-wise features o l and, hence, enables the network to explore their combination in the classification stage. The fully-connected layer (FC) of the residual connection is to convert x l into another vector having its size compatible to o l for a proper residual combination. All the residual connections also share their parameters.</p><formula xml:id="formula_3">(o 1 , o 2 , . . . , o L ) is then computed: o l = W ho [h b l ⊕ h f l ] + b o , 1 ≤ l ≤ L,<label>(3)</label></formula><formula xml:id="formula_4">z 1 z 2 z T ... a 1 a 2 a T ... α 2 α T α 1 ... EPB biRNN biRNN biRNN ... epoch EMG EOG EEG x EPB (b) (a)</formula><p>Softmax: The classification is carried out by the shared softmax layer to yield the output sequence of sleep stage probabilities (ŷ 1 ,ŷ 2 , . . . ,ŷ L ) from the sequence of output vectors (o 1 , o 2 , . . . , o L ). Different from SeqSleepNet in <ref type="bibr" target="#b3">[4]</ref> and DeepSleepNet in <ref type="bibr" target="#b5">[6]</ref>, we use a common softmax layer for classification at all indices 1, 2, . . . , L to reduce the number of network parameters rather than one separate softmax layer at each of the indices. A network that adheres to this framework can be trained to minimize the sequence classification loss over N training sequences in the training data:</p><formula xml:id="formula_5">E(θ) = − 1 L N n=1 L l=1 y l log (ŷ l (θ)) + λ 2 θ 2 2 .<label>(4)</label></formula><p>Here, θ represents the network parameters and λ denotes the hyper-parameter that trades off the error terms and the ℓ 2 -norm regularization term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. The derived networks</head><p>From the framework presented in Section III-A, we develop two networks as the base models for transfer learning:</p><p>SeqSleepNet+: This network is similar to SeqSleepNet presented in <ref type="bibr" target="#b3">[4]</ref>, except that a common softmax layer is used at all indices of the input sequence. Hence, SeqSleepNet+ is more compact than SeqSleepNet <ref type="bibr" target="#b3">[4]</ref>. The network receives the log-scale time-frequency representation <ref type="bibr" target="#b3">[4]</ref> as input. The timefrequency image is normalized to zero-mean and unit standard deviation. In case of multi-channel, the channel-wise image features are stacked as a multi-channel image. The network's EPB is realized by filterbank layers <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b16">[17]</ref>, one for each input image channel for preprocessing purpose, followed by an attentional biRNN as illustrated in <ref type="figure" target="#fig_3">Figure 3</ref>(a). Note that this EBP's biRNN should not be confused with the SBP's biRNN in <ref type="figure" target="#fig_2">Fig. 2</ref>. Both the EPB's biRNN and the SPB's biRNN of the network are implemented by a GRU cell <ref type="bibr" target="#b49">[50]</ref> with recurrent batch normalization <ref type="bibr" target="#b50">[51]</ref>. There is no residual connection (cf. <ref type="figure" target="#fig_2">Figure 2</ref>) in the SPB of this network.</p><p>DeepSleepNet+: This network is inherited from DeepSleep-Net <ref type="bibr" target="#b5">[6]</ref> and its end-to-end variant <ref type="bibr" target="#b3">[4]</ref>, except for the common softmax used at all indices of the input sequence. The network receives raw signals as input. When the input are composed of multiple signals, the raw signal are stacked to form a multichannel input. The network's EPB is composed of two deep CNNs organized in two branches with 4 convolutional layers each as illustrated in <ref type="figure" target="#fig_3">Figure 3</ref>(b). A CNN is a type of deep neural networks designed to efficiently process data that come in the form of multiple arrays <ref type="bibr" target="#b46">[47]</ref>, such as one-dimensional signals in this case. A CNN features local connections, shared weights, and pooling to learn translation-invariant features from the input. The convolutional kernels in the two branches are purposely designed to have different sizes so that they can learn features at both fine and coarse temporal resolutions. Each convolutional layer is associated with batch normalization <ref type="bibr" target="#b51">[52]</ref> and Rectified Linear Units (ReLU) activation <ref type="bibr" target="#b52">[53]</ref>. The SPB's biRNN relies on the LSTM cell <ref type="bibr" target="#b48">[49]</ref> and is designed to have two bidirectional LSTM layers, one stacked on top of the other. In addition, the SPB makes use of the residual connection.</p><p>As the two networks inherits SeqSleepNet's and DeepSleep-Net's architecture's, respectively, they are divergent in their inputs, EPB, and SPB components <ref type="bibr" target="#b37">[38]</ref>. Therefore, these differences suggest discrepant behaviors during transfer learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. TRANSFER LEARNING SCENARIOS FOR AUTOMATIC SLEEP STAGING ON SMALL COHORTS</head><p>Formally, let D S = {X S , Y S } denote the source domain with the feature space X S and the label space Y S . In addition, let T S denote the task in the source domain with the source conditional probability distributions</p><formula xml:id="formula_6">P (y S | x S ), where x S ∈ X S and y S ∈ Y S . Similarly, D T = {X T , Y T } denotes the target domain with the feature space X T and the label space Y T . T S denotes the task in the target domain with the conditional probability distributions P (y T | x T ), where x T ∈ X T and y T ∈ Y T , respectively. The objective of transfer learning is to improve learning P (y T | x T ) with information gained from D S and T S where D S = D T or T S = T T [54].</formula><p>In our case, T S ≡ T T , as we aim at performing sleep staging with the same set of sleep stages in both the source and target domains. Transfer learning <ref type="bibr" target="#b53">[54]</ref> relaxes the hypothesis that the training data must be identically distributed as the test data. Therefore, it is useful to deal with data mismatch and holds promise to leverage the large amount of available data to overcome the problem of having insufficient training data in small cohort studies.</p><p>In the present context, a model (e.g. SeqSleepNet+ or DeepSleepNet+) is firstly trained in the source domain and then finetuned in the target domain to complete knowledge transfer as illustrated in <ref type="figure" target="#fig_4">Figure 4</ref>. Without loss of generality, the pretraining process is to minimize the loss L S over the source-domain data, resulting in the model parameter θ:</p><formula xml:id="formula_7">argmin θ = (x,y)∈DS L S (x, P (y | x), P θ (y | x)) .<label>(5)</label></formula><p>The pretrained model is considered as a starting point in the target domain. To accomplish transfer learning, a subset of the pretrained network's parameter θ ′ ⊆ θ is finetuned (i.e. further trained) with the target-domain data while the rest θ\θ ′ remains unchanged (i.e. being reused):</p><formula xml:id="formula_8">argmin θ ′ ⊆θ = (x,y)∈DT L T (x, P (y | x), P θ (y | x)) .<label>(6)</label></formula><p>When θ ′ = θ, the entire pretrained network is finetuned in the target domain. In contrast, when θ ′ = ∅, no finetuning happens and the pretrained network is directly used in the target domain.</p><p>In order to study the influence of finetuning different components of a pretrained SeqSleepNet+ and DeepSleepNet+ to the sleep staging performance on the target domains, we examine four finetuning strategies corresponding to different component combinations: all, EPB+softmax, SPB+softmax, and softmax. The parameter subsets corresponding to these combinations will be adapted with the target-domain data while the rest remains fixed. The case in which the pretrained network is directly used in the target domain without finetuning is considered as a baseline. The finetuning strategies are carried out to study the following transfer learning scenarios:</p><p>EEG·EOG·EMG →EEG·EOG·EMG: Apart from brain activities, sleep also involves eye movements and muscular activities at different levels. For instance, Rapid Eye Movement (REM) stage usually associates with rapid eye movements and high muscular activities are usually seen during the Awake stage. Therefore, EOG and EMG are valuable additional sources, complementing EEG in the automatic sleep staging task <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>- <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b36">[37]</ref>. We study this three-channel EEG·EOG·EMG transfer learning scenario when all EEG, EOG, and EMG are available in a target domain (i.e. in case of Sleep-EDF-ST and Surrey-cEEGrid).</p><p>EEG·EOG →EEG·EOG: This scenario assumes the unavailability of EMG and examines two-channel EEG·EOG transfer learning. Different from the three-channel case, we are able to study this scenario across all the adopted target domains as they all have full EEG and EOG recordings available.</p><p>EEG →EEG: This scenario explores single-channel EEG transfer learning. Automatic sleep staging with single-channel EEG is prevalent in literature <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b54">[55]</ref>- <ref type="bibr" target="#b56">[57]</ref>. Without the augmentation from EOG and EMG, this single-channel setting usually results in a lower performance compared to those of the multi-channel ones; however, it is desirable due to the simple configuration. It is particularly useful for sleep monitoring applications with mobile EEG devices <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b39">[40]</ref>.</p><p>EOG →EOG: In general, EOG signals contain rich information from multiple sources, including ocular activity, frontal EEG activity, and EMG from cranial and eye muscles <ref type="bibr" target="#b35">[36]</ref>. They are, therefore, promising alternatives for EEG in single-channel sleep staging. In addition, due to the ease of electrode placements, it would be ideal for home-based sleep monitoring applications with wearable devices <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b39">[40]</ref>. Despite their potential, EOG signals have been mainly used as secondary modality in multi-channel sleep staging studies <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b57">[58]</ref>. With this scenario, we aim to exploit standalone EOG and deep transfer learning on this secondary modality to examine whether its performance is comparable to that using the primary EEG in single-channel sleep staging.</p><p>EEG →EOG: As an extension of the EOG →EOG scenario, this cross-modality transfer learning scenario investigates whether a base model trained on EEG in the source domain can be transferred to EOG in the target domain and if its performance is comparable to the same-domain EOG →EOG transfer learning scenario. If the answers to these questions are true, instead of modality-specific pretrained models, a single model pretrained solely on EEG can serve as a generic model for single-channel transfer learning regardless the modality of the target domain.</p><p>Apart from the data mismatch caused by the differences in recording devices and/or electrode placements in case of the same-modality scenarios (i.e. EEG·EOG·EMG →EEG·EOG·EMG, EEG·EOG →EEG·EOG, EEG →EEG, and EOG →EOG), heavy data mismatch is expected in case of the cross-modality EEG →EOG scenario when the base models are trained with EEG data in the source domain is transferred to EOG data in the target domains. On the one hand, with the same-modality scenarios, we aim to show that even when the source domain and the target domains are of the same modalities, transfer learning is still necessary. On the other hand, the cross-modality scenario is to emphasize that transfer learning is efficient in tackling heavy data mismatch to transfer knowledge from the source domain to the target domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setup</head><p>SeqSleepNet+ and DeepSleepNet+ were pretrained using the data from the entire 200 subjects of the MASS database (i.e. the source domain) and then finetuned in the target domains. To evaluate the efficiency of transfer learning on sleep staging in the target domains, cross-validation was conducted.</p><p>Leave-one-out cross-validation was conducted for Sleep-EDF-SC (20 subjects), and Surrey-cEEGrid (12 subjects) while 11fold cross-validation was performed for Sleep-EDF-ST (22 subjects) to have an equal number of test subjects (i.e. 2 subjects) in each cross-validation fold. At each iteration of cross-validation, a number of subjects were randomly selected and left out for validation purpose, i.e. for early stopping the finetuning process, (4 for Sleep-EDF-SC and Sleep-EDF-ST and 2 for Surrey-cEEGrid). The performance over all crossvalidation folds was then calculated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Network Parameters</head><p>Both SeqSleepNet+ and DeepSleepNet+ were implemented using Tensorflow <ref type="bibr" target="#b58">[59]</ref>. The networks were parametrized similar to SeqSleepNet and DeepSleepNet in our previous work <ref type="bibr" target="#b3">[4]</ref>. We experimented with the input sequence length L = 20 epochs as this value is a reasonable choice for these sequenceto-sequence models <ref type="bibr" target="#b3">[4]</ref>. The sequences were sampled from the training recordings with a hop size of one epoch for network training and finetuning. During testing, the test sequences were also shifted by one epoch, resulting in an ensemble of L classification decisions at each epoch of a test recordings. A probabilistic aggregation step similar to <ref type="bibr" target="#b3">[4]</ref> was carried out to fuse the decision ensemble into the final decision.</p><p>In the source domain, the networks were pretrained with the MASS database for 10 training epochs with a minibatch size of 32 sequences. For transfer learning, the pretrained networks were further finetuned on each target-domain databases for 10 finetuning epochs. The finetuning process was stopped early when no accuracy improvement was seen on the validation subjects for 50 finetuning steps. Both network training and finetuning were performed using Adam optimizer, an optimization algorithm proposed in <ref type="bibr" target="#b59">[60]</ref> for training deep neural networks. This optimizer leverages the power of adaptive learning rates methods to find individual learning rates for each parameter of the network. The initial learning rate of Adam optimizer was set to 10 −4 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Performance on the source domain:</head><p>It is first worth assessing SeqSleepNet+ and DeepSleepNet+ on the source domain to see how well they perform on a large number of subjects across the input spectrum. To this end, we conducted 10-fold cross-validation on the source domain. At each iteration, 180 subjects were used for training, 10 for validation, and 10 for testing. The results of the cross-validation folds were finally pooled to calculate the overall metrics, including accuracy, macro F1-score, and Cohen's kappa (κ). The obtained performance with different inputs are shown in <ref type="table" target="#tab_0">Table   TABLE III</ref> Acc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MF1 kappa</head><p>Sens.</p><p>Spec.  III. Firstly, the results in the table confirm the benefit of using EOG and EMG to complement EEG in the automatic sleep staging task as their presence lead to performance improvement. Secondly, with the sequence-to-sequence framework, the performance obtained by the secondary EOG is just marginally lower than that of the primary EEG, evidenced by both SeqSleepNet+ and DeepSleepNet+. This suggests that EOG can be used as a standalone modality similar to EEG when a single channel is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sleep-EDF-SC</head><note type="other">Sleep-EDF</note><p>2) The effect of transfer learning on the target domains: <ref type="figure" target="#fig_5">Figures 5 and 6</ref> give an overall picture on the performance obtained by SeqSleepNet+ and DeepSleepNet+ on the target domains with respect to different finetuning strategies and compared to the model trained from scratch using the targetdomain data only. The two networks show noticeably varying patterns on the transfer learning results. On the one hand, SeqSleepNet+'s results in <ref type="figure" target="#fig_5">Figure 5</ref> reveal that, while finetuning the softmax layer alone leads to better performance than that of the scratch model in some cases, it is essential to additionally finetune the feature-learning parts of the network, either the EPB for epoch-level feature learning or the SPB for sequence-level feature learning, or both. This pattern exists across all finetuning cases in the figure. This suggests that the features learned by SeqSleepNet+ in the   source domain are slightly different from those in the target domain. This is reasonable due to the data mismatch between the source and target domains. On the other hand, DeepSleepNet+'s finetuning results expose diverging patterns as shown in <ref type="figure" target="#fig_7">Figure 6</ref>. Finetuning the softmax layer alone results in comparable, or even better, performance than other finetuning strategies in some cases (such as the EEG →EEG scenarios) whereas its results are largely belittled in other cases (such as EEG →EEG scenarios). This suggests that, when the signals are of the same modality, the features learned from the source domain's raw signals persist in the target domain and only their combinations need to be adapted in the target domains. In contrast, when the signals are from different modalities, additional finetuning the feature learning parts (i.e. the EPB or the SPB or both) is necessary. It, however, should be emphasized that persistence of the learned features across the source and target domains does not necessarily mean good generalization as DeepSleep-Net+'s finetuning results are inferior to those of its counterpart, SeqSleepNet+ (see <ref type="table" target="#tab_0">Table IV</ref>).</p><p>Despite their different behaviors in finetuning, both Se-qSleepNet+ and DeepSleepNet+ meet the transfer learning's expectation. Compared to the network trained from scratch using the target-domain data only, transfer learning consis- tently results in improvements across different network types, the target domains, and the transfer learning scenarios. The benefits of transfer learning is further evidenced by contrasting the learning curves of the finetuned models and the scratch models. Taking the two-channel EEG·EOG →EEG·EOG scenario as an example (see <ref type="figure" target="#fig_8">Figure 7)</ref>, the learning curves were recorded on the test data during finetuning and training, respectively. Each learning curve was averaged over all crossvalidation folds. As the learning curves' lengths vary across different folds due to early stopping, those with shorter length than the maximum one were padded to the maximum length before averaging. SeqSleepNet+'s learning curves show better generalization and faster convergence of the finetuned models (except the softmax-only finetuning strategy) compared to their scratch opponents. Similar motifs are observed in DeepSleep-Net+'s learning curves; however, the softmax-only finetuning strategy shows a comparable generalization to other strategies (although slower convergence). These findings consolidate the explanation for the finetuning results in <ref type="figure" target="#fig_5">Figures 5 and 6</ref>.</p><p>3) Performance comparison on the target domains: To justify the necessity of transfer learning, in <ref type="table" target="#tab_0">Table IV</ref> we compare the finetuning overall performance against those of the scratch models and direct transfer (i.e. applying the pretrained models in the target domains without finetuning) across the target domains and the transfer learning scenarios. In addition, the obtained results are also contrasted to those reported in previous works to quantify the efficiency of the proposed transfer learning approach. As the transfer learning results vary depending on the finetuning strategies, for simplicity, out of different finetuning strategies, we retained the SPB+softmax one as the representative for comparison given its consistent finetuning results (see <ref type="figure" target="#fig_5">Figures 5 and 6</ref>). In practice, the finetuning strategies could be viewed as a hyper-parameter and determined via cross-validation. We should bring to readers' attention a large body of works, such as <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, that yielded an accuracy level on (extremely) large databases similar to that of our proposed systems. However, comparison to these results is not the main focus of this work; furthermore, such a comparison would be incompatible and, hence, does not offer much meaning.</p><p>Between SeqSleepNet+ and DeepSleepNet+, the former outperforms the latter in most of the cases in <ref type="table" target="#tab_0">Table IV.</ref> With scratch training, SeqSleepNet+ results in an average accuracy gain of 1.7%, 6.6%, and 17.3% over DeepSleep-Net+ on Sleep-EDF-SC, Sleep-EDF-ST, and Surrey-cEEGrid, respectively. This is consistent with the findings from the source domain (i.e. the MASS database) in <ref type="table" target="#tab_0">Table III</ref> and in <ref type="bibr" target="#b3">[4]</ref>. With transfer learning, SeqSleepNet+ also obtains better performance than DeepSleepNet+ with, improving the overall accuracy by 0.8%, 1.5%, and 7.7% on Sleep-EDF-SC, Sleep-EDF-ST, and Surrey-cEEGrid, respectively. These results suggest that DeepSleepNet+ is harder to train and finetune than SeqSleepNet+, especially when the data is small, partly due to its large model footprint <ref type="bibr" target="#b5">[6]</ref> and partly due to its reliance on raw signal inputs. However, the results in <ref type="table" target="#tab_0">Table IV</ref> show significant gains obtained by both the finetuned models over their scratch counterparts. On the one hand, averaging over all transfer learning scenarios, finetuning SeqSleepNet+ leads to an absolute accuracy gain of 2.5%, 2.0%, and 1.4% on Sleep-EDF-SC, Sleep-EDF-ST, and Surrey-cEEGrid, respectively. Those gains of DeepSleepNet+ are even larger, reaching 3.4%, 7.1%, and 10.9%, respectively, mainly because of the poor performance of the scratch DeepSleepNet+ on Sleep-EDF-ST and Surrey-cEEGrid. Interestingly, transfer learning helps compensate for the lack of training data, evidenced by the observation that the accuracy on Sleep-EDF-SC achieved by the finetuned SeqSleepNet+ is on par with that of MASS (cf <ref type="table" target="#tab_0">.  Table III</ref>) even though the number of subjects is ten times smaller. On the other hand, despite the heavy data mismatch in the cross-domain scenario, transferring the information of EEG data in the source domain to EOG data in the target domains still yields significant accuracy gains: 1.0% and 7.4% on average with SeqSleepNet+ and DeepSleepNet+, respectively. Interestingly, with the accuracy consistently around 80% obtained from the secondary EOG via DeepSleepNet+'s transfer learning, it is promising to be used as an alternative for EEG in single-channel sleep staging.</p><p>Directly applying the pretrained models in the target domains without finetuning results in suboptimal performance in many cases. Averaging over the same-modality transfer learning scenarios, the pretrained SeqSleepNet+ model with direct transfer obtains an accuracy with 10.3%, 5.7%, and 62.2% lower than those obtained by the finetuned models on Sleep-EDF-SC, Sleep-EDF-ST, and Surrey-cEEGrid, respectively. Those gaps in case of DeepSleepNet+ are 16.8%, 9.1%, and 32.6%, respectively. The direct transfer's results are particularly poor under heavy data mismatch conditions, such as the EEG →EOG scenario and the EEG →EEG scenario in Surrey-cEEGrid. It is reasonable as substantial differences in characteristics of the source domain and the target domain cause discrepancy in the feature-learning parts of the pretrained models in the target domain. As a consequence, finetuning is essential. Similar findings are also reflected in the class-wise performance (in terms of MF1) in <ref type="table" target="#tab_9">Table V</ref>.</p><p>The proposed transfer learning approach also outperforms all previous works and set state-of-the-art performance on all three target databases. On Sleep-EDF-SC, with the accuracies of 84.3% (two-channel EEG·EOG) and 85.2% (single-channel EEG) obtained by the transfer learning based SeqSleepNet+, the system yields absolute accuracy gains of 2.0% and 3.2% IV: Performance comparison between the proposed transfer-learning systems, and the baseline systems (i.e. the scratch models and the direct-transfer models, in italic font), and previous works. FT and DT are abbreviated for "finetuning" and "direct transfer", respectively. It should be noted that the comparison may not be completely compatible due to differences in experimental setup: * the transfer learning approach was personalized finetuning; † 30 minutes of data (mainly Wake epochs) before and after in-bed duration were included, therefore, the results are likely biased towards Wake stage; ‡ the evaluation was not subject-independent <ref type="bibr" target="#b4">[5]</ref>; ⋄ the number of subjects is different from that in our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>Transfer learning Yes <ref type="bibr" target="#b4">[5]</ref> No − − − 82.3 74.7 0.750 81.9 73.8 0.740   <ref type="bibr" target="#b36">[37]</ref> and VGGNet <ref type="bibr" target="#b17">[18]</ref>. These results suggest that the quality of the base model plays an important role in transfer learning for sleep staging. The results obtained by the proposed systems are also better than the personalization results in <ref type="bibr" target="#b8">[9]</ref> even though cohort transfer learning here is more challenging than personalized transfer learning as, with the former, we do not have access to test subjects' data during training. Similar to Sleep-EDF-SC, both proposed systems are superior to previous works on Sleep-EDF-ST. However, on Surrey-cEEGrid, while the transfer learning based SeqSleepNet+ uplifts the accuracy by a margin of 10.3% in two-channel EEG·EOG and 5.3% in single-channel EEG compared to the seminal work in <ref type="bibr" target="#b10">[11]</ref>, the DeepSleepNet+ experiences an accuracy drop of 11.8% in single-channel EEG even though 5.8% absolute accuracy gain is seen in two-channel EEG·EOG. 4) Influence of the number of finetuning subjects: This section investigates the influence of the amount of the targetdomain data to the network finetuning. Considering the EEG·EOG →EEG·EOG scenario and the entire-network finetuning strategies for this investigation. For a target domain, we randomly selected 25% of the subjects as the test subjects while the remaining subjects were used for finetuning. A pretrained network was finetuned using data from the finetuning set of N subjects for 500 finetuning steps and the test accuracy was recorded during the finetuning process. Starting with the finetuning set of N = 1 subject, we repeated this procedure and added two more subjects into it at each iteration. <ref type="figure" target="#fig_9">Figure 8</ref> shows the learning curves recorded with varying number of finetuning subjects. The learning curves present a strong impact of the number of finetuning subjects on SeqSleepNet+ while such influence on DeepSleepNet+ is less noticeable, except for Surrey-cEEGrid. It is rational if these results are linked to the networks' finetuning behaviors. While a pretrained SeqSleepNet+ requires its feature-learning parts to be adapted into the target domains, this requirement is not mandatory for DeepSleepNet+, except for the cEEGrid data (see Section V-C.2). And when the feature-learning parts need to be adjusted, less finetuning data make the networks converge to more subject-specific solutions, i.e. overfitting. On the contrary, more finetuning data allow the feature learning parts to converge to more generalizable solutions. This is supported by the SeqSleepNet+'s learning curves on the Sleep-EDF-SC and Surrey-cEEGrid domain, and DeepSleepNet+'s learning curves on the Surrey-cEEGrid domain. From these curves, we also speculate that when the feature-learning parts of a network needs to be adapted to a target domain, a generalizable solution can be obtained with the number of finetuning subjects being around 11-13. Particularly, the learning curves on Sleep-EDF-ST appears to be counter-intuitive as more finetuning subjects occasionally result in lowering learning curves. These irregularities can be explained by the fact that the Sleep-EDF-ST population has a very wide range of age, 18-79. As sleep patterns change with age <ref type="bibr" target="#b67">[68]</ref>, depending the age range of the test subjects, including a subject whose age is far from that range would hurt more than help. Further studies how to determine and select candidates from a population that are most beneficial for a finetuning task.</p><formula xml:id="formula_9">EEG·EOG·EMG →EEG·EOG·EMG EEG·EOG →EEG·EOG EEG →EEG EOG →EOG EEG →EOG Acc. MF1 κ Acc. MF1 κ Acc. MF1 κ Acc. MF1 κ Acc. MF1</formula><formula xml:id="formula_10">− − − 84.0 − − − − − − − − − − − VGG-FT [18] Yes − − − − − − 80.3 − − − − − − − − VGG-FE [18] Yes − − − − − − 76.3 − − − − − − − − ResNet [37] Yes − − − 76.8 − − − − − − − − − − − U-time [61] † No − − − − − − − 79.0 − − − − − − − IITNet [62] † No − − − − − − 84.0 77.7 0.78 − − − − − − DeepSleepNet † [6] No − − − − − − 82.0 76.9 0.760 − − − − − − Multitask 1-max CNN</formula><formula xml:id="formula_11">− − − − − − 1-max CNN [17] No − − − − − − 79.8 72.0 0.720 − − − − − − Attentional RNN [25] No − − − − − − 79.1 69.8 0.700 − − − − − − Deep auto-encoder [41] No − − − − − − 78.9 73.3 − − − − − − − Deep CNN [7] No − − − − − − 74.8 69.8 − − − − − − − Decision trees [63] ‡ No − − − − − − 93.1 − − − − − − − − k-NN [64] ‡ No − − − − − − 80.0 − − − − − − − − GMM [65] ‡ No − − − − − − 73.3 − − − − − − − − Sleep-EDF-ST FT</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Discussion</head><p>It is worth mentioning that, although we focused on studying with small cohorts in this work, the presented transfer learning approach would also be useful for a sleep study with a larger cohort. On the one hand, it only requires the data of a handful of subjects to be labelled, avoiding the burden of manual scoring the entire cohort. On the other hand, finetuning a pretrained model is generally much faster than training a model from scratch, as illustrated in <ref type="figure" target="#fig_8">Figure 7</ref>. This is because the pretrained model has reached already a reasonable accuracy. As a result, it is able to converge after a few additional finetuning epochs. On the downside, it is worth noting that still data from a number of subjects is needed for the validation purpose and future works should explore regularization methods, such as Kullback-Leibler divergence <ref type="bibr" target="#b68">[69]</ref>, to eliminate this requirement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>We presented a deep transfer learning approach to address the problem of insufficient data in many sleep studies and to improve automatic sleep staging performance on small cohorts. The SeqSleepNet+ and DeepSleepNet+ derived from the presented generic sequence-to-sequence sleep staging framework were employed to surpass data mismatch and enable transferring information from the source domain to the target domain. The networks were trained in the source domain and then finetuned in the target domains to complete knowledge transfer. Experiments were conducted with different finetuning strategies, transfer learning scenarios, and target domains. The experimental results showed that via transfer learning, the sleep staging performance was significantly improved across all learning cases over the scratch models trained solely on the target domains. The results also revealed the different behaviors of two SeqSleepNet+ and DeepSleepNet+ models in transfer learning. The former was found more consistent and stable and outperformed the latter in most of the transfer learning experiments. The number of subjects required for finetuning also varied between the two networks, however, overall, a small number of finetuning subjects was needed for the networks to converge to a generalizable solution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>(a). Twenty participants, aged 34.9 ± 13.8 years, had their overnight</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 :</head><label>2</label><figDesc>The proposed generic deep learning framework for sequence-to-sequence sleep staging which consists of the tied epoch processing block (EPB), the sequence processing block (SPB), and the tied softmax layer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 :</head><label>3</label><figDesc>Illustration of the EPBs of (a) SeqSleepNet+ and (b) DeepSleepNet+. The former relies on an attentional biRNN coupled with filterbank layers. The latter is a two-branch deep CNN.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Transfer learning from a source domain to a target domain. The base model is trained using the source-domain data, and then finetuned on the target-domain data to complete knowledge transfer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Performance patterns obtained by finetuning the pretrained SeqSleepNet+ with different finetuning strategies in comparison with those of the SeqSleepNet+ scratch model. (a) EEG·EOG·EMG →EEG·EOG·EMG, (b) EEG·EOG →EEG·EOG, (c) EEG →EEG, (d) EOG →EOG, and (e) EEG →EOG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>85</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 :</head><label>6</label><figDesc>Performance patterns obtained by finetuning the pretrained DeepSleepNet+ with different finetuning strategies in comparison with those of the DeepSleepNet+ scratch model. (a) EEG·EOG·EMG →EEG·EOG·EMG, (b) EEG·EOG →EEG·EOG, (c) EEG →EEG, (d) EOG →EOG, and (e) EEG →EOG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 7 :</head><label>7</label><figDesc>The test accuracy during the finetuning/training. Each curve was averaged over all the cross-validation folds. (a) SeqSleepNet+ and (b) DeepSleepNet+.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 8 :</head><label>8</label><figDesc>The learning curves obtained from the test data with varying the number of finetuning subjects. (a) SeqSleepNet+ and (b) DeepSleepNet+.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>Out-domain performance of the single-channel Se-qSleepNet+ trained on MASS database in comparison to its in-domain performance.</figDesc><table><row><cell>Database</cell><cell>MASS</cell><cell cols="3">Sleep-EDF-SC Sleep-EDF-ST Surrey-cEEGrid</cell></row><row><cell>Input</cell><cell>C4-A1</cell><cell>Fpz-Cz</cell><cell>Fpz-Cz</cell><cell>cEEGrid</cell></row><row><cell>Accuracy</cell><cell>84.5 (in-domain)</cell><cell>81.2 (out-of-domain)</cell><cell>80.5 (out-of-domain)</cell><cell>10.6 (out-of-domain)</cell></row><row><cell>Mismatch</cell><cell>-</cell><cell>slight</cell><cell>slight</cell><cell>severe</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc>Summary of the employed sleep databases.</figDesc><table><row><cell></cell><cell>Num. of subjects</cell><cell>EEG</cell><cell>EOG</cell><cell>EMG</cell><cell>Data mismatch</cell></row><row><cell>MASS</cell><cell>200</cell><cell cols="3">C4-A1 ROC-LOC CHIN1-CHIN2</cell><cell>-</cell></row><row><cell>Sleep-EDF-SC</cell><cell>20</cell><cell cols="2">Fpz-Cz ROC-LOC</cell><cell>-</cell><cell>slight</cell></row><row><cell>Sleep-EDF-ST</cell><cell>22</cell><cell cols="2">Fpz-Cz ROC-LOC</cell><cell>Submental</cell><cell>slight</cell></row><row><cell>Surrey-cEEGrid</cell><cell>12</cell><cell cols="3">cEEGrid ROC-A2 CHIN1-CHIN3</cell><cell>severe</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>:</head><label></label><figDesc>Sleep staging performance on the source domain (i.e. the MASS database).</figDesc><table><row><cell>78.4 kappa</cell><cell>MF1 79.0</cell><cell>73.2 kappa</cell><cell>77.1 MF1</cell><cell>75.8 kappa</cell><cell>MF1 71.9</cell></row><row><cell></cell><cell>84.9 Acc.</cell><cell></cell><cell>81.1 Acc.</cell><cell></cell><cell>82.6 Acc.</cell></row><row><cell>78.2 Sens.</cell><cell>95.7 Spec.</cell><cell>76.6 Sens.</cell><cell>94.5 Spec.</cell><cell>72.0 Sens.</cell><cell>95.4 Spec.</cell></row><row><cell>79.5 kappa</cell><cell>MF1 80.1</cell><cell>74.5 kappa</cell><cell>78.4 MF1</cell><cell>65.0 kappa</cell><cell>MF1 60.8</cell></row><row><cell></cell><cell>85.6 Acc.</cell><cell></cell><cell>81.9 Acc.</cell><cell></cell><cell>75.3 Acc.</cell></row><row><cell>79.6 Sens.</cell><cell>95.9 Spec.</cell><cell>78.3 Sens.</cell><cell>94.8 Spec.</cell><cell>60.6 Sens.</cell><cell>93.2 Spec.</cell></row><row><cell></cell><cell>75.4 MF1</cell><cell></cell><cell>77.5 MF1</cell><cell></cell><cell>72.2 MF1</cell></row><row><cell>74.0 kappa</cell><cell></cell><cell>73.4 kappa</cell><cell></cell><cell>75.8 kappa</cell><cell></cell></row><row><cell></cell><cell>81.9 Acc.</cell><cell></cell><cell>81.1 Acc.</cell><cell></cell><cell>82.6 Acc.</cell></row><row><cell>74.1 Sens.</cell><cell></cell><cell>76.7 Sens.</cell><cell></cell><cell>73.0 Sens.</cell><cell></cell></row><row><cell></cell><cell>94.7 Spec.</cell><cell></cell><cell>94.6 Spec.</cell><cell></cell><cell>95.4 Spec.</cell></row><row><cell></cell><cell>74.4 MF1</cell><cell></cell><cell>76.4 MF1</cell><cell></cell><cell>71.2</cell></row><row><cell>72.7 kappa</cell><cell></cell><cell>72.6 kappa</cell><cell></cell><cell>74.9</cell><cell></cell></row><row><cell></cell><cell>80.9</cell><cell></cell><cell>80.6</cell><cell></cell><cell>81.9</cell></row><row><cell></cell><cell>Acc.</cell><cell></cell><cell>Acc.</cell><cell></cell><cell></cell></row><row><cell>73.3 Sens.</cell><cell></cell><cell>Sens. 75.6</cell><cell></cell><cell>72.1</cell><cell></cell></row><row><cell></cell><cell>94.5 Spec.</cell><cell></cell><cell>Spec. 94.4</cell><cell></cell><cell>95.3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>SeqSleepNet</cell><cell>DeepSleepNet</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Input</cell><cell>Acc. MF1</cell><cell>κ</cell><cell>Acc. MF1</cell><cell>κ</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">EEG·EOG·EMG 87.0 83.3 0.815 86.5 82.4 0.807</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>EEG·EOG</cell><cell>86.5 82.4 0.808 85.9 81.6 0.799</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>EEG</cell><cell>84.5 79.8 0.778 84.3 79.7 0.777</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>EOG</cell><cell>83.9 79.1 0.769 83.7 78.9 0.767</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE V :</head><label>V</label><figDesc>Class-wise performance of the proposed transfer-learning systems and the baseline systems in terms of MF1.<ref type="bibr" target="#b53">54</ref>.0 84.2 71.9 91.1 81.0 55.5 84.7 71.8 90.4 81.8 59.5 84.4 72.9 89.2 80.3 57.7 83.9 70.4 90.3 78.9 52.7 83.5 71.8 88.9 FT DeepSleepNet+ Yes 80.8 55.7 82.9 71.3 87.9 81.7 57.3 83.8 70.7 89.5 82.9 56.9 85.2 74.0 88.4 81.8 56.1 81.3 63.8 87.3 77.0 45.7 80.7 68.5 85.3 DT SeqSleepNet+ Yes 76.9 47.5 85.4 68.5 86.7 63.5 39.6 85.2 65.5 67.3 78.8 56.0 85.2 69.2 88.6 62.2 44.0 80.4 61.9 48.3 62.8 41.1 66.5 17.7 53.8 DT DeepSleepNet+ Yes 67.9 33.7 81.9 71.9 81.6 73.2 36.0 78.4 70.2 69.3 66.8 36.1 73.6 63.4 66.6 62.4 32.8 79.6 70.5 71.2 32.4 13.7 40.6 64.1 4.3 Scratch SeqSleepNet+ No 80.9 49.2 83.5 70.0 89.1 82.0 48.2 83.3 70.7 89.6 80.3 38.9 82.0 69.9 81.6 76.5 38.4 83.6 72.2 87.2 76.5 38.4 83.6 72.2 87.2 Scratch DeepSleepNet+ No 72.0 46.1 78.3 67.4 84.4 59.5 47.4 80.9 72.3 77.8 61.0 40.3 81.1 67.1 73.7 67.1 45.7 74.9 64.3 77.2 67.1 45.7 74.9 64.3 77.2</figDesc><table><row><cell></cell><cell>System</cell><cell>Transfer learning</cell><cell cols="5">EEG·EOG·EMG →EEG·EOG·EMG W N1 N2 N3 REM</cell><cell>W</cell><cell>EEG·EOG →EEG·EOG N1 N2 N3</cell><cell>REM</cell><cell>W</cell><cell>N1</cell><cell>EEG →EEG N2</cell><cell>N3</cell><cell>REM</cell><cell>W</cell><cell>EOG →EOG N1 N2 N3</cell><cell>REM</cell><cell>W</cell><cell>N1</cell><cell>EEG →EOG N2</cell><cell>N3</cell><cell>REM</cell></row><row><cell>Sleep-EDF-SC</cell><cell>FT SeqSleepNet+ FT DeepSleepNet+ DT SeqSleepNet+ DT DeepSleepNet+ Scratch SeqSleepNet+ Scratch DeepSleepNet+</cell><cell>Yes Yes Yes Yes No No</cell><cell>− − − − − −</cell><cell>− − − − − −</cell><cell>− − − − − −</cell><cell>− − − − − −</cell><cell cols="13">− 80.0 45.9 88.0 85.9 88.9 85.4 50.9 88.8 86.4 86.5 75.1 46.4 86.3 80.3 87.3 72.8 40.3 84.9 78.7 84.8 − 82.6 50.0 87.8 86.2 88.4 81.0 50.5 88.2 86.9 87.2 75.3 42.7 84.5 79.3 85.4 75.7 41.9 83.9 78.1 84.5 − 63.2 29.8 84.9 72.2 60.2 74.1 46.9 86.9 81.2 83.8 67.7 33.9 79.3 54.4 60.4 51.4 28.9 61.0 19.8 51.6 − 59.6 30.6 82.7 80.5 45.5 69.0 31.9 80.0 74.6 78.8 38.9 15.1 74.6 78.8 2.0 29.6 11.5 48.9 75.1 13.8 − 75.0 38.3 86.8 86.0 85.0 78.5 37.1 87.6 86.2 81.2 73.5 25.8 84.4 77.7 80.3 73.5 25.8 84.4 77.7 80.3 − 67.5 47.9 86.8 86.8 87.0 70.3 48.1 86.4 84.6 81.3 62.8 33.1 81.5 74.8 82.5 62.8 33.1 81.5 74.8 82.5</cell></row><row><cell cols="20">Sleep-EDF-ST 80.5 Surrey-cEEGrid FT SeqSleepNet+ Yes FT SeqSleepNet+ Yes 91.6 81.3 27.2 81.3 81.3 90.9 79.9 23.1 81.4 80.2 90.6 58.0 10.6 71.5 73.4 91.2 78.8 26.6 81.1 83.3 91.3 76.0 26.4 81.0 81.0 FT DeepSleepNet+ Yes 80.4 63.3 10.3 67.5 77.1 86.7 70.9 15.5 77.1 82.5 74.9 23.2 5.7 47.0 63.4 87.0 66.6 22.0 77.7 79.8 90.2 78.5 20.2 80.9 82.8 DT SeqSleepNet+ Yes 57.0 1.6 11.9 3.1 0.0 54.4 0.4 12.1 6.0 0.0 29.2 0.6 9.9 3.3 2.5 46.7 12.1 13.7 30.1 0.0 67.9 2.8 10.1 3.7 0.1 DT DeepSleepNet+ Yes 57.6 0.0 1.3 0.0 0.0 57.0 0.0 1.7 0.0 0.0 57.1 1.2 0.0 0.0 0.0 67.0 0.4 17.2 42.4 0.0 66.2 3.1 14.6 43.3 0.0 Scratch SeqSleepNet+ No 90.8 81.1 5.7 80.2 80.0 90.4 79.9 3.3 79.9 78.7 88.2 50.5 1.0 67.4 68.8 90.3 79.6 12.3 79.5 77.5 90.3 79.6 12.3 79.5 77.5 Scratch DeepSleepNet+ No 75.0 61.4 23.4 64.4 62.4 72.9 59.4 24.0 68.7 61.8 57.6 12.3 6.9 23.1 51.4 75.2 66.1 19.7 73.0 66.0 75.2 66.1 19.7 73.0 66.0</cell></row><row><cell cols="11">over the best non-transfer-learning systems, Multitask 1-max</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="11">CNN [5] (82.3%) and DeepSleepNet [6] (82.0%), respectively.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Those respective gains achieved by the transfer learning based DeepSleepNet+ are 2.3% and 2.4%. Large margins, 7.5% and 7.8%, are seen when contrasting the proposed SeqSleepNet+ and DeepSleepNet+ systems with the existing transfer learning approach based on ResNet</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ACKNOWLEDGMENT This research received funding from the Flemish Government (AI Research Program). Maarten De Vos is affiliated to Leuven.AI -KU Leuven institute for AI, B-3000, Leuven, Belgium. We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan V GPU used for this research. We would like to thank Dr. Kaare Mikkelsen for sharing the Surrey-cEEGrid database.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The AASM manual for the scoring of sleep and associated events: Rules, terminology and technical specifications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Iber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>American Academy of Sleep Medicine</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A manual of standardized terminology, techniques and scoring system for sleep stages of human subjects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hobson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electroencephalography and Clinical Neurophysiology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">644</biblScope>
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cardiorespiratory-based sleep staging in subjects with obstructive sleep apnea</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Redmond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heneghan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="485" to="496" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">SeqSleepNet: end-to-end hierarchical recurrent neural network for sequence-to-sequence automatic sleep staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Syst Rehabil Eng</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="410" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Joint classification and prediction CNN framework for automatic sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1285" to="1296" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">DeepSleepNet: A model for automatic sleep stage scoring based on raw single-channel EEG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Supratak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Syst Rehabil Eng</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Automatic sleep stage scoring with single-channel EEG using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tsinalis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.01683</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Neural network analysis of sleep stages enables efficient diagnosis of narcolepsy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Stephansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Personalizing deep learning models for automatic sleep staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mikkelsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.02645</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A deep learning architecture for temporal sleep stage classification using multivariate and multimodal time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chambon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Syst Rehabil Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="758" to="769" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Machine-learning-derived sleep-wake staging from around-the-ear electroencephalogram outperforms manual scoring and actigraphy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Mikkelsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Sleep Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">12786</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Wearable in-ear encephalography sensor for monitoring sleep. preliminary observations from nap studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Looney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Ann Am Thorac Soc</publisher>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="32" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">In-ear EEG from viscoelastic generic earpieces: Robust and unobtrusive 24/7 monitoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Goverdovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Sens J</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="271" to="277" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A study of evoked potentials from ear-EEG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kidmose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2824" to="2830" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mixed neural network approach for temporal sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Neural Syst Rehabil Eng</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="324" to="333" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Visualising convolutional neural network decisions in automatic sleep scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Andreotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">De</forename><surname>Vos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. AIH</title>
		<meeting>AIH</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">DNN filter bank improves 1-max pooling CNN for single-channel EEG automatic sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="453" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for interpretable analysis of EEG sleep stage scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vilamala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MLSP</title>
		<meeting>MLSP</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A convolutional neural network for sleep stage scoring from raw single-channel eeg</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomed Signal Process Control</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="107" to="114" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An end-to-end framework for real-time automatic sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patanaik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Gooley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ancoli-Israel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W L</forename><surname>Chee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Expert-level sleep scoring with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Am Med Inform Assoc</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1707.08262</idno>
		<title level="m">SLEEPNET: Automated sleep staging system via deep learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Large-scale automated sleep staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SLEEP</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">139</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep residual networks for automatic sleep stage classification of raw polysomnographic waveforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Olesen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3713" to="3716" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic sleep stage classification using single-channel eeg: Learning sequential features with attention-based recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1452" to="1455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Recurrent neural network based early prediction of future hand movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4710" to="4713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Recurrent neural networks with weighting loss for early prediction of hand movements</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUSIPCO</title>
		<meeting>EUSIPCO</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Making sense of sleep: Multimodal sleep stage classification in a large, diverse population using movement and cardiac sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Interact. Mob. Wearable Ubiquitous Technol</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A review of automated sleep stage scoring based on physiological signals for the new millennia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Faust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Methods Programs Biomed</title>
		<imprint>
			<biblScope unit="volume">176</biblScope>
			<biblScope unit="page" from="81" to="91" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep learning-based electroencephalography analysis: a systematic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Neural Eng</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automated sleep scoring: A review of the latest approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fiorillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep Medicine Reviews</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page">101204</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Detection of REM sleep behaviour disorder by automated polysomnography analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cooray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Clin Neurophysiol</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="505" to="514" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Deep transfer learning for single-channel automatic sleep staging with channel mismatch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EUSIPCO</title>
		<meeting>EUSIPCO</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Analysis of a sleep-dependent neuronal feedback loop: the slow-wave microcontinuity of the EEG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kemp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1185" to="1194" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Physiobank, physiotoolkit, and physionet: Components of a new research resource for complex physiologic signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Goldberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Circulation</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="215" to="220" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A noise-assisted data analysis method for automatic eog-based sleepstage classification using ensemble learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Olesen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3769" to="3772" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multichannel sleep stage classification and transfer learning using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Andreotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fusion of end-to-end deep learning models for sequenceto-sequence sleep staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Montreal archive of sleep studies: An open-access resource for instrument benchmarking &amp; exploratory research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O&amp;apos;reilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Sleep Res</title>
		<imprint>
			<biblScope unit="page" from="628" to="635" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Sleep eeg derived from behind-the-ear electrodes (ceegrid) compared to standard polysomnography: A proof of concept study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sterr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Front Hum Neurosci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">452</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Automatic sleep stage scoring using time-frequency analysis and stacked sparse autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Tsinalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann Biomed Eng</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1587" to="1597" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Recommendations for performance assessment of automatic sleep staging algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Imtiaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodriguez-Villegas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="5044" to="5047" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An open-source toolbox for standardized use of PhysioNet Sleep EDF Expanded Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Imtiaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodriguez-Villegas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="6014" to="6017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Unobtrusive ambulatory EEG using a smartphone and flexible printed electrodes around the ear</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Debener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci. Rep</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">16743</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How about taking a low-cost, small, and wireless eeg for a walk?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Debener</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychophysiology</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">11</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<title level="m">Deep Learning</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Bidirectional recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Kuldip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2673" to="2681" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computing</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning phrase representations using RNN encoderdecoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Recurrent batch normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cooijmans</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.09025</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv Preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Knowl Data Eng</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">An ensemble system for automatic sleep stage classification using single channel EEG signal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Koley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Biol Med</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1186" to="95" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Automatic stage scoring of single-channel sleep EEG based on multiscale permutation entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-E</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BioCAS</title>
		<meeting>BioCAS</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="448" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Metric learning for automatic sleep stage classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="5025" to="5028" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Development of an EOG-based automatic sleepmonitoring eye mask</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-F</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Instrum Meas</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2977" to="2985" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Adam: a method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICLR</title>
		<meeting>ICLR</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">U-time: A fully convolutional network for time series segmentation applied to sleep staging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Perslev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Intra-and inter-epoch temporal context network (IITNet) for automatic sleep stage scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Back</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.06562</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Sleep stage classification using EEG signal analysis: A comprehensive survey and new investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A I</forename><surname>Aboalayon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">272</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Automatic sleep stages classification using eeg entropy features and unsupervised pattern analysis techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Rodríguez-Sotelo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Entropy</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6573" to="6589" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Semi-supervised sleep-stage scoring based on single channel EEG</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Munk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICASSP</title>
		<meeting>ICASSP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Diffuse to fuse EEG spectra -intrinsic geometry of sleep dynamics for classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-R</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.01710</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Sleep stage classification with cross frequency coupling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Sanders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mccurry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Clements</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. EMBC</title>
		<meeting>EMBC</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Modelling changes in sleep timing and duration across the lifespan: Changes in circadian rhythmicity or sleep homeostasis?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Skeldon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Derks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-J</forename><surname>Dijk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sleep Med Rev</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="96" to="107" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Personalized automatic sleep staging with single-night data: a pilot study with KL-divergence regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Phan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physiological Measurement</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">64004</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
