<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Top-DB-Net: Top DropBlock for Activation Enhancement in Person Re-Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodolfo</forename><surname>Quispe</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computing</orgName>
								<orgName type="institution">University of Campinas</orgName>
								<address>
									<postCode>13083-852</postCode>
									<settlement>Campinas</settlement>
									<region>SP</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helio</forename><surname>Pedrini</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institute of Computing</orgName>
								<orgName type="institution">University of Campinas</orgName>
								<address>
									<postCode>13083-852</postCode>
									<settlement>Campinas</settlement>
									<region>SP</region>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Corp</orgName>
								<address>
									<addrLine>One Microsoft Way</addrLine>
									<postCode>98052-6399</postCode>
									<settlement>Redmond</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Top-DB-Net: Top DropBlock for Activation Enhancement in Person Re-Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Person Re-Identification is a challenging task that aims to retrieve all instances of a query image across a system of non-overlapping cameras. Due to the various extreme changes of view, it is common that local regions that could be used to match people are suppressed, which leads to a scenario where approaches have to evaluate the similarity of images based on less informative regions. In this work, we introduce the Top-DB-Net, a method based on Top DropBlock that pushes the network to learn to focus on the scene foreground, with special emphasis on the most task-relevant regions and, at the same time, encodes low informative regions to provide high discriminability.</p><p>The Top-DB-Net is composed of three streams: (i) a global stream encodes rich image information from a backbone, (ii) the Top DropBlock stream encourages the backbone to encode low informative regions with high discriminative features, and (iii) a regularization stream helps to deal with the noise created by the dropping process of the second stream, when testing the first two streams are used. Vast experiments on three challenging datasets show the capabilities of our approach against stateof-the-art methods. Qualitative results demonstrate that our method exhibits better activation maps focusing on reliable parts of the input images. The source code is available at: https://github.com/RQuispeC/top-dropblock.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Person Re-Identification (ReID) aims to match all the instances of the same person across a system of non-overlapping cameras. This is a challenging task due to extreme viewpoint changes and occlusions. It has various applications in surveillance systems and it has gained a lot of popularity in the context of computer vision, where new scenarios of this task have been developed recently <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>.</p><p>Numerous approaches have been proposed using personrelated information, such as pose and body parts <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b7">[8]</ref>. However, ReID datasets only provide ID labels. Thus, these methods rely on other datasets proposed for related tasks during the training. This dependency introduces further errors in predictions and motivates the creation of general methods that do not learn from outer information.</p><p>In this paper, we introduce the Top DropBlock Network (Top-DB-Net) for the ReID problem. Top-DB-Net is designed to further push networks to focus on task-relevant regions and encode low informative regions with discriminative features.</p><p>Our method is based on three streams consisting of (i) a classic global stream as most of the state-of-the-art methods <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b9">[10]</ref>, (ii) a second stream drops 1 most activated horizontal stripes of feature tensors to enhance activation in taskdiscriminative regions and improve encoding of low informative regions, and (iii) a third stream regularizes the second stream avoiding that noise generated by dropping features degrades the final results.</p><p>As a result of our proposed method, we can observe in <ref type="figure">Figure 1</ref> that the activation maps <ref type="bibr" target="#b10">[11]</ref> generated by our baseline, focus both on body parts and background, whereas Top-DB-Net focus consistently on the body with stronger activation to discriminative regions. input image baseline baseline ours ours <ref type="figure">Fig. 1</ref>: Comparison of activation maps generated by the proposed method and a baseline <ref type="bibr" target="#b8">[9]</ref>. The first column shows the input images, the second and fourth columns present the activation maps that overlap the input images, and the third and fifth columns show a mask generated by thresholding the activation maps.</p><p>Contrasting our Top-DB-Net with BDB Network <ref type="bibr" target="#b8">[9]</ref>, there are three differences: (i) instead of dropping random features, our method drops only features with top (the largest) activations, which stimulates the network to maintain performance using only features with inferior discriminative power (the lowest activations), (ii) rather than using the same drop mask for every feature map in the batch, our method creates an independent drop mask for every input based on its top activations, and (iii) dropping top activated features creates noise inside the second stream ( <ref type="figure">Figure 2</ref>), thus we introduce a third stream that forces the features before the dropping step to be still discriminative for ReID, which works as a regularizer due to the multi-task principle <ref type="bibr" target="#b11">[12]</ref>. We use the same definition for 'batch' as Dai et al. <ref type="bibr" target="#b8">[9]</ref>, that is, "group of images participating in a single loss calculation during training". The intuition of why our implementation is better can be explained by analyzing <ref type="figure">Figure 2</ref>. For an input image, we can see that the major activations are over the upper body. BDB Network <ref type="bibr" target="#b8">[9]</ref> creates a random drop mask that, in this case, removes the lower body during training. This would encourage the network to continue focusing on the upper body. On the other hand, our method controls which regions are being dropped and encourages the network to learn from the lower body. Our results show that this helps during the learning process ( <ref type="figure" target="#fig_2">Figure 6</ref>) and generates activation maps better spread over the foreground <ref type="figure">(Figure 1</ref>). The evaluation of our proposed method is conducted through extensive experiments on three widely used datasets for ReID. We consider the BDB Network <ref type="bibr" target="#b8">[9]</ref> as a baseline for our work and demonstrate that our Top-DB-Net outperforms it by up to 4.7% in the CUHK03 dataset <ref type="bibr" target="#b12">[13]</ref>. Moreover, our results show competitive results against state-of-the-art approaches.</p><p>In Section II, we discuss the evolution of the ReID task and review relevant related work. In Section III, we introduce the Top-DB-Net. In Section IV, we describe our experiments and evaluate the results achieved in three challenging datasets. Finally, concluding remarks and directions for future work are presented in Section V.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. BACKGROUND</head><p>The term ReID was first stated by Zajdel et al. <ref type="bibr" target="#b13">[14]</ref> as a variation of people tracking problem. However, unlike tracking algorithms, ReID does not depend on the hypotheses of constancy. Thus, it is a more complicated problem due to considerable variations in biometric profile, position, appearance and point of view <ref type="bibr" target="#b14">[15]</ref>.</p><p>Many initial works in ReID considered it as a classification task. This is mainly because most datasets <ref type="bibr" target="#b15">[16]</ref> available at that time had just a few instances of each person. Because of this, various methods based on handcrafted features <ref type="bibr" target="#b16">[17]</ref>- <ref type="bibr" target="#b20">[21]</ref> were initially proposed.</p><p>With the popularization of deep learning and ReID, many datasets with larger amounts of instances per person in realworld scenarios have been made available <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b21">[22]</ref>- <ref type="bibr" target="#b24">[25]</ref> and deep networks-based methods had become the standard <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>.</p><p>This had two side effects: (i) the most popular datasets already include a predefined training and testing split -which helps with validation protocols and comparison between methods -and (ii) ReID turned into a retrieval problemthus, measures such as Cumulated Matching Characteristics (CMC) and Mean Average Precision (mAP) are widely used.</p><p>Various methods proposed for ReID use specific prior related to person's nature, such as pose and body parts <ref type="bibr" target="#b3">[4]</ref>- <ref type="bibr" target="#b7">[8]</ref>. However, labels such as segmented semantic regions and body skeleton that are necessary for these types of methods are not available in current ReID datasets. Thus, they usually leverage datasets proposed for other tasks captured in different domains, which introduces noise during training and makes the learning process more complicated.</p><p>On the other hand, there are methods <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b29">[30]</ref> that learn to encode rich information directly from the input images without relying on other types of signals. Our work follows this strategy. Most of the methods in this category use the concept of attention in their pipeline. Thus, their approaches expect networks to learn to focus on discriminative regions and encode those parts. However, assuming that the availability of consistent discriminative regions may introduce errors, since occlusions are a major problem in the context of ReID due to drastic view changes.</p><p>The discriminative regions that can be used to match two people may not be available in all instances, such that the approaches require to maintain performance without relying on the availability of high discriminability regions or, in other words, being able to encode richer information from less discriminative regions. In this sense, we propose a method that aims to simulate this scenario by dropping top activated (most discriminative) regions and reinforcing the network to perform ReID with only less discriminative regions available.</p><p>To further improve ReID performance, literature have proposed re-ranking <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b30">[31]</ref> and augmentation <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b32">[33]</ref> approaches. The former methods can improve ReID results by a huge margin, which makes it unfair to compare pipelines using them against pipelines not using them. Therefore, since various state-of-the-art methods report results with and without re-ranking, our comparison to them is made separately for these two scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head><p>This section describes our Top DropBlock Network (Top-DB-Net) for addressing the ReID problem. We first introduce our baseline based on BDB Network <ref type="bibr" target="#b8">[9]</ref>. Then, we present each of the three streams of our Top-DB-Net and the loss functions used to train our model. The combination of these streams leads to improvements in the final performance and activation maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Baseline</head><p>We decided to use BDB Network <ref type="bibr" target="#b8">[9]</ref> as the baseline for our proposal because of its similarity with our approach. BDB Network uses ResNet-50 <ref type="bibr" target="#b33">[34]</ref> as backbone as in many ReID works, however, a slight variation is made by removing the last pooling layer. Thus, a larger feature map is obtained, more specifically, with a size of 2048×24×8.</p><p>On top of the backbone, two streams are used. The first stream, also known as global stream, appends a global average pooling layer to obtain a 2048-dimensional feature vector. Then, a 1×1 convolution layer is used to further reduce the dimensions. The second stream, named as Batch DropBlock, randomly removes regions on training batches. We denote this dropping module as Batch DropBlock. Then a global maximum pooling layer is appended by creating a 2048-dimensional feature vector. A maximum pooling helps to dismiss the effect of dropped regions. Finally, a fully connected layer is used to reduce the feature vector to 1024 dimensions.</p><p>Batch DropBlock is defined to remove a region of a preestablished size based on a ratio of input images. Since BDB Network <ref type="bibr" target="#b8">[9]</ref> reports the best results in regions with a third of height and the same width as the feature map, our Top DropBlock is defined specifically for the same scenario, this is, removing horizontal stripes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Top-DB-Net</head><p>Our proposed network shares the same backbone as the baseline. Global, Top DropBlock and regularizer streams ( <ref type="figure" target="#fig_0">Figure 3</ref>) are then appended. Global streams aim to extract general features directly from the backbone, following various previous approaches <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. The Top DropBlock stream appends two BottleNeck layers <ref type="bibr" target="#b33">[34]</ref> to the backbone stream and removes horizontal stripes from the most activated regions in order to push the network to maintain discriminability with less relevant data.</p><p>Given a training batch of n images, the most activated (the most informative) stripes are defined for each image independently: the backbone outputs n feature maps F of size c×h×w, where c, h and w indicates channels, height and width respectively. We transform F into an activation map A based on the definition proposed by Zagoruyko et al. <ref type="bibr" target="#b10">[11]</ref>:</p><formula xml:id="formula_0">A = c i=1 |F i | p<label>(1)</label></formula><p>where F i represents every tensor slide of size h×w. Assuming that p &gt; 1 by definition <ref type="bibr" target="#b10">[11]</ref>, we will see that p value is not relevant to our approach. Based on A, we define the relevance R of each stripe r j as the average of the values on row j:</p><formula xml:id="formula_1">r j = w k=1 A j,k w<label>(2)</label></formula><p>Finally, we can zero out rows with the largest r j values. We denote this module as Top DropBlock. For the dropping process, we create a binary mask TDM, named Top Drop Mask, of size c×h×w for every feature map F and apply the dot product between TDM and G, where G is a tensor with the same size as F , which is the result of applying two BottleNeck layers <ref type="bibr" target="#b33">[34]</ref> on F :</p><formula xml:id="formula_2">TDM i,j,k = 0, if r j ∈ the largest values 1, otherwise (3) such that 1 ≤ i ≤ c and 1 ≤ k ≤ w.</formula><p>It is worth mentioning that, from Equations 1 to 2, r j can be expressed as:</p><formula xml:id="formula_3">r j = c i=1 w k=1 |F p i,j,k | w<label>(4)</label></formula><p>Thus, the value of p is not relevant because |x| p ≤ |x| p+1 for every p &gt; 1 and we use r j specifically for ranking.</p><p>Due to the |.| function in the r j definition, the most relevant stripes represent areas in F with values besides zero, both positives and negatives. We can consider those to hold more discriminative information. By removing them, we push the network to learn to distinguish between samples with less available information, thus enhancing its capabilities to encode low discriminative regions. However, if the dropped regions are too large, Top DropBlock can create noise in G due to false positives generated by removing regions that represent unique regions between different ID inputs.</p><p>To alleviate this problem, we propose a regularizer stream that will help maintain performance based on the multi-task principle <ref type="bibr" target="#b11">[12]</ref>. This stream is only used in the training. It appends a global average pooling layer to G and is then trained for ReID. Thus, it encourages G to keep the information relevant to the ReID.</p><p>The loss function used for the three streams is the cross entropy with the label smoothing regularizer <ref type="bibr" target="#b34">[35]</ref> and triplet loss with hard positive-negative mining <ref type="bibr" target="#b35">[36]</ref>. During the testing process, the output of global and Top DropBlock streams are concatenated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head><p>This section describes and discusses the main aspects related to implementation details, validation protocols and experimental results. An ablation study is carried out to analyze the effects of the Regularization and Top DropBlock streams on the Top-DB-Net. Then, we compare the results to our baseline and discuss the effects of our dropping top activation during the learning process. Finally, we compare our method to state-of-the-art approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation Details</head><p>All our experiments were conducted on a single Tesla v100 GPU. Due to this, we updated two items in the baseline code 2 :</p><p>(i) we trained it with batch size of 64, instead of 128, and (ii) we reduced the learning rate by a factor of 0.5× because of the "linear scaling rule" <ref type="bibr" target="#b36">[37]</ref> to minimize the effects of training with smaller batch size.</p><p>During the training step, input images are resized to 384×128 pixels and augmented by random horizontal flip, random zooming and random input erasing <ref type="bibr" target="#b37">[38]</ref>. As mentioned previously, our Top DropBlock stream removes horizontal stripes, thus width dropping ratio is 1. Following our baseline configuration, we use a height drop ratio of 0.3. During the testing step, no drop is applied.</p><p>Top-DropDB-Net follows the same training setup than our baseline, based on Adam Optimizer <ref type="bibr" target="#b38">[39]</ref> and a linear warmup <ref type="bibr" target="#b36">[37]</ref> in the first 50 epochs with initial value of 1e − 3, then decayed to 1 − e4 and 1e − 5 after 200 and 300 epochs, respectively. The training routine takes 400 epochs. Due to the randomness of the drop masks used in our baseline and the methods used for data augmentation, we performed each experiment 5 times and reported the mean and standard deviation. This will allow for a fairer comparison between our method, baseline and ablation pipelines.</p><p>To combine cross entropy loss with label smoothing regularizer <ref type="bibr" target="#b34">[35]</ref> and triplet loss with hard positive-negative mining <ref type="bibr" target="#b35">[36]</ref>, we used the neck method <ref type="bibr" target="#b9">[10]</ref>. <ref type="bibr">120</ref> 240 400 120 240 400 <ref type="figure">Fig. 4</ref>: Activation maps for Top-DB-Net in two images at different epochs. The number below the images indicates the epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Datasets</head><p>We evaluate our framework on three widely used datasets. DukeMTMC-ReID dataset <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> has hand-drawn bounding boxes with various backgrounds of outdoor scenes. Market1501 dataset <ref type="bibr" target="#b21">[22]</ref> aims to simulate a more real-world scenario and was generated through the Deformable Part Model (DPM) <ref type="bibr" target="#b39">[40]</ref>. CUHK03 dataset <ref type="bibr" target="#b12">[13]</ref> exhibits recurrently missing body parts, occlusions and misalignment; we tested its two versions: detected (CUHK03 (D)) and labeled (CUHK03 (L)).</p><p>For training and testing, we follow the standard train/test split proposed by the dataset authors <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b39">[40]</ref>. In the case of CUHK03, we use the new partition <ref type="bibr" target="#b22">[23]</ref> of 767/700, which makes this dataset more challenging. Results for each dataset are based on mean Average Precision (mAP) and Cumulative Matching Curve (CMC), more specifically, rank-1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation Study</head><p>We evaluate the effects of Top DropBlock and Regularization streams. Furthermore, we discuss the effects of Top DropBlock during the learning process and compare it to our baseline.</p><p>1) Influence of the Top DropBlock Stream: In this section, we aim to analyze the effect of our Top DropBlock stream. We train Top-DB-Net by removing the DropBlock stream and maintaining the global and regularization streams using the two Bottleneck layers. We refer to this version as no-drop Top-DB-Net. During testing, we concatenate the output of global and regularization branches because both streams are trained with the same loss function. Results for this comparison are shown in <ref type="table" target="#tab_1">Table I</ref>.</p><p>In all datasets, we can see that removing the Top DropBlock stream decreases performance, which is also true for the standard deviation. On the Market1501 <ref type="bibr" target="#b21">[22]</ref> and DukeMTMC-ReID <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> datasets, the difference is usually less than 1% for mAP and rank-1. However, on the CUHK03 <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b22">[23]</ref> dataset, we can observe significant differences: performance decreases 4.7% in mAP and 5.6% in rank-1 on CUHK03(L) and decreases 4.8% in mAP and 5.4% in rank-1 on CUHK03(D). The difference in effects between datasets may be related to the fact that CUHK03 is a more challenging benchmark. This same pattern is repeated when analyzing the effect of our Regularization stream and baseline.</p><p>These results are expected because the global and regularization streams follow the same optimization logic: push the backbone to encode relevant ReID information from the input images. On the other hand, when we use our Top DropBlock stream, we further encourage the backbone to recognize relevant regions and learn to describe less informative regions with richer features.</p><p>2) Influence of the Regularization Stream: In this section, our goal is to show that the regularization stream, in fact, helps to deal with the noise generated by the dropping step. For this purpose, we train a version of the Top-DB-Net without this stream, named no-reg Top-DB-Net and compare it to the proposed Top-DB-Net. We can see in <ref type="table" target="#tab_1">Table I</ref> a clear difference when using the regularization stream.</p><p>Using our regularization stream, we observe improvements of 1.9% and 1% for mAP and rank-1, respectively, on Mar-ket1501 dataset <ref type="bibr" target="#b21">[22]</ref>. DukeMTMC-ReID <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref> also shows improvements of 2.4% for mAP and 1.4% for rank-1. Similar to previous ablation analysis, the most substantial changes are for CUHK03 <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b22">[23]</ref>: we can observe improvements of 4.8% for rank-1 and 4% for mAP on CUHK03(L), and 3.8% for rank-1 and mAP on CUHK03(D).</p><p>3) Random DropBlock vs Top DropBlock: Results in <ref type="table" target="#tab_1">Table I</ref> show that our Top-DB-Net is better than our baseline in almost all metrics. The only metric with similar performance is mAP for DukeMTMC-ReID. The biggest differences are again on CUHK03 <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b22">[23]</ref> dataset, with up to 4.7% improvement for rank-1 and 3.2% for mAP when using our Top-DB-Net. To further understand the difference in performance, we explore activation maps and their relation with the core of our method and the baseline: DropBlocks. <ref type="figure" target="#fig_1">Figure 5</ref> shows the differences between the two dropping methods. In <ref type="figure" target="#fig_2">Figure 6</ref>, we compare the evolution of rank-3 at different epochs for our Top-DB-Net and baseline. We also show the evolution of the activation maps. This example shows that our Top DropBlock improves the dispersion of activation maps in the foreground and the feature extraction from images. At 120th epoch, the activations of the query are similarly spread over the upper body and feet, both in the baseline and our method. However, we can see that, in the gallery, our method is better spread across the lower body, causing Top-DB-Net to incorrectly obtain rank-1/2, confusing a person who shares pants similar to the query. At 240th epoch, we can see that query rank-1 rank-2 rank-3 query rank-1 rank-2 rank-3 query rank-1 rank-2 rank-3 The top and bottom sets show images for our baseline and our proposed method, respectively. We can see that using Top DropBlock, instead of Random DropBlock, makes the activations more spread out over the person, which helps to create a better feature representation. Correct results are highlighted in green, whereas incorrect results are highlighted in red.</p><p>the baseline activations for the query have barely changed. Moreover, because it focuses only on the upper-body and feet, it is confused with images of a person with a similar upper body, but wearing a squirt with similar color instead of pants. On the contrary, our Top-DB-Net changed its activations for the query between 120th and 240th epochs, and also focuses on the lower body. For this specific example, this is because our Top DropBlock removes the upper body regions and pushes the backbone to learn from the lower body since the 120th epoch, which helps to correctly match rank-1/2/3. It is also possible to notice that, because our Top DropBlock pushes the network to describe low informative regions with rich features, at 240th epoch, our network has better features to describe lower body regions, so it fixes rank-1/2 errors of 120th epoch. Finally, at 400th epoch, the baseline has still changed very little the distribution of its activations and still focuses only on the upper body and feet. It is able to obtain correct rank-2. On the other hand, our method still focuses on the entire body, retrieves the same correct baseline rank-2 and offers more similarity 3 to two images that <ref type="bibr" target="#b2">3</ref> Shortest Euclidean distance between features from query and gallery images.</p><p>show a strong viewpoint change and occlusions. This shows the improvement of the feature discriminability between 240th and 400th epochs.</p><p>Activation plots are useful for the interpretability of networks. In our case, our plots are generated following Equation 1. This equation is also used to define our Top DropBlock and Top Drop masks. This shows that the same tool used for interpretability can also be applied during the learning process to enhance discriminability <ref type="table" target="#tab_1">(Table I</ref>). In addition to quantitative improvements, we observe a clear improvement in the quality of regions where backbone is concentrated. As shown in <ref type="figure" target="#fig_2">Figures 4 and 6</ref>, there is a consistent and significant activation improvement between 120th and 240th epochs, when they start to focus on broader body parts. From 240th to 400th epochs, we can see that the activations become more stable and well spread out in the foreground, but with an enhanced discriminability. We use the activation definition of Zagoruyko et al. <ref type="bibr" target="#b10">[11]</ref> because it adjusts to our network pipeline and drop objective. However, there is a previous work for ReID <ref type="bibr" target="#b44">[45]</ref> that uses CAM <ref type="bibr" target="#b48">[49]</ref>, an activation definition that introduces weights for each channel to enhance the scope of network activation. Previous literature and our findings suggest that methods used II: Comparison to the state-of-the-art approaches. RK stands for re-ranking <ref type="bibr" target="#b22">[23]</ref>. The sub-index indicates the ordinal position of this result (for instance, x 3 indicates that x is the third best result).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Market1501</head><p>DukeMTMC-ReID CUHK03 (L) CUHK03 (D) for interpretability may be useful to improve ReID and network activation in general.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. State-of-the-Art Comparison</head><p>Our method focuses on ReID using information extracted only from input images. Thus, in our comparison to the stateof-the-art, we consider methods in a similar way, for instance, Zhuet al. <ref type="bibr" target="#b49">[50]</ref> used the camera ID and Wanget al. <ref type="bibr" target="#b50">[51]</ref> used the image time-stamp during training. This extra information may bias the models to learn the mapping between the camera and views or the time needed for a person to move from different viewpoints, instead of extracting reliable information from images, so that they are not included in our comparison. <ref type="table" target="#tab_1">Table II</ref> shows a comparison between our method and state-ofthe-art approaches. We compare the results separately when using re-ranking <ref type="bibr" target="#b22">[23]</ref>.</p><p>Our results are among the top-6 results for both mAP and rank-1 on Market1501. We have a similar performance for rank-1 on DukeMTMC-ReID, however, for mAP, we achieved results comparable to state-of-the-art methods, such as OSNet <ref type="bibr" target="#b26">[27]</ref>, CAMA <ref type="bibr" target="#b44">[45]</ref> and IANet <ref type="bibr" target="#b28">[29]</ref>. We obtained the second best rank-1 on CUHK03(L), third best mAP on both versions of CUHK03 and fourth best rank-1 on CUHK03(D). When using re-ranking, our method achieved state-of-the-art results on CUHK03(L) and CUHK03(R) in both mAP and rank-1, as well as best results for rank-1 on DukeMTMC-ReID, second best mAP on DukeMTMC-ReID and second best on Market1501 in both mAP and rank-1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSIONS AND FUTURE WORK</head><p>In this paper, we introduced Top-DB-Net, a network for the person re-identification problem based on Top DropBlock. Top-DB-Net encourages the network to improve its performance by learning to generate rich encoding based on low informative regions. It consists of three streams: a global stream that follows standard feature encoding for the backbone, the Top DropBlock that pushes the network to maintain its performance while using less discriminative regions by dropping most activated parts of the feature map, and a regularization stream that helps to deal with the noise created by the dropping process.</p><p>Extensive experiments conducted on three widely datasets demonstrated the power of our method to achieve competitive results and its capability to generate better activation maps than competing methods. Moreover, our results suggest that methods proposed for interpretability of activation maps can help during training in ReID.</p><p>As directions for future work, we expect to extend the definition of Top DropBlock to various dropping ratios, instead of only horizontal stripes. Furthermore, we intend to encode higher level features (for instance, gender) and analyze their impact on the ReID task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>Part of this work was done while the first author was affiliated with Microsoft Corp. We are thankful to Microsoft Research, São Paulo Research Foundation (FAPESP grant #2017/12646-3), National Council for Scientific and Technological Development (CNPq grant #309330/2018-1) and Coordination for the Improvement of Higher Education Personnel (CAPES) for their financial support.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 3 :</head><label>3</label><figDesc>Proposed Top DropBlock Network (Top-DB-Net). It is composed of three streams that are able to focus on reliable parts of the input and encode low informative regions with high discriminative features for enhanced performance. It is trained using triplet loss and cross entropy. During the testing stage, the outputs of Global and Top DropBlock streams are concatenated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 5 :</head><label>5</label><figDesc>Differences between the Batch DropBlock and proposed Top DropBlock.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 :</head><label>6</label><figDesc>Top-DB-Net epoch 120 (e) Top-DB-Net epoch 240 (f) Top-DB-Net epoch 400 Comparison of activation and rank-3 evolution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Influence of Top-DB-Net streams and comparison with baseline.</figDesc><table><row><cell></cell><cell cols="2">Market1501</cell><cell cols="2">DukeMTMC-ReID</cell><cell cols="2">CUHK03 (L)</cell><cell cols="2">CUHK03 (D)</cell></row><row><cell>Method</cell><cell>mAP</cell><cell>rank-1</cell><cell>mAP</cell><cell>rank-1</cell><cell>mAP</cell><cell>rank-1</cell><cell>mAP</cell><cell>rank-1</cell></row><row><cell>no-drop Top-DB-Net</cell><cell>84.7 ± 0.1</cell><cell>94.4 ± 0.3</cell><cell>72.7 ± 0.2</cell><cell>86.1 ± 0.3</cell><cell>70.7 ± 0.4</cell><cell>73.8 ± 0.6</cell><cell>68.4 ± 0.4</cell><cell>71.9 ± 0.3</cell></row><row><cell>no-reg Top-DB-Net</cell><cell>83.9 ± 0.1</cell><cell>93.9 ± 0.2</cell><cell>71.1 ± 0.2</cell><cell>86.1 ± 0.4</cell><cell>71.4 ± 0.4</cell><cell>74.6 ± 0.8</cell><cell>69.4 ± 0.4</cell><cell>73.5 ± 1.0</cell></row><row><cell>Top-DB-Net</cell><cell>85.8 ± 0.1</cell><cell>94.9 ± 0.1</cell><cell>73.5 ± 0.2</cell><cell>87.5 ± 0.3</cell><cell>75.4 ± 0.2</cell><cell>79.4 ± 0.5</cell><cell>73.2 ± 0.1</cell><cell>77.3 ± 0.5</cell></row><row><cell>Baseline</cell><cell>85.2 ± 0.1</cell><cell>94.1 ± 0.1</cell><cell>73.2 ± 0.2</cell><cell>85.6 ± 0.3</cell><cell>72.2 ± 0.3</cell><cell>74.7 ± 0.6</cell><cell>70.3 ± 0.2</cell><cell>73.7 ± 0.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use the terms remove and drop interchangeably to indicate that a tensor region has been zeroed out.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We used author's<ref type="bibr" target="#b8">[9]</ref> original source code available at https://github.com/ daizuozhuo/batch-DropBlock-network</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Vehicle Re-identification by Deep Hidden Multi-view Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3275" to="3287" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Large-scale Vehicle Re-identification in Urban Surveillance Videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Multimedia and Expo</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">MVB: A Large-Scale Dataset for Baggage Re-identification and Merged Siamese Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Chinese Conference on Pattern Recognition and Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="84" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Improved Person Re-identification based on Saliency and Semantic Parsing with Deep Neural Network Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Quispe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pedrini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page">103809</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Pose-aware Person Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Namboodiri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jawahar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6223" to="6232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Pose-invariant Embedding for Deep Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4500" to="4509" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning Deep Context-aware Features over Body and Latent Parts for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="384" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Person Reidentification by Multi-Channel Parts-based CNN with Improved Triplet Loss Function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1335" to="1344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Batch DropBlock Network for Person Re-identification and Beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3691" to="3701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Bag of Tricks and a Strong Baseline for Deep Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Paying more Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<meeting><address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06" />
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deepreid: Deep Filter Pairing Neural Network for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Keeping Track of Humans: Have I seen this Person Before?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zajdel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zivkovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="2081" to="2086" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">People Reidentification in Surveillance and Forensics: A Survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vezzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Baltieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Viewpoint Invariant Pedestrian Recognition with an Ensemble of Localized Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="262" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Person Re-identification using Haar-based and DCD-based Signature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Corvee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bremond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Thonnat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Advanced Video and Signal Based Surveillance</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Custom Pictorial Structures for Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stoppa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bazzani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Murino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Dense Appearance Modeling and Efficient Learning of Camera Transitions for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Beleznai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Köstinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Image Processing</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1617" to="1620" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Person Re-identification by Efficient Impostor-based Metric Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Ninth International Conference on Advanced Video and Signal-Based Surveillance</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="203" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Person Reidentification with Content and Context Re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="6989" to="7014" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Scalable Person Re-identification: A Benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1116" to="1124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Re-ranking Person Reidentification with k-reciprocal Encoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1318" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Unlabeled Samples Generated by GAN Improve the Person Re-identification Baseline in Vitro</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="754" to="3762" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision Workshops</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="17" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Torchreid: A Library for Deep Learning Person Re-identification in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.10093</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Omni-Scale Feature Learning for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3702" to="3712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Harmonious Attention Network for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2285" to="2294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Interaction-andaggregation Network for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9317" to="9326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Second-Order Non-Local Attention Networks for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Poellabauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3760" to="3769" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Pose-sensitive Embedding for Person Re-identification with Expanded Cross Neighborhood Re-ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sarfraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Eberle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="420" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Joint Discriminative and Generative Learning for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2138" to="2147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Camstyle: A Novel Data Augmentation Method for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1176" to="1190" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">In Defense of the Triplet Loss for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hermans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.07737</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Dropblock: A Regularization Method for Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y.</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10" to="727" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Object Detection with Discriminatively Trained Part-based Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1627" to="1645" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Aggregating Deep Pyramidal Representations for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Martinel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">Luca</forename><surname>Foresti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Micheloni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Auto-ReID: Searching for a Part-aware ConvNet for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3750" to="3759" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning Discriminative Features with Multiple Granularities for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="274" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Densely Semantically Aligned Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Towards Rich Feature Discovery with Class Activation Maps Augmentation for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1389" to="1398" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Mixed High-order Attention Network for Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="371" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Abd-net: Attentive but Diverse Person Re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8351" to="8361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pyramidal Person Re-identification via Multi-loss Dynamic Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8514" to="8522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning Deep Features for Discriminative Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2921" to="2929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Viewpoint-Aware Loss with Angular Regularization for Person Re-Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="13" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Spatial-temporal Person Reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="8933" to="8940" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
