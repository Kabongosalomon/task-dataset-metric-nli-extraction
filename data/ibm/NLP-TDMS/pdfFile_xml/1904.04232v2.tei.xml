<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A CLOSER LOOK AT FEW-SHOT CLASSIFICATION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Yu</forename><surname>Chen</surname></persName>
							<email>weiyuc@andrew.cmu.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
							<email>ycliu@gatech.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
							<email>zkira@gatech.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang</forename><forename type="middle">Frank</forename><surname>Wang</surname></persName>
							<email>ycwang@ntu.edu.tw</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia-Bin</forename><surname>Huang</surname></persName>
							<email>jbhuang@vt.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Virginia</forename><surname>Tech</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<country>Georgia Tech</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">National Taiwan University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A CLOSER LOOK AT FEW-SHOT CLASSIFICATION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Few-shot classification aims to learn a classifier to recognize unseen classes during training with limited labeled examples. While significant progress has been made, the growing complexity of network designs, meta-learning algorithms, and differences in implementation details make a fair comparison difficult. In this paper, we present 1) a consistent comparative analysis of several representative few-shot classification algorithms, with results showing that deeper backbones significantly reduce the performance differences among methods on datasets with limited domain differences, 2) a modified baseline method that surprisingly achieves competitive performance when compared with the state-of-the-art on both the mini-ImageNet and the CUB datasets, and 3) a new experimental setting for evaluating the cross-domain generalization ability for few-shot classification algorithms. Our results reveal that reducing intra-class variation is an important factor when the feature backbone is shallow, but not as critical when using deeper backbones. In a realistic cross-domain evaluation setting, we show that a baseline method with a standard fine-tuning practice compares favorably against other state-of-the-art few-shot learning algorithms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep learning models have achieved state-of-the-art performance on visual recognition tasks such as image classification. The strong performance, however, heavily relies on training a network with abundant labeled instances with diverse visual variations (e.g., thousands of examples for each new class even with pre-training on large-scale dataset with base classes). The human annotation cost as well as the scarcity of data in some classes (e.g., rare species) significantly limit the applicability of current vision systems to learn new visual concepts efficiently. In contrast, the human visual systems can recognize new classes with extremely few labeled examples. It is thus of great interest to learn to generalize to new classes with a limited amount of labeled examples for each novel class.</p><p>The problem of learning to generalize to unseen classes during training, known as few-shot classification, has attracted considerable attention <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref>; <ref type="bibr" target="#b27">Snell et al. (2017)</ref> <ref type="bibr">;</ref><ref type="bibr" target="#b6">Finn et al. (2017)</ref>; <ref type="bibr" target="#b25">Ravi &amp; Larochelle (2017)</ref>; <ref type="bibr" target="#b28">Sung et al. (2018)</ref>; <ref type="bibr" target="#b9">Garcia &amp; Bruna (2018)</ref>; <ref type="bibr" target="#b24">Qi et al. (2018)</ref>. One promising direction to few-shot classification is the meta-learning paradigm where transferable knowledge is extracted and propagated from a collection of tasks to prevent overfitting and improve generalization. Examples include model initialization based methods <ref type="bibr" target="#b25">Ravi &amp; Larochelle (2017)</ref> <ref type="bibr">;</ref><ref type="bibr" target="#b6">Finn et al. (2017)</ref>, metric learning methods <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref>; <ref type="bibr" target="#b27">Snell et al. (2017)</ref>; <ref type="bibr" target="#b28">Sung et al. (2018)</ref>, and hallucination based methods <ref type="bibr" target="#b0">Antoniou et al. (2018)</ref>; <ref type="bibr" target="#b11">Hariharan &amp; Girshick (2017)</ref>; <ref type="bibr" target="#b31">Wang et al. (2018)</ref>. Another line of work <ref type="bibr" target="#b10">Gidaris &amp; Komodakis (2018)</ref>; <ref type="bibr" target="#b24">Qi et al. (2018)</ref> also demonstrates promising results by directly predicting the weights of the classifiers for novel classes.</p><p>Limitations. While many few-shot classification algorithms have reported improved performance over the state-of-the-art, there are two main challenges that prevent us from making a fair comparison and measuring the actual progress. First, the discrepancy of the implementation details among multiple few-shot learning algorithms obscures the relative performance gain. The performance of Published as a conference paper at ICLR 2019 baseline approaches can also be significantly under-estimated (e.g., training without data augmentation). Second, while the current evaluation focuses on recognizing novel class with limited training examples, these novel classes are sampled from the same dataset. The lack of domain shift between the base and novel classes makes the evaluation scenarios unrealistic.</p><p>Our work. In this paper, we present a detailed empirical study to shed new light on the few-shot classification problem. First, we conduct consistent comparative experiments to compare several representative few-shot classification methods on common ground. Our results show that using a deep backbone shrinks the performance gap between different methods in the setting of limited domain differences between base and novel classes. Second, by replacing the linear classifier with a distance-based classifier as used in <ref type="bibr" target="#b10">Gidaris &amp; Komodakis (2018)</ref>; <ref type="bibr" target="#b24">Qi et al. (2018)</ref>, the baseline method is surprisingly competitive to current state-of-art meta-learning algorithms. Third, we introduce a practical evaluation setting where there exists domain shift between base and novel classes (e.g., sampling base classes from generic object categories and novel classes from fine-grained categories). Our results show that sophisticated few-shot learning algorithms do not provide performance improvement over the baseline under this setting. Through making the source code and model implementations with a consistent evaluation setting publicly available, we hope to foster future progress in the field. 1 Our contributions.</p><p>1. We provide a unified testbed for several different few-shot classification algorithms for a fair comparison. Our empirical evaluation results reveal that the use of a shallow backbone commonly used in existing work leads to favorable results for methods that explicitly reduce intra-class variation. Increasing the model capacity of the feature backbone reduces the performance gap between different methods when domain differences are limited.</p><p>2. We show that a baseline method with a distance-based classifier surprisingly achieves competitive performance with the state-of-the-art meta-learning methods on both mini-ImageNet and CUB datasets.</p><p>3. We investigate a practical evaluation setting where base and novel classes are sampled from different domains. We show that current few-shot classification algorithms fail to address such domain shifts and are inferior even to the baseline method, highlighting the importance of learning to adapt to domain differences in few-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Given abundant training examples for the base classes, few-shot learning algorithms aim to learn to recognizing novel classes with a limited amount of labeled examples. Much efforts have been devoted to overcome the data efficiency issue. In the following, we discuss representative few-shot learning algorithms organized into three main categories: initialization based, metric learning based, and hallucination based methods.</p><p>Initialization based methods tackle the few-shot learning problem by "learning to fine-tune". One approach aims to learn good model initialization (i.e., the parameters of a network) so that the classifiers for novel classes can be learned with a limited number of labeled examples and a small number of gradient update steps <ref type="bibr" target="#b6">Finn et al. (2017;</ref>; <ref type="bibr" target="#b22">Nichol &amp; Schulman (2018)</ref>; <ref type="bibr" target="#b26">Rusu et al. (2019)</ref>. Another line of work focuses on learning an optimizer. Examples include the LSTM-based meta-learner for replacing the stochastic gradient decent optimizer <ref type="bibr" target="#b25">Ravi &amp; Larochelle (2017)</ref> and the weight-update mechanism with an external memory <ref type="bibr" target="#b21">Munkhdalai &amp; Yu (2017)</ref>. While these initialization based methods are capable of achieving rapid adaption with a limited number of training examples for novel classes, our experiments show that these methods have difficulty in handling domain shifts between base and novel classes.</p><p>Distance metric learning based methods address the few-shot classification problem by "learning to compare". The intuition is that if a model can determine the similarity of two images, it can classify an unseen input image with the labeled instances <ref type="bibr" target="#b16">Koch et al. (2015)</ref>. To learn a sophisticated comparison models, meta-learning based methods make their prediction conditioned on distance or metric to few labeled instances during the training process. Examples of distance metrics include cosine similarity <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref>, Euclidean distance to class-mean representation <ref type="bibr" target="#b27">Snell et al. (2017)</ref>, CNN-based relation module <ref type="bibr" target="#b28">Sung et al. (2018)</ref>, ridge regression <ref type="bibr" target="#b1">Bertinetto et al. (2019)</ref>, and graph neural network <ref type="bibr" target="#b9">Garcia &amp; Bruna (2018)</ref>. In this paper, we compare the performance of three distance metric learning methods. Our results show that a simple baseline method with a distancebased classifier (without training over a collection of tasks/episodes as in meta-learning) achieves competitive performance with respect to other sophisticated algorithms.</p><p>Besides meta-learning methods, both <ref type="bibr" target="#b10">Gidaris &amp; Komodakis (2018)</ref> and <ref type="bibr" target="#b24">Qi et al. (2018)</ref> develop a similar method to our Baseline++ (described later in Section 3.2). The method in <ref type="bibr" target="#b10">Gidaris &amp; Komodakis (2018)</ref> learns a weight generator to predict the novel class classifier using an attentionbased mechanism (cosine similarity), and the <ref type="bibr" target="#b24">Qi et al. (2018)</ref> directly use novel class features as their weights. Our Baseline++ can be viewed as a simplified architecture of these methods. Our focus, however, is to show that simply reducing intra-class variation in a baseline method using the base class data leads to competitive performance.</p><p>Hallucination based methods directly deal with data deficiency by "learning to augment". This class of methods learns a generator from data in the base classes and use the learned generator to hallucinate new novel class data for data augmentation. One type of generator aims at transferring appearance variations exhibited in the base classes. These generators either transfer variance in base class data to novel classes <ref type="bibr" target="#b11">Hariharan &amp; Girshick (2017)</ref>, or use GAN models <ref type="bibr" target="#b0">Antoniou et al. (2018)</ref> to transfer the style. Another type of generators does not explicitly specify what to transfer, but directly integrate the generator into a meta-learning algorithm for improving the classification accuracy <ref type="bibr" target="#b31">Wang et al. (2018)</ref>. Since hallucination based methods often work with other few-shot methods together (e.g. use hallucination based and metric learning based methods together) and lead to complicated comparison, we do not include these methods in our comparative study and leave it for future work.</p><p>Domain adaptation techniques aim to reduce the domain shifts between source and target domain Pan et al. (2010); <ref type="bibr" target="#b8">Ganin &amp; Lempitsky (2015)</ref>, as well as novel tasks in a different domain <ref type="bibr" target="#b14">Hsu et al. (2018)</ref>. Similar to domain adaptation, we also investigate the impact of domain difference on fewshot classification algorithms in Section 4.5. In contrast to most domain adaptation problems where a large amount of data is available in the target domain (either labeled or unlabeled), our problem setting differs because we only have very few examples in the new domain. Very recently, the method in <ref type="bibr" target="#b5">Dong &amp; Xing (2018)</ref> addresses the one-shot novel category domain adaptation problem, where in the testing stage both the domain and the category to classify are changed. Similarly, our work highlights the limitations of existing few-shot classification algorithms problem in handling domain shift. To put these problem settings in context, we provided a detailed comparison of setting difference in the appendix A1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">OVERVIEW OF FEW-SHOT CLASSIFICATION ALGORITHMS</head><p>In this section, we first outline the details of the baseline model (Section 3.1) and its variant (Section 3.2), followed by describing representative meta-learning algorithms (Section 3.3) studied in our experiments. Given abundant base class labeled data X b and a small amount of novel class labeled data X n , the goal of few-shot classification algorithms is to train classifiers for novel classes (unseen during training) with few labeled examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">BASELINE</head><p>Our baseline model follows the standard transfer learning procedure of network pre-training and fine-tuning. <ref type="figure" target="#fig_0">Figure 1</ref> illustrates the overall procedure.</p><p>Training stage. We train a feature extractor f θ (parametrized by the network parameters θ ) and the classifier C(·|W b ) (parametrized by the weight matrix W b ∈ R d×c ) from scratch by minimizing a standard cross-entropy classification loss L pred using the training examples in the base classes</p><formula xml:id="formula_0">x i ∈ X b .</formula><p>Here, we denote the dimension of the encoded feature as d and the number of output classes as c. The classifier C(.|W b ) consists of a linear layer W b f θ (x i ) followed by a softmax function σ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline++ Baseline</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training stage Classifier</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature extractor</head><p>Novel class data (Few) Fine-tuning stage. To adapt the model to recognize novel classes in the fine-tuning stage, we fix the pre-trained network parameter θ in our feature extractor f θ and train a new classifier C(.|W n ) (parametrized by the weight matrix W n ) by minimizing L pred using the few labeled of examples (i.e., the support set) in the novel classes X n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fine-tuning stage</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">BASELINE++</head><p>In addition to the baseline model, we also implement a variant of the baseline model, denoted as Baseline++, which explicitly reduces intra-class variation among features during training. The importance of reducing intra-class variations of features has been highlighted in deep metric learning <ref type="bibr" target="#b15">Hu et al. (2015)</ref> and few-shot classification methods <ref type="bibr" target="#b10">Gidaris &amp; Komodakis (2018)</ref>.</p><p>The training procedure of Baseline++ is the same as the original Baseline model except for the classifier design. As shown in <ref type="figure" target="#fig_0">Figure 1</ref>, we still have a weight matrix W b ∈ R d×c of the classifier in the training stage and a W n in the fine-tuning stage in Baseline++. The classifier design, however, is different from the linear classifier used in the Baseline. Take the weight matrix W b as an example. We can write the weight matrix W b as [w 1 , w 2 , ...w c ], where each class has a d-dimensional weight vector. In the training stage, for an input feature f θ (x i ) where x i ∈ X b , we compute its cosine similarity to each weight vector [w 1 , · · · , w c ] and obtain the similarity scores</p><formula xml:id="formula_1">[s i,1 , s i,2 , · · · , s i,c ] for all classes, where s i, j = f θ (x i ) w j / f θ (x i ) w j .</formula><p>We can then obtain the prediction probability for each class by normalizing these similarity scores with a softmax function. Here, the classifier makes a prediction based on the cosine distance between the input feature and the learned weight vectors representing each class. Consequently, training the model with this distance-based classifier explicitly reduce intra-class variations. Intuitively, the learned weight vectors [w 1 , · · · , w c ] can be interpreted as prototypes (similar to <ref type="bibr" target="#b27">Snell et al. (2017)</ref>; <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref>) for each class and the classification is based on the distance of the input feature to these learned prototypes. The softmax function prevents the learned weight vectors collapsing to zeros.</p><p>We clarify that the network design in Baseline++ is not our contribution. The concept of distancebased classification has been extensively studied in <ref type="bibr" target="#b18">Mensink et al. (2012)</ref> and recently has been revisited in the few-shot classification setting <ref type="bibr" target="#b10">Gidaris &amp; Komodakis (2018)</ref>; <ref type="bibr" target="#b24">Qi et al. (2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">META-LEARNING ALGORITHMS</head><p>Here we describe the formulations of meta-learning methods used in our study. We consider three distance metric learning based methods <ref type="bibr">(MatchingNet Vinyals et al. (2016)</ref>, ProtoNet Snell et al.   <ref type="formula">2017)</ref>). While meta-learning is not a clearly defined, <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref> considers a few-shot classification method as meta-learning if the prediction is conditioned on a small support set S, because it makes the training procedure explicitly learn to learn from a given small support set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Meta-training stage</head><p>As shown in <ref type="figure" target="#fig_1">Figure 2</ref>, meta-learning algorithms consist of a meta-training and a meta-testing stage.</p><p>In the meta-training stage, the algorithm first randomly select N classes, and sample small base support set S b and a base query set Q b from data samples within these classes. The objective is to train a classification model M that minimizes N-way prediction loss L N−way of the samples in the query set Q b . Here, the classifier M is conditioned on provided support set S b . By making prediction conditioned on the given support set, a meta-learning method can learn how to learn from limited labeled data through training from a collection of tasks (episodes). In the meta-testing stage, all novel class data X n are considered as the support set for novel classes S n , and the classification model M can be adapted to predict novel classes with the new support set S n .</p><p>Different meta-learning methods differ in their strategies to make prediction conditioned on support set (see <ref type="figure" target="#fig_1">Figure 2</ref>). For both MatchingNet <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref> and ProtoNet <ref type="bibr" target="#b27">Snell et al. (2017)</ref>, the prediction of the examples in a query set Q is based on comparing the distance between the query feature and the support feature from each class. MatchingNet compares cosine distance between the query feature and each support feature, and computes average cosine distance for each class, while ProtoNet compares the Euclidean distance between query features and the class mean of support features. RelationNet <ref type="bibr" target="#b28">Sung et al. (2018)</ref> shares a similar idea, but it replaces distance with a learnable relation module. The MAML method <ref type="bibr" target="#b6">Finn et al. (2017)</ref> is an initialization based meta-learning algorithm, where each support set is used to adapt the initial model parameters using few gradient updates. As different support sets have different gradient updates, the adapted model is conditioned on the support set. Note that when the query set instances are predicted by the adapted model in the meta-training stage, the loss of the query set is used to update the initial model, not the adapted model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">EXPERIMENTAL SETUP</head><p>Datasets and scenarios. We address the few-shot classification problem under three scenarios: 1) generic object recognition, 2) fine-grained image classification, and 3) cross-domain adaptation.</p><p>For object recognition, we use the mini-ImageNet dataset commonly used in evaluating few-shot classification algorithms. The mini-ImageNet dataset consists of a subset of 100 classes from the ImageNet dataset <ref type="bibr" target="#b4">Deng et al. (2009)</ref> and contains 600 images for each class. The dataset was first proposed by <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref>, but recent works use the follow-up setting provided by <ref type="bibr" target="#b25">Ravi &amp; Larochelle (2017)</ref>, which is composed of randomly selected 64 base, 16 validation, and 20 novel classes.</p><p>For fine-grained classification, we use CUB-200-2011 dataset <ref type="bibr" target="#b30">Wah et al. (2011)</ref> (referred to as the CUB hereafter). The CUB dataset contains 200 classes and 11,788 images in total. Following the evaluation protocol of <ref type="bibr" target="#b13">Hilliard et al. (2018)</ref>, we randomly split the dataset into 100 base, 50 validation, and 50 novel classes.</p><p>For the cross-domain scenario (mini-ImageNet →CUB), we use mini-ImageNet as our base class and the 50 validation and 50 novel class from CUB. Evaluating the cross-domain scenario allows us to understand the effects of domain shifts to existing few-shot classification approaches.</p><p>Implementation details. In the training stage for the Baseline and the Baseline++ methods, we train 400 epochs with a batch size of 16. In the meta-training stage for meta-learning methods, we train 60,000 episodes for 1-shot and 40,000 episodes for 5-shot tasks. We use the validation set to select the training episodes with the best accuracy. 2 In each episode, we sample N classes to form N-way classification (N is 5 in both meta-training and meta-testing stages unless otherwise mentioned). For each class, we pick k labeled instances as our support set and 16 instances for the query set for a k-shot task.</p><p>In the fine-tuning or meta-testing stage for all methods, we average the results over 600 experiments.</p><p>In each experiment, we randomly sample 5 classes from novel classes, and in each class, we also pick k instances for the support set and 16 for the query set. For Baseline and Baseline++, we use the entire support set to train a new classifier for 100 iterations with a batch size of 4. For meta-learning methods, we obtain the classification model conditioned on the support set as in Section 3.3.</p><p>All methods are trained from scratch and use the Adam optimizer with initial learning rate 10 −3 . We apply standard data augmentation including random crop, left-right flip, and color jitter in both the training or meta-training stage. Some implementation details have been adjusted individually for each method. For Baseline++, we multiply the cosine similarity by a class-wise learnable scalar to adjust original value range [-1,1] to be more appropriate for subsequent softmax layer. For Match-ingNet, we use an FCE classification layer without fine-tuning in all experiments and also multiply cosine similarity by a constant scalar. For RelationNet, we replace the L2 norm with a softmax layer to expedite training. For MAML, we use a first-order approximation in the gradient for memory efficiency. The approximation has been shown in the original paper and in our appendix to have nearly identical performance as the full version. We choose the first-order approximation for its efficiency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">EVALUATION USING THE STANDARD SETTING</head><p>We now conduct experiments on the most common setting in few-shot classification, 1-shot and 5-shot classification, i.e., 1 or 5 labeled instances are available from each novel class. We use a four-layer convolution backbone (Conv-4) with an input size of 84x84 as in <ref type="bibr" target="#b27">Snell et al. (2017)</ref> and perform 5-way classification for only novel classes during the fine-tuning or meta-testing stage.</p><p>To validate the correctness of our implementation, we first compare our results to the reported numbers for the mini-ImageNet dataset in <ref type="table">Table 1</ref>. Note that we have a ProtoNet # , as we use 5-way classification in the meta-training and meta-testing stages for all meta-learning methods as mentioned in Section 4.1; however, the official reported results from ProtoNet uses 30-way for one shot and 20-way for five shot in the meta-training stage in spite of using 5-way in the meta-testing stage. We report this result for completeness.</p><p>From <ref type="table">Table 1</ref>, we can observe that all of our re-implementation for meta-learning methods do not fall more than 2% behind reported performance. These minor differences can be attributed to our modifications of some implementation details to ensure a fair comparison among all methods, such as using the same optimizer for all methods. <ref type="table">Table 1</ref>: Validating our re-implementation. We validate our few-shot classification implementation on the mini-ImageNet dataset using a Conv-4 backbone. We report the mean of 600 randomly generated test episodes as well as the 95% confidence intervals. Our reproduced results to all few-shot methods do not fall behind by more than 2% to the reported results in the literature. We attribute the slight discrepancy to different random seeds and minor implementation differences in each method. "Baseline * " denotes the results without applying data augmentation during training. ProtoNet # indicates performing 30-way classification in 1-shot and 20-way in 5-shot during the meta-training stage.  Moreover, our implementation of existing work also improves the performance of some of the methods. For example, our results show that the Baseline approach under 5-shot setting can be improved by a large margin since previous implementations of the Baseline do not include data augmentation in their training stage, thereby leads to over-fitting. While our Baseline * is not as good as reported in 1-shot, our Baseline with augmentation still improves on it, and could be even higher if our reproduced Baseline * matches the reported statistics. In either case, the performance of the Baseline method is severely underestimated. We also improve the results of MatchingNet by adjusting the input score to the softmax layer to a more appropriate range as stated in Section 4.1. On the other hand, while ProtoNet # is not as good as ProtoNet, as mentioned in the original paper a more challenging setting in the meta-training stage leads to better accuracy. We choose to use a consistent 5-way classification setting in subsequent experiments to have a fair comparison to other methods. This issue can be resolved by using a deeper backbone as shown in Section 4.3.</p><p>After validating our re-implementation, we now report the accuracy in <ref type="table" target="#tab_2">Table 2</ref>. Besides additionally reporting results on the CUB dataset, we also compare Baseline++ to other methods. Here, we find that Baseline++ improves the Baseline by a large margin and becomes competitive even when compared with other meta-learning methods. The results demonstrate that reducing intra-class variation is an important factor in the current few-shot classification problem setting.</p><p>However, note that our current setting only uses a 4-layer backbone, while a deeper backbone can inherently reduce intra-class variation. Thus, we conduct experiments to investigate the effects of backbone depth in the next section.  <ref type="figure">Figure 3</ref>: Few-shot classification accuracy vs. backbone depth. In the CUB dataset, gaps among different methods diminish as the backbone gets deeper. In mini-ImageNet 5-shot, some meta-learning methods are even beaten by Baseline with a deeper backbone. (Please refer to <ref type="figure">Figure A3</ref> and <ref type="table">Table A5</ref> for larger figure and detailed statistics.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">EFFECT OF INCREASING THE NETWORK DEPTH</head><p>In this section, we change the depth of the feature backbone to reduce intra-class variation for all methods. See appendix for statistics on how network depth correlates with intra-class variation.</p><p>Starting from Conv-4, we gradually increase the feature backbone to Conv-6, ResNet-10, 18 and 34, where Conv-6 have two additional convolution blocks without pooling after Conv-4. ResNet-18 and 34 are the same as described in <ref type="bibr" target="#b12">He et al. (2016)</ref> with an input size of 224×224, while ResNet-10 is a simplified version of ResNet-18 where only one residual building block is used in each layer. The statistics of this experiment would also be helpful to other works to make a fair comparison under different feature backbones.</p><p>Results of the CUB dataset shows a clearer tendency in <ref type="figure">Figure 3</ref>. As the backbone gets deeper, the gap among different methods drastically reduces. Another observation is how ProtoNet improves rapidly as the backbone gets deeper. While using a consistent 5-way classification as discussed in Section 4.2 degrades the accuracy of ProtoNet with Conv-4, it works well with a deeper backbone. Thus, the two observations above demonstrate that in the CUB dataset, the gap among existing methods would be reduced if their intra-class variation are all reduced by a deeper backbone.</p><p>However, the result of mini-ImageNet in <ref type="figure">Figure 3</ref> is much more complicated. In the 5-shot setting, both Baseline and Baseline++ achieve good performance with a deeper backbone, but some metalearning methods become worse relative to them. Thus, other than intra-class variation, we can assume that the dataset is also important in few-shot classification. One difference between CUB and mini-ImageNet is their domain difference in base and novel classes since classes in mini-ImageNet have a larger divergence than CUB in a word-net hierarchy <ref type="bibr" target="#b19">Miller (1995)</ref>. To better understand the effect, below we discuss how domain differences between base and novel classes impact few-shot classification results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">EFFECT OF DOMAIN DIFFERENCES BETWEEN BASE AND NOVEL CLASSES</head><p>To further dig into the issue of domain difference, we design scenarios that provide such domain shifts. Besides the fine-grained classification and object recognition scenarios, we propose a new cross-domain scenario: mini-ImageNet →CUB as mentioned in Section 4.1. We believe that this is practical scenario since collecting images from a general class may be relatively easy (e.g. due to increased availability) but collecting images from fine-grained classes might be more difficult.</p><p>We conduct the experiments with a ResNet-18 feature backbone. As shown in <ref type="table" target="#tab_5">Table 3</ref>, the Baseline outperforms all meta-learning methods under this scenario. While meta-learning methods learn to learn from the support set during the meta-training stage, they are not able to adapt to novel classes that are too different since all of the base support sets are within the same dataset. A similar concept is also mentioned in <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref>. In contrast, the Baseline simply replaces and trains a new classifier based on the few given novel class data, which allows it to quickly adapt to a novel class and is less affected by domain shift between the source and target domains. The Baseline also performs better than the Baseline++ method, possibly because additionally reducing intra-class variation compromises adaptability. In <ref type="figure" target="#fig_2">Figure 4</ref>, we can further observe how Baseline accuracy   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CUB</head><p>mini-ImageNet CUB→mini-ImageNet <ref type="figure">Figure 5</ref>: Meta-learning methods with further adaptation steps. Further adaptation improves MatchingNet and MAML, but has less improvement to RelationNet, and could instead harm ProtoNet under the scenarios with little domain differences.All statistics are for 5-shot accuracy with ResNet-18 backbone. Note that different methods use different further adaptation strategies.</p><p>becomes relatively higher as the domain difference gets larger. That is, as the domain difference grows larger, the adaptation based on a few novel class instances becomes more important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">EFFECT OF FURTHER ADAPTATION</head><p>To further adapt meta-learning methods as in the Baseline method, an intuitive way is to fix the features and train a new softmax classifier. We apply this simple adaptation scheme to MatchingNet and ProtoNet. For MAML, it is not feasible to fix the feature as it is an initialization method. In contrast, since it updates the model with the support set for only a few iterations, we can adapt further by updating for as many iterations as is required to train a new classification layer, which is 100 updates as mentioned in Section 4.1. For RelationNet, the features are convolution maps rather than the feature vectors, so we are not able to replace it with a softmax. As an alternative, we randomly split the few training data in novel class into 3 support and 2 query data to finetune the relation module for 100 epochs.</p><p>The results of further adaptation are shown in <ref type="figure">Figure 5</ref>; we can observe that the performance of MatchingNet and MAML improves significantly after further adaptation, particularly in the mini-ImageNet →CUB scenario. The results demonstrate that lack of adaptation is the reason they fall behind the Baseline. However, changing the setting in the meta-testing stage can lead to inconsistency with the meta-training stage. The ProtoNet result shows that performance can degrade in scenarios with less domain difference. Thus, we believe that learning how to adapt in the meta-training stage is important future direction. In summary, as domain differences are likely to exist in many real-world applications, we consider that learning to learn adaptation in the meta-training stage would be an important direction for future meta-learning research in few-shot classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSIONS</head><p>In this paper, we have investigated the limits of the standard evaluation setting for few-shot classification. Through comparing methods on a common ground, our results show that the Baseline++ model is competitive to state of art under standard conditions, and the Baseline model achieves competitive performance with recent state-of-the-art meta-learning algorithms on both CUB and mini-ImageNet benchmark datasets when using a deeper feature backbone. Surprisingly, the Baseline compares favorably against all the evaluated meta-learning algorithms under a realistic scenario where there exists domain shift between the base and novel classes. By making our source code publicly available, we believe that community can benefit from the consistent comparative experiments and move forward to tackle the challenge of potential domain shifts in the context of few-shot learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A1 RELATIONSHIP BETWEEN DOMAIN ADAPTATION AND FEW-SHOT CLASSIFICATION</head><p>As mentioned in Section 2, here we discuss the relationship between domain adaptation and fewshot classification to clarify different experimental settings. As shown in <ref type="table" target="#tab_6">Table A1</ref>, in general, domain adaptation aims at adapting source dataset knowledge to the same class in target dataset. On the other hand, the goal of few-shot classification is to learn from base classes to classify novel classes in the same dataset.</p><p>Several recent work tackle the problem at the intersection of the two fields of study. For example, cross-task domain adaptation <ref type="bibr" target="#b14">Hsu et al. (2018)</ref> also discuss novel classes in the target dataset. In contrast, while <ref type="bibr" target="#b20">Motiian et al. (2017)</ref> has "few-shot" in the title, their evaluation setting focuses on classifying the same class in the target dataset.</p><p>If base and novel classes are both drawn from the same dataset, minor domain shift exists between the base and novel classes, as we demonstrated in Section 4.4. To highlight the impact of domain shift, we further propose the mini-ImageNet →CUB setting. The domain shift in few-shot classification is also discussed in <ref type="bibr" target="#b5">Dong &amp; Xing (2018)</ref>. Different meta-learning works use different terminology in their works. We highlight their differences in appendix <ref type="table" target="#tab_2">Table A2</ref> to clarify the inconsistency. For completeness, here we also show the results under two additional scenarios in 4) character recognition 5) cross-domain character recognition.</p><p>For character recognition, we use the Omniglot dataset <ref type="bibr" target="#b17">Lake et al. (2011)</ref> commonly used in evaluating few-shot classification algorithms. Omniglot contains 1,623 characters from 50 languages, and we follow the evaluation protocol of <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref> to first augment the classes by rotations in 90, 180, 270 degrees, resulting in 6492 classes. We then follow <ref type="bibr" target="#b27">Snell et al. (2017)</ref> to split these classes into 4112 base, 688 validation, and 1692 novel classes. Unlike <ref type="bibr" target="#b27">Snell et al. (2017)</ref>, our validation classes are only used to monitor the performance during meta-training.</p><p>For cross-domain character recognition (Omniglot→EMNIST), we follow the setting of <ref type="bibr" target="#b5">Dong &amp; Xing (2018)</ref> to use Omniglot without Latin characters and without rotation augmentation as base classes, so there are 1597 base classes. On the other hand, EMNIST dataset <ref type="bibr" target="#b2">Cohen et al. (2017)</ref> contains 10-digits and upper and lower case alphabets in English, so there are 62 classes in total. We split these classes into 31 validation and 31 novel classes, and invert the white-on-black characters to black-on-white as in Omniglot.</p><p>We use a Conv-4 backbone with input size 28x28 for both settings. As Omniglot characters are black-and-white, center-aligned and rotation sensitive, we do not use data augmentation in this experiment. To reduce the risk of over-fitting, we use the validation set to select the epoch or episode with the best accuracy for all methods, including baseline and baseline++. 4</p><p>As shown in <ref type="table" target="#tab_5">Table A3</ref>, in both Omniglot and Omniglot→EMNIST settings, meta-learning methods outperform baseline and baseline++ in 1-shot. However, all methods reach comparable performance in the 5-shot classification setting. We attribute this to the lack of data augmentation for the baseline and baseline++ methods as they tend to over-fit base classes. When sufficient examples in novel classes are available, the negative impact of over-fitting is reduced.  <ref type="bibr" target="#b29">(Vinyals et al. (2016)</ref>) apply a Baseline with 1-NN classifier in the test stage. We include our result as in <ref type="table" target="#tab_9">Table A4</ref>. The result shows that using 1-NN classifier has better performance than that of using the softmax classifier in 1-shot setting, but softmax classifier performs better in 5-shot setting. We note that the number here are not directly comparable to results in <ref type="bibr" target="#b29">Vinyals et al. (2016)</ref> because we use a different mini-ImageNet as in <ref type="bibr" target="#b25">Ravi &amp; Larochelle (2017)</ref>. As discussed in Section 4.1, we use first-order approximation MAML to improve memory efficiency in all of our experiments. To demonstrate this design choice does not affect the accuracy, we compare their validation accuracy trends on Omniglot with 5-shot as in <ref type="figure" target="#fig_0">Figure A1</ref>. We observe that while the full version MAML converge faster, both versions reach similar accuracy in the end.</p><p>This phenomena is consistent with the difference of first-order (e.g. gradient descent) and secondorder methods (e.g. Newton) in convex optimization problems. Second-order methods converge faster at the cost of memory, but they both converge to similar objective value. <ref type="figure" target="#fig_0">Figure A1</ref>: Validation accuracy trends of MAML and MAML with first order approximation. Both versions converge to the same validation accuracy. The experimental results are on Omniglot with 5-shot with a Conv-4 backbone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A6 INTRA-CLASS VARIATION AND BACKBONE DEPTH</head><p>As mentioned in Section 4.3, here we demonstrate decreased intra-class variation as the network depth gets deeper as in <ref type="figure" target="#fig_1">Figure A2</ref>. We use the Davies-Bouldin index <ref type="bibr" target="#b3">Davies &amp; Bouldin (1979)</ref> to measure intra-class variation. The Davies-Bouldin index is a metric to evaluate the tightness in a cluster (or class, in our case). Our results show that both intra-class variation in the base and novel class feature decrease using deeper backbones.  <ref type="figure" target="#fig_1">Figure A2</ref>: Intra-class variation decreases as backbone gets deeper. Here we use Davies-Bouldin index to represent intra-class variation, which is a metric to evaluate the tightness in a cluster (or class, in our case). The statistics are Davies-Bouldin index for all base and novel class feature (extracted by feature extractor learned after training or meta-training stage) for CUB dataset under different backbone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A7 DETAILED STATISTICS IN EFFECTS OF INCREASING BACKBONE DEPTH</head><p>Here we show a high-resolution version of <ref type="figure">Figure 3</ref> in <ref type="figure">Figure A3</ref> and show detailed statistics in <ref type="table">Table A5</ref> for easier comparison.  <ref type="figure">Figure A3</ref>: Few-shot classification accuracy vs. backbone depth. In the CUB dataset, gaps among different methods diminish as the backbone gets deeper. In mini-ImageNet 5-shot, some meta-learning methods are even beaten by Baseline with a deeper backbone. <ref type="table">Table A5</ref>: Detailed statistics in <ref type="figure">Figure 3</ref>. We put exact value here for reference. We experiment with a practical setting that handles different testing scenarios. Specifically, we conduct the experiments of 5-way meta-training and N-way meta-testing (where N = 5, 10, 20) to examine the effect of testing scenarios that are different from training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conv</head><p>As in <ref type="table">Table A6</ref>, we compare the methods Baseline, Baseline++, MatchingNet, ProtoNet, and Re-lationNet. Note that we are unable to apply the MAML method as MAML learns the initialization for the classifier and can thus only be updated to classify the same number of classes. Our results show that for classification with a larger N-way in the meta-testing stage, the proposed Baseline++ compares favorably against other methods in both shallow or deeper backbone settings.</p><p>We attribute the results to two reasons. First, to perform well in a larger N-way classification setting, one needs to further reduce the intra-class variation to avoid misclassification. Thus, Baseline++ has better performance than Baseline in both backbone settings. Second, as meta-learning algorithms were trained to perform 5-way classification in the meta-training stage, the performance of these algorithms may drop significantly when increasing the N-way in the meta-testing stage because the tasks of 10-way or 20-way classification are harder than that of 5-way one.</p><p>One may address this issue by performing a larger N-way classification in the meta-training stage (as suggested in <ref type="bibr" target="#b27">Snell et al. (2017)</ref>). However, it may encounter the issue of memory constraint. For example, to perform a 20-way classification with 5 support images and 15 query images in each class, we need to fit a batch size of 400 (20 x (5 + 15)) that must fit into the GPUs. Without special hardware parallelization, the large batch size may prevent us from training models with deeper backbones such as ResNet. <ref type="table">Table A6</ref>: 5-way meta-training and N-way meta-testing experiment. The experimental results are on mini-ImageNet with 5-shot. We could see Baseline++ compares favorably against other methods in both shallow or deeper backbone settings.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Baseline and Baseline++ few-shot classification methods. Both the baseline and baseline++ method train a feature extractor f θ and classifier C(.|W b ) with base class data in the training stage In the fine-tuning stage, we fix the network parameters θ in the feature extractor f θ and train a new classifier C(.|W n ) with the given labeled examples in novel classes. The baseline++ method differs from the baseline model in the use of cosine distances between the input feature and the weight vector for each class that aims to reduce intra-class variations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Meta-learning few-shot classification algorithms. The meta-learning classifier M(·|S) is conditioned on the support set S. (Top) In the meta-train stage, the support set S b and the query set Q b are first sampled from random N classes, and then train the parameters in M(.|S b ) to minimize the N-way prediction loss L N−way . In the meta-testing stage, the adapted classifier M(.|S n ) can predict novel classes with the support set in the novel classes S n . (Bottom) The design of M(·|S) in different meta-learning algorithms. (2017), and RelationNet Sung et al. (2018)) and one initialization based method (MAML Finn et al. (</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>5-shot accuracy in different scenarios with a ResNet-18 backbone. The Baseline model performs relative well with larger domain differences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>± 0.74 64.16 ± 0.71 42.11 ± 0.71 62.53 ±0.69 Baseline++ 60.53 ± 0.83 79.34 ± 0.61 48.24 ± 0.75 66.43 ±0.63 MatchingNet Vinyals et al. (2016) 60.52 ± 0.88 75.29 ± 0.75 48.14 ± 0.78 63.48 ±0.66 ProtoNet Snell et al. (2017) 50.46 ± 0.88 76.39 ± 0.64 44.42 ± 0.84 64.24 ±0.72 MAML Finn et al. (2017) 54.73 ± 0.97 75.75 ± 0.76 46.47 ± 0.82 62.71 ±0.71 RelationNet Sung et al. (2018) 62.34 ± 0.94 77.84 ± 0.68 49.31 ± 0.85 66.60 ±0.69</figDesc><table><row><cell>CUB</cell><cell>mini-ImageNet</cell></row></table><note>Few-shot classification results for both the mini-ImageNet and CUB datasets. The Baseline++ consistently improves the Baseline model by a large margin and is competitive with the state-of-the-art meta-learning methods. All experiments are from 5-way classification with a Conv-4 backbone and data augmentation.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="3">Baseline Baseline++ MatchingNet ProtoNet MAML RelationNet</cell></row><row><cell>90%</cell><cell></cell><cell></cell></row><row><cell>80%</cell><cell></cell><cell></cell></row><row><cell>70%</cell><cell></cell><cell></cell></row><row><cell>60%</cell><cell></cell><cell></cell></row><row><cell>50%</cell><cell></cell><cell></cell></row><row><cell>40%</cell><cell></cell><cell></cell></row><row><cell>CUB</cell><cell>miniImageNet</cell><cell>miniImageNet -&gt; CUB</cell></row><row><cell>Small</cell><cell></cell><cell>Large</cell></row><row><cell></cell><cell>Domain Difference</cell><cell></cell></row><row><cell>: 5-shot accuracy under the</cell><cell></cell><cell></cell></row><row><cell>cross-domain scenario with a ResNet-18</cell><cell></cell><cell></cell></row><row><cell>backbone. Baseline outperforms all other</cell><cell></cell><cell></cell></row><row><cell>methods under this scenario.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table A1 :</head><label>A1</label><figDesc>Relationship between domain adaptation and few-shot classification.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>The two</cell></row><row><cell cols="4">field-of-studies have overlapping in the development. Notation "*" indicates minor domain shifts</cell></row><row><cell>exist between base and novel classes.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Domain shift Source to target dataset Base to novel class</cell></row><row><cell>Domain adaptation Motiian et al. (2017)</cell><cell>V</cell><cell>V</cell><cell>-</cell></row><row><cell>Cross-task domain adaptation Hsu et al. (2018)</cell><cell>V</cell><cell>V</cell><cell>V</cell></row><row><cell>Few-shot classification Ours (CUB, mini-ImageNet )</cell><cell>*</cell><cell>-</cell><cell>V</cell></row><row><cell>Cross-domain few-shot</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ours (mini-ImageNet →CUB)</cell><cell>V</cell><cell>V</cell><cell>V</cell></row><row><cell>Dong &amp; Xing (2018)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>A2 TERMINOLOGY DIFFERENCE</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table A2 :</head><label>A2</label><figDesc>Different terminology used in other works. Notation "-" indicates the term is the same as in this paper.</figDesc><table><row><cell cols="5">A3 ADDITIONAL RESULTS ON OMNIGLOT AND OMNIGLOT→EMNIST</cell><cell></cell></row><row><cell>Our terms</cell><cell>MatchingNet Vinyals et al.</cell><cell>ProtoNet Snell et al.</cell><cell>MAML Finn et al.</cell><cell>Meta-learn LSTM Ravi &amp; Larochelle</cell><cell>Imaginary Wang et al.</cell></row><row><cell>meta-training stage</cell><cell>training</cell><cell>training</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>meta-testing stage</cell><cell>test</cell><cell>test</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>base class</cell><cell>training set</cell><cell>training set</cell><cell>task</cell><cell>meta-training set</cell><cell>-</cell></row><row><cell>novel class</cell><cell>test set</cell><cell>test set</cell><cell>new task</cell><cell>meta-testing set</cell><cell>-</cell></row><row><cell>support set</cell><cell>-</cell><cell>-</cell><cell>sample</cell><cell>training dataset</cell><cell>training data</cell></row><row><cell>query set</cell><cell>batch</cell><cell>-</cell><cell>test time sample</cell><cell>test dataset</cell><cell>test data</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table A3 :</head><label>A3</label><figDesc>Few-shot classification results for both the Omniglot and Omniglot→EMNIST. All experiments are from 5-way classification with a Conv-4 backbone and without data augmentation. ± 0.45 99.12 ± 0.13 63.94 ± 0.87 86.00 ± 0.59 Baseline++ 95.41 ± 0.39 99.38 ± 0.10 64.74 ± 0.82 87.31 ± 0.58 MatchingNet 97.78 ± 0.30 99.37 ± 0.11 72.71 ± 0.79 87.60 ± 0.56 ProtoNet 98.01 ± 0.30 99.15 ± 0.12 70.43 ± 0.80 87.04 ± 0.55 MAML 98.57 ± 0.19 99.53 ± 0.08 72.04 ± 0.83 88.24 ± 0.56 RelationNet 97.22 ± 0.33 99.30 ± 0.10 75.55 ± 0.87 88.94 ± 0.54</figDesc><table><row><cell></cell><cell cols="2">Omniglot</cell><cell cols="2">Omniglot→EMNIST</cell></row><row><cell>Method</cell><cell>1-shot</cell><cell>5-shot</cell><cell>1-shot</cell><cell>5-shot</cell></row><row><cell cols="2">Baseline 94.89 A4 BASELINE WITH 1-NN CLASSIFIER</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Some prior work</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table A4 :</head><label>A4</label><figDesc>Baseline with softmax and 1-NN classifier in test stage. We note that we use cosine distance in 1-NN. 11±0.71 44.18±0.69 62.53±0.69 56.68±0.67 Baseline++ 48.24±0.75 49.57±0.73 66.43±0.63 61.93±0.65 A5 MAML AND MAML WITH FIRST-ORDER APPROXIMATION</figDesc><table><row><cell>1-shot</cell><cell></cell><cell>5-shot</cell><cell></cell></row><row><cell>softmax</cell><cell>1-NN</cell><cell>softmax</cell><cell>1-NN</cell></row></table><note>Baseline 42.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/wyharveychen/CloserLookFewShot</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">For example, the exact episodes for experiments on the mini-ImageNet in the 5-shot setting with a fourlayer ConvNet are: ProtoNet: 24,600; MatchingNet: 35,300; RelationNet: 37,100; MAML: 36,700.3 Reported results are from<ref type="bibr" target="#b25">Ravi &amp; Larochelle (2017)</ref> </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The exact epoch of baseline and baseline++ on Omniglot and Omniglot→EMNIST is 5 epochs</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgement. This work was supported in part by NSF under Grant No. 1755785  . We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan Xp GPU.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>mini-ImageNet 5-shot</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Data augmentation generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations Workshops (ICLR Workshops)</title>
		<meeting>the International Conference on Learning Representations Workshops (ICLR Workshops)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Meta-learning with differentiable closed-form solvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>João</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Emnist: an extension of mnist to handwritten letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Afshar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tapson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">André</forename><surname>Van Schaik</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.05373</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A cluster separation measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">W</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bouldin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page">15</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Domain adaption in one-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanqing</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Probabilistic model-agnostic meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Unsupervised domain adaptation by backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Bruna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dynamic few-shot visual learning without forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Low-shot visual recognition by shrinking and hallucinating features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Few-shot learning with metric-agnostic conditional embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Hilliard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Howland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artëm</forename><surname>Yankov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Courtney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><forename type="middle">O</forename><surname>Corley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hodas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.04376</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Learning to cluster in order to transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chang</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoyang</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep transfer metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junlin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yap-Peng</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Siamese neural networks for one-shot image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning Workshops (ICML Workshops)</title>
		<meeting>the International Conference on Machine Learning Workshops (ICML Workshops)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brenden</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cogsci</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Metric learning for large scale image classification: Generalizing to new classes at near-zero cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriela</forename><surname>Csurka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Wordnet: a lexical database for english</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Few-shot adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeid</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quinn</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seyed</forename><surname>Iranmanesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Meta networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsendsuren</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Machine Learning (ICML)</title>
		<meeting>the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<title level="m">Reptile: a scalable metalearning algorithm</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Sinno Jialin Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering (TKDE)</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Low-shot learning with imprinted weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimization as a model for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR</title>
		<meeting>the International Conference on Learning Representations (ICLR</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Meta-learning with latent embedding optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Andrei A Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakub</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Sygnowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hadsell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations (ICLR)</title>
		<meeting>the International Conference on Learning Representations (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The caltech-ucsd birds-200-2011 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catherine</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Low-shot learning from imaginary data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Conv-4</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
