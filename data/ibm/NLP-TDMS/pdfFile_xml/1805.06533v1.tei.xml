<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Modeling Naive Psychology of Characters in Simple Commonsense Stories</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannah</forename><surname>Rashkin</surname></persName>
							<email>hrashkin@cs.washington.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
							<email>antoineb@cs.washington.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Sap</surname></persName>
							<email>msap@cs.washington.edu</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Knight</surname></persName>
							<email>knight@isi.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Information Sciences Institute &amp; Computer Science</orgName>
								<orgName type="institution">University of Southern</orgName>
								<address>
									<country>California</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><forename type="middle">G</forename><surname>Allen</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">School of Computer Science &amp; Engineering</orgName>
								<orgName type="department" key="dep2">Allen Institute for Artificial Intelligence</orgName>
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Modeling Naive Psychology of Characters in Simple Commonsense Stories</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T09:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Understanding a narrative requires reading between the lines and reasoning about the unspoken but obvious implications about events and people's mental states -a capability that is trivial for humans but remarkably hard for machines. To facilitate research addressing this challenge, we introduce a new annotation framework to explain naive psychology of story characters as fully-specified chains of mental states with respect to motivations and emotional reactions. Our work presents a new largescale dataset with rich low-level annotations and establishes baseline performance on several new tasks, suggesting avenues for future research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Understanding a story requires reasoning about the causal links between the events in the story and the mental states of the characters, even when those relationships are not explicitly stated. As shown by the commonsense story cloze shared task <ref type="bibr" target="#b24">(Mostafazadeh et al., 2017)</ref>, this reasoning is remarkably hard for both statistical and neural machine readers -despite being trivial for humans. This stark performance gap between humans and machines is not surprising as most powerful language models have been designed to effectively learn local fluency patterns. Consequently, they generally lack the ability to abstract away from surface patterns in text to model more complex implied dynamics, such as intuiting characters' mental states or predicting their plausible next actions.</p><p>In this paper, we construct a new annotation formalism to densely label commonsense short stories <ref type="bibr" target="#b23">(Mostafazadeh et al., 2016)</ref> in terms of the mental states of the characters. The result-The band instructor told the band to start playing.</p><p>He often stopped the music when players were off-tone.</p><p>They grew tired and started playing worse after a while.</p><p>The instructor was furious and threw his chair. <ref type="figure">Figure 1</ref>: A story example with partial annotations for motivations (dashed) and emotional reactions <ref type="bibr">(solid)</ref>. Open text explanations are in black (e.g., "frustrated") and formal theory labels are in blue with brackets (e.g., "[esteem]").</p><p>ing dataset offers three unique properties. First, as highlighted in <ref type="figure">Figure 1</ref>, the dataset provides a fully-specified chain of motivations and emotional reactions for each story character as preand post-conditions of events. Second, the annotations include state changes for entities even when they are not mentioned directly in a sentence (e.g., in the fourth sentence in <ref type="figure">Figure 1</ref>, players would feel afraid as a result of the instructor throwing a chair), thereby capturing implied effects unstated in the story. Finally, the annotations encompass both formal labels from multiple theories of psychology <ref type="bibr" target="#b21">(Maslow, 1943;</ref><ref type="bibr" target="#b28">Reiss, 2004;</ref><ref type="bibr" target="#b27">Plutchik, 1980)</ref> as well as open text descriptions of motivations and emotions, providing a comprehensive mapping between open text explanations and label categories (e.g., "to spend time with her son"   <ref type="bibr">Reiss)</ref> and Emotional Reaction <ref type="bibr">(Plutchik)</ref>.</p><p>→ Maslow's category love). Our corpus 1 spans across 15k stories, amounting to 300k low-level annotations for around 150k character-line pairs. Using our new corpus, we present baseline performance on two new tasks focusing on mental state tracking of story characters: categorizing motivations and emotional reactions using theory labels, as well as describing motivations and emotional reactions using open text. Empirical results demonstrate that existing neural network models including those with explicit or latent entity representations achieve promising results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Mental State Representations</head><p>Understanding people's actions, motivations, and emotions has been a recurring research focus across several disciplines including philosophy and psychology <ref type="bibr" target="#b29">(Schachter and Singer, 1962;</ref><ref type="bibr" target="#b1">Burke, 1969;</ref><ref type="bibr" target="#b16">Lazarus, 1991;</ref><ref type="bibr" target="#b6">Goldman, 2015)</ref>. We draw from these prior works to derive a set of categorical labels for annotating the step-by-step causal dynamics between the mental states of story characters and the events they experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Motivation Theories</head><p>We use two popular theories of motivation: the "hierarchy of needs" of <ref type="bibr" target="#b21">Maslow (1943)</ref> and the "basic motives" of <ref type="bibr" target="#b28">Reiss (2004)</ref> to compile 5 coarse-grained and 19 fine-grained motivation categories, shown in <ref type="figure" target="#fig_0">Figure 2</ref>. Maslow's "hierarchy of needs" are comprised of five categories, ranging from physiological needs to spiritual growth, which we use as coarse-level categories. <ref type="bibr" target="#b28">Reiss (2004)</ref> proposes 19 more fine-grained categories that provide a more informative range of motivations. For example, even though they both relate to the physiological needs Maslow category, the food and rest motives from <ref type="bibr" target="#b28">Reiss (2004)</ref> are very different. While the Reiss theory allows for finergrained annotations of motivation, the larger set of abstract concepts can be overwhelming for annotators. Motivated by <ref type="bibr" target="#b31">Straker (2013)</ref>, we design a hybrid approach, where Reiss labels are annotated as sub-categories of Maslow categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Emotion Theory</head><p>Among several theories of emotion, we work with the "wheel of emotions" of <ref type="bibr" target="#b27">Plutchik (1980)</ref>, as it has been a common choice in prior literature on emotion categorization <ref type="bibr" target="#b22">(Mohammad and Turney, 2013;</ref><ref type="bibr" target="#b37">Zhou et al., 2016)</ref>. We use the eight basic emotional dimensions as illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Mental State Explanations</head><p>In addition to the motivation and emotion categories derived from psychology theories, we also obtain open text descriptions of character mental states. These open text descriptions allow learning computational models that can explain the mental states of characters in natural language, which is likely to be more accessible and informative to end users than having theory categories alone. Collecting both theory categories and open text also allows us to learn the automatic mappings between the two, which generalizes the previous work of <ref type="bibr" target="#b22">Mohammad and Turney (2013)</ref> on emotion category mappings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Annotation Framework</head><p>In this study, we choose to annotate the simple commonsense stories introduced by <ref type="bibr" target="#b23">Mostafazadeh et al. (2016)</ref>. Despite their simplicity, these stories pose a significant challenge to natural language understanding models <ref type="bibr" target="#b24">(Mostafazadeh et al., 2017</ref>  In addition, they depict multiple interactions between story characters, presenting rich opportunities to reason about character motivations and reactions. Furthermore, there are more than 98k such stories currently available covering a wide range of everyday scenarios.</p><p>Unique Challenges While there have been a variety of annotated resources developed on the related topics of sentiment analysis <ref type="bibr" target="#b22">(Mohammad and Turney, 2013;</ref><ref type="bibr" target="#b2">Deng and Wiebe, 2015)</ref>, entity tracking <ref type="bibr" target="#b11">(Hoffart et al., 2011;</ref><ref type="bibr" target="#b34">Weston et al., 2015)</ref>, and story understanding <ref type="bibr" target="#b7">(Goyal et al., 2010;</ref><ref type="bibr" target="#b25">Ouyang and McKeown, 2015;</ref><ref type="bibr" target="#b20">Lukin et al., 2016)</ref>, our study is the first to annotate the full chains of mental state effects for story characters. This poses several unique challenges as annotations require (1) interpreting discourse (2) understanding implicit causal effects, and (3) understanding formal psychology theory categories. In prior literature, annotations of this complexity have typically been performed by experts <ref type="bibr" target="#b2">(Deng and Wiebe, 2015;</ref><ref type="bibr" target="#b25">Ouyang and McKeown, 2015)</ref>. While reliable, these annotations are prohibitively expensive to scale up. Therefore, we introduce a new annotation framework that pipelines a set of smaller isolated tasks as illustrated in <ref type="figure" target="#fig_1">Figure 3</ref>. All annotations were collected using crowdsourced workers from Amazon Mechanical Turk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Annotation Pipeline</head><p>We describe the components and workflow of the full annotation pipeline shown in <ref type="figure" target="#fig_1">Figure 3</ref> below. The example story in the figure is used to illustrate the output of various steps in the pipeline (full annotations for this example are in the appendix).</p><p>(1) Entity Resolution The first task in the pipeline aims to discover (1) the set of characters E i in each story i and (2) the set of sentences S ij in which a specific character j ∈ E i is ex-plicitly mentioned. For example, in the story in <ref type="figure" target="#fig_1">Figure 3</ref>, the characters identified by annotators are "I/me" and "My cousin", whom appear in sentences {1, 4, 5} and {1, 2, 3, 4, 5}, respectively. We use S ij to control the workflow of later parts of the pipeline by pruning future tasks for sentences that are not tied to characters. Because S ij is used to prune follow-up tasks, we take a high recall strategy to include all sentences that at least one annotator selected.</p><p>(2a) Action Resolution The next task identifies whether a character j appearing in a sentence k is taking any action to which a motivation can be attributed. We perform action resolution only for sentences k ∈ S ij . In the running example, we would want to know that the cousin in line 2 is not doing anything intentional, allowing us to omit this line in the next pipeline stage (3a) where a character's motives are annotated. Description of state (e.g., "Alex is feeling blue") or passive event participation (e.g., "Alex trips") are not considered volitional acts for which the character may have an underlying motive. For each line and story character pair, we obtain 4 annotations. Because pairs can still be filtered out in the next stage of annotation, we select a generous threshold where only 2 annotators must vote that an intentional action took place for the sentence to be used as an input to the motivation annotation task (3a).</p><p>(2b) Affect Resolution This task aims to identify all of the lines where a story character j has an emotional reaction. Importantly, it is often possible to infer the emotional reaction of a character j even when the character does not explicitly appear in a sentence k. For instance, in <ref type="figure" target="#fig_1">Figure 3</ref>, we want to annotate the narrator's reaction to line 2 even though they are not mentioned because their emotional response is inferrable. We obtain 4 an-  <ref type="figure">Figure 4</ref>: Examples of open-text explanations that annotators provided corresponding with the categories they selected. The bars on the right of the categories represent the percentage of lines where annotators selected that category (out of those character-line pairs with positive motivation/emotional reaction). notations per character per line. The lines with at least 2 annotators voting are used as input for the next task: (3b) emotional reaction.</p><p>(3a) Motivation We use the output from the action resolution stage (2a) to ask workers to annotate character motives in lines where they intentionally initiate an event. We provide 3 annotators a line from a story, the preceding lines, and a specific character. They are asked to produce a free response sentence describing what causes the character's behavior in that line and to select the most related Maslow categories and Reiss subcategories. In <ref type="figure" target="#fig_1">Figure 3</ref>, an annotator described the motivation of the narrator in line 1 as wanting "to have company" and then selected the love (Maslow) and family (Reiss) as categorical labels. Because many annotators are not familiar with motivational theories, we require them to complete a tutorial the first time they attempt the task.</p><p>(3b) Emotional Reaction Simultaneously, we use the output from the affect resolution stage (2b) to ask workers what the emotional response of a character is immediately following a line in which they are affected. As with the motives, we give 3 annotators a line from a story, its previous context, and a specific character. We ask them to describe in open text how the character will feel following the event in the sentence (up to three emotions). As a follow-up, we ask workers to compare their free responses against Plutchik categories by using 3-point likert ratings. In <ref type="figure" target="#fig_1">Figure 3</ref>, we include a response for the emotional reaction of the narrator in line 1. Even though the narrator was not mentioned directly in that line, an annotator recorded that they will react to their cousin being a slob by feeling "annoyed" and selected the Plutchik categories for sadness, disgust and anger. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dataset Statistics and Insights</head><p>Cost The tasks corresponding to the theory category assignments are the hardest and most expensive in the pipeline (∼$4 per story). Therefore, we obtain theory category labels only for a third of our annotated stories, which we assign to the development and test sets. The training data is annotated with a shortened pipeline with only open text descriptions of motivations and emotional reactions from two workers (∼$1 per story).</p><p>Scale Our dataset to date includes a total of 300k low-level annotations for motivation and emotion across 15,000 stories (randomly selected from the ROC story training set). It covers over 150,000 character-line pairs, in which 56k character-line pairs have an annotated motivation and 105k have an annotated change in emotion (i.e. a label other than none). <ref type="table">Table 1</ref> shows the break down across training, development, and test splits. <ref type="figure">Figure 4</ref> shows the frequency of different labels being selected for motivational and emotional categories in cases with positive change.</p><p>Agreements For quality control, we removed workers who consistently produced low-quality work, as discussed in the Appendix. In the categorization sets (Maslow, Reiss and Plutchik), we compare the performance of annotators by treating each individual category as a binary label (1 Other -1.00 -0.11 -0.02 -0.11 0.00 -1.00 -0.02 -0.06 0.10 0.09 0.06 0.05 -0.07 -0.02 0.02 -0.06 -1.00 -0.03 0.05 0.04 0.02 -1.00 -0.10 -0.04</p><p>Idealism 0.02 0.26 0.04 0.04 -0.05 -0.09 0.01 0.01 0.06 -0.05 0.11 0.05 -0.18 0.00 0.02 -0.05 -0.07 -0.02 -0.01 0.01 -0.05 -0.03 -0.10 -0.17 Growth Indep 0.02 -0.01 0.18 0.10 0.13 0.05 0.02 0.06 0.01 0.02 0.00 0.00 -0.15 -0.06 -0.04 -0.10 -0.07 -0.09 -0.08 -0.01 -0.01 0.07 -0.14 -0.08 Serenity 0.01 0.03 0.06 0.27 0.06 0.01 -0.07 -0.07 -0.04 -0.09 -0.07 0.02 -0.07 -0.04 -0.08 -0.10 -0.07 0.01 -0.02 0.07 -0.05 0.02 -0.10 0.15 Curiosity -0.01 -0.02 0.13 0.03 0.40 -0.01 -0.04 -0.05 -0.04 -0.01 -0.08 -0.01 -0.16 -0.06 -0.07 -0.14 -0.01 -0.11 -0.12 -0.04 -0.10 0.08 -0.12 -0.07 Esteem Other -1.00 0.14 0.04 0.02 0.04 0.31 -0.05 0.03 0.10 -0.12 0.05 -1.00 -0.07 0.08 -1.00 -1.00 -1.00 -0.14 -0.05 -0.07 0.03 -1.00 -0.09 -0.04   if they included the category in their set of responses) and averaging the agreement per category. For Plutchik scores, we count 'moderately associated' ratings as agreeing with 'highly' associated' ratings. The percent agreement and Krippendorff's alpha are shown in <ref type="table" target="#tab_6">Table 2</ref>. We also compute the percent agreement between the individual annotations and the majority labels. 2 These scores are difficult to interpret by themselves, however, as annotator agreement in our categorization system has a number of properties that are not accounted for by these metrics (disagreement preferences -joy and trust are closer than joy and anger -that are difficult to quantify in a principled way, hierarchical categories map-ping Reiss subcategories from Maslow categories, skewed category distributions that inflate PPA and deflate KA scores, and annotators that could select multiple labels for the same examples).</p><p>To provide a clearer understanding of agreement within this dataset, we create aggregated confusion matrices for annotator pairs. First, we sum the counts of combinations of answers between all paired annotations (excluding none labels). If an annotator selected multiple categories, we split the count uniformly among the selected categories. We compute NPMI over the total confusion matrix. In <ref type="figure">Figure 5</ref>, we show the NPMI confusion matrix for motivational categories.</p><p>In the motivation annotations, we find the highest scores on the diagonal (i.e., Reiss agreement), with most confusions occurring between Reiss motives in the same Maslow category (outlined black in <ref type="figure">Figure 5</ref>). Other disagreements generally involve Reiss subcategories that are thematically similar, such as serenity (mental relaxation) and rest (physical relaxation). We provide this analysis for Plutchik categories in the appendix, finding high scores along the diagonal with disagreements typically occurring between categories in a "positive emotion" cluster (joy, trust) or a "negative emotion" cluster (anger, disgust,sadness).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Tasks</head><p>The multiple modes covered by the annotations in this new dataset allow for multiple new tasks to be explored. We outline three task types below, covering a total of eight tasks on which to evaluate. Open-text Explanation <ref type="figure">Figure 6</ref>: General model architectures for three new task types Differences between task type inputs and outputs are summarized in <ref type="figure">Figure 6</ref>.</p><p>State Classification The three primary tasks involve categorizing the psychological states of story characters for each of the label sets (Maslow, Reiss, Plutchik) collected for the dev and test splits of our dataset. In each classification task, a model is given a line of the story (along with optional preceding context lines) and a character and predicts the motivation (or emotional reaction). A binary label is predicted for each of the Maslow needs, Reiss motives or Plutchik categories.</p><p>Annotation Classification Because the dev and test sets contain paired classification labels and free text explanations, we propose three tasks where a model must predict the correct Maslow/Reiss/Plutchik label given an emotional reaction or motivation explanation.</p><p>Explanation Generation Finally, we can use the free text explanations to train models to describe the psychological state of a character in free text (examples in <ref type="figure">Figure 4</ref>). These explanations allow for two conditional generation tasks where the model must generate the words describing the emotional reaction or motivation of the character.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Baseline Models</head><p>The general model architectures for the three tasks are shown in <ref type="figure">Figure 6</ref>. We describe each model component below. The state classification and explanation generation models could be trained separately or in a multi-task set-up.</p><p>In the state classification and explanation generation tasks, a model is given a line from a story x s containing N words {w s 0 , w s 1 , . . . , w s N } from vocabulary V , a character in that story e j ∈ E where E is the set of characters in the story, and (optionally) the preceding sentences in the story C = {x 0 . . . , x s−1 } containing words from vocabulary V . A representation for a character's psychological state is encoded as:</p><formula xml:id="formula_0">h e = Encoder(x s , C[e j ])<label>(1)</label></formula><p>where C[e j ] corresponds to the concatenated subset of sentences in C where e j appears.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Encoders</head><p>While the end classifier or decoder is different for each task, we use the same set of encoders based on word embeddings, common neural network architectures, or memory networks to formulate a representation of the sentence and character, h e . Unless specified, h e is computed by encoding separate vector representations for the sentence (x s → h s ) and character-specific context (C[e j ] → h c ) and concatenating these encodings (h e = [h c ; h s ]). We describe the encoders below:</p><p>TF-IDF We learn a TD-IDF model on the full training corpus of <ref type="bibr" target="#b23">Mostafazadeh et al. (2016)</ref> (excluding the stories in our dev/test sets). To encode the sentence, we extract TF-IDF features for its words, yielding v s ∈ R V . A projection and nonlinearity is applied to these features to yield h s :</p><formula xml:id="formula_1">h s = φ(W s v s + b s )<label>(2)</label></formula><p>where W s ∈ R d×H . The character vector h c is encoded in the same way on sentences in the context pertaining to the character.</p><p>GloVe We extract pretrained Glove vectors <ref type="bibr" target="#b26">(Pennington et al., 2014)</ref>  </p><p>where CNN represents the categorization model from <ref type="bibr" target="#b14">(Kim, 2014)</ref>. The character vector h c is encoded in the same way with a separate CNN. Implementation details are provided in the appendix.</p><p>LSTM A two-layer bi-LSTM encodes the sentence words and concatenates the final time step hidden states from both directions to yield h s . The character vector h c is encoded the same way.</p><p>REN We use the "tied" recurrent entity network from <ref type="bibr" target="#b9">Henaff et al. (2017)</ref>. A memory cell m is initialized for each of the J characters in the story, E = {e 0 , . . . , e J }. The REN reads documents one sentence at a time and updates m j for e j ∈ E after reading each sentence. Unlike the previous encoders, all sentences of the context C are given to the REN along with the sentence x s . The model learns to distribute encoded information to the correct memory cells. The representation passed to the downstream model is:</p><formula xml:id="formula_3">h e = {m j } s<label>(5)</label></formula><p>where {m j } s is the memory vector in the cell corresponding to e j after reading x s . Implementation details are provided in the appendix.</p><p>NPN We also include the neural process network from <ref type="bibr" target="#b0">Bosselut et al. (2018)</ref> with "tied" entities, but "untied" actions that are not grounded to particular concepts. The memory is initialized and accessed similarly as the REN. Exact implementation details are provided in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">State Classifier</head><p>Once the sentence-character encoding h e is extracted, the state classifier predicts a binary label y z for every category z ∈ Z where Z is the set of category labels for a particular psychological theory (e.g., disgust, surprise, etc. in the Plutchik wheel). We use logistic regression as a classifier:</p><formula xml:id="formula_4">y z = σ(W z h e + b z )<label>(6)</label></formula><p>where W z and b z are a label-specific set of weights and biases for classifying each label z ∈ Z.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Explanation Generator</head><p>The explanation generator is a single-layer LSTM <ref type="bibr" target="#b10">(Hochreiter and Schmidhuber, 1997</ref>) that receives the encoded sentence-character representation h e and predicts each word y t in the explanation using the same method from . Implementation details are provided in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Annotation Classifier</head><p>For annotation classification tasks, words from open-text explanations are encoded with TF-IDF features. The same classifier architecture from Section 5.2 is used to predict the labels.</p><p>6 Experimental Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Training</head><p>State Classification The dev set D is split into two portions of 80% (D 1 ) and 20% (D 2 ). D 1 is used to train the classifier and encoder. D 2 is used to tune hyperparameters. The model is trained to minimize the weighted binary cross entropy of predicting a class label y z for each class z:</p><formula xml:id="formula_5">L = Z z=1 γ z y z logŷ z +(1−γ z )(1−y z ) log(1−ŷ z ) (7)</formula><p>where Z is the number of labels in each of the three classifications tasks and γ z is defined as:</p><formula xml:id="formula_6">γ z = 1 − e − √ P (yz) (8)</formula><p>where P (y z ) is the marginal class probability of a positive label for z in the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Annotation Classification</head><p>The dev set is split in the same manner as for state classification. The TF-IDF features are trained on the set of training annotations D t coupled with those from D 1 . The model must minimize the same loss as in Equation 7. Details are provided in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Explanation Generation</head><p>We use the training set of open annotations to train a model to predict explanations. The decoder is trained to minimize the negative loglikelihood of predicting each word in the explanation of a character's state:</p><formula xml:id="formula_7">L gen = − T t=1 log P (y t |y 0 , ..., y t−1 , h e ) (9)</formula><p>where h e is the sentence-character representation produced by an encoder from Section 5.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Metrics</head><p>Classification For the state and annotation classification task, we report the micro-averaged precision (P), recall (R), and F1 score of the Plutchik, Maslow, and Reiss prediction tasks. We report the results of selecting a label at random in the top two rows of <ref type="table" target="#tab_9">Table 3</ref>. Note that random is low because the distribution of positive instances for each  Generation Because explanations tend to be short sequences <ref type="figure">(Figure 4)</ref> with high levels of synonymy, traditional metrics such as BLEU are inadequate for evaluating generation quality. We use the vector average and vector extrema metrics from <ref type="bibr" target="#b19">Liu et al. (2016)</ref> computed using the Glove vectors of generated and reference words. We report results in <ref type="table">Table 5</ref> on the dev set and compare to a baseline that randomly samples an example from the dev set as a generated sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Ablations</head><p>Story Context vs. No Context Our dataset is motivated by the importance of interpreting story context to categorize emotional reactions and motivations of characters. To test this importance, we ablate h c , the representation of the context sentences pertaining to the character, as an input to the state classifier for each encoder (except the REN and NPN). In <ref type="table" target="#tab_9">Table 3</ref>, this ablation is the first row for each encoder presented.</p><p>Explanation Pretraining Because the state classification and explanation generation tasks use the same models to encode the story, we explore initializing a classification encoder with parameters trained on the generation task. For the CNN, LSTM, and REN encoders, we pretrain a generator to produce emotion or motivation explana-tions. We use the parameters from the emotion or motivation explanation generators to initialize the Plutchik or Maslow/Reiss classifiers respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Results</head><p>State Classification We show results on the test set for categorizing Maslow, Reiss, and Plutchik states in <ref type="table" target="#tab_9">Table 3</ref>. Despite the difficulty of the task, all models outperform the random baseline. Interestingly, the performance boost from adding entity-specific contextual information (i.e., not ablating h c ) indicates that the models learn to condition on a character's previous experience to classify its mental state at the current time step. This effect can be seen in a story about a man whose flight is cancelled. The model without context predicts the same emotional reactions for the man, his wife and the pilot, but with context correctly predicts that the pilot will not have a reaction while predicting that the man and his wife will feel sad. For the CNN, LSTM, REN, and NPN models, we also report results from pretraining encoder parameters using the free response annotations from the training set. This pretraining offers a clear performance boost for all models on all three prediction tasks, showing that the parameters of the encoder can be pretrained on auxiliary tasks providing emotional and motivational state signal.</p><p>The best performing models in each task are most effective at predicting Maslow physiological needs, Reiss food motives, and Plutchik reactions of joy. The relative ease of predicting motivations   <ref type="table">Table 5</ref>: Vector average and extrema scores for generation of annotation explanations related to food (and physiological needs generally) may be because they involve a more limited and concrete set of actions such as eating or cooking.</p><p>Annotation Classification <ref type="table" target="#tab_11">Table 4</ref> shows that a simple model can learn to map open text responses to categorical labels. This further supports our hypothesis that pretraining a classification model on the free-response annotations could be helpful in boosting performance on the category prediction.</p><p>Explanation Generation Finally, we provide results for the task of generating explanations of motivations and emotions in <ref type="table">Table 5</ref>. Because the explanations are closely tied to emotional and motivation states, the randomly selected explanation can often be close in embedding space to the reference explanations, making the random baseline fairly competitive. However, all models outperform the strong baseline on both metrics, indicating that the generated short explanations are closer semantically to the reference annotation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Related Work</head><p>Mental State Annotations Incorporating emotion theories into NLP tasks has been explored in previous projects. <ref type="bibr" target="#b5">Ghosh et al. (2017)</ref> modulate language model distributions by increasing the probability of words that express certain affective LIWC (Tausczik and Pennebaker, 2016) categories. More generally, various projects tackle the problem of generating text from a set of attributes like sentiment or generic-ness <ref type="bibr" target="#b4">(Ficler and Goldberg, 2017;</ref><ref type="bibr" target="#b3">Dong et al., 2017)</ref>. Similarly, there is also a body of research in reasoning about commonsense stories and discourse <ref type="bibr" target="#b18">(Li and Jurafsky, 2017;</ref><ref type="bibr" target="#b23">Mostafazadeh et al., 2016)</ref> or detecting emotional stimuli in stories <ref type="bibr" target="#b8">(Gui et al., 2017)</ref>. Previous work in plot units <ref type="bibr" target="#b17">(Lehnert, 1981)</ref> developed formalisms for affect and mental state in story narratives that included motivations and reactions. In our work, we collect mental state annotations for stories to used as a new resource in this space.</p><p>Modeling Entity State Recently, novel works in language modeling <ref type="bibr" target="#b12">(Ji et al., 2017;</ref><ref type="bibr" target="#b35">Yang et al., 2016)</ref>, question answering <ref type="bibr" target="#b9">(Henaff et al., 2017)</ref>, and text generation <ref type="bibr" target="#b13">(Kiddon et al., 2016;</ref><ref type="bibr" target="#b0">Bosselut et al., 2018)</ref> have shown that modeling entity state explicitly can boost performance while providing a preliminary interface for interpreting a model's prediction. Entity modeling in these works, however, was limited to tracking entity reference <ref type="bibr" target="#b13">(Kiddon et al., 2016;</ref><ref type="bibr" target="#b35">Yang et al., 2016;</ref><ref type="bibr" target="#b12">Ji et al., 2017)</ref>, recognizing entity state similarity <ref type="bibr" target="#b9">(Henaff et al., 2017)</ref> or predicting simple attributes from entity states <ref type="bibr" target="#b0">(Bosselut et al., 2018)</ref>. Our work provides a new dataset for tracking emotional reactions and motivations of characters in stories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>We present a large scale dataset as a resource for training and evaluating mental state tracking of characters in short commonsense stories. This dataset contains over 300k low-level annotations for character motivations and emotional reactions. We provide benchmark results on this new resource. Importantly, we show that modeling character-specific context and pretraining on freeresponse data can boost labeling performance.</p><p>While our work only use information present in our dataset, we view our dataset as a future testbed for evaluating models trained on any number of resources for learning common sense about emotional reactions and motivations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A AMT Annotation Notes</head><p>We ran AMT tasks in batches. We performed quality control tests after every 1-2 batches and banned workers who were consistently performing poorly (and removed their responses from our dataset). For quality control, we used a combination of automatic methods (SGD over interannotator agreement using the quality control objectives described in the supplementary material of <ref type="bibr" target="#b36">Yatskar et al., 2016)</ref> and manual methods (e.g. searching for workers who always selected the same answers, who had strange answering patterns, who copied-and-pasted free responses) to identify workers with poor-quality work. Work by such annotators was reviewed, and these workers were banned if they were repeatedly not following instructions on a number of HIT's.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Emotion Agreement Matrix</head><p>We include a NPMI confusion matrix for aggregated Plutchik paired responses in <ref type="figure" target="#fig_4">Figure 7</ref>. Black boxes signify the same emotion but at different intensities (high vs. moderate). In general higher cooccurring responses are along the diagonal. However, we note that there are two main clusters coinciding with strongly positive emotions (joy and trust) and strongly negative emotions (anger, disgust, and sadness) where disagreements are more likely to occur. To a lesser extent, there also is a slight co-occurrence between fear and the strongly negative emotions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Model Implementation Details</head><p>All classification models are trained with the Adam Optimizer (Kingma and Ba, 2015) with a learning rate 0.001 and gradient clipping if the norm of the gradients exceeds 1. We regularize with dropout layers whose probabilities are specific to each model. All models are trained with word embeddings of dimensionality 100 that are initialized with pretrained Glove vectors <ref type="bibr" target="#b26">(Pennington et al., 2014)</ref>. For classification labels, we use the majority label among annotators for a particular character-line pair.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 LSTM Classifier</head><p>We train a 2-layer bidirectional LSTM encoder. The hidden states of the LSTM have dimensionality 100. We add dropout layers with p=0.5 in between the word embedding layer and the LSTM and between LSTM layers <ref type="bibr" target="#b30">(Srivastava et al., 2014)</ref>. We include a dropout layer with p=0.5 before the logistic regression classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 CNN Classifier</head><p>We follow the approach of <ref type="bibr" target="#b14">Kim (2014)</ref> and train a CNN classifier with kernels of size 3, 4, and 5. We use 100 kernels of each size. We add a dropout layer with p=0.5 between the word embedding layer and the convolutional kernel layers. We include a dropout layer with p=0.5 before the logistic regression classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 REN Classifier</head><p>We use the same implementation as <ref type="bibr" target="#b9">Henaff et al. (2017)</ref> except that we remove the output module designed to encode questions and instead select the memory cell tied to the entity of interest for every training example. All equations from the input encoder and dynamic memory are identical to those of <ref type="bibr" target="#b9">(Henaff et al., 2017)</ref>. The input encoder computes a positionally weighted average of all the words in a sentence:</p><formula xml:id="formula_8">s t = i f i e i (10)</formula><p>where e i is a word embedding at index i in a sentence, f i is a positional weight for that index in the sentence, and s t is a sentence representation. The dynamic memory is updated in the following way:</p><formula xml:id="formula_9">g j = σ(s T t h j + s T t w j )<label>(11)</label></formula><formula xml:id="formula_10">h j = φ(U h j + V w j + W s t )<label>(12)</label></formula><formula xml:id="formula_11">h j ← h j + g j h j (13) h j ← h j ||h j ||<label>(14)</label></formula><p>where h j is the value stored in memory cell j, w j is a key corresponding to memory cell j, U , V , W are projection matrices, and φ is a PReLU nonlinearity. We initialize entity memory keys and entity memory values with the sum of the Glove vectors for all the words in the character name. Entity key values w j are locked during training. We use dropout with p=0.3 between the encoder and dynamic memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 NPN Classifier</head><p>We use the same implementation as in <ref type="bibr" target="#b0">Bosselut et al. (2018)</ref> with a few modifications to the underlying architecture. First, we use the same encoder  as for the REN <ref type="bibr" target="#b9">(Henaff et al., 2017)</ref>. We define a set of action function embeddings that can be applied to entities to change their state, A. After each sentence, the model selects an action function embedding to use to change the state of the entity memory. Unlike in <ref type="bibr" target="#b0">Bosselut et al. (2018)</ref>, these action function embeddings are not tied to real actions and are instead treated as latent t The dynamic memory is updated in the following way:</p><formula xml:id="formula_12">g j = σ(s T t W 1 [h j , w j ]) (15) α t = sof tmax(M LP (s t )) (16) a t = α T t A (17) h j = φ(W 3 a t + W 4 s t ) (18) h j ← (1 − g j )h j + g j h j (19) h j ← h j ||h j ||<label>(20)</label></formula><p>where h j is the value stored in memory cell j, w j is a key corresponding to memory cell j, W k are projection matrices, φ is a PReLU nonlinearity and α t is a distribution over possible action function embeddings. We initialize entity memory keys and entity memory values with the sum of the Glove vectors for all the words in the character name. Entity key values w j are locked during training. We use dropout with p=0.5 between the encoder and dynamic memory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 LSTM Decoder</head><p>For the explanation generation task, we train a single-layer LSTM with a learning rate of 0.0003 and gradient clipping when the norm of the gradients exceeds 1. When outputting words, we con-catenate the original hidden state from the encoder h e to the output of the LSTM decoder before predicting a word. Word embeddings are initialized with pretrained Glove vectors <ref type="bibr" target="#b26">(Pennington et al., 2014</ref>). In the generation task, the model must learn to generate individual annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Experimental Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.1 Data used for Annotation Classification Task</head><p>We split the development set into two parts, 80% used for training (D 1 ), 20% used for evaluating hyperparameters (D 2 ). We train a set of TF-IDF features for each word using all of the explanations from the real training set (D t ) and the portion of the development set used for training (D 1 ). We train a logistic regression classifier with L2 regularization. When training the classifier on D 1 , we only train on examples where the explanation was written by a Turker who selected at least one Plutchik category label that was part of the majority set of Plutchik labels for the sentence the explanation and labels belong to. We prune D 2 and the test set similarly. We use individual annotations rather than majority labels to better learn specific fine-grained mappings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Emotional Explanation to Plutchik Labels</head><p>We re-balance the dataset by sampling from the training set evenly among positive examples and negative examples for each category. We use L2 regularization with λ = 0.1 We include the full positive class distributions for each category in <ref type="table" target="#tab_14">Table 6</ref>.</p><p>Motivation Explanation to Maslow Labels We use L2 regularization with λ = 0.01. The dataset is not rebalanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motivation Explanation to Reiss Labels</head><p>We use L2 regularization with λ = 0.1. The dataset is not rebalanced.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Maslow</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I (myself) Cousin</head><p>M: Love, Family/Contact "company, to have company, to show kinship and friendship" E: Joy/Anticipation " proud, concerned, helpful" M: Esteem/Stability , Power/Order "to control things, to cause my cousin to leave, to be mad at him if not for our relationship." E: Disgust/Anger " fed up, upset" M: Phys./Love, Family/Food "to permit a relative to live with me, to extend kindness, to kick him out" E: Joy/Trust " grateful, happy, sympathetic" E: Joy/Trust/Surprise " satisfaction" M: Phys. / Love, Rest "some stay away, to be slovenly, to be at her house" M: Love/Esteem "to prepare a meal, to prove himself, show appreciation" E: Fear/Sadness " alone, lost" E: Fear/Disgust/Sad/Anger " annoyed, losing, upset" </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Theories of Motivation (Maslow and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>The annotation pipeline for the fine-grained annotations with an example story.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Approv 0 .</head><label>0</label><figDesc>02 -0.01 0.03 -0.08 -0.05 0.08 0.16 0.14 0.02 0.08 0.05 0.01 -0.03 0.02 0.08 -0.08 0.07 -0.06 -0.11 -0.04 -0.01 -0.11 -0.17 -0.18 Status -0.04 0.00 0.07 -0.05 -0.01 0.04 0.14 0.18 0.08 0.12 0.02 0.05 -0.07 -0.05 0.07 -0.14 0.06 -0.08 -0.12 -0.06 0.00 -0.13 -0.17 -0.15 Power 0.04 0.06 0.02 -0.10 -0.03 0.12 0.01 0.06 0.25 0.13 0.10 -0.06 -0.13 -0.08 -0.03 -0.05 0.02 -0.08 -0.06 -0.01 -0.01 -0.01 -0.15 -0.10 Compet -0.05 0.00 0.01 -0.12 -0.01 0.02 0.09 0.12 0.14 0.42 0.07 -0.05 -0.25 -0.09 0.07 -0.17 -0.03 -0.11 -0.14 -0.14 -0.10 -0.18 -0.26 -0.22Honor 0.00 0.17 -0.01 -0.04 -0.06 -0.01 0.07 0.05 0.09 0.06 0.14 -0.03 -0.12 -0.04 0.07 -0.03 -0.03 -0.07 -0.05 0.01 0.01 0.04 -0.14 -0.10 Love Other 0.03 0.00 0.02 -0.07 -0.05 -1.00 0.09 0.06 -0.05 -0.03 0.04 0.14 -0.03 0.17 0.07 -0.02 -0.03 -0.09 -0.11 -0.07 -0.14 0.00 -0.14 -0.04 Romance 0.07 -0.13 -0.15 -0.07 -0.18 -1.00 -0.04 -0.09 -0.13 -0.19 -0.10 -0.01 0.65 0.03 -0.01 0.01 -0.10 -0.23 -0.20 -0.13 -0.29 -0.20 -0.20 -0.11 Contact 0.03 0.00 -0.07 -0.02 -0.07 0.01 0.00 -0.02 -0.07 -0.08 -0.02 0.15 0.04 0.39 0.11 -0.02 -0.02 -0.17 -0.17 -0.14 -0.19 -0.07 -0.15 -0.14 Belong -0.06 -0.02 -0.01 -0.01 -0.01 -0.02 0.07 0.07 0.00 0.03 0.05 0.01 0.02 0.10 0.11 -0.08 -0.02 -0.03 -0.08 -0.06 -0.06 -0.05 -0.11 -0.12 Family -0.02 -0.06 -0.12 0.00 -0.09 -0.03 -0.08 -0.09 -0.08 -0.19 0.00 0.01 -0.02 -0.03 -0.06 0.48 -0.06 -0.06 -0.08 -0.05 -0.19 -0.05 -0.11 -0.12 Stability Other -1.00 -0.02 0.07 0.03 -0.02 -1.00 -0.04 0.05 -0.07 -0.03 0.02 0.08 -0.07 -0.14 0.03 -0.07 -1.00 0.00 -0.11 0.08 0.12 0.18 -0.07 -0.03 Health -0.03 -0.04 -0.06 -0.02 -0.13 -0.08 -0.05 -0.06 -0.09 -0.10 -0.05 -0.07 -0.18 -0.20 -0.10 -0.06 0.00 0.45 0.15 -0.02 -0.16 0.14 -0.03 0.09 Tranq -0.07 -0.06 -0.05 -0.04 -0.10 0.02 -0.11 -0.08 -0.02 -0.16 -0.01 -0.15 -0.19 -0.16 -0.09 -0.08 0.01 0.10 0.42 0.13 -0.06 0.09 -0.18 -0.02 Order -0.03 0.00 -0.02 0.05 -0.07 -0.04 -0.03 -0.05 -0.01 -0.17 -0.01 -0.03 -0.15 -0.11 -0.05 -0.08 0.06 -0.02 0.11 0.24 0.14 -0.01 -0.16 0.04 Savings 0.06 0.02 0.01 -0.09 -0.10 0.01 -0.02 -0.01 0.00 -0.10 0.01 -0.16 -0.28 -0.16 -0.08 -0.16 0.09 -0.14 -0.05 0.09 0.45 -0.10 -0.12 -0.17 Physiolog. Other -1.00 -0.02 -0.03 -0.02 -0.01 0.13 -0.02 -0.02 -0.14 0.01 -0.14 0.05 -0.16 -0.04 -1.00 -0.11 -1.00 0.12 0.07 0.09 -0.01 -1.00 -0.04 0.10 Food -0.03 -0.11 -0.10 -0.11 -0.14 -1.00 -0.17 -0.22 -0.18 -0.20 -0.14 -0.15 -0.20 -0.18 -0.11 -0.09 -0.20 0.00 -0.13 -0.13 -0.12 -0.10 0.67 -0.08 Rest -0.02 -0.13 -0.05 0.15 -0.06 0.02 -0.22 -0.13 -0.16 -0.17 -0.17 -0.04 -0.15 -0.11 -0.11 -0.07 0.08 0.09 -0.02 0.02 -0.10 0.15 -0.05 0.56</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>NPMI confusion matrix on emotion categories for all annotator pairs with color scaling for legibility.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 :</head><label>8</label><figDesc>Fully annotated example from the annotation pipeline</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>arXiv:1805.06533v1 [cs.CL] 16 May 2018</figDesc><table><row><cell>Spiritual Growth</cell><cell>curiosity, serenity, idealism, independence competition, honor,</cell><cell>anticipation</cell><cell>joy</cell><cell>trust</cell></row><row><cell>Esteem</cell><cell>approval, power, status</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Love/belonging</cell><cell>family, social contact romance, belonging,</cell><cell>anger</cell><cell></cell><cell>fear</cell></row><row><cell>Stability</cell><cell>health, savings, order, safety</cell><cell>disgust</cell><cell></cell><cell>surprise</cell></row><row><cell>Physiological needs</cell><cell>food, rest</cell><cell cols="2">sadness</cell><cell></cell></row><row><cell>Maslow's needs</cell><cell>Reiss' motives</cell><cell cols="3">Plutchik basic emotions</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>).</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Character action lines:</cell><cell>Motivation:</cell></row><row><cell></cell><cell></cell><cell></cell><cell>I, me: 1, 4, 5</cell><cell>… Line 1, I, me:</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Cousin: 3, 4, 5</cell><cell>love/family</cell></row><row><cell></cell><cell>Story:</cell><cell></cell></row><row><cell cols="2">(1) I let my cousin stay with me. (2) He had nowhere to go.</cell><cell cols="2">(2a) Action Resolution</cell><cell>(3a) Motivation</cell></row><row><cell>(3)</cell><cell>However, he was a slob.</cell><cell>(1) Entity</cell></row><row><cell cols="2">(4) I was about to kick him out.</cell><cell>Resolution</cell></row><row><cell cols="2">(5) When he cooked me a huge</cell><cell cols="2">(2b) Affect</cell><cell>(3b) Emotional</cell></row><row><cell></cell><cell>breakfast, I decided he could</cell><cell cols="2">Resolution</cell><cell>Reaction</cell></row><row><cell></cell><cell>stay.</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Character mentions:</cell><cell>Character affect lines:</cell><cell>Emotional Reaction:</cell></row><row><cell></cell><cell></cell><cell>I, me (lines 1,4,5),</cell><cell>I, me: 2-5</cell><cell>… Line 3, I, me:</cell></row><row><cell></cell><cell></cell><cell>Cousin (lines 1-5)</cell><cell>Cousin: 2, 5</cell><cell>sad/disgusted/angry</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Spir. growth Esteem Love Stability Phys</head><label></label><figDesc></figDesc><table><row><cell></cell><cell cols="2"># Unique Open Text</cell><cell cols="2">% Annotations where selected</cell><cell></cell><cell># Unique Open Text</cell><cell cols="2">% Annotations where selected</cell></row><row><cell>outraged; picky</cell><cell>2055</cell><cell>disgust</cell><cell>0.14</cell><cell></cell><cell></cell><cell>8740</cell><cell></cell><cell></cell></row><row><cell>dismayed; disoriented</cell><cell>3205</cell><cell>surprise</cell><cell>0.33</cell><cell></cell><cell>become experienced</cell><cell></cell><cell></cell><cell>0.17</cell></row><row><cell>enraged; provoked</cell><cell>2016</cell><cell>anger</cell><cell>0.16</cell><cell></cell><cell>meet goal; to look nice</cell><cell>9676</cell><cell></cell><cell>0.22</cell></row><row><cell>touched; appreciated excluded; bleak</cell><cell>2964 2371</cell><cell>trust sadness</cell><cell>0.25 0.23</cell><cell></cell><cell>to support his friends</cell><cell>19768</cell><cell></cell><cell>0.3</cell></row><row><cell>future oriented; uptight</cell><cell>3868</cell><cell>anticipation</cell><cell></cell><cell>0.49</cell><cell>be employed; stay dry</cell><cell>11645</cell><cell></cell><cell>0.3</cell></row><row><cell>happier; jubiliation frozen in fear; fatalistic</cell><cell>3136 2376</cell><cell>joy fear</cell><cell>0.2</cell><cell>0.51</cell><cell>rest more; food</cell><cell>4953</cell><cell>.</cell><cell>0.13</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>NPMI confusion matrix on motivational categories for all annotator pairs with color scaling for legibility. The highest values are generally along diagonal or within Maslow categories (outlined in black). We highlight a few common points of disagreement between thematically similar categories.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Annotator 1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Disagreements</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Idealism vs. Honor</cell><cell>max= NPMI</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Serenity vs. Rest</cell><cell>0.68</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Approval vs.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Belonging</cell></row><row><cell>Annotator 2</cell><cell></cell><cell></cell><cell></cell><cell>0.34</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Health (Stability) vs.</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Physiological needs</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.10</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>&lt; 0</cell></row><row><cell>Figure 5: Label Type</cell><cell></cell><cell>PPA KA</cell><cell>% Agree w/ Maj. Lbl</cell></row><row><cell>Maslow</cell><cell>Dev Test</cell><cell>.77 .30 .77 .31</cell><cell>0.88 0.89</cell></row><row><cell>Reiss</cell><cell>Dev Test</cell><cell>.91 .24 .91 .24</cell><cell>0.95 0.95</cell></row><row><cell>Plutchik</cell><cell>Dev Test</cell><cell>.71 .32 .70 .29</cell><cell>0.84 0.83</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>: Agreement Statistics (PPA = Pairwise</cell></row><row><cell>percent agreement of worker responses per binary</cell></row><row><cell>category, KA= Krippendorff's Alpha)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>for each word in V . The word embeddings are max-pooled, yielding embedding v s ∈ R H , where H is the dimensionality of the Glove vectors. Using this max-pooled representation, h s and h c are extracted in the same manner as for TF-IDF features (Equation 2).</figDesc><table><row><cell cols="2">CNN We implement a CNN text categorization</cell></row><row><cell cols="2">model using the same configuration as Kim (2014)</cell></row><row><cell cols="2">to encode the sentence words. A sentence is rep-</cell></row><row><cell cols="2">resented as a matrix, v s ∈ R M ×d where each row</cell></row><row><cell>is a word embedding x s n for a word w s n ∈ x s .</cell><cell></cell></row><row><cell>v s = [x s 0 , x s 1 , . . . , x s N ]</cell><cell>(3)</cell></row><row><cell>h</cell><cell></cell></row></table><note>s = CNN(v s )</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>21.21 24.88 18.40 20.67 19.46 20.05 24.11 21.90 + Entity Context 29.79 34.56 32.00 20.55 24.81 22.48 22.71 25.24 23.91</figDesc><table><row><cell>Model</cell><cell>P</cell><cell>Maslow R</cell><cell>F1</cell><cell>P</cell><cell>Reiss R</cell><cell>F1</cell><cell>P</cell><cell>Plutchik R</cell><cell>F1</cell></row><row><cell>Random</cell><cell cols="3">7.45 49.99 12.96</cell><cell cols="2">1.76 50.02</cell><cell cols="4">3.40 10.35 50.00 17.15</cell></row><row><cell>Random (Weighted)</cell><cell>8.10</cell><cell>8.89</cell><cell>8.48</cell><cell>2.25</cell><cell>2.40</cell><cell cols="4">2.32 12.28 11.79 12.03</cell></row><row><cell cols="10">TF-IDF 30.10 GloVe 25.15 29.70 27.24 16.65 18.83 17.67 15.19 30.56 20.29</cell></row><row><cell>+ Entity Context</cell><cell cols="9">27.02 37.00 31.23 16.99 26.08 20.58 19.47 46.65 27.48</cell></row><row><cell>LSTM</cell><cell cols="9">24.64 35.30 29.02 19.91 19.76 19.84 20.27 30.37 24.31</cell></row><row><cell>+ Entity Context</cell><cell cols="9">31.29 33.85 32.52 18.35 27.61 22.05 23.98 31.41 27.20</cell></row><row><cell>+ Explanation Training</cell><cell cols="9">30.34 40.12 34.55 21.38 28.70 24.51 25.31 33.44 28.81</cell></row><row><cell>CNN (Kim, 2014)</cell><cell cols="9">26.21 31.09 28.44 20.30 23.24 21.67 21.15 23.36 22.20</cell></row><row><cell>+ Entity Context</cell><cell cols="9">27.47 41.01 32.09 18.89 31.22 23.54 24.32 30.76 27.16</cell></row><row><cell>+ Explanation Training</cell><cell cols="9">29.30 44.18 35.23 17.87 37.52 24.21 24.47 38.87 30.04</cell></row><row><cell>REN (Henaff et al., 2017)</cell><cell cols="9">26.24 42.14 32.34 16.79 22.20 19.12 26.22 33.26 29.32</cell></row><row><cell>+ Explanation Training</cell><cell cols="9">26.85 44.78 33.57 16.73 26.55 20.53 25.30 37.30 30.15</cell></row><row><cell cols="10">NPN (Bosselut et al., 2018) 24.27 44.16 31.33 13.13 26.44 17.55 21.98 37.31 27.66</cell></row><row><cell>+ Explanation Training</cell><cell cols="9">26.60 39.17 31.69 15.75 20.34 17.75 24.33 40.10 30.29</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell>: State Classification Results</cell></row><row><cell>category is very uneven: macro-averaged positive</cell></row><row><cell>class probabilities of 8.2, 1.7, and 9.9% per cate-</cell></row><row><cell>gory for Maslow, Reiss, and Plutchik respectively.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 4 :</head><label>4</label><figDesc>F1 scores of predicting correct category labels from free response annotations</figDesc><table><row><cell>Model</cell><cell>Motivation Avg VE</cell><cell>Emotion Avg VE</cell></row><row><cell cols="3">Random 56.02 45.75 40.23 39.98</cell></row><row><cell>LSTM</cell><cell cols="2">58.48 51.07 52.47 52.30</cell></row><row><cell>CNN</cell><cell cols="2">57.83 50.75 52.49 52.31</cell></row><row><cell>REN</cell><cell cols="2">58.83 51.79 53.95 53.79</cell></row><row><cell>NPN</cell><cell cols="2">57.77 51.77 54.02 53.85</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 6 :let my cousin stay with me. He had nowhere to go. However, he was a slob. I was about to kick him out. When he cooked me a huge breakfast, I decided he could stay.</head><label>6</label><figDesc>Class Distribution (percent positive instances) per category.</figDesc><table><row><cell>I</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We make our dataset publicly available at https:// uwnlp.github.io/storycommonsense/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Majority label for the motivation categories is what was agreed upon by at least two annotators per category. For emotion categories, we averaged the point-wise ratings and counted a category if the average rating was ≥ 2.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank the reviewers for their insightful comments. We also thank Bowen Wang, xlab members, Martha Palmer, Tim O'Gorman, Susan W. Brown, and Ghazaleh Kazeminejad for helpful discussions on inter-annotator agreement and the annotation pipeline. This work was supported in part by NSF GRFP DGE-1256082, NSF IIS-1714566, IIS-1524371, Samsung AI, and DARPA CwC (W911NF-15-1-0543).</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Anticipation Joy</head><p>Trust <ref type="table">Fear  Surprise  Sadness  Disgust  Anger   H  M  H  M  H  M  H  M  H  M  H  M  H  M  H  M</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Simulating action dynamics with neural process networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bosselut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ari</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corin</forename><surname>Ennis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 6th International Conference on Learning Representations</title>
		<meeting>the 6th International Conference on Learning Representations</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A Grammar of Motives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Burke</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<publisher>Univ of California Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Mpqa 3.0: An entity/event-level sentiment corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janyce</forename><surname>Wiebe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1323" to="1328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning to generate product reviews from attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaohan</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mirella</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Controlling linguistic style aspects in neural language generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Ficler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoav</forename><surname>Goldberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP Workshop on Stylistic Variation</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Affect-LM: A neural language model for customizable affective text generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sayan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Chollet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugene</forename><surname>Laksana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Louis-Philippe</forename><surname>Morency</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Scherer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvin I</forename><surname>Goldman</surname></persName>
		</author>
		<title level="m">Theory of Human Action</title>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Automatically producing plot unit representations for narrative text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellen</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hal</forename><surname>Daumé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A question answering approach for emotion cause extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiannan</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Du</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<meeting><address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1594" to="1603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Tracking the world state with recurrent entity networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arthur</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Robust disambiguation of named entities in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Amir</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilaria</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagen</forename><surname>Fürstenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilyana</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Dynamic entity representations in neural language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenhao</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Martschat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP. Association for Computational Linguistics</title>
		<meeting><address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1831" to="1840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Globally coherent text generation with neural checklist models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chloé</forename><surname>Kiddon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="329" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for sentence classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoon</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Progress on a cognitivemotivational-relational theory of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lazarus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">819</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Plot units and narrative summarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><forename type="middle">G</forename><surname>Lehnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="293" to="331" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neural net models for Open-Domain discourse coherence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">How not to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">Joseph</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iulian</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joelle</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Personabank: A corpus of personal narratives and their story intention graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><forename type="middle">M</forename><surname>Lukin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Bowden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Casey</forename><surname>Barackman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marilyn</forename><forename type="middle">A</forename><surname>Walker</surname></persName>
		</author>
		<idno>abs/1708.09082</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A theory of human motivation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maslow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">370</biblScope>
			<date type="published" when="1943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Crowdsourcing a word-emotion association lexicon</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saif</forename><surname>Mohammad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">D</forename><surname>Turney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="436" to="465" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A corpus and cloze evaluation for deeper understanding of commonsense stories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><surname>Vanderwende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Lsdsem 2017 shared task: The story cloze test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nasrin</forename><surname>Mostafazadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Annie</forename><surname>Louis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathanael</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</title>
		<meeting>the 2nd Workshop on Linking Models of Lexical, Sentential and Discourse-level Semantics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="46" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Modeling reportable events as turning points in narrative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><surname>Mckeown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Glove: Global vectors for word representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A general psychoevolutionary theory of emotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Plutchik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theories of emotion</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multifaceted nature of intrinsic motivation: The theory of 16 basic desires</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Reiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Gen. Psychol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">179</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Cognitive, social, and physiological determinants of emotional state</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Schachter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerome</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">379</biblScope>
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Straker</surname></persName>
		</author>
		<ptr target="http://changingminds.org/explanations/needs/reiss_16_needs.htm.Accessed" />
		<title level="m">Reiss&apos; 16 human needs</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Sequence to sequence learning with neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3104" to="3112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">The psychological meaning of words: LIWC and computerized text analysis methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">W</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Lang. Soc. Psychol</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Van Merriënboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.05698</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Reference-aware language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phil</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename><surname>Ling</surname></persName>
		</author>
		<idno>abs/1611.01628</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Situation recognition: Visual semantic role labeling for image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Yatskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Emotion distribution learning from texts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
