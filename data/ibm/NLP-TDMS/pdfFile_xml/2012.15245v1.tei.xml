<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DDANet: Dual Decoder Attention Network for Automatic Polyp Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Kumar Tomar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SimulaMet</orgName>
								<address>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debesh</forename><surname>Jha</surname></persName>
							<email>debesh@simula.no</email>
							<affiliation key="aff0">
								<orgName type="institution">SimulaMet</orgName>
								<address>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">The Arctic University of Norway</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharib</forename><surname>Ali</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Engineering Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Håvard</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">The Arctic University of Norway</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dag</forename><surname>Johansen</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">The Arctic University of Norway</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SimulaMet</orgName>
								<address>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pål</forename><surname>Halvorsen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SimulaMet</orgName>
								<address>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Oslo Metropolitan University</orgName>
								<address>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">DDANet: Dual Decoder Attention Network for Automatic Polyp Segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Polyp segmentation</term>
					<term>Deep Learning</term>
					<term>Convolutional neural network</term>
					<term>Benchmarking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Colonoscopy is the gold standard for examination and detection of colorectal polyps. Localization and delineation of polyps can play a vital role in treatment (e.g., surgical planning) and prognostic decision making. Polyp segmentation can provide detailed boundary information for clinical analysis. Convolutional neural networks have improved the performance in colonoscopy. However, polyps usually possess various challenges, such as intra-and inter-class variation and noise. While manual labeling for polyp assessment requires time from experts and is prone to human error (e.g., missed lesions), an automated, accurate, and fast segmentation can improve the quality of delineated lesion boundaries and reduce missed rate. The Endotect challenge provides an opportunity to benchmark computer vision methods by training on the publicly available Hyperkvasir and testing on a separate unseen dataset. In this paper, we propose a novel architecture called "DDANet" based on a dual decoder attention network. Our experiments demonstrate that the model trained on the Kvasir-SEG dataset and tested on an unseen dataset achieves a dice coefficient of 0.7874, mIoU of 0.7010, recall of 0.7987, and a precision of 0.8577, demonstrating the generalization ability of our model.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Colorectal cancer is one of the leading causes of cancer. Colonoscopy is a standard medical procedure for the surveillance examination and treatment. Regular screening and removal of pre-cancerous lesions through colonoscopy is essential for early cancer detection and prevention. Studies suggest that the miss-rate of adenoma is between 6 to 27% <ref type="bibr" target="#b0">[1]</ref>.</p><p>The automatic segmentation of the suspected areas with lesions in colonoscopy images can play a crucial role, and identifying each colon pixel can significantly impact clinical settings. With the increase of publicly available datasets, dominant methodology such as convolutional neural network, improved hardware, and collaboration between computational and clinical communities to tackle the problems in endoscopic imaging through computer vision tasks is gaining momentum than ever before. An automatic polyp detection or surveillance system can help to achieve low-cost design solutions and save time of clinicians allowing them to use their time to look into more severe cases.</p><p>In this respect, the Endotect challenge <ref type="bibr" target="#b7">[8]</ref> offers three tasks, namely, detection of Gastrointestinal (GI) tract images, efficient detection on the same images, and automatic polyp segmentation. The detection and efficient detection task are based on the HyperKvasir dataset <ref type="bibr" target="#b4">[5]</ref>, and the segmentation is based on the Kvasir-SEG dataset <ref type="bibr" target="#b11">[12]</ref>. Out of these three tasks, we participated in the "segmentation task", where the goal was to generate an automatic segmentation of the polyps for the unseen dataset.</p><p>In this paper, we propose a novel deep learning architecture, called Dual Decoder Attention Network (DDANet), for automatic polyp segmentation. It follows an encoder-decoder scheme and incorporates a single encoder that is shared by two parallel decoders, where the first decoder acts as a segmentation network and the second decoder acts as an autoencoder network. The autoencoder network helps to strengthen the feature maps in the encoder network. It is used as an auxiliary task training, which is used to generate an attention map. This attention map is used in each decoder to improve the semantic representation of the feature maps. This, in turn, helps to improve the performance of the entire network. The proposed DDANet is fed with an RGB input image,where it predicts the segmentation mask and the reconstructed grayscale image. The architecture is efficient in terms of Frame per Second (FPS) and also has a decent evaluation score. These metrics are the requirement for the real-world settings toward developing a Computer Aided Diagnosis (CADx) system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Automatic polyp segmentation task is a well-defined computer vision problem. Recently, there have been several competitions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b9">10]</ref> and individual efforts <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b8">9]</ref> toward building a CADx system for the polyp segmentation. With these competitions and individual efforts, polyp segmentation is becoming more and more mature. However, comparing models and results of the many individual approaches is difficult due to the use of diverse (often publicly nonavailable) datasets and different hardware. In this respect, competitions provide an opportunity to benchmark and compare the designed methods with other competitors' on the same dataset. Moreover, the evaluation metrics are independently calculated by the organizers, including the ranking decision of each team.</p><p>The competitions can help us to define the strengths and weaknesses of each method. It also provides us with an opportunity to disseminate methods and discuss the results collectively in the same space. Through this year's Endotect challenge, we provide a novel solution to develop more efficient algorithms that can be useful to build an automatic polyp segmentation system. Our architecture is composed of an autoencoder branch in addition to the segmentation branch, which is different from other encoder-decoder based network (for example, UNet <ref type="bibr" target="#b13">[14]</ref>, ResUNet++ <ref type="bibr" target="#b12">[13]</ref>, DoubleUNet <ref type="bibr" target="#b10">[11]</ref>). The benefit of incorporating autoencoder in the network can be seen from the quantitative and qualitative results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">DDANet</head><p>In this section, we will first describe each component of our DDANet and then detail the overall proposed DDANet architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Residual block</head><p>As the network depth increases, the performance also increases to a certain limit as the gradients can be effectively calculated. However, after a certain depth, the performance of the model may be impacted due to the vanishing or exploding gradients as the gradients become either zero or too large. By introducing a skip-connection in residual learning, the problem of the vanishing or exploding gradients has been solved. Our residual block (see <ref type="figure" target="#fig_0">Figure 1a</ref>) consists of two 3×3 convolutions, each followed by a batch normalization and a Rectified linear unit (ReLU) activation function. The residual learning introduces a shortcut connection or identity mapping, which connects the input with the residual block's output. The identity mapping tries to learn an identity function since the input is directly passed to the output. It also helps in a better flow of the gradients during the backpropagation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Squeeze and Excitation block</head><p>A Convolutional Neural Network (CNN) is used to extract features from an image and then transform the image into a feature map. A problem with CNNs is that they treat every feature channel as equally important. To overcome this problem, we introduce a squeeze and excitation layer, which acts as a channelwise attention mechanism. It re-weights every feature channel accordingly to create a more accurate feature map. In this way, the overall network becomes more sensitive towards essential features that improve the network performance significantly. The squeeze and excitation network mainly consists of two steps. In the first step, the feature maps are compressed using the global average pooling function to generate a compressed representation for the feature maps. While, in the second step, a 2-layered neural network is used, where features are first reduced and then expanded. This generates a feature vector, which is used to scale the feature channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The DDANet architecture</head><p>The proposed architecture named DDANet follows an encoder-decoder design similar to ResUNet++ <ref type="bibr" target="#b12">[13]</ref>. The DDANet combines the strength of the residual learning and the squeeze and excitation network. The proposed DDANet is a fully convolutional network that consists of a single encoder shared by dual decoders. The encoder network consists of a 4 encoder block, whereas each decoder network also consists of 4 decoder block (see <ref type="figure" target="#fig_0">Figure 1d</ref>).</p><p>The RGB input image is first fed into the encoder network (see <ref type="figure" target="#fig_0">Figure 1b</ref>), which encodes it into an abstract feature representation while gradually downsampling it. The output of the encoder network is fed to both decoders (see <ref type="figure" target="#fig_0">Figure 1c</ref>), where it is followed by a 4 × 4 transpose convolution that doubles its spatial dimensions. After that, the image is concatenated with an appropriate feature maps from the encoder network using the skip connection. These skip connections fetch the features from earlier layers at their original resolution, which increases their feature representation strength. The skip connections also act as an alternative path for the gradient flow and are often beneficial for model convergence.</p><p>Two residual blocks are then used to learn the necessary feature required by the network during back-propagation. The output of the second decoder block (autoencoder branch) follows a 1 × 1 convolution and a sigmoid activation function to generates an attention map. This attention map is multiplied by the output of the first decoder block (segmentation branch), which acts as an input for the next decoder block in the segmentation branch. The final decoder block's output is passed through a 1 × 1 convolution and a sigmoid activation function, where the first decoder outputs a segmentation mask, and the second outputs the reconstructed grayscale image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Setup</head><p>In this section, we present the implementation details and datasets used in this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Implementation Details</head><p>The proposed DDANet architecture is implemented in the PyTorch 1.6 framework 1 . For training the DDANet, we used an NVIDIA DGX-2 machine that uses an Nvidia V100 Tensor Core GPUs.During training, we have used an input image resolution of 512 × 512. We use a combination of binary cross-entropy and dice loss for calculating the loss between the predicted masks and the ground-truth masks. We have used binary cross-entropy in the case of predicting the grayscale image. An Adam optimizer was used with a learning rate of 1e −4 . The models were trained for 200 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Datasets</head><p>The Kvasir-SEG <ref type="bibr" target="#b11">[12]</ref> dataset was used for training the model. We have used 88% of the dataset for training and the remaining 12% images for developmenttest-set. Kvasir-SEG consists of 1000 polyp images, ground truth segmentation masks, and bounding boxes. A separate test dataset with 200 images was provided for prediction. However, the ground truth for this dataset was not provided by the organizers. The exact number of images used for the training and testing can also be found in our GitHub repository. More details about the dataset and the baseline results on it can be found in <ref type="bibr" target="#b11">[12]</ref>. <ref type="table" target="#tab_0">Table 1</ref> shows the results of the DDANet trained and validated on Kvasir-SEG. Additionally, evaluation scores on the test dataset can also be found here. The evaluation metrics for the challenge was Dice Coefficient (DSC). However, we have also calculated other commonly used metrics such as mean Intersection over Union (mIoU), recall, precision, and FPS. The DDANet obtained a DSC of 0.8576, a mIoU of 0.7800, a recall of 0.8880, and a precision of 0.8643. All the metrics suggest that our method performs quite well on the Kvasir-SEG dataset. When we compare the results with our previous results <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b11">12]</ref>, where  the DSC values were 0.8133, and 0.7877, DDANet achieves a higher DSC of 0.8576. However, we can not compare directly with this work with our previous works as a different train-test split of the dataset is used. <ref type="figure" target="#fig_1">Figure 2</ref> shows the qualitative results of the DDANet on Kvasir-SEG. The figure shows that the proposed DDANet is able to segment both larger and smaller polyps. However, the figure also shows the challenges in identifying the flat polyps, which is one of the open issues in the field of development of CADx systems for colonoscopy. From the quantitative results on development and un-seen test dataset, we can say that the proposed method is comprehensive in producing reliable segmentation output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>The qualitative results (see <ref type="figure" target="#fig_1">Figure 2)</ref> show that the proposed model was able to segment polyps ranging from large to small <ref type="figure" target="#fig_1">(Figure 2</ref>), but still, challenges remain within some polyps (for example, flat or sessile). We can also see a nearly perfect reconstruction of the grayscale image. In the future, we would like to use image super-resolution instead of just a grayscale image reconstruction.</p><p>From all the results, we can see that our method achieves high precision and recall evaluation scores on both the Kvasir-SEG validation dataset and on the unseen test dataset (see <ref type="table" target="#tab_0">Table 1</ref>). Additionally, we also achieved a DSC of 0.7874 on the unseen dataset. Thus, high DSC, recall, and precision results validate our proposed method. Moreover, our approach is quite fast with an average FPS of 70.23. Thus, the results show that our method can identify polyps in real-time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>The Endotect challenge <ref type="bibr" target="#b7">[8]</ref> aims to benchmark various computer-vision approaches on the HyperKvasir dataset containing GI images and videos. Here, we have proposed the DDANet architecture for automatic polyp segmentation, and the proposed architecture provides good results in the segmentation task. We have obtained a high precision, recall, DSC, mIoU, and FPS. However, there are large rooms for improvements. We intend to further improve the architecture by applying post-processing and analyzing the optimal parameters in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>DDANet architecture and its components.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Qualitative results of the DDANet on the Kvasir-SEG test dataset. The blue line divides the segmentation and the reconstruction part. Columns 4 and 5 show the reconstruction part that was used in the DDANet as an auxiliary task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Quantitative results on Kvasir-SEG and unseen (Challenge) dataset.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Method DSC mIOU Recall Precision FPS</cell></row><row><cell>Kvasir-SEG</cell><cell>DDANet 0.8576 0.7800 0.8880 0.8643</cell><cell>69.59</cell></row><row><cell cols="2">Unseen (Challenge) DDANet 0.7874 0.7010 0.7987 0.8577</cell><cell>70.23</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/nikhilroxtomar/DDANet</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work is funded in part by the Research Council of Norway, project number 263248 (Privaton) and project number 282315 (AutoCap). We performed all computations in this paper on equipment provided by the Experimental Infrastructure for Exploration of Exascale Computing (eX 3 ), which is financially supported by the Research Council of Norway under contract 270053.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The miss rate for colorectal adenoma determined by quality-adjusted, back-to-back colonoscopies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Bae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Byun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Eun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gut and liver</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">64</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dmitrieva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ghatwary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Polat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Temizel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hekalo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">B</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Matuszewski</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.06034</idno>
		<title level="m">A translational pathway of deep learning methods in gastrointestinal endoscopy</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An objective comparison of detection and segmentation algorithms for artefacts in clinical endoscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Braden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kayser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Soberanis-Mukul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific reports</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Comparative Validation of Polyp Detection Methods in Video Colonoscopy: Results From the MICCAI 2015 Endoscopic Vision Challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tajkbaksh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Matuszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Angermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Romain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rustad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Balasingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on medical imaging</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1231" to="1249" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Borgli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Eskeland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Randel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pogorelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Griwodz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Stensland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Garcia-Ceja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">T</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Lange</surname></persName>
		</author>
		<title level="m">HyperKvasir, a Comprehensive Multi-Class Image and Video Dataset for Gastrointestinal Endoscopy</title>
		<imprint>
			<publisher>Springer Nature Scientific Data</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Giana polyp segmentation with fully convolutional dilation neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">B</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Matuszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications</title>
		<meeting>the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="632" to="641" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Polyp Segmentation with Fully Convolutional Deep Neural Networks-Extended Evaluation Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Matuszewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Imaging</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">69</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">EndoTect: A Competition on Automatic Disease Detection in the Gastrointestinal Tract</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR 2020 Workshops and Challenges</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rittscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11392</idno>
		<title level="m">Real-Time Polyp Detection, Localisation and Segmentation in Colonoscopy Using Deep Learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Emanuelsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<title level="m">Medico Multimedia Task at MediaEval 2020:Automatic Polyp Segmentation</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Proceedings of MediaEval CEUR Workshop</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">DoubleU-Net: A Deep Convolutional Neural Network for Medical Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Johansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Computer Based Medical Systems (CBMS)</title>
		<meeting>the International Symposium on Computer Based Medical Systems (CBMS)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<title level="m">Proceedings of the International Conference on Multimedia Modeling (MMM)</title>
		<meeting>the International Conference on Multimedia Modeling (MMM)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
	<note>Kvasir-SEG: A Segmented Polyp Dataset</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">ResUNet++: An Advanced Architecture for Medical Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Symposium on Multimedia (ISM)</title>
		<meeting>the International Symposium on Multimedia (ISM)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="225" to="230" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of International Conference on Medical image computing and computer-assisted intervention</title>
		<meeting>International Conference on Medical image computing and computer-assisted intervention</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
