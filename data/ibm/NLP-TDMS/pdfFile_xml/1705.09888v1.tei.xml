<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Cross-modal Subspace Learning for Fine-grained Sketch-based Image Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
							<email>peng.xu@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Laboratory</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiyue</forename><surname>Yin</surname></persName>
							<email>qyyin@nlpr.ia.ac.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Automation, Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">National Lab of Pattern Recognition</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongye</forename><surname>Huang</surname></persName>
							<email>yongye@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Laboratory</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
							<email>yizhe.song@qmul.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="department">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="laboratory">SketchX Lab</orgName>
								<orgName type="institution">Mary University of London</orgName>
								<address>
									<settlement>London</settlement>
									<region>Queen</region>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanyu</forename><surname>Ma</surname></persName>
							<email>mazhanyu@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Laboratory</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wang</surname></persName>
							<email>wangliang@nlpr.ia.ac.cn</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Automation, Chinese Academy of Sciences</orgName>
								<orgName type="laboratory">National Lab of Pattern Recognition</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
							<email>t.xiang@qmul.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="department">School of Electronic Engineering and Computer Science</orgName>
								<orgName type="laboratory">SketchX Lab</orgName>
								<orgName type="institution">Mary University of London</orgName>
								<address>
									<settlement>London</settlement>
									<region>Queen</region>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Bastiaan</forename><surname>Kleijn</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Communications and Signal Processing Group</orgName>
								<orgName type="institution">Victoria University of Wellington</orgName>
								<address>
									<country key="NZ">New Zealand</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Guo</surname></persName>
							<email>guojun@bupt.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Pattern Recognition and Intelligent System Laboratory</orgName>
								<orgName type="institution">Beijing University of Posts and Telecommunications</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Cross-modal Subspace Learning for Fine-grained Sketch-based Image Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Cross-modal subspace learning</term>
					<term>Sketch-based image retrieval</term>
					<term>Fine-grained</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Sketch-based image retrieval (SBIR) is challenging due to the inherent domain-gap between sketch and photo. Compared with pixel-perfect depictions of photos, sketches are iconic renderings of the real world with highly abstract. Therefore, matching sketch and photo directly using low-level visual clues are unsufficient, since a common low-level subspace that traverses semantically across the two modalities is non-trivial to establish. Most existing SBIR studies do not directly tackle this cross-modal problem. This naturally motivates us to explore the effectiveness of cross-modal retrieval methods in SBIR, which have been applied in the image-text matching successfully. In this paper, we introduce and compare a series of state-of-the-art cross-modal subspace learning methods and benchmark them on two recently released fine-grained SBIR datasets. Through thorough examination of the experimental results, we have demonstrated that the subspace learning can effectively model the sketch-photo domain-gap. In addition we draw a few key insights to drive future research.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Sketch-based image retrieval (SBIR) has drawn increasingly more attention in the past decade, especially with the prevalence of touchscreens. There exist many annotated datasets <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref> and methods tackling all aspects of the problem <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref>. The vibrancy of the SBIR area also promoted the development of other related research problems, such as sketch recognition <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>, sketch synthesis <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>, sketch-based 3D retrieval <ref type="bibr" target="#b15">[16]</ref>, and sketch segmentation <ref type="bibr" target="#b16">[17]</ref>. From a technical perspective, SBIR is traditionally cast into a classification task, with most prior work evaluating the retrieval performance at categorylevel <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. More recently, fine-grained variants of SBIR <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b0">1]</ref> requires retrieval to be conducted within single object categories. With this more constrained ranking setting of the problem, researchers no longer carry out similarity matching based only on low-level and hand-designed visual features <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b21">22]</ref>, but begin to devolve into high-level and partial information for sketch and photo matching, e.g., local stroke ordering <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b22">23]</ref>, and part-level attributes <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b8">9]</ref>.</p><p>Despite great strides made, most prior work ignores the cross-modal gap that inherently exists between sketch and photo, treating images as edgemaps (semi-sketches) <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b9">10]</ref>. This assumption works well when the retrieval system is presented with good quality sketches that are close to contour tracings of intended objects, but would not work well with freehand sketches where sketches are much more abstract and do not offer close resemblance natural objects. However, effectively solving the sketch-photo cross-modal gap is non-trivial: (i) Sketch can only capture limited shape and contour information. It utilizes coarse lines to describe key features of an object at an abstract and semantic level. As shown in <ref type="figure" target="#fig_0">Fig. 1</ref>, a pyramid can be denoted as a triangle in sketch form. (ii) Different people have different observations, past experiences, drawing styles, and drawing skill <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref>. <ref type="figure" target="#fig_0">Fig. 1</ref> shows us that sketches drawn by different persons for the same cat or shoe may be highly diverse. This naturally motivates us to apply cross-modal matching methods to tackle the SBIR problem. However, to the best of our knowledge, all previous cross-modal work <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref> are designed to address the image-text modal gap (e.g., Wikipedia image-text dataset <ref type="bibr" target="#b23">[24]</ref>, Pascal VOC dataset <ref type="bibr" target="#b29">[30]</ref>, NUS-WIDE <ref type="bibr" target="#b30">[31]</ref>, LabelMe <ref type="bibr" target="#b31">[32]</ref>). Therefore, making their general applicableness to SBIR remains unclear.</p><p>The main approaches behind existing image-text cross-modal research can be roughly categorized into pair-wise modeling <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>, ranking <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38]</ref>, mapping <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41]</ref>, and graph embedding <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b42">43]</ref>. In particular, probabilistic models <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b44">45]</ref>, metric learning approaches <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b48">49]</ref>, and subspace learning methods <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b49">50]</ref> have been proven to be effective across a number of datasets. Probabilistic approaches learn the multimodal correlation by modeling the joint multi-modal data distribution <ref type="bibr" target="#b43">[44]</ref>. Metric learning methods learn and compute appropriate distance metrics between different modalities <ref type="bibr" target="#b45">[46]</ref>. Subspace learning constructs the common subspace and map multi-modal data into it to conduct cross-modal matching <ref type="bibr" target="#b39">[40]</ref>. Among these cross-modal techniques, cross-modal subspace learning methods have achieved state-of-the-art results in recent years <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b51">52]</ref>, which have borrowed much inspiration from the conventional subspace approaches <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b58">59]</ref>. For a comprehensive survey, please refer to <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b60">61]</ref>.</p><p>In this paper, we focus on analyzing the interaction and relationship between sketch and photo in the cross-modal setting. The main contributions of this paper are two-fold:</p><p>• We present and compare a series of state-of-the-art cross-modal subspace learning methods, and benchmark them on two recently released fine-grained SBIR datasets [1, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5].</head><p>• We conduct detailed comparative analysis towards the general applicability of crossmodal techniques on matching sketches and photos.</p><p>The remaining parts of this paper are organized as follows. Section 2 briefly presents some state-of-the-art cross-modal subspace learning methods and the corresponding characteristics. In Section 3, we report and analyze their experimental performances for the SBIR task. Potential future research insights for SBIR are discussed in Section 4. Finally, conclusions are drawn in Section 5.</p><p>A preliminary version of this work has been presented in <ref type="bibr" target="#b61">[62]</ref>. The main extensions are:</p><p>• We add three cross-modal subspace learning methods (CDFE <ref type="bibr" target="#b62">[63]</ref>, CCA-3V <ref type="bibr" target="#b63">[64]</ref>, JF-SSL <ref type="bibr" target="#b42">[43]</ref>) for intensive comparisons.</p><p>• Extensive experiments are performed on one extra recently released fine-grained SBIR dataset (i.e., the chair SBIR dataset).</p><p>• We simultaneously evaluate the performances of these methods for SBIR tasks on both subcategory-level and instance-level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Cross-modal Subspace Learning</head><p>In this section, we will briefly survey some state-of-the-art cross-modal subspace learning methods designed for image and text. All these methods will share the same notation. Suppose that sample matrices X a = [x a 1 , x a 2 , · · · , x a n ] ∈ R da×n and</p><formula xml:id="formula_0">X b = [x b 1 , x b 2 , · · · , x b n ] ∈ R d b ×n</formula><p>are extracted from modality a and modality b, respectively. These multi-modal samples can be categorized into c classes. Samples and the corresponding class labels are denoted as</p><formula xml:id="formula_1">{x a i , c a i } n i=1 and {x b i , c b i } n i=1 , where each pair {x a i , x b i } (1 i n)</formula><p>represents the same object or content belonging to the same class. Y = [y 1 , y 2 , · · · , y n ] T ∈ R n×c denotes the class label matrix for the multi-modal data. The transform for the i-th sample of modality a is denoted as x a i → f a i . Similarly, the transform for the i-th sample of modality b is denoted as x b i → f b i . Throughout this paper, vectors and matrices are denoted as straight bold lower-case x and upper-case X, respectively. These cross-modal subspace learning methods have the common workflow of learning a projection matrix for each modality to project the data from different modalities into a common comparable subspace in the training phase. In the test phase, the test data samples from one modality will be taken as the query set to retrieve matched samples from the other modality. In this paper, W a and W b denote the projection matrices for modality a and modality b, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Canonical Correlation Analysis (CCA)</head><p>CCA <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b49">50]</ref> is an effective multivariate statistical analysis approach, which is analogous to principal component analysis (PCA) <ref type="bibr" target="#b64">[65]</ref>. It was originally designed for data correlation modeling and dimension reduction. Recently, CCA has been applied widely in multi-modal data fusion and cross-media retrieval <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b65">66]</ref>. CCA has become one of the most popular unsupervised cross-modal subspace learning methods due to its generalization capability.</p><p>CCA learns a set of canonical component pairs for X a and X b , i.e., directions w a ∈ R da and w b ∈ R d b along which the multi-modal data is maximally correlated <ref type="bibr" target="#b23">[24]</ref> as</p><formula xml:id="formula_2">max wa =0,w b =0 w T a Σ ab w b w T a Σ aa w a w T b Σ bb w b ,<label>(1)</label></formula><p>where Σ aa and Σ bb denote the empirical covariance matrices for a modality and b modality, respectively. Σ ab = Σ T ba represents the cross-covariance matrix between different modalities. By repeatedly solving (1), we can obtain a series of canonical component pairs. We can choose the first d canonical component pairs {w a , w b } i (1 i d) for projecting X a and X b into two d dimensional subspaces. Here, d is a hyper-parameter. This optimization objective of (1) can be solved as a generalized eigenvalue problem (GEV) <ref type="bibr" target="#b66">[67]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Partial Least Squares (PLS)</head><p>PLS <ref type="bibr" target="#b67">[68]</ref> can linearly map multi-modal data into a linear subspace that preserves the data correlation. It can be adopted to solve the cross-modal matching in many multi-modal scenarios. PLS has been effectively applied in face recognition and multi-media retrieval with different motivations <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b68">69,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b70">71,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b73">74]</ref>.</p><p>PLS models X a and X b such that [52]</p><formula xml:id="formula_3">X T a = TP T + E X T b = UQ T + F U = TD + H .<label>(2)</label></formula><p>T ∈ R n×d and U ∈ R n×d contain the d extracted PLS scores or latent projections. P ∈ R p×d and Q ∈ R q×d are the matrices of loadings and E ∈ R n×p , F ∈ R n×q , and H ∈ R n×d are the residual matrices. D ∈ R d×d is a diagonal matrix describing the latent scores of X T a and X T b .</p><p>PLS learns the basis vectors w a and w b such that the covariance between the score vectors t and u (rows of T and U) is maximized as</p><formula xml:id="formula_4">max([cov(t, u)] 2 ) = max wa,w b ([cov(X T a w a , X T b w b )] 2 ) s.t. w a = w b = 1 .<label>(3)</label></formula><p>2.3. Generalized Multi-view Analysis (GMA) GMA <ref type="bibr" target="#b24">[25]</ref> is a special multi-view framework, which can be solved efficiently as a generalized eigenvalue problem. As we will show in this section, many popular supervised and unsupervised feature extraction techniques can be derived based on GMA.</p><p>The constrained objective is</p><formula xml:id="formula_5">max wa,w b w T a A a w a + µw T b A b w b + βw T a X a X T b w b s.t. w T a B a w a + αw T b B b w b = 1 ,<label>(4)</label></formula><p>where, w a and w b denote the projection directions. The positive terms µ, β, and α are hyperparameters controlling the balance among the objectives. A i (i = a, b) is the between-class variance matrix while B i (i = a, b) is the within-class covariance matrix. Sharma et al. <ref type="bibr" target="#b24">[25]</ref> have illustrated that if we substitute {A i , B i , X i } i=a,b in (4) with particular expressions, we obtain the corresponding objective functions of different methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1.">Bilinear Model (BLM)</head><p>In (4), setting A i = X i X T i /n, B i = I, and we obtain BLM under the proposed GMA framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2.">Generalized Multi-view Linear Discriminant Analysis (GMLDA)</head><p>We can set A i = S B i , B i = S W i , where S W /S B are the within/between-class scatter matrices. Here, X i is substituted by its class mean matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3.">Generalized Multi-view Margin Fisher Analysis (GMMFA)</head><p>Based on GMA framework, the expression for the multi-view version of MFA is complex. It utilizes the graph construction to restrict the projected data. More details can be found in <ref type="bibr" target="#b24">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Common Discriminant Feature Extraction (CDFE)</head><p>Lin and Tang <ref type="bibr" target="#b62">[63]</ref> used the empirical separability and the local consistency to propose the CDFE method for subspace learning. The empirical separability ensures the intra-class compactness and the inter-class dispersion, which are measured respectively as follows <ref type="bibr" target="#b62">[63]</ref> </p><formula xml:id="formula_6">J intraclass = 1 N 1 n i=1 j:c b j =c a i f a i − f b j 2 ,<label>(5)</label></formula><formula xml:id="formula_7">J interclass = 1 N 2 n i=1 j:c b j =c a i f a i − f b j 2 ,<label>(6)</label></formula><p>where N 1 and N 2 are the quantities of sample pairs from the same class and the different classes, respectively. As shown in <ref type="figure" target="#fig_1">Fig. 2</ref>, the empirical separability can be defined as:</p><formula xml:id="formula_8">J e = J intraclass − αJ interclass ,<label>(7)</label></formula><p>where α is a hyper-parameter for trade-off. To prevent the overfitting, local consistency can be used to regularize the empirical separability. The objective function of CDFE can be formulated as follows:</p><formula xml:id="formula_9">J CDF E = J e + βJ l ,<label>(8)</label></formula><p>where β is a hyper-parameter to adjust the trade-off between these two objectives. Here, J l represents the local consistency objective. More details can be found in <ref type="bibr" target="#b62">[63]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Three-view Canonical Correlation Analysis (CCA-3V)</head><p>The objective function of CCA-3V has three terms <ref type="bibr" target="#b63">[64]</ref>: Obviously, the latent correlation among three views or three modalities can be captured by optimising this function. Moreover, for the cross-modal matching, some high-level semantic information can be utilized as the third view <ref type="bibr" target="#b63">[64]</ref>. If we put the ground-truth labels into its third view, it becomes a supervised method. As shown in <ref type="figure" target="#fig_2">Fig. 3</ref>, comparing with the conventional CCA, CCA-3V constructs a semantic embedding subspace to improve the performance. CCA-3V aligns the corresponding multi-modal sample pairs by not only referring to the data distribution but also following the guidance of the high-level semantics.</p><formula xml:id="formula_10">min Wa,W b ,Wc X T a W a − X T b W b 2 F + X T a W a − X T c W c 2 F + X T b W b − X T c W c 2 F .<label>(9)</label></formula><p>Multi-modal samples belonging to the same semantic cluster are forced to be close to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Learning Coupled Feature Spaces for Cross-modal Matching (LCFS)</head><p>Many earlier studies have demonstrated two properties:</p><p>• l 21 -norm has good performances in feature selection <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b76">77]</ref>.</p><p>• The trace norm <ref type="bibr" target="#b77">[78,</ref><ref type="bibr" target="#b78">79,</ref><ref type="bibr" target="#b79">80,</ref><ref type="bibr" target="#b80">81]</ref> can model the correlation of the design matrix or prior knowledge as the low-rank solution.</p><p>Integrating the properties of the l 21 -norm and the trace norm, Wang et al. <ref type="bibr" target="#b39">[40]</ref> proposed a model of the following form min</p><formula xml:id="formula_11">Wa,W b 1 2 ( X T a W a − Y 2 F + X T b W b − Y 2 F ) +λ 1 ( W a 21 + W b 21 ) + λ 2 [X T a W a X T b W b ] * ,<label>(10)</label></formula><p>where W a and W b are the projection matrices for the coupled a modality and b modality, respectively. The first term is a coupled linear regression, which is used to learn two projection matrices for mapping multi-modal data into a common subspace defined by label information. The second term containing l 21 -norms conducts feature selection on two feature spaces X a and X b simultaneously. The trace norm can enhance the relevance of projected data with connections inside the subspace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7.">Joint Feature Selection and Subspace Learning for Cross-modal Retrieval (JFSSL)</head><p>JFSSL <ref type="bibr" target="#b42">[43]</ref> is an extension based on LCFS <ref type="bibr" target="#b39">[40]</ref>. The objective function is a generic minimization problem among M different modalities of data objects in the following form:</p><formula xml:id="formula_12">min W 1 ,··· ,W M M p=1 X T p W p − Y 2 F + λ 1 M p=1 W p 21 + λ 2 Ω(W 1 , · · · , W M ) ,<label>(11)</label></formula><p>where W p (p = 1, · · · , M ) denotes the projection matrix for the M -th modality. The roles of its first term and the second term are the same as those in LCFS. The third term is a multi-modal graph regularization reinforcing the intra-modality and inter-modality similarity. Similar to the empirical separability term of CDFE objective, this multi-modal graph regularization preserves the intra-modality compactness and the inter-modality dispersion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Results and Discussions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets</head><p>In this section, we will apply the aforementioned cross-modal subspace learning methods on two recently released fine-grained sketch-based image retrieval datasets <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref>. Each photo has a corresponding freehand sketch. That is, each sketch sample has a ground-truth photo counterpart as shown in <ref type="figure" target="#fig_3">Fig. 4</ref>.</p><p>The shoe dataset has 419 photo-sketch pairs, which can be categorized into three subclasses. All the sample pairs are single-labeled. The chair dataset contains 297 photo-sketch pairs. These chairs can be divided into six subclasses. The sketches are drawn by nonexperts using their fingers on the touch screens, therefore, these sketches are abstract enough to escape the photo modal space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Experimental Settings</head><p>These cross-modal subspace learning methods (i.e., CCA, PLS, BLM, GMLDA, GMMFA, CDFE, CCA-3V, LCFS, JFSSL) were applied to be performed on shoe dataset and chair dataset, for two SBIR retrieval tasks ((1) photos query sketches and (2) sketches query photos). The experimental results contain randomness due to the limitation by the numbers of the samples in the shoe dataset and chair dataset. To remove the effect of randomness, we repeated each model on each setting 50 times. On the shoe dataset, each evaluation we randomly chose 304 sample pairs as training set, and treated the remaining 115 sample pairs as test set. On the chair dataset, the ratio of training and test data sets was kept as 200 to 97.</p><p>In the training phase, we input photo and sketch features into these cross-modal subspace learning methods to learn a projection matrix for each modality. After model training, we used the projection matrices to map the photo and sketch testing samples into a common subspace. The cosine distance was adopt to measure the similarity between the projected photos and sketches. Given a photo (or sketch) query, the goal of each SBIR task is to find the nearest neighbors (NN) from the sketch (or photo) database.</p><p>In all the following experiments, we used Histogram of Oriented Gradient (HOG) features to describe the photos and sketches. In order to evaluate the performance of these methods with different scales, two kinds of metrics were adopted. The mean average precision (MAP) <ref type="bibr" target="#b23">[24]</ref> was applied to evaluate the performances on semi-fine-grained level. A retrieval was judged as correct by MAP as long as the retrieved sample and the query sample have the same subclass label. Another metric "acc.@K" <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b4">5]</ref> was used to carry out fine-grained evaluation on the instance-level, which is the percentage of the corresponding photos or sketches ranked in the top K results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Results on Shoe Dataset 3.3.1. Evaluation by MAP</head><p>The MAP scores of different cross-modal subspace learning methods on shoe dataset are reported in <ref type="table" target="#tab_0">Table 1</ref>. The minimum (min), maximum (max), mean value (mean), variance (var), and standard deviation (std) for each method are also presented.</p><p>Wang et al. <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b42">43]</ref> have illustrated that CCA, PLS, BLM, GMLDA, GMMFA, CDFE, and CCA-3V are incapable of feature selection. Hence we utilize Principal Component Analysis (PCA) to remove the redundancy in the input features for these seven kinds of methods. In order to validate the feature selection abilities of LCFS and JFSSL, their results without performing PCA on the input features are also reported in <ref type="table" target="#tab_0">Table 1</ref>. It can be observed that LCFS and JFSSL outperform the remaining methods for photo querying sketch and sketch querying photo on shoe dataset. This is because LCFS and JFSSL can simultaneously select discriminative and effective features from different modalities while learning the common subspace.</p><p>In terms of performance, GMLDA and GMMFA are close to LCFS and JFSSL. The performance gaps between GMLDA, GMMFA, and LCFS, JFSSL are not as obvious as those for image and text matching. This is due to the inherent data difference between sketch and text. GMLDA and GMMFA are superior to CDFE and CCA-3V. Among these cross-modal subspace learning methods, CCA performs the worst while its supervised enhanced version CCA-3V achieves good performance. PLM and BLM are a little better than CCA for photo querying sketch and sketch querying photo.</p><p>The overall trend of <ref type="table" target="#tab_0">Table 1</ref> can be summarized as supervised methods outperforming the unsupervised methods. This trend can also be explained by <ref type="figure" target="#fig_9">Fig. 9</ref>, which shows the differences between these methods. CCA, PLS, and BLM used only pair-wise information to build the common subspace, as shown in <ref type="figure" target="#fig_9">Fig. 9</ref>(c). <ref type="figure" target="#fig_9">Fig. 9(d)</ref> illustrates that GMLDA, GMMFA, and CCA-3V can take the advantage of class label information and pair-wise relationship to construct preferable inter-class separation in the common subspace. CDFE mainly attempts to keep the intra-class and inter-class structures in a subspace. LCFS and JFSSL devote to minimize the subcategory-based residuals. However, their graph embedding technologies can only improve intra-class compactness and inter-class dispersion. CDFE, LCFS, and JFSSL cannot thoroughly capture the pair-wise relationship. In contrast to <ref type="figure" target="#fig_9">Fig. 9(e)</ref>, the sample pairs of <ref type="figure" target="#fig_9">Fig. 9(d)</ref> have dashed lines to connect each other to visualize the pair-wise connections.</p><p>These phenomena are consistent with the results presented in <ref type="bibr" target="#b42">[43]</ref>. In <ref type="bibr" target="#b42">[43]</ref>, it was discussed and verified that JFSSL can utilize the multi-modal graph embedding constraint to obtain performance improvements basing on LCFS. However, for experiments on shoe dataset, their performances are almost the same. This is because the graph embedding constraint of JFSSL cannot fully play its role on this sketch dataset.</p><p>All the experimental results in <ref type="table" target="#tab_0">Table 1</ref> are also visualized as box-plots in <ref type="figure" target="#fig_4">Fig. 5</ref>. The box range of certain method shows the performance stability of corresponding method for the SBIR tasks. We can conclude that these cross-modal subspace learning methods have similar stabilities for SBIR on shoe dataset.</p><p>All the samples extracted from the same dataset follow the same underlying data distribution. Each method has its own unique principle and can be regarded as a system. Theoretically, the experimental results of a method will also follow a certain latent data distribution when it is repeated on the same dataset. Thus we can judge that the performances of these aforementioned methods for the SBIR tasks on shoe dataset are fundamentally different, only when their experimental result distributions do not belong to the same distribution.   According to <ref type="table" target="#tab_0">Table 1</ref> and <ref type="figure" target="#fig_4">Fig. 5</ref>, we get a preliminary conclusion that LCFS is the best among these methods on shoe dataset for photo querying sketch and sketch querying photo. To verify whether LCFS is fundamentally superior to other methods, we conducted students t-test between LCFS and other methods, as shown in <ref type="table" target="#tab_2">Table 3</ref>. The null hypothesis is that the two results have similar means with unknown variance. We can observe that LCFS and JFSSL have the same output MAP distribution for photo querying sketch task no matter whether their input features are preprocessed by PCA. However, their output MAP distributions for sketch querying photo task are different. In all other cases, LCFS is statistically different from the others. Based on the above observations, we conclude that the performance of LCFS for the subcategory-level SBIR tasks on shoe dataset is essentially different with the performances of CCA, PLS, BLM, GMLDA, GMMFA, CDFE, and CCA-3V.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Evaluation by "acc.@K"</head><p>The shoe dataset and the chair dataset are fine-grained SBIR datasets in which each sketch sample has a photo sample as its instance-level counterpart. Hence we can also evaluate the performances of these cross-modal subspace learning methods by counting the percentage of the corresponding photos or sketches ranked in the top K results. Please note that the parameters of all the methods are readjusted when we evaluated them by "acc.@K".</p><p>Similar as the previous chapter, PCA is conducted for all the methods. In addition, to verify the feature selection capabilities of LCFS and JFSSL, we also input features without PCA reprocessing for these two methods.</p><p>The Cumulative Match Characteristic (CMC) curves are plotted in <ref type="figure">Fig. 6</ref>. We can observe that in terms of relative distribution relationships and trends of the curves, <ref type="figure">Fig. 6(a)</ref> is consistent with <ref type="figure">Fig. 6(b)</ref>. And the performances of these cross-modal subspace learning methods are different from theirs on subcategory-level evaluation (MAP). CCA-3V achieves the highest instance-level accuracy for photo-sketch query and sketch-photo query on shoe dataset. The curves of CCA, GMMFA, PLS, and BLM are slightly lower than CCA-3V's. GMLDA obtains more satisfying experimental results than LCFS and JFSSL. LCFS and JFSSL are little better than CDFE. And LCFS and JFSSL still can obviously show their feature selection ability for the instance-level SBIR retrieval on shoe dataset. The experimental result of CDFE is the worst.</p><p>These supervised cross-modal subspace learning methods do not show a distinct advantage over unsupervised methods for the instance-level SBIR tasks on shoe dataset. We can  conclude that learning pair-wise information is more effective than learning subcategory-level relationship for instance-level SBIR. CCA, PLS, and BLM can achieve good results because they can learn the pair-wise relationships of multi-modal samples. CCA-3V, GMLDA, and GMMFA can utilize sample labels to learn some subcategory separation in the common subspace in the same time capturing the sample pair-based correlation crossing modalities. CCA-3V is more focused on modeling the association between the pairs of samples while GMMFA and GMLDA also learn some structured information in the common subspace. LCFS and JFSSL cannot obtain the desired results. For LCFS, its objective function engages in optimizing the subcategory-based residuals and feature selection for each modality. The trace norm constraint in Eq. (10) can enforce the relevance of projected sample data with connections, but its weighting coefficient λ 2 is often too small to learn enough sample pair-wise information. For JFSSL, its optimization is also mainly minimizing the subcategory-based residuals. Its graph embedding term in Eq. (11) only preserves the inter-   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Results on Chair Dataset 3.4.1. Evaluation by MAP</head><p>The MAP score comparison of different cross-modal subspace learning methods on chair dataset are reported in <ref type="table" target="#tab_1">Table 2</ref>. Each experiment on each setting is also repeated for 50 times. And as in the previous chapter, PCA is also utilized to remove the redundancy in the input features for CCA, PLS, BLM, GMLDA, GMMFA, CDFE, and CCA-3V. We can observe that the experimental results are analogous to those on shoe dataset. Comprehensively considering photo-sketch query and sketch-photo query tasks, LCFS and JFSSL performs best. The performances of GMLDA and GMMFA are very close to the performances of LCFS and JFSSL.</p><p>The corresponding box-plots for <ref type="table" target="#tab_1">Table 2</ref> are visualized in <ref type="figure">Fig. 7</ref>. We observe that the stabilities of these methods for subcategory-level SBIR on chair dataset do not have much difference. We also conducted the students t-test for the repeated 50 times experimental results between LCFS and other methods, as shown in <ref type="table" target="#tab_3">Table 4</ref>. We observe that GMLDA, GMMFA, LCFS, and JFSSL have the same output MAP distribution for photo querying sketch and sketch querying photo tasks.</p><p>As described above, shoe dataset contains three subcategories and chair dataset has six subcategories. In common sense, the three-class problem should be easier than the six-class one when we evaluate the experimental results by MAP. Thus the MAP score of the same method on shoe dataset should be significantly higher than it on chair dataset. However, comparing <ref type="table" target="#tab_0">Table 1</ref> and <ref type="table" target="#tab_1">Table 2</ref>, the MAP scores in <ref type="table" target="#tab_0">Table 1</ref> are not obviously higher than their counterpart values in <ref type="table" target="#tab_1">Table 2</ref>. Moreover, <ref type="figure" target="#fig_4">Fig. 5</ref> has many outliers (marked red) while <ref type="figure">Fig. 7</ref> shows almost no outliers. These phenomena can be interpreted as that these shoe sketches are not drew very well. Shoe dataset is mixed with too much noise due to that those shoe sketch samples were painted too rough.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Evaluation by "acc.@K"</head><p>We readjust the parameters for all the methods and compare their performances by counting the percentage of the corresponding photos or sketches ranked in the top K results. The CMC curves are plotted in <ref type="figure" target="#fig_8">Fig. 8</ref>. For photo querying sketch task and sketch querying photo task, CCA-3V outperforms other methods. And the curves of GMMFA, GMLDA, BLM, and PLS in <ref type="figure" target="#fig_8">Fig. 8(a)</ref> and <ref type="figure" target="#fig_8">Fig. 8(b)</ref> almost overlap together respectively. We can observe that in <ref type="figure" target="#fig_8">Fig. 8(a)</ref>, 'LCFS' curve is slightly lower than 'PCA+LCFS' curve and 'JFSSL' curve locates at a high distance above 'PCA+JFSSL' curve. In <ref type="figure" target="#fig_8">Fig. 8(b)</ref>, 'LCFS' curve is significantly lower than 'PCA+LCFS' curve and 'JFSSL' curve and 'PCA+JFSSL' curve are overlapped. This illustrates that the feature selection abilities of LCFS and JFSSL cannot work well for instance-level SBIR on chair dataset. In the objective functions of LCFS and JFSSL, the constraint terms for feature selection are optimized with the subcategory-based regression residuals simultaneously. Thus the effect of their feature selection is to reduce the subcategory-based errors rather than instance-level matching errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Feature Selection and Graph Embedding</head><p>In the experiments of this paper, the performances of LCFS and JFSSL are almost the same on shoe dataset and chair dataset. However, JFSSL is the improved version of LCFS and owns theoretical advantages. JFSSL has feature selection constraint and graph embedding constraint which are classical operational processes or technologies for crossmodal matching. Hence, it is worth exploring the synergy between the feature selection and graph embedding terms for SBIR tasks. In its objective function Eq. (11), λ 1 and λ 2 are the weighting parameters for feature selection and graph embedding terms, respectively. We tune λ 1 and λ 2 in the range of {0, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100} fixing the remaining parameters. This adjusting process is illustrated in <ref type="figure" target="#fig_0">Fig. 10</ref>. We can observe a smooth and symmetric correlation variation between λ 1 and λ 2 . This shows us that these two techniques can co-work harmoniously for SBIR. When λ 1 is fixed, MAP value slightly changes with the variations of λ 2 . MAP varies with λ 1 while λ 2 is set to a certain value. This proves that the performance of JFSSL is largely determined by its feature selection technology. The importances of the feature selection technology and the graph embedding technology are not equal in the optimization process of JFSSL for subcategory-level SBIR. This inspires us to further explore these two techniques in our future research for sketch.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Complexity Analysis</head><p>In this section, the computational complexity of each compared cross-modal subspace learning method is discussed briefly. The asymptotic time complexity of CCA is O(d 3 ) [82] </p><formula xml:id="formula_13">where d = max(d a , d b ).</formula><p>PLS is a fitting model embedding regression technique, for which its complexity is defined in terms of its Degrees of Freedom <ref type="bibr" target="#b82">[83]</ref>. GMA can be formulated as a standard generalized eigenvalue problem and solved by any eigenvalue solving technique <ref type="bibr" target="#b24">[25]</ref>. CDFE can be solved using an alternate optimization strategy including a main step that is a convex quadratic optimization program with linear constraint <ref type="bibr" target="#b62">[63]</ref>. The approximate kernel maps can be adopted to solving CCA-3V <ref type="bibr" target="#b63">[64]</ref> reducing the size of this problem to (d 1 +d 2 +d 3 ) × For rigorous comparison, the running time for learning the projection matrices is compared among these cross-modal subspace learning methods. Each methods on each setting are repeated 50 times. The average running time are reported in <ref type="table" target="#tab_4">Table 5</ref> which reveals that the feature selection processing is time-consuming. All the MATLAB codes are run on a 2.40GHz server with 64G RAM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Discussion</head><p>Our experimental results demonstrate that the cross-modal subspace learning methods designed for image and text can be applied in subcategory-level and instance-level SBIR tasks. The main advantage of cross-modal subspace learning for SBIR is its clear physical significance. Their performance rankings for subcategory-level SBIR tasks are almost consistent with those in cross-modal retrieval for image and text. For subcategory-level SBIR, the class label information is useful and supervised methods are usually superior to unsupervised methods. Feature selection and graph embedding technologies are also efficient to subcategory-level SBIR and they can work together well. Their performance rankings for instance-level SBIR tasks are not the same as those for subcategory-level retrieval. Learning pair-wise information is more effective than learning subcategory-level relationship for instance-level SBIR. Supervised learning has no significant advantages over unsupervised methods for instance-level SBIR task. On the shoe dataset and the chair dataset, LCFS outperforms other methods for subcategory-level SBIR and CCA-3V achieves the highest accuracy for instance-level SBIR. This leads us to conclude that subcategory-level information can also be beneficial to instance-level SBIR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion and Future work</head><p>We have demonstrated the feasibility of utilizing cross-modal subspace learning methods to tackle the domain-gap between sketches and photos. In the future, we may gain access to better solutions for SBIR by including the advantages of the cross-modal subspace learning techniques, e.g., pair-wise modeling, subcategory-based residual, joint feature selection, graph embedding. In particular, many researchers use deep Convolutional Neural Network (CNN) to conduct cross-modal matching <ref type="bibr" target="#b83">[84,</ref><ref type="bibr" target="#b84">85,</ref><ref type="bibr" target="#b85">86]</ref> or SBIR which is essentially to learn some feature subspaces to match multi-modal data. Moreover, the convolutional sparse coding technology can also learn subspace satisfying certain qualities <ref type="bibr" target="#b86">[87,</ref><ref type="bibr" target="#b87">88,</ref><ref type="bibr" target="#b88">89]</ref>, which illustrates the convolutional idea and subspace learning can be reasonably combined. Therefore, it is natural to also utilize cross-modal subspace learning concepts to improve CNN for SBIR, and potentially incorporating saliency information <ref type="bibr" target="#b89">[90,</ref><ref type="bibr" target="#b90">91]</ref> to improve partlevel examination in the same network.</p><p>If we assume that sketch sits between photo and text in terms of their expressive power, i.e., photo is the most expressive for it can capture a like-for-like depiction of the visual world, sketches are unlikely to do so since they are highly abstract yet still visual, text on the other hand can be vague and more importantly not in the visual domain anymore. This bears the question that if modeling sketch together with text and photo could be worthwhile to better bridge the gap between text and photo, e.g., for text-based image retrieval. The fact that CCA-3V achieved the best performance for the fine-grained case is a good indicator of the promise that such three-way modelling offers. However, currently available SBIR datasets cannot provide detailed and adequate semantic textual information. Hence new datasets that capture all three domains are required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we discussed and evaluated a series of state-of-the-art cross-modal subspace learning methods. We described each method and applied these approaches to two recently released fine-grained SBIR datasets. This paper provided detailed comparisons and analysis on experimental results and discussed future research opportunities for SBIR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgement</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of abstraction and diversity of sketches.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Diagram of CDFE empirical separability. The smaller solid and hollow figures represent the data from the different modalities. The smaller figures with the same shape and different colors represent different samples belonging to the same class. The bigger figures with different shapes indicate the corresponding domain-independent semantic labels. The short dashed straight lines visualize the pair-wise relationships. The short bold arrows link multi-modal sample pairs to their semantic labels. The short dashed straight lines visualize the pair-wise relationships. The bold black dashed circles describe the empirical separability. The intra-class compactness can be intuitively understood as compressing the two circles. The inter-class dispersion can be described as keeping them far from each other.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>(a) Subspace learned by CCA-2V (b) Subspace learned by CCA-3V The differences between CCA-2V and CCA-3V. (a) Traditional two-view CCA pair-wise maximizes the correlation. (b) Three-view CCA incorporates semantic classes as a third view. The smaller solid and hollow figures represent the data from the different modalities. The smaller figures with the same shape and different colors represent different samples belonging to the same class. The bigger figures with different shapes indicate the corresponding domain-independent semantic labels. The short dashed straight lines visualize the pair-wise relationships. The short bold arrows link multi-modal sample pairs to their semantic labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Samples of the shoe dataset and the chair dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Box-plots of MAP scores achieved by different cross-modal subspace learning methods on shoe dataset. The inputs of all the methods are preprocessed by PCA excepting methods marked with an asterisk. The top and bottom edges of the box are the 75th and 25th percentiles, respectively. The outliers are marked as red cross patterns individually.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>CMC curves for different cross-modal subspace learning methods on shoe dataset. Box-plots of MAP scores achieved by different cross-modal subspace learning methods on chair dataset. The inputs of all the methods are preprocessed by PCA excepting methods marked with an asterisk. The top and bottom edges of the box are the 75th and 25th percentiles, respectively. The outliers are marked as red cross patterns individually.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 8 :</head><label>8</label><figDesc>CMC curves for different cross-modal subspace learning methods on chair dataset. modality and intra-modality similarity. Hence, LCFS and JFSSL are not good at learning the instance-level or pair-wise relationship of sample data pairs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 9 :</head><label>9</label><figDesc>Demonstration and comparison of various cross-modal approaches. The smaller solid and hollow figures represent the data from the different modalities. The smaller figures with the same shape and different colors represents different samples belonging to the same class. The bigger figures with different shapes indicate the corresponding domain-independent semantic labels. The short dashed straight lines visualize the pair-wise relationships. The short bold arrows link multi-modal sample pairs to their semantic labels. The short dashed straight lines visualize the pair-wise relationships. The short bold arrows link multi-modal sample pairs to their semantic labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Sketch queries photo on chair dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 10 :</head><label>10</label><figDesc>JFSSL MAP variation with respect to λ 1 and λ 2 while its remaining parameters are fixed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>MAP scores achieved by different cross-modal subspace learning methods on shoe dataset.</figDesc><table><row><cell>Method</cell><cell>min</cell><cell cols="3">Photo queries sketch max mean var</cell><cell>std</cell><cell>min</cell><cell cols="3">Sketch queries photo max mean var</cell><cell>std</cell></row><row><cell>PCA+CCA</cell><cell>0.5442</cell><cell>0.6442</cell><cell>0.5836</cell><cell>0.0007</cell><cell>0.0264</cell><cell>0.5474</cell><cell>0.6415</cell><cell>0.5868</cell><cell>0.0006</cell><cell>0.0255</cell></row><row><cell>PCA+PLS</cell><cell>0.5712</cell><cell>0.6687</cell><cell>0.6169</cell><cell>0.0005</cell><cell>0.0218</cell><cell>0.5795</cell><cell>0.6649</cell><cell>0.6187</cell><cell>0.0004</cell><cell>0.0205</cell></row><row><cell>PCA+BLM</cell><cell>0.5805</cell><cell>0.6762</cell><cell>0.6272</cell><cell>0.0005</cell><cell>0.0217</cell><cell>0.5900</cell><cell>0.6755</cell><cell>0.6294</cell><cell>0.0004</cell><cell>0.0206</cell></row><row><cell>PCA+GMLDA</cell><cell>0.6943</cell><cell>0.8103</cell><cell>0.7542</cell><cell>0.0007</cell><cell>0.0267</cell><cell>0.7244</cell><cell>0.8213</cell><cell>0.7712</cell><cell>0.0006</cell><cell>0.0253</cell></row><row><cell>PCA+GMMFA</cell><cell>0.7000</cell><cell>0.8111</cell><cell>0.7577</cell><cell>0.0006</cell><cell>0.0248</cell><cell>0.7317</cell><cell>0.8199</cell><cell>0.7733</cell><cell>0.0005</cell><cell>0.0227</cell></row><row><cell>PCA+CDFE</cell><cell>0.6696</cell><cell>0.8024</cell><cell>0.7302</cell><cell>0.0008</cell><cell>0.0277</cell><cell>0.6755</cell><cell>0.8268</cell><cell>0.7559</cell><cell>0.0007</cell><cell>0.0271</cell></row><row><cell>PCA+CCA-3V</cell><cell>0.6339</cell><cell>0.7284</cell><cell>0.6837</cell><cell>0.0005</cell><cell>0.0219</cell><cell>0.6494</cell><cell>0.7261</cell><cell>0.6930</cell><cell>0.0004</cell><cell>0.0191</cell></row><row><cell>PCA+LCFS</cell><cell>0.7229</cell><cell>0.8365</cell><cell>0.7705</cell><cell>0.0007</cell><cell>0.0255</cell><cell>0.7079</cell><cell>0.8473</cell><cell>0.7745</cell><cell>0.0006</cell><cell>0.0244</cell></row><row><cell>LCFS</cell><cell>0.7236</cell><cell>0.8480</cell><cell>0.7798</cell><cell>0.0007</cell><cell>0.0258</cell><cell>0.7475</cell><cell>0.8518</cell><cell>0.8014</cell><cell>0.0006</cell><cell>0.0237</cell></row><row><cell>PCA+JFSSL</cell><cell>0.7211</cell><cell>0.8355</cell><cell>0.7700</cell><cell>0.0006</cell><cell>0.0254</cell><cell>0.7067</cell><cell>0.8457</cell><cell>0.7748</cell><cell>0.0006</cell><cell>0.0242</cell></row><row><cell>JFSSL</cell><cell>0.7080</cell><cell>0.8222</cell><cell>0.7619</cell><cell>0.0006</cell><cell>0.0249</cell><cell>0.7016</cell><cell>0.8253</cell><cell>0.7632</cell><cell>0.0006</cell><cell>0.0244</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>MAP scores achieved by different cross-modal subspace learning methods on chair dataset.</figDesc><table><row><cell>Method</cell><cell>min</cell><cell cols="3">Photo queries sketch max mean var</cell><cell>std</cell><cell>min</cell><cell cols="3">Sketch queries photo max mean var</cell><cell>std</cell></row><row><cell>PCA+CCA</cell><cell>0.4973</cell><cell>0.6407</cell><cell>0.5558</cell><cell>0.0012</cell><cell>0.0347</cell><cell>0.4998</cell><cell>0.6400</cell><cell>0.5588</cell><cell>0.0011</cell><cell>0.0334</cell></row><row><cell>PCA+PLS</cell><cell>0.5477</cell><cell>0.6557</cell><cell>0.5948</cell><cell>0.0008</cell><cell>0.0279</cell><cell>0.5557</cell><cell>0.6585</cell><cell>0.5998</cell><cell>0.0007</cell><cell>0.0273</cell></row><row><cell>PCA+BLM</cell><cell>0.5435</cell><cell>0.6549</cell><cell>0.5942</cell><cell>0.0007</cell><cell>0.0260</cell><cell>0.5541</cell><cell>0.6507</cell><cell>0.5987</cell><cell>0.0006</cell><cell>0.0241</cell></row><row><cell>PCA+GMLDA</cell><cell>0.6469</cell><cell>0.7798</cell><cell>0.7110</cell><cell>0.0010</cell><cell>0.0311</cell><cell>0.6426</cell><cell>0.7826</cell><cell>0.7077</cell><cell>0.0010</cell><cell>0.0321</cell></row><row><cell>PCA+GMMFA</cell><cell>0.6473</cell><cell>0.7852</cell><cell>0.7094</cell><cell>0.0011</cell><cell>0.0331</cell><cell>0.6341</cell><cell>0.7892</cell><cell>0.7053</cell><cell>0.0011</cell><cell>0.0336</cell></row><row><cell>PCA+CDFE</cell><cell>0.5638</cell><cell>0.7393</cell><cell>0.6585</cell><cell>0.0011</cell><cell>0.0328</cell><cell>0.5603</cell><cell>0.7400</cell><cell>0.6637</cell><cell>0.0009</cell><cell>0.0293</cell></row><row><cell>PCA+CCA-3V</cell><cell>0.5457</cell><cell>0.6692</cell><cell>0.6040</cell><cell>0.0007</cell><cell>0.0265</cell><cell>0.5585</cell><cell>0.6765</cell><cell>0.6127</cell><cell>0.0006</cell><cell>0.0254</cell></row><row><cell>PCA+LCFS</cell><cell>0.6491</cell><cell>0.7993</cell><cell>0.7139</cell><cell>0.0013</cell><cell>0.0357</cell><cell>0.6292</cell><cell>0.8043</cell><cell>0.7046</cell><cell>0.0013</cell><cell>0.0360</cell></row><row><cell>LCFS</cell><cell>0.6302</cell><cell>0.7804</cell><cell>0.7120</cell><cell>0.0012</cell><cell>0.0351</cell><cell>0.6227</cell><cell>0.7819</cell><cell>0.7049</cell><cell>0.0013</cell><cell>0.0363</cell></row><row><cell>PCA+JFSSL</cell><cell>0.6504</cell><cell>0.8004</cell><cell>0.7137</cell><cell>0.0013</cell><cell>0.0356</cell><cell>0.6284</cell><cell>0.8036</cell><cell>0.7043</cell><cell>0.0013</cell><cell>0.0359</cell></row><row><cell>JFSSL</cell><cell>0.6339</cell><cell>0.7949</cell><cell>0.7119</cell><cell>0.0013</cell><cell>0.0357</cell><cell>0.6283</cell><cell>0.7833</cell><cell>0.7045</cell><cell>0.0013</cell><cell>0.0365</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>P -value comparisons between LCFS (inputting feature without PCA preprocess) and other cross-modal subspace learning methods on shoe dataset. The significant level is 0.05.</figDesc><table><row><cell></cell><cell>PCA+ CCA</cell><cell>PCA+ PLS</cell><cell>PCA+ BLM</cell><cell>PCA+ GMLDA</cell><cell>PCA+ GMMFA</cell><cell>PCA+ CDFE</cell><cell>PCA+ CCA-3V</cell><cell>PCA+ LCFS</cell><cell>PCA+ JFSSL</cell><cell>JFSSL</cell></row><row><cell>Photo Query</cell><cell>5.1e-60</cell><cell>3.9e-56</cell><cell>1.2e-53</cell><cell>4.0e-06</cell><cell>3.2e-05</cell><cell>4.8e-15</cell><cell>1.7e-36</cell><cell>0.0728</cell><cell>0.0578</cell><cell>0.0006</cell></row><row><cell>Sketch Query</cell><cell>5.2e-66</cell><cell>9.4e-64</cell><cell>3.0e-61</cell><cell>1.5e-08</cell><cell>2.8e-08</cell><cell>2.4e-14</cell><cell>1.3e-44</cell><cell>2.0e-07</cell><cell>2.4e-07</cell><cell>3.5e-12</cell></row><row><cell>Average Value</cell><cell>2.5e-60</cell><cell>1.9e-56</cell><cell>6.1e-54</cell><cell>2.0e-06</cell><cell>1.6e-05</cell><cell>1.4e-14</cell><cell>8.9e-37</cell><cell>0.0364</cell><cell>0.0289</cell><cell>0.0003</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>P -value comparisons between LCFS (inputting feature without PCA preprocess) and other cross-modal subspace learning methods on chair dataset. The significant level is 0.05.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">PCA+ CCA</cell><cell>PCA+ PLS</cell><cell>PCA+ BLM</cell><cell>PCA+ GMLDA</cell><cell>PCA+ GMMFA</cell><cell>PCA+ CDFE</cell><cell>PCA+ CCA-3V</cell><cell>PCA+ LCFS</cell><cell>PCA+ JFSSL</cell><cell>JFSSL</cell></row><row><cell cols="3">Photo Query</cell><cell cols="2">2.7e-40</cell><cell>1.0e-33</cell><cell>9.9e-35</cell><cell>0.8698</cell><cell>0.6971</cell><cell>4.4e-12</cell><cell>1.0e-31</cell><cell>0.7965</cell><cell>0.8117</cell><cell>0.9825</cell></row><row><cell cols="3">Sketch Query</cell><cell cols="2">5.9e-38</cell><cell>8.8e-30</cell><cell>2.1e-31</cell><cell>0.6830</cell><cell>0.9536</cell><cell>1.0e-08</cell><cell>1.4e-26</cell><cell>0.9633</cell><cell>0.9309</cell><cell>0.9516</cell></row><row><cell cols="3">Average Value</cell><cell cols="2">2.9e-38</cell><cell>4.4e-30</cell><cell>1.0e-31</cell><cell>0.7764</cell><cell>0.8254</cell><cell>5.3e-09</cell><cell>7.2e-27</cell><cell>0.8799</cell><cell>0.8713</cell><cell>0.9670</cell></row><row><cell></cell><cell>0.85</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.75</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>MAP</cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.65</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.55</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>CCA</cell><cell>PLS</cell><cell>BLM</cell><cell cols="3">GMLDA GMMFA CDFE CCA-3V LCFS</cell><cell>LCFS* JFSSL JFSSL*</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Running time comparison in the unit of second.</figDesc><table><row><cell></cell><cell>PCA+ CCA</cell><cell>PCA+ PLS</cell><cell>PCA+ BLM</cell><cell>PCA+ GMLDA</cell><cell>PCA+ GMMFA</cell><cell>PCA+ CDFE</cell><cell>PCA+ CCA-3V</cell><cell>PCA+ LCFS</cell><cell>LCFS</cell><cell>PCA+ JFSSL</cell><cell>JFSSL</cell></row><row><cell>shoe</cell><cell>0.793</cell><cell>4.217</cell><cell>5.609</cell><cell>5.497</cell><cell>10.287</cell><cell>5.558</cell><cell>4.035</cell><cell>5.124</cell><cell>139.665</cell><cell>5.357</cell><cell>160.894</cell></row><row><cell>chair</cell><cell>0.691</cell><cell>7.189</cell><cell>5.979</cell><cell>7.454</cell><cell>7.416</cell><cell>5.200</cell><cell>2.494</cell><cell>2.785</cell><cell>122.104</cell><cell>2.938</cell><cell>137.910</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>d 1 +d 2 +d 3 ), whered i (i = 1, 2, 3) are the dimensionalities of the respective explicit mappings. The complexity of LCFS is O(d 3 + n 2.376 ) [40] where d = max(d a , d b ). The complexity of JFSSL can be denoted as O(dn 2 + d 2 ) [43] where d = max(d a , d b ).</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Loy</surname></persName>
		</author>
		<title level="m">Sketch me that shoe</title>
		<imprint>
			<publisher>CVPR</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An evaluation of descriptors for large-scale image retrieval from sketched feature lines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hildebrand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Boubekeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alexa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="482" to="498" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A performance evaluation of gradient field hog descriptor for sketch based image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Collomosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="790" to="806" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Cross-modal face matching: beyond viewed sketches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>ACCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Fine-grained sketch-based image retrieval: The role of part-aware attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>WACV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The sketchy database: learning to retrieve badly drawn bunnies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sangkloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Burnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Graph</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">119</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Intra-category sketch-based image retrieval by matching deformable part models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>BMVC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sketch-a-net: A deep neural network that beats humans</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Instance-level coupled subspace learning for fine-grained sketch-based image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV workshop</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Deep multi-task attribute-based ranking for fine-grained sketch-based image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ruan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>BMVC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Recognition of facial sketch styles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="page" from="1188" to="1197" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Free-hand sketch recognition by multi-kernel feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Local face sketch synthesis learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="1921" to="1930" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Photo-sketch synthesis and recognition based on subspace learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="840" to="852" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Free-hand sketch synthesis with deformable stroke models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<title level="m">Multi-view convolutional neural networks for 3d shape recognition</title>
		<imprint>
			<publisher>ICCV</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Making better use of edges via perceptual grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Mindfinder: interactive sketch-based image search on millions of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Edgel index for large-scale sketch-based image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Im2sketch: Sketch generation by unconflicted perceptual grouping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z.-H</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">165</biblScope>
			<biblScope unit="page" from="338" to="349" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Sketch-based 3d shape retrieval using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Data-driven visual similarity for cross-domain image matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">154</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
		<title level="m">Sketch-a-net that beats humans</title>
		<imprint>
			<publisher>BMVC</publisher>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rasiwasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Costa</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Coviello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
		<title level="m">A new approach to cross-modal multimedia retrieval</title>
		<imprint>
			<publisher>ACM MM</publisher>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Generalized multiview analysis: A discriminative latent space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Daume</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iii</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Co-regularized hashing for multimodal data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Multimodal similarity-preserving hashing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="824" to="830" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning unified binary codes for cross-modal retrieval via latent semantic hashing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shimada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Taniguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">213</biblScope>
			<biblScope unit="page" from="191" to="203" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semantic consistency hashing for cross-modal retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page" from="250" to="259" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Reading between the lines: Object localization using implicit cues from image tags</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1145" to="1158" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Nus-wide: A real-world web image database from national university of singapore</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CIVR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Modeling the shape of the scene: A holistic representation of the spatial envelope</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="145" to="175" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Learning multi-view neighborhood preserving projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Quadrianto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Heterogeneous metric learning with joint graph regularization for cross-media retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Image-text cross-modal retrieval via modality-specific feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICMR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A discriminative kernel-based approach to retrieval images from text queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1371" to="1384" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Wsabie: Scaling up to large vocabulary image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>IJCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Medical media analytics via ranking and big learning: A multi-modality image-based disease severity prediction study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">204</biblScope>
			<biblScope unit="page" from="125" to="134" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Canonical correlation analysis: An overview with application to learning methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Hardoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Szedmak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="2639" to="2664" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Learning coupled feature spaces for cross-modal matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">A two-step approach to cross-modal hashing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICMR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multi-manifold sparse graph embedding for multi-modal image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="page" from="501" to="510" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Part</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Joint feature selection and subspace learning for crossmodal retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="2010" to="2023" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Topic regression multi-modal latent dirichlet allocation for image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Putthividhy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Nagarajan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Learning cross-modality similarity for multinomial data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Learning similarity function between objects in heterogeneous spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note type="report_type">Microsoft Research Technique Report</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Cmml: a new metric learning approach for cross modal matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>ACCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Linear cross-modal hashing for efficient multimedia search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Hypergraph spectral hashing for image retrieval with heterogeneous social contexts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Discriminative learning and recognition of image set classes using canonical correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1005" to="1018" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">On the role of correlation and abstraction in cross-modal multimedia retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Costa</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Coviello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rasiwasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Lanckriet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="521" to="535" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Bypassing synthesis: PLS for face recognition with pose, low-resolution and sketch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Robust subspace segmentation by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Latent low-rank representation for subspace segmentation and feature extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Robust recovery of subspace structures by low-rank representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="171" to="184" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Complex non-rigid motion 3d reconstruction by union of subspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D L</forename><surname>Torre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">A convex formulation for semi-supervised multi-label feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">A convex formulation for spectral shrunk clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Compound rank-k projections for bilinear analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TNNLS</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1502" to="1513" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06215</idno>
		<title level="m">A comprehensive survey on cross-modal retrieval</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Cross-media retrieval: state-of-the-art and open issues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Multimedia Intelligence and Security</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="33" to="52" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Cross-modal subspace learning for sketch-based image retrieval: A comparative study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>IC-NIDC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Inter-modality face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A multi-view embedding space for modeling internet images, tags, and their semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Isard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="210" to="233" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jolliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Springer verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Multi-label cross-modal retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rasiwasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">V</forename><surname>Jawahar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Functional data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">O</forename><surname>Ramsay</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Wiley Online Library</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Overview and recent advances in partial least squares</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosipal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Krämer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Subspace, latent structure and feature selection</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="34" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Face recognition using partial least squares components</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PR</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1303" to="1306" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Efficient sparse kernel feature extraction based on partial least squares</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dhanjal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1347" to="1361" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Maximizing intra-individual correlations for face recognition across pose differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Gabor-based kernel partial-least-squares discrimination features for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Štruc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Pavešić</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Informatica</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="115" to="138" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">A robust and scalable approach to face identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>ECCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Continuum regression for cross-modal multimedia retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>ICIP</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Joint feature selection and subspace learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>IJCAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">21 regularized correntropy for robust feature selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-S</forename><surname>Zheng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Efficient and robust feature selection via joint 21 norms minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Ding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">The generalized trace-norm and its application to structure-frommotion problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Angst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pollefeys</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Low-rank matrix recovery via iteratively reweighted least squares minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fornasier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rauhut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ward</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Optimization</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1614" to="1640" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Trace lasso: a trace norm regularization for correlated designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Obozinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>NIPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Large-scale image classification with tracenorm regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Harchaoui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dudik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Cluster canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rasiwasia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mahadevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Aggarwal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>AISTATS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">The degrees of freedom of partial least squares regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nicole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page" from="697" to="705" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Mmss: Multi-modal sharable and specific feature learning for rgb-d object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Cham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Conditional convolutional neural network for modality-aware face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jayashree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Cnn vs. sift for image retrieval: Alternative or complementary?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ACM MM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">A multi-modal sparse coding classifier using dictionaries with different number of atoms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shafiee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Kamangar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Athitsos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>WACV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Brady</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sturim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kung</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.05212</idno>
		<title level="m">Multimodal sparse coding for event detection</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Convolutional sparse coding for trajectory reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="529" to="540" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Salient band selection for hyperspectral image classification via manifold ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="1279" to="1289" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">A universal framework for salient object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Callet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1783" to="1795" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
