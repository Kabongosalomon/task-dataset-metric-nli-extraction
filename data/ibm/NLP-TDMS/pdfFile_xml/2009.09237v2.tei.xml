<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AAA: Adaptive Aggregation of Arbitrary Online Trackers with Theoretical Performance Guarantee</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heon</forename><surname>Song</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Suehiro</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seiichi</forename><surname>Uchida</surname></persName>
						</author>
						<title level="a" type="main">AAA: Adaptive Aggregation of Arbitrary Online Trackers with Theoretical Performance Guarantee</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Online visual object tacking</term>
					<term>Adaptive expert aggregation</term>
					<term>Regret bound !</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For visual object tracking, it is difficult to realize an almighty online tracker due to the huge variations of target appearance depending on an image sequence. This paper proposes an online tracking method that adaptively aggregates arbitrary multiple online trackers. The performance of the proposed method is theoretically guaranteed to be comparable to that of the best tracker for any image sequence, although the best expert is unknown during tracking. The experimental study on the large variations of benchmark datasets and aggregated trackers demonstrates that the proposed method can achieve state-of-the-art performance. The code is available at https://github.com/songheony/AAA-journal.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>V ISUAL object tracking (VOT) is a research field of significant interest, and is widely applied in fields such as video surveillance <ref type="bibr" target="#b0">[1]</ref>, traffic flow monitoring <ref type="bibr" target="#b1">[2]</ref> and autonomous driving <ref type="bibr" target="#b2">[3]</ref>. Various tracking methods are proposed every year <ref type="bibr" target="#b3">[4]</ref>, but VOT still involves issues relating to areas such as target appearance change, target motion change, occlusion, camera motion, environment illumination change <ref type="bibr" target="#b4">[5]</ref>.</p><p>These issues are amplified in online tracking tasks, where the target location needs to be determined in a frame-byframe manner. Even when there is no target-like region in the current frame due to heavy appearance changes or occlusion of the target object, it is necessary to determine the target location before consideration of the next frame. Once an erroneous determination is made, it is difficult to recover and track the target object properly again. <ref type="figure" target="#fig_0">Fig. 1</ref> shows issues with online tracking. Twelve state-ofthe-art trackers are applied to six benchmark datasets, with monitoring based on the ratio of achievement for the best tracker in each dataset. The results indicate the difficulty of realizing an "almighty" tracker even for a single dataset. That is, no single tracker based on a specific criterion can handle extended variation of tracking tasks.</p><p>A promising strategy for more robust online tracking is to use multiple trackers <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b10">[11]</ref>. Aggregation of various trackers with different characteristics can be expected to produce complementary interaction. In particular, the potential to combine and/or select trackers based on their reliability will make the results more robust than with a single one.</p><p>• H. <ref type="bibr">Song</ref>   <ref type="bibr" target="#b28">[29]</ref> DaSiamRPN <ref type="bibr" target="#b29">[30]</ref> GradNet <ref type="bibr" target="#b35">[36]</ref> MemTrack <ref type="bibr" target="#b36">[37]</ref> SiamDW <ref type="bibr" target="#b37">[38]</ref> SiamFC <ref type="bibr" target="#b38">[39]</ref> SiamMCF <ref type="bibr" target="#b30">[31]</ref> SiamRPN <ref type="bibr" target="#b39">[40]</ref> SiamRPN++ <ref type="bibr" target="#b31">[32]</ref> SPM <ref type="bibr" target="#b32">[33]</ref> Staple <ref type="bibr" target="#b40">[41]</ref> THOR <ref type="bibr" target="#b33">[34]</ref>  However, estimating the reliability of each tracker is not straightforward, and reliability should be updated during the image sequence because the target condition (i.e., the appearance of the target and the background) will change frame-by-frame. <ref type="figure" target="#fig_1">Fig. 2</ref> shows two examples in which the most reliable tracker (i.e., the one that determines the target) for one frame becomes totally unreliable in a later frame.</p><p>In this paper, the authors propose a novel tracking method called Adaptive Aggregation of Arbitrary (AAA) trackers based on Adaptive Expert Aggregation (AEA). AEA has been studied in the field of theoretical machine learning <ref type="bibr" target="#b11">[12]</ref>  <ref type="bibr" target="#b0">1</ref> , and is a problem involving the aggregation of experts online. More specifically, individual experts give their own solutions to the given task at each time step, and these solutions are then aggregated using a particular algorithm. In AAA, each expert corresponds to an online tracker that <ref type="bibr" target="#b0">1</ref>. Adaptive expert aggregation is often called online prediction <ref type="bibr" target="#b11">[12]</ref> or online learning <ref type="bibr" target="#b12">[13]</ref> in theoretical machine learning research. In this paper, these terms are avoided in order to avoid confusion with their different meanings in computer vision and pattern recognition research. estimates the location of the target as its solution, as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. N different online trackers will produce N location predictions (i.e., N bounding boxes, often with different sizes) for each frame t. These predictions are then aggregated into a single solution (i.e., the target location) for each frame t using a weighted random selection algorithm.</p><p>The strength of AAA is that its performance is theoretically guaranteed in terms of regret due to the solid theoretical background of AEA. Regret is defined by the difference between the performance of the best expert 2 and the performance of the aggregation result. In VOT with N trackers, the best expert among them gives the best tracking accuracy over an image sequence. If regret is bounded, the accuracy difference between AAA and the best expert can also be bounded. It is practically meaningful to have a theoretical guarantee (i.e., a regret bound) because this means that the target location estimated using AAA at frame t(&lt; T ) is often not far away from the estimation of the best expert.</p><p>This strength of AAA is further emphasized as described here. First, this theoretical bound holds with arbitrary experts. Arbitrary trackers (especially state-of-the-art trackers) can therefore be used as experts, whereas the traditional method with multiple trackers often can employ only specific trackers. The bound holds even in an adversarial environment <ref type="bibr" target="#b12">[13]</ref> in which, for example, a tracker that was reliable until t can become totally unreliable at t + 1. This is not an unrealistic environment, as already observed in <ref type="figure" target="#fig_1">Fig. 2</ref>. Even for image sequences with such extreme situations, the proposed method is still guaranteed in terms of regret. Even though we can know the best expert for an image sequence may be known only at the last (T th) frame, it is still theoretically possible to bound the regret of AAA.</p><p>In AAA, the reliability (i.e., the weight) of each tracker 2. As noted below, the best expert is unknown during tracking -only at the very end of the image sequence, i.e., at t = T , can it be known which N is the best expert for the sequence. . At each frame, the target location is determined as the estimation of an expert which is stochastically selected according to the weight (i.e., reliability) of experts. At the anchor frame, expert weights are updated using delayed feedback.</p><p>is better evaluated by the proximity of tracker estimation to the true target location (i.e., the ground truth); in theoretical machine learning research, the ground truth for expert evaluation is called feedback. In VOT tasks, however, it is impossible to obtain exact feedback for each frame because the true target location is not given during online tracking. Accordingly, a practical strategy called delayed feedback is adopted in AAA. As shown in <ref type="figure" target="#fig_2">Fig. 3</ref>, experts receive feedback for anchor frames, where the target location is determined with high reliability. At the qth anchor frame u q , feedback for the ith tracker is calculated as the difference from a very reliable offline tracking result between the previous and current anchor frames u q−1 and u q . Since feedback at the frame τ ∈ [u q−1 + 1, u q ] is postponed until u q , this is known as delayed feedback. It should be noted that the performance of the proposed method is still guaranteed in terms of regret, even with the delayed feedback strategy. Additionally, although offline tracking results are not always exact and thus the delayed feedback is not calculated from the true target location, the theoretical guarantee of the proposed method still holds. These strong theoretical guarantees underpin the very promising performance of the proposed method in various practical situations, as experimentally proved in the later sections.</p><p>The main contributions of this paper are as follows:</p><p>• The authors propose an online tracking algorithm called AAA, by which arbitrary experts (online trackers) are aggregated with promising theoretical performance guarantees.</p><p>• To the best of the authors' knowledge, this is the first application of an AEA-based algorithm with delayed feedback in a computer vision task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>To demonstrate the experimental performance of the proposed method in an adversarial environment, various experiments were conducted with combinations of arbitrary experts on various datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>The experimental results show that the proposed method produced quasi-optimal or optimal performance among state-of-the-art trackers.</p><p>Numerous extensions are shown in this work from preliminary publication by the authors <ref type="bibr" target="#b13">[14]</ref>. A new important theoretical investigation (Proposition 1) is presented to clarify how AAA outperforms other trackers. The paper outlines more up-to-date experimental validations based on six recent benchmark datasets as well as state-of-the-art online trackers and ensemble tracking methods. The experimental results show that AAA can be used to achieve state-of-theart performance, and several new experimental setups are added. By way of example, different expert sets were used to allow observation of related effects on performance, with results revealing that AAA is very stable in relation to expert choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Adaptive Expert Aggregation (AEA)</head><p>The goal of AEA is to make predictions with a low regret by aggregating experts. The theories around AEA are discussed in Sec. 4.1 and 4.2, as AEA is not popular in the computer vision field. The Hedge algorithm <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref> is a popular algorithm in AEA for prediction of the weighted average of expert solutions. It can be easily applied to expert selection using weights for probability distribution, and achieves good regret bound for the expert selection tasks.</p><p>One application of the Hedge algorithm involves an adaptive disk spin-down problem. Helmbold et al. <ref type="bibr" target="#b16">[17]</ref> proposed a method to minimize the energy cost of the disk by aggregating experts estimating the timing of this spin-down.</p><p>Recently an algorithm called Follow the Regularized Leader (FTRL) has been applied for meta-learning <ref type="bibr" target="#b17">[18]</ref>. On the other hand, algorithms with delayed feedback have mainly been discussed from a theoretical perspective. Specifically, Quanrud et al. <ref type="bibr" target="#b18">[19]</ref> proposed various algorithms, including the Hedge algorithm with delayed feedback. However, neither practical application nor experimental validation have been completed in <ref type="bibr" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Ensemble tracking methods</head><p>Many of the various ensemble tracking methods previously proposed <ref type="bibr" target="#b19">[20]</ref>- <ref type="bibr" target="#b22">[23]</ref> have leveraged carefully designed synergy among trackers, making it difficult to aggregate arbitrary trackers. By way of example, Avidan et al. <ref type="bibr" target="#b5">[6]</ref> and Grabner et al. <ref type="bibr" target="#b6">[7]</ref> aggregated trackers complementarily trained using AdaBoost <ref type="bibr" target="#b15">[16]</ref>. Zhang et al. <ref type="bibr" target="#b7">[8]</ref> proposed a tracking method whose experts are trackers derived from the same (e.g., SVM-based) tracking algorithm. Experts differ in terms of updated frames used to deal with past appearances of the target object.</p><p>Some ensemble methods can be applied to aggregate arbitrary trackers. Wang et al. <ref type="bibr" target="#b8">[9]</ref> proposed a tracking method, called the Multi-Cue Correlation filter based Tracker (MCCT). Similar to the method proposed AAA, any tracker that outputs a bounding box as its prediction can be employed as an expert. However, the practical success of the MCCT is supported by the strong assumption that bounding boxes given by experts are close together. Accordingly, MCCT used specific experts that satisfy assumptions based on inter-expert sharing of ROI. In aggregation of arbitrary trackers, this assumption may not be met because some trackers may predict a completely different location to others as described in the Appendix A. The authors' experimental results show that deviation from the assumption degrades MCCT performance.</p><p>Qi et al. <ref type="bibr" target="#b10">[11]</ref> proposed an AEA-based tracking method called the Hedged Deep Tracker (HDT*) based on the Hedge algorithm with multiple experts. To the best of the authors' knowledge, this is the only trial to have applied AEA-based aggregation for VOT. As detailed in the Appendix B, HDT* uses feedback based on expert predictions (rather than other reliable resources such as offline trackers). HDT* also assumes that feedback is given for every frame regardless of reliability. Accordingly, the feedback may be relatively unreliable when a majority of experts do not perform well, and such unreliability degrades overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ADAPTIVE AGGREGATION OF ARBITRARY TRACKERS (AAA)</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>As shown in <ref type="figure" target="#fig_2">Fig. 3</ref>, the proposed method, AAA, assumes N arbitrary experts (online trackers). At each frame t, the method involves stochastic selection of an expert based on weights w t 1 , . . . , w t N ∈ R as probabilistic distribution, where N i=1 w t i = 1 and w t i ≥ 0 for any i. That is, an expert with a greater weight has a higher chance of being selected. The target location p t estimated by the selected expert is then used as the output of AAA at t. Through this simple process, the proposed method enables performance similar to that of the best expert over an image sequence in any situation, even for extreme conditions.</p><p>From an algorithmic viewpoint, the main concern is how and when to update the weights w t 1 , . . . , w t N . Since w t i indicates the reliability of the ith tracker, it should be updated using reliable information. Ideally, if the true target location is present at t, a greater weight acn be assigned for a tracker that estimates a similar location. However, determination of the true target location is practically impossible.</p><p>Accordingly, a reliable offline tracker between two anchor frames was used to update weights. The frame t is defined as the qth anchor frame u q if the target object is found at a certain location y t by an object identifier (or tracker) with very high confidence. Connecting two reliable target locations y uq−1 and y uq using an accurate offline tracker produces the pseudo-ground-truth sequence y τ , τ ∈ [u q−1 + 1, u q ]. If the target location estimated via the ith expert is similar to the pseudo-ground-truth during [u q−1 + 1, u q ], the weight of the expert will be increased at the anchor frame u q . Globally-optimal offline tracking is used based on Dijkstra's algorithm, as detailed in Appendix C.</p><p>The pseudo-ground-truth is referred to as feedback based on the terminology of theoretical AEA research because it is used for posterior evaluation in relation to individual experts. Specifically in AAA, it is referred to as delayed feedback because feedback during τ ∈ [u q−1 +1, u q ] is given in a later frame u q , as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. It should be emphasized again that the performance of the proposed Algorithm 1 The proposed method: AAA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Inputs:</head><p>The initial target location f 0 . N arbitrary experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outputs:</head><p>Predicted target location p 1 , . . . , p t , . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Initialize:</head><p>The Weight of the experts</p><formula xml:id="formula_0">w 1 i ← 1/N, ∀i. The initial anchor frame u 1 ← 1 and q ← 1. The initial learning rate η ← √ ln N . for t = 2, . . . do Get estimation f t 1 , .</formula><p>. . , f t N from the experts. if t is determined to be an anchor frame then Increase the number of anchor frame q ← q + 1. Store t as the last anchor frame u q ← t.</p><p>Obtain delayed feedback y uq−1+1 , . . . , y uq . Calculate each cumulative loss by using <ref type="bibr" target="#b0">(1)</ref>. Update η using doubling trick. Update weights by using <ref type="formula" target="#formula_4">(3)</ref>.</p><formula xml:id="formula_1">Set the target location p t ← y t . else Do not update weights w t i ← w t−1 i , ∀i Select the target location p t from f t 1 , . . . , f t N stochastically using w t 1 , . . . , w t N . end if end for</formula><p>method is still guaranteed even with the use of the pseudoground-truth as delayed feedback, as detailed in Sec. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Updating of expert weights</head><p>Expert weights are updated at each anchor frame using the delayed feedback given at the frame as shown in <ref type="figure" target="#fig_2">Fig. 3</ref>. At the anchor frame t, the loss L i of the expert i is first calculated using the delayed feedback y τ , τ ∈ [u q−1 + 1, u q ] via:</p><formula xml:id="formula_2">L i = uq τ =uq−1+1 (f τ i , y τ ),<label>(1)</label></formula><p>where</p><formula xml:id="formula_3">(f τ i , y τ ) = 1 − P(f τ i , y τ ),<label>(2)</label></formula><p>and f τ i is the ith expert's estimation at frame τ . Locations such as f τ i and y τ are represented as a bounding box, and the function P provides evaluation of proximity between two bounding boxes. Based on this loss, the weight of the expert i is updated at t = u q via the following equation and used from t + 1:</p><formula xml:id="formula_4">w t+1 i = w t i exp (−ηL i ) N j=1 w t j exp (−ηL j ) .<label>(3)</label></formula><p>In <ref type="formula" target="#formula_4">(3)</ref>, η is the learning rate, and its value is carefully and automatically controlled for performance guarantee as detailed in Sec. 4.3.</p><p>For clarity, AAA is briefly summarized in Algorithm 1. The first frame is treated as the first anchor frame u 1 . The weights are initialized as w 1 i = 1/N, ∀i. If the current frame t is not an anchor frame, the weight is not updated, i.e.,</p><formula xml:id="formula_5">w t+1 i = w t i .</formula><p>To evaluate the proximity P(f τ i , y τ ) of two bounding boxes specified by f τ i and y τ , IoU <ref type="bibr" target="#b23">[24]</ref> is a possible choice. However, if the bounding boxes do not overlap, the IoU score is zero regardless of distance. Accordingly, GIoU <ref type="bibr" target="#b24">[25]</ref> is employed to evaluate both overlap and distance. Any arbitrary function can be used as the loss function to give a theoretical performance guarantee if values are limited in the interval [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Anchor frame determination</head><p>For accurate delayed feedback close to the exact target location, it is necessary to carefully determine anchor frames because these give the boundary conditions of the offline tracker for such feedback. An anchor frame is determined when the target location is determined with very high confidence. There are several approaches to highly-confident determination. For example, if the target is a specific pedestrian or athlete, the face or jersey number can be used for determination with the help of person re-identification or scene text OCR techniques.</p><p>For application of AAA to various datasets with various targets, a more general approach can be used for highlyconfident target determination with reliance on the target template image. In VOT tasks, the template is generally given as the bounding box at the initial frame. If one or more N experts determine a bounding box whose normalized cosine similarity 3 to the template is greater than the threshold θ, the current frame t is determined as an anchor frame. The bounding box of the expert with the maximum similarity is determined as y t . The threshold θ is the only hyper-parameter of the proposed method. As discussed in Sec. 5.1.4, an appropriate value of θ is experimentally determined for experts.</p><p>The cosine similarity between the template and the bounding box determined is evaluated using the feature vectors given by ResNet <ref type="bibr" target="#b25">[26]</ref>. Specifically, like <ref type="bibr" target="#b26">[27]</ref>, the output of the average pooling layer of ResNet is used as a feature vector. Here, ResNet pre-trained with ImageNet <ref type="bibr" target="#b27">[28]</ref> is used with no extra training. Both the template and the bounding box are converted to feature vectors using ResNet, and their normalized cosine similarity is calculated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">THEORETICAL GUARANTEE OF AAA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">General preliminaries of AEA</head><p>Before an explanation of the theoretical guarantee of AAA, there is a need for a brief introduction to the general theories surrounding AEA, which is generally considered as a repeated game between a player and an adversarial environment. At each round t = 1, . . . , T , the player receives N advice f t 1 , . . . , f t N from N experts. The player makes a prediction p t based on this advice, and the environment gives its feedback y t to p t . The player suffers the loss (p t , y t ).</p><p>Here, AAA is based on AEA and thus has clear correspondence with the above terminologies. Specifically, the round, player and experts correspond to the frame t, AAA (i.e., the proposed tracker) and the online trackers to be 3. "Normalized" cosine similarity ∈ [0, 1] is simply given by (1 + cosine similarity)/2. aggregated, respectively. The prediction p t , advice f t i , and feedback y t correspond to the target location determined from AAA, the target locations estimated from the N online trackers, and the offline tracking result, respectively.</p><p>The goal of AEA is to minimize the regret R T :</p><formula xml:id="formula_6">R T = E T t=1 (p t , y t ) − min i=1,...,N T t=1 (f t i , y t ),<label>(4)</label></formula><p>where the first and second terms represent the cumulative loss of the player and the best expert, respectively. The best expert is the one with the minimum cumulative loss among N experts. Intuitively, lower regret means the performance of the player is close to that of the best expert.</p><p>In AEA with delayed feedback, the player suffers a loss only at Q(≤ T ) rounds u 1 , . . . , u q , . . . , u Q rather than at each t. At the round u q , the environment gives feedback y τ , τ ∈ [u q−1 + 1, u q ] for the predictions of the player between u q−1 and u q . In Sec. 3.1, it can be seen that u q corresponds to the qth anchor frame in AAA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Regret bound of AEA with delayed feedback</head><p>The regret bound of AEA with delayed feedback is given as follows:</p><p>Theorem 1 (From Theorem A.5 of <ref type="bibr" target="#b18">[19]</ref>). Assume an AEA algorithm with the weight-updating strategy of (3) and delayed feedback. Also assume the loss function ∈ [0, 1] and the learning rate η ∝ ln N/(T + D). The regret of the AEA algorithm after T frames is then bounded as follows:</p><formula xml:id="formula_7">R T = O (T + D) ln N ,<label>(5)</label></formula><p>where D is the total delay.</p><p>The total delay D is defined as</p><formula xml:id="formula_8">D = Q q=2 uq−uq−1 τ =1 τ = Q q=2 (u q − u q−1 ) (u q − u q−1 + 1) /2.</formula><p>Thus, D takes its minimum value T when feedback is given at every frame and its maximum value (T 2 + T )/2 when no feedback is given until t = T after t = 1 (i.e., u 1 = 1, u 2 = T , and Q = 2). Appendix D details the derivation of Theorem 1 from Theorem A.5 of <ref type="bibr" target="#b18">[19]</ref>.</p><p>Theorem 1 states that regret R T increases according to D. In the worst case, when D takes its maximum value (T 2 + T )/2, the regret bound is linearly proportional to T . This means that the performance difference between AEA and the best expert will increase drastically with T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Regret bound of AAA</head><p>Based on Theorem 1, the regret bound of AAA can be derived. This can be lower than <ref type="bibr" target="#b4">(5)</ref> in general because delayed feedback will be far more frequent than the worst case in real-world tracking. Denoting r as the anchor frame ratio, which is the probability that a frame is determined as an anchor frame, the regret bound outlined below is derived.</p><p>Theorem 2. Assume the AEA algorithm of Theorem 1 can have delayed feedback with the anchor ratio r ∈ (0, 1] at each frame. The expectation of the regret is then upper-bounded as follows:</p><formula xml:id="formula_9">E r [R T ] = O 1 r T ln N .<label>(6)</label></formula><p>Proof. The expected delay length E r [u q −u q−1 ] is 1/r and the expected number of anchor frames is rT . Thus, the expectation of the total delay is E r [D] = Q q=2 (1/r) (1/r + 1) /2 = rT (1/r) (1/r + 1) /2 = O(T /r). Finally, consideration for the expectation of the regret of R T with r produces the above bound.</p><p>In contrast to Theorem 1, when the regret increases linearly with T in the worst case, Theorem 2 guarantees that the regret of AAA increases in O( √ T ). This indicates that the regret of AAA is bounded more tightly, and stable performance of AAA can therefore be expected even for a longer sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Impact of the regret bound for VOT</head><p>Theorem 2 guarantees that the performance difference between the proposed AAA and the best expert is upperbounded by <ref type="bibr" target="#b5">(6)</ref>. Intuitively speaking, this bound is significant in a number of ways. First, it means that the performance of AAA is not far from that of the best expert. Second, this guarantee holds for arbitrary experts, arbitrarily delayed feedback (i.e., arbitrary offline trackers and the determination rule for anchor frames) and arbitrary image sequences. Third, and most interestingly, AAA may demonstrate performance similar to that of the best expert even though the best expert and its performance is unknown until T , i.e., the end of the image sequence. Expert selection is made at each frame t in a strictly online condition, and it remains unknown which expert will be the best; nevertheless, these theorems guarantee that the performance of AAA will not be far from that of the best expert.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Effect of the anchor frame ratio r</head><p>One might expect that it is better to set r = 1 (to make all frames the anchor frames), since the regret bound based on (6) is minimum when r = 1. However, it must be remembered that the anchor frame should be set to give reliable delayed feedback with a reliable offline tracking result. All the above theories rely on the loss function , which treats y t given by the offline tracking result as a pseudo-groundtruth. Accordingly, using unreliable feedback eventually produces a choice far from the true ground-truth as the best expert. Finally, AAA tries to follow this false best expert to keep the regret bound. Consequently, for better AAA performance, anchor frames must be carefully determined with higher settings of θ, even though this makes r smaller. This is experimentally demonstrated in Appendix E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">Effect of the number of experts N</head><p>The theorems remove the need for concern over the choice of experts, because the regret bound is simply a logarithmic representation of the number of experts N . In other words, even if many experts are employed, the regret bound will increase only slightly. This increase will not be problematic to practical tracking performance. As regret represents the difference from the best expert, using more experts with different characteristics will increases the chances to have the best expert with better performance. Since the difference is bounded by <ref type="formula" target="#formula_9">(6)</ref>, the presence of a better best expert will enhance AAA performance.  · The best tracker is indicated with red bold and the second is indicated with blue italic. · AUC: average area-under-curve score, DP: average distance precision. Bigger AUC and DP mean better performance. · HDT is only evaluated by DP for a fair comparison. See Appendix B for the detailed reason.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.4">Learning rate η</head><p>Theorem 2, as well as Theorem 1, assumes that the learning rate η should be proportional to ln N/(T + D). However, T and D are usually unknown until the end of the sequence in online tracking tasks. Fortunately, the doubling trick <ref type="bibr" target="#b18">[19]</ref> allows adaptive control of η with the regret guarantee in the same order in Theorem 2. Roughly speaking, this trick uses a tentative value Z instead of T + D. Thus, the parameter η is initially set as η = ln N/Z. Then, if the actual value of T + D reaches Z at the current frame t, 4 the value of Z is doubled and η is updated using the new value of Z.</p><p>The proof that the doubling trick still guarantees the regret bound of Theorem 1 is detailed in <ref type="bibr" target="#b34">[35]</ref> and <ref type="bibr" target="#b18">[19]</ref> and the proof for Theorem 2 is trivial from this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental setup</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Experts and comparative methods</head><p>In relation to experts and comparative methods, twelve state-of-the-art online trackers were employed (ATOM <ref type="bibr" target="#b28">[29]</ref>, DaSiamRPN <ref type="bibr" target="#b29">[30]</ref>, GradNet <ref type="bibr" target="#b35">[36]</ref>, MemTrack <ref type="bibr" target="#b36">[37]</ref>, SiamDW <ref type="bibr" target="#b37">[38]</ref>, SiamFC <ref type="bibr" target="#b38">[39]</ref>, SiamMCF <ref type="bibr" target="#b30">[31]</ref>, SiamRPN <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b3">4</ref>. Specifically, this condition means that t + Dt is the same as Z, where Dt is the total delay until t defined as Dt =</p><formula xml:id="formula_10">t−uq τ =1 τ + q q=2 uq −u q−1 τ =1</formula><p>τ .q is the latest anchor frame by t.</p><p>SiamRPN++ <ref type="bibr" target="#b31">[32]</ref>, SPM <ref type="bibr" target="#b32">[33]</ref>, Staple <ref type="bibr" target="#b40">[41]</ref>, and THOR <ref type="bibr" target="#b33">[34]</ref>). For fair comparison and better performance, parameters optimized by the authors of the individual experts were applied.</p><p>In addition to these online trackers, AAA was also compared with the MCCT <ref type="bibr" target="#b8">[9]</ref> and HDT* <ref type="bibr" target="#b10">[11]</ref>, aggregationbased tracking methods as detailed in Appendix A and Appendix B, respectively. Other naive aggregation-based methods referred to as "Random" and "Max" were also examined. "Random" randomly selects an expert estimation for each frame, while "Max" selects the estimation most similar to the template image for each frame. "Max" is the same as AAA when each frame is an anchor frame and thus feedback is given for each frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2">Benchmark datasets</head><p>The proposed AAA and the comparative methods were evaluated with OTB2015 <ref type="bibr" target="#b41">[42]</ref>, TColor128 <ref type="bibr" target="#b42">[43]</ref>, UAV123 <ref type="bibr" target="#b43">[44]</ref>, NFS <ref type="bibr" target="#b44">[45]</ref>, and LaSOT <ref type="bibr" target="#b45">[46]</ref>. OTB2015 is a popular benchmark dataset for evaluating online trackers, consisting of 100 image sequences including gray-scale image sequences. TColor128 contains 128 color image sequences, and is specifically designed for evaluation of color-enhanced trackers. VOT2018 is a dataset produced for competition, and consists of 60 image sequences. UAV123 consists of 123 image sequences taken from unmanned aerial vehicles. NFS consists of 100 image sequences captured with a higher frame rate of 240fps. LaSOT is the largest benchmark dataset among the above, and is divied into "training" and "testing" subsets.</p><p>Here, image sequences from the testing subset containing 280 image sequences were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Performance monitoring</head><p>For performance monitoring, the area-under-the-curve (AUC) score and average distance precision (DP) were referenced as standard metrics <ref type="bibr" target="#b23">[24]</ref>. AUC (referred to as AO in VOT2018) is derived using "success plot" for the performance curve. This plot is based on evaluation of the ratio of frames where the IoU with the ground truth is larger than the threshold value (∈ [0, 1]). <ref type="figure" target="#fig_3">Fig. 4</ref> shows examples of the success plot. DP is derived from "precision plot" based on evaluation of the ratio of frames where the geometric distance between the location determined and the ground-truth location is less than the threshold value (∈ [0, 50] pixels). <ref type="figure" target="#fig_3">Fig. 4</ref> also shows examples of the precision plot. DP is eventually determined as the value of the precision plot at the threshold 20 based on <ref type="bibr" target="#b23">[24]</ref>.</p><p>In addition to AUC and DP, the performance rank of individual trackers for each image sequence was used. Since there are N experts and AAA, the rank varies from 1 (the best) to N + 1 (the worst). If AAA successfully follows the best expert for arbitrary image sequences, it will be frequently ranked second.</p><p>Performance was evaluated under the "strictly-online" conditions described here. First, no tracker has any prior information on the total frame length T . Second, the noreset evaluation protocol was used; in some experimental evaluations (e.g., VOT2018) a reset-based evaluation protocol is employed, where failed trackers (with zero IoU with ground-truth) can restart from the correct location a fixed number of frames later. In no-reset evaluation, however, the failed tracker continues tracking rather than being reset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.4">Hyper-parameter search</head><p>The threshold θ, which is just one hyper-parameter in the proposed method, is optimized using the GOT10K <ref type="bibr" target="#b46">[47]</ref>, Generic Object Tracking Benchmark. Specifically, the AUC score of AAA with the expert group is first evaluated by changing θ from 0.6 to 0.9 at 0.01 intervals with GOT10K. Then, the θ for the highest AUC score is chosen for evaluation of the other datasets. Appendix E details the procedure. It should be noted that GOT10K was not used in the performance evaluation experiments described below or in training of individual experts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Quantitative evaluation using three expert groups with different performance</head><p>Comprehensive experiments were conducted to determine whether the proposed method can be applied to properly aggregate various experts and achieve near-best performance (i.e., the performance similar to that of the best expert) without attentive expert selection. This section outlines quantitative evaluation conducted using three expert groups (referred to as High, Low, and Mix) with different performance characteristics as follows:</p><p>• High group consists of six higher-performance experts (ATOM, DaSiamRPN, SiamMCF, SiamRPN++, SPM, and THOR).</p><p>• Low group consists of six lower-performance experts (GradNet, MemTrack, SiamDW, SiamFC, SiamRPN, and Staple), and was examined to determine whether the proposed method can be applied to follow the best experts among lower-performance experts.</p><p>• Mix group consists of the three higher-performance experts (ATOM, SiamRPN++, and SPM) and the three lower-performance experts (MemTrack, SiamFC, and Staple). Observation of the proposed method with this is importance in verifying that the method supports automatic selection of higherperformance experts while helping to eliminate erroneous estimations from lower-performance experts. <ref type="table" target="#tab_1">Table 1</ref> shows the average performance of the six experts in the High group and their aggregations. As noted, AUC and DP are derived from the success plot and the precision  plot as shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. AAA outperformed state-of-theart trackers in most datasets and demonstrated the best performance for all datasets except for UAV123, and even then was only marginally second best. <ref type="figure" target="#fig_4">Fig. 5 (a)</ref> shows an image sequence-level rank histogram for six trackers in the High group and AAA. The histogram is normalized based on the number of image sequences in each dataset. As seen in <ref type="figure" target="#fig_0">Fig. 1</ref>, no tracker consistently achieved the best performance, and the best expert drastically changed over image sequences even within the same dataset. As also shown in <ref type="figure" target="#fig_4">Fig. 5 (a)</ref>, even a very good tracker (such as SiamRPN++) is sometimes worst-ranked (i.e., 7th). In contrast, AAA was the second-or third-best tracker for most image sequences, although it was not often the best. More importantly, it was rarely ranked lowly. These experimental highlight the importance of a regret bound guaranteeing a minimal difference between performance of the proposed method and the best expert. <ref type="table" target="#tab_1">Table 1</ref> also shows that the performance of the other aggregation-based trackers (HDT*, MCCT, Random, and Max) was lower than that of AAA despite their aggregation of the same experts. As detailed in Appendix B and Appendix A, HDT* and MCCT did not show ideal performance in the study's stringent experimental setup with aggregation of arbitrary experts. Max, which relies on the feedback given for each frame, sometimes demonstrated the worst performance. <ref type="table" target="#tab_2">Table 2</ref> and <ref type="figure" target="#fig_4">Fig. 5 (b)</ref> show quantitative evaluation of the trackers in the Low group and their aggregations. AAA again demonstrated at least the second-best average performance for all datasets even with aggregation of experts in the Low group. This means that AAA automatically finds and follows the best among lower-performance experts as expected. It should be emphasized that the other aggregation strategies suffered from lower expert performance.</p><p>As shown in <ref type="table" target="#tab_3">Table 3</ref> and <ref type="figure" target="#fig_4">Fig. 5 (c)</ref>, AAA was at least the third-best of all trackers with experts in the Mix group, and there were significant performance gaps between the three higher-and lower-performance experts in this group. Here, a selection of lower-performance experts drastically degrades aggregation performance. AAA, however, automatically and successfully selected higher-performance experts and was the second-or third-best tracker for most image sequences. This indicates that AAA is not disturbed even when several experts do not perform well, making it a very practical aggregation-based tracker.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Quantitative evaluation with experts generated from a single tracking method</head><p>As explained in 4.3.3, Theorem 2 guarantees that the use of more experts does not result in any significant degradation of AAA performance. One strategy here is to employ a wide variety of tracking methods based on different algorithms as per the experiments detailed in the previous section. However, due to the difficulty of arranging such a variety, it is preferable to employ a single tracking method and generate various versions thereof by changing its internal parameters, like <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b37">[38]</ref>.</p><p>For evaluation of AAA with the second strategy, different versions of the lower-performance SiamDW (collectively referred to as the SiamDW group) were generated by changing the related parameter sets (e.g., backbone networks, the weight of the network, and hyper-parameters) based on the suggestions of the original paper <ref type="bibr" target="#b37">[38]</ref>. The higher-performance tracker SiamRPN++ was also adapted to generate the SiamRPN++ group. · Depending on the backbone network used and what dataset it is designed for, the names of experts are written as follows: "base algorithm"/"backbone network"/"target benchmark". The authors of SiamDW and SiamRPN++ propose different hyperparameters according to the target benchmark even for the same backbone network. · See the notes below <ref type="table" target="#tab_1">Table 1</ref> for the other details. · "VOTLT" is a dataset consisting of relatively long-term image sequences rather than VOT <ref type="bibr" target="#b4">[5]</ref>. · See the notes below <ref type="table" target="#tab_1">Table 1</ref> for the other details. <ref type="table" target="#tab_4">Tables 4 and 5</ref> show the results from the SiamDW and SiamRPN++ groups. Even with experts generated from a single tracking method, AAA outperformed the individual experts in these groups, and the negative effect of increasing the number of experts N on the regret bound was therefore not significant. These results are promising for practical application. Rather than focusing on the internal parameters of individual experts, it is simply necessary to have more experts generated with different internal parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Tracking examples</head><p>In <ref type="figure" target="#fig_5">Fig. 6, two</ref> tracking examples from the High group are shown to demonstrate how AAA tries to track the best expert and achieve similar performance by updating the weights w t i adaptively. Specifically, it shows change in the overlap errors (IOU) and the weights of experts and AAA for "Girl2" in OTB2015 and "Yo-yos ce1" in TColor128.</p><p>For "Girl2", all experts successfully tracked the target object at (a). However, because of the occlusion between (b) and (c), the experts failed to track at (c) and only ATOM properly tracked the target object at (d). AAA also tracked the object well at (d), with an anchor frame being determined after the target object reappeared and high weight given to ATOM via appropriate feedback. At (e), (f) and (g), other experts were also able to properly track the target object, and AAA still achieved high performance.</p><p>For "Yo-yos ce1", tracker accuracy frequently varied throughout the sequence. For example, SiamMCF was ac-curate and ATOM was inaccurate at (l), but this situation was reversed at (o). Even here, AAA tried to follow the better tracker by changing the weights of the experts at the anchor frames, resulting in lower errors for most parts (except the period around (k), when all experts failed). AAA outperformed all the experts in this image sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">WHEN DOES AAA PERFORM BEST ON A DATASET? -A THEORETICAL INSPECTION</head><p>It is considered useful to know the conditions in which AAA outperforms experts as seen in the above experiments. However, Theorem 2 simply implies that the performance of AAA is similar to that of the best expert for an image sequence based on its regret bound. It does not indicate the conditions in which AAA outperforms experts for a certain sequence. However, it is still possible to determine the conditions in which AAA outperforms experts on average over an image sequence set V. The four notations are used to indicate these conditions. First, R V denotes the average regret of AAA over V. Second, the overall-best expert i * is the expert whose total loss (or, equivalently, average loss) over V is the minimum among the N experts, that is: where a new suffix v is attached to f t i and y t i . Third, S ⊂ V is the set of image sequences where the overall-best expert is the best expert. Finally, a value δ is defined as:</p><formula xml:id="formula_11">i * = argmin i∈[1,N ] v∈V T t=1 (f v,t i , y v,t ),<label>(7)</label></formula><formula xml:id="formula_12">δ = min v∈V\S T t=1 (f v,t i * , y v,t ) − min i T t=1 (f v,t i , y v,t ) . (8)</formula><p>In this definition, for the sequence v ∈ V \ S (i.e., the sequence v for which the overall-best expert is not the best expert), the overall-best expert performs worse than the best expert with a loss value of δ or more. From the proof given in Appendix F, the following proposition holds: Proposition 1. AAA outperforms all the experts on average over the image sequence set V if the following condition is satisfied:</p><formula xml:id="formula_13">R V ≤ |V \ S| |V| δ.<label>(9)</label></formula><p>This proposition states that AAA performs better on average (i.e., R V is smaller) when it satisfies the condition (9) with a smaller S and/or a larger δ. The set S is smaller if the overall-best expert is the best expert for only a smaller number of sequences. The difference δ is larger if the performance of the overall-best expert degrades drastically at v ∈ V \ S. From these discussions it can be concluded that when there is no almighty tracker (i.e., where S is small), AAA performs better than all experts over V based on appropriate aggregation. A large δ also indicates that AAA is better with employment of various experts, each of which can be an outstanding expert for certain sequences in V</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">CONCLUSION</head><p>This paper proposes a tracking method referred to as the Adaptive Aggregation of Arbitrary trackers (AAA) for robust online tracking. The performance of individual trackers varies significantly with different image sequences, creating variations in simple aggregation strategies. The proposed AAA is based on adaptive expert aggregation (AEA), which demonstrates strong theoretical support in terms of "regret", with a theoretically bounded performance difference between AAA and the best tracker (referred to as the best expert). It should be emphasized that the best tracker for an image sequence is identified at the end of the sequence. This means that it is unknown which tracker will be the best when AAA aggregates the trackers for each frame; nevertheless, this theoretical support guarantees that the performance of AAA will be close to that of the best tracker.</p><p>An exhaustive experimental study on the large variations of benchmark datasets and trackers to be aggregated demonstrated that the proposed method provides stateof-the-art performance. As a theoretical guarantee, AAA performed similar to or better than the best tracker for each image sequence, and often outperformed trackers on average over a benchmark dataset. We also derived a condition that AAA becomes the best tracker on average. Future work will focus on extension to multiple object tracking. It might seem straightforward to aggregate multiple object trackers, but is in fact challenging because it is not obvious how we determine anchor frames, define delayed feedback and design a new loss function. Other potentially worthwhile work involves the development of  We annotate the true target location (black), the proposed method and HDT (red). The expert which has the highest weight is also annotated. a methodology for organizing expert sets that give better performance with the proposed aggregation for a certain dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A MCCT DETAILS [9]</head><p>An MCCT (Multi-Cue Correlation Tracker) <ref type="bibr" target="#b8">[9]</ref> evaluates and weights experts for every frame, and simply selects the one with the highest weight to determine the target location. For each expert, the MCCT evaluates the overlap ratio of bounding boxes from other experts and the variance of the overlap ratio in a short period. The expert with smaller variance is evaluated as more stable and therefore more reliable.</p><p>However, with the employment of arbitrary experts, the MCCT may select a failed expert due to the nature of the above evaluation. More specifically, some experts that have already lost the target location will constantly have a zero overlap ratio and therefore zero variance; see <ref type="figure" target="#fig_6">Fig. 7</ref> for examples. It can be seen that MCCT selects failed experts that maintain a zero overlap ratio. The authors' experiments revealed numerous such cases, and MCCT therefore demonstrated lower performance than other methods. Accordingly, to fully utilize the potential of MCCT, it is necessary to carefully choose experts with bounding boxes that tend to be close together. In fact, the study reported in the original paper <ref type="bibr" target="#b8">[9]</ref> used specific experts with adaptive updating to allow ROI sharing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B HDT* DETAILS [11]</head><p>This section outlines the implementation of HDT* <ref type="bibr" target="#b10">[11]</ref> and related issues encountered in the study's experimental setup (with tough adversarial environments). As the current HDT* source code has not been published, the experiments here involved careful implementation based on the source code of the first version of HDT* <ref type="bibr" target="#b9">[10]</ref>. However, ideal implementation was challenging because HDT* uses its own Siamese networks to evaluate similarity between the template and the predicted target bounding box, and it implicitly assumes that expert predictions are based on the same bounding box size. This assumption conflicts with the study's experimental setup using arbitrary experts. To make the comparison as fair as possible in light of the above issues, the same criteria were used for similarity evaluation. Specifically, V T () from (10) was used rather than the Siamese network in HDT* implementation. In addition, as the same experts were used for HDT*, AUC-based evaluation for HDT* was omitted due to related influence from bounding box sizes.</p><p>HDT* evaluates experts by the following two criteria given for every frame. The first criterion is the difference in appearance between the template image of the target and the cropped image for the predicted location by an expert. The second is the location difference between expert prediction and feedback (i.e., the weighted average of expert prediction). Reliable evaluation using the first criterion is challenging when the target may be occluded and/or shows heavy deformation. Moreover, since the feedback in the second criterion is directly determined via expert prediction (rather than from more reliable information), it is often unreliable in tough tracking situations. <ref type="figure" target="#fig_7">Fig. 8</ref> shows two typical cases of HDT* failure. Since feedback is the weighted average of expert prediction (rather than another more reliable pseudo-ground-truth, like input from an offline tracker), performance will degrade when the weight of the wrong expert is high. In addition, the final location is determined via Hedge's prediction, and is sometimes distant from all other expert predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX C OFFLINE TRACKER DETAILS</head><p>In the study's experiments, an offline tracker based on Dijkstra's algorithm was used although any accurate offline tracker providing the delayed feedback can be applied. First, a graph linking two consecutive anchor frames, u q and u q+1 ,  was produced with node content corresponding to one of f uq ∪{f τ i |τ ∈ [u q +1, u q+1 ]}, where f uq is the target location based on AAA at the previous anchor frame u q , and f τ i is the target location based on the ith expert at τ . The edges of the graph were assigned between nodes f τ −1 i and f τ j with cost C f τ −1 i , f τ j . According to <ref type="bibr" target="#b47">[48]</ref>, the cost was defined as</p><formula xml:id="formula_14">C f τ −1 i , f τ j = − log P(f τ −1 i , f τ j )V E (f τ −1 i , f τ j )V T (f τ j ) ,<label>(10)</label></formula><p>where P ∈ [0, 1] is the value of GIoU between two bounding boxes and V E ∈ [0, 1] is the normalized cosine similarity between the feature vectors for the bounding box regions. The feature vectors are given by ResNet, as per the anchor frame determination in Sec. 3.3. V T ∈ [0, 1] is the normalized cosine similarity to the feature vector of the given template image. The globally minimum cost path between f uq and one of {f uq+1 i } is determined using Dijkstra's algorithm, and the node sequence of the path gives the pseudo-groundtruth y τ , τ ∈ [u q−1 + 1, u q ] as delayed feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX D DERIVATION OF THEOREM 1</head><p>Quanrud et al. <ref type="bibr" target="#b18">[19]</ref> gives the regret bound for the Online Mirror Descent (OMD) algorithm (a versatile choice for AEA) with delayed feedback. Various AEA algorithms can be derived from OMD by changing its regularizer for the expert selection process. Based on Theorem A.5 of <ref type="bibr" target="#b18">[19]</ref>, the regret bound of OMD with delayed feedback is given as</p><formula xml:id="formula_15">R T = O 1 η ψ + η G 2 (T + D) σ ,</formula><p>where the values ψ and σ are determined by the regularizer choice, η is the learning rate and G is the difference between the maximum and minimum values of a loss function. The authours' expert selection algorithm based on weights (3) is also a special case of OMD. According to <ref type="bibr" target="#b18">[19]</ref>, if an entropic regularizer is applied, weight can be derived by updating the (3) scheme. Moreover, σ is 1 and ψ is upperbounded by O(ln N ) <ref type="bibr" target="#b18">[19]</ref>. The loss function (1) takes values in [0, 1], and therefore G = 1. Based on these values and the assumption that η ∝ ln N/(T + D), Theorem 1 is supported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX E DETERMINATION OF THE ANCHOR FRAME THRESH-OLD θ</head><p>The hyper-parameter θ, which is the threshold used to determine the anchor frame, was determined experimentally using the GOT10K dataset as noted in Sec.5.1.4. <ref type="figure" target="#fig_8">Fig. 9</ref> shows the AUC score and the anchor frame ratio based on changing the hyper-parameter θ from 0.6 to 0.9 at intervals of 0.1. Here, AUC is normalized to the range between [0, 1] for easier observation. As a general trend, a smaller threshold value results in a high anchor ratio and, in turn, a higher AUC. However, detailed observation reveals that this trend does not always hold because anchor frames determined using lower values of θ are less reliable and will result in inaccurate feedback. Consequently, smaller threshold values do not always give better performance. Specifically, the best θ values for each expert group was as follows: High:0.69; Low:0.60; Mix:0.65; SiamDW:0.65; and SiamRPN++:0.61.</p><p>Evaluation was also performed to determine whether AAA can identify the target location with high confidence at anchor frames. AAA accuracy with experts in the High group is shown in <ref type="table" target="#tab_6">Table 6</ref>, in addition to the accuracy of individual experts. The hyper-parameter θ was set at 0.69, as indicated by <ref type="figure" target="#fig_8">Fig. 9</ref>. AAA achieved the best AUC score for all datasets. This proves that the proposed method can be applied to determine anchor frames appropriately.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>No "almighty" tracker. The percentages represent the ratio of image sequences that each state-of-the-art tracker performs best for the individual tracking benchmarks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>The change of the most reliable tracker. The images of a frame (top) and a few frames after it (bottom) in two image sequences are shown. Each bounding box represents the estimation of experts and the true target location (black). The best tracker changes during the two frames.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>The overview of the proposed online tracking method, called Adaptive Aggregation of Arbitrary trackers (AAA)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Success and precision plots in High group.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 :</head><label>5</label><figDesc>Rank histograms of (a) High, (b) Low, and (c) Mix groups.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 :</head><label>6</label><figDesc>Tracking examples. The top is "Girl2" in OTB2015 and the bottom is "Yo-yos ce1" in TColor128. For the picked-up frame, we annotate the true target location (black), the proposed method (red), and the expert which has the highest weight. In all the graphs, gray vertical lines indicate the location of the anchor frames.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 :</head><label>7</label><figDesc>Tracking example of (top) the proposed method and (bottom) MCCT. We annotate the true target location (black), the proposed method and MCCT (red). The expert which has the highest weight is also annotated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 8 :</head><label>8</label><figDesc>Tracking example of (top) the proposed method and (bottom) HDT.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 9 :</head><label>9</label><figDesc>0.61 0.62 0.63 0.64 0.65 0.66 0.67 0.68 0.69 0.70 0.71 0.72 0.73 0.74 0.75 0.76 0.77 0.78 0.79 0.80 0.81 0.82 0.83 0.84 0.85 0.86 0.87 0.88 0.89 0(top) Normalized AUC score and (bottom) anchor ratio for thresholds θ. For each comparison group, the AUC scores are normalized by min-max normalization. The threshold with the highest AUC score (i.e., 1) is indicated by a circle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1 :</head><label>1</label><figDesc>Tracking Accuracy by High Group</figDesc><table><row><cell>Tracker</cell><cell cols="2">OTB2015 AUC DP</cell><cell cols="2">TColor128 AUC DP</cell><cell cols="2">UAV123 AUC DP</cell><cell>NFS AUC</cell><cell>DP</cell><cell cols="2">LaSOT AUC DP</cell><cell>VOT2018 AUC</cell></row><row><cell>ATOM [29]</cell><cell>0.67</cell><cell>0.87</cell><cell>0.60</cell><cell>0.81</cell><cell>0.62</cell><cell>0.82</cell><cell>0.58</cell><cell>0.69</cell><cell>0.51</cell><cell>0.51</cell><cell>0.52</cell></row><row><cell>DaSiamRPN [30]</cell><cell>0.65</cell><cell>0.88</cell><cell>0.53</cell><cell>0.75</cell><cell>0.57</cell><cell>0.78</cell><cell>0.55</cell><cell>0.67</cell><cell>0.43</cell><cell>0.42</cell><cell>0.43</cell></row><row><cell>SiamMCF [31]</cell><cell>0.65</cell><cell>0.85</cell><cell>0.57</cell><cell>0.78</cell><cell>0.54</cell><cell>0.77</cell><cell>0.57</cell><cell>0.70</cell><cell>0.44</cell><cell>0.45</cell><cell>0.45</cell></row><row><cell>SiamRPN++ [32]</cell><cell>0.69</cell><cell>0.90</cell><cell>0.58</cell><cell>0.77</cell><cell>0.60</cell><cell>0.80</cell><cell>0.60</cell><cell>0.74</cell><cell>0.49</cell><cell>0.51</cell><cell>0.50</cell></row><row><cell>SPM [33]</cell><cell>0.67</cell><cell>0.87</cell><cell>0.58</cell><cell>0.79</cell><cell>0.59</cell><cell>0.77</cell><cell>0.57</cell><cell>0.67</cell><cell>0.47</cell><cell>0.48</cell><cell>0.48</cell></row><row><cell>THOR [34]</cell><cell>0.64</cell><cell>0.85</cell><cell>0.52</cell><cell>0.72</cell><cell>0.57</cell><cell>0.77</cell><cell>0.57</cell><cell>0.68</cell><cell>0.40</cell><cell>0.41</cell><cell>0.47</cell></row><row><cell>HDT* [11]</cell><cell>-</cell><cell>0.83</cell><cell>-</cell><cell>0.71</cell><cell>-</cell><cell>0.73</cell><cell>-</cell><cell>0.58</cell><cell>-</cell><cell>0.37</cell><cell>-</cell></row><row><cell>MCCT [9]</cell><cell>0.64</cell><cell>0.83</cell><cell>0.53</cell><cell>0.72</cell><cell>0.58</cell><cell>0.76</cell><cell>0.57</cell><cell>0.69</cell><cell>0.42</cell><cell>0.44</cell><cell>0.40</cell></row><row><cell>Random</cell><cell>0.66</cell><cell>0.87</cell><cell>0.56</cell><cell>0.77</cell><cell>0.58</cell><cell>0.79</cell><cell>0.57</cell><cell>0.69</cell><cell>0.46</cell><cell>0.46</cell><cell>0.48</cell></row><row><cell>Max</cell><cell>0.68</cell><cell>0.89</cell><cell>0.56</cell><cell>0.77</cell><cell>0.58</cell><cell>0.78</cell><cell>0.61</cell><cell>0.74</cell><cell>0.46</cell><cell>0.46</cell><cell>0.46</cell></row><row><cell>AAA(Proposed)</cell><cell>0.70</cell><cell>0.91</cell><cell>0.62</cell><cell>0.84</cell><cell>0.62</cell><cell>0.83</cell><cell>0.61</cell><cell>0.75</cell><cell>0.53</cell><cell>0.55</cell><cell>0.52</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 2 :</head><label>2</label><figDesc>Tracking Accuracy by Low Group</figDesc><table><row><cell>Tracker</cell><cell cols="2">OTB2015 AUC DP</cell><cell cols="2">TColor128 AUC DP</cell><cell cols="2">UAV123 AUC DP</cell><cell>NFS AUC</cell><cell>DP</cell><cell cols="2">LaSOT AUC DP</cell><cell>VOT2018 AUC</cell></row><row><cell>GradNet [36]</cell><cell>0.63</cell><cell>0.85</cell><cell>0.56</cell><cell>0.76</cell><cell>0.51</cell><cell>0.74</cell><cell>0.51</cell><cell>0.64</cell><cell>0.36</cell><cell>0.38</cell><cell>0.40</cell></row><row><cell>MemTrack [37]</cell><cell>0.63</cell><cell>0.82</cell><cell>0.54</cell><cell>0.74</cell><cell>0.49</cell><cell>0.70</cell><cell>0.50</cell><cell>0.61</cell><cell>0.34</cell><cell>0.35</cell><cell>0.39</cell></row><row><cell>SiamDW [38]</cell><cell>0.67</cell><cell>0.91</cell><cell>0.53</cell><cell>0.75</cell><cell>0.46</cell><cell>0.69</cell><cell>0.50</cell><cell>0.63</cell><cell>0.35</cell><cell>0.34</cell><cell>0.37</cell></row><row><cell>SiamFC [39]</cell><cell>0.59</cell><cell>0.78</cell><cell>0.52</cell><cell>0.70</cell><cell>0.51</cell><cell>0.74</cell><cell>0.51</cell><cell>0.60</cell><cell>0.35</cell><cell>0.36</cell><cell>0.33</cell></row><row><cell>SiamRPN [40]</cell><cell>0.63</cell><cell>0.83</cell><cell>0.52</cell><cell>0.71</cell><cell>0.58</cell><cell>0.77</cell><cell>0.56</cell><cell>0.66</cell><cell>0.45</cell><cell>0.45</cell><cell>0.48</cell></row><row><cell>Staple [41]</cell><cell>0.60</cell><cell>0.79</cell><cell>0.51</cell><cell>0.68</cell><cell>0.45</cell><cell>0.64</cell><cell>0.41</cell><cell>0.48</cell><cell>0.24</cell><cell>0.23</cell><cell>0.30</cell></row><row><cell>HDT* [11]</cell><cell>-</cell><cell>0.75</cell><cell>-</cell><cell>0.63</cell><cell>-</cell><cell>0.64</cell><cell>-</cell><cell>0.48</cell><cell>-</cell><cell>0.26</cell><cell>-</cell></row><row><cell>MCCT [9]</cell><cell>0.59</cell><cell>0.79</cell><cell>0.49</cell><cell>0.66</cell><cell>0.50</cell><cell>0.70</cell><cell>0.51</cell><cell>0.63</cell><cell>0.32</cell><cell>0.34</cell><cell>0.32</cell></row><row><cell>Random</cell><cell>0.62</cell><cell>0.83</cell><cell>0.53</cell><cell>0.72</cell><cell>0.50</cell><cell>0.71</cell><cell>0.50</cell><cell>0.60</cell><cell>0.35</cell><cell>0.35</cell><cell>0.38</cell></row><row><cell>Max</cell><cell>0.63</cell><cell>0.83</cell><cell>0.52</cell><cell>0.71</cell><cell>0.51</cell><cell>0.73</cell><cell>0.53</cell><cell>0.64</cell><cell>0.35</cell><cell>0.35</cell><cell>0.38</cell></row><row><cell>AAA(Proposed)</cell><cell>0.66</cell><cell>0.87</cell><cell>0.59</cell><cell>0.82</cell><cell>0.56</cell><cell>0.78</cell><cell>0.58</cell><cell>0.69</cell><cell>0.45</cell><cell>0.46</cell><cell>0.45</cell></row></table><note>· See the notes below Table 1 for the details.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3 :</head><label>3</label><figDesc>Tracking Accuracy by Mix Group</figDesc><table><row><cell>Tracker</cell><cell cols="2">OTB2015 AUC DP</cell><cell cols="2">TColor128 AUC DP</cell><cell cols="2">UAV123 AUC DP</cell><cell>NFS AUC</cell><cell>DP</cell><cell cols="2">LaSOT AUC DP</cell><cell>VOT2018 AUC</cell></row><row><cell>ATOM [29]</cell><cell>0.67</cell><cell>0.87</cell><cell>0.60</cell><cell>0.81</cell><cell>0.62</cell><cell>0.82</cell><cell>0.58</cell><cell>0.69</cell><cell>0.51</cell><cell>0.51</cell><cell>0.52</cell></row><row><cell>SiamRPN++ [32]</cell><cell>0.69</cell><cell>0.90</cell><cell>0.58</cell><cell>0.77</cell><cell>0.60</cell><cell>0.80</cell><cell>0.60</cell><cell>0.74</cell><cell>0.49</cell><cell>0.51</cell><cell>0.50</cell></row><row><cell>SPM [33]</cell><cell>0.67</cell><cell>0.87</cell><cell>0.58</cell><cell>0.79</cell><cell>0.59</cell><cell>0.77</cell><cell>0.57</cell><cell>0.67</cell><cell>0.47</cell><cell>0.48</cell><cell>0.48</cell></row><row><cell>MemTrack [37]</cell><cell>0.63</cell><cell>0.82</cell><cell>0.54</cell><cell>0.74</cell><cell>0.49</cell><cell>0.70</cell><cell>0.50</cell><cell>0.61</cell><cell>0.34</cell><cell>0.35</cell><cell>0.39</cell></row><row><cell>SiamFC [39]</cell><cell>0.59</cell><cell>0.78</cell><cell>0.52</cell><cell>0.70</cell><cell>0.51</cell><cell>0.74</cell><cell>0.51</cell><cell>0.60</cell><cell>0.35</cell><cell>0.36</cell><cell>0.33</cell></row><row><cell>Staple [41]</cell><cell>0.60</cell><cell>0.79</cell><cell>0.51</cell><cell>0.68</cell><cell>0.45</cell><cell>0.64</cell><cell>0.41</cell><cell>0.48</cell><cell>0.24</cell><cell>0.23</cell><cell>0.30</cell></row><row><cell>HDT* [11]</cell><cell>-</cell><cell>0.78</cell><cell>-</cell><cell>0.68</cell><cell>-</cell><cell>0.67</cell><cell>-</cell><cell>0.50</cell><cell>-</cell><cell>0.28</cell><cell>-</cell></row><row><cell>MCCT [9]</cell><cell>0.60</cell><cell>0.78</cell><cell>0.50</cell><cell>0.66</cell><cell>0.53</cell><cell>0.71</cell><cell>0.53</cell><cell>0.65</cell><cell>0.36</cell><cell>0.38</cell><cell>0.33</cell></row><row><cell>Random</cell><cell>0.64</cell><cell>0.84</cell><cell>0.55</cell><cell>0.75</cell><cell>0.54</cell><cell>0.74</cell><cell>0.53</cell><cell>0.63</cell><cell>0.40</cell><cell>0.41</cell><cell>0.42</cell></row><row><cell>Max</cell><cell>0.65</cell><cell>0.84</cell><cell>0.56</cell><cell>0.76</cell><cell>0.55</cell><cell>0.76</cell><cell>0.57</cell><cell>0.68</cell><cell>0.40</cell><cell>0.42</cell><cell>0.43</cell></row><row><cell>AAA(Proposed)</cell><cell>0.68</cell><cell>0.89</cell><cell>0.62</cell><cell>0.83</cell><cell>0.60</cell><cell>0.81</cell><cell>0.59</cell><cell>0.71</cell><cell>0.51</cell><cell>0.53</cell><cell>0.49</cell></row></table><note>· See the notes below Table 1 for the details.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 4 :</head><label>4</label><figDesc>Tracking Accuracy by SiamDW Group</figDesc><table><row><cell>Tracker</cell><cell cols="2">OTB2015 AUC DP</cell><cell cols="2">TColor128 AUC DP</cell><cell cols="2">UAV123 AUC DP</cell><cell>NFS AUC</cell><cell>DP</cell><cell cols="2">LaSOT AUC DP</cell><cell>VOT2018 AUC</cell></row><row><cell>SiamDW/SiamFCRes22/OTB</cell><cell>0.64</cell><cell>0.84</cell><cell>0.58</cell><cell>0.79</cell><cell>0.51</cell><cell>0.73</cell><cell>0.52</cell><cell>0.64</cell><cell>0.38</cell><cell>0.39</cell><cell>0.38</cell></row><row><cell>SiamDW/SiamFCIncep22/OTB</cell><cell>0.61</cell><cell>0.81</cell><cell>0.55</cell><cell>0.76</cell><cell>0.50</cell><cell>0.72</cell><cell>0.51</cell><cell>0.64</cell><cell>0.36</cell><cell>0.38</cell><cell>0.35</cell></row><row><cell>SiamDW/SiamFCNext22/OTB</cell><cell>0.62</cell><cell>0.82</cell><cell>0.57</cell><cell>0.76</cell><cell>0.49</cell><cell>0.71</cell><cell>0.51</cell><cell>0.63</cell><cell>0.37</cell><cell>0.38</cell><cell>0.32</cell></row><row><cell>SiamDW/SiamRPNRes22/OTB</cell><cell>0.67</cell><cell>0.91</cell><cell>0.53</cell><cell>0.75</cell><cell>0.46</cell><cell>0.69</cell><cell>0.50</cell><cell>0.63</cell><cell>0.35</cell><cell>0.34</cell><cell>0.37</cell></row><row><cell>SiamDW/SiamFCRes22/VOT</cell><cell>0.63</cell><cell>0.84</cell><cell>0.56</cell><cell>0.77</cell><cell>0.51</cell><cell>0.73</cell><cell>0.52</cell><cell>0.65</cell><cell>0.36</cell><cell>0.37</cell><cell>0.37</cell></row><row><cell>SiamDW/SiamFCIncep22/VOT</cell><cell>0.60</cell><cell>0.80</cell><cell>0.54</cell><cell>0.75</cell><cell>0.50</cell><cell>0.73</cell><cell>0.49</cell><cell>0.61</cell><cell>0.35</cell><cell>0.36</cell><cell>0.35</cell></row><row><cell>SiamDW/SiamFCNext22/VOT</cell><cell>0.61</cell><cell>0.81</cell><cell>0.54</cell><cell>0.74</cell><cell>0.49</cell><cell>0.72</cell><cell>0.51</cell><cell>0.63</cell><cell>0.35</cell><cell>0.38</cell><cell>0.34</cell></row><row><cell>SiamDW/SiamRPNRes22/VOT</cell><cell>0.66</cell><cell>0.90</cell><cell>0.53</cell><cell>0.74</cell><cell>0.46</cell><cell>0.69</cell><cell>0.51</cell><cell>0.66</cell><cell>0.35</cell><cell>0.35</cell><cell>0.43</cell></row><row><cell>HDT* [11]</cell><cell>-</cell><cell>0.81</cell><cell>-</cell><cell>0.70</cell><cell>-</cell><cell>0.67</cell><cell>-</cell><cell>0.57</cell><cell>-</cell><cell>0.30</cell><cell>-</cell></row><row><cell>MCCT [9]</cell><cell>0.63</cell><cell>0.83</cell><cell>0.54</cell><cell>0.74</cell><cell>0.50</cell><cell>0.71</cell><cell>0.51</cell><cell>0.65</cell><cell>0.34</cell><cell>0.36</cell><cell>0.34</cell></row><row><cell>Random</cell><cell>0.63</cell><cell>0.84</cell><cell>0.55</cell><cell>0.76</cell><cell>0.49</cell><cell>0.71</cell><cell>0.51</cell><cell>0.64</cell><cell>0.36</cell><cell>0.37</cell><cell>0.37</cell></row><row><cell>Max</cell><cell>0.64</cell><cell>0.86</cell><cell>0.55</cell><cell>0.76</cell><cell>0.51</cell><cell>0.74</cell><cell>0.53</cell><cell>0.66</cell><cell>0.36</cell><cell>0.36</cell><cell>0.37</cell></row><row><cell>AAA(Proposed)</cell><cell>0.66</cell><cell>0.88</cell><cell>0.60</cell><cell>0.82</cell><cell>0.52</cell><cell>0.75</cell><cell>0.55</cell><cell>0.68</cell><cell>0.42</cell><cell>0.43</cell><cell>0.42</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 5 :</head><label>5</label><figDesc>Tracking Accuracy by SiamRPN++ Group</figDesc><table><row><cell>Tracker</cell><cell cols="2">OTB2015 AUC DP</cell><cell cols="2">TColor128 AUC DP</cell><cell cols="2">UAV123 AUC DP</cell><cell>NFS AUC</cell><cell>DP</cell><cell cols="2">LaSOT AUC DP</cell><cell>VOT2018 AUC</cell></row><row><cell>SiamRPN++/AlexNet/VOT</cell><cell>0.66</cell><cell>0.87</cell><cell>0.57</cell><cell>0.77</cell><cell>0.58</cell><cell>0.77</cell><cell>0.54</cell><cell>0.65</cell><cell>0.45</cell><cell>0.45</cell><cell>0.47</cell></row><row><cell>SiamRPN++/AlexNet/OTB</cell><cell>0.66</cell><cell>0.86</cell><cell>0.55</cell><cell>0.75</cell><cell>0.58</cell><cell>0.78</cell><cell>0.54</cell><cell>0.66</cell><cell>0.43</cell><cell>0.43</cell><cell>0.45</cell></row><row><cell>SiamRPN++/ResNet-50/VOT</cell><cell>0.65</cell><cell>0.86</cell><cell>0.56</cell><cell>0.75</cell><cell>0.61</cell><cell>0.80</cell><cell>0.58</cell><cell>0.71</cell><cell>0.50</cell><cell>0.51</cell><cell>0.51</cell></row><row><cell>SiamRPN++/ResNet-50/OTB</cell><cell>0.69</cell><cell>0.90</cell><cell>0.58</cell><cell>0.77</cell><cell>0.60</cell><cell>0.80</cell><cell>0.60</cell><cell>0.74</cell><cell>0.49</cell><cell>0.51</cell><cell>0.50</cell></row><row><cell>SiamRPN++/ResNet-50/VOTLT</cell><cell>0.63</cell><cell>0.84</cell><cell>0.58</cell><cell>0.79</cell><cell>0.61</cell><cell>0.81</cell><cell>0.56</cell><cell>0.68</cell><cell>0.52</cell><cell>0.54</cell><cell>0.51</cell></row><row><cell>SiamRPN++/MobileNetV2/VOT</cell><cell>0.65</cell><cell>0.86</cell><cell>0.56</cell><cell>0.76</cell><cell>0.60</cell><cell>0.79</cell><cell>0.57</cell><cell>0.70</cell><cell>0.45</cell><cell>0.46</cell><cell>0.50</cell></row><row><cell>SiamRPN++/SiamMask/VOT</cell><cell>0.65</cell><cell>0.85</cell><cell>0.54</cell><cell>0.73</cell><cell>0.60</cell><cell>0.80</cell><cell>0.58</cell><cell>0.72</cell><cell>0.47</cell><cell>0.48</cell><cell>0.48</cell></row><row><cell>HDT* [11]</cell><cell>-</cell><cell>0.80</cell><cell>-</cell><cell>0.68</cell><cell>-</cell><cell>0.71</cell><cell>-</cell><cell>0.59</cell><cell>-</cell><cell>0.38</cell><cell>-</cell></row><row><cell>MCCT [9]</cell><cell>0.64</cell><cell>0.84</cell><cell>0.55</cell><cell>0.75</cell><cell>0.61</cell><cell>0.81</cell><cell>0.59</cell><cell>0.72</cell><cell>0.48</cell><cell>0.50</cell><cell>0.45</cell></row><row><cell>Random</cell><cell>0.66</cell><cell>0.86</cell><cell>0.56</cell><cell>0.76</cell><cell>0.60</cell><cell>0.79</cell><cell>0.57</cell><cell>0.69</cell><cell>0.47</cell><cell>0.48</cell><cell>0.49</cell></row><row><cell>Max</cell><cell>0.66</cell><cell>0.87</cell><cell>0.56</cell><cell>0.76</cell><cell>0.60</cell><cell>0.80</cell><cell>0.60</cell><cell>0.73</cell><cell>0.47</cell><cell>0.48</cell><cell>0.50</cell></row><row><cell>AAA(Proposed)</cell><cell>0.68</cell><cell>0.89</cell><cell>0.61</cell><cell>0.83</cell><cell>0.64</cell><cell>0.85</cell><cell>0.61</cell><cell>0.74</cell><cell>0.54</cell><cell>0.56</cell><cell>0.52</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 6 :</head><label>6</label><figDesc>Tracking Accuracy at Anchor Frames by High Group</figDesc><table><row><cell>Tracker</cell><cell cols="2">OTB2015 AUC DP</cell><cell cols="2">TColor128 AUC DP</cell><cell cols="2">UAV123 AUC DP</cell><cell>NFS AUC</cell><cell>DP</cell><cell cols="2">LaSOT AUC DP</cell><cell>VOT2018 AUC</cell></row><row><cell>ATOM</cell><cell>0.72</cell><cell>0.93</cell><cell>0.66</cell><cell>0.88</cell><cell>0.71</cell><cell>0.91</cell><cell>0.66</cell><cell>0.80</cell><cell>0.66</cell><cell>0.70</cell><cell>0.61</cell></row><row><cell>DaSiamRPN</cell><cell>0.70</cell><cell>0.92</cell><cell>0.61</cell><cell>0.84</cell><cell>0.68</cell><cell>0.88</cell><cell>0.64</cell><cell>0.79</cell><cell>0.59</cell><cell>0.62</cell><cell>0.57</cell></row><row><cell>SiamMCF</cell><cell>0.71</cell><cell>0.91</cell><cell>0.66</cell><cell>0.88</cell><cell>0.66</cell><cell>0.88</cell><cell>0.67</cell><cell>0.83</cell><cell>0.60</cell><cell>0.64</cell><cell>0.57</cell></row><row><cell>SiamRPN++</cell><cell>0.73</cell><cell>0.94</cell><cell>0.64</cell><cell>0.85</cell><cell>0.70</cell><cell>0.89</cell><cell>0.68</cell><cell>0.84</cell><cell>0.64</cell><cell>0.69</cell><cell>0.60</cell></row><row><cell>SPM</cell><cell>0.72</cell><cell>0.92</cell><cell>0.65</cell><cell>0.89</cell><cell>0.69</cell><cell>0.87</cell><cell>0.65</cell><cell>0.78</cell><cell>0.63</cell><cell>0.67</cell><cell>0.60</cell></row><row><cell>THOR</cell><cell>0.68</cell><cell>0.90</cell><cell>0.59</cell><cell>0.79</cell><cell>0.67</cell><cell>0.87</cell><cell>0.64</cell><cell>0.79</cell><cell>0.55</cell><cell>0.58</cell><cell>0.59</cell></row><row><cell>AAA(Proposed)</cell><cell>0.74</cell><cell>0.94</cell><cell>0.70</cell><cell>0.92</cell><cell>0.72</cell><cell>0.93</cell><cell>0.70</cell><cell>0.87</cell><cell>0.70</cell><cell>0.76</cell><cell>0.64</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by JSPS KAKENHI Grant Number JP17H06100 and JP18K18001.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX F PROOF OF PROPOSITION 1</head><p>Proof. If tracking performance evaluation is based on loss (rather than AUC or DP), the situation in which AAA outperforms experts on average over V is expressed as the inequality</p><p>where p v,t is the result of location identification using AAA at t for the sequence v ∈ V and y v,t is the pseudo-groundtruth given as delayed feedback. As defined in Sec. 6, the i * th expert is the overall-best expert having the most optimal average performance over V. The left side of (11) is relative to the loss of AAA over V. The right side is relative to the loss of the overall-best expert over V, as defined by <ref type="bibr" target="#b6">(7)</ref>. Accordingly, the inequality (11) indicates the situation in which AAA outperforms all experts on average over V.</p><p>From <ref type="formula">(11)</ref>, the following inequality is derived:</p><p>The left side is the sum of AAA regrets (see (4)) over V, and is therefore equal to |V|R V . The right side of (12) can be decomposed into two terms by splitting V into S and V \ S. Then, the first term is</p><p>because the overall-best (i.e., the i * th) expert is the best expert in the image sequence v ∈ S. By the definition of δ in <ref type="formula">(9)</ref>, the second term is</p><p>From <ref type="formula">(13)</ref> and <ref type="formula">(14)</ref>, we have:</p><p>(15) From <ref type="bibr" target="#b11">(12)</ref> and <ref type="bibr" target="#b14">(15)</ref>, if the condition |V|R V ≤ |V \ S|δ is satisfied, this gives</p><p>This means that if the condition holds, (12) holds and immediately <ref type="bibr" target="#b10">(11)</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Object tracking algorithms for video surveillance applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mangawati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V R</forename><surname>Leesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aradhya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCSP</title>
		<meeting>ICCSP</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Video processing techniques for traffic flow monitoring: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ITSC</title>
		<meeting>ITSC</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey of autonomous driving: Common practices and emerging technologies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yurtsever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Carballo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Takeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Handcrafted and deep trackers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fiaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Javed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Jung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A novel performance evaluation methodology for single-target trackers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vojir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pflugfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nebehay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cehovin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">TPAMI</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Ensemble tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avidan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note type="report_type">TPAMI</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real-time tracking via on-line boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Grabner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grabner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Meem: robust tracking via multiple experts using entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multicue correlation filters for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hedged deep tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Hedging deep features for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">TPAMI</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A game of prediction with expert advice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vovk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JCSS</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Online learning and online convex optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Foundations and Trends in Machine Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adaptive aggregation of arbitrary online trackers with a regret bound</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Suehiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Uchida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. WACV</title>
		<meeting>WACV</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The weighted majority algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Littlestone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Warmuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information and Computation</title>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A decision-theoretic generalization of on-line learning and an application to boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JCSS</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A dynamic disk spin-down technique for mobile computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Helmbold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D E</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sherrod</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MobiCom</title>
		<meeting>MobiCom</meeting>
		<imprint>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Online learning with adversarial delays</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Quanrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Khashabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NIPS</title>
		<meeting>NIPS</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Ensemble-based tracking: Aggregating crowdsourced structured time series data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-Y</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICML</title>
		<meeting>ICML</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Branchout: Regularization for online ensemble tracking with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An ensemble of deep neural networks for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICIP</title>
		<meeting>ICIP</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">On-line ensemble svm for robust object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ACCV</title>
		<meeting>ACCV</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Online object tracking: A benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Generalized intersection over union: A metric and a loss for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pre-trained convolutional neural networks as feature extractors for tuberculosis detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Lopes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Valiati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers in Biology and Medicine</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ImageNet large scale visual recognition challenge,&quot; IJCV</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">ATOM: Accurate tracking by overlap maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Distractoraware siamese networks for visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multiple context features in siamese networks for visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Morimitsu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV Workshops</title>
		<meeting>ECCV Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Siamrpn++: Evolution of siamese visual tracking with very deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">SPM-tracker: Seriesparallel matching for real-time visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Tracking holistic object representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Haddadin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. BMVC</title>
		<meeting>BMVC</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Foundations of machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rostamizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Grad-Net: Gradient-guided network for visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning dynamic memory networks for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Deeper and wider siamese networks for real-time visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fully-convolutional siamese networks for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">High performance visual tracking with siamese region proposal network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Staple: Complementary learners for real-time tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Golodetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Miksik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H S</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Object tracking benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Encoding color information for visual tracking: Algorithms and benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Blasch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A benchmark and simulator for uav tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Need for speed: A benchmark for higher frame rate object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">K</forename><surname>Galoogahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fagg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">LaSOT: A high-quality benchmark for largescale single object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">GOT-10k: A large highdiversity benchmark for generic object tracking in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Global data association for multiobject tracking using network flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nevatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
