<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SCALE-EQUIVARIANT STEERABLE NETWORKS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Sosnovik</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UvA-Bosch Delta Lab University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michał</forename><surname>Szmaja</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UvA-Bosch Delta Lab University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><surname>Smeulders</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UvA-Bosch Delta Lab University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">SCALE-EQUIVARIANT STEERABLE NETWORKS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The effectiveness of Convolutional Neural Networks (CNNs) has been substantially attributed to their built-in property of translation equivariance. However, CNNs do not have embedded mechanisms to handle other types of transformations. In this work, we pay attention to scale changes, which regularly appear in various tasks due to the changing distances between the objects and the camera. First, we introduce the general theory for building scale-equivariant convolutional networks with steerable filters. We develop scale-convolution and generalize other common blocks to be scale-equivariant. We demonstrate the computational efficiency and numerical stability of the proposed method. We compare the proposed models to the previously developed methods for scale equivariance and local scale invariance. We demonstrate state-of-the-art results on the MNIST-scale dataset and on the STL-10 dataset in the supervised learning setting.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Scale transformations occur in many image and video analysis tasks. They are a natural consequence of the variable distances among objects, or between objects and the camera. Such transformations result in significant changes in the input space which are often difficult for models to handle appropriately without careful consideration. At a high level, there are two modeling paradigms which allow a model to deal with scale changes: models can be endowed with an internal notion of scale and transform their predictions accordingly, or instead, models can be designed to be specifically invariant to scale changes. In image classification, when scale changes are commonly a factor of 2, it is often sufficient to make class prediction independent of scale. However, in tasks such as image segmentation, visual tracking, or object detection, scale changes can reach factors of 10 or more. In these cases, it is intuitive that the ideal prediction should scale proportionally to the input. For example, the segmentation map of a nearby pedestrian should be easily converted to that of a distant person simply by downscaling.</p><p>Convolutional Neural Networks (CNNs) demonstrate state-of-the-art performance in a wide range of tasks. Yet, despite their built-in translation equivariance, they do not have a particular mechanism for dealing with scale changes. One way to make CNNs account for scale is to train them with data augmentation <ref type="bibr" target="#b0">Barnard &amp; Casasent (1991)</ref>. This is, however, suitable only for global transformations. As an alternative, <ref type="bibr" target="#b11">Henriques &amp; Vedaldi (2017)</ref> and <ref type="bibr" target="#b25">Tai et al. (2019)</ref> use the canonical coordinates of scale transformations to reduce scaling to well-studied translations. While these approaches do allow for scale equivariance, they consequently break translation equivariance.</p><p>Several attempts have thus been made to extend CNNs to both scale and translation symmetry simultaneously. Some works use input or filter resizing to account for scaling in deep layers <ref type="bibr" target="#b35">Xu et al. (2014)</ref>; <ref type="bibr" target="#b15">Kanazawa et al. (2014)</ref>. Such methods are suboptimal due to the time complexity of tensor resizing and the need for interpolation. In <ref type="bibr" target="#b10">Ghosh &amp; Gupta (2019)</ref> the authors pre-calculate filters defined on several scales to build scale-invariant networks, while ignoring the important case of scale equivariance. In contrast, <ref type="bibr" target="#b33">Worrall &amp; Welling (2019)</ref> employ the theory of semigroup equivariant networks with scale-space as an example; however, this method is only suitable for integer downscale factors and therefore limited.</p><p>Published as a conference paper at ICLR 2020</p><p>In this paper we develop a theory of scale-equivariant networks. We demonstrate the concept of steerable filter parametrization which allows for scaling without the need for tensor resizing. Then we derive scale-equivariant convolution and demonstrate a fast algorithm for its implementation. Furthermore, we experiment to determine to what degree the mathematical properties actually hold true. Finally, we conduct a set of experiments comparing our model with other methods for scale equivariance and local scale invariance.</p><p>The proposed model has the following advantages compared to other scale-equivariant models:</p><p>1. It is equivariant to scale transformations with arbitrary discrete scale factors and is not limited to either integer scales or scales tailored by the image pixel grid.</p><p>2. It does not rely on any image resampling techniques during training, and therefore, produces deep scale-equivariant representations free of any interpolation artifacts.</p><p>3. The algorithm is based on the combination of tensor expansion and 2-dimensional convolution, and demonstrates the same computation time as the general CNN with a comparable filter bank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PRELIMINARIES</head><p>Before we move into scale-equivariant mappings, we discuss some aspects of equivariance, scaling transformations, symmetry groups, and the functions defined on them. For simplicity, in this section, we consider only 1-dimensional functions. The generalization to higher-dimensional cases is straightforward.</p><p>Equivariance Let us consider some mapping g. It is equivariant under L θ if and only if there exists L θ such that g • L θ = L θ • g. In case L θ is the identity mapping, the function g is invariant.</p><p>In this paper we consider scaling transformations. In order to guarantee the equivariance of the predictions to such transformations, and to improve the performance of the model, we seek to incorporate this property directly inside CNNs.</p><p>Scaling Given a function f : R → R, a scale transformation is defined as follows:</p><formula xml:id="formula_0">L s [f ](x) = f (s −1 x), ∀s &gt; 0<label>(1)</label></formula><p>We refer to cases with s &gt; 1 as upscale and to cases with s &lt; 1 as downscale. If we convolve the downscaled function with an arbitrary filter ψ and perform a simple change of variables inside the integral, we get the following property:</p><formula xml:id="formula_1">[L s [f ] ψ](x) = R L s [f ](x )ψ(x − x)dx = R f (s −1 x )ψ(x − x)dx = s R f (s −1 x )ψ(s(s −1 x − s −1 x))d(s −1 x ) = sL s [f L s −1 [ψ]](x)<label>(2)</label></formula><p>In other words, convolution of the downscaled function with a filter can be expressed through a convolution of the function with the correspondingly upscaled filter where downscaling is performed afterwards. Equation 2 shows us that the standard convolution is not scale-equivariant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Steerable Filters</head><p>In order to make computations simpler, we reparametrize ψ σ (x) = σ −1 ψ(σ −1 x), which has the following property:</p><formula xml:id="formula_2">L s −1 [ψ σ ](x) = ψ σ (sx) = s −1 ψ s −1 σ (x)<label>(3)</label></formula><p>It gives a shorter version of Equation 2:</p><formula xml:id="formula_3">L s [f ] ψ σ = L s [f ψ s −1 σ ]<label>(4)</label></formula><p>We will refer to such a parameterization of filters as Steerable Filters because the scaling of these filters is the transformation of its parameters. Note that we may construct steerable filters from any function. This has the important consequence that it does not restrict our approach. Rather it will make the analysis easier for discrete data. Moreover, note that any linear combination of steerable filters is still steerable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scale-Translation Group</head><p>All possible scales form the scaling group S. Here we consider the discrete scale group, i.e. scales of the form . . . a −1 , a −1 , 1, a, a 2 , . . . with base a as a parameter of our method. Analysis of this group by itself breaks the translation equivariance of CNNs. Thus we seek to incorporate scale and translation symmetries into CNNs, and, therefore consider the Scale-Translation Group H. It is a semidirect product of the scaling group S and the group of translations T ∼ = R. In other words: H = {(s, t)|s ∈ S, t ∈ T }. For multiplication of group elements, we have (s 2 , t 2 ) · (s 1 , t 1 ) = (s 2 s 1 , s 2 t 1 + t 2 ) and for the inverse (s 2 , t 2 ) −1 · (s 1 , t 1 ) = (s −1 2 s 1 , s −1 2 (t 1 − t 2 )). Additionally, for the corresponding scaling and translation transformations, we have L st = L s L t = L t L s , which means that the order of the operations matters.</p><p>From now on, we will work with functions defined on groups, i.e. mappings H → R. Note, that simple function f : R → R may be considered as a function on H with constant value along the S axis. Therefore, Equation 4 holds true for functions on H as well. One thing we should keep in mind is that when we apply L s to functions on H and R we use different notations. For example</p><formula xml:id="formula_4">L s [f ](x ) = f (s −1 x ) and L s [f ](s , t ) = f ((s, 0) −1 (s , t )) = f (s −1 s , s −1 t )</formula><p>Group-Equivariant Convolution Given group G and two functions f and ψ defined on it, Gequivariant convolution is given by</p><formula xml:id="formula_5">[f G ψ](g) = G f (g )L g [ψ](g )dµ(g ) = G f (g )ψ(g −1 g )dµ(g )<label>(5)</label></formula><p>Here µ(g ) is the Haar measure also known as invariant measure Folland (2016). For T ∼ = R we have dµ(g ) = dg . For discrete groups, the Haar measure is the counting measure, and integration becomes a discrete sum. This formula tells us that the output of the convolution evaluated at point g is the inner product between the function f and the transformed filter L g [ψ].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SCALE-EQUIVARIANT MAPPINGS</head><p>Now we define the main building blocks of scale-equivariant models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scale Convolution</head><p>In order to derive scale convolution, we start from group equivariant convolution with G = H. We first use the property of semidirect product of groups which splits the integral, then choose the appropriate Haar measures, and finally use the properties of steerable filters. Given the function f (s, t) and a steerable filter ψ σ (s, t) defined on H, a scale convolution is given by:</p><formula xml:id="formula_6">[f H ψ σ ](s, t) = S T f (s , t )L st [ψ σ ](s , t )dµ(s )dµ(t ) = s T f (s , t )ψ sσ (s −1 s , t − t)dt = s [f (s , ·) ψ sσ (s −1 s , ·)](t)<label>(6)</label></formula><p>And for the case of C in input and C out output channels we have:</p><formula xml:id="formula_7">[f H ψ σ ] m (s, t) = Cin n=1 s [f n (s , ·) ψ n,m,sσ (s −1 s , ·)](t), m = 1 . . . C out<label>(7)</label></formula><p>The proof of the equivariance of this convolution to transformations from H is given in Appendix A. <ref type="bibr" target="#b19">Kondor &amp; Trivedi (2018)</ref> prove that a feed-forward neural network is equivariant to transformations from G if and only if it is constructed from G-equivariant convolutional layers. Thus Equation <ref type="formula" target="#formula_7">7</ref> shows the most general form of scale-equivariant layers which allows for building scale-equivariant convolutional networks with such choice of S. We will refer to models using scale-equivariant layers with steerable filters as Scale-Equivariant Steerable Networks, or shortly SESN 1</p><p>Nonlinearities In order to guarantee the equivariance of the network to scale transformations, we use scale equivariant nonlinearities. We are free to use simple point-wise nonlinearities. Indeed, point-wise nonlinearities ν, like ReLU, commute with scaling transformations:</p><formula xml:id="formula_8">[ν • L s [f ]](s , x ) = ν(L s [f ](s , x )) = ν(f (s −1 s , s −1 x )) = ν[f ](s −1 s , s −1 x ) = [L s • ν[f ]](s , x ) (8)</formula><p>Pooling Until now we did not discuss how to convert an equivariant mapping to invariant one. One way to do this is to calculate the invariant measure of the signal. In case of translation, such a measure could be the maximum value for example.</p><p>First, we propose the maximum scale projection defined as f (s, x) → max s f (s, x). This transformation projects the function f from H to T . Therefore, the representation stays equivariant to scaling, but loses all information about the scale itself.</p><p>Second, we are free to use spatial max-pooling with a moving window or global max pooling. Trans-</p><formula xml:id="formula_9">formation f (s, x) → max x f (s, x)</formula><p>projects the function f from H to S. The obtained representation is invariant to scaling in spatial domain, however, it stores the information about scale.</p><p>Finally, we can combine both of these pooling mechanisms in any order. The obtained transformation produces a scale invariant function. It is useful to utilize this transformation closer to the end of the network, when the deep representation must be invariant to nuisance input variations, but already has very rich semantic meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IMPLEMENTATION</head><p>In this paragraph we discuss an efficient implementation of Scale-Equivariant Steerable Networks. We illustrate all algorithms in <ref type="figure" target="#fig_0">Figure 1</ref>. For simplicity we assume that zero padding is applied when it is needed for both the spatial axes and the scale axis.</p><p>Filter Basis A direct implementation of Equation 7 is impossible due to several limitations. First, the infinite number of scales in S calls for a discrete approximation. We truncate the scale group and limit ourselves to N S scales and use discrete translations instead of continuous ones. Training of SESN involves searching for the optimal filter in functional space which is a problem by itself. Rather than solving it directly, we choose a complete basis of N b steerable functions</p><formula xml:id="formula_10">Ψ = {ψ s −1 σ,i } N b i=1</formula><p>and represent convolutional filter as a linear combination of basis functions with</p><formula xml:id="formula_11">trainable parameters w = {w i } N b i=1 .</formula><p>In other words, we do the following substitution in Equation 7:</p><formula xml:id="formula_12">ψ σ → κ = i w i Ψ i</formula><p>In our experiments we use a basis of 2D Hermite polynomials with 2D Gaussian envelope, as it demonstrates good results. The basis is pre-calculated for all scales and fixed. For filters of size V × V , the basis is stored as an array of shape [N b , S, V, V ]. See Appendix C for more details.</p><p>Conv T → H If the input signal is just a function on T with spatial size U × U , stored as an array of shape [C in , U, U ], then Equation 7 can be simplified. The summation over S degenerates, and the final result can be written in the following form:</p><formula xml:id="formula_13">convTH(f, w, Ψ) = squeeze(conv2d(f, expand(w × Ψ)))<label>(9)</label></formula><p>Here w is an array of shape</p><formula xml:id="formula_14">[C out , C in , N b ]. We compute filter w × Ψ of shape [C out , C in , S, V, V ] and expand it to shape [C out , C in S, V, V ].</formula><p>Then we use standard 2D convolution to produce the output with C out S channels and squeeze it to shape [C out , S, U, U ]. Note that the output can be viewed as a stack of feature maps, where all the features in each spatial position are vectors of S components instead of being scalars as in standard CNNs.</p><p>Conv H → H The function on H has a scale axis and therefore there are two options for choosing weights of the convolutional filter. The filter may have just one scale and, therefore, does not capture the correlations between different scales of the input function; or, it may have a non-unitary extent K S in the scale axis and capture the correlation between K S neighboring scales. We refer to the second case as interscale interaction.</p><p>It the first case w has shape [C out , C in , N b ] and Equation 7 degenerates in the same way as before</p><formula xml:id="formula_15">convHH(f, w, Ψ) = squeeze(conv2d(expand(f ), expand(w × Ψ)))<label>(10)</label></formula><p>We expand f to an array of shape [C in S, U, U ] and expand w × Ψ to have shape</p><formula xml:id="formula_16">[C out S, C in S, V, V ].</formula><p>The result of the convolution is then squeezed in the same way as before.</p><p>In the case of interscale interaction, w has shape [C out , C in , K S , N b ]. We iterate over all scales in interaction, shift f for each scale, choose a corresponding part of w, and apply convHH to them. We sum the obtained K S results afterwards.   <ref type="formula" target="#formula_0">(2019)</ref> and SS- <ref type="bibr">CNN Ghosh &amp; Gupta (2019)</ref>. "Interscale" refers to the ability of capturing interscale interactions with kernels of non-unitary scale extent. "Grid" stands for the scales which generate images which lie exactly on the initial pixel grid. They use filter dilation to analyze the images on different scales. While this approach is as fast as the standard CNN, it is restricted only to integer downscale factors 2, 4, 8 . . . . In <ref type="bibr" target="#b10">Ghosh &amp; Gupta (2019)</ref>, while discussing SS-CNN the authors use scale-steerable filters to deal with scale changes. The paper does not discuss equivariance, which is an important aspect for scale.</p><p>We summarize the information about these models in <ref type="table">Table 1</ref>. In contrast to other scale-equivariant models, SESN uses steerable filters which allows for fast scale-convolution with no limitation of flexibility. With the framework of Scale-Equivariant Convolutional Networks we are free to build both equivariant and invariant models of different kinds.   <ref type="table">Table 2</ref>: Classification error of different methods on MNIST-scale dataset, lower is better. In experiment we use image resolution of 28 × 28 and 56 × 56. We test both the regime without data augmentation, and the regime with scaling data augmentation, denoted with "+". All results are reported as mean ± std over 6 different fixed realizations of the dataset. The best results are bold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">EQUIVARIANCE ERROR</head><p>We have presented scale-convolution which is equivariant to scale transformation and translation for continuous signals. While translation equivariance holds true even for discretized signals and filters, scale equivariance may not be exact. Therefore, before starting any experiments, we check to which degree the predicted properties of scale-convolution hold true. We do so by measuring the difference</p><formula xml:id="formula_17">∆ = [L s Φ(f ) − ΦL s (f ) 2 2 / L s Φ(f ) 2 2 , where Φ is scale-convolution with randomly initialized weights.</formula><p>In case of perfect equivariance the difference is equal to zero. We calculate the error on randomly sampled images from the STL-10 dataset <ref type="bibr" target="#b1">Coates et al. (2011)</ref>. The results are represented in <ref type="figure" target="#fig_2">Figure 2</ref>. The networks on the left and on the middle plots do not have interscale interactions. The networks on the middle and on the right plots consist of just one layer. We use N S = 5, 13, 5 scales for the networks on the left, the middle, and the right plots respectively. While discretization introduces some error, it stays very low, and is not much higher than 6% for the networks with 50 layers. The difference, however, increases if the input image is downscaled more than 16 times. Therefore, we are free to use deep networks. However, we should pay extra attention to extreme cases where scale changes are of very big magnitude. These are quite rare but still appear in practice. Finally, we see that using SESN with interscale interaction introduces extra equivariance error due to the truncation of S. We will build the networks with either no scale interaction or interaction of 2 scales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">MNIST-SCALE</head><p>Following <ref type="bibr" target="#b15">Kanazawa et al. (2014)</ref>; <ref type="bibr" target="#b22">Marcos et al. (2018)</ref>; <ref type="bibr" target="#b10">Ghosh &amp; Gupta (2019)</ref> we conduct experiments on the MNIST-scale dataset. We rescale the images of the MNIST dataset <ref type="bibr" target="#b20">LeCun et al. (1998)</ref> to 0.3 − 1.0 of the original size and pad them with zeros to retain the initial resolution. The scaling factors are sampled uniformly and independently for each image. The obtained dataset is then split into 10,000 for training, 2,000 for evaluation and 50,000 for testing. We generate 6 different realizations and fix them for all experiments.</p><p>As a baseline model we use the model described in <ref type="bibr" target="#b10">Ghosh &amp; Gupta (2019)</ref>, which currently holds the state-of-the-art result on this dataset. It consists of 3 convolutional and 2 fully-connected layers. Each layer has filters of size 7 × 7. We keep the number of trainable parameters almost the same for all tested methods. This is achieved by varying the number of channels. For scale equivariant models we add scale projection at the end of the convolutional block.</p><p>For SiCNN, DSS, SEVF and our model, we additionally train counterparts where after each convolution, an extra projection layer is inserted. Projection layers transform vector features in each spatial position of each channel into scalar ones. All of the layers have now scalar inputs instead of vector inputs. Therefore, we denote these models with "Scalar". The original models are denoted as "Vector". The exact type of projection depends on the way the vector features are constructed. For SiCNN, DSS, and SESN, we use maximum pooling along the scale dimension, while for SEVF, it is a calculation of the L 2 -norm of the vector.</p><p>All models are trained with the Adam optimizer Kingma &amp; Ba (2014) for 60 epochs with a batch size of 128. Initial learning rate is set to 0.01 and divided by 10 after 20 and 40 epochs. We conduct the experiments with 4 different settings. Following the idea discussed in <ref type="bibr" target="#b10">Ghosh &amp; Gupta (2019)</ref>, in addition to the standard setting we train the networks with input images upscaled to 56 × 56 using bilinear interpolation. This results in all image transformations performed by the network becoming more stable, which produces less interpolation artifacts. For both input sizes we conduct the experiments without data augmentation and with scaling augmentation, which results in 4 setups in total. We run the experiments on 6 different realizations of MNIST-scale and report mean ± std calculated over these runs.</p><p>The obtained results are summarized in <ref type="table">Table 2</ref>. The reported errors may differ a bit from the ones in the original paper because of the variations in generated datasets and slightly different training procedure. Nevertheless, we try to keep our configuration as close as possible to <ref type="bibr" target="#b10">Ghosh &amp; Gupta (2019)</ref> which currently demonstrated the best classification accuracy on MNIST-scale. For example, SS-CNN reports error of 1.91 ± 0.04 in <ref type="bibr" target="#b10">Ghosh &amp; Gupta (2019)</ref> while it has 1.84 ± 0.10 in our experiments.</p><p>SESN significantly outperforms other methods in all 4 regimes. "Scalar" versions of it already outperform all previous methods, and "Vector" versions make the gain even more significant. The global architectures of all models are the same for all rows, which indicates that the way scale convolution is done plays an important role.  We additionally report the current best result achieved by Harm WRN from <ref type="bibr" target="#b27">Ulicny et al. (2019)</ref>.</p><p>In order to evaluate the role of scale equivariance in natural image classification, we conduct the experiments on STL-10 dataset <ref type="bibr" target="#b1">Coates et al. (2011)</ref>. This dataset consists of 8,000 training and 5,000 testing labeled images. Additionally, it includes 100,000 unlabeled images. The images have a resolution of 96×96 pixels and RGB channels. Labeled images belong to 10 classes such as bird, horse or car. We use only the labeled subset to demonstrate the performance of the models in the low data regime.</p><p>The dataset is normalized by subtracting the per-channel mean and dividing by the per-channel standard deviation. During training, we augment the dataset by applying 12 pixel zero padding and randomly cropping the images to size 96 × 96. Additionally, random horizontal flips with probability 50% and Cutout DeVries &amp; Taylor (2017) with 1 hole of 32 pixels are used.</p><p>As a baseline we choose WideResNet <ref type="bibr" target="#b36">Zagoruyko &amp; Komodakis (2016)</ref> with 16 layers and a widening factor of 8. We set dropout probability to 0.3 in all blocks. We train SESN-A with just vector features. For SESN-B we use maximum scalar projection several times in the intermediate layers, and for SESN-C we use interscale interaction.</p><p>All models are trained for 1000 epochs with a batch size of 128. We use SGD optimizer with Nesterov momentum of 0.9 and weight decay of 5 · 10 −4 . The initial learning rate is set to 0.1 and divided by 5 after 300, 400, 600 and 800 epochs.</p><p>The results are summarized in <ref type="table" target="#tab_3">Table 3</ref>. We found SEVF training unstable and therefore do not include it in the table. Pure scale-invariant SI-ConvNet and SS-CNN demonstrate significantly worse results than the baseline. We note the importance of equivariance for deep networks. We also find that SESN-C performs significantly worse than SESN-A and SESN-B due to high equivariance error caused by interscale interaction. SESN-B significantly improves the results of both WRN and DSS due to the projection between scales. The maximum scale projection makes the weights of the next layer to have a maximum receptive field in the space of scales. This is an easy yet effective method for capturing the correlations between different scales. This experiment shows that scale-equivariance is a very useful inductive bias for natural image classification with deep neural networks.</p><p>To the best of our knowledge, the proposed method achieves a new state-of-the-art result on the STL-10 dataset in the supervised learning setting. The previous lowest error is demonstrated in <ref type="bibr" target="#b27">Ulicny et al. (2019)</ref>. The authors propose Harm WRN -a network where the convolutional kernels are represented as a linear combination of Discrete Cosine Transform filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">DISCUSSION</head><p>In this paper, we have presented the theory of Scale-Equivariant Steerable Networks. We started from the scaling transformation and its application to continuous functions. We have obtained the exact formula for scale-equivariant mappings and demonstrated how it can be implemented for discretized signals. We have demonstrated that this approach outperforms other methods for scale-equivariant and local scale-invariant CNNs. It demonstrated new state-of-the-art results on MNIST-scale and on the STL-10 dataset in the supervised learning setting.</p><p>We suppose that the most exciting possible application of SESN is in computer vision for autonomous vehicles. Rapidly changing distances between the objects cause significant scale variations which makes this well suited for our work. We especially highlight the direction of siamese visual tracking where the equivariance to principle transformations plays an important role.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROOF OF EQUIVARIANCE</head><p>Let us first show that scale-convolution defined in Equation 6 is equivariant to translations.</p><p>[</p><formula xml:id="formula_18">Lt[f ] H ψ σ ](s, t) = s [Lt[f ](s , ·) ψ sσ (s −1 s , ·)](t) = s Lt[f (s , ·) ψ sσ (s −1 s , ·)](t) = Lt s [f (s , ·) ψ sσ (s −1 s , ·)] (t) = Lt[f H ψ σ ](s, t)<label>(11)</label></formula><p>Now we show that scale convolution is equivariant to scale transformations:</p><formula xml:id="formula_19">[Lŝ[f ] H ψ σ ](s, t) = s [Lŝ[f ](s , ·) ψ sσ (s −1 s , ·)](t) = s Lŝ[f (ŝ −1 s , ·) ψŝ−1 sσ (s −1 s , ·)](t) = s [f (s , ·) ψŝ−1 sσ (ŝs −1 s , ·)](ŝ −1 t) = [f H ψ σ ](ŝ −1 s,ŝ −1 t) = Lŝ[f H ψ σ ](s, t)<label>(12)</label></formula><p>Finally, we can use the property of semidirect product of groups  <ref type="table" target="#tab_6">Table 4</ref>. Experimental setups from Section 6.2 are used. We used 1 Nvidia GeForce GTX 1080Ti GPU for training the models.</p><p>The methods relying on image rescaling techniques during training (SiCNN, SI-ConvNet, SEVF) demonstrate significantly worse time performance that the ones, using either steerable filters or filter dilation. Additionally, we see that our method outperforms SS-CNN by a wide margin. Despite the similar filter sizes and comparable number of parameters between SS-CNN and SESN Scalar, the second one demonstrates significantly better results due to the algorithm proposed in Section 4. Finally, DSS performs slightly faster in some cases than our method as each convolution involves less FLOPs. Dilated filters are sparse, while steerable filters are dense.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C BASIS</head><p>Assuming that the center of the filter is point (0, 0) in coordinates (x, y), we use the filters of the following form:</p><formula xml:id="formula_20">ψ σ (x, y) = A 1 σ 2 H n x σ H m y σ exp − x 2 + y 2 2σ 2<label>(14)</label></formula><p>Here A is a constant independent on σ, H n -Hermite polynomial of the n-th order. We iterate over increasing pairs of n, m to generate the required number of functions.   <ref type="table">Table 6</ref>: Number of channels in convolutional blocks and number of scales used by different models in Section 6.2. We report the number of channels up to the widening factor.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Left: the way steerable filters are computed using steerable filter basis. Middle and right: a representation of scale-convolution using Equation 9 and Equation 10. As an example we use input signal f with 3 channels. It has 1 scale on T and 4 scales on H. It is convolved with filter κ = w ×Ψ without scale interaction, which produces the output with 2 channels and 4 scales as well. Here we represent only channels of the signals and the filter. Spatial components are hidden for simplicity.5 RELATED WORKVarious works on group-equivariant convolutional networks have been published recently. These works have considered roto-translation groups in 2D Cohen &amp; Welling (2016a); Hoogeboom et al. (2018); Worrall et al. (2017); Weiler &amp; Cesa (2019) and 3D Worrall &amp; Brostow (2018); Kondor (2018); Thomas et al. (2018) and rotation equivariant networks in 3D Cohen et al. (2017); Esteves et al. (2018); Cohen et al. (2019</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc><ref type="bibr" target="#b22">Marcos et al. (2018)</ref>, in the SEVF model, the input of the layers is rescaled and convolved multiple times to form vector features instead of scalar ones. The length of the vector in each position is the maximum magnitude of the convolution, while the direction of the angle encodes the scale of the image which gave this response. These scale-equivariant networks rely on image rescaling which is quite slow. Worrall &amp; Welling (2019) (DSS) generalize the concept of scale-space to deep networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Equivariance error ∆ as a function of the number of layers (left), downscaling applied to the input image (middle), and as a function of number of scales in interscale interactions (right</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>To date, the majority of papers on group equivariant networks have considered rotations in 2D and 3D, but have not payed attention to scale symmetry. As we have argued above, it is a fundamentally different case.Many papers and even conferences have been dedicated to image scale-space -a concept where the image is analyzed together with all its downscaled versions. Initially introduced in<ref type="bibr" target="#b13">Iijima (1959)</ref> and later developed by Witkin (1987);<ref type="bibr" target="#b24">Perona &amp; Malik (1990)</ref>;<ref type="bibr" target="#b21">Lindeberg (2013)</ref> scale space relies on the scale symmetry of images. The differential structure of the image Koenderink (1984) allows one to make a connection between image formation mechanisms and the space of solutions of the 2dimensional heat equation, which significantly improved the image analysis models in the pre-deep learning era.</figDesc><table><row><cell>Method</cell><cell>Equivariance Admissible Scales</cell><cell>Approach</cell><cell>Interscale</cell></row><row><cell>SiCNN</cell><cell>Grid</cell><cell>Filter Rescaling</cell><cell></cell></row><row><cell>SI-ConvNet</cell><cell>Grid</cell><cell>Input Rescaling</cell><cell></cell></row><row><cell>SEVF</cell><cell>Grid</cell><cell>Input Rescaling</cell><cell></cell></row><row><cell>DSS</cell><cell>Integer</cell><cell>Filter Dilation</cell><cell></cell></row><row><cell>SS-CNN</cell><cell>Any</cell><cell>Steerable Filters</cell><cell></cell></row><row><cell>SESN, Ours</cell><cell>Any</cell><cell>Steerable Filters</cell><cell></cell></row><row><cell cols="4">Table 1: Comparing SESN to SiCNN Xu et al. (2014), SI-ConvNet Kanazawa et al. (2014), SEVF</cell></row><row><cell cols="2">Marcos et al. (2018), DSS Worrall &amp; Welling</cell><cell></cell><cell></cell></row></table><note>). In Freeman &amp; Adelson (1991) authors describe the algorithm for designing steerable filters for rotations. Rotation steerable filters are used in Cohen &amp; Welling (2016b); Weiler et al. (2018a;b) for building equivariant networks. In Jacobsen et al. (2017) the authors build convolutional blocks locally equivariant to arbitrary k-parameter Lie group by using a steerable basis. And in Murugan et al. the authors discuss the approach for learning steerable filters from data.One of the first works on scale equivariance and local scale invariance in the framework of CNNs was proposed by Xu et al. (2014) named SiCNN. The authors describe the model with siamese CNNs, where the filters of each instance are rescaled using interpolation techniques. This is the simplest case of equivariance where no interaction between different scales is done in intermediate layers. In SI-ConvNet by Kanazawa et al. (2014) the original network is modified such that, in each layer, the input is first rescaled, then convolved and rescaled back to the original size. Finally, the response with the maximum values is chosen between the scales. Thus, the model is locally scale-invariant. In</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Classification error on STL-10. The best results are bold.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Lŝt[f ] H ψ σ = LŝLt[f ] H ψ σ = Lŝ[Lt[f ] H ψ σ ] = LŝLt[f H ψ σ ] = Lŝt[f H ψ σ ] (13) B TIME PERFORMANCEWe report the average time per epoch of different methods for scale equivariance and local scale invariance in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Average time per epoch during training on input data with resolution 28 × 28 and 56 × 56.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Number of channels in convolutional layers, number of units in fully-connected layers and number of scales used by different models in Section 6.2.</figDesc><table><row><cell>D.2 STL-10</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell cols="4">Block 1 Block 2 Block 3 # Scales</cell></row><row><cell>CNN</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>1</cell></row><row><cell>SiCNN</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>3</cell></row><row><cell>SI-ConvNet</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>3</cell></row><row><cell>SEVF</cell><cell>11</cell><cell>23</cell><cell>45</cell><cell>3</cell></row><row><cell>DSS</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>4</cell></row><row><cell>SS-CNN</cell><cell>11</cell><cell>22</cell><cell>44</cell><cell>3</cell></row><row><cell>SESN</cell><cell>16</cell><cell>32</cell><cell>64</cell><cell>3</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">pronounced 'season'</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We thank Daniel Worrall for insightful discussion, Thomas Andy Keller, Victor Garcia, Artem Moskalev and Konrad Groh for valuable comments and feedback.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Invariance and neural nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Etienne</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Casasent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on neural networks</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="498" to="508" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">An analysis of single-layer networks in unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the fourteenth international conference on artificial intelligence and statistics</title>
		<meeting>the fourteenth international conference on artificial intelligence and statistics</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="215" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Group equivariant convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2990" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Köhler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.04893</idno>
		<title level="m">Convolutional networks for spherical signals</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Taco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.08498</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Steerable cnns. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Taco S Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berkay</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kicanaoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.04615</idno>
		<title level="m">Gauge equivariant convolutional networks and the icosahedral cnn</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved regularization of convolutional neural networks with cutout</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning so (3) equivariant representations with spherical cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Esteves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Allen-Blanchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameesh</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="52" to="68" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A course in abstract harmonic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Folland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The design and use of steerable filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Edward H Adelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis &amp; Machine Intelligence</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="891" to="906" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohan</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Anupam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.03861</idno>
		<title level="m">Scale steerable filters for locally scale-invariant convolutional neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Warped convolutions: Efficient invariance to spatial transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1461" to="1469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emiel</forename><surname>Hoogeboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Jorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Taco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hexaconv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02108</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Basic theory of pattern observation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taizo</forename><surname>Iijima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technical Group on Automata and Automatic Control</title>
		<imprint>
			<biblScope unit="page" from="3" to="32" />
			<date type="published" when="1959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bert</forename><forename type="middle">De</forename><surname>Brabandere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold Wm</forename><surname>Smeulders</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.00598</idno>
		<title level="m">Dynamic steerable blocks in deep residual networks</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Jacobs</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.5104</idno>
		<title level="m">Locally scale-invariant convolutional neural networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The structure of images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Koenderink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological cybernetics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="363" to="370" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<idno type="arXiv">arXiv:1803.01588</idno>
		<title level="m">Risi Kondor. N-body networks: a covariant hierarchical neural network architecture for learning atomic potentials</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">On the generalization of equivariance and convolution in neural networks to the action of compact groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubhendu</forename><surname>Trivedi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.03690</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Léon</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Scale-space theory in computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Lindeberg</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">256</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Kellenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Lobry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devis</forename><surname>Tuia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.11783</idno>
		<title level="m">Scale equivariance in cnns with vector fields</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">So (2)-equivariance in neural networks using tensor nonlinearity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muthuvel</forename><surname>Murugan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Subrahmanyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Siruseri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Scale-space and edge detection using anisotropic diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="629" to="639" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai Sheng</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Bailis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Valiant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.11399</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Equivariant transformer networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tess</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lusann</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Kohlhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08219</idno>
		<title level="m">Tensor field networks: Rotation-and translation-equivariant neural networks for 3d point clouds</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Ulicny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rozenn</forename><surname>Krylov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahyot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.00135</idno>
		<title level="m">Harmonic networks with limited training samples</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">General e (2)-equivariant steerable cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Cesa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14334" to="14345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">3d steerable cnns: Learning rotationally equivariant features in volumetric data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wouter</forename><surname>Boomsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10381" to="10392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning steerable filters for rotation equivariant cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Storath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="849" to="858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scale-space filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew P Witkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings in Computer Vision</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="329" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Cubenet: Equivariance to 3d rotation and translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="567" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Deep scale-spaces: Equivariance over scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11697</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Harmonic networks: Deep translation and rotation equivariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">J</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniyar</forename><surname>Garbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><forename type="middle">J</forename><surname>Turmukhambetov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5028" to="5037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianjun</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.6369</idno>
		<title level="m">Scale-invariant convolutional neural networks</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Wide residual networks. arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
