<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Large-Scale Evolution of Image Classifiers</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esteban</forename><surname>Real</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherry</forename><surname>Moore</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Selle</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Saxena</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutaka</forename><forename type="middle">Leon</forename><surname>Suematsu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
						</author>
						<title level="a" type="main">Large-Scale Evolution of Image Classifiers</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T10:59+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Our goal is to minimize human participation, so we employ evolutionary algorithms to discover such networks automatically. Despite significant computational requirements, we show that it is now possible to evolve models with accuracies within the range of those published in the last year. Specifically, we employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions and reaching accuracies of 94.6% (95.6% for ensemble) and 77.0%, respectively. To do this, we use novel and intuitive mutation operators that navigate large search spaces; we stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Neural networks can successfully perform difficult tasks where large amounts of training data are available <ref type="bibr" target="#b11">(He et al., 2015;</ref><ref type="bibr" target="#b41">Weyand et al., 2016;</ref><ref type="bibr" target="#b27">Silver et al., 2016;</ref><ref type="bibr" target="#b42">Wu et al., 2016)</ref>. Discovering neural network architectures, however, remains a laborious task. Even within the specific problem of image classification, the state of the art was attained through many years of focused investigation by hundreds of researchers <ref type="bibr" target="#b18">(Krizhevsky et al. (2012)</ref>; Simonyan &amp; Zisserman (2014); <ref type="bibr" target="#b37">Szegedy et al. (2015)</ref>; <ref type="bibr" target="#b12">He et al. (2016)</ref>; <ref type="bibr" target="#b13">Huang et al. (2016a)</ref>, among many others).</p><p>Proceedings of the 34 th International Conference on Machine Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017 by the author(s).</p><p>It is therefore not surprising that in recent years, techniques to automatically discover these architectures have been gaining popularity <ref type="bibr" target="#b3">(Bergstra &amp; Bengio, 2012;</ref><ref type="bibr" target="#b30">Snoek et al., 2012;</ref><ref type="bibr" target="#b10">Han et al., 2015;</ref><ref type="bibr" target="#b1">Baker et al., 2016;</ref><ref type="bibr" target="#b45">Zoph &amp; Le, 2016)</ref>. One of the earliest such "neuro-discovery" methods was neuro-evolution <ref type="bibr" target="#b22">(Miller et al., 1989;</ref><ref type="bibr" target="#b34">Stanley &amp; Miikkulainen, 2002;</ref><ref type="bibr" target="#b33">Stanley, 2007;</ref><ref type="bibr" target="#b2">Bayer et al., 2009;</ref><ref type="bibr" target="#b35">Stanley et al., 2009;</ref><ref type="bibr" target="#b4">Breuel &amp; Shafait, 2010;</ref><ref type="bibr" target="#b24">Pugh &amp; Stanley, 2013;</ref><ref type="bibr" target="#b16">Kim &amp; Rigazio, 2015;</ref><ref type="bibr" target="#b44">Zaremba, 2015;</ref><ref type="bibr" target="#b5">Fernando et al., 2016;</ref><ref type="bibr" target="#b23">Morse &amp; Stanley, 2016)</ref>. Despite the promising results, the deep learning community generally perceives evolutionary algorithms to be incapable of matching the accuracies of hand-designed models <ref type="bibr" target="#b39">(Verbancsics &amp; Harguess, 2013;</ref><ref type="bibr" target="#b1">Baker et al., 2016;</ref><ref type="bibr" target="#b45">Zoph &amp; Le, 2016)</ref>. In this paper, we show that it is possible to evolve such competitive models today, given enough computational power.</p><p>We used slightly-modified known evolutionary algorithms and scaled up the computation to unprecedented levels, as far as we know. This, together with a set of novel and intuitive mutation operators, allowed us to reach competitive accuracies on the CIFAR-10 dataset. This dataset was chosen because it requires large networks to reach high accuracies, thus presenting a computational challenge. We also took a small first step toward generalization and evolved networks on the CIFAR-100 dataset. In transitioning from CIFAR-10 to CIFAR-100, we did not modify any aspect or parameter of our algorithm. Our typical neuro-evolution outcome on CIFAR-10 had a test accuracy with µ = 94.1%, σ = 0.4% @ 9 × 10 19 FLOPs, and our top model (by validation accuracy) had a test accuracy of 94.6% @ 4×10 20 FLOPs. Ensembling the validation-top 2 models from each population reaches a test accuracy of 95.6%, at no additional training cost. On CIFAR-100, our single experiment resulted in a test accuracy of 77.0% @ 2 × 10 20 FLOPs. As far as we know, these are the most accurate results obtained on these datasets by automated discovery methods that start from trivial initial conditions. Throughout this study, we placed special emphasis on the simplicity of the algorithm. In particular, it is a "oneshot" technique, producing a fully trained neural network requiring no post-processing. It also has few impactful meta-parameters (i.e. parameters not optimized by the algorithm). Starting out with poor-performing models with <ref type="table">Table 1</ref>. Comparison with single-model hand-designed architectures. The "C10+" and "C100+" columns indicate the test accuracy on the data-augmented CIFAR-10 and CIFAR-100 datasets, respectively. The "Reachable?" column denotes whether the given handdesigned model lies within our search space. An entry of "-" indicates that no value was reported. The † indicates a result reported by <ref type="bibr" target="#b14">Huang et al. (2016b)</ref> instead of the original author. Much of this table was based on that presented in <ref type="bibr" target="#b13">Huang et al. (2016a)</ref> no convolutions, the algorithm must evolve complex convolutional neural networks while navigating a fairly unrestricted search space: no fixed depth, arbitrary skip connections, and numerical parameters that have few restrictions on the values they can take. We also paid close attention to result reporting. Namely, we present the variability in our results in addition to the top value, we account for researcher degrees of freedom <ref type="bibr" target="#b28">(Simmons et al., 2011)</ref>, we study the dependence on the meta-parameters, and we disclose the amount of computation necessary to reach the main results. We are hopeful that our explicit discussion of computation cost could spark more study of efficient model search and training. Studying model performance normalized by computational investment allows consideration of economic concepts like opportunity cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Neuro-evolution dates back many years <ref type="bibr" target="#b22">(Miller et al., 1989)</ref>, originally being used only to evolve the weights of a fixed architecture. <ref type="bibr" target="#b34">Stanley &amp; Miikkulainen (2002)</ref> showed that it was advantageous to simultaneously evolve the architecture using the NEAT algorithm. NEAT has three kinds of mutations: (i) modify a weight, (ii) add a connection between existing nodes, or (iii) insert a node while splitting an existing connection. It also has a mechanism for recombining two models into one and a strategy to promote diversity known as fitness sharing <ref type="bibr" target="#b7">(Goldberg et al., 1987)</ref>. Evolutionary algorithms represent the models using an encoding that is convenient for their purposeanalogous to nature's DNA. NEAT uses a direct encoding: every node and every connection is stored in the DNA. The alternative paradigm, indirect encoding, has been the subject of much neuro-evolution research <ref type="bibr" target="#b9">(Gruau, 1993;</ref><ref type="bibr" target="#b35">Stanley et al., 2009;</ref><ref type="bibr" target="#b24">Pugh &amp; Stanley, 2013;</ref><ref type="bibr" target="#b16">Kim &amp; Rigazio, 2015;</ref><ref type="bibr" target="#b5">Fernando et al., 2016)</ref>. For example, the CPPN <ref type="bibr" target="#b33">(Stanley, 2007;</ref><ref type="bibr" target="#b35">Stanley et al., 2009</ref>) allows for the evolution of repeating features at different scales. Also, <ref type="bibr" target="#b16">Kim &amp; Rigazio (2015)</ref> use an indirect encoding to improve the convolution filters in an initially highly-optimized fixed architecture.</p><p>Research on weight evolution is still ongoing <ref type="bibr" target="#b23">(Morse &amp; Stanley, 2016)</ref> but the broader machine learning community defaults to back-propagation for optimizing neural network weights <ref type="bibr" target="#b25">(Rumelhart et al., 1988)</ref>. Back-propagation and evolution can be combined as in <ref type="bibr" target="#b35">Stanley et al. (2009)</ref>, where only the structure is evolved. Their algorithm follows an alternation of architectural mutations and weight back-propagation. Similarly, <ref type="bibr" target="#b4">Breuel &amp; Shafait (2010)</ref> use this approach for hyper-parameter search. <ref type="bibr" target="#b5">Fernando et al. (2016)</ref> also use back-propagation, allowing the trained weights to be inherited through the structural modifications.</p><p>The above studies create neural networks that are small in comparison to the typical modern architectures used for image classification <ref type="bibr" target="#b12">(He et al., 2016;</ref><ref type="bibr" target="#b13">Huang et al., 2016a)</ref>. Their focus is on the encoding or the efficiency of the evolutionary process, but not on the scale. When it comes to images, some neuro-evolution results reach the computational scale required to succeed on the MNIST dataset <ref type="bibr">(Le-Cun et al., 1998</ref>). Yet, modern classifiers are often tested on realistic images, such as those in the CIFAR datasets <ref type="bibr" target="#b17">(Krizhevsky &amp; Hinton, 2009)</ref>, which are much more challenging. These datasets require large models to achieve high accuracy.</p><p>Non-evolutionary neuro-discovery methods have been more successful at tackling realistic image data. <ref type="bibr" target="#b30">Snoek et al. (2012)</ref> used Bayesian optimization to tune 9 hyper-parameters for a fixed-depth architecture, reach- <ref type="table">Table 2</ref>. Comparison with automatically discovered architectures. The "C10+" and "C100+" contain the test accuracy on the dataaugmented CIFAR-10 and CIFAR-100 datasets, respectively. An entry of "-" indicates that the information was not reported or is not known to us. For <ref type="bibr" target="#b45">Zoph &amp; Le (2016)</ref>, we quote the result with the most similar search space to ours, as well as their best result. Please refer to <ref type="table">Table 1</ref>  In their approach, a neural network-the "discoverer"-constructs a convolutional neural network-the "discovered"-one layer at a time. In addition to tuning layer parameters, they add and remove skip connections. This, together with some manual postprocessing, gets them very close to the (current) state of the art. (Additionally, they surpassed the state of the art on a sequence-to-sequence problem.) <ref type="bibr" target="#b1">Baker et al. (2016)</ref> use Q-learning to also discover a network one layer at a time, but in their approach, the number of layers is decided by the discoverer. This is a desirable feature, as it would allow a system to construct shallow or deep solutions, as may be the requirements of the dataset at hand. Different datasets would not require specially tuning the algorithm. Comparisons among these methods are difficult because they explore very different search spaces and have very different initial conditions <ref type="table">(Table 2)</ref>.</p><p>Tangentially, there has also been neuro-evolution work on LSTM structure <ref type="bibr" target="#b2">(Bayer et al., 2009;</ref><ref type="bibr" target="#b44">Zaremba, 2015)</ref>, but this is beyond the scope of this paper. Also related to this work is that of <ref type="bibr" target="#b26">Saxena &amp; Verbeek (2016)</ref>, who embed convolutions with different parameters into a species of "supernetwork" with many parallel paths. Their algorithm then selects and ensembles paths in the super-network. Finally, canonical approaches to hyper-parameter search are grid search (used in <ref type="bibr" target="#b43">Zagoruyko &amp; Komodakis (2016)</ref>, for example) and random search, the latter being the better of the two <ref type="bibr" target="#b3">(Bergstra &amp; Bengio, 2012)</ref>.</p><p>Our approach builds on previous work, with some important differences. We explore large model-architecture search spaces starting with basic initial conditions to avoid priming the system with information about known good strategies for the specific dataset at hand. Our encoding is different from the neuro-evolution methods mentioned above: we use a simplified graph as our DNA, which is transformed to a full neural network graph for training and evaluation (Section 3). Some of the mutations acting on this DNA are reminiscent of NEAT. However, instead of single nodes, one mutation can insert whole layers-i.e. tens to hundreds of nodes at a time. We also allow for these layers to be removed, so that the evolutionary process can simplify an architecture in addition to complexifying it. Layer parameters are also mutable, but we do not prescribe a small set of possible values to choose from, to allow for a larger search space. We do not use fitness sharing. We report additional results using recombination, but for the most part, we used mutation only. On the other hand, we do use back-propagation to optimize the weights, which can be inherited across mutations. Together with a learning rate mutation, this allows the exploration of the space of learning rate schedules, yielding fully trained models at the end of the evolutionary process (Section 3). Tables 1 and 2 compare our approach with hand-designed architectures and with other neuro-discovery techniques, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Evolutionary Algorithm</head><p>To automatically search for high-performing neural network architectures, we evolve a population of models. Each model-or individual-is a trained architecture. The model's accuracy on a separate validation dataset is a measure of the individual's quality or fitness. During each evolutionary step, a computer-a worker-chooses two individuals at random from this population and compares their fitnesses. The worst of the pair is immediately removed from the population-it is killed. The best of the pair is selected to be a parent, that is, to undergo reproduction. By this we mean that the worker creates a copy of the parent and modifies this copy by applying a mutation, as described below. We will refer to this modified copy as the child. After the worker creates the child, it trains this child, evaluates it on the validation set, and puts it back into the population. The child then becomes alive-i.e. free to act as a parent. Our scheme, therefore, uses repeated pairwise competitions of random individuals, which makes it an example of tournament selection <ref type="bibr" target="#b6">(Goldberg &amp; Deb, 1991)</ref>. Using pairwise comparisons instead of whole population operations prevents workers from idling when they finish early. Code and more detail about the methods described below can be found in Supplementary Section S1.</p><p>Using this strategy to search large spaces of complex image models requires considerable computation. To achieve scale, we developed a massively-parallel, lock-free infrastructure. Many workers operate asynchronously on different computers. They do not communicate directly with each other. Instead, they use a shared file-system, where the population is stored. The file-system contains directories that represent the individuals. Operations on these individuals, such as the killing of one, are represented as atomic renames on the directory 2 . Occasionally, a worker may concurrently modify the individual another worker is operating on. In this case, the affected worker simply gives up and tries again. The population size is 1000 individuals, unless otherwise stated. The number of workers is always 1 4 of the population size. To allow for long run-times with a limited amount of space, dead individuals' directories are frequently garbage-collected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Encoding and Mutations</head><p>Individual architectures are encoded as a graph that we refer to as the DNA. In this graph, the vertices represent rank-3 tensors or activations. As is standard for a convo-lutional network, two of the dimensions of the tensor represent the spatial coordinates of the image and the third is a number of channels. Activation functions are applied at the vertices and can be either (i) batch-normalization <ref type="bibr" target="#b15">(Ioffe &amp; Szegedy, 2015)</ref> with rectified linear units (ReLUs) or (ii) plain linear units. The graph's edges represent identity connections or convolutions and contain the mutable numerical parameters defining the convolution's properties. When multiple edges are incident on a vertex, their spatial scales or numbers of channels may not coincide. However, the vertex must have a single size and number of channels for its activations. The inconsistent inputs must be resolved. Resolution is done by choosing one of the incoming edges as the primary one. We pick this primary edge to be the one that is not a skip connection. The activations coming from the non-primary edges are reshaped through zerothorder interpolation in the case of the size and through truncation/padding in the case of the number of channels, as in <ref type="bibr" target="#b12">He et al. (2016)</ref>. In addition to the graph, the learning-rate value is also stored in the DNA.</p><p>A child is similar but not identical to the parent because of the action of a mutation. In each reproduction event, the worker picks a mutation at random from a predetermined set. The set contains the following mutations:</p><p>• ALTER-LEARNING-RATE (sampling details below). • IDENTITY (effectively means "keep training").</p><p>• RESET-WEIGHTS (sampled as in <ref type="bibr" target="#b11">He et al. (2015)</ref>, for example). The inserted convolution has 3 × 3 filters, strides of 1 or 2 at random, number of channels same as input. May apply batch-normalization and ReLU activation or none at random). • REMOVE-CONVOLUTION.</p><p>• ALTER-STRIDE (only powers of 2 are allowed).</p><p>• ALTER-NUMBER-OF-CHANNELS (of random conv.).</p><p>• FILTER-SIZE (horizontal or vertical at random, on random convolution, odd values only). • INSERT-ONE-TO-ONE (inserts a one-to-one/identity connection, analogous to insert-convolution mutation). • ADD-SKIP (identity between random layers).</p><p>• REMOVE-SKIP (removes random skip).</p><p>These specific mutations were chosen for their similarity to the actions that a human designer may take when improving an architecture. This may clear the way for hybrid evolutionary-hand-design methods in the future. The probabilities for the mutations were not tuned in any way.</p><p>A mutation that acts on a numerical parameter chooses the new value at random around the existing value. All sampling is from uniform distributions. For example, a mutation acting on a convolution with 10 output channels will result in a convolution having between 5 and 20 output channels (that is, half to twice the original value). All values within the range are possible. As a result, the models are not constrained to a number of filters that is known to work well. The same is true for all other parameters, yielding a "dense" search space. In the case of the strides, this applies to the log-base-2 of the value, to allow for activation shapes to match more easily 3 . In principle, there is also no upper limit to any of the parameters. All model depths are attainable, for example. Up to hardware constraints, the search space is unbounded. The dense and unbounded nature of the parameters result in the exploration of a truly large set of possible architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Initial Conditions</head><p>Every evolution experiment begins with a population of simple individuals, all with a learning rate of 0.1. They are all very bad performers. Each initial individual constitutes just a single-layer model with no convolutions. This conscious choice of poor initial conditions forces evolution to make the discoveries by itself. The experimenter contributes mostly through the choice of mutations that demarcate a search space. Altogether, the use of poor initial conditions and a large search space limits the experimenter's impact. In other words, it prevents the experimenter from "rigging" the experiment to succeed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Training and Validation</head><p>Training and validation is done on the CIFAR-10 dataset. This dataset consists of 50,000 training examples and 10,000 test examples, all of which are 32 x 32 color images labeled with 1 of 10 common object classes <ref type="bibr" target="#b17">(Krizhevsky &amp; Hinton, 2009)</ref>. 5,000 of the training examples are held out in a validation set. The remaining 45,000 examples constitute our actual training set. The training set is augmented as in <ref type="bibr" target="#b12">He et al. (2016)</ref>. The CIFAR-100 dataset has the same number of dimensions, colors and examples as CIFAR-10, but uses 100 classes, making it much more challenging.</p><p>Training is done with TensorFlow <ref type="bibr" target="#b0">(Abadi et al., 2016)</ref>, using SGD with a momentum of 0.9 <ref type="bibr" target="#b36">(Sutskever et al., 2013)</ref>, a batch size of 50, and a weight decay of 0.0001. Each training runs for 25,600 steps, a value chosen to be brief enough so that each individual could be trained in a few seconds to a few hours, depending on model size. The loss function is the cross-entropy. Once training is complete, a single evaluation on the validation set provides the accuracy to use as the individual's fitness. Ensembling was done by majority voting during the testing evaluation. The models used in the ensemble were selected by validation accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Computation cost</head><p>To estimate computation costs, we identified the basic TensorFlow (TF) operations used by our model training and validation, like convolutions, generic matrix multiplications, etc. For each of these TF operations, we estimated the theoretical number of floating-point operations (FLOPs) required. This resulted in a map from TF operation to FLOPs, which is valid for all our experiments.</p><p>For each individual within an evolution experiment, we compute the total FLOPs incurred by the TF operations in its architecture over one batch of examples, both during its training (F t FLOPs) and during its validation (F v FLOPs). Then we assign to the individual the cost</p><formula xml:id="formula_0">F t N t + F v N v ,</formula><p>where N t and N v are the number of training and validation batches, respectively. The cost of the experiment is then the sum of the costs of all its individuals.</p><p>We intend our FLOPs measurement as a coarse estimate only. We do not take into account input/output, data preprocessing, TF graph building or memory-copying operations. Some of these unaccounted operations take place once per training run or once per step and some have a component that is constant in the model size (such as disk-access latency or input data cropping). We therefore expect the estimate to be more useful for large architectures (for example, those with many convolutions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Weight Inheritance</head><p>We need architectures that are trained to completion within an evolution experiment. If this does not happen, we are forced to retrain the best model at the end, possibly having to explore its hyper-parameters. Such extra exploration tends to depend on the details of the model being retrained. On the other hand, 25,600 steps are not enough to fully train each individual. Training a large model to completion is prohibitively slow for evolution. To resolve this dilemma, we allow the children to inherit the parents' weights whenever possible. Namely, if a layer has matching shapes, the weights are preserved. Consequently, some mutations preserve all the weights (like the identity or learning-rate mutations), some preserve none (the weightresetting mutation), and most preserve some but not all. An example of the latter is the filter-size mutation: only the filters of the convolution being mutated will be discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Reporting Methodology</head><p>To avoid over-fitting, neither the evolutionary algorithm nor the neural network training ever see the testing set. Each time we refer to "the best model", we mean the model with the highest validation accuracy. However, we always report the test accuracy. This applies not only to the choice of the best individual within an experiment, but also to the choice of the best experiment. Moreover, we only include experiments that we managed to reproduce, unless explicitly noted. Any statistical analysis was fully decided upon before seeing the results of the experiment reported, to avoid tailoring our analysis to our experimental data <ref type="bibr" target="#b28">(Simmons et al., 2011).</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head><p>We want to answer the following questions:</p><p>• Can a simple one-shot evolutionary process start from trivial initial conditions and yield fully trained models that rival hand-designed architectures? • What are the variability in outcomes, the parallelizability, and the computation cost of the method? • Can an algorithm designed iterating on CIFAR-10 be applied, without any changes at all, to CIFAR-100 and still produce competitive models?</p><p>We used the algorithm in Section 3 to perform several experiments. Each experiment evolves a population in a few days, typified by the example in <ref type="figure" target="#fig_1">Figure 1</ref>. The figure also contains examples of the architectures discovered, which turn out to be surprisingly simple. Evolution attempts skip connections but frequently rejects them.</p><p>To get a sense of the variability in outcomes, we repeated the experiment 5 times. Across all 5 experiment runs, the best model by validation accuracy has a testing accuracy of 94.6 %. Not all experiments reach the same accuracy, but they get close (µ = 94.1%, σ = 0.4). Fine differences in the experiment outcome may be somewhat distinguishable by validation accuracy (correlation coefficient = 0.894). The total amount of computation across all 5 experiments was 4×10 20 FLOPs (or 9×10 19 FLOPs on average per experiment). Each experiment was distributed over 250 parallel workers (Section 3.1). <ref type="figure" target="#fig_2">Figure 2</ref> shows the progress of the experiments in detail.</p><p>As a control, we disabled the selection mechanism, thereby reproducing and killing random individuals. This is the form of random search that is most compatible with our infrastructure. The probability distributions for the parameters are implicitly determined by the mutations. This control only achieves an accuracy of 87.3 % in the same amount of run time on the same hardware ( <ref type="figure" target="#fig_2">Figure 2)</ref>. The total amount of computation was 2×10 17 FLOPs. The low FLOP count is a consequence of random search generating many small, inadequate models that train quickly but consume roughly constant amounts of setup time (not included in the FLOP count). We attempted to minimize this overhead by avoiding unnecessary disk access operations, to no avail: too much overhead remains spent on a combination of neural network setup, data augmentation, and training step initialization.</p><p>We also ran a partial control where the weight-inheritance mechanism is disabled. This run also results in a lower accuracy (92.2 %) in the same amount of time <ref type="figure" target="#fig_2">(Figure 2</ref>), using 9×10 19 FLOPs. This shows that weight inheritance is important in the process.</p><p>Finally, we applied our neuro-evolution algorithm, without any changes and with the same meta-parameters, to CIFAR-100. Our only experiment reached an accuracy of 77.0 %, using 2 × 10 20 FLOPs. We did not attempt other datasets. <ref type="table">Table 1</ref> shows that both the CIFAR-10 and CIFAR-100 results are competitive with modern handdesigned networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Analysis</head><p>Meta-parameters. We observe that populations evolve until they plateau at some local optimum ( <ref type="figure" target="#fig_2">Figure 2</ref>). The fitness (i.e. validation accuracy) value at this optimum varies between experiments <ref type="figure" target="#fig_2">(Figure 2</ref>, inset). Since not all experiments reach the highest possible value, some populations are getting "trapped" at inferior local optima. This entrapment is affected by two important meta-parameters (i.e. parameters that are not optimized by the algorithm). These are the population size and the number of training steps per individual. Below we discuss them and consider their relationship to local optima.</p><p>Effect of population size. Larger populations explore the space of models more thoroughly, and this helps reach better optima <ref type="figure" target="#fig_3">(Figure 3, left)</ref>. Note, in particular, that a population of size 2 can get trapped at very low fitness values. Some intuition about this can be gained by considering the fate of a super-fit individual, i.e. an individual such that any one architectural mutation reduces its fitness (even though a sequence of many mutations may improve it). In the case of a population of size 2, if the super-fit individual wins once, it will win every time. After the first win, it will produce a child that is one mutation away. By definition of super-fit, therefore, this child is inferior 4 . Consequently, in the next round of tournament selection, the super-fit individual competes against its child and wins again. This cycle repeats forever and the population is trapped. Even if a sequence of two mutations would allow for an "escape" from the local optimum, such a sequence can never take place. This is only a rough argument to heuristically suggest why a population of size 2 is easily trapped. More generally, <ref type="figure" target="#fig_3">Figure 3</ref> (left) empirically demonstrates a benefit from an increase in population size. Theoretical analyses of this dependence are quite complex and assume very specific models of population dynamics; often larger populations are better at handling local optima, at least beyond a size threshold <ref type="bibr" target="#b40">(Weinreich &amp; Chao (2005)</ref>   therein). Effect of number of training steps. The other metaparameter is the number T of training steps for each individual. Accuracy increases with T <ref type="figure" target="#fig_3">(Figure 3, right)</ref>. Larger T means an individual needs to undergo fewer identity mutations to reach a given level of training. Escaping local optima. While we might increase population size or number of steps to prevent a trapped population from forming, we can also free an already trapped population. For example, increasing the mutation rate or resetting all the weights of a population <ref type="figure" target="#fig_4">(Figure 4</ref>) work well but are quite costly (more details in Supplementary Section S3). Recombination. None of the results presented so far used recombination. However, we explored three forms of recombination in additional experiments. Following <ref type="bibr" target="#b38">Tuson &amp; Ross (1998)</ref>, we attempted to evolve the mutation probability distribution too. On top of this, we employed a recombination strategy by which a child could inherit structure from one parent and mutation probabilities from another. The goal was to allow individuals that progressed well due to good mutation choices to quickly propagate such choices to others. In a separate experiment, we attempted recombining the trained weights from two parents in the hope that each parent may have learned different concepts from the training data. In a third experiment, we recombined structures so that the child fused the architectures of both parents side-by-side, generating wide models fast. While none of these approaches improved our recombination-free results, further study seems warranted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>In this paper we have shown that (i) neuro-evolution is capable of constructing large, accurate networks for two challenging and popular image classification benchmarks; (ii) neuro-evolution can do this starting from trivial initial conditions while searching a very large space; (iii) the process, once started, needs no experimenter participation; and (iv) the process yields fully trained models. Completely training models required weight inheritance (Sections 3.6). In contrast to reinforcement learning, evolution provides a natural framework for weight inheritance: mutations can be constructed to guarantee a large degree of similarity be- tween the original and mutated models-as we did. Evolution also has fewer tunable meta-parameters with a fairly predictable effect on the variance of the results, which can be made small.</p><p>While we did not focus on reducing computation costs, we hope that future algorithmic and hardware improvement will allow more economical implementation. In that case, evolution would become an appealing approach to neurodiscovery for reasons beyond the scope of this paper. For example, it "hits the ground running", improving on arbitrary initial models as soon as the experiment begins. The mutations used can implement recent advances in the field and can be introduced without having to restart an experiment. Furthermore, recombination can merge improvements developed by different individuals, even if they come from other populations. Moreover, it may be possible to combine neuro-evolution with other automatic architecture discovery methods.   <ref type="formula">(2560)</ref> to make it more likely for a population to get trapped and to reduce resource usage. Each dot represents an individual. The vertical axis is the accuracy. TOP: example of a population of size 100 escaping a local optimum by using a period of increased mutation rate in the middle (Section 5). BOTTOM: example of a population of size 50 escaping a local optimum by means of three consecutive weight resetting events (Section 5). Details in Supplementary Section S3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Material</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S1. Methods Details</head><p>This section contains additional implementation details, roughly following the order in Section 3. Short code snippets illustrate the ideas. The code is not intended to run on its own and it has been highly edited for clarity.</p><p>In our implementation, each worker runs an outer loop that is responsible for selecting a pair of random individuals from the population. The individual with the highest fitness usually becomes a parent and the one with the lowest fitness is usually killed (Section 3.1). Occasionally, either of these two actions is not carried out in order to keep the population size close to a set-point: Much of the code is wrapped in try-except blocks to handle various kinds of errors. These have been removed from the code snippets for clarity. For example, the method above would be wrapped like this:</p><p>def evolve_population(self): while True: try: # Select two random individuals from the population. ... except: except exceptions.PopulationTooSmallException: self._create_new_individual() continue except exceptions.ConcurrencyException: # Another worker did something that interfered with the action of this worker. # Abandon the current task and keep going. continue</p><p>The encoding for an individual is represented by a serializable DNA class instance containing all information except for the trained weights (Section 3.2). For all results in this paper, this encoding is a directed, acyclic graph where edges represent convolutions and vertices represent nonlinearities. This is a sketch of the DNA class:</p><p>class DNA(object):</p><p>def __init__(self, dna_proto): """Initializes the 'DNA' instance from a protocol buffer.</p><p>The 'dna_proto' is a protocol buffer used to restore the DNA state from disk. Together with the corresponding 'to_proto' method, they allow for a serialization-deserialization mechanism. """ # Allows evolving the learning rate, i. Mutations act on DNA instances. The set of mutations restricts the space explored somewhat (Section 3.2). The following are some example mutations. The AlterLearningRateMutation simply randomly modifies the attribute in the DNA:</p><p>class AlterLearningRateMutation(Mutation):</p><p>"""Mutation that modifies the learning rate.""" def mutate(self, dna): mutated_dna = copy.deepcopy(dna) # Mutate the learning rate by a random factor between 0.5 and 2.0, # uniformly distributed in log scale. factor = 2 ** random. For clarity, we omitted the details of a vertex ID targeting mechanism based on regular expressions, which is used to constrain where the additional edges are placed. This mechanism ensured the skip connections only joined points in the "main convolutional backbone" of the convnet. The precedence range is used to give the main backbone precedence over the skip connections when resolving scale and depth conflicts in the presence of multiple incoming edges to a vertex. Also omitted are details about the attributes of the edge to add. The training and evaluation (Section 3.4) is done in a fairly standard way, similar to that in the tensorflow.org tutorials for image models. The individual's fitness is the accuracy on a held-out validation dataset, as described in the main text.</p><p>Parents are able to pass some of their learned weights to their children (Section 3.6). When a child is constructed from a parent, it inherits IDs for the different sets of trainable weights (convolution filters, batch norm shifts, etc.). These IDs are embedded in the TensorFlow variable names. When the child's weights are initialized, those that have a matching ID in the parent are inherited, provided they have the same shape: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S2. FLOPs estimation</head><p>This section describes how we estimate the number of floating point operations (FLOPs) required for an entire evolution experiment. To obtain the total FLOPs, we sum the FLOPs for each individual ever constructed. An individual's FLOPs are the sum of its training and validation FLOPs. Namely, the individual FLOPs are given by F t N t + F v N v , where F t is the FLOPs in one training step, N t is the number of training steps, F v is the FLOPs required to evaluate one validation batch of examples and N v is the number of validation batches.</p><p>The number of training steps and the number of validation batches are known in advance and are constant throughout the experiment. F t was obtained analytically as the sum of the FLOPs required to compute each operation executed during training (that is, each node in the TensorFlow graph). F v was found analogously.</p><p>Below is the code snippet that computes FLOPs for the training of one individual, for example. Note that we also need to declare how to compute FLOPs for each operation type present (that is, for each node type in the TensorFlow graph). We did this for the following operation types (and their gradients, where applicable):</p><p>• unary math operations: square, squre root, log, negation, element-wise inverse, softmax, L2 norm;</p><p>• binary element-wise operations: addition, subtraction, multiplication, division, minimum, maximum, power, squared difference, comparison operations;</p><p>• reduction operations: mean, sum, argmax, argmin;</p><p>• convolution, average pooling, max pooling;</p><p>• matrix multiplication.</p><p>For example, for the element-wise addition operation type: from tensorflow.python.framework import graph_util from tensorflow.python.framework import ops @ops.RegisterStatistics("Add", "flops") def _add_flops(graph, node): """Compute flops for the Add operation.""" out_shape = graph_util.tensor_shape_from_node_def_name(graph, node.name) out_shape.assert_is_fully_defined() return ops.OpStats("flops", out_shape.num_elements())</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3. Escaping Local Optima Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3.1. Local optima and mutation rate</head><p>Entrapment at a local optimum may mean a general lack of exploration in our search algorithm. To encourage more exploration, we increased the mutation rate (Section 5). In more detail, we carried out experiments in which we first waited until the populations converged. Some reached higher fitnesses and others got trapped at poor local optima. At this point, we modified the algorithm slightly: instead of performing 1 mutation at each reproduction event, we performed 5 mutations. We evolved with this increased mutation rate for a while and finally we switched back to the original singlemutation version. During the 5-mutation stage, some populations escape the local optimum, as in <ref type="figure" target="#fig_4">Figure 4 (top)</ref>, and none get worse. Across populations, however, the escape was not frequent enough (8 out of 10) and took too long for us to propose this as an efficient technique to escape optima. An interesting direction for future work would be to study more elegant methods to manage the exploration vs. exploitation trade-off in large-scale neuro-evolution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S3.2. Local optima and weight resetting</head><p>The identity mutation offers a mechanism for populations to get trapped in local optima. Some individuals may get trained more than their peers just because they happen to have undergone more identity mutations. It may, therefore, occur that a poor architecture may become more accurate than potentially better architectures that still need more training.</p><p>In the extreme case, the well-trained poor architecture may become a super-fit individual and take over the population. Suspecting this scenario, we performed experiments in which we simultaneously reset all the weights in a population that had plateaued (Section 5). The simultaneous reset should put all the individuals on the same footing, so individuals that had accidentally trained more no longer have the unfair advantage. Indeed, the results matched our expectation. The populations suffer a temporary degradation in fitness immediately after the reset, as the individuals need to retrain. Later, however, the populations end up reaching higher optima (for example, <ref type="figure" target="#fig_4">Figure 4</ref>, bottom). Across 10 experiments, we find that three successive resets tend to cause improvement (p &lt; 0.001). We mention this effect merely as evidence of this particular drawback of weight inheritance. In our main results, we circumvented the problem by using longer training times and larger populations. Future work may explore more efficient solutions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>• INSERT-CONVOLUTION (inserts a convolution at a random location in the "convolutional backbone", as in Figure 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Progress of an evolution experiment. Each dot represents an individual in the population. Blue dots (darker, top-right) are alive. The rest have been killed. The four diagrams show examples of discovered architectures. These correspond to the best individual (rightmost) and three of its ancestors. The best individual was selected by its validation accuracy. Evolution sometimes stacks convolutions without any nonlinearity in between ("C", white background), which are mathematically equivalent to a single linear operation. Unlike typical hand-designed architectures, some convolutions are followed by more than one nonlinear function ("C+BN +R+BN +R+...", orange background).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Repeatability of results and controls. In this plot, the vertical axis at wall-time t is defined as the test accuracy of the individual with the highest validation accuracy that became alive at or before t. The inset magnifies a portion of the main graph. The curves show the progress of various experiments, as follows. The top line (solid, blue) shows the mean test accuracy across 5 large-scale evolution experiments. The shaded area around this top line has a width of ±2σ (clearer in inset). The next line down (dashed, orange, main graph and inset) represents a single experiment in which weight-inheritance was disabled, so every individual has to train from random weights. The lowest curve (dotteddashed) is a random-search control. All experiments occupied the same amount and type of hardware. A small amount of noise in the generalization from the validation to the test set explains why the lines are not monotonically increasing. Note the narrow width of the ±2σ area (main graph and inset), which shows that the high accuracies obtained in evolution experiments are repeatable.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Dependence on meta-parameters. In both graphs, each circle represents the result of a full evolution experiment. Both vertical axes show the test accuracy for the individual with the highest validation accuracy at the end of the experiment. All populations evolved for the same total wall-clock time. There are 5 data points at each horizontal axis value. LEFT: effect of population size. To economize resources, in these experiments the number of individual training steps is only 2560. Note how the accuracy increases with population size. RIGHT: effect of number of training steps per individual. Note how the accuracy increases with more steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Escaping local optima in two experiments. We used smaller populations and fewer training steps per individual</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>for hand-designed results, including the state of the art. "Discrete params." means that the parameters can be picked from a handful of values only (e.g. strides ∈ {1, 2, 4}).</figDesc><table><row><cell>STUDY</cell><cell>STARTING POINT</cell><cell cols="2">CONSTRAINTS</cell><cell>POST-PROCESSING</cell><cell>PARAMS.</cell><cell>C10+</cell><cell>C100+</cell></row><row><cell>BAYESIAN</cell><cell>3 LAYERS</cell><cell cols="2">FIXED ARCHITECTURE, NO</cell><cell>NONE</cell><cell>-</cell><cell>90.5%</cell><cell>-</cell></row><row><cell>(SNOEK</cell><cell></cell><cell>SKIPS</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>ET AL., 2012)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Q-LEARNING</cell><cell>-</cell><cell cols="2">DISCRETE PARAMS., MAX.</cell><cell>TUNE, RETRAIN</cell><cell>11.2 M</cell><cell>93.1%</cell><cell>72.9%</cell></row><row><cell>(BAKER</cell><cell></cell><cell cols="2">NUM. LAYERS, NO SKIPS</cell><cell></cell><cell></cell><cell></cell></row><row><cell>ET AL., 2016)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>RL (ZOPH &amp;</cell><cell>20 LAYERS, 50%</cell><cell cols="2">DISCRETE PARAMS.,</cell><cell>SMALL GRID</cell><cell>2.5 M</cell><cell>94.0%</cell><cell>-</cell></row><row><cell>LE, 2016)</cell><cell>SKIPS</cell><cell cols="2">EXACTLY 20 LAYERS</cell><cell>SEARCH, RETRAIN</cell><cell></cell><cell></cell></row><row><cell>RL (ZOPH &amp;</cell><cell>39 LAYERS, 2 POOL</cell><cell cols="2">DISCRETE PARAMS.,</cell><cell>ADD MORE FILTERS,</cell><cell>37.0 M</cell><cell>96.4%</cell><cell>-</cell></row><row><cell>LE, 2016)</cell><cell>LAYERS AT 13 AND</cell><cell cols="2">EXACTLY 39 LAYERS, 2</cell><cell>SMALL GRID</cell><cell></cell><cell></cell></row><row><cell></cell><cell>26, 50% SKIPS</cell><cell cols="2">POOL LAYERS AT 13 AND 26</cell><cell>SEARCH, RETRAIN</cell><cell></cell><cell></cell></row><row><cell>EVOLUTION (OURS)</cell><cell>SINGLE LAYER, ZERO CONVS.</cell><cell cols="2">POWER-OF-2 STRIDES</cell><cell>NONE</cell><cell>ENSEMB. 5.4 M 40.4 M</cell><cell>95.6% 94.6%</cell><cell>77.0%</cell></row><row><cell cols="3">ing a new state of the art at the time.</cell><cell>Zoph &amp;</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Le (2016) used reinforcement learning on a deeper</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">fixed-length architecture.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>The DNA holds Vertex and Edge instances. The Vertex class looks like this:</figDesc><table><row><cell></cell><cell>Large-Scale Evolution</cell></row><row><cell cols="2">self.edges_in = set(vertex_proto.edges_in) # Incoming edge IDs. self.scale_precedence = edge_proto.scale_precedence</cell></row><row><cell cols="2">self.edges_out = set(vertex_proto.edges_out) # Outgoing edge IDs.</cell></row><row><cell cols="2">def to_proto(self):</cell></row><row><cell cols="2"># The type of activations. ...</cell></row><row><cell cols="2">if vertex_proto.HasField('linear'):</cell></row><row><cell></cell><cell>self.type = LINEAR # Linear activations.</cell></row><row><cell cols="2">elif vertex_proto.HasField('bn_relu'):</cell></row><row><cell></cell><cell>self.type = BN_RELU # ReLU activations with batch-normalization.</cell></row><row><cell cols="2">else:</cell></row><row><cell></cell><cell>raise NotImplementedError()</cell></row><row><cell cols="2"># Some parts of the graph can be prevented from being acted upon by mutations.</cell></row><row><cell cols="2"># The following boolean flags control this.</cell></row><row><cell cols="2">self.inputs_mutable = vertex_proto.inputs_mutable</cell></row><row><cell cols="2">self.outputs_mutable = vertex_proto.outputs_mutable</cell></row><row><cell cols="2">self.properties_mutable = vertex_proto.properties_mutable</cell></row><row><cell cols="2"># Each vertex represents a 2ˆs x 2ˆs x d block of nodes. s and d are positive</cell></row><row><cell cols="2">e. exploring the space of # integers computed dynamically from the in-edges. s stands for "scale" so</cell></row><row><cell cols="2"># learning rate schedules. # that 2ˆx x 2ˆs is the spatial size of the activations. d stands for "depth",</cell></row><row><cell cols="2">self.learning_rate = dna_proto.learning_rate # the number of channels.</cell></row><row><cell cols="2">self._vertices = {} # String vertex ID to 'Vertex' instance. def to_proto(self):</cell></row><row><cell cols="2">for vertex_id in dna_proto.vertices: ...</cell></row><row><cell></cell><cell>vertices[vertex_id] = Vertex(vertex_proto=dna_sproto.vertices[vertex_id])</cell></row><row><cell cols="2">The Edge class looks like this:</cell></row><row><cell cols="2">self._edges = {} # String edge ID to 'Edge' instance.</cell></row><row><cell cols="2">for edge_id in dna_proto.edges: class Edge(object):</cell></row><row><cell></cell><cell>mutable_edges[edge_id] = Edge(edge_proto=dna_proto.edges[edge_id])</cell></row><row><cell cols="2">def __init__(self, edge_proto):</cell></row><row><cell cols="2">... # Relationship to the rest of the graph.</cell></row><row><cell cols="2">self.from_vertex = edge_proto.from_vertex # Source vertex ID.</cell></row><row><cell cols="2">def to_proto(self): self.to_vertex = edge_proto.to_vertex # Destination vertex ID.</cell></row><row><cell cols="2">"""Returns this instance in protocol buffer form."""</cell></row><row><cell cols="2">dna_proto = dna_pb2.DnaProto(learning_rate=self.learning_rate) if edge_proto.HasField('conv'):</cell></row><row><cell></cell><cell># In this case, the edge represents a convolution.</cell></row><row><cell cols="2">for vertex_id, vertex in self._vertices.iteritems(): self.type = CONV</cell></row><row><cell></cell><cell>dna_proto.vertices[vertex_id].CopyFrom(vertex.to_proto())</cell></row><row><cell></cell><cell># Controls the depth (i.e. number of channels) in the output, relative to the</cell></row><row><cell cols="2">for edge_id, edge in self._edges.iteritems(): # input. For example if there is only one input edge with a depth of 16 channels</cell></row><row><cell></cell><cell>dna_proto.edges[edge_id].CopyFrom(edge.to_proto()) # and 'self._depth_factor' is 2, then this convolution will result in an output</cell></row><row><cell></cell><cell># depth of 32 channels. Multiple-inputs with conflicting depth must undergo</cell></row><row><cell cols="2">... # depth resolution first.</cell></row><row><cell></cell><cell>self.depth_factor = edge_proto.conv.depth_factor</cell></row><row><cell cols="2">return dna_proto</cell></row><row><cell></cell><cell># Control the shape of the convolution filters (i.e. transfer function).</cell></row><row><cell cols="2">def add_edge(self, dna, from_vertex_id, to_vertex_id, edge_type, edge_id): # This parameterization ensures that the filter width and height are odd</cell></row><row><cell cols="2">"""Adds an edge to the DNA graph, ensuring internal consistency.""" # numbers: filter_width = 2 * filter_half_width + 1.</cell></row><row><cell cols="2"># 'EdgeProto' defines defaults for other attributes. self.filter_half_width = edge_proto.conv.filter_half_width</cell></row><row><cell cols="2">edge = Edge(EdgeProto( self.filter_half_height = edge_proto.conv.filter_half_height</cell></row><row><cell></cell><cell>from_vertex=from_vertex_id, to_vertex=to_vertex_id, type=edge_type))</cell></row><row><cell cols="2">self._edges[edge_id] = edge # Controls the strides of the convolution. It will be 2ˆstride_scale.</cell></row><row><cell cols="2">self._vertices[from_vertex_id].edges_out.add(edge_id) # Note that conflicting input scales must undergo scale resolution. This</cell></row><row><cell cols="2">self._vertices[to_vertex].edges_in.add(edge_id) # controls the spatial scale of the output activations relative to the</cell></row><row><cell cols="2">return edge # spatial scale of the input activations.</cell></row><row><cell></cell><cell>self.stride_scale = edge_proto.conv.stride_scale</cell></row><row><cell cols="2"># Other methods like 'add_edge' to manipulate the graph structure. elif edge_spec.HasField('identity'):</cell></row><row><cell>...</cell><cell>self.type = IDENTITY</cell></row><row><cell cols="2">else:</cell></row><row><cell></cell><cell>raise NotImplementedError()</cell></row><row><cell cols="2">class Vertex(object): # In case depth or scale resolution is necessary due to conflicts in inputs,</cell></row><row><cell cols="2"># These integer parameters determine which of the inputs takes precedence in</cell></row><row><cell cols="2">def __init__(self, vertex_proto): # deciding the resolved depth or scale.</cell></row><row><cell cols="2"># Relationship to the rest of the graph. self.depth_precedence = edge_proto.depth_precedence</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Many mutations modify the structure. Mutations to insert and excise vertex-edge pairs build up a main convolutional column, while mutations to add and remove edges can handle the skip connections. For example, the AddEdgeMutation can add a skip connection between random vertices.</figDesc><table><row><cell>Large-Scale Evolution</cell></row><row><cell>...</cell></row><row><cell>return True</cell></row><row><cell>uniform(-1.0, 1.0)</cell></row><row><cell>mutated_dna.learning_rate = dna.learning_rate * factor</cell></row><row><cell>return mutated_dna</cell></row><row><cell>class AddEdgeMutation(Mutation):</cell></row><row><cell>"""Adds a single edge to the graph."""</cell></row><row><cell>def mutate(self, dna):</cell></row><row><cell># Try the candidates in random order until one has the right connectivity.</cell></row><row><cell>for from_vertex_id, to_vertex_id in self._vertex_pair_candidates(dna):</cell></row><row><cell>mutated_dna = copy.deepcopy(dna)</cell></row><row><cell>if (self._mutate_structure(mutated_dna, from_vertex_id, to_vertex_id)):</cell></row><row><cell>return mutated_dna</cell></row><row><cell>raise exceptions.MutationException() # Try another mutation.</cell></row><row><cell>def _vertex_pair_candidates(self, dna):</cell></row><row><cell>"""Yields connectable vertex pairs."""</cell></row><row><cell>from_vertex_ids = _find_allowed_vertices(dna, self._to_regex, ...)</cell></row><row><cell>if not from_vertex_ids:</cell></row><row><cell>raise exceptions.MutationException() # Try another mutation.</cell></row><row><cell>random.shuffle(from_vertex_ids)</cell></row><row><cell>to_vertex_ids = _find_allowed_vertices(dna, self._from_regex, ...)</cell></row><row><cell>if not to_vertex_ids:</cell></row><row><cell>raise exceptions.MutationException() # Try another mutation.</cell></row><row><cell>random.shuffle(to_vertex_ids)</cell></row><row><cell>for to_vertex_id in to_vertex_ids:</cell></row><row><cell># Avoid back-connections.</cell></row><row><cell>disallowed_from_vertex_ids, _ = topology.propagated_set(to_vertex_id)</cell></row><row><cell>for from_vertex_id in from_vertex_ids:</cell></row><row><cell>if from_vertex_id in disallowed_from_vertex_ids:</cell></row><row><cell>continue</cell></row><row><cell># This pair does not generate a cycle, so we yield it.</cell></row><row><cell>yield from_vertex_id, to_vertex_id</cell></row><row><cell>def _mutate_structure(self, dna, from_vertex_id, to_vertex_id):</cell></row><row><cell>"""Adds the edge to the DNA instance."""</cell></row><row><cell>edge_id = _random_id()</cell></row><row><cell>edge_type = random.choice(self._edge_types)</cell></row><row><cell>if dna.has_edge(from_vertex_id, to_vertex_id):</cell></row><row><cell>return False</cell></row><row><cell>else:</cell></row><row><cell>new_edge = dna.add_edge(from_vertex_id, to_vertex_id, edge_type, edge_id)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>To evaluate an individual's fitness, its DNA is unfolded into a TensorFlow model by the Model class. This describes how each Vertex and Edge should be interpreted. For example:</figDesc><table><row><cell>class Model(object):</cell></row><row><cell>...</cell></row><row><cell>def _compute_vertex_nonlinearity(self, tensor, vertex):</cell></row><row><cell>"""Applies the necessary vertex operations depending on the vertex type."""</cell></row><row><cell>if vertex.type == LINEAR:</cell></row><row><cell>pass</cell></row><row><cell>elif vertex.type == BN_RELU:</cell></row><row><cell>tensor = slim.batch_norm(</cell></row><row><cell>inputs=tensor, decay=0.9, center=True, scale=True,</cell></row><row><cell>epsilon=self._batch_norm_epsilon,</cell></row><row><cell>activation_fn=None, updates_collections=None,</cell></row><row><cell>is_training=self.is_training, scope='batch_norm')</cell></row><row><cell>tensor = tf.maximum(tensor, vertex.leakiness * tensor, name='relu')</cell></row><row><cell>else:</cell></row><row><cell>raise NotImplementedError()</cell></row><row><cell>return tensor</cell></row><row><cell>def _compute_edge_connection(self, tensor, edge, init_scale):</cell></row><row><cell>"""Applies the necessary edge connection ops depending on the edge type."""</cell></row><row><cell>scale, depth = self._get_scale_and_depth(tensor)</cell></row><row><cell>if edge.type == CONV:</cell></row><row><cell>scale_out = scale</cell></row><row><cell>depth_out = edge.depth_out(depth)</cell></row><row><cell>stride = 2 ** edge.stride_scale</cell></row><row><cell># 'init_scale' is used to normalize the initial weights in the case of</cell></row><row><cell># multiple incoming edges.</cell></row><row><cell>weights_initializer = slim.variance_scaling_initializer(</cell></row><row><cell>factor=2.0 * init_scale ** 2, uniform=False)</cell></row><row><cell>weights_regularizer = slim.l2_regularizer(</cell></row><row><cell>weight=self._dna.weight_decay_rate)</cell></row><row><cell>tensor = slim.conv2d(</cell></row><row><cell>inputs=tensor, num_outputs=depth_out,</cell></row><row><cell>kernel_size=[edge.filter_width(), edge.filter_height()],</cell></row><row><cell>stride=stride, weights_initializer=weights_initializer,</cell></row><row><cell>weights_regularizer=weights_regularizer, biases_initializer=None,</cell></row><row><cell>activation_fn=None, scope='conv')</cell></row><row><cell>elif edge.type == IDENTITY:</cell></row><row><cell>pass</cell></row><row><cell>else:</cell></row><row><cell>raise NotImplementedError()</cell></row><row><cell>return tensor</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Build the neural network using the 'Model' class and the 'DNA' instance. ... tf.Session.reset(self._master) with tf.Session(self._master, graph=graph) as sess: # Initialize all variables ...</figDesc><table><row><cell>with graph.as_default():</cell></row><row><cell># # Make sure we can inherit batch-norm variables properly.</cell></row><row><cell># The TF-slim batch-norm variables must be handled separately here because some</cell></row><row><cell># of them are not trainable (the moving averages).</cell></row><row><cell>batch_norm_extras = [x for x in tf.all_variables() if (</cell></row><row><cell>x.name.find('moving_var') != -1 or</cell></row><row><cell>x.name.find('moving_mean') != -1)]</cell></row><row><cell># These are the variables that we will attempt to inherit from the parent.</cell></row><row><cell>vars_to_restore = tf.trainable_variables() + batch_norm_extras</cell></row><row><cell># Copy as many of the weights as possible.</cell></row><row><cell>if mutated_weights:</cell></row><row><cell>assignments = []</cell></row><row><cell>for var in vars_to_restore:</cell></row><row><cell>stripped_name = var.name.split(':')[0]</cell></row><row><cell>if stripped_name in mutated_weights:</cell></row><row><cell>shape_mutated = mutated_weights[stripped_name].shape</cell></row><row><cell>shape_needed = var.get_shape()</cell></row><row><cell>if shape_mutated == shape_needed:</cell></row><row><cell>assignments.append(var.assign(mutated_weights[stripped_name]))</cell></row><row><cell>sess.run(assignments)</cell></row><row><cell>graph = tf.Graph()</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>import tensorflow as tf tfprof_logger = tf.contrib.tfprof.python.tools.tfprof.tfprof_logger RunOptions(trace_level=tf.RunOptions.FULL_TRACE)) # Compute analytical FLOPs for all nodes in the graph. logged_ops = tfprof_logger._get_logged_ops(graph, run_meta=run_metadata) # Determine which nodes were executed during one training step # by looking at elapsed execution time of each node.</figDesc><table><row><cell>Large-Scale Evolution</cell></row><row><cell>[train_op],</cell></row><row><cell>feed_dict=feed_dict,</cell></row><row><cell>run_metadata=run_meta,</cell></row><row><cell>options=tf.elapsed_us_for_ops = {}</cell></row><row><cell>for dev_stat in run_metadata.step_stats.dev_stats:</cell></row><row><cell>for node_stat in dev_stat.node_stats:</cell></row><row><cell>name = node_stat.node_name</cell></row><row><cell>elapsed_us = node_stat.op_end_rel_micros -node_stat.op_start_rel_micros</cell></row><row><cell>elapsed_us_for_ops[name] = elapsed_us</cell></row><row><cell># Compute FLOPs of executed nodes.</cell></row><row><cell>total_flops = 0</cell></row><row><cell>for op in graph.get_operations():</cell></row><row><cell>name = op.name</cell></row><row><cell>if elapsed_us_for_ops.get(name, 0) &gt; 0 and name in logged_ops:</cell></row><row><cell>total_flops += logged_ops[name].float_ops</cell></row><row><cell>return total_flops</cell></row><row><cell>def compute_flops():</cell></row><row><cell>"""Compute flops for one iteration of training."""</cell></row><row><cell>graph = tf.Graph()</cell></row><row><cell>with graph.as_default():</cell></row><row><cell># Build model</cell></row><row><cell>...</cell></row><row><cell># Run one iteration of training and collect run metadata.</cell></row><row><cell># This metadata will be used to determine the nodes which were</cell></row><row><cell># actually executed as well as their argument shapes.</cell></row><row><cell>run_meta = tf.RunMetadata()</cell></row><row><cell>with tf.Session(graph=graph) as sess:</cell></row><row><cell>feed_dict = {...}</cell></row><row><cell>_ = sess.run(</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Google Brain, Mountain View, California, USA 2 Google Research, Mountain View, California, USA. Correspondence to: Esteban Real &lt;ereal@google.com&gt;.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The use of the file-name string to contain key information about the individual was inspired by<ref type="bibr" target="#b4">Breuel &amp; Shafait (2010)</ref>, and it speeds up disk access enormously. In our case, the file name contains the state of the individual (alive, dead, training, etc.).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">For integer DNA parameters, we actually store and mutate a floating-point value. This allows multiple small mutations to have a cumulative effect in spite of integer round-off.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Except after identity or learning rate mutations, but these produce a child with the same architecture as the parent.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We wish to thank Vincent Vanhoucke, Megan Kacholia, Rajat Monga, and especially Jeff Dean for their support and valuable input; Geoffrey Hinton, Samy Bengio, Thomas Breuel, Mark DePristo, Vishy Tirumalashetty, Martin Abadi, Noam Shazeer, Yoram Singer, Dumitru Erhan, Pierre Sermanet, Xiaoqiang Zheng, Shan Carter and Vijay Vasudevan for helpful discussions; Thomas Breuel, Xin Pan and Andy Davis for coding contributions; and the larger Google Brain team for help with TensorFlow and training vision models.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Tensorflow: Large-scale machine learning on heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martín</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brevdo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eugene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhifeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Citro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Craig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devin</forename><surname>Jeffrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Matthieu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Designing neural network architectures using reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bowen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Otkrist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Naik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Raskar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02167</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Evolving memory cell structures for sequence learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Togelius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="755" to="764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Random search for hyper-parameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="281" to="305" />
			<date type="published" when="2012-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automlp: Simple, effective, fully automated learning rate and size adjustment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faisal</forename><surname>Shafait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Learning Workshop</title>
		<meeting><address><addrLine>Utah</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Convolution by evolution: Differentiable pattern producing networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chrisantha</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malcolm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Besse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Frederic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jaderberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Max</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 on Genetic and Evolutionary Computation Conference</title>
		<meeting>the 2016 on Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A comparative analysis of selection schemes used in genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kalyanmoy</forename><surname>Deb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations of genetic algorithms</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="69" to="93" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Genetic algorithms with sharing for multimodal function optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Genetic algorithms and their applications: Proceedings of the Second International Conference on Genetic Algorithms</title>
		<meeting><address><addrLine>Hillsdale, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum</publisher>
			<date type="published" when="1987" />
			<biblScope unit="page" from="41" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Warde</forename><forename type="middle">-</forename><surname>Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mehdi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aaron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bengio</forename></persName>
		</author>
		<title level="m">Yoshua. Maxout networks. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1319" to="1327" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Genetic synthesis of modular neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frederic</forename><surname>Gruau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Genetic Algorithms</title>
		<meeting>the 5th International Conference on Genetic Algorithms</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="318" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning both weights and connections for efficient neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1135" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiangyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiangyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1608.06993</idno>
		<title level="m">Laurens. Densely connected convolutional networks</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep networks with stochastic depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="646" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minyoung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Rigazio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.01824</idno>
		<title level="m">Deep clustered convolutional kernels</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deeply-supervised nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Yu</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saining</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><forename type="middle">W</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyou</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AISTATS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4400</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Designing neural networks using genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">F</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hegde</forename><surname>Shailesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the third international conference on Genetic algorithms</title>
		<meeting>the third international conference on Genetic algorithms</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1989" />
			<biblScope unit="page" from="379" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Simple evolutionary optimization can rival stochastic gradient descent in neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Morse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 on Genetic and Evolutionary Computation Conference</title>
		<meeting>the 2016 on Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="477" to="484" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evolving multimodal controllers with hyperneat</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><forename type="middle">K</forename><surname>Pugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th annual conference on Genetic and evolutionary computation</title>
		<meeting>the 15th annual conference on Genetic and evolutionary computation</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="735" to="742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">E</forename><surname>Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Williams</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Modeling</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Convolutional neural fabrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shreyas</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances In Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4053" to="4061" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mastering the game of go with deep neural networks and tree search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Silver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aja</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><forename type="middle">J</forename><surname>Maddison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sifre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Den Driessche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schrittwieser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Julian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Antonoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ioannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Panneershelvam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Veda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lanctot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">529</biblScope>
			<biblScope unit="issue">7587</biblScope>
			<biblScope unit="page" from="484" to="489" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Leif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Simonsohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1359" to="1366" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Practical bayesian optimization of machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><forename type="middle">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="2951" to="2959" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Striving for simplicity: The all convolutional net</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tobias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6806</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Jürgen. Highway networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Compositional pattern producing networks: A novel abstraction of development. Genetic programming and evolvable machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="131" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Evolving neural networks through augmenting topologies. Evolutionary Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risto</forename><surname>Miikkulainen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="99" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Jason. A hypercube-based encoding for evolving largescale neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">O</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D&amp;apos;</forename><surname>Ambrosio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gauci</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Life</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="212" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">On the importance of initialization and momentum in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ilya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Martens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1139" to="1147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yangqing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dragomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dumitru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adapting operator settings in genetic algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tuson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolutionary computation</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="184" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Verbancsics</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Harguess</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.5355</idno>
		<title level="m">Generative neuroevolution for deep learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Rapid evolutionary escape by large populations from local fitness peaks is likely in nature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">M</forename><surname>Weinreich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Chao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Evolution</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1175" to="1182" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Planet-photo geolocation with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Kostrikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="37" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mike</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhifeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohammad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Wide residual networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">An empirical exploration of recurrent network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><surname>Zaremba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01578</idno>
		<title level="m">Neural architecture search with reinforcement learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
