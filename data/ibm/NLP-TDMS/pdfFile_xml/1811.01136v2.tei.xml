<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Margin-based Parallel Corpus Mining with Multilingual Sentence Embeddings</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikel</forename><surname>Artetxe</surname></persName>
							<email>mikel.artetxe@ehu.eus</email>
							<affiliation key="aff0">
								<orgName type="institution">University of the Basque Country (UPV/EHU)</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
							<email>schwenk@fb.com</email>
							<affiliation key="aff1">
								<orgName type="department">Facebook AI Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Margin-based Parallel Corpus Mining with Multilingual Sentence Embeddings</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T12:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Machine translation is highly sensitive to the size and quality of the training data, which has led to an increasing interest in collecting and filtering large parallel corpora. In this paper, we propose a new method for this task based on multilingual sentence embeddings. In contrast to previous approaches, which rely on nearest neighbor retrieval with a hard threshold over cosine similarity, our proposed method accounts for the scale inconsistencies of this measure, considering the margin between a given sentence pair and its closest candidates instead. Our experiments show large improvements over existing methods. We outperform the best published results on the BUCC mining task and the UN reconstruction task by more than 10 F1 and 30 precision points, respectively. Filtering the English-German ParaCrawl corpus with our approach, we obtain 31.2 BLEU points on newstest2014, an improvement of more than one point over the best official filtered version.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While Neural Machine Translation (NTM) has obtained breakthrough improvements in standard benchmarks, it is known to be particularly sensitive to the size and quality of the training data <ref type="bibr" target="#b15">(Koehn and Knowles, 2017;</ref><ref type="bibr" target="#b13">Khayrallah and Koehn, 2018)</ref>. In this context, effective approaches to mine and filter parallel corpora are crucial to apply NMT in practical settings.</p><p>Traditional parallel corpus mining has relied on heavily engineered systems. Early approaches were mostly based on metadata information from web crawls <ref type="bibr" target="#b19">(Resnik, 1999;</ref><ref type="bibr" target="#b22">Shi et al., 2006)</ref>. More recent methods focus on the textual content instead. For instance, Zipporah learns a classifier * This work was performed during an internship at Facebook AI Research. over bag-of-word features to distinguish between ground truth translations and synthetic noisy ones <ref type="bibr" target="#b27">(Xu and Koehn, 2017)</ref>. STACC uses seed lexical translations induced from IBM alignments, which are combined with set expansion operations to score translation candidates through the Jaccard similarity coefficient <ref type="bibr" target="#b8">(Etchegoyhen and Azpeitia, 2016;</ref><ref type="bibr" target="#b2">Azpeitia et al., 2017</ref><ref type="bibr" target="#b3">Azpeitia et al., , 2018</ref>. Many of these approaches rely on cross-lingual document retrieval <ref type="bibr" target="#b23">(Utiyama and Isahara, 2003;</ref><ref type="bibr">Marcu, 2005, 2006</ref>; Abdul-Rauf and <ref type="bibr" target="#b0">Schwenk, 2009)</ref> or machine translation (Abdul-Rauf and <ref type="bibr" target="#b0">Schwenk, 2009;</ref><ref type="bibr" target="#b4">Bouamor and Sajjad, 2018)</ref>.</p><p>More recently, a new research line has shown promising results using multilingual sentence embeddings alone 1 <ref type="bibr" target="#b20">(Schwenk, 2018;</ref><ref type="bibr" target="#b11">Guo et al., 2018)</ref>. These methods use an NMT inspired encoder-decoder to train sentence embeddings on existing parallel data, which are then directly applied to retrieve and filter new parallel sentences using nearest neighbor retrieval over cosine similarity with a hard threshold <ref type="bibr" target="#b7">(España-Bonet et al., 2017;</ref><ref type="bibr" target="#b20">Schwenk, 2018)</ref>.</p><p>In this paper, we argue that this retrieval method suffers from the scale of cosine similarity not being globally consistent. As illustrated by the example in <ref type="table">Table 1</ref>, some sentences without any correct translation have overall high cosine scores, making them rank higher than other sentences with a correct translation. This issue was also pointed out by <ref type="bibr" target="#b11">Guo et al. (2018)</ref>, who learn an encoder to score known translation pairs above synthetic negative examples and train a separate model to dynamically scale and shift the dot product on held out supervised data. In contrast, our 1 Multilingual entence embeddings have also been used as part of a larger system, either to obtain an initial alignment that is then further filtered <ref type="bibr" target="#b4">(Bouamor and Sajjad, 2018)</ref> or as an intermediate representation of an end-to-end classifier <ref type="bibr" target="#b10">(Grégoire and Langlais, 2017</ref> Les produits agricoles sont constitués de thé, de riz, de sucre, de tabac, de camphre, de fruits et de soie.</p><p>0.818 Main crops include wheat, sugar beets, potatoes, cotton, tobacco, vegetables, and fruit. 0.817 The fertile soil supports wheat, corn, barley, tobacco, sugar beet, and soybeans. 0.814 Main agricultural products include grains, cotton, oil, pigs, poultry, fruits, vegetables, and edible fungus. 0.808 The important crops grown are cotton, jowar, groundnut, rice, sunflower and cereals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(B)</head><p>Mais dans le contexte actuel, nous pourrons les ignorer sans risque.</p><p>0.737 But, in view of the current situation, we can safely ignore these. 0.499 But without the living language, it risks becoming an empty shell. 0.498 While the risk to those working in ceramics is now much reduced, it can still not be ignored. 0.488 But now they have discovered they are not free to speak their minds. <ref type="table">Table 1</ref>: Motivating example of the proposed method. We show the nearest neighbors of two French sentences on the BUCC training set along with their cosine similarities. Only the nearest neighbor of B is a correct translation, yet that of A has a higher cosine similarity. We argue that this is caused by the cosine similarity of different sentences being in different scales, making it a poor indicator of the confidence of the prediction. Our method tackles this issue by considering the margin between a given candidate and the rest of the k nearest neighbors.</p><p>proposed method tackles this issue by considering the margin between the cosine of a given sentence pair and that of its respective k nearest neighbors.</p><p>2 Multilingual sentence embeddings <ref type="figure" target="#fig_0">Figure 1</ref> shows our encoder-decoder architecture to learn multilingual sentence embeddings, which is based on <ref type="bibr" target="#b20">Schwenk (2018)</ref>. The encoder consists of a bidirectional LSTM, and our sentence embeddings are obtained by applying a max-pooling operation over its output. These embeddings are fed into an LSTM decoder in two ways: 1) they are used to initialize its hidden and cell state after a linear transformation, and 2) they are concatenated to the input embeddings at every time step. We use a shared encoder and decoder for all languages with a joint 40k BPE vocabulary learned on the concatenation of all training corpora. <ref type="bibr">2</ref> The encoder is fully language agnostic, without any explicit signal of the input or output language, whereas the decoder receives an output language ID embedding at every time step. Training minimizes the cross-entropy loss on parallel corpora, alternating over all combinations of the languages involved. We train on 4 GPUs with a total batch size of 48,000 tokens, using Adam with a learning rate of 0.001 and dropout set to 0.1. We use a single layer for both the encoder and the decoder with a hidden size of 512 and 2048, respectively, yielding 1024 dimensional sentence embeddings. The input embeddings size is set to 512, while the lan-guage ID embeddings have 32 dimensions. After training, the decoder is discarded, and the encoder is used to map a sentence to a fixed-length vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Scoring and filtering parallel sentences</head><p>The multilingual encoder can be used to mine parallel sentences by taking the nearest neighbor of each source sentence in the target side according to cosine similarity, and filtering those below a fixed threshold. While this approach has been reported to be competitive <ref type="bibr" target="#b20">(Schwenk, 2018)</ref>, we argue that it suffers from the scale of cosine similarity not being globally consistent across different sentences. <ref type="bibr">3</ref> For instance, <ref type="table">Table 1</ref> shows an example where an incorrectly aligned sentence pair has a larger cosine similarity than a correctly aligned one, thus making it impossible to filter it through a fixed threshold. In that case, all four nearest neighbors have equally high values. In contrast, for example B, there is a big gap between the nearest neighbor and its other candidates. As such, we argue that the margin between the similarity of a given candidate and that of its k nearest neighbors is a better indicator of the strength of the alignment. <ref type="bibr">4</ref> We next describe our scoring method inspired by this idea in Section 3.1, and discuss our candidate generation and filtering strategy in Section 3.2. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Margin-based scoring</head><p>We consider the margin between the cosine of a given candidate and the average cosine of its k nearest neighbors in both directions as follows:</p><formula xml:id="formula_0">score(x, y) = margin(cos(x, y), z∈NN k (x) cos(x, z) 2k + z∈NN k (y) cos(y, z) 2k )</formula><p>where NN k (x) denotes the k nearest neighbors of x in the other language excluding duplicates, 5 and analogously for NN k (y). We explore the following variants of this general definition:</p><p>• Absolute (margin(a, b) = a): Ignoring the average. This is equivalent to cosine similarity and thus our baseline.</p><p>• Distance (margin(a, b) = a − b): Subtracting the average cosine similarity from that of the given candidate. This is proportional to the CSLS score <ref type="bibr" target="#b5">(Conneau et al., 2018)</ref>, which was originally motivated to mitigate the hubness problem on Bilingual Lexicon Induction (BLI) over cross-lingual word embeddings. 6</p><p>• Ratio (margin(a, b) = a b ): The ratio between the candidate and the average cosine of its nearest neighbors in both directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Candidate generation and filtering</head><p>When mining parallel sentences, we explore the following strategies to generate candidates:</p><p>• Forward: Each source sentence is aligned with exactly one best scoring target sentence. 7 Some target sentences may be aligned with multiple source sentences or with none.</p><p>• Backward: Equivalent to the forward strategy, but going in the opposite direction.</p><p>• Intersection of forward and backward candidates, which discards sentences with inconsistent alignments.</p><p>• Max. score: Combination of forward and backward candidates that, instead of discarding all inconsistent alignments, it selects those with the highest score.</p><p>These candidates are then sorted according to their margin scores, and a threshold is applied. This can be either optimized on the development data, or adjusted to obtain the desired corpus size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and results</head><p>We next present our results on the BUCC mining task, UN corpus reconstruction, and machine translation over filtered ParaCrawl. All experiments use an English/French/Spanish/German multilingual encoder trained on Europarl v7 <ref type="bibr" target="#b14">(Koehn, 2005)</ref> for 10 epochs. To cover all languages in BUCC, we use a separate English/French/Russian/Chinese model trained on the UN corpus <ref type="bibr" target="#b28">(Ziemski et al., 2016)</ref> for 4 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">BUCC mining task</head><p>The shared task of the workshop on Building and Using Comparable Corpora (BUCC) is a wellestablished evaluation framework for bitext mining <ref type="bibr" target="#b29">(Zweigenbaum et al., 2017</ref><ref type="bibr" target="#b30">(Zweigenbaum et al., , 2018</ref>  to mine for parallel sentences between English and four foreign languages: German, French, Russian and Chinese. There are 150K to 1.2M sentences for each language, split into a sample, training and test set. About 2-3% of the sentences are parallel. <ref type="table" target="#tab_2">Table 2</ref> reports precision, recall and F1 scores on the training set. <ref type="bibr">8</ref> Our results show that multilingual sentence embeddings already achieve competitive performance using standard forward retrieval over cosine similarity, which is in line with <ref type="bibr" target="#b20">Schwenk (2018)</ref>. Both of our bidirectional retrieval strategies achieve substantial improvements over this baseline while still relying on cosine similarity, with intersection giving the best results. Moreover, our proposed margin-based scoring brings large improvements when using either the distance or the ratio functions, outperforming cosine similarity by more than 10 points in all cases. The best results are achieved by ratio, which outperforms distance by 0.3-0.5 points. Interestingly, the retrieval strategy has a very small effect in both cases, suggesting that the proposed scoring is more robust than cosine. <ref type="table" target="#tab_4">Table 3</ref> reports the results on the test set for both the Europarl and the UN model in comparison to previous work. 9 Our proposed system outperforms all previous methods by a large margin, <ref type="bibr">8</ref> Note that the gold standard information was exclusively used to optimize the filtering threshold for each configuration, making results comparable across different variants. <ref type="bibr">9</ref> We use the ratio margin function with maximum score retrieval for our method. The filtering threshold was optimized to maximize the F1 score on the training set for each language pair and model. The gold-alignments of the test set are not publicly available -these scores on the test set are calculated by the organizers of the BUCC workshop. We have done one single submission.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">UN corpus reconstruction</head><p>So as to compare our method to the similarly motivated system of <ref type="bibr" target="#b11">Guo et al. (2018)</ref>, we mimic their experiment on aligning the 11.3M sentences of the UN corpus. This task does not require any filtering, so we use forward retrieval with the ratio margin function. As shown in <ref type="table" target="#tab_5">Table 4</ref>, our system outperforms that of <ref type="bibr" target="#b11">Guo et al. (2018)</ref> by a large margin despite using only a fraction of the training data (2M sentences from Europarl in contrast with over 400M sentences from Google's internal data).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Filtering ParaCrawl for NMT</head><p>Finally, we filter the English-German ParaCrawl corpus and evaluate NMT models trained on them. Our NMT models use fairseq's implementation of the big transformer model <ref type="bibr" target="#b24">(Vaswani et al., 2017)</ref>, using the same configuration as  and training for 100 epochs. Following common practice, we use newstest2013 and newstest2014 as our development and test sets, respectively, and report both tokenized and detokenized BLEU scores as computed by multi-bleu.perl and sacreBLEU. We decode with a beam size of 5 using an ensemble of the last 10 epochs. One single model is only slightly worse. Given the large size of ParaCrawl, we first preprocess it to remove all duplicated sentence pairs,   sentences for which the fastText language identification model 10 predicts a different language, those with less than 3 or more than 80 tokens, or those with either an overlap of at least 50% or a ratio above 2 between the source and target tokens. This reduces the corpus size from 4.59 billion to 64.4 million sentence pairs, mostly due to deduplication. We then score each sentence pair with the ratio function, processing the entire corpus in batches of 5 million sentences, and take the top scoring entries up to the desired size. <ref type="figure">Figure 2</ref> shows the development BLEU scores of the resulting system for different thresholds, which peaks at 10 million sentences. As shown in <ref type="table" target="#tab_7">Table 5</ref>, this model clearly outperforms the two official filtered versions of ParaCrawl in the test set. Finally, <ref type="table" target="#tab_9">Table 6</ref> compares our results to previous works in the literature using different training data. In addition to our ParaCrawl system, we include an additional one combining it with all parallel data from WMT18 except Common-Crawl. As it can be seen, our system outperforms all previous systems but , who use a large in-domain monolingual corpus through back-translation, making both works complementary. Quite remarkably, our full system outperforms    our improvement can be attributed to a better filtering of ParaCrawl. 11</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and future work</head><p>In this paper, we propose a new method for parallel corpus mining based on multilingual sentence embeddings. We use a sequence-to-sequence architecture to train a multilingual sentence encoder on an initial parallel corpus, and a novel marginbased scoring method that overcomes the scale inconsistencies of cosine similarity. Our experiments show large improvements over previous methods. Our system obtains the best published results on the BUCC mining task, outperforming previous systems by more than 10 F1 points for all the four language pairs. In addition, our method obtains up to 85% precision at reconstructing the 11.3M sentence pairs from the UN corpus, improving over the similarly motivated method of <ref type="bibr" target="#b11">Guo et al. (2018)</ref> by more than 30 points. Finally, we show that our improvements also carry over to downstream machine translation, as we obtain 31.2 BLEU points for English-German newstest2014 training on our filtered version of ParaCrawl, an improvement of more than one point over the best performing official release.</p><p>The code of this work is freely available as part of the LASER toolkit, together with an additional single encoder which covers 93 languages. 12 11 To confirm this, we trained a separate model on WMT data, obtaining 29.4 tokenized BLEU. This is on par with the results reported by  for the same data (29.3 tokenized BLEU). This shows that the difference cannot be attributed to implementation details. 12 https://github.com/facebookresearch/ LASER</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Architecture of our system to learn multilingual sentence embeddings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>). The task is</figDesc><table><row><cell cols="2">Func. Retrieval</cell><cell></cell><cell>EN-DE</cell><cell>EN-FR</cell></row><row><cell></cell><cell></cell><cell>P</cell><cell>R F1</cell><cell>P</cell><cell>R F1</cell></row><row><cell></cell><cell>Forward</cell><cell cols="3">78.9 75.1 77.0 82.1 74.2 77.9</cell></row><row><cell>Abs.</cell><cell cols="4">Backward 79.0 73.1 75.9 77.2 72.2 74.7</cell></row><row><cell>(cos)</cell><cell cols="4">Intersection 84.9 80.8 82.8 83.6 78.3 80.9</cell></row><row><cell></cell><cell cols="4">Max. score 83.1 77.2 80.1 80.9 77.5 79.2</cell></row><row><cell></cell><cell>Forward</cell><cell cols="3">94.8 94.1 94.4 91.1 91.8 91.4</cell></row><row><cell>Dist.</cell><cell cols="4">Backward 94.8 94.1 94.4 91.5 91.4 91.4 Intersection 94.9 94.1 94.5 91.2 91.8 91.5</cell></row><row><cell></cell><cell cols="4">Max. score 94.9 94.1 94.5 91.2 91.8 91.5</cell></row><row><cell></cell><cell>Forward</cell><cell cols="3">95.2 94.4 94.8 92.4 91.3 91.8</cell></row><row><cell>Ratio</cell><cell cols="4">Backward 95.2 94.4 94.8 92.3 91.3 91.8 Intersection 95.3 94.4 94.8 92.4 91.3 91.9</cell></row><row><cell></cell><cell cols="4">Max. score 95.3 94.4 94.8 92.4 91.3 91.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>BUCC results (precision, recall and F1) on the training set, used to optimize the filtering threshold.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>BUCC results (F1) on the test set. We use the ratio function with maximum score retrieval and the filtering threshold optimized on the training set.</figDesc><table><row><cell>en-fr en-es</cell></row><row><cell>Guo et al. (2018) 48.90 54.94</cell></row><row><cell>Proposed method 83.27 85.78</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>: Results on UN corpus reconstruction (P@1)</cell></row><row><cell>obtaining improvements of 10-15 F1 points and</cell></row><row><cell>showing very consistent performance across dif-</cell></row><row><cell>ferent languages, including distant ones.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Results on English-German newstest2014 for different filtered versions of the ParaCrawl corpus.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Results on English-German newstest2014 in comparison to previous work. wmt for WMT parallel data (excluding ParaCrawl), pc for ParaCrawl, and nc for monolingual News Crawl with back-translation.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Prior to BPE segmentation, we tokenize and lowercase the input text using standard Moses tools. As the only exception, we use Jieba (https://github.com/fxsjy/ jieba) for Chinese word segmentation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Note that, even if cosine similarity is normalized in the (-1, 1) range, it is still susceptible to concentrate around different values.4  As a downside, this approach will penalize sentences with many paraphrases in the corpus. While possible, we argue that such cases rarely happen in practice and, even when they do, filtering them is unlikely to cause any major harm.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Unless otherwise indicated, we use k = 4. 6 While our work is motivated by thresholding, which is not used in BLI, this connection points out a related problem that our approach also addresses: even when the source sentence is fixed, the potentially different scales of its target candidates might also affect their relative ranking, which ultimately causes the hubness problem. Thanks to its bidirectional nature, our proposed scoring method penalizes target sentences with overall high cosine similarities, so it can learn better alignments that account for this factor.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">For efficiency, only the k nearest neighbors over cosine similarity are considered, where the neighborhood size k is the same as that used for the margin-based scoring.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">On the Use of Comparable Corpora to Improve SMT performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sadaf</forename><surname>Abdul-Rauf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EACL</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="16" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Weighted Transformer Network for Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karim</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Shirish Keskar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.02132</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Weighted Set-Theoretic Alignment of Comparable Sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andoni</forename><surname>Azpeitia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva Martínez</forename><surname>Thierry Etchegoyhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BUCC</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="41" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Extracting Parallel Sentences from Comparable Corpora with STACC Variants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andoni</forename><surname>Azpeitia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva Martínez</forename><surname>Thierry Etchegoyhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BUCC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">H2@BUCC18: Parallel Sentence Extraction from Comparable Corpora Using Multilingual Sentence Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houda</forename><surname>Bouamor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Sajjad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BUCC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Word Translation Without Parallel Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc&amp;apos;aurelio</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hervé</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Understanding Back-Translation at Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An Empirical Analysis of NMT-Derived Interlingual Embeddings and their Use in Parallel Sentence Identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristina</forename><surname>España-Bonet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ádám</forename><forename type="middle">Csaba</forename><surname>Varga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Van Genabith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Signal Processing</title>
		<imprint>
			<biblScope unit="page" from="1340" to="1348" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Set-Theoretic Alignment for Comparable Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Etchegoyhen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andoni</forename><surname>Azpeitia</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1189</idno>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2009" to="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Convolutional Sequence to Sequence Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann N</forename><surname>Dauphin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1243" to="1252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Shared Task: a First Attempt Toward a Deep Learning Framework for Identifying Parallel Sentences in Comparable Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Grégoire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Langlais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BUCC</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="46" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effective Parallel Corpus Mining using Bilingual Sentence Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandy</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinlan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinfei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heming</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><forename type="middle">Hernandez</forename><surname>Abrego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun-Hsuan</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ray</forename><surname>Kurzweil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="165" to="176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hany</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Aue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Chowdhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Federmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuedong</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujie</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tie-Yan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Renqian</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arul</forename><surname>Menezes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Seide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuangzhi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingce</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.05567</idno>
		<title level="m">Achieving Human Parity on Automatic Chinese to English News Translation</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On the Impact of Various Types of Noise on Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huda</forename><surname>Khayrallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WNMT</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="74" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Europarl: A parallel corpus for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MT summit</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Six Challenges for Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><surname>Knowles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WNMT</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Improving Machine Translation Performance by Exploiting Non-Parallel Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Dragos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Munteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="477" to="504" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Extracting Parallel Sub-Sentential Fragments from Non-Parallel Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Dragos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Munteanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scaling neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mining the Web for Bilingual Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Resnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Filtering and Mining Parallel Data in a Joint Multilingual Space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="228" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Self-Attention with Relative Position Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="464" to="468" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A DOM Tree Alignment Model for Mining Parallel Data from the Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="489" to="496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Reliable Measures for Aligning Japanese-English News Articles and Sentences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masao</forename><surname>Utiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitoshi</forename><surname>Isahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6000" to="6010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghui</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Klingner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apurva</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melvin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Łukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshikiyo</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hideto</forename><surname>Kazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Kurian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nishant</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oriol Vinyals</title>
		<imprint>
			<publisher>Macduff Hughes</publisher>
		</imprint>
	</monogr>
	<note>and Jeffrey Dean. 2016. Google&apos;s</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<idno type="arXiv">arXiv:1609.08144</idno>
		<title level="m">Neural Machine Translation System: Bridging the Gap between Human and Machine Translation</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Zipporah: a Fast and Scalable Data Cleaning System for Noisy Web-Crawled Parallel Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hainan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2945" to="2950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The United Nations Parallel Corpus v1.0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michał</forename><surname>Ziemski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcin</forename><surname>Junczys-Dowmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Pouliquen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Overview of the Second BUCC Shared Task: Spotting Parallel Sentences in Comparable Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Sharoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Rapp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BUCC</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="60" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Overview of the Third BUCC Shared Task: Spotting Parallel Sentences in Comparable Corpora</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Zweigenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Sharoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Rapp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BUCC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
