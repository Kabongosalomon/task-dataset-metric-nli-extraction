<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Null-sampling for Interpretable and Fair Representations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kehrenberg</surname></persName>
							<email>t.kehrenberg@sussex.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Predictive Analytics Lab (PAL)</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<settlement>Brighton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myles</forename><surname>Bartlett</surname></persName>
							<email>m.bartlett@sussex.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Predictive Analytics Lab (PAL)</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<settlement>Brighton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Thomas</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Predictive Analytics Lab (PAL)</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<settlement>Brighton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Novi</forename><surname>Quadrianto</surname></persName>
							<email>n.quadrianto@sussex.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Predictive Analytics Lab (PAL)</orgName>
								<orgName type="institution">University of Sussex</orgName>
								<address>
									<settlement>Brighton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Null-sampling for Interpretable and Fair Representations</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T16:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Fairness</term>
					<term>Interpretability</term>
					<term>Adversarial Learning</term>
					<term>Normalis- ing Flows</term>
					<term>Invertible Neural Networks</term>
					<term>Variational Autoencoders</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose to learn invariant representations, in the data domain, to achieve interpretability in algorithmic fairness. Invariance implies a selectivity for high level, relevant correlations w.r.t. class label annotations, and a robustness to irrelevant correlations with protected characteristics such as race or gender. We introduce a non-trivial setup in which the training set exhibits a strong bias such that class label annotations are irrelevant and spurious correlations cannot be distinguished. To address this problem, we introduce an adversarially trained model with a null-sampling procedure to produce invariant representations in the data domain. To enable disentanglement, a partially-labelled representative set is used. By placing the representations into the data domain, the changes made by the model are easily examinable by human auditors. We show the effectiveness of our method on both image and tabular datasets: Coloured MNIST, the CelebA and the Adult dataset. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Without due consideration for the data collection process, machine learning algorithms can exacerbate biases, or even introduce new ones if proper control is not exerted over their learning <ref type="bibr">[10]</ref>. While most of these issues can be solved by controlling and curating data collection in a fairness-conscious fashion, doing so is not always an option, such as when working with historical data. Efforts to address this problem algorithmically have been centred on developing statistical definitions of fairness and learning models that satisfy these definitions. One popular definition of fairness used to guide the training of fair classifiers, for example, is demographic parity, stating that positive outcome rates should be equalised (or invariant) across protected groups.</p><p>In the typical setup, we have an input x, a sensitive attribute s that represents some non-admissible information like gender and a class label y which is the prediction target. The idea of fair representation learning <ref type="bibr" target="#b28">[29]</ref> <ref type="bibr">[6]</ref> <ref type="bibr" target="#b23">[24]</ref> is then to transform the input x to a representation z which is invariant to s. Thus, learning from z will not introduce a forbidden dependence on s. A good fair representation is one that preserves most of the information from x while satisfying the aforementioned constraints.</p><p>As unlabelled data is much more freely available than labelled data, it is of interest to learn the representation in an unsupervised manner. This will allow us to draw on a much more diverse pool of data to learn from. While annotations for y are often hard to come by (and often noisy <ref type="bibr">[16]</ref>), annotations for the sensitive attribute s are usually less so, as s can often be obtained from demographic information provided by census data. We thus consider the setting where the representation is learned from data that is only labelled with s and not y. This is in contrast to most other representation learning methods. We call the set used to learn the representation the representative set, because its distribution is meant to match the distribution of the deployment setting (and is thus representative).</p><p>Once we have learnt the mapping from x to z, we can transform the training set which, in contrast to the representative set, has the y labels (and s labels). In order to make our method more widely applicable, we consider an aggravated fairness problem in which the training set contains a strong spurious correlation between s and y, which makes it impossible to learn from it a representation which is invariant to s but not invariant to y. Non-invariance to y is important in order to be able to predict y. The training set thus does not match the deployment setting, thereby rendering the representative set essential for learning the right invariance. From hereon, we will use the terms spurious and sensitive interchangeably, depending on the context, to refer to an attribute of the data we seek invariance to. We can draw a connection between learning in the presence of spurious correlations and what <ref type="bibr">[15]</ref> call residual unfairness. Consider the Stop, Question and Frisk (SQF) dataset for example: the data was collected in New York City, but the demographics of the recorded cases do not represent the true demographics of NYC well. The demographic attributes of the recorded individuals might correlate so strongly with the prediction target that the two are nearly indistinguishable. This is the scenario that we are investigating: s and y are so closely correlated in the labelled dataset that they cannot be distinguished, but the learning of s is favoured due to being the "path of least resistance". The deployment setting (i.e. the test set) does not possess this strong correlation and thus a naïve approach will lead to very unfair predictions. In this case, a disentangled representation is insufficient; the representation needs to be explicitly invariant solely with respect to s. In our approach, we make use of the (partially labelled) representative set to learn this invariant representation.</p><p>While there is a substantial body of literature devoted to the problems of fair representation-learning, exactly how the invariance in question is achieved is often overlooked. When critical decisions, such as who should receive bail or be released from jail, are being deferred to an automated decision making system, it is critical that people be able to trust the logic of the model underlying it, whether it be via semantic or visual explanations. We build on the work of <ref type="bibr" target="#b24">[25]</ref> and learn a decomposition (f −1 : Z s × Z ¬s → X) of the data domain (X) into independent subspaces invariant to s (Z ¬s ) and indicative of s (Z s ), which lends an interpretability that is absent from most representation-learning methods. While model interpretability has no strict definition <ref type="bibr" target="#b29">[30]</ref>, we follow the intuition of <ref type="bibr">[1]</ref> -a simple relationship to something we can understand, a definition which representations in the data domain naturally fulfil.</p><p>Whether as a result of the aforementioned sampling bias or simply because the features necessarily co-occur, it is not rare for features to correlate with one another in real-world datasets. Lipstick and gender for example, are two attributes that we expect to be highly correlated and to enforce invariance to gender can implicitly enforce invariance to makeup. This is arguably the desired behaviour. However, unforeseen biases in the data may engender cases which are less justifiable. By baking interpretability into our model (by having representations in the data domain), though we still have no better control over what is learned, we can at least diagnose such pathologies.</p><p>To render our representations interpretable, we rely on a simple transformation we call null-sampling to map invariant representations in the data domain. Previous approaches to fair representation learning <ref type="bibr">[3,</ref><ref type="bibr">6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b22">23]</ref> predominantly rely upon autoencoder models to jointly minimise reconstruction loss and invariance. We discuss first how this can be done with such a model that we refer to as cVAE (conditional VAE), before arguing that the bijectivity of invertible neural networks (INNs) <ref type="bibr">[5]</ref> makes them better suited to this task. We refer to the variant of our method based on these as cFlow (conditional Flow). INNs have several properties that make them appealing for unsupervised representation learning. The focus of our approach is on creating invariant representations that preserve the non-sensitive information maximally, with only knowledge of s and not of the target y, while at the same time having the ability to easily probe what has been learnt.</p><p>Our contribution is thus two-fold: 1) We propose a simple approach to generating representations that are invariant to a feature s, while having the benefit of interpretability that comes with being in the data domain. We call our model NIFR (Null-sampling for Interpretable and Fair Representations). 2) We explore a setting where the labelled training set suffers from varying levels of sampling bias, demonstrating an approach based on transferring information from a more diverse representative set, with guarantees of the non-spurious information being preserved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>Learning fair representations. Given a sensitive attribute s (for example, gender or race) and inputs x, a fair representation z of x is then one for which z ⊥ s holds, while ideally also being predictive of the class label y. <ref type="bibr" target="#b28">[29]</ref> was the first to propose the learning of fair representations which allow for transfer to new classification tasks. More recent methods are often based on variational  Reconstructions using only information unrelated to s. (c) Reconstruction using only information related to ¬s. The model learns to disentangle gender from the non-gender related information. Note that some attributes like skin tone seem to change along with gender due to the correlation between the attributes. This is especially visible in images (1,1) and <ref type="bibr">(3,</ref><ref type="bibr">2)</ref>. Only because our representations are produced in the data-domain can we easily spot such instances of entanglement.</p><p>autoencoders (VAEs) <ref type="bibr">[20,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr">6,</ref><ref type="bibr">3]</ref>. The achieved fairness of the representation can be measured with various fairness metrics. These measure, however, usually how fair the predictions of a classifier are and not how fair a representation is. The appropriate measure of fairness for a given task is domain-specific <ref type="bibr" target="#b20">[21]</ref> and there is often not a universally accepted measure. However, Demographic Parity is the most widely used <ref type="bibr" target="#b22">[23,</ref><ref type="bibr">6,</ref><ref type="bibr">3]</ref>. Demographic Parity demandsŷ ⊥ s whereŷ refers to the predictions of the classifier. In the context of fair representations, we measure the Demographic Parity of a downstream classifier, f (·), which is trained on the representation z i.e. f : Z →Ŷ .</p><p>A core principle of all fairness methods is the accuracy-fairness trade-off. As previously stated, the fair representation should be invariant to s (→ fairness) but still be predictive of y (→ accuracy). These desiderata cannot, in general, be simultaneously satisfied if s and y are correlated.</p><p>The majority of existing methods for fair representations also make use of y labels during training, in order to ensure that z remains predictive of y. This as-   pect can, in theory, be removed from the methods, but then there is no guarantee that information about y is preserved <ref type="bibr" target="#b22">[23]</ref>.</p><p>Learning fair, transferrable representations. In addition to producing fair representations, <ref type="bibr" target="#b23">[24]</ref> want to ensure the representations are transferrable. Here, an adversary is used to remove sensitive information from a representation z. Auxiliary prediction and reconstruction networks, to predict class label y and reconstruct the input x respectively, are trained on top of z, with s being ancillary input to the reconstruction. Also related is <ref type="bibr">[4]</ref> who employ a FactorVAE <ref type="bibr">[18]</ref> regularised for fairness. The idea is to learn a representation that is both disentangled and invariant to multiple sensitive attributes. This factorisation makes the latent space easily manipulable such that the different subspaces can be freely removed and composed at test time. Zeroing out the dimensions or replacing them with independent noise imparts invariance to the corresponding sensitive attribute. This method closely resembles ours when we use an invertible encoder. However, the emphasis of our approach is on interpretability, information-preservation, and coping with sampling bias -especially extreme cases where | supp</p><formula xml:id="formula_0">(S tr × Y tr )| &lt; | supp(S te × Y te )|.</formula><p>Attempts were made by <ref type="bibr" target="#b24">[25]</ref> prior to this work to learn fair representations in the data domain in order to make it interpretable and transferable. In their work, the input is assumed to be additively decomposable in the feature space into a fair and unfair component, which together can be used by the decoder to recover the original input. This allows us to examine representations in a humaninterpretable space and confirm that the model is not learning a relationship reliant on a sensitive attribute. Though a first step in this direction, we believe such a linear decomposition is not sufficiently expressive to fully capture the relationship between the sensitive and non-sensitive attributes. Our approach allows for the modelling of more complex relationships.</p><p>Learning in the presence of spurious correlations. Strong spurious correlations make the task of learning a robust classifier challenging: the classifier may learn to exploit correlations unrelated to the true causal relationship between the features and label, and thereby fail to generalise to novel settings. This problem was recently tackled by <ref type="bibr">[17]</ref> who apply a penalty based on the mutual information between the feature embedding and the spurious variable. While the method is effective under mild biasing, we show experimentally that it is not robust to the range of settings we consider.</p><p>Jacobsen et al. <ref type="bibr">[12]</ref> explore the vulnerability of traditional neural networks to spurious variables -e.g., textures, in the case of ImageNet <ref type="bibr">[8]</ref> -and propose a INN-based solution akin to ours. The INN's encoding is split such that one partition, z b is encouraged to be predictive of the spurious variable while the other serves as the logits for classification of the semantic label. Information related to the nuisance variable is "pulled out" of the logits as a result of maximising log p(s|z n ). This specific approach, however, is incompatible with the settings we consider, due to its requirement that both s and y be available at training time.</p><p>Viewing the problem from a causal perspective, <ref type="bibr">[2]</ref> develop a variant of empirical risk minimisation called invariant risk minimisation (IRM). The goal of IRM is to train a predictor that generalises across a large set of unseen environments; because variables with spurious correlations do not represent a stable causal mechanism, the predictor learns to be invariant to them. IRM assumes that the training data is not iid but is partitioned into distinct environments, e ∈ E. The optimal predictor is then defined as the minimiser of the sum of the empirical risk R e over this set. In contrast, we assume possession of only a single source of labelled, albeit spuriously-correlated, data, but that we have a second source of data that is free of spurious correlations, with the benefit being that it only needs to be labelled with respect to s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Interpretable Invariances by Null-Sampling</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Statement</head><p>We assume we are given inputs x ∈ X and corresponding labels y ∈ Y. Furthermore, there is some spurious variable s ∈ S associated with each input x which we do not want to predict. Let X, S and Y be random variables that take on the values x, s and y, respectively. The fact that both y and s are predictive of x implies that I(X; Y ), I(X; S) &gt; 0, where I(·; ·) is the mutual information. Note, however, that the conditional entropy is non-zero: H(S|X) = 0, i.e., S is not completely determined by X.</p><p>The difficulty of this setup emerges in the training set: there is a close correspondence between S and Y , such that for a model that sees the data through the lens of the loss function, the two are indistinguishable. Furthermore, we assume that this is not the case in the test set, meaning the model cannot rely on shortcuts provided by S if it is to generalise from the training set.  We call this scenario where we only have access to the labels of a biasedlysampled subpopulation an aggravated fairness problem. These are not uncommon in the real-world. For instance, in long-feedback systems such as mortgageapproval where the demographics of the subpopulation with observed outcomes is not representative of the subpopulation on which the model has been deployed. In this case, s has the potential to act as a false (or spurious) indicator of the class label and training a model with such a dataset would limit generalisability. Let (X tr , S tr , Y tr ) then be the random variables sampled for the training set and (X te , S te , Y te ) be the random variables for the test set. The training and test sets thus induce the following inequality for their mutual information:</p><formula xml:id="formula_1">I(S tr ; Y tr ) I(S te ; Y te ) ≈ 0.</formula><p>Our goal is to learn a representation z u that is independent of s and transferable between downstream tasks. Complementary to z u , we refer to some abstract component of the model that absorbs the unwanted information related to s as B, the realisation of which we define with respect to each of the two models to be described. The requirement for z u can be expressed via mutual information:</p><formula xml:id="formula_2">I(z u ; s) ! = 0 .<label>(1)</label></formula><p>However, for the representation to be useful, we need to capture as much relevant information in the data as possible. Thus, the combined objective function:</p><formula xml:id="formula_3">min θ E x∼X [− log p θ (x)] + λI(f θ (x); s)<label>(2)</label></formula><p>where θ refers to the trainable parameters of our model f θ and p θ (x) is the likelihood it assigns to the data. We optimise this loss in an adversarial fashion by playing a min-max game, in which our encoder acts as the generative component. The adversary is an auxiliary classifier g, which receives z u as input and attempts to predict the spurious variable s. We denote the parameters of the adversary as φ; for the parameters of the encoder we use θ, as before. The objective from Eq <ref type="formula" target="#formula_3">(2)</ref> is then</p><formula xml:id="formula_4">min θ∈Θ max φ∈Φ E x∼X [log p θ (x) − λL c (g φ (f θ (x))); s)]<label>(3)</label></formula><p>where L c is the cross-entropy between the predictions for s and the provided labels. In practice, this adversarial term is realised with a gradient reversal layer (GRL) <ref type="bibr">[7]</ref> between z u and g as is common in adversarial approaches <ref type="bibr">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Disentanglement Dilemma</head><p>The objective in Eq (3) balances the two desiderata: predicting y and being invariant to s. However, in the training set (X tr , S tr , Y tr ), y and s are so strongly correlated that removing information about s inevitably removes information about y. This strong correlation makes existing methods fail under this setting. In order to even define the right learning goal, we require another source of information that allows us to disentangle s and y. For this, we assume the existence of another set of samples that follow a similar distribution to the test set, but whilst the sensitive attribute is available, the class labels are not. In reality, this is not an unreasonable assumption, as, while properly annotated data is scarce, unlabelled data can be obtained in abundance (with demographic information from census data, electoral rolls, etc.). Previous work has also considered treated "unlabelled data" as still having s labels <ref type="bibr" target="#b26">[27]</ref>. We are restricted only in the sense that the spurious correlations we want to sever are indicated in the features. We call this the representative set, consisting of X rep and S rep . It fulfils I(S rep ; Y rep ) ≈ 0 (or rather, it would, if the class labels Y rep were available). We now summarise the training procedure; an outline for the invertible network model (cFlow) can be seen in <ref type="figure" target="#fig_6">Fig. 3a</ref>. First, the encoder network f is trained on (X rep , S rep ), during the first phase. The trained network is then used to encode the training set, taking in x and producing the representation, z u , decorrelated from the spurious variable. The encoded dataset can then be used to train any off-the-shelf classifier safely, with information about the spurious variable having been absorbed by some auxiliary component B. In the case of the conditional VAE (cVAE) model, B takes the form of the decoder subnetwork, which reconstructs the data conditional on a one-hot encoding of s, while for the invertible network B is realised as a partition of the feature map z (such that z = [z u , z b ]), given the bijective constraint. Thus, the classifier cannot take the shortcut of learning s and instead must learn how to predict y directly. Obtaining the s-invariant representations, x u , in the data domain is simply a matter of replacing the B component of the decoder's input for the cVAE, and z b for cFlow, with a zero vector of equivalent size. We refer to this procedure used to generate x u as null-sampling (here, with respect to z b ).</p><p>Null-sampling resembles the annihilation operation described in <ref type="bibr" target="#b27">[28]</ref>, however we note that the two serve very different roles. Whereas the annihilation operation serves as a regulariser to prevent trivial solutions (similar to <ref type="bibr">[13]</ref>), null-sampling is used to generate the invariant representations post-training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Conditional Decoding</head><p>We first describe a VAE-based model similar to that proposed in <ref type="bibr" target="#b23">[24]</ref>, before highlighting some of its shortcomings that motivate the choice of an invertible representation learner.</p><p>The model takes the form of a class conditional β-VAE <ref type="bibr">[9]</ref>, in which the decoder is conditioned on the spurious attribute. We use θ enc , θ dec ∈ θ to denote the parameters of the encoder and decoder sub-networks, respectively. Concretely, the encoder component performs the mapping x → z u , while B is instantiated as the decoder, B := p θ dec (x|z u , s), which takes in a concatenation of the learned non-spurious latent vector z u and a one-hot encoding of the spurious label s to produce a reconstruction of the inputx. Conditioning on a one-hot encoding of s, rather than a single value, as done in <ref type="bibr" target="#b23">[24]</ref> is the key to visualising invariant representations in the data domain. If I(z u ; s) is properly minimised, the decoder can only derive its information about s from the label, thereby freeing up z u from encoding the unwanted information while still allowing for reconstruction of the input. Thus, by feeding a zero-vector to the decoder we achievex ⊥ s. The full learning objective for the cVAE is given as</p><formula xml:id="formula_5">L cVAE =E q θenc (zu,b|x) [log p θ dec (x|z, b) − log p θ dec (s|z u )] − βD KL (q θenc (z u |x) p(z u ))<label>(4)</label></formula><p>where β is a hyperparameter that determines the trade-off between reconstruction accuracy and independence constraints, and p(z u ) is the prior imposed on the variational posterior. For all our experiments, p(z u ) is realised as an Isotropic Gaussian. <ref type="figure" target="#fig_6">Fig. 3b</ref> summarises the procedure as a diagram. While we show this setup can indeed work for simple problems, as <ref type="bibr" target="#b23">[24]</ref> before us have, we show that it lacks scalability due to disagreement between the components of the loss. Since information about s is only available to the decoder as a binary encoding, if the relationship between s and x is highly non-linear and cannot be summarised by a simple on/off mechanism, as is the case if s is an attribute such as gender, off-loading information to the decoder by conditioning is no longer possible. As a result, z u is forced to carry information about s in order to minimise the reconstruction error.</p><p>The obvious solution to this is to allow the encoder to store information about s in a partition of the latent space as in <ref type="bibr">[4]</ref>. However, we question whether an autoencoder is the best choice for this setup, with the view that an invertible model is the better tool for the task. Using an invertible model has several guarantees, namely complete information-preservation and freedom from a reconstruction loss, the importance of which we elaborate on below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Conditional Flow</head><p>Invertible Neural Networks. Invertible neural networks are a class of neural network architecture characterised by a bijective mapping between their inputs and output <ref type="bibr">[5]</ref>. The transformations are designed such that their inverses and Jacobians are efficiently computable. These flow-based models permit exact likelihood estimation <ref type="bibr">[14]</ref> through the warping of a base density with a series of invertible transformations and computing the resulting, highly multi-modal, but still normalised, density, using the change of variable theorem:</p><formula xml:id="formula_6">log p(x) = log p(z) + log det dh i h i−1 , p(z) = N (z; 0, I)<label>(5)</label></formula><p>where h i refers to the outputs of the layers of the network and p(z) is the base density, specifically an Isotropic Gaussian in our case. Training of the invertible neural network is then reduced to maximising log p(x) over the training set, i.e. maximising the probability the network assigns to samples in the training set.</p><p>The Benefits of Bijectivity. Using an invertible network to generate our encoding, z u , carries a number of advantages over other approaches. Ordinarily, the main benefit of flow-based models is that they permit exact density estimation. However, since we are not interested in sampling from the model's distribution, in our case the likelihood term serves as a regulariser, as it does for <ref type="bibr">[11]</ref>. Critically, this forces the mean of each latent dimension to zero enabling null-sampling. The invertible property of the network guarantees the preservation of all information relevant to y which is independent of s, regardless of how it is allocated in the output space. Secondly, we conjecture that the encodings are more robust to out-of-distribution data. Whereas an autoencoder could map a previously seen input and a previously unseen input to the same representation, an invertible network sidesteps this due to the network's bijective property, ensuring all relevant information is stored somewhere. This opens up the possibility of transfer learning between datasets with a similar manifestation of s, as we demonstrate in the Appendix G.</p><p>Under our framework, the invertible network f maps the inputs x to a representation z u : f (x) = z. We interpret the embedding z as being the concatenation of two smaller embeddings: z = [z u , z b ]. The dimensionality of z b , and z u , by complement, is a free parameter (see Appendix C.5 for tuning strategies). As f is invertible, x can be recovered like so:</p><formula xml:id="formula_7">x = f −1 ([z u , z b ])<label>(6)</label></formula><p>where z b is required for equality of the output dimension and input dimension to satisfy the bijectivity of the network -we cannot output z u alone, but have to output z b as well. In order to generate the pre-image of z u , we perform null-sampling with respect to z b by zeroing-out the elements of z b (such that</p><formula xml:id="formula_8">x u = f −1 ([z u ,</formula><p>→ 0 ])), i.e. setting them to the mean of the prior density, N (z; 0, I). How can we be sure that z u contains enough information about y? The importance of the invertible architecture bears out from this consideration. As long as z b does not contain the information about y, z u necessarily must. We can raise or lower the information capacity of z b by adjusting its size; this should be set to the smallest size sufficient to capture all information about s, so as not to sacrifice class-relevant information. Appendix B.3 explores the effects of the size further.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We present experiments to demonstrate that the null-sampled representations are in fact invariant to s while still allowing a classifier to predict y from them. We run our cVAE and cFlow models on the coloured MNIST (cMNIST) and CelebA dataset, which we artificially bias, first describing the sampling procedure we follow to do so for non-synthetic datasets. As baselines we have the model of <ref type="bibr">[17]</ref> (Ln2L) and the same CNN used to evaluate the cFlow and cVAE models but with the unmodified images as input (CNN). For the cFlow model we adopt a Glowlike architecture <ref type="bibr">[19]</ref>, while both subnetworks of the cVAE model comprise gated convolutions <ref type="bibr" target="#b25">[26]</ref>, where the encoding size is 256. For cMNIST, we construct the Ln2L baseline according to its original description, for CelebA, we treat it as an augmentation of the baseline CNN's objective function. Detailed information regarding model architectures can be found in Appendix A and C.  Synthesising Dataset Bias. For our experiments, we require a training set that exhibits a strong spurious correlation, together with a test set that does not. For cMNIST, this is easily satisfied as we have complete control over the data generation process. For CelebA and UCI Adult, on the other hand, we have to generate the split from the existing data. To this end, we first set aside a randomly selected portion of the dataset from which to sample the biased dataset The portion itself is then split further into two parts: one in which (s = −1 ∧ y = −1) ∨ (s = +1 ∧ y = +1) holds true for all samples, call this part D eq , and the other part, call it D opp , which contains the remaining samples. To investigate the behaviour at different levels of correlation, we mix these two subsets according to a mixing factor η. For η ≤ 1 2 , we combine (all of) D eq with a fraction of 2η from D opp . For η &gt; 1 2 , we combine (all of) D opp and a fraction of 2(1 − η) from D eq . Thus, for η = 0, the biased dataset is just D eq , for η = 1 it is just D opp and for η = 1 2 the biased dataset is an ordinary subset of the whole data. The test set is simply the data remaining from the initial split.</p><p>Evaluation protocol. We evaluate our results in terms of accuracy and fairness. A model that perfectly decouples its predictions from s will achieve near-uniform accuracy across all biasing-levels. For binary s/y we quantify the fairness of a classifier's predictions using demographic parity (DP): the absolute difference in the probability of a positive prediction for each sensitive group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental results</head><p>We report the results from two image datasets. cMNIST, a synthetic dataset, is a good starting point for evaluating our model due to the direct control we have over the biasing. CelebA, on the other hand, is a more practical and challenging example. We also test our method on a tabular dataset, the Adult dataset.</p><p>cMNIST. The coloured MNIST (cMNIST) dataset is a variant of the MNIST dataset in which the digits are coloured. In the training set, the colours have a one-to-one correspondence with the digit class. In the test set (and the representative set), colours are assigned randomly. The colours are drawn from Gaussians with 10 different means. We follow the colourisation procedure outlined by <ref type="bibr">[17]</ref>, with the mean colour values selected so as to be maximally dispersed. The full list of such values can be found in Appendix D. We produce multiple variants of the cMNIST dataset corresponding to different standard deviations σ for the colour sampling: σ ∈ {0.00, 0.01, ..., 0.05}.</p><p>For this specific dataset, we can establish an additional baseline by simply grey-scaling the dataset which only leaves the luminosity as spurious information.</p><p>We also evaluate the model, with all the associated hyperparameters, from <ref type="bibr">[17]</ref>. The only difference between the setups is the dataset creation, including the range of σ values we consider. Our versions of the dataset, on the whole, exhibit much stronger colour bias, to the point of the mapping the digit's colour and class being bijective. <ref type="figure" target="#fig_11">Fig. 6</ref> shows that the model significantly underperforms even the naïve baseline, aside from at σ = 0, where they are on par.</p><p>Inspection of the null-samples shows that both the cVAE and cFlow model succeed in removing almost all colour information, which is supported quantitatively by <ref type="figure" target="#fig_11">Fig. 6</ref>. While the cVAE outperforms cFlow marginally at low σ values, performance degrades as this increases. This highlights the problems with the conditional decoder we anticipated in Section 3.3. The lower σ, and therefore the variation in sampled colour, is, the more reliably the s label, corresponding to the mean of RGB distribution, encodes information about the colour. For higher σ values, the sampled colours can deviate far from the mean and so the encoder must incorporate information about s into its representation if it is to minimise the reconstruction loss. cFlow, on the other hand, is consistent across σ values.</p><p>CelebA. To evaluate the effectiveness of our framework on real-world image data we use the CelebA dataset <ref type="bibr" target="#b21">[22]</ref>, consisting of 202,599 celebrity images. These images are annotated with various binary physical attributes, including "gender", "hair color", "young", etc, from which we select our sensitive and target attributes. The images are centre cropped and resized to 64 × 64, as is standard practice. For our experiments, we designate "gender" as the sensitive attribute, and "smiling" and "high cheekbones" as target attributes. We chose gender as the sensitive attribute as it a common sensitive attribute in the fairness literature. For the target attributes, we chose attributes that are harder to learn than gender and which do not correlate too strongly with gender in the dataset ("wearing lipstick" for example being an attribute too closely correlated with gender). The model is trained on the representative set (normal subset of CelebA) and is then used to encode the artificially biased training set and the test set. The results for the most strongly biased training set (η = 0) can be found in <ref type="figure" target="#fig_8">Fig. 4</ref>. Our method outperforms the baselines in accuracy and fairness.</p><p>We also assess performance for different mixing factors (η) which correspond to varying degrees of bias in the training set (see <ref type="figure" target="#fig_9">Fig. 5</ref>). This is to verify that the model does not harm performance when there is not much bias in the training set. For these experiments, the model is trained once on the representative set and is then used to encode different training sets. The results show that for the intermediate values of η, our model incurs a small penalty in terms of accuracy, but at the same time makes the results fairer (corresponding to an accuracyfairness trade-off). Qualitative results can be found in <ref type="figure" target="#fig_1">Fig. 1</ref> (images from cVAE can be found in Appendix F).</p><p>To show that our method can handle multinomial, as well as binary, sensitive attributes, we also conduct experiments with s = hair color as a ternary attribute ("Blonde" "Black", "Brown"), excluding "Red" because of the paucity of samples and the noisiness of their labels. The results for these experiments can be found in Appendix B.2.  Results for the UCI Adult dataset. The UCI Adult dataset consists of census data and is commonly used to evaluate models focused on algorithmic fairness. Following convention, we designate "gender" as the sensitive attribute s and whether an individual's salary is $50,000 or greater as y. We show the performance of our approach in comparison to baseline approaches in <ref type="figure" target="#fig_13">Fig. 7</ref>. We evaluate the performance of all models for mixing factors (η) 0 and 1. Results shown in <ref type="figure" target="#fig_13">Fig. 7</ref> show that we match or exceed the baseline. In terms of fairness metrics, our approach generally outperforms the baseline models for both of η. Detailed results can be found in the Appendix B.1.</p><p>We also did experiments to show that the encoder transfers to other tasks. These transfer-learning experiments can be found in Appendix G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We have proposed a general and straightforward framework for producing invariant representations, under the assumption that a representative but partiallylabelled representative set is available. Training consists of two stages: an encoder is first trained on the representative set to produce a representation that is invariant to a designated spurious feature. This is then used as input for a downstream task-classifier, the training data for which might exhibit extreme bias with respect to that feature. We train both a VAE-and INN-based model according to this procedure, and show that the latter is particularly well-suited to this setting due to its losslessness. The design of the models allows for representations that are in the data domain and therefore exhibit meaningful invariances. We characterise this for synthetic as well as real-world datasets for which we develop a method for simulating sampling bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Model Architectures</head><p>For both cMNIST and CelebA we parameterise the coupling layers with the same convolutional architecture as in <ref type="bibr">[11]</ref>, consisting of 3 convolutional layers each with 512 filters of, in order, sizes 3 × 3, 1 × 1, and 3 × 3. Following <ref type="bibr">[1]</ref>, we Xavier initialise all but the last convolutional layer of the s and t sub-networks which itself is zero-initialised so that the coupling layers begin by performing an identity transform. We used a Glow-like architecture <ref type="bibr">[11]</ref> (affine coupling layers together with checkerboard reshaping and invertible 1 × 1 convolutions) for the convolutional INNs. <ref type="table" target="#tab_0">Table 1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>summarises the INN architectures used for each dataset.</head><p>For the image datasets each level of the cVAE encoder consists of two gated convolutional layers <ref type="bibr">[18]</ref> with ReLU activation. At each subsequent level, the number of filters is doubled, starting with an initial value 32 and 64 in the case of CelebA and cMNIST respectively. In the case of the Adult dataset, we use an encoder with one fully-connected hidden layer of width 35, followed by SeLU activation <ref type="bibr">[12]</ref>. For both cMNIST and CelebA, we downsample to a feature map with spatial dimensions 8 × 8, but with 3 and 16 channels respectively. For the Adult dataset, the encoding is a vector of size 35. The output layer specifies both the parameters (mean and variance) of the representation's distribution. In all cases the KL-divergence is computed with respect to a standard isotropic Gaussian prior. Details of the encoder architectures can be found in <ref type="table" target="#tab_1">Table 2</ref>. The loss pre-factors were sampled from a logarithmic scale; without proper balancing the networks can exhibit instability, especially during the early stages of training. This census data is commonly used to evaluate models focused on algorithmic fairness. Following convention, we designate "gender" as the s and whether an individual's salary is $50,000 or greater as y. We show the performance of our approach in comparison to baseline approaches in <ref type="figure" target="#fig_1">Fig. 1</ref>. We evaluate the performance of all models for mixing factors (η) of value {0, 0.1, ..., 1}. Results shown in <ref type="figure" target="#fig_1">Fig. 1</ref> show that whilst our model fails to surpass the baseline models in terms of accuracy for the balanced case (and those close to it), we match or exceed the baseline as η moves the dataset to a more imbalanced setting. In terms of fairness metrics, our approach generally outperforms the baseline models regardless of η.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Multinomial sensitive attributes</head><p>In addition to binary sensitive attribute s, we also investigate multinomial s in the CelebA dataset. First, we do experiments with hair color, where s has three possible values: blond hair, brown hair and black hair. The other experiment is with a combination of age and gender, where s has four possible values, each of which is a combination of a gender and an age: Young/Female, Young/Male, Old/Female and Old/Male. To evaluate the fairness for multinomial s, we use the Hirschfeld-Gebelein-Rényi Maximum Correlation Coefficient (HGR) <ref type="bibr">[15]</ref> that is defined on the domain [0, 1] and gives HGR(Y, S) = 0 iff Y ⊥ S and 1 if there is a deterministic function to map between them. Results can be found in <ref type="figure" target="#fig_4">Figure 2</ref>. In the cFlow model, the size of z b is an important hyperparameter which can affect the result significantly. Here we investigate the sensitivity of the model to the choice of z b size. <ref type="table" target="#tab_2">Table 3</ref> shows accuracy and fairness (as measured by DP diff ) for different sizes of z b . The results show that both too large and too small z b is detrimental. However, they also show that the model is not overly sensitive to this parameter: both sizes 5 and 10 achieve nearly identical results. In addition to DP diff, we report here the result from other fairness measures. These results are from the same setup as those reported in the main paper. We report the difference in true positive rates (TPR) between the two groups (male and female), which corresponds to a measure of Equality of Opportunity, and the difference in true negative rates (TNR) between the two groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Investigation into the size of z b</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Additional fairness metrics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Optimisation Details</head><p>All our models were trained using the RAdam optimiser <ref type="bibr">[13]</ref> with learning rates 3 × 10 −4 and 1 × 10 −3 for the encoder/discriminator pair and classifier respectively. A batch size of 128 was used for all experiments. We now detail the optimisation settings, including the choice of adversary, specific to each dataset. Details of the cVAE and cFlow architectures can be found in <ref type="table" target="#tab_1">Table 2</ref> and <ref type="table" target="#tab_0">Table 1</ref>, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 UCI Adult</head><p>For this dataset our experiment benefited from using null-samples as inputs to the adversary of the cFlow model. Unlike for the image datasets, we found a single adversary to be sufficient. This was realised as a multi-layer perceptron (MLP) with one hidden layer, 256 units wide. The INN performs a bijection of the form f : R n → R n . However, the adult dataset is composed of mostly discrete (binary/categorical) features. To achieve good performance, we found it necessary to first pre-process the inputs with a pretrained autoencoder, using its encodings as the input to the cFlow model, as well as to the adversary. The learned representations were evaluated with a logistic regression model from scikit-learn <ref type="bibr">[16]</ref>, using the standard settings. All baseline models were trained for 200 epochs. The Ln2L <ref type="bibr">[10]</ref> and MLP baselines share the architecture of the cVAE's encoder, only with a classification layer affixed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Coloured MNIST</head><p>Each level of the architecture used for the downstream classifier and naïve baseline alike consists of two convolutional layers, each with kernel size 3 and followed by Batch Norm <ref type="bibr">[8]</ref> and ReLU activation. For the Ln2L baseline, we use an a setup identical to that described in <ref type="bibr">[10]</ref>. Each level has twice the number of filters in its convolutional layer and half the spatial input dimensions as the last. The original input is downsampled to the point of the output being reduced to a vector, to which a fully-connected classification layer is applied.</p><p>To allow for an additional level in the INN (the downsampling operations requiring the number of spatial dimensions to be even), the data was zero-padded to a size of 32 × 32. The cVAE and cFlow models were trained for 50 and 200 epochs respectively, using 2 reconstruction loss for the former. The downstream classifier and all baselines were trained for 40 epochs. For both of our models, an ensemble of 5 adversaries was applied to the encodings, with each member taking the form of a fully-connected ResNet, 2 blocks in depth, with SeLU activation <ref type="bibr">[12]</ref>. The adversaries were reinitialised independently with probability 0.2 at the end of each epoch. While the adversaries could equally well take null-samples as input, as done for the Adult dataset, doing so requires the performing of both forward and inverse passes each iteration, which, for the convolutional INNs of the depths we require for the image datasets, introduces a large computational overhead, while also showing to be the less stable of the two approaches in our preliminary experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 CelebA</head><p>The downstream classifier and naïve baseline take the same form as described above for cMNIST, but with an additional level with 32 filters in each of its convolutions at the top of the network. For this dataset we adapt the Ln2L model by simply considering it as an augmentation the naïve baseline's objective function, with the entropy loss applied to the output of the final convolutional layer. These models were again trained for 40 epochs, which we found to be sufficient for convergence for the tasks in question. The cVAE and cFlow models were respectively trained for 100 epochs and 30 epochs, using 1 reconstruction loss for the former. Compared with cMNIST, the size of the adversarial ensemble was increased to 10, the reinitialisation probability to 0.33, but no changes were made to the architectures of its members.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4 The Pitfalls of Adversarial Training</head><p>Adversarial learning has become one of the go-to methods for enforcing invariance in fair representation learning <ref type="bibr">[7]</ref> with MMD <ref type="bibr">[14]</ref> and HSIC <ref type="bibr">[17]</ref>, being popular non-parametric alternatives. <ref type="bibr">[7]</ref> proposed adversarial learning for domain adaptation problems, with <ref type="bibr">[5]</ref> soon after making this and learning a representation promoting demographic parity. The adversarial approach carries the benefits of being both efficient and scalable to multi-class categorical variables, which many sensitive attributes are in practice, whereas the non-parametric methods only permit pair-wise comparison.</p><p>However, when realised as a neural network, the adversary is both sensitive to the values of the inputs as well as their ordering (though exchangeable architectures, such as <ref type="bibr">[20]</ref> do exist, but which sacrifice expressiveness). Thus, it can happen that the representation learner optimises for the surrogate objective of eluding the adversary rather than the real objective of expelling s-related information. Moreover, the non-stationarity of the dynamics can lead to cyclicequilibria, irrespective of the capacity of the adversary.</p><p>When working with a partitioned latent space, this behaviour can be averted by instead encouraging z b to be predictive of s, acting as a kind of information "sink", as in <ref type="bibr">[9]</ref>. However, this does not have the guarantee of making z u invariant to s -there are often many indicators for s, not all of which are needed to predict the label perfectly. Training the network to convergence before taking each gradient step with the representation learner is one way one to attempt to tame the unstable minimax dynamics <ref type="bibr">[6]</ref>. However, this does not prevent the emergence of the aforementioned cyclicity.</p><p>We try to mitigate the aforementioned degeneracies by maintaining a diverse set of adversaries, as has shown to be effective for GAN training <ref type="bibr">[4]</ref>, and by decorrelating the individual trajectories by intermittently re-initialising them with some small probability following each iteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5 Tuning the Partition Sizes.</head><p>There are several ways of ensuring that z b is of sufficient size to capture all s dependencies, while at time is minimised such as that information unrelated to s is maximally preserved. We adopt the straightforward search strategy of, starting from some initial guess, calibrating the value according to accuracy attained by a classifier trained to predict s from z b on a held-out subset of the representative set, which is measured whenever the adversarial loss plateaus. If the accuracy is above chance level then that suggests the size of the z b partition, |z b |, needs to be increased to accommodate more information about s. If the accuracy is found to be at chance level then are two possibilities: 1) |z b | is already optimal; 2) |z b | is large enough that it fully contains both information s as well as that of a portion of y. If the former is true, then perturbations around the current value allow us to confirm this; if the latter is true then decreasing the value was indeed the correct decision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Synthesising Coloured MNIST</head><p>We use a colourised version of MNIST as a controlled setting investigate learning from biased data in the image domain. In the biased training set, each digit is assigned a unique mean RGB value parameterising the multivariate Gaussian from which its colour is drawn. These values were chosen to be maximally dispersed across the 8-bit colour spectrum and are listed in <ref type="table" target="#tab_4">Table 5</ref>. By adjusting the standard deviation, σ, of the Gaussians, we adjust the degree of bias in the dataset. When σ = 0, there is a perfect and noiseless correspondence between colour and digit class which a classifier can exploit. The classifier can favour the learning of the low-level spurious feature over those higher level features constituent of the digit's class. As the standard deviation increases, the sampled RGB values are permitted to drift further from the mean, leading to overlap between the samples of the colour distributions and reducing their reliability as indicators of the digit class. In the test and representative sets alike, however, the colour of each sample is sampled from one of the 10 distributions randomly, such that colour can no longer be leveraged as a shortcut to predicting the digit's class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Stabilising the Coupling layers</head><p>Heuristically, we found that applying an additional nonlinear function to the scale coefficient of the form s = σ(f (u)) + 0.5 greatly improved the stability of the affine coupling layers. Here, σ is the logistic function, which we shift to be centred on 1 so that zero-initialising f results in the coupling layers initially performing an identity-mapping.  biases it may have implicitly captured due to entanglement between the sensitive attribute and other attributes present in the data. We highlight a few examples of such biases manifesting in the cFlow model's CelebA null-samples in <ref type="figure" target="#fig_8">Fig. 4</ref>. In these cases, makeup and hair style have been inadvertently modified during the null-sampling due to the tight correlation between these two attributes and the sensitive attribute, gender, to which we had aimed to make our representations invariant. Additionally, in all highlighted images, the skin tone has changed: from male to gender-neutral, the skin becomes lighter and from female to genderneutral, the skin becomes darker; in the change from male to gender-neutral, glasses are also often removed. As the model cannot know that the label is meant to only refer to gender, and not to these other (correlated) attributes, the links cannot be disentangled by the model. However, the advantage of our method is that we can at least identify such biases due to the interpretability that comes with the representations being in the data domain.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G Transfer Learning</head><p>For our method, we require a representative set which follows the same distribution as that observed during deployment. Such a representative set might not always be available. In such a scenario, we can resort to using a set that is merely similar to that in the deployment setting and leverage transfer learning. One of the advantages of using an invertible architecture over conventional, surjective ones that we stressed in the main text is its losslessness. Since the transformations are necessarily bijective, the information contained in the input can never be destroyed, only redistributed. This makes such models particularly well-suited, in our minds, for transferring learned invariances: even if the input is unfamiliar, no information should be lost when trying to transform it. This works as long as only the information about s ends up in the z b partition. If s takes a form similar to that which we pre-trained on, and can thus be correctly partitioned in the latent space, by complement we have the information about ¬s stored in the z u partition, without presupposing similarity to the ¬s observed during pre-training.</p><p>Transferring from mixed-NIST to MNIST. We test our hypothesis by comparing the performance of the cFlow and cVAE models pre-trained on a mixture of datasets belonging to the NIST family, colourised in the same way as cMNIST, while the downstream train and test sets remain the same as in the original cMNIST experiments. Specifically, we create this representative set by sampling 24,000 images (to match the cardinality of the original representative set) from EMNIST (letters only) <ref type="bibr">[3]</ref>, FashionMNIST <ref type="bibr">[19]</ref> and KMNIST <ref type="bibr">[2]</ref>, in equal proportion. We use the same architectures for the cVAE and cFlow models as we did in the non-transfer learning setting. In terms of hyperparameters, the only change made was to the KL-divergence's pre-factor, finding it necessary to increase it to 1 to guarantee stability.</p><p>The results for the range of σ values are shown in <ref type="figure" target="#fig_9">Fig. 5a</ref>. Unsurprisingly, the performance of both models suffers when the representative and test sets do not completely correspond. However, the cFlow model consistently outperforms the cVAE model, with the gap increasing as the bias decreases. Although some colour information is retained in the cFlow null-samples, symptomatic of an imperfect transfer, semantic information is almost entirely retained as well. Conversely, the cVAE is very much flawed in this respect; as can be seen in the bottom row of <ref type="figure" target="#fig_9">Fig. 5a</ref>, for some samples, semantic information is degraded to the point of the digit's identity being altered. As a result of this semantic degradation, the performance of the downstream classifier is curtailed by the noisiness of the digit's identity and is relatively unchanging across σ-values, in contrast to the monotonic improvement of that achieved on the cFlow null-samples.  and after (right) null-sampling. Note that for some of the cVAE samples, the clarity of the digits has clearly changed due to null-sampling, serving as an explanation for the non-increasing downstream performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>(a) Original images. (b) xu null-samples from the cFlow model. (c) x b null-samples from the cFlow model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>CelebA null-samples learned by our cFlow model, with gender as the sensitive attribute. (a) The original, untransformed samples from the CelebA dataset (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(a) Samples from the cM-NIST training set, σ = 0.(b) xu null-samples from the cFlow model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(c) x b null-samples from the cFlow model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 2 .</head><label>2</label><figDesc>Sample images from the coloured MNIST dataset problem with 10 predefined mean colours. (a): Images from the spuriously correlated subpopulation where colour is a reliable signal of the digit class-label. (b-c): Results of running our approach realised with cFlow on the cMNIST dataset. The model learns to retain the shape of the digit shape while removing the relationship with colour. A downstream classifier is now less prone to exploiting correlations between colour and the digit label class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 .</head><label>3</label><figDesc>Training procedure for our models. x: input, s: sensitive attribute, zu: debiased representation, xu: de-biased version of the input in the data domain. The red bar indicates a gradient reversal layer, and → 0 the null-sampling operation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 4 .</head><label>4</label><figDesc>Performance of our model for different targets (mixing factor η = 0). Left: Smiling as target, right: high cheekbones. DP diff measures fairness with respect to demographic parity. A perfectly fair model has a DP diff of 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 5 .</head><label>5</label><figDesc>Performance of our model for the target "smiling" for different mixing factors η. DP diff measures fairness with respect to demographic parity. A perfectly fair model has a DP diff of 0, thus the closer to top-left the better it is in terms of we accuracyfairness trade-off. Only values η = 0 and η = 1 correspond to the scenario of a strongly biased training set. The results for 0.1 ≤ η ≤ 0.9 are to confirm that our model does not harm performance for non-biased training sets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 6 .</head><label>6</label><figDesc>Accuracy of our approach in comparison with other baseline models on the cMNIST dataset, for different standard deviations (σ) for the colour sampling.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Fig. 7 .</head><label>7</label><figDesc>Results for the Adult dataset. The x-axis corresponds to the difference in positive rates. An ideal result would occupy the top-left.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Results for the Adult dataset. The x-axis corresponds to the difference in positive rates. An ideal result would occupy the top-left. For hair color, s takes on the values Blond, Brown and Black. For age+gender, s takes on the values Young/Female, Young/Male, Old/Female and Old/Male.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 3 .</head><label>3</label><figDesc>CelebA null-samples learned by our cVAE model, with gender as the sensitive attribute. (a) The original, untransformed samples from the CelebA dataset (b) Reconstructions using only information unrelated to s. (c) Reconstruction using only information related to ¬s. The model learns to disentangle gender from the non-gender related information. Compared with the cFlow model, there is a severe degradation in reconstruction quality due to the model trying to simultaneously satisfy conflicting objectives.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>( a )</head><label>a</label><figDesc>Original images. (b) xu null-samples generated by the cFlow model. (c) x b null-samples generated by the cFlow model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Fig. 4 .</head><label>4</label><figDesc>CelebA null-samples learned by our cFlow model, with gender as the sensitive attribute. (a) The original, untransformed samples from the CelebA dataset (b) Reconstructions using only information unrelated to s. (c) Reconstruction using only information related to ¬s. The model learns to disentangle gender from the non-gender related information. Attributes such as makeup and hair length are also often modified in the process (prime examples framed with red) due to inherent correlations between them and the sensitive attribute, which the interpretability of our representations allows us to easily identify.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head></head><label></label><figDesc>Performance on cMNIST test data after pretraining on the mixed NIST dataset. (b) Test data input to the cFlow model. (c) xu null-samples generated by the cFlow model. (d) Test data input to the cVAE model. (e) xu null-samples generated by the cVAE model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Fig. 5 .</head><label>5</label><figDesc>Results for the transfer learning experiments in which the representative set consists of colourised samples from EMNIST, KMNIST, and FashionMNIST, while the downstream dataset remains as cMNIST. (a) Quantitative results for different σvalues. (b-c) Qualitative results for the cFlow model. (d-e) Qualitative results for the cVAE model. The qualitative results provide comparisons of the images before (left)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>INN architecture used for each dataset.</figDesc><table><row><cell>Dataset</cell><cell cols="4">Levels Level depth Coupling channels Input to discriminator(s)</cell></row><row><cell cols="2">UCI Adult 1</cell><cell>1</cell><cell>35</cell><cell>Null-samples</cell></row><row><cell>cMNIST</cell><cell>3</cell><cell>16</cell><cell>512</cell><cell>Encodings</cell></row><row><cell>CelebA</cell><cell>3</cell><cell>32</cell><cell>512</cell><cell>Encodings</cell></row><row><cell cols="3">B Additional results</cell><cell></cell><cell></cell></row></table><note>B.1 Detailed results for UCI Adult dataset</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>cVAE encoder architecture used for each dataset. The decoder architecture in each case mirrors that of its encoder counterpart through use of transposed convolutions. For the adult dataset we apply 2 and cross-entropy losses to the reconstructions of the continuous features and discrete features, respectively.</figDesc><table><row><cell>Dataset</cell><cell>Initial channels</cell><cell>Levels</cell><cell>β</cell><cell>Recon. loss</cell></row><row><cell>UCI Adult</cell><cell>35</cell><cell>-</cell><cell>0</cell><cell>2 + CE</cell></row><row><cell>cMNIST</cell><cell>32</cell><cell>4</cell><cell>0.01</cell><cell>2</cell></row><row><cell>CelebA</cell><cell>32</cell><cell>5</cell><cell>1</cell><cell>1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Results on the CelebA dataset with different sizes of z b .</figDesc><table><row><cell>|z b |</cell><cell>|z b |/|z|</cell><cell>Accuracy</cell><cell>DP diff</cell></row><row><cell>1</cell><cell>0.0082%</cell><cell>0.60</cell><cell>0.63</cell></row><row><cell>3</cell><cell>0.0245%</cell><cell>0.60</cell><cell>0.63</cell></row><row><cell>5</cell><cell>0.0410%</cell><cell>0.84</cell><cell>0.12</cell></row><row><cell>10</cell><cell>0.0820%</cell><cell>0.84</cell><cell>0.12</cell></row><row><cell>30</cell><cell>0.2442%</cell><cell>0.74</cell><cell>0.23</cell></row><row><cell>50</cell><cell>0.4070%</cell><cell>0.68</cell><cell>0.27</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Additional fairness metrics for the experiments on the CelebA dataset (Fig. 5 from the main text). TPR diff. refers to the difference in true positive rate. TNR diff. refers to the difference in true negative rate. Left: η = 0. Right: η = 1.</figDesc><table><row><cell cols="5">Method Accuracy DP diff TPR diff TNR diff</cell><cell cols="5">Method Accuracy DP diff TPR diff TNR diff</cell></row><row><cell>cFlow</cell><cell>0.83</cell><cell>0.10</cell><cell>0.15</cell><cell>0.25</cell><cell>cFlow</cell><cell>0.82</cell><cell>0.33</cell><cell>0.28</cell><cell>0.21</cell></row><row><cell>cVAE</cell><cell>0.82</cell><cell>0.05</cell><cell>0.09</cell><cell>0.18</cell><cell>cVAE</cell><cell>0.81</cell><cell>0.16</cell><cell>0.10</cell><cell>0.05</cell></row><row><cell>CNN</cell><cell>0.61</cell><cell>0.63</cell><cell>0.70</cell><cell>0.64</cell><cell>CNN</cell><cell>0.67</cell><cell>0.75</cell><cell>0.66</cell><cell>0.76</cell></row><row><cell>Ln2L[10]</cell><cell>0.52</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>Ln2L[10]</cell><cell>0.51</cell><cell>0.08</cell><cell>0.06</cell><cell>0.09</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Mean RGB values (in practice normalised to [0, 1]) parameterising the Multivariate Gaussian distributions from which each digit's colour is sampled in the biased (training) dataset. In the representative and test sets, the colour of each digit is sampled from one of the specified Gaussian distributions at random.</figDesc><table><row><cell>Digit</cell><cell>Colour Name</cell><cell>Mean RGB</cell></row><row><cell>0</cell><cell>Cyan</cell><cell>(0, 255, 255)</cell></row><row><cell>1</cell><cell>Blue</cell><cell>(0, 0, 255)</cell></row><row><cell>2</cell><cell>Magenta</cell><cell>(255, 0, 255)</cell></row><row><cell>3</cell><cell>Green</cell><cell>(0, 128, 0)</cell></row><row><cell>4</cell><cell>Lime</cell><cell>(0, 255, 0)</cell></row><row><cell>5</cell><cell>Maroon</cell><cell>(128, 0, 0)</cell></row><row><cell>6</cell><cell>Navy</cell><cell>(0, 0, 128)</cell></row><row><cell>7</cell><cell>Purple</cell><cell>(128, 0, 128)</cell></row><row><cell>8</cell><cell>Red</cell><cell>(255, 0, 0)</cell></row><row><cell>9</cell><cell>Yellow</cell><cell>(255, 255, 0)</cell></row><row><cell cols="2">F Qualitative Results for CelebA</cell><cell></cell></row><row><cell cols="3">Learning a representation alongside its inverse mapping, be it approximate or</cell></row><row><cell cols="3">exact, enables us to probe the behaviour of the model that produced it, and any</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was in part funded by the European Research Council under the ERC grant agreement no. 851538. We are grateful to NVIDIA for donating GPUs.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Discovering interpretable representations for both deep generative and discriminative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tameem</forename><surname>Adel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoubin</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Weller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="50" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Invariant risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Arjovsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data Decisions and Theoretical Implications when Adversarially Learning Fair Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Beutel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Fairness, Accountability, and Transparency in Machine Learning (FAT/ML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Flexibly Fair Representation Learning by Disentanglement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elliot</forename><surname>Creager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning (ICML)</title>
		<meeting>the 36th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1436" to="1445" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">NICE: Non-linear Independent Components Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Censoring Representations with an Adversary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Geirhos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">β-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irina</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Improving fairness in machine learning systems: What do industry practitioners need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Holstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">In: CHI Conference on Human Factors in Computing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Oyallon</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>i-RevNet: Deep Invertible Networks</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Excessive Invariance Causes Adversarial Vulnerability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Unsupervised adversarial invariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayush</forename><surname>Jaiswal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5092" to="5102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Variational Inference with Normalizing Flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danilo</forename><surname>Jimenez Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakir</forename><surname>Mohamed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Residual Unfairness in Fair Machine Learning from Prejudiced Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Kallus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2444" to="2453" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tuning Fairness by Balancing Target Labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Kehrenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zexun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Novi</forename><surname>Quadrianto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning Not to Learn: Training Deep Neural Networks with Biased Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungju</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision and pattern recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Disentangling by Factorising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunjik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andriy</forename><surname>Mnih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2654" to="2663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10236" to="10245" />
		</imprint>
	</monogr>
	<note>Glow: Generative Flow with Invertible 1x1 Convolutions</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Auto-Encoding Variational Bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Delayed Impact of Fair Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lydia</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep Learning Face Attributes in the Wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Variational Fair Autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning Adversarially Fair and Transferable Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Madras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3381" to="3390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Discovering Fair Representations in the Data Domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Novi</forename><surname>Quadrianto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktoriia</forename><surname>Sharmanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision and pattern recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4790" to="4798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unlocking Fairness: a Tradeoff Revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Wick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Tristan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8783" to="8792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">DNA-GAN: Learning disentangled representations from multi-attribute images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taihong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiapeng</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwen</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR workshop</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning Fair Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Visual interpretability for deep learning: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Quan-Shi Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers of Information Technology &amp; Electronic Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="27" to="39" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Guided Image Generation with Conditional Invertible Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lynton</forename><surname>Ardizzone</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02392</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Deep learning for classical japanese literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tarin</forename><surname>Clanuwat</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01718</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">EMNIST: Extending MNIST to handwritten letters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 International Joint Conference on Neural Networks (IJCNN). IEEE. 2017</title>
		<imprint>
			<biblScope unit="page" from="2921" to="2926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generative Multi-Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ishan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Durugkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sridhar</forename><surname>Gemp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahadevan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Censoring Representations with an Adversary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harrison</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Learning fair representations via an adversarial framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.13341</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaroslav</forename><surname>Ganin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.03167</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jörn-Henrik</forename><surname>Jacobsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnold</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Oyallon</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>i-RevNet: Deep Invertible Networks</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning Not to Learn: Training Deep Neural Networks with Biased Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungju</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision and pattern recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10236" to="10245" />
		</imprint>
	</monogr>
	<note>Glow: Generative Flow with Invertible 1x1 Convolutions</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Self-normalizing neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Günter</forename><surname>Klambauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="971" to="980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">On the variance of the adaptive learning rate and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyuan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.03265</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The Variational Fair Autoencoder</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Louizos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Fairnessaware learning for continuous attributes and treatments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jérémie</forename><surname>Mary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clément</forename><surname>Calauzènes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noureddine</forename><forename type="middle">El</forename><surname>Karoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4382" to="4391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Discovering Fair Representations in the Data Domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Novi</forename><surname>Quadrianto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktoriia</forename><surname>Sharmanska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer vision and pattern recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Conditional image generation with pixelcnn decoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4790" to="4798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kashif</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deep sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3391" to="3401" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
