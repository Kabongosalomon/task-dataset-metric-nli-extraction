<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Suarez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">DDRprog: A CLEVR Differentiable Dynamic Reasoning Programmer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a novel Dynamic Differentiable Reasoning (DDR) framework for jointly learning branching programs and the functions composing them; this resolves a significant nondifferentiability inhibiting recent dynamic architectures. We apply our framework to two settings in two highly compact and data efficient architectures: DDRprog for CLEVR Visual Question Answering and DDRstack for reverse Polish notation expression evaluation. DDRprog uses a recurrent controller to jointly predict and execute modular neural programs that directly correspond to the underlying question logic; it explicitly forks subprocesses to handle logical branching. By effectively leveraging additional structural supervision, we achieve a large improvement over previous approaches in subtask consistency and a small improvement in overall accuracy. We further demonstrate the benefits of structural supervision in the RPN setting: the inclusion of a stack assumption in DDRstack allows our approach to generalize to long expressions where an LSTM fails the task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction and Related Works</head><p>Deep learning is inherently data driven -visual question answering, scene recognition, language modeling, speech recognition, translation, and other supervised tasks can be expressed as: given input x, predict output y. The field has attempted to model different underlying data structures with neural architectures, but core convolutional and recurrent building blocks were designed with only general notions of spatial and temporal locality. In some cases, additional information about the problem can be expressed simply as an additional loss, but when hard logical assumptions are present, it is nonobvious how to do so in a manner compatible with backpropagation.</p><p>Discrete logic is a fundamental component of human visual reasoning: we present a general neural framework for differentiable reasoning over discrete data structures, including stacks and trees. Prior work has demonstrated some success for individual data structures and settings. StackRNN <ref type="figure">Figure 1</ref>. Prior work reads the question and predicts a program composed of functional modules (denoted f1, f2, etc.); in contrast our model interleaves module prediction and module execution. Whereas IEP suffers an important nondifferentibility (red X), our model provides an end-to-end differentiable gradient path. <ref type="bibr" target="#b7">(Joulin &amp; Mikolov, 2015)</ref> allows recurrent architectures to push and pop from a stack without explicit supervision. However, implicit learning only goes so far: the hardest task it was tested on is binary addition. Approaches such as recursive NN <ref type="bibr" target="#b13">(Socher et al., 2011)</ref> and TreeRNN <ref type="bibr" target="#b15">(Tai et al., 2015)</ref> enable explicit tree structure supervision, but only when the structure is also known at test time.</p><p>Our framework is flexible to differing degrees of increased supervision and demonstrates improved results when structural assumptions are available at test time. This approach is intended for maximally complex problems not feasible with minimal supervision: we are concerned with efficient incorporation of additional supervision rather than avoiding it. This paradigm enables our framework to circumvent scalability limitations commonly apparent in tasks involving discrete data structures, as demonstrated by both our RPN experiments and the restricted task scope of StackRNN.</p><p>We present our framework in the context of two broad architecture classes: Neural Module Networks (NMN, <ref type="bibr" target="#b0">(Andreas et al., 2015)</ref>) and Neural Programmer-Interpreters (NPI, <ref type="bibr" target="#b11">(Reed &amp; de Freitas, 2015)</ref>). The original NMN allows per-arXiv:1803.11361v1 [cs.CV] 30 Mar 2018 example dynamic architectures assembled from a set of smaller models; it was concurrently adapted in N2NMN <ref type="bibr" target="#b4">(Hu et al., 2017)</ref> and IEP <ref type="bibr" target="#b6">(Johnson et al., 2017)</ref> as the basis of the first visual question answering (VQA) architectures successful on CLEVR <ref type="bibr" target="#b5">(Johnson et al., 2016)</ref>. The NPI work allows networks to execute programs by directly maximizing the probability of a successful execution trace. Our framework is a superset of both approaches; DDRprog is an application thereof to CLEVR VQA. Our model interleaves program prediction and program execution by using the output of each module to predict the next module. This is an important contribution because discrete program prediction in IEP/N2NMN is not differentiable <ref type="figure">(Figure 1</ref>). Selection of modules in our model is also not differentiable, but it is influenced by the loss gradient: program execution gives a learnable pathway through the question answer loss. The second contribution of this architecture is a novel differentiable forking mechanism that enables our network to process logical tree structures by maintaining a stack of saved states. This allows our model to perform a broad range of logical operations; DDRprog is the first architecture to obtain strong performance across all CLEVR subtasks.</p><p>CLEVR has been effectively solved with and without program supervision, but it remains the best available proxy task for designing discrete visual reasoning systems because of its scale, diverse logical subtask categories, and program annotations. By effectively leveraging the additional program annotations, we improve over the previous state-of-the-art with a much smaller model -on the important Count and Compare Integer subtasks, we improve from 94.5 to 96.5 percent and 93.8 to 98.4 percent, respectively. However, our true objective is to enable discrete logic in neural architectures and thereby motivate more complex tasks over knowledge graphs. CLEVR is an early first step, inevitably solvable without program annotations. In the long term, human-level general visual reasoning from scratch is less reasonable than from expressively annotated data: we consider generalizing the ability of architectures to leverage additional supervision to be a likely avenue of success.</p><p>Prior work on CLEVR is largely categorized by dynamic and static approaches. IEP and N2NMN both generalized the original neural module networks architecture and used the functional annotations in CLEVR to predict a static program which is then assembled into a tree of discrete modules and executed. IEP further demonstrated success when program annotations are available for only a few percent of questions. These are most similar to our approach; we focus largely upon comparison to IEP, which performs significantly better. RN <ref type="bibr" target="#b12">(Santoro et al., 2017)</ref> and FiLM <ref type="bibr" target="#b10">(Perez et al., 2017b)</ref>, the latter being the direct successor of CBN <ref type="bibr" target="#b9">(Perez et al., 2017a)</ref> are both static architectures which incorporate some form of implicit reasoning module in order to achieve high performance without program annotations. <ref type="figure">Figure 2</ref>. The baseline LSTM fails to learn the expression parse tree underlying reverse Polish notation; it therefore fails to generalize to expressions longer than seen at training time. In contrast, our DDRstack architecture cleanly incorporates supervision of this stack based tree representation and solves the generalization task.</p><p>In contrast, our architecture uses program annotations to explicitly model the underlying question structure and jointly executes the corresponding functional representation. As a result, our architecture performs comparably on questions requiring only a sequence of filtering operations and significantly better on questions involving higher level operations such as counting and numerical comparison.</p><p>We present DDRstack as a second application of our framework and introduce a reverse Polish notation (RPN) expression evaluation task. The task is solvable by leveraging the stack structure of expression evaluation, but is extremely difficult without additional supervision. DDRstack effectively solves the task by differentiably incorporating the relevant stack structure; in contrast, a much larger LSTM baseline fails the generalization test ( <ref type="figure">Figure 2</ref>). Thus, we use RPN as additional motivation for our framework: despite major quantitative differences from CLEVR VQA, the RPN task is structurally similar. In the former, questions seen at training time contain programmatic representations well modeled by a set of discrete logical operations and a stack requiring at most one recursive call. The latter is an extreme case with deep recursion requiring a full stack representation, but this stack structure is also available at test time.</p><p>In summary: the DDR framework combines the interleaving program prediction and execution behavior of NPI with the learnable module structure of NMN and IEP to jointly learn branching programs and the functions composing them. Our approach resolves common differentibility issues and is easily adapted to problem specifics: we achieve a moderate improvement over previous state-of-the-art on CLEVR and succeed on RPN; a large baseline LSTM fails to generalize.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">CLEVR</head><p>CLEVR is a synthetic but realistic VQA dataset that encourages discrete reasoning approaches through its inclusion of functional program annotations that model the logic of each question. The dataset consists of 100k images and 1 million question/answer pairs and has been carefully calibrated to avoid exploitable biases. Over 850k of these questions are unique. Images are high quality 3D Blender <ref type="bibr" target="#b1">(Blender, 2017)</ref> renders of scenes containing geometric objects of various shapes, sizes, colors, textures, and materials: Unlike earlier VQA datasets, no external knowledge of natural images is required. Program annotations link natural language questions to discrete logic. For example, "How many red spheres are there?" is represented as [filter red, filter sphere, count]. Some questions require branching programs, such as "How many objects are red or spheres?", which is represented by a tree with branches [filter red] and [filter sphere] followed by a binary <ref type="bibr">[union]</ref> operation and a final <ref type="bibr">[count]</ref>. We include additional examples in the Supplement.</p><p>Initial benchmarks made CLEVR appear challenging, but clever architectures quickly solved the task both with and without using program annotations. One perspective is that this should motivate a return to the natural image setting without programs or with transfer learning from CLEVR. In contrast, we believe recent successes motivate more complex synthetic tasks -perhaps involving harder logical inference over general knowledge graphs. Designing a visual Turing test with corresponding training data will likely require much iteration and experimentation. The synthetic setting is uniquely suited to this task: iterative prototyping is expensive and time consuming for natural image datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">RPN</head><p>We introduce the reverse Polish notation (RPN) expression evaluation dataset to motivate additional supervision in higher level learning tasks. The specific problem form we consider eliminates order of operations: [NUM]*(n+1)-[OP]*n, that is, n + 1 numbers followed by n operations. For example, "2 3 4 + *" evaluates to 14. Thus the task is: given a sequence of tokens corresponding to a valid expression in reverse Polish notation, evaluate the expression and produce a single real valued answer.</p><p>This may seem like a simple task; it is not. For large n, expressions behave somewhat like a hash function. Small changes in the input can cause wild variations in the output -we found the problem intractable in general. Our objective is to make stronger structural assumptions about the problem and create an architecture to leverage them. For this reason, our framework is incomparable to StackRNN, which attempts to learn a stack structure implicitly but is unable to incorporate additional supervision when the problem is likely too difficult to solve otherwise. We therefore modify the problem as such: instead of producing only the final expression evaluation, produce the sequence of answers to all n intermediate expressions in the answer labels. For the example "2 3 4 + *", the expected output would be <ref type="bibr">[7,</ref><ref type="bibr">14]</ref> because 3+4=7 and 2*7=14. We further assume the stack structure of the problem is available to the architecture should it be capable of taking advantage of such information. The problem is still sufficiently complex -note that to the model, {1, 3, 4, +, * } would all be meaningless tokens: it must learn both the NUM and the OP tokens.</p><p>The dataset consists of 100k train, 5k validation, and 20k test expression with n = 10 -that is, 11 numbers followed by 10 operations. We also provide a 20k expression generalization set with n = 30. The label for each question contains the n solutions to each intermediate operation. During data generation, we sample NUM and OP tokens uniformly, reject expressions including division by zero, and omit expressions with |answer| &gt; 100. The NUM tokens correspond to 0, 0.1, ..., 0.9 and the OP tokens correspond to +, -, *, /; however, architectures are not privy to this information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">DDR Architecture</head><p>The purpose of the DDR framework is to naturally incorporate structured information into a neural reasoning architecture. This is important when the given problem is hard without additional supervision and allows the model to perform discrete, complex reasoning. Our framework addresses the difficulty of combining discrete logic with differentiable training and is capable of interfacing with a broad range of data structures. Like IEP, we maintain a set of neural modules to allow our model to learn relevant program primitives. Like NPI, we interleave program prediction with program execution, differentiably learning modules when module arrangement is not known at test time. This is much more general compared to either IEP/NMN or NPI independently, and the particular mechanism for combining them is a non-trivial differentiable forking operation. IEP alone lacks the ability to examine the output of intermediate operations; our CLEVR results demonstrate the importance of this. The NPI architecture can learn sequences of functions, but lacks the ability to learn the functions themselves. Our approach responds flexibly to the problem supervision: in VQA, modules are known only at train time. At each timestep, the controller therefore produces an index corresponding to a neural module, which is then executed. On the RPN task, the problem structure is also known at test time; the controller is therefore deterministic and directly executes the correct module. We refer to our VQA and RPN architecture adaptations as DDRprog and DDRstack, respectively; details are provided below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">CLEVR Visual Question Answering: DDRprog</head><p>DDRprog is a direct adaptation of our framework to CLEVR. We provide pseudocode in Algorithm 1, a visual example in <ref type="figure" target="#fig_0">Figure 3</ref>, and subnetwork details the Supplement.</p><p>The input data x for each sample is a (image, question, program) triple; the training label y is a (answer, program) pair. Our model must predict the program at test time.</p><p>The network first applies standard LSTM and ResNet  encoders to the question/image to produce language and visual states, respectively. The ResNet encoder is unchanged from FiLM/IEP. Both the language and visual states are passed to the controller. We use a recurrent highway network (RHN) <ref type="bibr" target="#b17">(Zilly et al., 2016)</ref> as recommended by <ref type="bibr" target="#b14">(Suarez, 2017)</ref> instead of an LSTM <ref type="bibr" target="#b3">(Hochreiter &amp; Schmidhuber, 1997</ref>) -both accept flat inputs. As the visual state contains convolutional maps, we flatten it with a standard classifier.</p><p>At each time step, the controller outputs a standard softmax classification prediction, which is interpreted as an index over the set of learnable neural modules. These are smaller, slightly modified variants of the modules used in IEP. The selected module is executed on the visual state; crucially, the visual state is then set to the output. The module prediction at the final timestep is followed by a small classifier network, which uses the IEP classifier. This architecture introduces a significant advantage over IEP: as modules are predicted and executed one at a time instead of being compiled into a static program, our model can observe the result of intermediate function operations -these have meaning as filtering and counting operations on CLEVR.</p><p>Algorithm 1 DDRprog. Note that CNN produces a flattened output and Controller also performs a projection and argmax over program scores to produce</p><formula xml:id="formula_0">programP rediction input img, question ← x stack ← Stack() img, imgCopy ← ResNetFeaturizer(img) langState ← LSTM(question) for i = 1...M axP rogramLength do visualState ← CNN(img) programP rediction ← Controller(visualState, langState) cell ← Cells[programP rediction] if cell is F ork then stack.push(cell(img, imgCopy)) else if cell is Binary then img ← cell(stack.pop(), img) else img ← cell(img) end if end for output Classifier(img)</formula><p>We now motivate our differentiable forking mechanism. As presented thus far, our approach is sufficient on the subset of CLEVR programs that do not contain comparison operations and are effectively linear -indeed, we observe a large performance increase over IEP on this subset of CLEVR. However, some CLEVR questions contain a logical branching operation (e.g. are there more of ... than ... ?) and cannot be answered by structurally linear programs. In general, programs can take the form of expressive trees, but CLEVR programs contain at most two branches; our ap- proach handles the general case without modification. Upon encountering a program branch, denoted by a special fork module, our architecture pushes the current language and visual states to a stack and forks a subprocess. This subprocess has its own visual state (output by the special fork module) but is otherwise equivalent to the main network. After processing the last operation in the branch, a binary cell is applied to the final subprocess state and the main process states (popped from the stack), merging them as shown in <ref type="figure" target="#fig_0">Figure 3</ref>. Our architecture is likely to generalize even past the setting of tree processing, as it could interact with arbitrary hashing algorithms, heaps, priority queues, or any other problem-specific data structures.</p><p>Finally, a technical note for reproducibility: the fork module must differ from a standard unary module, as it is necessary to pass the original ResNet features (e.g. the initial visual state) to the subprocess in addition to the current visual state. Consider the question: "Is the red thing larger than the blue thing?" In this case, the main network filters by red; it is impossible to recover the blue objects in the subprocess given a red filtered image. We found that it is insufficient to pass only the original images to the subprocess, as the controller is small and has difficulty tracking the current branch. We therefore use a variant of the binary module architecture that merges the original ResNet features with the current visual state (see Algorithm 1). As the fork module is shared across all branch patterns, it is larger than the other binary modules and also one layer deeper -refer to the Supplement for full architecture details on each layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Expressions in Reverse Polish Notation: DDRstack</head><p>The DDRstack architecture applies our framework to the RPN task, where module arrangement is a fixed expression parse tree. One natural view of the task is: given a parse tree structure, simultaneously socket and refine the learnable NUM and OP nodes. Our model consists of an LSTM controller and a set of four learnable binary modules -one per OP -as well as an explicit stack. DDRstack processes one token at a time; similar to unary/binary modules in IEP, NUM and OP tokens are processed differently: NUM: Our model embeds the token and passes it to the LSTM. It then pushes the result to the stack. OP: Our model pops twice, calls the OP specific binary cell, and then passes the results to the LSTM. It then pushes the result to the stack. The binary cell concatenates the arguments and applies a single fully connected layer DDRstack can be viewed as a neural analog to standard analytical RPN expression evaluation algorithm where the values of the NUM and OP tokens are unknown. We provide high level pseudocode for the model in Algorithm 2 and a visual representation in <ref type="figure" target="#fig_1">Figure 4</ref>.</p><p>We also train a baseline vanilla LSTM. DDRstack uses the same LSTM as its core controller, but includes the aforementioned stack behavior. Both models are given intermediate supervision, with predictions made in the last n timesteps (Algorithm 2 shows only the final return).  <ref type="table">Table 1</ref>. Accuracy on all CLEVR question types for baselines and competitive models. The Human baseline is from the original CLEVR work. * denotes additional program supervision. SA refers to stacked spatial attention <ref type="bibr" target="#b16">(Yang et al., 2015)</ref> . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Discussion</head><p>FiLM and RN have both exceeded human accuracy on CLEVR without program supervision -the task remains important for two reasons. First, both models exhibit curiously poor performance on at least one important subtask. Second, CLEVR remains the best proxy task for evaluating discrete reasoning systems because of its program annotations. We achieve a modest improvement over previous state-of-the-art in raw accuracy, but our work is more concerned with this second goal of creating of a general reasoning framework.</p><p>We presently consider RN, FiLM, IEP, and our architecture as competitive models. From <ref type="table">Table 1</ref>, no architecture has particular difficulty with Exist, Query, or Compare questions. Count and Compare Integer are thus the most discriminative unary and binary tasks, respectively. We achieve strong performance on both subtasks and a significant increment over previous state-of-the-art on the Count subtask.</p><p>We first compare to IEP. Our model is 4x smaller than IEP (see <ref type="table">Table 1</ref>) and resolves IEP's poor performance on the challenging Count subtask. Overall, DDRprog performs at least 2x better across all unary tasks (+1.7 percent on Exist, +3.8 percent on Count, + 1.0 percent on Query) and closely matches binary performance (+0.2 percent on Compare, -0.3 percent on Compare Integer). We believe that our model's lack of similar gains on binary task performance can be attributed to the use of a singular fork module, which is responsible for cross-communication during prediction of both branches of a binary program tree, shared across all binary modules. We have observed that this module is essential to obtaining competitive performance on binary tasks; it is likely suboptimal to use a large shared fork module as opposed to a separate smaller cell for each binary cell.</p><p>Our model surpasses RN in all categories of reasoning, achieving a 2.6x reduction in overall error. RN achieves impressive results for its size and lack of program labels, but it is questionable whether the all-to-all comparison model will generalize to more logically complex questions. In particular, Count operations do not have a natural formulation as a comparison between pairs of objects, in which case our model achieves a significant 6.4 percent improvement. RN also struggles on the challenging Compare Integer subtask, where we achieve a 4.8 percent improvement. Furthermore, it is unclear how essential high epoch counts are to the model's performance. As detailed in <ref type="table">Table 1</ref>, RN was trained in a distributed setting for 1000 epochs. Both our result and FiLM were obtained on single graphics cards and were only limited in number of epochs for practicality.</p><p>Both IEP and our model achieve a roughly 4x improvement over FiLM on Compare Integer questions (4.9 and 4.6 percent, respectively), the difference being that our model eliminates the Count deficiency and is also 4X smaller than IEP. The contrast between FiLM's Compare Integer and Exist/Query/Compare performance suggests a logical deficiency in the model -we believe it is difficult to model the more complex binary question structures using only implicit branching through batch normalization parameters. FiLM does achieve strong Compare Attribute performance, but many such questions are resolvable through a series of pure filtering operations. FiLM achieves 1.5x relative improvement over our architecture on Exist questions, but this is offset by our 1.5x relative improvement on Count questions.</p><p>Given proximity in overall performance, FiLM could be seen as the main competitor to our model. However, they achieve entirely different aims: DDRprog is an application of a general framework, &gt;5X smaller, and achieves stable performance over all subtasks. FiLM is larger and suffers from a significant deficiency on the Compare Integer subtask, but it uses less supervision. As mentioned in the introduction, our model is part of a general framework that better enables neural architectures to leverage discrete logical and structural information about the given problem. In contrast, FiLM is a single architecture that is likely more directly applicable to low-supervision natural image tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">DDRstack: RPN Experiments and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Experiments</head><p>For our architecture, we use hidden dimension 32 throughout the model, resulting in only 17k parameters overall. We train with Adam using learning rate 1e-3 and obtain a test L1 error of 0.17 after 63 epochs. Using the same hidden dimension in the pure LSTM baseline (9k parameters) results in test error 0.28. We overcompensate for the difference in model size by increasing the hidden dimension of the LSTM to 128 (255k parameters), resulting in an only slightly lower test error of 0.24 after nearly 3000 epochs. <ref type="figure" target="#fig_2">Figure 5</ref> shows training curves for the LSTM baseline and DDRstack.</p><p>After training both models on problems of length n = 10, we test both models on sequences of length n = 10 and n = 30. Recall that the loss is evaluated on the predicted answers to all n subproblems corresponding to the outputs of each OP function. Results are shown in <ref type="figure" target="#fig_2">Figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Discussion</head><p>We argue that the LSTM fails the RPN task. This is not immediately obvious: from <ref type="figure" target="#fig_2">Figure 5</ref>, both the small and large LSTM baselines approximately match our model's performance on the first 5 subproblems of the n = 10 dataset. From n = 6 to n = 10, the performance gap grows between our models -as neither LSTM baseline learned deep stack behavior, performance decays sharply.</p><p>The n = 30 dataset reveals the LSTM's failure. Performance is far worse on the first few subproblems of this dataset than on the test set of the original task. This is not an error: recall the question formatting [NUM]*(n + 1)-[OP]*n. The leading subproblems do not correspond to the leading tokens of the question, but rather to a central crop. For example, the first two subproblems of "12345+-*/" are given by "345+-", not "12345" -the latter is not a valid expression. The rapid increase in error on the LSTM implies that it did not learn this property, let alone the stack structure. Instead, it memorized all possible subproblems of length n ∈ {1, 2, 3} expressions preceding the first few OP tokens. Performance quickly decays to L1 error greater than 2.0, which corresponds to mostly noise (the standard deviation of answers minus the first few subproblems is approximately 6.0). In contrast, our model's explicit incorporation of the stack assumption results in a smooth generalization curve that gradually decays with increasing problem length.</p><p>We briefly address likely objections. First, one might argue that DDRstack cannot be compared to an LSTM, as the latter uses less supervision. This evaluation is precisely correct but is antithetical to the purpose of our work. There is no obvious method to include knowledge of a stack structure in an LSTM -the prevailing approach would be to ignore it and then argue superiority on the basis of achieving good performance with less supervision. This logic might suggest implicit reasoning approaches such as StackRNN, which attempt to model the underlying data structure without direct supervision. However, we do not expect such approaches to scale to RPN: the hardest task on which StackRNN was evaluated is binary addition. While StackRNN exhibited significantly better generalization compared to the LSTM baseline, the latter did not completely fail the task. In contrast, RPN is a more complex task that completely breaks the baseline LSTM. While we did not evaluate StackRNN on RPN (the original implementation is not compatible modern frameworks), we consider it highly improbably that StackRNN would generalize to RPN, which was intentionally designed to be difficult without additional supervision. In contrast, our approach solves the task through effective incorporation of additional supervision. StackRNN is to DDRstack as FiLM is to DDRprog: one motive is to maximize performance with minimal supervision whereas our motive is to leverage structural data to solve harder tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The DDR framework facilitates high level reasoning in neural architectures by enabling networks to leverage discrete logical information. Our approach represents a clean synthesis of the modeling capabilities of IEP/NMN and NPI through a forking mechanism that resolves common differentiability issues. We have demonstrated efficacy and ease of application to specific problems through DDRprog and DDRstack. DDRprog achieves a moderate improvement over previous state-of-the-art on CLEVR with greatly increased consistency and reduced model size. DDRstack succeeds on RPN where a much larger baseline LSTM fails to attain generalization. Our framework and its design principles enable modeling of complex data structure assumptions across a wide class of problems where standard monolithic approaches would ignore such useful properties. We hope that this increase in interoperability between discrete data structures and deep learning architectures aids in motivating higher level tasks for the continued development and progression of neural reasoning.  Concatenate <ref type="formula">(1)</ref> and <ref type="formula">(2)</ref> 2h × 14 × 14 (4)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Supplement</head><formula xml:id="formula_1">Conv(1 × 1, 2h → h) h × 14 × 14 (5) ReLU h × 14 × 14 (6) Conv(3 × 3, h → h) h × 14 × 14 (7) ReLU h × 14 × 14 (8) Conv(3 × 3, h → h) h × 14 × 14 (9)</formula><p>Add <ref type="formula">(5)</ref> and <ref type="formula">(8)</ref>     <ref type="table">Table 8</ref>. Architectural details of subnetworks in DDRprog as referenced in <ref type="figure" target="#fig_0">Figure 3</ref> and Algorithm 1 of the main paper. Finegrained layer details are provided in tables 1-5 of this supplement. Full source code will be released pending publication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subnetwork Details</head><p>ResNetFeaturizer Features from ResNet101 pretrained on ImageNet, as in IEP and FiLM LSTM 2-Layer LSTM that encodes the question CNN IEP classifier variant; produces a flat visual state.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Controller</head><p>Recurrent Highway Network for language and CNN Encoded visual states Cells IEP set of unary and binary modules, plus our fork module and pads <ref type="table">Table 9</ref>. Success examples on CLEVR. The numerical prefix on each program function is its arity.</p><p>• Image Index: 5156</p><p>• Question: there is a small purple rubber object; what shape is it ?</p><p>• Program (label): 1 filter size small 1 filter color purple 1 filter material rubber 1 unique 1 query shape • Answer (predicted, label): cylinder, cylinder • Image Index: 2364</p><p>• Question: what number of tiny brown shiny things are to the right of the matte sphere that is on the left side of the tiny red object to the right of the small yellow object ?</p><p>• Program (label): 1 filter size small 1 filter color yellow 1 unique 1 relate right 1 filter size small 1 filter color red 1 unique 1 relate left 1 filter material rubber 1 filter shape sphere 1 unique 1 relate right 1 filter size small 1 filter color brown 1 filter material metal 1 count • Answer (predicted, label): 1, 1</p><p>• Image Index: 4287</p><p>• Question: there is a block that is behind the cyan metal thing; what material is it ?</p><p>• Program (label): 1 filter color cyan 1 filter material metal 1 unique 1 relate behind 1 filter shape cube 1 unique 1 query material</p><p>• Answer (predicted, label): rubber, rubber</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Visualization of the DDRprog architecture. This configuration answers "How many things are red or spheres?" by predicting [f ilter red, f ork, f ilter sphere, union, count]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Visualization of the DDRstack architecture with n = 1. This particular configuration evaluates the [NUM][NUM][OP] formatted expression [0.4, 0.8, /], which is 0.4/0.8=0.5. NUM tokens are embedded before being passed to the LSTM. OP tokens are used as an index to select the corresponding cell. LSTM predictions at each OP token are used to predict intermediate losses (only one for n = 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Left: Training curves for DDRstack (train/val overlapping, 17k parameters) and the LSTM128 baseline (255k parameters) on RPN10. Right: Generalization performance of DDRstack and the LSTM baseline to RPN30 after training on RPN10.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Unary Module</figDesc><table><row><cell>Index</cell><cell>Layer</cell><cell>Output Size</cell></row><row><cell>(1)</cell><cell>Previous Module Output</cell><cell>h × 14 × 14</cell></row><row><cell>(2)</cell><cell>Conv(3 × 3, h → h)</cell><cell>h × 14 × 14</cell></row><row><cell>(3)</cell><cell>ReLU</cell><cell>h × 14 × 14</cell></row><row><cell>(4)</cell><cell>Conv(3 × 3, h → h)</cell><cell>h × 14 × 14</cell></row><row><cell>(5)</cell><cell cols="2">Residual: Add (1) and (4) h × 14 × 14</cell></row><row><cell>(6)</cell><cell>ReLU</cell><cell>h × 14 × 14</cell></row><row><cell>(7)</cell><cell>InstanceNorm</cell><cell>h × 14 × 14</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Binary Module</figDesc><table><row><cell>Index</cell><cell>Layer</cell><cell>Output Size</cell></row><row><cell>(1)</cell><cell cols="2">Previous Module Output h × 14 × 14</cell></row><row><cell>(2)</cell><cell cols="2">Previous Module Output h × 14 × 14</cell></row><row><cell>(3)</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>ResNetFeaturizer</figDesc><table><row><cell>Index</cell><cell>Layer</cell><cell>Output Size</cell></row><row><cell>(1)</cell><cell>Input Image</cell><cell>3 × 224 × 224</cell></row><row><cell>(2)</cell><cell>ResNet101 conv4 6</cell><cell>1024 × 14 × 14</cell></row><row><cell>(3)</cell><cell cols="2">Conv(3 × 3, 1024 → h) h × 14 × 14</cell></row><row><cell>(4)</cell><cell>ReLU</cell><cell>h × 14 × 14</cell></row><row><cell>(5)</cell><cell>Conv(3 × 3, h → h)</cell><cell>h × 14 × 14</cell></row><row><cell>(6)</cell><cell>ReLU</cell><cell>h × 14 × 14</cell></row><row><cell></cell><cell>Table 6. CNN</cell><cell></cell></row><row><cell>Index</cell><cell>Layer</cell><cell>Output Size</cell></row><row><cell>(1)</cell><cell>Previous Module Output</cell><cell>h × 14 × 14</cell></row><row><cell>(2)</cell><cell>Conv(3 × 3, h → h)</cell><cell>h × 14 × 14</cell></row><row><cell>(3)</cell><cell>ReLU</cell><cell>h × 14 × 14</cell></row><row><cell>(4)</cell><cell>Conv(3 × 3, h → h)</cell><cell>h × 14 × 14</cell></row><row><cell>(5)</cell><cell cols="2">Residual: Add (1) and (4) h × 14 × 14</cell></row><row><cell>(6)</cell><cell>ReLU</cell><cell>h × 14 × 14</cell></row><row><cell>(7)</cell><cell>MaxPool(2 × 2, h → h)</cell><cell>h × 7 × 7</cell></row><row><cell>(8) (9) (10)</cell><cell>Conv(3 × 3, h → 1 2 h) Flatten Linear( 1 2 h*5*5 × 1024)</cell><cell>1 2 h × 5 × 5 1 2 h*5*5 1024</cell></row><row><cell>(11)</cell><cell>ReLU</cell><cell>1024</cell></row><row><cell>(12)</cell><cell>Linear(1024 × Classes)</cell><cell>Classes</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 .</head><label>7</label><figDesc>Hyperparameter details for DDRprog. Only the learning rate and model size were coarsely cross validated due to hardware limitations: hyperparameter are not optimal.</figDesc><table><row><cell>Module</cell><cell>Architecture</cell></row><row><cell cols="2">Hidden dim., convolutional layers 64</cell></row><row><cell>Hidden dim., recurrent layers</cell><cell>128</cell></row><row><cell>Question encoder depth</cell><cell>2</cell></row><row><cell>Recurrent controller depth</cell><cell>3</cell></row><row><cell>Question vocabulary embedding</cell><cell>300</cell></row><row><cell>Learning rate</cell><cell>1e-4</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="table">Table 10</ref><p>. Failure examples on CLEVR. The numerical prefix on each program function is its arity. Many errors are the result of occlusions. This can be extreme: the second error example is only answerable by process of elimination.</p><p>• Image Index: 6688</p><p>• Question: what is the color of the tiny matte cylinder ?</p><p>• Program (label): 1 filter size small 1 filter material rubber 1 filter shape cylinder 1 unique 1 query color</p><p>• Answer (predicted, label): brown, gray</p><p>• Image Index: 8307</p><p>• Question: there is a small cube that is made of the same material as the gray object; what is its color ?</p><p>• Program (label): 1 filter color gray 1 unique 1 same material 1 filter size small 1 filter shape cube 1 unique 1 query color</p><p>• Answer (predicted, label): purple, yellow</p><p>• Image Index: 1902</p><p>• Question: what color is the block that is to the left of the big yellow matte block and behind the large blue shiny block ?</p><p>• Program (label): 1 filter size large 1 filter color yellow 1 filter material rubber 1 filter shape cube 1 unique 1 relate left 0 fork 1 filter size large 1 filter color blue 1 filter material metal 1 filter shape cube 1 unique 1 relate behind 2 intersect 1 filter shape cube 1 unique 1 query color • Answer (predicted, label): green, blue • Image Index: 8543</p><p>• Question: are there fewer small purple rubber things that are behind the green metallic cylinder than small things that are in front of the tiny matte block ?</p><p>• Program (label): 1 filter size small 1 filter material rubber 1 filter shape cube 1 unique 1 relate front 1 filter size small 1 count 0 fork 1 filter color green 1 filter material metal 1 filter shape cylinder 1 unique 1 relate behind 1 filter size small 1 filter color purple 1 filter material rubber 1 count 2 less than • Answer (predicted, label): no, yes</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Deep compositional question answering with neural module networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Andreas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
		<idno>abs/1511.02799</idno>
		<ptr target="http://arxiv.org/abs/1511.02799" />
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Blender -a 3D modelling and rendering package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blender</surname></persName>
		</author>
		<ptr target="http://www.blender.org" />
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>Blender Institute, Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>Blender Foundation</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Deep residual learning for image recognition. CoRR, abs/1512.03385</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaiming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiangyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1512.03385" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Long shortterm memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
		<ptr target="http://dx.doi.org/10.1162/neco.1997.9.8.1735" />
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Learning to reason: End-to-end module networks for visual question answering. CoRR, abs/1704.05526</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronghang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Saenko</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1704.05526" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bharath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girshick</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename></persName>
		</author>
		<idno>abs/1612.06890</idno>
		<ptr target="http://arxiv.org/abs/1612.06890" />
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Inferring and executing programs for visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justin</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bharath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Laurens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judy</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girshick</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename></persName>
		</author>
		<idno>abs/1705.03633</idno>
		<ptr target="http://arxiv.org/abs/1705.03633" />
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Inferring algorithmic patterns with stack-augmented recurrent nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>abs/1503.01007</idno>
		<ptr target="http://arxiv.org/abs/1503.01007" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization. CoRR, abs/1412</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6980</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Learning visual reasoning without strong priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Florian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<title level="m">Visual reasoning with a general conditioning layer</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Neural programmerinterpreters. CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">E</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nando</forename><surname>De Freitas</surname></persName>
		</author>
		<idno>abs/1511.06279</idno>
		<ptr target="http://arxiv.org/abs/1511.06279" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">A simple neural network module for relational reasoning. CoRR, abs/1706.01427</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">G T</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mateusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Razvan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">P</forename><surname>Lillicrap</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1706.01427" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Parsing Natural Scenes and Natural Language with Recursive Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th International Conference on Machine Learning (ICML)</title>
		<meeting>the 26th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Language modeling with recurrent highway hypernetworks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">;</forename><surname>Suarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garnett</forename></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/6919-language-modeling-with-recurrent-highway-hypernetworks.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>R.</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="3269" to="3278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Improved semantic representations from treestructured long short-term memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<idno>abs/1503.00075</idno>
		<ptr target="http://arxiv.org/abs/1503.00075" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Stacked attention networks for image question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zichao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xiaodong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jianfeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<idno>abs/1511.02274</idno>
		<ptr target="http://arxiv.org/abs/1511.02274" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><forename type="middle">G</forename><surname>Zilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rupesh</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Koutník</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1607.03474" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Recurrent highway networks. CoRR, abs/1607.03474</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
