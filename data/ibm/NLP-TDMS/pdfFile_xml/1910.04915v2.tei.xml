<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Flexible Multi-task Networks by Learning Parameter Allocation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Maziarz</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jagiellonian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Efi</forename><forename type="middle">Kokiopoulou</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jagiellonian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Gesmundo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jagiellonian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Luciano</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jagiellonian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sbaiz</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jagiellonian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabor</forename><forename type="middle">Bartok</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jagiellonian University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Berent</forename><surname>Google</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Jagiellonian University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Flexible Multi-task Networks by Learning Parameter Allocation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T17:01+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Index Terms-machine learning, neural networks</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper proposes a novel learning method for multi-task applications. Multi-task neural networks can learn to transfer knowledge across different tasks by using parameter sharing. However, sharing parameters between unrelated tasks can hurt performance. To address this issue, we propose a framework to learn fine-grained patterns of parameter sharing. Assuming that the network is composed of several components across layers, our framework uses learned binary variables to allocate components to tasks in order to encourage more parameter sharing between related tasks, and discourage parameter sharing otherwise. The binary allocation variables are learned jointly with the model parameters by standard back-propagation thanks to the Gumbel-Softmax reparametrization method. When applied to the Omniglot benchmark, the proposed method achieves a 17% relative reduction of the error rate compared to state-of-the-art.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Multi-task learning <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> based on neural networks has attracted a lot of research interest in the past years, and has been successfully applied to several application domains, such as recommender systems <ref type="bibr" target="#b2">[3]</ref>, real-time object detection <ref type="bibr" target="#b3">[4]</ref> and learning text representations <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. For instance, a movie recommendation system may optimize not only the likelihood of the user clicking on a suggested movie, but also the likelihood that the user is going to watch it.</p><p>The most common architecture used in practice for multitask learning is the so-called shared bottom, where the tasks share parameters in the early layers of the model, which are followed by task-specific heads. However, as our experiments on synthetic data show, when the tasks are unrelated, parameter sharing may actually hurt individual tasks performance. Therefore, resorting to flexible parameter sharing becomes very important. This can be achieved by manually trying several different static sharing patterns. However, this option is not scalable, since it requires significant effort. Instead, an approach where the sharing pattern is learned and adapted to the task relatedness is preferable.</p><p>In this work, we introduce a novel method that learns the sharing pattern jointly with the model parameters using standard back-propagation. Assuming that the network consists of several layers, where each layer consists of several components, the core idea of the proposed method is to learn, for each component, a set of binary allocation variables indicating which tasks use this component. We rely on the Gumbel-Softmax reparameterization method <ref type="bibr" target="#b6">[7]</ref> in order to train these binary variables jointly with the parameters of the components.</p><p>We provide experiments on both synthetic tasks and commonly used benchmarks, showing that the proposed framework can adapt the sharing pattern to the task relatedness, outperforming strong baselines and previous state-of-the-art methods. In summary, the paper contributions are the following:</p><p>• We analyze positive and negative transfer effects on synthetic tasks. This analysis motivates the need for taskdependent parameter sharing in multi-task networks. <ref type="bibr">•</ref> We propose a novel multi-task learning method based on Gumbel binary variables. It allows for learning flexible parameter sharing which adapts to the task relatedness, and can be optimized with standard back-propagation. <ref type="bibr">•</ref> We show that our method can be used to produce sparse task embeddings by concatenating the binary allocation patterns. We provide experimental evidence that such embeddings reflect task relatedness. The source code implementing the proposed method and the benchmarks described in this paper is publicly available under this link.</p><p>The rest of the paper is organized as follows. In Section II we provide experiments on synthetic data, showing that negative transfer may occur in practice, which motivates the need for flexible parameter sharing. In Section III we introduce in detail the proposed framework, and discuss related works in Section IV. Section V shows the experimental results, and Section VI summarizes our paper and outlines future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. POSITIVE AND NEGATIVE TRANSFER</head><p>We start with a practical example, showing that besides positive transfer, negative transfer may occur as well. That is, when the tasks are unrelated, allowing them to interact in a bigger model instead of training them separately harms the model performance. To show that both positive and negative transfer occurs, we generate two synthetic tasks, where the task relatedness ρ can be explicitly controlled. Our synthetic data generation process is based on that of <ref type="bibr" target="#b7">[8]</ref>, and we describe it in detail in Appendix A1. We consider two edge cases: two unrelated tasks (ρ = 0), and two tasks that are the same up to noise (ρ = 1).</p><p>We create a simple multi-task network. component contains a stack of fully connected layers. Each input example can be passed through any subset of the four parallel components; the outputs of the components are averaged before being passed to a task-specific linear head. We chose this network to have low enough capacity, so that there is visible competition between tasks. For more information about the architecture, please refer to Appendix A2.</p><p>For this experiment, we use two hard-coded sharing patterns. The 'shared bottom' pattern means that both tasks use all four components, while 'no sharing' means that each task is assigned two components out of four. Therefore, in the 'no sharing' pattern, the tasks are completely independent. Note that regardless of the pattern, the total amount of parameters in the model remains the same; the only difference is in which parameters get used by which tasks. In other words, 'no sharing' corresponds to imposing a constraint that the network should be evenly divided between the tasks, while 'shared bottom' leaves that to the optimization algorithm to decide.</p><p>We run four experiments: one for every combination of sharing pattern ('shared bottom' and 'no sharing'), and task relatedness (ρ ∈ {0, 1}). For each experiment, we report the L2 loss over time, averaged over the two tasks. The results are shown in <ref type="figure">Figure 1</ref>. Since for 'no sharing' there is no interaction between the tasks, the average loss behaves in the same way irrespective of the task relatedness. For 'shared bottom', both tasks are allowed to update all parameters, and we see that while it improves performance if the tasks are related, it actually hurts for two completely unrelated tasks.</p><p>Motivated by this example, we argue that general multi-task models should be able to learn flexible sharing patterns that can adapt to the task relatedness. In Section III, we introduce a framework which can learn such flexible sharing patterns, including but not limited to 'no sharing' and 'shared bottom'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. FRAMEWORK</head><p>We design our method so that it is able to learn to flexibly allocate components to tasks in a large modular network. In <ref type="figure" target="#fig_0">Figure 2</ref> we show an example, containing two tasks and two modular layers, followed by task-specific heads. Each task selects a subset of components within every layer. For every layer, we encode the component allocation as a binary matrix. Concretely, if there are T tasks, and C l components in the l-th layer, the matrix for that layer has shape T x C l , where the (i, j) entry is 1 if the j-th component is allocated to the i-th task. We show these binary allocation matrices at the bottom of <ref type="figure" target="#fig_0">Figure 2</ref>.</p><p>Our goal is to learn the binary allocation matrices in the way that maximizes the average per-task performance of the model. Note that the set of components used by a given input is conditioned on the task id only, which implies that all samples from the same task will go through the same part of the network. We refer to our framework as the Gumbel-Matrix framework. At training time our method samples many different allocation matrices, but after training a single binary matrix is selected for every layer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Training</head><p>For each layer, we want to maintain a probability distribution over all possible binary allocations. To make the problem tractable, we assume this distribution to be factorized, and explicitly maintain a matrix of probabilities for each component-task pair. Each probability is represented as a pair of two complementary logits. To perform a forward pass, we sample all binary connections independently according to the probability matrix. In principle, it is possible that for a given task all allocation variables for some layer are sampled to 0, meaning that no component in that layer is assigned to the task. In that case, we assume the output of the layer to be a zero vector, independently of the input. In practice, we found that this happens very rarely, and mostly at the beginning of training, since usually one of the allocation probabilities quickly becomes close to 1.0. Therefore, we did not try to devise a method which would artificially prevent an all-zeros allocation pattern from being sampled.</p><p>To initialize our method, we have to set the allocation probabilities to some initial values. In principle, it is possible to introduce prior knowledge, and set these probabilities in a way that encourages or discourages certain patterns. However, here we consider the most general approach, where all proba- bilities are initialized to the same constant value p init . Setting p init = 0.5 gives the highest entropy, and corresponds to the weakest prior, therefore we consider it as a default choice. However, in our experiments with large and deep networks, it is often beneficial to set p init closer to 1.0, in order to enhance the trainability of the components and to stabilize the initial learning phase.</p><p>In the backwards pass, only the components that are activated will get gradients, as the inactive components do not contribute to the final output of the network. However, in order to get a gradient for the allocation probabilities, we would have to back-propagate through sampling. In the next section, we describe a method which we use to accomplish that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Propagating gradients through binary samples</head><p>In order to get gradients to the allocation probabilities, we follow <ref type="bibr" target="#b6">[7]</ref>, and reparameterize sampling from a Bernoulli distribution using the Gumbel-Softmax trick. The Gumbel distribution can be defined by the following forward sampling procedure:</p><formula xml:id="formula_0">u ∼ Uniform(0, 1) ⇒ g = − log(− log(u)) ∼ Gumbel.</formula><p>Instead of using the logits to directly sample a binary value, we add independent noise from the Gumbel distribution to each of the logits, and then select the binary value with the highest logit (i.e. argmax) as the sample z. Formally, to sample from Bernoulli(p), we use the following procedure. Let π = [p, 1 − p]; we draw g 0 and g 1 independently from the Gumbel distribution, and produce the sample z as</p><formula xml:id="formula_1">z = arg max i∈{0,1} v i , where v := log(π) + [g 0 , g 1 ].</formula><p>The argmax operation is not differentiable, but it can be approximated by a softmax with annealing temperature. Therefore, on the forward pass, we use the argmax to obtain a binary connection value, while on the backwards pass, we approximate it with softmax, similarly to <ref type="bibr" target="#b8">[9]</ref>. This approach is known as the Straight-Through Gumbel-Softmax estimator <ref type="bibr" target="#b6">[7]</ref>. Note that the backwards pass actually requires all components to be evaluated, irrespective of whether they are used in the forward pass or not. Therefore, if an allocation is sampled to be inactive, then the corresponding component will not get gradients, but its output will be used to compute the gradient for the allocation probability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Inference</head><p>At inference time, it is possible to follow the same procedure as at training time, i.e. sample the connection pattern for every test batch. In our experiments, we found that this works well and does not introduce a large amount of noise in the evaluation result, since the allocation probabilities naturally tend to converge to either 0.0 or 1.0 during training. An alternative approach is to fix the allocations to their maximum likelihood variants, and use that pattern for every forward pass. We do that in the evaluation phase of all of our experiments, since we believe this is closer to how the Gumbel-Matrix framework should be used in practice. Note that for the maximum likelihood approach, we can discard all allocation probabilities after training has completed. The probabilities are used only to describe how to select a part of the network for each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Budget penalty</head><p>We have found that Gumbel-Matrix method generally trains well in its vanilla form. However, we note some ways in which it is possible to alter its default behavior. For example, one might want to learn an allocation pattern with a certain degree of sparsity. To that end, we introduce the budget penalty, which penalizes the model from exceeding a given computational budget. We define the budget as a maximum percentage of active allocations. Since we explicitly maintain all allocation probabilities, by averaging them out over all layers we obtain the expected fraction of active allocations e c . Therefore, we can set a budget b ∈ (0, 1 , corresponding to the maximum allowed fraction of active allocations, and define the budget auxiliary loss as: λ max(0, e c − b), where λ is a constant that controls the strength of the penalty. For a sufficiently large λ, this penalty can be viewed as a hard constraint in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Sparse task embeddings</head><p>Finally, we note that our framework can be used to produce sparse embeddings for the tasks, and uncover latent clusters of related tasks.</p><p>Let us denote the total number of components across all layers of a model by C = l C l . After training with the Gumbel-Matrix framework, for each task, we collect together all the binary allocation vectors from all layers, describing which components are allocated to this task. This results into a (concatenated) binary vector of total dimension C for each of the T tasks. This process can be understood as embedding all tasks into a common shared space; in this space, we can compare tasks by computing the distance between their embedding vectors. Note that for a fixed pair of tasks, higher similarity of their corresponding embedding vectors implies higher level of parameter sharing.</p><p>Based on the observation above, we conjecture that these embeddings can be used to discover latent clusters within a set of tasks. We verify this conjecture empirically in Section V-C.</p><p>IV. RELATED WORK Traditionally, work on multi-task learning includes handdesigning the sharing pattern, in order to strike a good balance between shared and task-specific parameters. Going beyond static patterns, our method is more related to recent works in multi-task learning, where the parameter sharing pattern is dynamically learned together with the model parameters. These works can be mainly divided based on the underlying algorithm used to learn the pattern.</p><p>Some methods cast learning the pattern as a Reinforcement Learning problem. The authors in <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b10">[11]</ref> propose a framework based on multi-agent Reinforcement Learning, where the positive-negative transfer problem is taken care of by finding a Nash equilibrium. In contrast, our work does not rely on Reinforcement Learning, and can be trained with standard back-propagation.</p><p>Many other works use the Sparsely-Gated Mixture-of-Experts <ref type="bibr" target="#b11">[12]</ref>, initially developed for a single-task model. This idea is extended in <ref type="bibr" target="#b7">[8]</ref> by introducing a separate gating function per task, and in <ref type="bibr" target="#b12">[13]</ref> by using architecturally diverse experts and increasing the routing depth. However, <ref type="bibr" target="#b12">[13]</ref> report that their models are often hard to train. In contrast, we show that our method can improve accuracy even when routing in large and deep neural networks.</p><p>In order to learn the sharing pattern, one can also use evolutionary algorithms. <ref type="bibr" target="#b13">[14]</ref> use evolution to find task-specific paths through a shared computational graph. Some methods use soft combinations instead of discrete routing decisions. Cross-stitch networks <ref type="bibr" target="#b14">[15]</ref> use single-task models that are stitched together with cross-stitch units, which learn shared representations by linearly combining intermediate representations from the single task models. <ref type="bibr" target="#b15">[16]</ref> learn a soft ordering of shared layers, where different tasks use the same blocks, but composed in a different soft order.</p><p>Sub-Network Routing <ref type="bibr" target="#b16">[17]</ref> proposes a routing method for multi-task networks, but it does not learn task-dependent routing, as the same pattern is applied to all the tasks.</p><p>The authors in <ref type="bibr" target="#b18">[18]</ref> propose a task routing layer for many task learning, which is a special case of multi-task learning where more than 20 tasks are performed by a single model. The task routing layer relies on binary random masks, which are created when the model is instantiated, but the masks are not trainable and they remain fixed throughout the training process. The amount of parameter sharing across tasks is governed by a single scalar knob.</p><p>Additionally, some works use concepts similar to ones used in this paper, but not for multi-task learning. In particular, <ref type="bibr" target="#b8">[9]</ref> also rely on the Gumbel-Softmax trick to learn binary variables, with a focus on fine-tuning for transfer learning applications. The binary variables are used to decide which layers of a pre-trained model should be fine-tuned on the target task. Another related method <ref type="bibr" target="#b19">[19]</ref> learns binary variables that mask the outputs of each layer, conditioning on the activations of the previous layers. In order to learn these binary variables, the REINFORCE algorithm <ref type="bibr" target="#b20">[20]</ref> is used. A similar notion of adaptive inference graphs has been proposed in <ref type="bibr" target="#b21">[21]</ref> that uses convolutional neural nets for image classification based on a ResNet-type of architecture, where some layers are skipped using learned gating functions. However, note that these methods have not been designed for multi-task learning.</p><p>Finally, our approach is related to methods for Neural Architecture Search (NAS) <ref type="bibr" target="#b22">[22]</ref>- <ref type="bibr" target="#b25">[25]</ref>, which automatically design neural network architectures for a given task. Our method is of similar spirit as the efficient NAS methods <ref type="bibr" target="#b26">[26]</ref>, <ref type="bibr" target="#b27">[27]</ref> in the sense that the architecture parameters are jointly optimized with the model parameters. Our method searches for a multi-task architecture that learns a flexible parameter sharing pattern according to the task relatedness, and uses a simpler architecture encoding based on binary variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTS</head><p>In all our experiments, we impose an additional constraint that each input batch contains samples for only one task. Since the routing is conditioned only on the task, this allows us to sample the allocation pattern once per forward pass. To train the network in a multi-task setting, we draw one batch of input samples per task, pass them through the network in random order, and repeat that process for a predefined number of steps.</p><p>To start, we have tested our method on the same synthetic data as in Section II. We provide the experimental results in Appendix A3. To test our method in a controlled environment where we know which pairs of tasks are more related, we create the following 4-MNISTs setup based on the MNIST dataset.</p><p>We first define the MNIST-rot task, by taking the inputoutput pairs of MNIST, and rotating all input images clockwise by 90 degrees. We run experiments on four tasks, where the first two tasks are copies of MNIST, and the next two are copies of MNIST-rot. Note that two copies of the same task have the same training and test datasets, but the order of training examples is different. In order to make the setup difficult, we use a relatively small modular network. It consists of three layers, containing four components each. The components in the first layer are 5x5 convolutions, while in the second and third layers are 3x3 convolutions. After the last layer, the output feature map is flattened, and passed through a taskspecific linear head. For more details, see Appendix B. b) Results: We first run two baselines, corresponding to the 'no sharing' and 'shared bottom' patterns introduced in Section II. In this case, 'no sharing' corresponds to the i-th of the four tasks using only the i-th component in every layer -again, this means that there is no interaction between tasks. 'Shared bottom' means that all tasks use all components. We also train two variants of Gumbel-Matrix: one without any auxiliary penalties, and one with the budget constraint set to 0.75. We report all of the results in <ref type="table" target="#tab_1">Table I</ref>.</p><p>We see that 'shared bottom' strongly outperforms 'no sharing', which shows that this network is small even for MNIST, and using one component per layer is not enough to reliably learn the task. For the Gumbel-Matrix experiments, we found that the two copies of MNIST end up using the same allocation patterns, as well as the two are copies of MNIST-rot. However, patterns used by the copies of MNIST are different from the ones used by MNIST-rot. As seen in the results, this gives better performance, since the processing is task-dependent. Furthermore, we see that by using the budget penalty, we can reduce the number of active connections without sacrificing the test accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Omniglot</head><p>Next, we test our method on the Omniglot multi-task setup <ref type="bibr" target="#b28">[28]</ref>. The Omniglot dataset consists of 50 different alphabets, each containing some number of characters. Input samples for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modular layers</head><p>In (Omniglot 1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Linear projections</head><p>In <ref type="table" target="#tab_1">(Omniglot 19)</ref> ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>In (Omniglot 2)</head><p>In (Omniglot 20)</p><p>Projection (Omniglot 1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Projection (Omniglot 2)</head><p>Projection <ref type="table" target="#tab_1">(Omniglot 19)</ref> Projection <ref type="table" target="#tab_1">(Omniglot 20)</ref> ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out (Omniglot 1)</head><p>Out <ref type="table" target="#tab_1">(Omniglot 19)</ref> ...</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Out (Omniglot 2)</head><p>Out (Omniglot 20)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Flatten &amp; Dropout</head><p>Layer #1 stride 2</p><p>Layer #2 stride 2</p><p>Layer #3 stride 1</p><p>Layer #4 stride 2</p><p>Layer #5 stride 2</p><p>Layer #6 stride 1</p><p>Layer #7 stride 2</p><p>Layer #8 stride 1 <ref type="figure">Fig. 3</ref>. The Omniglot multi-task network.</p><p>each of the characters are handwritten grayscale images of size 105 × 105. a) Experimental setup: We create our setup following <ref type="bibr" target="#b15">[16]</ref>, where each alphabet is treated as a separate task of predicting the character class. We follow previous works <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b29">[29]</ref> and use a fixed random subset of 20 alphabets, splitting every alphabet into training/validation/test sets with proportions 50%/20%/30%. These alphabets are the first 20 in the order originally reported by <ref type="bibr" target="#b15">[16]</ref>.</p><p>In order to have a direct comparison with the state-of-theart of <ref type="bibr" target="#b12">[13]</ref>, we use the same underlying network, optimizer, and regularization techniques; the only difference is how the parameter sharing pattern is learned. We have reached out to the authors of <ref type="bibr" target="#b12">[13]</ref> to obtain various details and make sure the setups match. We report the architecture here for completeness.</p><p>The network consists of: one shared 1x1 convolution, then 8 modular layers, and finally linear task specific heads. Each modular layer contains 7 different components: conv 3x3 → conv 3x3, conv 5x5 → conv 5x5, conv 7x7 → conv 7x7, conv 1x7 → conv 7x1, 3x3 max pooling, 3x3 average pooling and identity. The number of channels is 48 throughout the network. All components use padding to make sure the output shape is the same as the input shape; the spatial dimensions are reduced by adding a stride of 2 to 5 of the modular layers. We use GroupNorm <ref type="bibr" target="#b30">[30]</ref> and ReLU after each convolution and after each modular layer. We present the overview of the architecture in <ref type="figure">Figure 3</ref>, while a single modular layer is shown in <ref type="figure">Figure 4</ref>.</p><p>We regularize the model with Dropout and L2regularization. For training, we use the Adam optimizer. Since the allocation logits are updated only once every T steps (where T is the number of tasks), we have found that for T = 20 it is beneficial to use a higher learning rate for updating the allocation logits than that used for updating the components. Therefore, we set the learning rate for the allocation logits to be T times larger than the one for the other model weights, and found this rule of thumb to work reasonably well in practice. We set the training period to be larger than needed for the methods to attain their peak performance, select the best checkpoint for each method based on validation accuracy, and evaluate that single checkpoint on the test set. For hyperparameter values, as well  <ref type="figure">Fig. 4</ref>. Components inside a modular layer in the Omniglot multi-task network. We denote GroupNorm by GN, and the layer stride as s. Note that for this specific architecture we have s ∈ {1, 2}.</p><p>as more details about the network, please see Appendix C1. b) Results: Before training a model based on the proposed Gumbel-Matrix method, we train a 'shared bottom' variant, where all tasks use all components. We do not evaluate a 'no sharing' variant, since the number of tasks T is higher than the number of components per layer. We show the results of the experiments in <ref type="table" target="#tab_1">Table II</ref>.</p><p>We see that the 'shared bottom' approach actually outperforms the Mixture-of-Experts routing of <ref type="bibr" target="#b12">[13]</ref>, which we found to be quite surprising. We conjecture that even though the Mixture-of-Experts variant is more powerful, in the case of multi-task learning on Omniglot, optimization difficulties outweigh that benefit. In contrast to our method, the Mixtureof-Experts framework hard-codes the required sparsity for each layer. This can bring immense computational savings <ref type="bibr" target="#b11">[12]</ref>, but may also sacrifice accuracy. In some cases, like the one of <ref type="bibr" target="#b11">[12]</ref>, the 'shared bottom' variant would be prohibitively expensive to run, making the comparison infeasible. However, we encourage researchers to compare their methods with their 'shared bottom' counterparts whenever possible.</p><p>Next, we train the model based on the proposed Gumbel-Matrix method. We do not use any auxiliary losses, and find that the model naturally removes some of the allocations to allow for task-specific processing. Even though the network is not explicitly penalized for high entropy, the allocation probabilities still converge to be either close to 0.0 or close to 1.0. We report the resulting accuracy in <ref type="table" target="#tab_1">Table II</ref>. We see that the Gumbel-Matrix method improves the accuracy over a very strong 'shared bottom' baseline. c) Analysis: In order to analyze the parameter sharing patterns learned by our network, we compute several statistics. First, for each task, we compute the binary embedding vector according to Section III-E. Note that if two tasks have exactly the same embedding, the network will process them in the same way (up to the task-specific linear heads). We find that, on average, the model converges to having 10.1 different embedding vectors. That means that tasks are 'clustered' into groups that are processed in the same way, and the average size of such group is approximately 2.</p><p>Next, we analyze what kinds of components are used at </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Valid. error (%) Test error (%)</p><p>Single Task <ref type="bibr" target="#b15">[16]</ref> 36.41 ± 0.53 39.19 ± 0.50 Soft Ordering <ref type="bibr" target="#b15">[16]</ref> 32.33 ± 0.74 33.41 ± 0.71 CMTR <ref type="bibr" target="#b29">[29]</ref> 11.80 ± 1.02 12.81 ± 1.02 MoE <ref type="bibr" target="#b12">[13]</ref> 7.95 ± 0.37 7.81 ± 0.54 Shared bottom 6.16 ± 0.50 6.75 ± 0.33 Gumbel-Matrix 5.69 ± 0.22 6.48 ± 0.28 every depth in the network. Recall that each layer in the model consists of 7 components, out of which 4 are different kinds of convolutions, 2 are pooling (max and average), and the last one is identity, which can be thought of as a skip connection. We found that the usage trends are consistent across experimental runs, and mostly depend on the layer in question. The trends are the following (please see Appendix C2 for detailed illustrations):</p><p>• In layers 1 − 4, we found that the allocations of all components are being dropped at a similar rate; most of the diversity in processing different tasks concentrates in these layers. • In layers 5 − 7, almost all components are always used, and the only source of differences between tasks is that some of them use the average pooling component, while others don't. • In layer 8, the average pooling component is never used, and the other components are always used.</p><p>Our interpretation of this result is that the Gumbel-Matrix shows a mixture of two behaviors. First, components can be dropped in order to obtain task-specific processing; this trend is visible in the first layers of the model. Second, all allocations to specific components can be removed, which corresponds to a form of network pruning. We speculate that the task-specific processing in the initial layers 'aligns' the feature spaces of samples coming from different tasks. In the final layers, the tasks are processed in a uniform way, but some components are pruned to improve the model quality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Discovering latent clusters of related tasks</head><p>To test our hypothesis from Section III-E that the proposed method can discover the task relatedness, we create a setup in which there are clearly defined latent clusters of tasks. Specifically, we use a benchmark composed of three sets of tasks:</p><p>• Following <ref type="bibr" target="#b9">[10]</ref>, we create 20 tasks from the CIFAR-100 dataset <ref type="bibr" target="#b31">[31]</ref>. For each of the 20 coarse labels, we create a task of predicting the fine-grained label. 9-way classification task, and the i-th variant never sees nor is asked to classify the digit i. • In the same way as with MNIST, we create 10 variants of the Fashion-MNIST dataset <ref type="bibr" target="#b32">[32]</ref>. This benchmark contains T = 40 tasks. Note that the tasks within the MNIST cluster are highly related, since any two tasks within the cluster share 8 out of 9 of the classification classes. Similarly, tasks within the Fashion-MNIST cluster are highly related. On the other hand, tasks within the CIFAR-100 cluster are related since the input images come from the same data distribution, but the shared information is more on the level of features than on the level of classes. Note that the Gumbel-Matrix framework is informed with only the task ids ranging from 0 and T − 1, and has no access to information regarding the task set composition.</p><p>a) Experimental setup: The input images for each of the MNIST and Fashion-MNIST tasks are in grayscale, while CIFAR contains RGB images. In order for the input shape to match across all tasks, we reshape the images from the MNIST and Fashion-MNIST from 28x28 to 32x32. We also convert these images to have three channels instead of one.</p><p>The architecture of the neural network used in the following experiments consists of: one shared 1x1 convolution, then 3 modular layers, and finally linear task specific heads. Each modular layer contains 16 different components: 8 3x3 convolutions, and 8 5x5 convolutions. The number of channels throughout the network is 8. We follow the setup described in Section V-B with respect to the use of padding, GroupNorm and ReLU. All modular layers downscale the input by applying a stride of 2.</p><p>Finally, for all tasks, we employ a standard CIFAR image augmentation: we pad the 32x32 input image to the size of 40x40, and then crop out a random region of shape 32x32.</p><p>We train with Adam optimizer, with learning rate set to 0.0003 for the model parameters, and to 0.006 for the allocation logits. We also use a budget of b = 0.5 with λ = 1 to promote sparsity. The allocation probabilities are initialized to p init = 0.5, matching the budget. b) Analysis: After training with the Gumbel-Matrix method, we extract binary allocation vectors of length C = 3 · 16 = 48 for each of the tasks, following Section III-E. We visualize the embedding vectors in <ref type="figure" target="#fig_1">Figure 5</ref>. Interestingly, all tasks within the MNIST cluster are assigned the same embedding, matching the expectation that all the tasks in this cluster are highly related. The same holds for tasks within the Fashion-MNIST cluster. On the other hand, tasks within the CIFAR cluster are assigned varying embeddings, hinting that this cluster is more diverse.</p><p>To further illustrate that the method can recover the structure of the three clusters, we compute the pairwise cosine similarity for each pair of task embeddings, and visualize the resulting distance matrix in <ref type="figure" target="#fig_2">Figure 6</ref>. As noted before, the CIFAR cluster seems to be the most inhomogeneous, but remains distinct from the other two clusters. Moreover, the MNIST and Fashion-MNIST clusters are closer to each other than to the CIFAR cluster, which may be related to the fact that these two clusters have grayscale input images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSIONS AND FUTURE WORK</head><p>We introduced a new method for multi-task learning that learns the pattern of parameter sharing together with the model parameters using standard back-propagation. We provided experimental results showing that our method can learn flexible sharing patterns that leverage task relatedness, which results in significantly improved performances over the state-of-theart. The presented method conditions the binary allocation variables only on the task id. Future work can extend this method by conditioning the allocation variables on richer information such as task metadata.</p><formula xml:id="formula_2">w 1 = cu 1 , w 2 = c(ρu 1 + 1 − ρ 2 u 2 )<label>(1)</label></formula><p>3) We randomly sample a data point x ∈ R d where each dimension is sampled from N (0, 1). 4) Generate two labels y 1 , y 2 for the two tasks as follows:</p><formula xml:id="formula_3">y 1 = w 1 x + m i=1 sin(α i w 1 x + β i ) + 1<label>(2)</label></formula><formula xml:id="formula_4">y 2 = w 2 x + m i=1 sin(α i w 2 x + β i ) + 2<label>(3)</label></formula><p>where 1 , 2 ∼ N (0, 0.01). In the procedure above, the values of d, c, m, and the sequences α i , β i are hyperparameters. For all of our experiments with synthetic data, we set d = 128, c = 1, m = 6, α i = i, β i = (i − 1) 2 . We found m to be the most important of these hyperparameters, as it controls the non-linearity (and hence the difficulty) of the tasks. In particular, for m = 0 the inputoutput relation for the produced task will be linear (up to noise). 2) Architecture for the 'Positive and Negative transfer' experiment: Here we describe in detail the network used for the experiment in Section II.</p><p>The network starts with a layer containing 4 parallel fully connected components. Two of these components components consist of 1 fully connected layer, and the other two consist of 2 layers with 4 hidden units. All components have 4 output units, and use ReLU activations on the hidden and output units. Note that a specific input can be passed through multiple components; the outputs of the components are averaged before being passed to a task-specific linear head.</p><p>3) Gumbel-Matrix experiment: We additionally test the Gumbel-Matrix method on synthetic data. To that end, we create a modular network that does not contain task specific heads. Instead, it consists of a layer with 4 components, each with 1 output unit. Each component is 3 layers deep, with 16 hidden units in every hidden layer, ReLU activations on the hidden units, and no activation on the output units. We use batch size of 64, learning rate 0.01, and we clip the gradient norm to 1.0.</p><p>We generate two pairs of tasks according to Appendix A1, so that each pair contains tasks that are the same up to noise, but tasks in different pairs are unrelated. Since we use a network with no task-specific heads, if two tasks go through the same set of components, the network will implement the same function for these tasks. Therefore, if the allocation pattern is incorrect (two tasks from different pairs go through the same subset of components), the rest of the network cannot make up for it, making it a good sanity check for our method.</p><p>Note that in this network, each component is capable of learning the synthetic task on its own, and using a 'no sharing' pattern is a solid baseline. However, dynamically learning the parameter sharing pattern should still be able to improve performance: if it manages to correctly discover the related pairs of tasks, they can use a shared set of components, and parameters in these components would get twice as much training data compared to the 'no sharing' case.</p><p>We train for 3000 batches per task, and track the average loss over tasks. The result is shown in <ref type="figure" target="#fig_3">Figure 7</ref>. We found that the related tasks converge to using the same subset of components, but the subsets used by the unrelated tasks are distinct. Because of that, the Gumbel-Matrix method outperforms the 'no sharing' variant. In this setup, the 'shared bottom' setup works very poorly, since it is unable to learn both pairs of tasks at the same time. Hence, we omit the results for the 'shared bottom' baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Architecture for the multi-task MNIST experiment</head><p>Here we report additional details on the network used for the MNIST experiments.</p><p>As stated before, the network consists of three modular layers, containing convolutions with kernels 5x5, 3x3 and 3x3, respectively. We do not use padding in any of the convolutions, which means spatial dimensions are slightly reduced in each modular layer. After the first and second layer, we further reduce the spatial dimensions by applying 2x2 average pooling. All convolutions throughout the network have 4 filters.</p><p>During training, we regularize the model with Dropout (dropout probability 0.5, applied right before the tasks-specific heads). We set the training length to 10 epochs per task, and use a batch size of 16.</p><p>C. Omniglot 1) Architecture and hyperparameters: For the Omniglot experiments, we use a large convolutional network, developed by the authors of Diversity and Depth in Per-Example Routing Models <ref type="bibr" target="#b12">[13]</ref>.</p><p>One detail that we copy from <ref type="bibr" target="#b12">[13]</ref> is that the identity component, in the case when it belongs to a layer with a stride larger than 1, is actually implemented as a strided 1x1 convolution. While it makes the name 'identity component' slightly inappropriate, we follow this to be directly comparable. <ref type="figure">Fig. 8</ref>. Allocation probabilities over time (for one run, and one task). Each plot above shows the allocation probabilities for all components of a certain modular layer in the network.</p><p>We tuned the network hyperparameters using the validation set, and used the following values for all of our Omniglot experiments. Dropout probability is 0.5, L2-regularization strength 0.0003, and the learning rate is set to 0.0001. We train with a batch size of 16.</p><p>For the Gumbel-Matrix method, we set p init = 0.97. We found that increasing p init does slightly increase the average number of active connections at convergence, however, even with initialization as high as 0.97, the model still confidently removes many connections. On the other hand, we found p init = 0.97 trains much better than p init = 0.5. We believe that in a deep network with many components in every layer, setting p init to 0.5 introduces too much noise during training.</p><p>2) Additional analysis: As we have discussed in Section V-B, the connection to the average pooling component is being dropped most often, while other connections are only dropped in the early layers. <ref type="figure">Figure 8</ref> illustrates these trends and shows how the connection probabilities are evolving over time for a the 'Syriac' alphabet task. Note that for the experiments in Section V-B we ran 10 experiments for every method; here, for ease of presentation, we only show one of the runs. We see for example that for this specific task, the connection to the 3 × 3 convolutional component gets dropped in the first layer, while connections to average pooling are dropped in layers 3, 6 and 8. In the remaining three layers, the task uses all components.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>An example network with two tasks. Some components are used by both tasks (purple), some by only one of the tasks (red or blue, respectively), and one identity component is completely unused (white). Below each layer we show the corresponding allocation matrix.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>•Fig. 5 .</head><label>5</label><figDesc>We create 10 variants of the MNIST dataset; the i-th variant is the task of telling apart all MNIST digits besides digit i. In other words, every MNIST variant is a Binary allocation vectors for the 40 tasks. Rows correspond to tasks: first 20 rows form the CIFAR cluster, next 10 the MNIST cluster, and the last 10 the Fashion-MNIST cluster. Columns correspond to the 48 components of the model: 16 components in each of the 3 modular layers. A yellow pixel denotes a 1 (the component is allocated to a given task), while a purple pixel denotes a 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 6 .</head><label>6</label><figDesc>Pairwise cosine similarity of the binary embedding vectors for the 40 tasks. Rows and columns correspond to tasks. Yellow pixels denote similarity of 1 (vectors are the same), while on the other end of the spectrum purple denote similarity of 0 (vectors are orthogonal).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 7 .</head><label>7</label><figDesc>Comparison of the 'no sharing' pattern with the Gumbel-Matrix method on the synthetic data experiment. The plot shows loss over time (averaged over the four tasks and smoothed over a window of 100 steps). We ran each experiment 20 times, and the shaded area corresponds to the 90% confidence interval.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I RESULTS</head><label>I</label><figDesc>ON THE 4-MNISTS MULTI-TASK SETUP. EACH EXPERIMENT WAS RUN 30 TIMES, WE REPORT MEAN AND STANDARD DEVIATION OF THE ERROR.</figDesc><table><row><cell>Method</cell><cell cols="2">Test accuracy (%) Active connections (%)</cell></row><row><cell>No sharing</cell><cell>93.5 ± 5.1</cell><cell>25</cell></row><row><cell>Shared bottom</cell><cell>95.7 ± 0.5</cell><cell>100</cell></row><row><cell>Ours</cell><cell>96.8 ± 0.2</cell><cell>96</cell></row><row><cell>Ours (budget = 0.75)</cell><cell>96.7 ± 0.3</cell><cell>75</cell></row><row><cell>A. MNIST</cell><cell></cell><cell></cell></row><row><cell cols="2">a) Experimental setup:</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE II RESULTS</head><label>II</label><figDesc>ON MULTI-TASK OMNIGLOT SETUP. EACH EXPERIMENT WAS RUN 10 TIMES, WE REPORT MEAN AND STANDARD DEVIATION OF THE ERROR.</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX</head><p>A. Synthetic data 1) Generation: We follow a process for synthetic data generation based on <ref type="bibr" target="#b7">[8]</ref>, which allows for explicit control of the relatedness between tasks. In particular, we generate the data as follows:</p><p>1) We generate two orthogonal unit vectors u 1 , u 2 ∈ R d . That is, u 1 and u 2 satisfy u 1 u 2 = 0 and u 1 = u 2 = 1. 2) Given a desired score of task relatedness 0 ≤ ρ ≤ 1, we generate two weight vectors w 1 , w 2 such that</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Caruana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
	<note>Learning to learn</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Multitask learning: A knowledge-based source of inductive bias</title>
	</analytic>
	<monogr>
		<title level="m">Machine Learning: Proceedings of the Tenth International Conference</title>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Ask the GRU: Multi-task learning for deep text recommendations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">10th ACM Conference on Recommender Systems</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="107" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fast R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Bam! born-again multi-task networks for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno>abs/1907.04829</idno>
		<ptr target="http://arxiv.org/abs/1907.04829" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">ERNIE 2.0: A continual pre-training framework for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1907.12412" />
		<imprint>
			<date type="published" when="1907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Categorical reparametrization with Gumbel-softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KDD</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">SpotTune: Transfer Learning through Adaptive Finetuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rosing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feris</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1811.08737" />
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Routing Networks: Adaptive Selection of Non-Linear Functions for Multi-Task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riemer</surname></persName>
		</author>
		<ptr target="https://openreview.net/pdf?id=ry8dvM-R-" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Routing networks and the challenges of modular and compositional computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cases</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riemer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Klinger</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.12774</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Outrageously large neural networks: The sparsely-gated mixture-of-experts layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mirhoseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Maziarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06538</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Diversity and Depth in Per-Example Routing Models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<ptr target="https://openreview.net/pdf?id=BkxWJnC9tX" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Pathnet: Evolution channels gradient descent in super neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Banarse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zwols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pritzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.08734</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cross-stitch networks for multi-task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shrivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3994" to="4003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Beyond shared hierarchies: Deep multitask learning through soft layer ordering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SNR: Sub-Network Routing for Flexible Parameter Sharing in Multi-task Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<ptr target="http://www.jiaqima.com/papers/SNR.pdf" />
		<title level="m">Available</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Many Task Learning With Task Routing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Strezoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Van Noord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1375" to="1384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-L</forename><surname>Bacon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06297</idno>
		<title level="m">Conditional computation in neural networks for faster models</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Simple statistical gradient-following algorithms for connectionist reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="229" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Convolutional Networks with Adaptive Inference Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Neural Architecture Search with Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Large-Scale Evolution of Image Classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Selle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Suematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Evolutionary-neural hybrid agents for architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Maziarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khorlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Georgiev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gesmundo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML): Workshop on AutoML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Bananas: Bayesian optimization with neural architectures for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Neiswanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Savani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.11858</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameters sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">DARTS: Differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="page">13321338</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Evolutionary architecture search for deep multitask networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Meyerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Miikkulainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Genetic and Evolutionary Computation Conference</title>
		<meeting>the Genetic and Evolutionary Computation Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="466" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Group normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
