<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FINDING REMO (RELATED MEMORY OBJECT): A SIMPLE NEURAL ARCHITECTURE FOR TEXT BASED REASONING</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-01-26">26 Jan 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihyung</forename><surname>Moon</surname></persName>
							<email>zoon@snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial Engineering</orgName>
								<orgName type="institution">Seoul National University Seoul</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyochang</forename><surname>Yang</surname></persName>
							<email>hyochang@dm.snu.ac.kr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial Engineering</orgName>
								<orgName type="institution">Seoul National University Seoul</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungzoon</forename><surname>Cho</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Industrial Engineering</orgName>
								<orgName type="institution">Seoul National University Seoul</orgName>
								<address>
									<country key="KR">South Korea</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FINDING REMO (RELATED MEMORY OBJECT): A SIMPLE NEURAL ARCHITECTURE FOR TEXT BASED REASONING</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-01-26">26 Jan 2018</date>
						</imprint>
					</monogr>
					<note>Under review as a conference paper at ICLR 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To solve the text-based question and answering task that requires relational reasoning, it is necessary to memorize a large amount of information and find out the question relevant information from the memory. Most approaches were based on external memory and four components proposed by Memory Network. The distinctive component among them was the way of finding the necessary information and it contributes to the performance. Recently, a simple but powerful neural network module for reasoning called Relation Network (RN) has been introduced. We analyzed RN from the view of Memory Network, and realized that its MLP component is able to reveal the complicate relation between question and object pair. Motivated from it, we introduce Relation Memory Network (RMN) which uses MLP to find out relevant information on Memory Network architecture. It shows new state-of-the-art results in jointly trained bAbI-10k story-based question answering tasks and bAbI dialog-based question answering tasks. * Code is publicly available at: https://github.com/juung/RMN</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Neural network has made an enormous progress on the two major challenges in artificial intelligence: seeing and reading. In both areas, embedding methods have served as the main vehicle to process and analyze text and image data for solving classification problems. As for the task of logical reasoning, however, more complex and careful handling of features is called for. A reasoning task requires the machine to answer a simple question upon the delivery of a series of sequential information. For example, imagine that the machine is given the following three sentences: "Mary got the milk there.", "John moved to the bedroom.", and "Mary traveled to the hallway." Once prompted with the question, "Where is the milk?", the machine then needs to sequentially focus on the two supporting sentences, "Mary got the milk there." and "Mary traveled to the hallway." in order to successfully determine that the milk is located in the hallway. Inspired by this reasoning mechanism, J.  has introduced the memory network (MemNN), which consists of an external memory and four components: input feature map (I), generalization (G), output feature map (O), and response (R). The external memory enables the model to deal with a knowledge base without loss of information. Input feature map embeds the incoming sentences. Generalization updates old memories given the new input and output feature map finds relevant information from the memory. Finally, response produces the final output.</p><p>Based on the memory network architecture, neural network based models like end-to-end memory network (MemN2N) <ref type="bibr" target="#b11">(Sukhbaatar et al., 2015)</ref>, gated end-to-end memory network (GMemN2N) <ref type="bibr" target="#b7">(Liu &amp; Perez, 2017)</ref>, dynamic memory network (DMN) <ref type="bibr" target="#b6">(Kumar et al., 2016)</ref>, and dynamic memory network + (DMN+) <ref type="bibr" target="#b13">(Xiong et al., 2016)</ref> are proposed. Since strong reasoning ability depends on whether the model is able to sequentially catching the right supporting sentences that lead to the answer, the most important thing that discriminates those models is the way of constructing the output feature map. As the output feature map becomes more complex, it is able to learn patterns for more complicate relations. For example, MemN2N, which has the lowest performance among the four models, measures the relatedness between question and sentence by the inner product, while the best performing DMN+ uses inner product and absolute difference with two embedding matrices.</p><p>Recently, a new architecture called Relation Network (RN) <ref type="bibr" target="#b9">(Santoro et al., 2017)</ref> has been proposed as a general solution to relational reasoning. The design philosophy behind it is to directly capture the supporting relation between the sentences through the multi-layer perceptron (MLP). Despite its simplicity, RN achieves better performance than previous models without any catastrophic failure.</p><p>The interesting thing we found is that RN can also be interpreted in terms of MemNN. It is composed of O and R where each corresponds to MLP which focuses on the related pair and another MLP which infers the answer. RN does not need to have G because it directly finds all the supporting sentences at once. In this point of view, the significant component would be MLP-based output feature map. As MLP is enough to recognize highly non-linear pattern, RN could find the proper relation better than previous models to answer the given question.</p><p>However, as RN considers a pair at a time unlike MemNN, the number of relations that RN learns is n 2 when the number of input sentence is n. When n is small, the cost of learning relation is reduced by n times compared to MemNN based models, which enables more data-efficient learning <ref type="bibr" target="#b9">(Santoro et al., 2017)</ref>. However, when n increases, the performance becomes worse than the previous models. In this case, the pair-wise operation increases the number of non-related sentence pairs more than the related sentence pair, thereby confuses RN's learning. <ref type="bibr" target="#b9">Santoro et al. (2017)</ref> has suggested attention mechanisms as a solution to filter out unimportant relations; however, since it interrupts the reasoning operation, it may not be the most optimal solution to the problem.</p><p>Our proposed model, "Relation Memory Network" (RMN), is able to find complex relation even when a lot of information is given. It uses MLP to find out relevant information with a new generalization which simply erase the information already used. In other words, RMN inherits RN's MLP-based output feature map on Memory Network architecture. Experiments show its state-ofthe-art result on the text-based question answering tasks.  Relation Memory Network (RMN) is composed of four components -embedding, attention, updating, and reasoning. It takes as the inputs a set of sentences x 1 , x 2 , ..., x n and its related question u, and outputs an answer a. Each of the x i , u, and a is made up of one-hot representation of words, for example,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATION MEMORY NETWORK</head><formula xml:id="formula_0">hallway σ ͙ σ ͙ ͙ ͙ ¡ ¢ £ ¤ ¥ ¦ § ¨ ൈ © ! " # $ % &amp; ' ( ) 0 1 2 3 4 5 6 7 8 9 @ A B C D E F G H I P Q R S T U V W X Y ` a b c d e f g h i p q r s t u v w x y d e f g h i j k l m</formula><formula xml:id="formula_1">x i = {x i1 , x i2 , x i3 , ..., x ini } (x ij ∈ R V , j = (1, 2, .</formula><p>.., n i ), V = vocabulary size, n i = number of words in sentence i).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">EMBEDDING COMPONENT</head><p>We first embed words in each x i = {x i1 , x i2 , x i3 , ..., x ini } and u to a continuous space multiplying an embedding matrix A ∈ R d×V . Then, the embedded sentence is stored and represented as a memory object m i while question is represented as q. Any of the following methods are available for embedding component: simple sum (equation 1), position encoding (J.  (equation 2), concatenation (equation 3), LSTM, and GRU. In case of LSTM or GRU, m i is the final hidden state of it.</p><formula xml:id="formula_2">m i = j Ax ij (1) m i = j l j · Ax ij (l kj = (1 − j/n i ) − (k/d)(1 − 2j/n i )) (2) m i = [Ax i1 , Ax i2 , ... , Ax ini ]<label>(3)</label></formula><p>As the following attention component takes the concatenation of m i and q, it is not necessarily the case that sentence and question have the same dimensional embedding vectors unlike previous memory-augmented neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">ATTENTION COMPONENT</head><p>Attention component can be applied more than once depending on the problem; <ref type="figure" target="#fig_0">Figure 1</ref> illustrates 2 hop version of RMN. We refer to the i th embedded sentence on the t th hop as m t i . To constitute the attention component, we applied simple MLP represented as g t θ . It must be ended with 1 unit output layer to provide a scalar weight w t i , which leads to an attention weight α t i between 0 and 1. In the beginning, a vector concatenated with m 1 i and q flows to the g 1 θ . From the result of g 1 θ , attention weight α 1 i is calculated using additional variable β 1 (≥ 1) to control the intensity of attention, inspired by the way Neural Turing Machine <ref type="bibr" target="#b1">(Graves et al., 2014)</ref> reads from the memory. Then we get the related memory object r 1 , a weighted sum of α 1 i and memory object m 1 i for all i. If there exist more hops, r 1 is directly taken to the next hop and iterates over this process with the updated memory object m 2 i . All the procedures are rewritten as equation 4, 5, and 6:</p><formula xml:id="formula_3">w t i ← g t θ ([m t i , r t−1 ]) (i = (1, 2, ..., n), r 0 = q) (4) α t i ← exp(β t w t i ) i exp(β t w t i ) (β t (z) = 1 + log(1 + exp(z))) (5) r t ← i α t i · m t i<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">UPDATING COMPONENT</head><p>To forget the information already used, we use intuitive updating component to renew the memory. It is replaced by the amount of unconsumed from the old one:</p><formula xml:id="formula_4">m t+1 i ← (1 − α t i ) m t i<label>(7)</label></formula><p>Contrary to other components, updating is not a mandatory component. When it is considered to have 1 hop, there is no need to use this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">REASONING COMPONENT</head><p>Similar to attention component, reasoning component is also made up of MLP, represented as f φ . It receives both q and the final result of attention component r f and then takes a softmax to produce the model answerâ: </p><formula xml:id="formula_5">â ← Softmax(f φ ([r f , q]))<label>(8)</label></formula><formula xml:id="formula_6">α t i = Softmax((r t ) T m t i )(r 0 = q) o t = i α t i m t i r t+1 = o t + r t m t = W t m t−1 RN r i = g θ -MLP([m i , m j , q]) o = i r i - RMN r t i = g t θ -MLP([m t i , r t−1 ])(r 0 = q) α t i = Softmax(β t r t i ) r t = i α t i m t i m t i = (1 − α t−1 i )m t−1 i 3 RELATED WORK 3.1 MEMORY-AUGMENTED NEURAL NETWORK</formula><p>To answer the question from a given set of facts, the model needs to memorize these facts from the past. Long short term memory (LSTM) <ref type="bibr" target="#b2">(Hochreiter &amp; Schmidhuber, 1997)</ref>, one of the variants of recurrent neural network (RNN), is inept at remembering past stories because of their small internal memory <ref type="bibr" target="#b11">(Sukhbaatar et al., 2015)</ref>. To cope with this problem, J. Weston &amp; Bordes <ref type="formula">(2015)</ref>  MemN2N, GMemN2N, DMN, and DMN+ all follow the same structure of MemNN from a broad perspective, however, output feature map is composed in slightly different way. The relation between question and supporting sentences is realized from its cooperation. MemN2N first calculates the relatedness of sentences in the question and memory by taking the inner product, and the sentence with the highest relatedness is selected as the first supporting sentence for the given question. The first supporting sentence is then added with the question and repeat the same operation with the updated memory to find the second supporting sentence. GMemN2N selects the supporting sentence in the same way as MemN2N, but uses the gate to selectively add the the question to control the influence of the question information in finding the supporting sentence in the next step. DMN and DMN + use output feature map based on various relatedness such as absolute difference, as well as inner product, to understand the relation between sentence and question at various points. The more difficult the task, the more complex the output feature map and the generalization component to get the correct answer. For a dataset experimenting the text-based reasoning ability of the model, the overall accuracy could be increased in order of MemN2N, GMemN2N, DMN, and DMN+, where the complexity of the component increases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">RELATION NETWORK</head><p>Relation Network (RN) has emerged as a new and simpler framework for solving the general reasoning problem. RN takes in a pair of objects as its input and simply learns from the compositions of two MLPs represented as g θ and f φ . The role of each MLP is not clearly defined in the original paper, but from the view of MemNN, it can be understood that g θ corresponds to O and f φ corresponds to R. <ref type="table" target="#tab_1">Table 1</ref> summarizes the interpretation of RN compared to MemN2N and our model, RMN.</p><p>To verify the role of g θ , we compare the output when pairs are made with supporting sentences and when made with unrelated sentences. <ref type="figure" target="#fig_2">Figure 2</ref> shows the visualization result of each output. When we focus on whether the value is activated or not, we can see that g θ distinguishes supporting sentence pair from non-supporting sentence pair as output feature map examines how relevant the sentence is to the question. Therefore, we can comprehend the output of g θ reveals the relation between the object pair and the question and f φ aggregates all these outputs to infer the answer. bAbI story-based QA dataset bAbI story-based QA dataset  is composed of 20 different types of tasks for testing natural language reasoning ability. Each task requires different methods to infer the answer. The dataset includes a set of statements comprised of multiple sentences, a question and answer. A statement can be as short as two sentences and as long as 320 sentences. To answer the question, it is necessary to find relevant one or more sentences to a given question and derive answer from them. Answer is typically a single word but in a few tasks, answers are a set of words. Each task is regarded as success when the accuracy is greater than 95%. There are two versions of this dataset, one that has 1k training examples and the other with 10k examples. Most of the previous models test their accuracy on 10k dataset with trained jointly.</p><p>bAbI dialog dataset bAbI dialog dataset <ref type="bibr" target="#b0">(Bordes &amp; Weston, 2016</ref>) is a set of 5 tasks within the goal-oriented context of restaurant reservation. It is designed to test if model can learn various abilities such as performing dialog management, querying knowledge bases (KBs), and interpreting the output of such queries. The KB can be queried using API calls and 4 fields (a type of cuisine, a location, a price range, and a party size). They should be filled to issue an API call. Task 1 tests the capacity of interpreting a request and asking the right questions to issue an API call. Task 2 checks the ability to modify an API call. Task 3 and 4 test the capacity of using outputs from an API call to propose options in the order of rating and to provide extra-information of what user asks for.</p><p>Task 5 combines everything. The maximum length of the dialog for each task is different: 14 for task 1, 20 for task 2, 78 for task 3, 13 for task 4, and 96 for task 5. As restaurant name, locations, and cuisine types always face new entities, there are normal and OOV test sets to assess model's generalization ability. Training sets consist fo 1k examples, which is not a large amount of creating realistic learning conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">TRAINING DETAILS</head><p>bAbI story-based QA dataset We trained 2 hop RMN jointly on all tasks using 10k dataset for model to infer the solution suited to each type of tasks. We limited the input to the last 70 stories for all tasks except task 3 for which we limited input to the last 130 stories, similar to <ref type="bibr" target="#b13">Xiong et al. (2016)</ref> which is the hardest condition among previous models. Then, we labeled each sentence with its relative position. Embedding component is similar to <ref type="bibr" target="#b9">Santoro et al. (2017)</ref>, where story and question are embedded through different LSTMs; 32 unit word-lookup embeddings; 32 unit LSTM for story and question. For attention component, as we use 2 hop RMN, there are g 1 θ and g 2 θ ; both are three-layer MLP consisting of 256, 128, 1 unit with ReLU activation function <ref type="bibr" target="#b8">(Nair &amp; Hinton, 2010)</ref>. f φ is composed of 512, 512, and 159 units (the number of words appearing in bAbI dataset is 159) of three-layer MLP with ReLU non-linearities where the final layer was a linear that produced logits for a softmax over the answer vocabulary. For regularization, we use batch normalization <ref type="bibr" target="#b3">(Ioffe &amp; Szegedy, 2015)</ref> for all MLPs. The softmax output was optimized with a cross-entropy loss function using the Adam optimizer <ref type="bibr" target="#b5">(Kingma &amp; Ba, 2014)</ref> with a learning rate of 2e −4 .</p><p>bAbI dialog dataset We trained on full dialog scripts with every model response as answer, all previous dialog history as sentences to be memorized, and the last user utterance as question. Model selects the most probable response from 4,212 candidates which are ranked from a set of all bot utterances appearing in training, validation and test sets (plain and OOV) for all tasks combined. We also report results when we use match type features for dialog. Match type feature is an additional label on the candidates indicating if word is found on the dialog history. For example, if the    <ref type="table" target="#tab_4">Table 3</ref> shows how our model solved several tasks. RMN's attention component g 1 θ and g 2 θ complement each other to identify the necessary facts to answer correctly. Sometimes both g 1 θ and g 2 θ concentrate on the same sentences which are all critical to answer the question, and sometimes g 1 θ finds a fact related to the given question and with this information g 2 θ chooses the key fact to answer. While trained jointly, RMN learns these different solutions for each task. For the task 3, the only failed task, attention component still functions well; it focuses sequentially on the supporting sentences. However, the reasoning component, f φ , had difficulty catching the word 'before'. We could easily figure out 'before' implies 'just before' the certain situation, whereas RMN confused its meaning. As shown in table 3c, our model found all previous locations before the garden. Still, it is remarkable that the simple MLP carried out all of these various roles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">BABI DIALOG</head><p>The results in the <ref type="table" target="#tab_5">Table 4</ref> show that the RMN has the best results in any conditions. Without any match type, RN and RMN outperform previous memory-augmented models on both normal and OOV tasks. This is mainly attributed to the impressive result on task 4 which can be interpreted as an effect of MLP based output feature map.</p><p>To solve task 4, it is critical to understand the relation between 'phone number' of user input and 'r phone' of previous dialog as shown in <ref type="table" target="#tab_9">Table 8c</ref>. We assumed that inner product was not sufficient  to capture their implicit similarity and performed an supporting experiment. We converted RMN's attention component to inner product based attention, and the results revealed the error rate increased to 11.3%.</p><p>For the task 3 and task 5 where the maximum length is especially longer than the others, RN performs worse than MemN2N, GMemN2N and RMN. The number of unnecessary object pairs created by the RN not only increases the processing time but also decreases the accuracy.</p><p>With the match type feature, all models other than RMN have significantly improved their performance except for task 3 compared to the plain condition. RMN was helped by the match type only on the OOV tasks and this implies RMN is able to find relation in the With Match condition for the normal tasks.</p><p>When we look at the OOV tasks more precisely, RMN failed to perform well on the OOV task 1 and 2 even though g 1 θ properly focused on the related object as shown in <ref type="table" target="#tab_9">Table 8a</ref>. We state that this originated from the fact that the number of keywords in task 1 and 2 is bigger than that in task 4. In task 1 and 2, all four keywords (cuisine, location, number and price) must be correctly aligned from the supporting sentence in order to make the correct API call which is harder than task 4. Consider the example in <ref type="table" target="#tab_9">Table 8a and Table 8c</ref>. Supporting sentence of task 4 have one keyword out of three words, whereas supporting sentences of task 1 and 2 consist of four keywords (cuisine, location, number and price) out of sixteen words. Different from other tasks, RMN yields the same error rate 25.1% with MemN2N and GMemN2N on the task 3. The main goal of task 3 is to recommend restaurant from knowledge base in the order of rating. All failed cases are displaying restaurant where the user input is &lt;silence&gt;which is somewhat an ambiguous trigger to find the input relevant previous utterance. As shown in <ref type="table" target="#tab_9">Table 8b</ref>, there are two different types of response to the same user input. One is to check whether all the required fields are given from the previous utterances and then ask user for the missing fields or send a "Ok let me look into some options for you." message. The other type is to recommend restaurant starting from the highest rating. All models show lack of ability to discriminate these two types of silences so that concluded to the same results. To verify our statement, we performed an additional experiment on task 3 and checked the performance gain (extra result is given in <ref type="table" target="#tab_1">Table 10</ref> of Appendix B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">MODEL ANALYSIS</head><p>Effectiveness of the MLP-based output feature map The most important feature that distinguishes MemNN based models is the output feature map. <ref type="table" target="#tab_6">Table 5</ref> summarizes the experimental results for the bAbI story-based QA dataset when replacing the RMN's MLP-based output feature map with the idea of the previous models. inner product was used in MemN2N, inner product with gate was used in GMemN2N, and inner product and absolute difference with two embedding matrices was used in DMN and DMN+. From the <ref type="table" target="#tab_6">Table 5</ref>, the more complex the output feature map, the better the overall performance. In this point of view, MLP is the effective output feature map.  <ref type="table" target="#tab_7">Table 6</ref>.</p><p>When memory size is small, we could observe the data-effeciency of RN. It shows similar performance to RMN in less time. However, when the memory size increases, performance is significantly reduced compared to RMN, even though it has been learned for a longer time. It is even lower than itself when the memory size is 20. On the other hand, RMN maintains high performance even when the memory size increases. Effectiveness of the number of hops bAbI story based QA dataset differs in the number of supporting sentences by each task that need to be referenced to solve problems. For example, task 1, 2, and 3 require single, two, and three supporting facts, respectively. The result of the mean error rate for each task according to the number of hops is in <ref type="table" target="#tab_8">Table 7</ref>. Overall, the number of hops is correlated with the number of supporting sentences. In this respect, when the number of relations increases, RMN could reason across increasing the number of hops to 3, 4 or more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>Our work, RMN, is a simple and powerful architecture that effectively handles text-based question answering tasks when large size of memory and high reasoning ability is required. Multiple access to the external memory to find out necessary information through a multi-hop approach is similar to most existing approaches. However, by using a MLP that can effectively deal with complex relatedness when searching for the right supporting sentences among a lot of sentences, RMN raised the state-of-the-art performance on the story-based QA and goal-oriented dialog dataset. When comparing RN which also used MLP to understand relations, RMN was more effective in the case of large memory.</p><p>Future work will apply RMN to image based reasoning task (e.g., CLEVR, DAQUAR, VQA etc.).</p><p>To extract features from the image, VGG net <ref type="bibr" target="#b10">(Simonyan &amp; Zisserman, 2014)</ref> is used in convention and outputs 196 objects of 512 dimensional vectors which also require large sized memory. An important direction will be to find an appropriate way to focus sequentially on related object which was rather easy in text-based reasoning. A MODEL DETAILS  We modify the user input from &lt;silence&gt;to &lt;silence&gt;&lt;silence&gt;when looking for restaurant recommendations. This makes model to distinguish two different situations whether to ask for additional fields or to recommend restaurant.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Relation Memory Network</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>has proposed a new class of memory-augmented model called Memory Network (MemNN). MemNN comprises an external memory m and four components: input feature map (I), generalization (G), output feature map (O), and response (R). I encodes the sentences which are stored in memory m. G updates the memory, whereas O reads output feature o from the memory. Finally, R infers an answer from o.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The output vector of g θ when the input objects are related and unrelated</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>18 Mary travelled to the kitchen. 146 Daniel travelled to the hallway. 147 Daniel went back to the garden. 148 Where was the apple before the garden? ͙ ͙ 144 Daniel grabbed the apple. 145 Mary went to the bedroom.</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>MemN2N, RN, and RMN in terms of MemNN architecture</figDesc><table><row><cell>Output feature map</cell><cell>Generalization</cell></row><row><cell>MemN2N</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Test error on bAbI story-based tasks with 10k training samples</figDesc><table><row><cell>Task</cell><cell cols="9">MemNN MemN2N GMemN2N DMN DMN+ DNC EntNet 1 RN 2 RMN</cell></row><row><cell>1: Single Supporting Fact</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.1</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>2: Two Supporting Facts</cell><cell>0.0</cell><cell>0.3</cell><cell>0.0</cell><cell>1.8</cell><cell>0.3</cell><cell>0.4</cell><cell>2.8</cell><cell>8.3</cell><cell>0.5</cell></row><row><cell>3: Three Supporting Facts</cell><cell>0.0</cell><cell>9.3</cell><cell>4.5</cell><cell>4.8</cell><cell>1.1</cell><cell>1.8</cell><cell>10.6</cell><cell cols="2">17.1 14.7</cell></row><row><cell>4: Two Argument Relations</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>bAbI story-based task visualization of α</figDesc><table><row><cell></cell><cell>(a) Task 7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(c) Task 3</cell><cell></cell></row><row><cell>Seq.</cell><cell>Task 7: Counting</cell><cell></cell><cell>α 1</cell><cell>α 2</cell><cell>Seq.</cell><cell>Task 3: Three Supporting Facts</cell><cell>α 1</cell><cell>α 2</cell></row><row><cell>8</cell><cell>John grabbed the apple there .</cell><cell></cell><cell cols="2">0.02 0.00</cell><cell>33</cell><cell>Daniel took the football .</cell><cell cols="2">0.46 0.01</cell></row><row><cell cols="2">9 10 11 13 14 15 16 User input Answer Model answer Two John gave the apple to Mary . Mary passed the apple to John . Mary journeyed to the hallway . Sandra went to the garden . Mary went to the kitchen . Mary picked up the football there . Mary picked up the milk there . How many objects is Mary carrying? Two</cell><cell cols="3">0.08 0.16 0.17 0.24 0.00 0.01 0.00 0.00 0.00 0.03 0.29 0.24 0.27 0.32 [Correct]</cell><cell cols="4">39 40 41 42 46 50 51 User input Answer Model answer Bathroom Sandra travelled to the bedroom . Daniel moved to the bathroom . Sandra got the milk . Daniel travelled to the garden . Daniel went to the hallway . Daniel put down the apple . Daniel put down the football there . Where was the football before the garden ? Bathroom [Correct] 0.01 0.00 0.01 0.31 0.00 0.00 0.04 0.42 0.00 0.25 0.00 0.01 0.38 0.00</cell></row><row><cell></cell><cell>(b) Task 14</cell><cell></cell><cell></cell><cell></cell><cell>Seq. 1</cell><cell>Task 3: Three Supporting Facts Mary got the football .</cell><cell cols="2">α 1 0.26 0.00 α 2</cell></row><row><cell>Seq. 1 2 3 4</cell><cell cols="2">Task 14: Time reasoning Mary went back to the school yesterday . Fred went to the school yesterday . Julie went back to the kitchen yesterday . Fred journeyed to the kitchen this morning .</cell><cell cols="2">α 1 0.00 0.01 α 2 0.00 0.00 0.13 0.98 0.00 0.00</cell><cell>3 5 6 11 12</cell><cell>Mary picked up the football . Mary moved to the office . Mary went to the hallway . Mary travelled to the garden . Mary travelled to the kitchen .</cell><cell cols="2">0.39 0.00 0.00 0.05 0.00 0.05 0.00 0.21 0.00 0.29</cell></row><row><cell>5</cell><cell cols="2">This morning julie journeyed to the school .</cell><cell cols="2">0.66 0.02</cell><cell>14</cell><cell>Mary moved to the office .</cell><cell cols="2">0.00 0.25</cell></row><row><cell>6</cell><cell cols="2">This evening mary went back to the school .</cell><cell cols="2">0.01 0.00</cell><cell>16</cell><cell>Mary went to the garden .</cell><cell cols="2">0.00 0.05</cell></row><row><cell>7</cell><cell>This afternoon julie went to the bedroom .</cell><cell></cell><cell cols="2">0.06 0.00</cell><cell>22</cell><cell>Mary discarded the football there .</cell><cell cols="2">0.24 0.00</cell></row><row><cell>User input</cell><cell>Where was Julie before the school ?</cell><cell></cell><cell></cell><cell></cell><cell>User input</cell><cell cols="2">Where was the football before the garden ?</cell></row><row><cell>Answer</cell><cell>Kitchen</cell><cell></cell><cell></cell><cell></cell><cell>Answer</cell><cell>Office</cell><cell></cell></row><row><cell cols="2">Model answer Kitchen</cell><cell cols="2">[Correct]</cell><cell></cell><cell cols="2">Model answer Kitchen</cell><cell>[Incorrect]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Test error on bAbI dialog tasks 3</figDesc><table><row><cell>Task</cell><cell cols="8">Plain MemN2N GMemN2N RN 4 RMN MemN2N GMemN2N RN 4 RMN With Match</cell></row><row><cell>1: Issuing API calls</cell><cell>0.1</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>2: Updating API calls</cell><cell>0.0</cell><cell>0.0</cell><cell>0.5</cell><cell>0.0</cell><cell>1.7</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>3: Displaying options</cell><cell>25.1</cell><cell>25.1</cell><cell cols="2">26.6 25.1</cell><cell>25.1</cell><cell>25.1</cell><cell cols="2">27.1 25.1</cell></row><row><cell>4: Providing extra information</cell><cell>40.5</cell><cell>42.8</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>5: Conducting full dialogs</cell><cell>3.9</cell><cell>3.7</cell><cell cols="2">23.3 2.5</cell><cell>6.6</cell><cell>2.0</cell><cell cols="2">16.6 1.8</cell></row><row><cell>Average error rates (%)</cell><cell>13.9</cell><cell>14.3</cell><cell cols="2">10.1 5.5</cell><cell>6.7</cell><cell>5.4</cell><cell>8.7</cell><cell>5.4</cell></row><row><cell>1 (OOV): Issuing API calls</cell><cell>27.7</cell><cell>17.6</cell><cell cols="2">17.8 16.8</cell><cell>3.5</cell><cell>0.0</cell><cell>1.5</cell><cell>0.0</cell></row><row><cell>2 (OOV): Updatining API calls</cell><cell>21.1</cell><cell>21.1</cell><cell cols="2">23.2 21.1</cell><cell>5.5</cell><cell>5.8</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>3 (OOV): Displaying options</cell><cell>25.6</cell><cell>24.7</cell><cell cols="2">27.2 24.9</cell><cell>24.8</cell><cell>24.9</cell><cell cols="2">29.8 25.1</cell></row><row><cell cols="2">4 (OOV): Providing extra information 42.4</cell><cell>43.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>5 (OOV): Conducting full dialogs</cell><cell>34.5</cell><cell>33.3</cell><cell cols="2">38.3 34.5</cell><cell>22.3</cell><cell>20.6</cell><cell cols="2">28.4 21.7</cell></row><row><cell>Average error rates (%)</cell><cell>30.3</cell><cell>27.9</cell><cell cols="2">21.3 19.5</cell><cell>11.2</cell><cell>10.3</cell><cell cols="2">12.0 9.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Test error of RMN on bAbI story-based QA dataset with different configurations Performance of RN and RMN according to memory size Additional experiments were conducted with the bAbI story-based QA dataset to see how memory size affects both performance and training time of RN and RMN. Test errors with training time written in parentheses are summarized in</figDesc><table><row><cell></cell><cell cols="2">inner product inner product with gate</cell><cell>inner product and absolute difference with two embedding matrices</cell><cell>MLP</cell></row><row><cell>error rate</cell><cell>29.4</cell><cell>25.9</cell><cell>11.2</cell><cell>1.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Test error and training time of RN and RMN on bAbI story-based QA dataset with different</figDesc><table><row><cell>memory size</cell><cell></cell><cell></cell></row><row><cell>memory size</cell><cell>RN</cell><cell>RMN</cell></row><row><cell>20</cell><cell cols="2">2.0 (0.65 days) 1.5 (1.46 days)</cell></row><row><cell>130</cell><cell cols="2">9.8 (9.47 days) 1.2 (4.94 days)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Test error of RMN on bAbI story-based QA dataset with different number of hops</figDesc><table><row><cell></cell><cell cols="3">hop 1 hop 2 hop 3</cell></row><row><cell>task 1 (1) 5</cell><cell>0.0</cell><cell>0.0</cell><cell>0.2</cell></row><row><cell>task 2 (2)</cell><cell>62.0</cell><cell>0.5</cell><cell>2.1</cell></row><row><cell>task 3 (3)</cell><cell>62.4</cell><cell>14.7</cell><cell>14.6</cell></row><row><cell>task 10 (1)</cell><cell>0.0</cell><cell>0.0</cell><cell>3.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>Visualization of α on bAbI dialog task 1, 3, and 4 without match type</figDesc><table><row><cell></cell><cell></cell><cell>(a) Plain and OOV result of task 1</cell><cell></cell></row><row><cell cols="3">Seq. Locutor Task 1: Issuing API calls</cell><cell></cell><cell>α 1</cell></row><row><cell>1</cell><cell>user</cell><cell>Good morning</cell><cell></cell><cell>0.01</cell></row><row><cell>2</cell><cell>bot</cell><cell>Hello what can i help you with today</cell><cell></cell><cell>0.01</cell></row><row><cell>3</cell><cell>user</cell><cell cols="2">Can you make restaurant reservation for eight people in cheap price range with british cuisine</cell><cell>0.23</cell></row><row><cell>4</cell><cell>bot</cell><cell>I'm on it</cell><cell></cell><cell>0.00</cell></row><row><cell>5</cell><cell>user</cell><cell>&lt;silence&gt;</cell><cell></cell><cell>0.14</cell></row><row><cell>6</cell><cell>bot</cell><cell>Where should it be</cell><cell></cell><cell>0.01</cell></row><row><cell>7</cell><cell>user</cell><cell>In madrid</cell><cell></cell><cell>0.25</cell></row><row><cell>8</cell><cell>bot</cell><cell>Ok let me look into some options for you</cell><cell></cell><cell>0.18</cell></row><row><cell cols="2">User input</cell><cell>&lt;silence&gt;</cell><cell></cell></row><row><cell>Answer</cell><cell></cell><cell>API call british madrid eight cheap</cell><cell></cell></row><row><cell cols="2">Model answer</cell><cell>API call british madrid eight cheap</cell><cell>[Correct]</cell></row><row><cell cols="3">Seq. Locutor Task 1 (OOV): Issuing API calls</cell><cell></cell><cell>α 1</cell></row><row><cell>1</cell><cell>user</cell><cell>Hi</cell><cell></cell><cell>0.01</cell></row><row><cell>2</cell><cell>bot</cell><cell>Hello what can i help you with today</cell><cell></cell><cell>0.01</cell></row><row><cell>3</cell><cell>user</cell><cell cols="2">May I have table with cantonese cuisine in cheap price range in seoul for two people</cell><cell>0.49</cell></row><row><cell>4</cell><cell>bot</cell><cell>I'm on it</cell><cell></cell><cell>0.10</cell></row><row><cell>5</cell><cell>user</cell><cell>&lt;silence&gt;</cell><cell></cell><cell>0.01</cell></row><row><cell>6</cell><cell>bot</cell><cell>Ok let me look into some options for you</cell><cell></cell><cell>0.27</cell></row><row><cell cols="2">User input</cell><cell>&lt;silence&gt;</cell><cell></cell></row><row><cell>Answer</cell><cell></cell><cell>API call cantonese seoul two cheap</cell><cell></cell></row><row><cell cols="2">Model answer</cell><cell>API call italian paris two cheap</cell><cell>[Incorrect]</cell></row><row><cell></cell><cell></cell><cell>(b) Same user input with different goal in task 3</cell><cell></cell></row><row><cell cols="3">Seq. Locutor Task 3: Displaying options</cell><cell></cell><cell>α 1</cell></row><row><cell>7</cell><cell>user</cell><cell>resto 1 r rating 1</cell><cell></cell><cell>0.01</cell></row><row><cell>14</cell><cell>user</cell><cell>resto 8 r rating 8</cell><cell></cell><cell>0.01</cell></row><row><cell>21</cell><cell>user</cell><cell>resto 3 r rating 3</cell><cell></cell><cell>0.01</cell></row><row><cell>22</cell><cell>user</cell><cell>Hello</cell><cell></cell><cell>0.01</cell></row><row><cell>23</cell><cell>bot</cell><cell>Hello what can i help you with today</cell><cell></cell><cell>0.01</cell></row><row><cell>24</cell><cell>user</cell><cell cols="2">Can you book table with french food for two people in madrid in moderate price range</cell><cell>0.21</cell></row><row><cell>25</cell><cell>bot</cell><cell>I'm on it</cell><cell></cell><cell>0.01</cell></row><row><cell cols="2">User input</cell><cell>&lt;silence&gt;</cell><cell></cell></row><row><cell>Answer</cell><cell></cell><cell>Where should it be?</cell><cell></cell></row><row><cell cols="2">Model answer</cell><cell>Where should it be?</cell><cell>[Correct]</cell></row><row><cell cols="3">Seq. Locutor Task 3: Displaying options</cell><cell></cell><cell>α 1</cell></row><row><cell>7</cell><cell>user</cell><cell>resto 1 r rating 1</cell><cell></cell><cell>0.00</cell></row><row><cell>14</cell><cell>user</cell><cell>resto 8 r rating 8</cell><cell></cell><cell>0.00</cell></row><row><cell>21</cell><cell>user</cell><cell>resto 3 r rating 3</cell><cell></cell><cell>0.00</cell></row><row><cell>24</cell><cell>user</cell><cell cols="2">Can you book table with french food for two people in madrid in moderate price range</cell><cell>0.14</cell></row><row><cell>25</cell><cell>bot</cell><cell>I'm on it</cell><cell></cell><cell>0.00</cell></row><row><cell>26</cell><cell>user</cell><cell>&lt;silence&gt;</cell><cell></cell><cell>0.09</cell></row><row><cell>27</cell><cell>bot</cell><cell>Ok let me look into some options for you</cell><cell></cell><cell>0.15</cell></row><row><cell>28</cell><cell>user</cell><cell>&lt;silence&gt;</cell><cell></cell><cell>0.10</cell></row><row><cell>29</cell><cell>bot</cell><cell>What do you think of this option : resto 8</cell><cell></cell><cell>0.08</cell></row><row><cell>30</cell><cell>user</cell><cell>No this does not work for me</cell><cell></cell><cell>0.06</cell></row><row><cell>31</cell><cell>bot</cell><cell>Sure let me find other option for you</cell><cell></cell><cell>0.08</cell></row><row><cell cols="2">User input</cell><cell>&lt;silence&gt;</cell><cell></cell></row><row><cell>Answer</cell><cell></cell><cell>What do you think of this option: resto 3</cell><cell></cell></row><row><cell cols="2">Model answer</cell><cell>What do you think of this option: resto 7</cell><cell>[Incorrect]</cell></row><row><cell></cell><cell></cell><cell>(c) Plain and OOV result of task 4</cell><cell></cell></row><row><cell cols="3">Seq. Locutor Task 4: Providing extra information</cell><cell></cell><cell>α 1</cell></row><row><cell>1</cell><cell>user</cell><cell>resto 3 r phone resto 3 phone</cell><cell></cell><cell>0.77</cell></row><row><cell>3</cell><cell>user</cell><cell>resto 3 r address resto 3 address</cell><cell></cell><cell>0.01</cell></row><row><cell>4</cell><cell>user</cell><cell>resto 3 r location london</cell><cell></cell><cell>0.01</cell></row><row><cell>6</cell><cell>user</cell><cell>resto 3 r price cheap</cell><cell></cell><cell>0.01</cell></row><row><cell>10</cell><cell>user</cell><cell>I'd like to book table at resto 3</cell><cell></cell><cell>0.02</cell></row><row><cell>11</cell><cell>bot</cell><cell>Great let me do reservation</cell><cell></cell><cell>0.03</cell></row><row><cell cols="2">User input</cell><cell>What is phone number of restaurant?</cell><cell></cell></row><row><cell>Answer</cell><cell></cell><cell>Here it is: resto 3 phone</cell><cell></cell></row><row><cell cols="2">Model answer</cell><cell>Here it is: resto 3 phone</cell><cell>[Correct]</cell></row><row><cell cols="3">Seq. Locutor Task 4 (OOV): Providing extra information</cell><cell></cell><cell>α 1</cell></row><row><cell>1</cell><cell>user</cell><cell>resto 1 r phone resto 1 phone</cell><cell></cell><cell>0.79</cell></row><row><cell>3</cell><cell>user</cell><cell>resto 1 r address resto 1 address</cell><cell></cell><cell>0.01</cell></row><row><cell>4</cell><cell>user</cell><cell>resto 1 r location hanoi</cell><cell></cell><cell>0.01</cell></row><row><cell>6</cell><cell>user</cell><cell>resto 1 r price expensive</cell><cell></cell><cell>0.01</cell></row><row><cell>10</cell><cell>user</cell><cell>Can you make restaurant reservation at resto 1</cell><cell></cell><cell>0.01</cell></row><row><cell>11</cell><cell>bot</cell><cell>Great let me do reservation</cell><cell></cell><cell>0.04</cell></row><row><cell cols="2">User input</cell><cell>What is phone number of restaurant?</cell><cell></cell></row><row><cell>Answer</cell><cell></cell><cell>Here it is: resto 1 phone</cell><cell></cell></row><row><cell cols="2">Model answer</cell><cell>Here it is: resto 1 phone</cell><cell>[Correct]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Hyperparameters of Relation Memory Networks on bAbI dialog tasks</figDesc><table><row><cell>Task</cell><cell>Story and Question Embedding</cell><cell>Word-lookup Embedding Dim</cell><cell>Hop</cell><cell>gθ</cell><cell>fφ</cell><cell cols="2">Activation Use Batch Norm</cell></row><row><cell>1</cell><cell>sum</cell><cell>128</cell><cell>1</cell><cell>2048, 2048, 1</cell><cell>2048, 2048, 4212</cell><cell>tanh</cell><cell>True</cell></row><row><cell>2</cell><cell>sum</cell><cell>128</cell><cell>1</cell><cell>1024, 1024, 1</cell><cell>1024, 1024, 4212</cell><cell>tanh</cell><cell>True</cell></row><row><cell>3</cell><cell>sum</cell><cell>128</cell><cell>1</cell><cell cols="2">1024, 1024, 1024, 1 1024, 1024, 1024, 4212</cell><cell>tanh</cell><cell>True</cell></row><row><cell>4</cell><cell>concatenation</cell><cell>50</cell><cell>1</cell><cell>1024, 1024, 1</cell><cell>1024, 1024, 4212</cell><cell>tanh</cell><cell>True</cell></row><row><cell>5</cell><cell>concatenation</cell><cell>64</cell><cell>2</cell><cell>4096, 4096, 1</cell><cell>4096, 4096, 4212</cell><cell>tanh</cell><cell>True</cell></row><row><cell cols="3">B ADDITIONAL RESULTS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 :</head><label>10</label><figDesc>Visualization of α 1 and α 2 on user input revised bAbI dialog task 3 without match type</figDesc><table><row><cell cols="3">Seq. Locutor Task 3: Displaying options</cell><cell>α 1</cell><cell>α 2</cell></row><row><cell>1</cell><cell>user</cell><cell>resto 8 r phone resto 8 phone</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>2</cell><cell>user</cell><cell>resto 8 r cuisine french</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>3</cell><cell>user</cell><cell>resto 8 r address resto 8 address</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>4</cell><cell>user</cell><cell>resto 8 r location madrid</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>5</cell><cell>user</cell><cell>resto 8 r number two</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>6</cell><cell>user</cell><cell>resto 8 r price moderate</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>7</cell><cell>user</cell><cell>resto 8 r rating 8</cell><cell>0.01</cell><cell>0.39</cell></row><row><cell>8</cell><cell>user</cell><cell>resto 3 r phone resto 3 phone</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>9</cell><cell>user</cell><cell>resto 3 r cuisine french</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>10</cell><cell>user</cell><cell>resto 3 r address resto 3 address</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>11</cell><cell>user</cell><cell>resto 3 r location madrid</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>12</cell><cell>user</cell><cell>resto 3 r number two</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>13</cell><cell>user</cell><cell>resto 3 r price moderate</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>14</cell><cell>user</cell><cell>resto 3 r rating 3</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>15</cell><cell>user</cell><cell>resto 1 r phone resto 1 phone</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>16</cell><cell>user</cell><cell>resto 1 r cuisine french</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>17</cell><cell>user</cell><cell>resto 1 r address resto 1 address</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>18</cell><cell>user</cell><cell>resto 1 r location madrid</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>19</cell><cell>user</cell><cell>resto 1 r number two</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>20</cell><cell>user</cell><cell>resto 1 r price moderate</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>21</cell><cell>user</cell><cell>resto 1 r rating 1</cell><cell>0.00</cell><cell>0.01</cell></row><row><cell>22</cell><cell>user</cell><cell>Good morning</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>23</cell><cell>bot</cell><cell>Hello what can I help you with today?</cell><cell>0.12</cell><cell>0.01</cell></row><row><cell>24</cell><cell>user</cell><cell>May I have table for two with french food?</cell><cell>0.08</cell><cell>0.02</cell></row><row><cell>25</cell><cell>bot</cell><cell>I'm on it</cell><cell>0.03</cell><cell>0.01</cell></row><row><cell>26</cell><cell>user</cell><cell>&lt;silence&gt;</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>27</cell><cell>bot</cell><cell>Where should it be</cell><cell>0.09</cell><cell>0.01</cell></row><row><cell>28</cell><cell>user</cell><cell>In madrid</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>29</cell><cell>bot</cell><cell>Which price range are looking for?</cell><cell>0.09</cell><cell>0.01</cell></row><row><cell>30</cell><cell>user</cell><cell>In moderate price range please</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>31</cell><cell>bot</cell><cell>Ok let me look into some options for you</cell><cell>0.24</cell><cell>0.01</cell></row><row><cell cols="2">User input</cell><cell>&lt;silence&gt;&lt;silence&gt;</cell><cell></cell><cell></cell></row><row><cell>Answer</cell><cell></cell><cell>What do you think of this option: resto 8</cell><cell></cell><cell></cell></row><row><cell cols="2">Model answer</cell><cell>What do you think of this option: resto 8</cell><cell>[correct]</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For a fair comparison, we report EntNet's result which was jointly trained on all tasks. It was written in the appendix of the paper.2 Our implementation. The result is different from what<ref type="bibr" target="#b9">Santoro et al. (2017)</ref> mentioned, which is caused by the initialization.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We only compare models under the same conditions 4 Our implementation.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Number in parentheses indicates the number of supporting sentences to solve the task</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning end-to-end goal-oriented dialog</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<idno>abs/1605.07683</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivo</forename><surname>Danihelka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.5401</idno>
		<title level="m">Neural turing machines</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jürgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<title level="m">Memory networks. International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diederik</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Ask me anything: Dynamic memory networks for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1378" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Gated end-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Perez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 15th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th international conference on machine learning (ICML-10)</title>
		<meeting>the 27th international conference on machine learning (ICML-10)</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A simple neural network module for relational reasoning. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Pascanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lillicrap</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Towards ai-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>abs/1502.05698</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dynamic memory networks for visual and textual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2397" to="2406" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
