<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Non-convex Learning via Replica Exchange Stochastic Gradient MCMC</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Deng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Feng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liyao</forename><surname>Gao</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faming</forename><surname>Liang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Lin</surname></persName>
						</author>
						<title level="a" type="main">Non-convex Learning via Replica Exchange Stochastic Gradient MCMC</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Replica exchange Monte Carlo (reMC), also known as parallel tempering, is an important technique for accelerating the convergence of the conventional Markov Chain Monte Carlo (MCMC) algorithms. However, such a method requires the evaluation of the energy function based on the full dataset and is not scalable to big data. The naïve implementation of reMC in mini-batch settings introduces large biases, which cannot be directly extended to the stochastic gradient MCMC (SGMCMC), the standard sampling method for simulating from deep neural networks (DNNs). In this paper, we propose an adaptive replica exchange SGMCMC (reSGMCMC) to automatically correct the bias and study the corresponding properties. The analysis implies an accelerationaccuracy trade-off in the numerical discretization of a Markov jump process in a stochastic environment. Empirically, we test the algorithm through extensive experiments on various setups and obtain the state-of-the-art results on CIFAR10, CI-FAR100, and SVHN in both supervised learning and semi-supervised learning tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The increasing concern for AI safety problems draws our attention to MCMC, which is known for its asymptotic uncertainty quantification <ref type="bibr" target="#b42">Teh et al., 2016)</ref>, and guarantees in non-convex optimizations <ref type="bibr" target="#b47">(Zhang et al., 2017;</ref><ref type="bibr" target="#b36">Raginsky et al., 2017)</ref>. Traditional MCMC methods have achieved tremendous success. However, the efficient sampling algorithm in DNNs was not well studied until the invention of stochastic gradient Langevin dynamics (SGLD) <ref type="bibr" target="#b43">(Welling and Teh, 2011)</ref>, which scales up the computation in DNNs by injecting noises to stochastic gradients. Since then, various high-order SGMCMC algorithms have been proposed, which incorporate strategies such as Hamiltonian dynamics <ref type="bibr" target="#b30">Ma et al., 2015;</ref><ref type="bibr" target="#b18">Ding et al., 2014)</ref>, Hessian approximation <ref type="bibr" target="#b26">(Li et al., 2016;</ref><ref type="bibr" target="#b15">Ş imşekli et al., 2016)</ref>, and high-order numerical schemes <ref type="bibr" target="#b27">Li et al., 2019)</ref> to improve the convergence.</p><p>In addition to the high-order algorithms, we can also follow traditional MCMC algorithms combined with simulated annealing <ref type="bibr" target="#b23">(Kirkpatrick et al., 1983)</ref>, simulated tempering <ref type="bibr" target="#b32">(Marinari and Parisi, 1992)</ref>, dynamical weighting (Wong and <ref type="bibr" target="#b44">Liang, 1997)</ref> or replica exchange Monte Carlo <ref type="bibr" target="#b41">(Swendsen and Wang, 1986;</ref><ref type="bibr" target="#b20">Earl and Deem, 2005)</ref>. Among these advancements, simulated annealing SGMCMC <ref type="bibr" target="#b31">(Mangoubi and Vishnoi, 2018)</ref> and simulated tempering SGMCMC <ref type="bibr" target="#b25">(Lee et al., 2018)</ref> show how dynamical temperatures speed up the convergence. However, simulated annealing is very sensitive to the fast-decaying temperatures, and simulated tempering requires a lot on the approximation of the normalizing constant. For the latter, the replica exchange Monte Carlo is easier to analyze and implement and is suitable for parallelism. Specifically, the replica exchange Langevin diffusion utilizes multiple diffusion processes with different temperatures and proposes to swap the processes while training. Intuitively, the high-temperature process acts as a bridge to connect the various modes. As such, the acceleration effect can be theoretically quantified <ref type="bibr" target="#b19">(Dupuis et al., 2012;</ref><ref type="bibr" target="#b14">Chen et al., 2019)</ref>. However, despite these advantages, a proper replica exchange SGMCMC (reSGMCMC) has long been missing in the deep learning community.</p><p>A bottleneck that hinders the development of reSGMCMC is the naïve extension of the acceptance-rejection criterion that fails in mini-batch settings. Various attempts <ref type="bibr" target="#b5">(Bardenet et al., 2017;</ref><ref type="bibr" target="#b24">Korattikara et al., 2014)</ref> were proposed to solve this issue. However, they introduce biases even with the ideal normality assumption on the noise. Some unbiased estimators <ref type="bibr" target="#b8">(Bhanot and Kennedy, 1985;</ref><ref type="bibr" target="#b7">Beskos et al., 2006)</ref> have ever been presented, but the large variance leads to inefficient inference. To remove the bias while maintaining efficiency, <ref type="bibr" target="#b11">Ceperley and Dewing (1999)</ref> proposed a corrected criterion under normality assumptions, and <ref type="bibr" target="#b40">Seita et al. (2017)</ref>; <ref type="bibr" target="#b35">Quiroz et al. (2019)</ref> further analyzed the model errors with the asymptotic normality assumptions. However, the above algorithms fail when the required corrections are arXiv:2008.05367v3 [stat.ML] 22 Mar 2021 time-varying and much larger than the energies as shown in <ref type="figure">Fig.3(a-b)</ref>. Consequently, an effective algorithm with the potential to adaptively estimate the corrections and balance between acceleration and accuracy is in great demand.</p><p>In this paper, we propose an adaptive replica exchange SGMCMC algorithm via stochastic approximation (SA) <ref type="bibr" target="#b37">(Robbins and Monro, 1951;</ref><ref type="bibr" target="#b29">Liang et al., 2007;</ref><ref type="bibr" target="#b17">Deng et al., 2019)</ref>, a standard method in adaptive sampling to estimate the latent variable: the unknown correction. The adaptive algorithm not only shows the asymptotic convergence in standard scenarios but also gives a good estimate when the corrections are time-varying and excessively large. We theoretically analyze the discretization error for reSGMCMC in mini-batch settings and show the accelerated convergence in 2-Wasserstein distance. Such analysis sheds light on the use of biased estimates of unknown corrections to obtain a trade-off between acceleration and accuracy. In summary, this algorithm has three main contributions:</p><p>1. We propose a novel reSGMCMC to speed up the computations of SGMCMC in DNNs with theoretical guarantees. The theory shows the potential of using biased corrections and a large batch size to obtain better performance.</p><p>2. We identify the problem of time-varying corrections in DNNs and propose to adaptively estimate the time-varying corrections, with potential extension to a variety of timeseries prediction techniques.</p><p>3. We test the algorithm through extensive experiments using various models. It achieves the state-of-the-art results in both supervised learning and semi-supervised learning tasks on CIFAR10, CIFAR100, and SVHN datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries</head><p>A standard sampling algorithm is the Langevin diffusion, which is a stochastic differential equation (SDE) as follows:</p><formula xml:id="formula_0">dβ (1) t = −∇U (β (1) t )dt + √ 2τ 1 dW (1) t ,<label>(1)</label></formula><p>where β</p><p>(1) t ∈ R d , U (·) is the energy function, W</p><p>(1) t ∈ R d is the Brownian motion, and τ 1 &gt; 0 is the temperature.</p><p>Under mild growth conditions on U , the Langevin diffusion {β (1) t } t≥0 converges to the unique invariant Gibbs distribution π τ1 (β (1) ) ∝ exp(− U (β (1) ) τ1 ), where the temperature τ 1 is crucial for both optimization and sampling of the non-convex energy function U . On the one hand, a high-temperature τ 1 achieves the exploration effect: the convergence to the flattened Gibbs distribution of the whole domain is greatly facilitated. However, the flattened distribution is less concentrated around the global optima <ref type="bibr" target="#b36">(Raginsky et al., 2017)</ref>, and the geometric connection to the global minimum is affected <ref type="bibr" target="#b47">(Zhang et al., 2017)</ref>. On the other hand, a low-temperature τ 1 leads to the exploitation effect: the solutions explore the local geometry rapidly, but they are more likely to get trapped in local optima, leading to a slow convergence in both optimization and sampling. Therefore, the potential of using a fixed temperature is quite limited.</p><p>A powerful algorithm called replica exchange Langevin diffusion (reLD), also known as parallel tempering Langevin diffusion, has been proposed to accelerate the convergence of the SDE as shown in <ref type="figure" target="#fig_0">Fig.1</ref>. reLD proposes to simulate a high-temperature particle for exploration and a lowtemperature particle for exploitation and allows them to swap simultaneously. Now consider the following coupled processes with a higher temperature τ 2 &gt; τ 1 and</p><formula xml:id="formula_1">W (2) independent of W (1) : dβ (1) t = −∇U (β (1) t )dt + √ 2τ 1 dW (1) t dβ (2) t = −∇U (β (2) t )dt + √ 2τ 2 dW (2) t .</formula><p>(2)</p><p>Eq.</p><p>(2) converges to the invariant distribution with density</p><formula xml:id="formula_2">π(β (1) , β (2) ) ∝ e − U (β (1) ) τ 1 − U (β (2) ) τ 2 .<label>(3)</label></formula><p>By allowing the two particles to swap, the positions are likely to change from (β</p><formula xml:id="formula_3">(1) t , β (2) t ) to (β (2) t+dt , β (1) t+dt ) with a swapping rate r(1 ∧ S(β (1) t , β</formula><p>(2) t ))dt, where the constant r ≥ 0 is the swapping intensity, and S(·, ·) satisfies</p><formula xml:id="formula_4">S(β (1) t , β (2) t ) := e 1 τ 1 − 1 τ 2 U (β (1) t )−U (β (2) t ) . (4)</formula><p>In such a case, reLD is a Markov jump process, which is reversible <ref type="bibr" target="#b14">(Chen et al., 2019)</ref> and leads to the same invariant distribution (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Replica Exchange Stochastic Gradient Langevin Dynamics</head><p>The wide adoption of the replica exchange Monte Carlo in traditional MCMC algorithms motivates us to design replica exchange stochastic gradient Langevin dynamics for DNNs, but the straightforward extension of reLD to replica exchange stochastic gradient Langevin dynamics is highly non-trivial <ref type="bibr" target="#b30">Ma et al., 2015;</ref><ref type="bibr" target="#b15">Ş imşekli et al., 2016)</ref>. In this section, we will first show that naïve extensions of replica exchange Monte Carlo to SGLD (naïve reSGLD) lead to large biases. Afterward, we will present an adaptive replica exchange stochastic gradient Langevin dynamics (reSGLD) that will automatically adjust the bias and yield a good approximation to the correct distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Naïve reSGLD</head><p>We denote the entire data by D = {d i } N i=1 , where d i is a data point. Given the model parameter β, we consider the following energy function (negative log-posterior)</p><formula xml:id="formula_5">L( β) = − log p( β) − N i=1 log P (d i | β).<label>(5)</label></formula><p>where p( β) is a proper prior and</p><formula xml:id="formula_6">N i=1 log P (d i | β)</formula><p>is the complete data log-likelihood. When the number of data points N is large, it is expensive to evaluate L( β) directly. Instead, we propose to approximate the energy function with a mini-batch of data B = {d si } n i=1 , where s i ∈ {1, 2, ..., N }. We can easily check that if B is sampled randomly with or without replacement, we obtain the following unbiased estimator of the energy function</p><formula xml:id="formula_7">L( β) = − log p( β) − N n n i=1 log P (d si | β).<label>(6)</label></formula><p>Let β k denote the estimate of β at the k-th iteration. Next, SGLD proposes the following iterations:</p><formula xml:id="formula_8">β k+1 = β k − η k ∇ L( β k ) + 2η k τ 1 ξ k ,<label>(7)</label></formula><p>where η k is the learning rate, the stochastic gradient ∇ L( β k ) is the unbiased estimator of the exact gradient ∇L( β k ), ξ is a standard d-dimensional Gaussian vector with mean 0 and identity covariance matrix. It is known that SGLD asymptotically converges to a unique invariant distribution π( β) ∝ exp −L( β)/τ 1 <ref type="bibr" target="#b42">(Teh et al., 2016)</ref> as η k → 0. If we simply replace gradients with stochastic gradients in the replica exchange gradient Langevin dynamics, we have</p><formula xml:id="formula_9">β (1) k+1 = β (1) k − η k ∇ L( β (1) k ) + 2η k τ 1 ξ (1) k β (2) k+1 = β (2) k − η k ∇ L( β (2) k ) + 2η k τ 2 ξ (2) k .<label>(8)</label></formula><p>Furthermore, we swap the Markov chains in (8) with the naïve stochastic swapping rate r(1 ∧ S( β</p><formula xml:id="formula_10">(1) k+1 , β (2) k+1 ))η k § : S( β (1) k+1 , β (2) k+1 ) = e 1 τ 1 − 1 τ 2 L( β (1) k+1 )− L( β (2) k+1 ) . (9)</formula><p>Apparently, the unbiased estimators L( β</p><formula xml:id="formula_11">(1) k+1 ) and L( β (2) k+1 ) in S( β (1) k+1 , β (2) k+1 ) do not provide an unbiased estimator of S( β (1) k+1 , β (2) k+1</formula><p>) after a non-linear transformation as shown in (9), which leads to a large bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Replica Exchange Stochastic Gradient Langevin Dynamics with Correction</head><p>A viable MCMC algorithm requires the approximately unbiased estimators of the swapping rates to "satisfy" the § In the implementations, we fix rη k = 1 by default.</p><p>detailed balance property <ref type="bibr" target="#b11">(Ceperley and Dewing, 1999;</ref><ref type="bibr" target="#b0">Andrieu and Roberts, 2009;</ref><ref type="bibr" target="#b34">Nicholls et al., 2012)</ref> and the weak solution of a Markov jump process with unbiased stochastic coefficients has also been studied in <ref type="bibr" target="#b22">Gyöngy (1986)</ref>; Bentata and Cont (2012). When we make normality assumption on the stochastic energy L(β) ∼ N (L(β), σ 2 ), it follows</p><formula xml:id="formula_12">L( β (1) )− L( β (2) ) = L( β (1) )−L( β (2) )+ √ 2σW 1 ,<label>(10)</label></formula><p>where W 1 follows the standard normal distribution and can be viewed as a Brownian motion at t = 1. Consider the evolution of the stochastic swapping rate { S t } t∈[0,1] in each swap as a geometric Brownian motion:</p><formula xml:id="formula_13">St = e 1 τ 1 − 1 τ 2 L( β (1) )− L( β (2) )− 1 τ 1 − 1 τ 2 σ 2 t = e 1 τ 1 − 1 τ 2 L( β (1) )−L( β (2) )− 1 τ 1 − 1 τ 2 σ 2 t+ √ 2σW t .<label>(11)</label></formula><p>Set τ δ = 1 τ1 − 1 τ2 and take the partial derivatives of S t</p><formula xml:id="formula_14">d S t dt = −τ 2 δ σ 2 S t , d S t dW t = √ 2τ δ σ S t , d 2 S t dW 2 t = 2τ 2 δ σ 2 S t .</formula><p>Itô's lemma shows that</p><formula xml:id="formula_15">d S t = d S t dt + 1 2 d 2 S t dW 2 t dt + d S t dW t dW t = √ 2τ δ σ S t dW t .</formula><p>Notice that { S t } t∈[0,1] is a Martingale and yields the same expectation for ∀t ∈ [0, 1]. By fixing t = 1 in (11), we have</p><formula xml:id="formula_16">S 1 = e 1 τ 1 − 1 τ 2 L( β (1) )− L( β (2) )− 1 τ 1 − 1 τ 2 σ 2 ,<label>(12)</label></formula><p>where the stochastic swapping rate S 1 is an unbiased estimator of S 0 = e 1 τ 1 − 1 τ 2 (L( β (1) )−L( β (2) )) , and the correction term 1 τ1 − 1 τ2 σ 2 aims to remove the bias from the swaps.</p><p>An advantage of interpreting the correction term from the perspective of geometric Brownian motion is that we may extend it to geometric Lévy process <ref type="bibr" target="#b1">(Applebaum, 2004)</ref>, which is more suitable for the heavy-tailed energy noise <ref type="bibr">(Ş imşekli et al., 2019)</ref>. Admittedly, the estimation of the tail-index of extreme-value distributions and the correction under Lévy process go beyond the scope of this paper, so we leave it for future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Adaptive Replica Exchange Stochastic Gradient Langevin Dynamics</head><p>In reality, the exact variance σ 2 is hardly known and subject to estimation. The normality assumption may be violated and even no longer time-independent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">FIXED VARIANCE σ 2</head><p>We use stochastic approximation (SA) to adaptively estimate the unknown variance while sampling from the posterior. In each SA step, we obtain an unbiased sample varianceσ 2 for the true σ 2 and update the adaptive estimateσ 2 m+1 througĥ</p><formula xml:id="formula_17">σ 2 m+1 = (1 − γ m )σ 2 m + γ mσ 2 m+1 ,<label>(13)</label></formula><p>where γ m is the smoothing factor at the m-th SA step. The SA step is updated less frequently than the standard sampling to reduce the computational cost. When the normality assumption holds, we notice thatσ 2 m = m i=1σ 2 i /m when γ m = 1 m . Following central limit theorem (CLT), we have thatσ 2 m − σ 2 = O( 1 m ). Inspired by theorem 2 from , we expect that the weak convergence of the adaptive sampling algorithm holds since the bias decreases sufficiently fast ( 1 m m l=1 O( 1 l ) → 0 as m → ∞). In practice, the normality assumption is likely to be violated when we use a small batch size n, but the unknown distribution asymptotically approximates the normal distribution as n → ∞ and yield a bias O( 1 n ) in each SA step. Besides, the mini-batch setting usually introduces a very large noise on the estimator of the energy function, which requires a large correction term and leads to almost-zero swapping rates.</p><p>To handle this issue, we introduce a correction factor F to reduce the correction term from 1 τ1 − 1 τ2 σ 2 to</p><formula xml:id="formula_18">1 τ 1 − 1 τ 2 σ 2 F</formula><p>. We note that a large F &gt; 1 introduces some bias, but may significantly increase the acceleration effect, giving rise to an acceleration-accuracy trade-off in finite time. Now, we show the algorithm in Alg.1. In addition to simulations of multi-modal distributions, our algorithm can be also combined with simulated annealing <ref type="bibr" target="#b28">(Li et al., 2009;</ref><ref type="bibr" target="#b33">Martino et al., 2016)</ref> to accelerate the non-convex optimization and increase the hitting probability to the global optima (Mangoubi and Vishnoi, 2018).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">TIME-VARYING VARIANCE σ 2</head><p>In practice, the variance σ 2 usually varies with time, resulting in time-varying corrections. For example, in the optimization of residual networks on CIFAR10 and CI-FAR100 datasets, we notice from <ref type="figure">Fig.3</ref>(a-b) that the corrections are time-varying. As such, we cannot use a fixed correction anymore to deal with the bias. The treatment for the time-varying corrections includes standard methods for time-series data, and a complete recipe for modeling the data goes beyond our scope. We still adopt the method of stochastic approximation and choose a fixed smoothing factor γ so that</p><formula xml:id="formula_19">σ 2 m+1 = (1 − γ)σ 2 m + γσ 2 m+1 .<label>(14)</label></formula><p>Such a method resembles the simple exponential smoothing and acts as robust filters to remove high-frequency noise. It can be viewed as a special case of autoregressive integrated moving average (ARIMA) (0,1,1) model but often</p><p>Algorithm 1 Adaptive Replica Exchange Stochastic Gradient Langevin Dynamics Algorithm. For sampling purposes, we fix the temperatures τ 1 and τ 2 ; for optimization purposes, we keep annealing τ 1 and τ 2 during each epoch. Empirically, a larger γ m tracks the dynamics better but is less robust. The intensity r and η are omitted in the corrected swaps. repeat Sampling</p><p>Step</p><formula xml:id="formula_20">β (1) k+1 = β (1) k − η (1) k ∇ L( β (1) k ) + 2η (1) k τ1ξ (1) k β (2) k+1 = β (2) k − η (2) k ∇ L( β (2) k ) + 2η (2) k τ2ξ (2) k ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SA Step</head><p>Obtain an unbiased estimateσ 2 m+1 for σ 2 .</p><formula xml:id="formula_21">σ 2 m+1 = (1 − γ m )σ 2 m + γ mσ 2 m+1 ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Swapping</head><p>Step Generate a uniform random number u ∈ [0, 1].</p><formula xml:id="formula_22">S 1 = e 1 τ 1 − 1 τ 2 L( β (1) k+1 )− L( β (2) k+1 )− ( 1 τ 1 − 1 τ 2 )σ 2 m+1 F . if u &lt;Ŝ 1 then Swap β (1) k+1 and β (2) k+1 . end if until k = k max</formula><p>outperforms the ARIMA equivalents because it is less sensitive to the model selection error <ref type="bibr" target="#b9">(Bossons, 1966)</ref>. From the regression perspective, this method can be viewed as a zero-degree local polynomial kernel model <ref type="bibr" target="#b21">(Gijbels et al., 1999)</ref>, which is robust to distributional assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Convergence Analysis</head><p>We theoretically analyze the acceleration effect and the accuracy of reSGLD in terms of 2-Wasserstein distance between the Borel probability measures µ and ν on R d</p><formula xml:id="formula_23">W 2 (µ, ν) := inf Γ∈Couplings(µ,ν) β µ − β ν 2 dΓ(β µ , β ν ),</formula><p>where · is the Euclidean norm, and the infimum is taken over all joint distributions Γ(β µ , β ν ) with µ and ν being its marginal distributions.</p><p>Our analysis begins with the fact that reSGLD in Algorithm.1 tracks the replica exchange Langevin diffusion (2). For ease of analysis, we consider a fixed learning rate η for both chains. reSGLD can be viewed as a special discretization of the continuous-time Markov jump process. In particular, it differs from the standard discretization of the continuous-time Langevin algorithms <ref type="bibr" target="#b14">(Chen et al., 2019;</ref><ref type="bibr" target="#b46">Yin and Zhu, 2010;</ref><ref type="bibr" target="#b36">Raginsky et al., 2017;</ref><ref type="bibr" target="#b39">Sato and Nakagawa, 2014)</ref> in that we need to consider the discretization of the Markov jump process in a stochastic environment. To handle this issue, we follow <ref type="bibr" target="#b19">Dupuis et al. (2012)</ref> and view the swaps of positions as swaps of the temperatures, which have been proven equivalent in distribution.</p><p>Lemma 1 (Discretization Error). Given the smoothness and dissipativity assumptions in the appendix, and a small learning rate η, we have that</p><formula xml:id="formula_24">E[sup 0≤t≤T βt− β η t || 2 ]≤Õ(η+maxi E[ φi 2 ]+maxi √ E[|ψi| 2 ]),</formula><p>where β η t is the continuous-time interpolation for reSGLD, φ := ∇ U − ∇U is the noise in the stochastic gradient, and ψ := S − S is the noise in the stochastic swapping rate.</p><p>Then we quantify the evolution of the 2-Wasserstein distance between ν t and the invariant distribution π, where ν t is the probability measure associated with reLD at time t. The key tool is the exponential decay of entropy when π satisfies the log-Sobolev inequality (LSI) <ref type="bibr" target="#b4">(Bakry et al., 2014)</ref>. To justify LSI, we first verify LSI for reLD without swaps, which is a direct result <ref type="bibr" target="#b10">(Cattiaux et al., 2010)</ref> given the Lyapunov function criterion and the Poincaré inequality <ref type="bibr" target="#b14">(Chen et al., 2019)</ref>. Then we verify LSI for reLD with swaps by analyzing the corresponding Dirichlet form, which is strictly larger than the Dirichlet form associated with reLD without swaps. Finally, the exponential decay of the 2-Wasserstein distance follows from the Otto-Villani theorem <ref type="bibr" target="#b4">(Bakry et al., 2014)</ref> by connecting 2-Wasserstein distance with the relative entropy.</p><p>Lemma 2 (Accelerated exponential decay of W 2 ). Under the smoothness and dissipativity assumptions, we have that the replica exchange Langevin diffusion converges exponentially fast to the invariant distribution π:</p><formula xml:id="formula_25">W 2 (ν t , π) ≤ D 0 e −kη(1+δ S )/cLS ,<label>(15)</label></formula><p>where</p><formula xml:id="formula_26">δ S := inf t&gt;0 E S ( dν t dπ ) E( dν t dπ )</formula><p>− 1 is the very acceleration effect depending on the swapping rate S, E and E S are the Dirichlet forms defined in the appendix, c LS is the constant in the log-Sobolev inequality, D 0 = 2c LS D(ν 0 ||π).</p><p>Finally, combining the definition of Wasserstein distance and the triangle inequality, we have that Theorem 1 (Convergence of reSGLD). Let the smoothness and dissipativity assumptions hold. For the distribution {µ k } k≥0 associated with the discrete dynamics { β k } k≥1 , we have the following estimates for k ∈ N + :</p><formula xml:id="formula_27">W 2 (µ k ,π) ≤ D 0 e −kη(1+δ S )/cLS +Õ(η 1 2 + max i (E[ φ i 2 ]) 1 2 + max i (E |ψ i | 2 ) 1 4 ), where D 0 = 2c LS D(µ 0 ||π), δ S := min i E S ( dµ i dπ ) E( dµ i dπ ) − 1.</formula><p>Ideally, we want to boost the acceleration effect δ S by using a larger swapping rate S and increase the accuracy by reducing the mean squared errors E[ φ i 2 ] and E[|ψ i | 2 ]. One possible way is to apply a large enough batch size, which may be yet inefficient given a large dataset. Another way is to balance between acceleration and accuracy by tuning the correction factor F . In practice, a larger F leads to a larger acceleration effect and also injects more biases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Simulations of Gaussian Mixture Distributions</head><p>In this group of experiments, we evaluate the acceleration effects and the biases for reSGLD on multi-modal distributions based on different assumptions on the estimators for the energy function. As a comparison, we choose SGLD and the naïve reSGLD without corrections as baselines. The learning rates η (1) and η (2) are both set to 0.03, and the temperatures τ 1 and τ 2 are set to 1 and 10, respectively. In particular, SGLD uses the learning rate η (1) and the temperature τ 1 . We simulate 100,000 samples from each distribution and propose to estimate the correction every 100 iterations. The correction estimator is calculated based on the variance of 10 samples of U 1 (x). The initial correction is set to 100 and the step size γ m for stochastic approximation is chosen as 1 m . The correction factor F is 1 in the first two examples. We first demonstrate reSGLD on a simple Gaussian mixture distribution e −U1(x) ∼ 0.4N (−3, 0.7 2 ) + 0.6N (2, 0.5 2 ), where U 1 (x) is the energy function. We assume we can only obtain the unbiased energy estimator U 1 (x) ∼ N (U 1 (x), 2 2 ) and the corresponding stochastic gradient at each iteration. From <ref type="figure" target="#fig_6">Fig.2(a,b)</ref>, we see that SGLD suffers from the local trap problem and takes a long time to converge. The naïve reSGLD algorithm alleviated the local trap problem, but is still far away from the ground truth distribution without a proper correction. The naïve reSGLD converges faster than reSGLD in the early phase due to a higher swapping rate, but ends up with a large bias when the training continues. By contrast, reSGLD successfully identifies the right correction through adaptive estimates and yields a close approximation to the ground truth distribution. The high-temperature chain serves as a bridge to facilitate the movement, and the local trap problem is greatly reduced.</p><p>In the second example, we relax the normality assumption to a heavy-tail distribution. Given a Gaussian mixture distribution e −U2(x) ∼ 0.4N (−4, 0.7 2 ) + 0.6N (3, 0.5 2 ), we assume that we can obtain the stochastic energy estimator U 2 (x) ∼ U 2 (x) + t(ν = 5), where t(ν = 5) denotes the Student's t-distribution with degree of freedom 5. We see  <ref type="figure" target="#fig_6">Figure 2</ref>. Evaluation of reSGLD on Gaussian mixture distributions, where the naïve reSGLD doesn't make any corrections and reSGLD proposes to adaptively estimate the unknown corrections. In <ref type="figure" target="#fig_0">Fig.1(d)</ref>, we omit SGLD because it gets stuck in a single mode.</p><formula xml:id="formula_28">0.0 0.2 0.4 −5.0 −2.5 0.0 2.5 X Density Ground truth Naive reSGLD reSGLD SGLD (a) U 1 (x)∼N (U 1 (x),2 2 ).</formula><formula xml:id="formula_29">(c) U 2 (x)∼U 2 (x)+t(ν=5). S=0.4% S=7.1% S=46% 0.00 0.05 0.10 0.15 0.20 −10 −5 0 5 X Density Ground truth reSGLD F=2 reSGLD F=4 reSGLD F=Inf (d) U 3 (x)∼U 3 (x)+7t(ν=10).</formula><p>from <ref type="figure" target="#fig_6">Fig.2</ref>(c) that reSGLD still gives a good approximation to the ground true distribution while the others don't.</p><p>In the third example, we show a case when the correction factor F is useful. We sample from a Gaussian mixture distribution e −U3(x) ∼ 0.4N (−6, 0.7 2 ) + 0.6N (4, 0.5 2 ). We note that the two modes are far away from each other and the distribution is more difficult to simulate. More interestingly, we assume U 3 (x) ∼ U 3 (x) + 7t(ν = 10), which requires a large correction term and ends up with no swaps in the finite 100,000 iterations at F = 1. In such a case, the unbiased algorithm behaves like the ordinary SGLD as in <ref type="figure" target="#fig_6">Fig.2</ref>(c) and still suffers from the local trap problems. To achieve larger acceleration effects to avoid local traps and maintain accuracy, we try F at 2, 4 and ∞ (Inf), where the latter is equivalent to the naïve reSGLD. We see from <ref type="figure" target="#fig_6">Fig.2(d</ref>) that F = 2 shows the best approximations, despite that the swapping rate S is only 0.4%. Further increases on the acceleration effect via larger correction factors F give larger swapping rates (7.1% and 46%) and potentially accelerate the convergence in the beginning. However, the biases become more significant as we increase F and lead to larger errors in the end.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Optimization of Image Data</head><p>We evaluate the adaptive replica exchange Monte Carlo on CIFAR10 and CIFAR100 , which consist of 50,000 32 × 32 RGB images for training and 10,000 images for testing. CIFAR10 and CIFAR100 have 10 classes and 100 classes, respectively. We adopt the well-known residual networks (ResNet) and wide ResNet (WRN) as model architectures. We use the 20, 32, 56-layer ResNet (denoted as <ref type="bibr">et al.)</ref>, WRN-16-8 and WRN-28-10, where, for example, WRN-16-8 denotes a ResNet that has 16 layers and is 8 times wider than the original. Inspired by the popular momentum stochastic gradient descent, we use stochastic gradient Hamiltonian Monte Carlo (SGHMC) as the baseline sampling algorithm and use the numerical method proposed by <ref type="bibr" target="#b38">Saatci and Wilson (2017)</ref> to reduce the tuning cost. We refer to the momentum stochastic gradient descent algorithm as M-SGD and the adaptive replica exchange SGHMC algorithm as reSGHMC.</p><p>We first run several experiments to study the ideal corrections for the optimization of deep neural networks based on the fixed temperatures τ 1 = 0.01 and τ 2 = 0.05. We observe from <ref type="figure">Fig.(3)</ref>(a, b) that the corrections are thousands of times larger than the energy losses, which implies that an exact correction leads to no swaps in practice and no acceleration can be achieved. The desire to obtain more acceleration effects drives us to manually shrink the corrections by increasing F to increase the swapping rates, although we have to suffer from some model bias.</p><p>We study the model performance by applying different correction factors F . We choose batch-size 256 and run the experiments within 500 epochs. We first tune the optimal hyperparameters for M-SGD, SGHMC and the lowtemperature chain of reSGHMC: we set the learning rate η (1) k to 2e-6 in the first 200 epochs and decay it afterward by a factor of 0.984 every epoch; the low temperature follows an annealing schedule τ 1 = 0.01 1.02 k to accelerate the optimization; the weight decay is set to 25. Then, as to the high-temperature chain of reSGHMC, we use a larger learning rate η</p><p>(2) k = 1.5η</p><p>(1) k and a higher temperature τ 2 = 5τ 1 . We set F as F 0 in the beginning and then adapt the value to counteract the annealing effect of the temperatures. The variance estimator is updated each epoch based on the variance of 10 samples of the stochastic energies and the smoothing factor is set to γ = 0.3 in <ref type="formula" target="#formula_0">(14)</ref>. Consequently, the computations only increase by less than 5%. In addition, we use a thinning factor 200 and report all the results based on Bayesian model averaging. We repeat every experiment five times to obtain the mean and 2 standard deviations.</p><p>We see from <ref type="figure">Fig.3(c,d)</ref> that both datasets rely on a very large initial correction factor F 0 to yield good performance and the optimal initial correction factor F 0 is achieved at 3e5. Empirically, we notice that the first five swaps provide the largest marginal improvement in acceleration. A larger F 0 than F 0 leads to a larger swapping rate with more swaps and  thus a larger acceleration effect, however, the performance still decreases as we increase F 0 , implying that the biases start to dominate the error and the diminishing marginal improvement on the acceleration effect is no longer significant. We note that there is only one extra hyper-parameter, namely, the correction factor F , required to tune, and it is independent of the standard SGHMC. This shows that the tuning cost is acceptable. To obtain a comprehensive evaluation of reSGHMC, we use the optimal correction factor for reSGHMC and test it on ResNet20, 32, 56, WRN-16-8 and WRN-28-10. From We also conduct the experiments using larger batch sizes with ResNet-20 and report the results in <ref type="table" target="#tab_2">Table.</ref>2. We run the same iterations and keep the other setups the same. We find that a larger batch size significantly boosts the performance of reSGHMC by as much as 0.4% accuracies on CIFAR10 and 1% on CIFAR100, which shows the potential of using a large batch size in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Bayesian GANs for Semi-supervised Learning</head><p>Semi-supervised learning (SSL) is an economic machine learning task because it doesn't require all the data to have pricey labels and still shows promising results. However, the multi-modal problem is more severe in the training of SSLs, such as Bayesian GANs <ref type="bibr" target="#b38">(Saatci and Wilson, 2017)</ref>, which motivates us to utilize a more powerful algorithm for multimodal sampling. Therefore, we further evaluate reSGHMC in SSL on CIFAR10, CIFAR100 and the StreetView House Numbers dataset (SVHN) † using Bayesian GANs and study how swaps boost the performance.</p><p>Regarding the Bayesian GANs used for SSLs, we transform the ordinary discriminator into a K+1-class classifier, where K is the number of classes in each dataset, and K = 10 for CIFAR10 and SVHN and K = 100 for CIFAR100. During training, a five-layer Bayesian deconvolutional GAN is used as the generator to increase the performance of the † SVHN consists of 73,257 10-class images for training and 26,032 images for testing.   discriminator. After training, we discard the generator and use the discriminator for predictions. Since SGHMC is the standard baseline method to simulate from Bayesian GAN, we only compare reSGHMC with SGHMC and no longer report the results based on M-SGD. Following <ref type="bibr" target="#b38">Saatci and Wilson (2017)</ref>, we take 10 Monte Carlo (MC) samples for the generator and just 1 MC sample for the discriminator. We also simulate 2 samples from SGHMC or reSGHMC for each MC sample. Moreover, we only use 2 chains in the reSGHMC algorithm.</p><p>We study the model performance based on different number of labeled data N s in semi-supervised learning: N s = {2000, 2500, ..., 5000}. Similar to the experiments of supervised learning in Section 5.2, a large correction factor F tends to decrease the performance by injecting more biases, and a smaller correction factor F leads to smaller acceleration effects. Therefore, a good correction factor F is required to balance between the acceleration effects and accuracies. We choose batch-size 64 and detail the other hyper-parameter settings in the Appendix. We decay the learning rate while training, but no longer decrease the temperatures. We report each result using Bayesian model average and repeat each experiment five times to get the average and 2 standard deviations.</p><p>As shown in <ref type="figure" target="#fig_4">Fig.4</ref> and <ref type="table" target="#tab_2">Table.</ref>3, we observe that a larger number of labeled images leads to better performance for all the three datasets. In particular, the 3000 additional labeled images boost the prediction accuracies on CIFAR10, CIFAR100, and SVHN by 7%, 9%, and 3%, respectively. CIFAR10 and CIFAR100 are more sensitive to the labeled images and show larger marginal improvements given a smaller number of labeled images.</p><p>Compared to SGHMC, reSGHMC shows a significantly pronounced difference in performance. The consistent improvements are nearly 3% for CIFAR10, 5% for CIFAR100 and 2% for SVHN, respectively. From <ref type="table" target="#tab_0">Table.1 and Table.</ref>3, the large improvement in SSL indicates that the multi-modal problem is more severe in Bayesian GANs and the hightemperature chain facilitates the low-temperature chain to jump over distinct modes for the exploration of rich multimodal distributions. In the end, the low-temperature chain obtains both the exploration ability to traverse the whole domain and the exploitation ability to explore the local geometry, which greatly avoids the mode collapse problems and enables the state-of-the-art performance in SSL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Future Work</head><p>We propose the adaptive replica exchange SGMCMC algorithm and prove the accelerated convergence in terms of 2-Wasserstein distance. The theory implies an accuracyacceleration trade-off and guides us to tune the correction factor F to obtain the optimal performance. We support our theory with extensive experiments and obtain significant improvements over the vanilla SGMCMC algorithms on CIFAR10, CIFAR100, and SVHN.</p><p>For future works, it is promising to relax the asymptotic normality assumption to the heavy-tailed generalization of Lévy-stable distribution <ref type="bibr">(Ş imşekli et al., 2019)</ref> and apply Itô's lemma to geometric Lévy process to analyze the bias from fat-tailed noises with small batch sizes. Besides, variance reduction <ref type="bibr" target="#b45">(Xu et al., 2018)</ref> of the stochastic noise to obtain a larger acceleration effect is also appealing in both theory and practice. From the computational perspective, it is also interesting to study parallel multi-chain reSGMCMC in larger machine learning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplimentary Material for "Non-convex Learning via Replica Exchange Stochastic Gradient MCMC"</head><p>In this supplementary material, we prove the convergence in §A and show the experimental setup in §B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Convergence Analysis</head><p>A.1. Background</p><p>The continuous-time replica exchange Langevin diffusion (reLD) {β t } t≥0 := β</p><formula xml:id="formula_30">(1) t β (2) t t≥0</formula><p>is a Markov process compounded with a Poisson jump process. In particular, the Markov process follows the stochastic differential equations</p><formula xml:id="formula_31">dβ (1) t = −∇U (β (1) t )dt + √ 2τ 1 dW (1) t dβ (2) t = −∇U (β (2) t )dt + √ 2τ 2 dW (2) t ,<label>(16)</label></formula><p>where β</p><p>(1) t , β</p><p>(2) t are the particles (parameters) at time t in R d , W (1) , W (2) ∈ R d are two independent Brownian motions, U : R d → R is the energy function, τ 1 &lt; τ 2 are the temperatures. The jumps originate from the swaps of particles β (1) t and β</p><p>(2) t and follow a Poisson process where the jump rate is specified as the Metropolis form r(1 ∧ S(β (1) t , β</p><p>(2) t ))dt. Here r ≥ 0 is a constant, and S follows</p><formula xml:id="formula_32">S(β (1) t , β (2) t ) = e 1 τ 1 − 1 τ 2 U (β (1) t )−U (β (2) t ) .</formula><p>Under such a swapping rate, the probability ν t associated with reLD at time t is known to converge to the invariant measure (Gibbs distribution) with density</p><formula xml:id="formula_33">π(β (1) , β (2) ) ∝ e − U (β (1) ) τ 1 − U (β (2) ) τ 2 .</formula><p>In practice, obtaining the exact energy and gradient for reLD (16) in a large dataset is quite expensive. We consider the replica exchange stochastic gradient Langevin dynamics (reSGLD), which generates iterates { β η (k)} k≥1 as follows</p><formula xml:id="formula_34">β η(1) (k + 1) = β η(1) (k) − η∇ U ( β η(1) (k)) + 2ητ 1 ξ (1) k β η(2) (k + 1) = β η(2) (k) − η∇ U ( β η(2) (k)) + 2ητ 2 ξ (2) k ,<label>(17)</label></formula><p>where η is considered to be a fixed learning rate for ease of analysis, and ξ</p><p>(1) k and ξ</p><p>(2) k are independent Gaussian random vectors in R d . Moreover, the positions of the particles swap based on the stochastic swapping rate. In particular, S(β (1) , β (2) ) := S(β (1) , β (2) ) + ψ, and the stochastic gradient ∇ U (·) can be written as ∇U (·) + φ, where both ψ ∈ R 1 and φ ∈ R d are random variables with mean not necessarily zero. We also denote µ k as the probability measure associated with { β η (k)} k≥1 in reSGLD (17) at step k, which is close to ν kη in a suitable sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Overview of the analysis</head><p>We aim to study the convergence analysis of the probability measure µ k to the invariant measure π in terms of 2-Wasserstein distance,</p><formula xml:id="formula_35">W 2 (µ, ν) := inf Γ∈Couplings(µ,ν) β µ − β ν 2 dΓ(β µ , β ν ),<label>(18)</label></formula><p>where · is the Euclidean norm, and the infimum is taken over all joint distributions Γ(β µ , β ν ) with µ and ν being the marginals distributions.</p><p>By the triangle inequality, we easily obtain that for any k ∈ N and t = kη, we have</p><formula xml:id="formula_36">W 2 (µ k , π) ≤ W 2 (µ k , ν t ) Discretization error + W 2 (ν t , π) Exponential decay .</formula><p>We start with the discretization error first by analyzing how reSGLD (17) tracks the reLD (16) in 2-Wasserstein distance. The critical part is to study the discretization of the Poisson jump process in mini-batch settings. To handle this issue, we follow <ref type="bibr" target="#b19">Dupuis et al. (2012)</ref> and view the swaps of positions as swaps of temperatures. Then we apply standard techniques in stochastic calculus <ref type="bibr" target="#b14">(Chen et al., 2019;</ref><ref type="bibr" target="#b46">Yin and Zhu, 2010;</ref><ref type="bibr" target="#b39">Sato and Nakagawa, 2014;</ref><ref type="bibr" target="#b36">Raginsky et al., 2017)</ref> to discretize the Langevin diffusion and derive the corresponding discretization error.</p><p>Next, we quantify the evolution of the 2-Wasserstein distance between ν t and π. The key tool is the exponential decay of entropy (Kullback-Leibler divergence) when π satisfies the log-Sobolev inequality (LSI) <ref type="bibr" target="#b4">(Bakry et al., 2014)</ref>. To justify LSI, we first verify LSI for reSGLD without swaps, which is a direct result given a proper Lyapunov function criterion <ref type="bibr" target="#b10">(Cattiaux et al., 2010)</ref> and the Poincaré inequality <ref type="bibr" target="#b14">(Chen et al., 2019)</ref>. Then we follow <ref type="bibr" target="#b14">Chen et al. (2019)</ref> and verify LSI for reLD with swaps by analyzing the Dirichlet form. Finally, the exponential decay of the 2-Wasserstein distance follows from the Otto-Villani theorem by connecting the 2-Wasserstein distance with the entropy <ref type="bibr" target="#b4">(Bakry et al., 2014)</ref>.</p><p>Before we move forward, we first lay out the following assumptions: Assumption 1 (Smoothness). The energy function U (·) is C-smoothness, which implies that there exists a Lipschitz constant C &gt; 0, such that for every x, y ∈ R d , we have ∇U (x) − ∇U (y) ≤ C x − y . * Assumption 2 (Dissipativity). The energy function U (·) is (a, b)-dissipative, i.e. there exist constants a &gt; 0 and b ≥ 0</p><formula xml:id="formula_37">such that ∀x ∈ R d , x, ∇U (x) ≥ a x 2 − b.</formula><p>Here the smoothness assumption is quite standard in studying the convergence of SGLD, and the dissipativity condition is widely used in proving the geometric ergodicity of dynamic systems <ref type="bibr" target="#b36">(Raginsky et al., 2017;</ref><ref type="bibr" target="#b45">Xu et al., 2018)</ref>. Moreover, the convexity assumption is not required in our theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Analysis of discretization error</head><p>The key to deriving the discretization error is to view the swaps of positions as swaps of the temperatures, which has been proven equivalent in distribution <ref type="bibr" target="#b19">(Dupuis et al., 2012)</ref>. Therefore, we model reLD using the following SDE,</p><formula xml:id="formula_38">dβ t = −∇G(β t )dt + Σ t dW t ,<label>(19)</label></formula><p>where</p><formula xml:id="formula_39">G(β t ) = U (β (1) t ) U (β (1) t )</formula><p>, W ∈ R 2d is a Brownian motion, Σ t is a random matrix in continuous-time that swaps between the diagonal matrices M 1 =</p><formula xml:id="formula_40">√ 2τ 1 I d 0 0 √ 2τ 2 I d and M 2 = √ 2τ 2 I d 0 0 √ 2τ 1 I d with probability rS(β (1) t , β<label>(2)</label></formula><p>t )dt, and I d ∈ R d×d is denoted as the identity matrix.</p><p>Moreover, the corresponding discretization of replica exchange SGLD (reSGLD) follows:</p><formula xml:id="formula_41">β η (k + 1) = β η (k) − η∇ G( β η (k)) + √ η Σ η (k)ξ k ,<label>(20)</label></formula><p>where ξ k is a standard Gaussian distribution in R 2d , and Σ η (k) is a random matrix in discrete-time that swaps between M 1 and M 2 with probability r S( β η(1) (k), β η(2) (k))η. We denote { β η t } t≥0 as the continuous-time interpolation of { β η (k)} k≥1 , which satisfies the following SDE,</p><formula xml:id="formula_42">β η t = β 0 − t 0 ∇ G( β η s/η η )ds + t 0 Σ η s/η η dW s .<label>(21)</label></formula><p>Here the random matrix Σ η s/η η follows a similar trajectory as Σ η ( s/η ). For k ∈ N + with t = kη, the relation β η t = β η kη = β η (k) follows. Lemma 3 (Discretization error). Given the smoothness and dissipativity assumptions (1) and (2), and the learning rate η satisfying 0 &lt; η &lt; 1 ∧ a/C 2 , there exists constants D 1 , D 2 and D 3 such that</p><formula xml:id="formula_43">E[ sup 0≤t≤T β t − β η t || 2 ] ≤ D 1 η + D 2 max k E[ φ k 2 ] + D 3 max k E [|ψ k | 2 ],<label>(22)</label></formula><p>where D 1 depends on τ 1 , τ 2 , d, T, C, a, b; D 2 depends on T and C; D 3 depends on r, d, T and C.</p><p>* · denotes the Euclidean L 2 norm.</p><p>Proof Based on the replica exchange Langevin diffusion {β t } t≥0 and the continuous-time interpolation of the stochastic gradient Langevin diffusion { β η t } t≥0 , we have the following SDE for the difference β t − β η t . For any t ∈ [0, T ], we have</p><formula xml:id="formula_44">β t − β η t = − t 0 (∇G(β s ) − ∇ G( β η s/η η )ds + t 0 (Σ s − Σ η s/η η )dW s Indeed, note that sup 0≤t≤T β t − β η t ≤ T 0 ∇G(β s ) − ∇ G( β η s/η η ) )ds + sup 0≤t≤T t 0 (Σ s − Σ η s/η η )dW s</formula><p>We first square both sides and take expectation, then apply the Burkholder-Davis-Gundy inequality and Cauchy-Schwarz inequality, we have</p><formula xml:id="formula_45">E[ sup 0≤t≤T β t − β η t 2 ] ≤ 2E   T 0 ∇G(β s ) − ∇ G( β η s/η η ) ds 2 + sup 0≤t≤T t 0 (Σ s − Σ η s/η η )dW s 2   ≤ 2T E T 0 ∇G(β s ) − ∇ G( β η s/η η ) 2 ds I + 8E T 0 Σ s − Σ η s/η η 2 ds J<label>(23)</label></formula><p>Estimate of stochastic gradient: For the first term I, by using the inequality</p><formula xml:id="formula_46">a + b + c 2 ≤ 3( a 2 + b 2 + c 2 ),</formula><p>we get</p><formula xml:id="formula_47">I =2T E T 0 ∇G(β s ) − ∇G( β η s ) + ∇G( β η s ) − ∇G( β η s/η η ) + ∇G( β η s/η η ) − ∇ G( β η s/η η ) 2 ds ≤ 6T E T 0 ∇G(β s ) − ∇G( β η s ) 2 ds I1 + 6T E T 0 ∇G( β η s ) − ∇G( β η s/η η ) 2 ds I2 + 6T E T 0 ∇G( β η s/η η ) − ∇ G( β η s/η η ) 2 ds I3 ≤I 1 + I 2 + I 3 .<label>(24)</label></formula><p>By using the smoothness assumption 1, we first estimate</p><formula xml:id="formula_48">I 1 ≤ 6T C 2 E T 0 β s − β η s 2 ds .</formula><p>By applying the smoothness assumption 1 and discretization scheme, we can further estimate</p><formula xml:id="formula_49">I 2 ≤ 6T C 2 E T 0 β η s − β η s/η η 2 ds ≤ 6T C 2 T /η k=0 E (k+1)η kη β η s − β η s/η η 2 ds ≤ 6T C 2 T /η k=0 (k+1)η kη E sup kη≤s&lt;(k+1)η β η s − β η s/η η 2 ds<label>(25)</label></formula><p>For ∀ k ∈ N and s ∈ [kη, (k + 1)η), we have</p><formula xml:id="formula_50">β η s − β η s/η η = β η s − β η kη = −∇ G( β η kη ) · (s − kη) + Σ η kη s kη dW r which indeed implies sup kη≤s&lt;(k+1)η β η s − β η s/η η ≤ ∇ G( β η kη ) (s − kη) + sup kη≤s&lt;(k+1)η Σ η kη s kη dW r</formula><p>Similar to the estimate (23), square both sides and take expectation, then apply the Burkholder-Davis-Gundy inequality, we have</p><formula xml:id="formula_51">E sup kη≤s&lt;(k+1)η β η s − β η s/η η 2 ≤ 2E[ ∇ G( β η kη ) 2 (s − kη) 2 ] + 8 2d j=1 E Σ η kη (j) · kη dW r 1/2 s 2 ≤ 2(s − kη) 2 E[ ∇ G( β η kη ) 2 ] + 32dτ 2 (s − kη),</formula><p>where the last inequality follows from the fact that Σ η kη is a diagonal matrix with diagonal elements √ 2τ 1 or √ 2τ 2 . For the first term in the above inequality, we further have</p><formula xml:id="formula_52">2(s − kη) 2 E[ ∇ G( β η kη ) 2 ] = 2(s − kη) 2 E[ (∇G( β η kη ) + φ k ) 2 ] ≤ 4η 2 E[ ∇G( β η kη ) − ∇G(β * ) 2 + φ k 2 ] ≤ 8C 2 η 2 E[ β η kη 2 + β * 2 ] + 4η 2 E[ φ k 2 ],</formula><p>where the first inequality follows from the separation of the noise from the stochastic gradient and the choice of stationary point β * of G(·) with ∇G(β * ) = 0, and φ k is the stochastic noise in the gradient at step k. Thus, combining the above two parts and integrate E sup kη≤s&lt;(k+1)η β η s − β η kη 2 on the time interval [kη, (k + 1)η), we obtain the following bound</p><formula xml:id="formula_53">(k+1)η kη E sup kη≤s&lt;(k+1)η β η s − β η kη 2 ds ≤ 8C 2 η 3 sup k≥0 E[ β η kη 2 + β * 2 ] + 4η 3 max k E[ φ k 2 ] + 32dτ 2 η 2<label>(26)</label></formula><p>By plugging the estimate (26) into estimate <ref type="formula" target="#formula_5">(25)</ref>, we obtain the following estimates when η ≤ 1,</p><formula xml:id="formula_54">I 2 ≤ 6T C 2 (1 + T /η) 8C 2 η 3 sup k≥0 E[ β η kη 2 + β * 2 ] + 4η 3 max k E[ φ k 2 ] + 32dτ 2 η 2 ≤δ 1 (d, τ 2 , T, C, a, b)η + 24T C 2 (1 + T ) max k E[ φ k 2 ],<label>(27)</label></formula><p>whereδ 1 (d, τ 2 , T, C, a, b) is a constant depending on d, τ 2 , T, C, a and b. Note that the above inequality requires a result on the bounded second moment of sup k≥0 E[ β η kη 2 ], and this is majorly † proved in Lemma C.2 in <ref type="bibr" target="#b14">Chen et al. (2019)</ref> when we choose the stepzise η ∈ (0, a/C 2 ). We are now left to estimate the term I 3 and we have</p><formula xml:id="formula_55">I 3 ≤ 6T T /η k=0 E (k+1)η kη ∇G( β η kη ) − ∇ G( β η kη ) 2 ds ≤ 6T (1 + T /η) max k E[ φ k 2 ]η ≤ 6T (1 + T ) max k E[ φ k 2 ].</formula><p>(28) † The slight difference is that the constant in the RHS of (C.38) <ref type="bibr" target="#b14">Chen et al. (2019)</ref> is changed to account for the stochastic noise.</p><p>Combing all the estimates of I 1 , I 2 and I 3 , we obtain</p><formula xml:id="formula_56">I ≤ 6T C 2 T 0 E sup 0≤s≤T β s − β η s 2 ds I1 +δ 1 (d, τ 2 , T, C, a, b)η + 24T C 2 (1 + T ) max k E[ φ k 2 ] I2 + 6T (1 + T ) max k E[ φ k 2 ] I3 .<label>(29)</label></formula><p>Estimate of stochastic diffusion: For the second term J , we have</p><formula xml:id="formula_57">J = 8E T 0 Σ s (j) − Σ s/η η (j) 2 ds ≤ 8 2d j=1 T /η k=0 (k+1)η kη E Σ s (j) − Σ η kη (j) 2 ds ≤ 8 2d j=1 T /η k=0 (k+1)η kη E Σ s (j) − Σ η kη (j) + Σ η kη (j) − Σ η kη (j) 2 ds ≤ 16 2d j=1 T /η k=0      (k+1)η kη E Σ s (j) − Σ η kη (j) 2 ds J1 + (k+1)η kη E Σ η kη (j) − Σ η kη (j) 2 ds J2      .<label>(30)</label></formula><p>where Σ η kη is the temperature matrix for the continuous-time interpolation of {β η (k)} k≥1 , which is similar to (21) without noise generated from mini-batch settings and is defined as below</p><formula xml:id="formula_58">β η t = β 0 − t 0 ∇G(β η kη )ds + t 0 Σ η kη dW s .<label>(31)</label></formula><p>We estimate J 1 first, considering that Σ s and Σ η s/η η are both diagonal matrices, we have</p><formula xml:id="formula_59">J 1 = 4( √ τ 2 − √ τ 1 ) 2 (k+1)η kη P(Σ s (j) = Σ η kη (j))ds = 4( √ τ 2 − √ τ 1 ) 2 E (k+1)η kη P(Σ s (j) = Σ η kη (j)|β η kη )ds = 4( √ τ 2 − √ τ 1 ) 2 r (k+1)η kη [(s − kη) + R(s − kη)]ds ≤δ 2 (r, τ 1 , τ 2 )η 2 ,</formula><p>whereδ 2 (r, τ 1 , τ 2 ) = 4( √ τ 2 − √ τ 1 ) 2 r, and the equality follows from the fact that the conditional probability P(Σ s (j) =</p><formula xml:id="formula_60">Σ η kη (j)|β η kη ) = rS(β η(1) kη , β η(2) kη ) · (s − η) + rR(s − kη).</formula><p>Here R(s − kη) denotes the higher remainder with respect to s − kη. The estimate of J 1 without stochastic gradient for the Langevin diffusion is first obtained in <ref type="bibr" target="#b14">Chen et al. (2019)</ref>, we however present here again for reader's convenience. As for the second term J 2 , it follows that</p><formula xml:id="formula_61">J 2 = 4( √ τ 2 − √ τ 1 ) 2 (k+1)η kη P(Σ kη (j) = Σ kη (j))ds = 4( √ τ 2 − √ τ 1 ) 2 rηE S(β η(1) kη , β η(2) kη ) −S( β η(1) kη , β η(2) kη ) ≤δ 2 (r, τ 1 , τ 2 )η E S(β η(1) kη , β η(2) kη ) −S( β η(1) kη , β η(2) kη ) 2 ≤δ 2 (r, τ 1 , τ 2 )η E [|ψ k | 2 ],<label>(32)</label></formula><p>where ψ k is the noise in the swapping rate. Thus, one concludes the following estimates combing I and J .</p><formula xml:id="formula_62">E[ sup 0≤t≤T β t − β η t || 2 ] ≤ 6T C 2 T 0 E sup 0≤s≤T β s − β η s 2 ds I1 +δ 1 (d, τ 2 , T, C, a, b)η + 24T C 2 (η + T ) max k E[ φ k 2 ] I2 + 6T (1 + T )E[ φ k 2 ] I3 + 32d(1 + T )δ 2 (r, τ 1 , τ 2 ) η + max k E [|ψ k | 2 ] J .<label>(33)</label></formula><p>Apply Gronwall's inequality to the function</p><formula xml:id="formula_63">t → E sup 0≤u≤t β u − β η u 2 ,</formula><p>and deduce that</p><formula xml:id="formula_64">E[ sup 0≤t≤T β t − β η t || 2 ] ≤ D 1 η + D 2 max k E[ φ k 2 ] + D 3 max k E [|ψ k | 2 ],<label>(34)</label></formula><p>where D 1 is a constant depending on τ 1 , τ 2 , d, T, C, a, b; D 2 depends on T and C; D 3 depends on r, d, T and C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Exponential decay of Wasserstein distance in continuous-time</head><p>We proceed to quantify the evolution of the 2-Wasserstein distance between ν t and π. We first consider the ordinary Langevin diffusion without swaps and derive the log-Sobolev inequality (LSI). Then we extend LSI to reLD and obtain the exponential decay of the relative entropy. Finally, we derive the exponential decay of the 2-Wasserstein distance.</p><p>In order to distinguish from the replica exchange Langevin diffusion β t defined in <ref type="formula" target="#formula_0">(19)</ref>, we call itβ t which follows,</p><formula xml:id="formula_65">dβ t = −∇G(β t )dt + Σ t dW t .<label>(35)</label></formula><p>where Σ t ∈ R 2d×2d is a diagonal matrix with the form</p><formula xml:id="formula_66">√ 2τ 1 I d 0 0 √ 2τ 2 I d .</formula><p>The processβ t is a Markov diffusion process with infinitesimal generator L in the following form, for x 1 ∈ R d and x 2 ∈ R d ,</p><formula xml:id="formula_67">L = − ∇ x1 f (x 1 , x 2 ), ∇U (x 1 ) + τ 1 ∆ x1 f (x 1 , x 2 ) − ∇ x2 f (x 1 , x 2 ), ∇U (x 2 ) + τ 2 ∆ x2 f (x 1 , x 2 )</formula><p>Note that since matrix Σ t is a non-degenerate diagonal matrix, operator L is an elliptic diffusion operator. According to the smoothness assumption (1), we have that ∇ 2 G ≥ −CI 2d , where C &gt; 0, the unique invariant measure π associate with the underlying diffusion process satisfies the Poincare inequality and LSI with the Dirichlet form given as follows,</p><formula xml:id="formula_68">E(f ) = τ 1 ∇ x1 f 2 + τ 2 ∇ x2 f 2 dπ(x 1 , x 2 ), f ∈ C 2 0 (R 2d ).<label>(36)</label></formula><p>In this elliptic case with G being convex, the proof for LSI follows from standard Bakry-Emery calculus <ref type="bibr">(Bakry andémery, 1985)</ref>. Since, we are dealing with the non-convex function G, we are particularly interested in the case of ∇ 2 G ≥ −CI 2d . To obtain a Poincaré inequality for invariant measure π, <ref type="bibr" target="#b14">Chen et al. (2019)</ref> adapted an argument from <ref type="bibr" target="#b3">Bakry et al. (2008)</ref> and <ref type="bibr" target="#b36">Raginsky et al. (2017)</ref> by constructing an appropriate Lyapunov function for the replica exchange diffusion without swappingβ t . Denote ν t as the distribution associated with the diffusion process {β t } t≥0 , which is absolutely continuous with respect to π. It is a direct consequence of the aforementioned results that the following log-Sobolev inequality holds. Lemma 4 (LSI for Langevin Diffusion). Under assumptions (1) and (2), we have the following log-Sobolev inequality for invariant measure π, for some constant c LS &gt; 0,</p><formula xml:id="formula_69">D(ν t ||π) ≤ 2c LS E( dν t dπ ).</formula><p>where D(ν t ||π) = dν t log dνt dπ denotes the relative entropy and the Dirichlet form E(·) is defined in (36).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Proof</head><p>According to <ref type="bibr" target="#b10">Cattiaux et al. (2010)</ref>, the sufficient conditions to establish LSI are:</p><p>1. There exists some constant C ≥ 0, such that ∇ 2 G −CI 2d .</p><p>2. π satisfies a Poincaré inequality with constant c p , namely, for all probability measures ν π, χ 2 (ν||π) ≤ c p E( dνt dπ ), where χ 2 (ν||π) := dν dπ − 1 2 is the χ 2 divergence between ν and π.</p><p>3. There exists a C 2 Lyapunov function V :</p><formula xml:id="formula_70">R 2d → [1, ∞) such that LV (x1,x2) V (x1,x2) ≤ κ − γ( x 1 2 + x 2 2 ) for all (x 1 , x 2 ) ∈ R 2d and some κ, γ &gt; 0.</formula><p>Note that the first condition on the Hessian is obtained from the smoothness assumption (1). Moreover, the Poincaré inequality in the second condition is derived from Lemma C.1 in <ref type="bibr" target="#b14">Chen et al. (2019)</ref> given assumptions <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula" target="#formula_40">(2)</ref>. Finally, to verify the third condition, we follow <ref type="bibr" target="#b36">Raginsky et al. (2017)</ref> and construct the Lyapunov function V (x 1 , x 2 ) := exp a/4 · x1 2 τ1 + x2 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>τ2</head><p>. From the dissipitive assumption 2, V (x 1 , x 2 ) satisfies the third condition because</p><formula xml:id="formula_71">L(V (x 1 , x 2 )) = a 2τ 1 + a 2τ 2 + a 2 4τ 2 1 x 1 2 + a 2 4τ 2 2 x 2 2 − a 2τ 2 1 x 1 , ∇G(x 1 ) − a 2τ 2 2 x 1 , ∇G(x 2 ) V (x 1 , x 2 ) ≤ a 2τ 1 + a 2τ 2 + ab 2τ 2 1 + ab 2τ 2 2 − a 2 4τ 2 1 x 1 2 − a 2 4τ 2 2 x 2 2 V (x 1 , x 2 ) ≤ κ − γ( x 1 2 + x 2 2 ) V (x 1 , x 2 ),<label>(37)</label></formula><p>where κ = a 2τ1 + a 2τ2 + ab . Therefore, the invariant measure π satisfies a LSI with the constant</p><formula xml:id="formula_72">c LS = c 1 + (c 2 + 2)c p ,<label>(38)</label></formula><p>where</p><formula xml:id="formula_73">c 1 = 2C γ + 2 C and c 2 = 2C γ κ + γ R 2d ( x 1 2 + x 2 2 )π(dx 1 dx 2 ) .</formula><p>We are now ready to prove the log-Sobolev inequality for invariant measure associated with the replica exchange Langevin diffusion <ref type="bibr">(19)</ref>. We use a similar idea from <ref type="bibr" target="#b14">Chen et al. (2019)</ref> where they prove the Poincaré inequality for the invariant measure associated with the replica exchange Langevin diffusion (19) by analyzing the corresponding Dirichlet form. In particular, a larger Dirichlet form ensures a smaller log-Sobolev constant and hence results in a faster convergence in the relative entropy and Wasserstein distance.</p><p>Lemma 5 (Accelerated exponential decay of W 2 ). Under assumptions <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula" target="#formula_40">(2)</ref>, we have that the replica exchange Langevin diffusion converges exponentially fast to the invariant distribution π:</p><formula xml:id="formula_74">W 2 (ν t , π) ≤ D 0 e −kη(1+δ S )/cLS ,<label>(39)</label></formula><formula xml:id="formula_75">where D 0 = 2c LS D(ν 0 ||π), δ S := inf t&gt;0 E S ( dν t dπ ) E( dν t dπ )</formula><p>− 1 is a non-negative constant depending on the swapping rate S(·, ·) and obtains 0 only if S(·, ·) = 0.</p><p>Proof Consider the infinitesimal generator associated with the diffusion process (19), denoted as L S , contains an extra term arising from the temperature swapping. The operator L S in this particular case, indeed, has the following form L S = L + rS(x 1 , x 2 ) · (f (x 2 , x 1 ) − f (x 1 , x 2 )).</p><p>According to Theorem 3.3 <ref type="bibr" target="#b14">(Chen et al., 2019)</ref>, the Dirichlet form associated with operator L S under the invariant measure π has the form E S (f ) = E(f ) + r 2 S(x 1 , x 2 ) · (f (x 2 , x 1 ) − f (x 1 , x 2 )) 2 dπ(x 1 , x 2 ) acceleration , f ∈ C 2 0 (R 2d ),</p><p>where f corresponds to dνt dπ(x1,x2) , and the asymmetry of νt π(x1,x2) is critical in the acceleration effect <ref type="bibr" target="#b14">(Chen et al., 2019)</ref>. Given two different temperatures τ 1 and τ 2 , a non-trivial distribution π and function f , the swapping rate S(x 1 , x 2 ) is positive for almost any x 1 , x 2 ∈ R d . As a result, the Dirichlet form associated with L S is strictly larger than L. Therefore, there exists a constant δ S &gt; 0 depending on S(x 1 , x 2 ), such that δ S = inf t&gt;0</p><formula xml:id="formula_78">E S ( dν t dπ ) E( dν t dπ ) − 1. From Lemma 4, we have D(ν t ||π) ≤ 2c LS E( dν t dπ ) ≤ 2c LS sup t E( dνt dπ ) E S ( dνt dπ ) E S ( dν t dπ ) = 2 c LS 1 + δ S E S ( dν t dπ ).<label>(42)</label></formula><p>Thus, we obtain the following log-Sobolev inequality for the unique invariant measure π associated with replica exchange Langevin diffusion {β t } t≥0 and its corresponding Dirichlet form E S (·). In particular, the LSI constant cLS 1+δ S in replica exchange Langevin diffusion with swapping rate S(·, ·) &gt; 0 is strictly smaller than the LSI constant c LS in the replica exchange Langevin diffusion with swapping rate S(·, ·) = 0. By the exponential decay in entropy <ref type="bibr" target="#b4">(Bakry et al., 2014)</ref>[Theorem 5.2.1] and the tight log-Sobolev inequality in Lemma 4, we get that, for any t ∈ [kη, (k + 1)η), D(ν t ||π) ≤ D(ν 0 ||π)e −2t(1+δ S )/cLS ≤ D(µ 0 ||π)e −2kη(1+δ S )/cLS .</p><p>Finally, we can estimate the term W 2 (ν t , π) by the Otto-Villani theorem <ref type="bibr" target="#b4">(Bakry et al., 2014)</ref>[Theorem 9.6.1], W 2 (ν t , π) ≤ 2c LS D(ν t ||π) ≤ 2c LS D(µ 0 ||π)e −kη(1+δ S )/cLS .</p><p>A.5. Summary: Convergence of reSGLD</p><p>Now that we have all the necessary ingredients in place, we are ready to derive the convergence of the distribution µ k to the invariant measure π in terms of 2-Wasserstein distance,</p><p>Theorem 2 (Convergence of reSGLD). Let the assumptions <ref type="formula" target="#formula_0">(1)</ref> and <ref type="formula" target="#formula_40">(2)</ref> hold. For the unique invariant measure π associated with the Markov diffusion process (19) and the distribution {µ k } k≥0 associated with the discrete dynamics { β η (k)} k≥1 , we have the following estimates, for 0 ≤ k ∈ N + and the learning rate η satisfying 0 &lt; η &lt; 1 ∧ a/C 2 , − 1 is a non-negative constant depending on the swapping rate S(·, ·) and obtains the minimum zero only if S(·, ·) = 0.</p><p>Proof We reduce the estimates into the following two terms by using the triangle inequality, W 2 (µ k , π) ≤ W 2 (µ k , ν t ) + W 2 (ν t , π), t ∈ [kη, (k + 1)η).</p><p>The first term W 2 (µ k , ν t ) follows from the analysis of discretization error in Lemma.3. Recall the very definition of the W 2 (·, ·) distance defined in (18). Thus, in order to control the distance W 2 (µ k , ν t ), t ∈ [kη, (k + 1)η), we need to consider the diffusion process whose law give µ k and ν t , respectively. Indeed, it is obvious that ν t = L(β t ) for t ∈ [kη, (k + 1)η).</p><p>For the other measure µ k , it follows that µ k =ν kη for t = kη, whereν kη = L( β η t ) is the probability measure associated with the continuous interpolation of reSGLD (20). By Lemma.3, we have that for k ∈ N and t ∈ [kη, (k + 1)η),</p><formula xml:id="formula_82">W 2 (µ k , ν t ) = W 2 (ν kη , ν t ) ≤ E[ sup 0≤s≤t β s − β η s 2 ] ≤ δ 1 η + δ 2 max k E[ φ k 2 ] + δ 3 max k E [|ψ k | 2 ],<label>(47)</label></formula><p>Recall from the accelerated exponential decay of replica exchange Langevin diffusion in Lemma.5, we have W 2 (ν t , π) ≤ 2c LS D(ν 0 ||π)e −kη(1+δ S )/cLS = 2c LS D(µ 0 ||π)e −kη(1+δ S )/cLS .</p><p>Combing the above two estimates completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Hyper-parameter Setting for Bayesian GANs</head><p>In the semi-supervised learning tasks, we fine-tune the hyper-parameters for Bayesian GANs and report them in <ref type="table" target="#tab_4">Table  4</ref>. In particular, N s is the number of labeled data; η (1) and η (2) are the learning rates for the low-temperature chain and high-temperature chain, respectively; τ 1 and τ 2 are the temperatures;F is the correction factor, which often yields several swaps. In addition, the learning rates also follow a truncated exponential decay, for example, η </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Paths of reLD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Effects of correction factors on CIFAR100 Figure 3. Time-varying variances of the stochastic energy based on batch-size 256 on CIFAR10 &amp; CIFAR100 datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>reSGHMC versus SGHMC on benchmark datasets in semi-supervised learning.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>W 2</head><label>2</label><figDesc>(µ k , π) ≤ D 0 e −kη(1+δ S )/cLS + δ 1 η + δ 2 max k E[ φ k 2 ] + δ 3 max k E [|ψ k | 2 ](45)where D 0 = 2c LS D(µ 0 ||π), δ S := min k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>PREDICTION ACCURACIES (%) WITH DIFFERENT ARCHITECTURES ON CIFAR10 AND CIFAR100. 21±0.16 94.22±0.12 94.62±0.18 72.45±0.20 72.49±0.18 74.14±0.22 RESNET-32 95.15±0.08 95.18±0.06 95.35±0.08 75.01±0.22 75.14±0.28 76.55±0.30 RESNET-56 96.01±0.08 95.95±0.10 96.12±0.06 78.96±0.32 79.04±0.30 80.14±0.34 WRN-16-8 96.71±0.06 96.73±0.08 96.87±0.06 81.70±0.26 82.07±0.22 82.95±0.30 WRN-28-10 97.33±0.08 97.32±0.06 97.42±0.06 83.79±0.18 83.76±0.14 84.38±0.18</figDesc><table><row><cell>MODEL</cell><cell>M-SGD</cell><cell>CIFAR10 SGHMC</cell><cell>RESGHMC</cell><cell>M-SGD</cell><cell>CIFAR100 SGHMC</cell><cell>RESGHMC</cell></row><row><cell cols="2">RESNET-20 94.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>PREDICTION ACCURACIES (%) WITH DIFFERENT BATCH SIZES ON CIFAR10 &amp; CIFAR100 USING RESNET-20.</figDesc><table><row><cell>BATCH</cell><cell>M-SGD</cell><cell>SGHMC</cell><cell>RESGHMC</cell></row><row><cell></cell><cell></cell><cell>CIFAR10</cell><cell></cell></row><row><cell>256</cell><cell cols="3">94.21±0.16 94.22±0.12 94.62±0.18</cell></row><row><cell>1024</cell><cell cols="3">94.49±0.12 94.57±0.14 95.01±0.16</cell></row><row><cell></cell><cell></cell><cell>CIFAR100</cell><cell></cell></row><row><cell>256</cell><cell cols="3">72.45±0.20 72.49±0.18 74.14±0.21</cell></row><row><cell>1024</cell><cell cols="3">73.31±0.18 73.23±0.20 75.11±0.26</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table .</head><label>.</label><figDesc></figDesc><table><row><cell>1, we see that reSGHMC consistently outperforms</cell></row><row><cell>SGHMC and M-SGD on both datasets, showing the ro-</cell></row><row><cell>bustness of reSGHMC to various model architectures. For</cell></row><row><cell>CIFAR10, our method works better with ResNet-20 and</cell></row><row><cell>ResNet-32 and improves the prediction accuracy by 0.4%</cell></row><row><cell>and 0.2%, respectively. Regarding the other model ar-</cell></row></table><note>chitectures, it still slightly outperforms the baselines by roughly 0.1%-0.2%, although this dataset is highly opti- mized. Specifically, reSGHMC achieves the state-of-the-art 97.42% accuracy with WRN-28-10 model. For CIFAR100, reSGHMC works particularly well based on various model architectures. It outperforms the baseline by as high as 1.5% using ResNet-20 and ResNet-32, and around 1% based on the other architectures. It also achieves the state-of-the-art 84.38% based on WRN-28-10 on CIFAR100.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>SEMI-SUPERVISED LEARNING ON CIFAR10, CIFAR100 AND SVHN BASED ON DIFFERENT NUMBER OF LABELS. 72±0.39 77.73±0.31 50.76±0.71 55.53± 0.64 88.75±0.44 91.59±0.38 3000 77.96±0.32 80.85±0.23 53.07±0.71 57.09± 0.77 91.32±0.41 94.03±0.36 4000 79.06±0.29 81.61±0.24 57.05±0.59 62.23± 0.69 91.92±0.41 94.25±0.31 5000 81.74±0.36 84.67±0.28 59.34±0.64 64.83± 0.72 92.63±0.46 94.33±0.34</figDesc><table><row><cell>N s</cell><cell>CIFAR10 SGHMC RESGHMC</cell><cell>CIFAR100 SGHMC RESGHMC</cell><cell>SVHN SGHMC RESGHMC</cell></row><row><cell cols="2">2000 74.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>, where k is the number of iterations. Hyper-parameter setting of Bayesian GANs for Semi-Supervised Learning experiments.</figDesc><table><row><cell>) k = 0.05 ∨ e − k 800</cell><cell>η (1)</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank the reviewers for their suggestions. We acknowledge the support from the Bilsland Dissertation Fellowship (Deng), the National Science Foundation DMS-1555072, DMS-1736364, DMS-1821233 (Lin) and DMS-1818674  (Liang)  and the GPU grant program from NVIDIA.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Pseudo-Marginal Approach for Efficient Monte Carlo Computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Andrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="697" to="725" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Applebaum</surname></persName>
		</author>
		<title level="m">Lévy Processes and Stochastic Calculus</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Diffusions Hypercontractives. Séminaire de Probabilités XIX</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominique</forename><surname>Bakry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Michelémery</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page" from="177" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A Simple Proof of the Poincaré Inequality for A Large Class of Probability Measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominique</forename><surname>Bakry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Cattiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Barthe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Guillin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Electron. Comm. Probab</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="60" to="66" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Analysis and Geometry of Markov Diffusion Operators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominique</forename><surname>Bakry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Gentil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Ledoux</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">On Markov Chain Monte Carlo Methods for Tall Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rémi</forename><surname>Bardenet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Doucet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Holmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="1" to="43" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Mimicking the Marginal Distributions of a Semimartingale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amel</forename><surname>Bentata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rama</forename><surname>Cont</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0910.3992v5</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exact and Computationally Efficient Likelihood-Based Estimation for Discretely Observed Diffusion Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Beskos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omiros</forename><surname>Papaspiliopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fearnhead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="333" to="382" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Bosonic Lattice Gauge Theory with Noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><forename type="middle">D</forename><surname>Bhanot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kennedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics Letters B</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="page" from="70" to="76" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The Effects of Parameter Misspecification and Non-stationary on The Applicability of Adaptive Forecasts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Bossons</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="659" to="669" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A Note on Talagrand&apos;s Transportation Inequality and Logarithmic Sobolev Inequality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Cattiaux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnaud</forename><surname>Guillin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Ming</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Prob. Theory and Rel. Fields</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page" from="285" to="334" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The Penalty Method for Random Walks with Uncertain Energies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ceperley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Dewing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Chemical Physics</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="9812" to="9820" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the Convergence of Stochastic Gradient MCMC Algorithms with High-order Integrators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changyou</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2278" to="2286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Stochastic Gradient Hamiltonian Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">B</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Machine Learning (ICML)</title>
		<meeting>of the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Accelerating Nonconvex Learning via Replica Exchange Langevin Diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinglin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaoran</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Learning Representation (ICLR)</title>
		<meeting>of the International Conference on Learning Representation (ICLR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Stochastic Quasi-Newton Langevin Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Umut Ş Imşekli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Taylan</forename><surname>Badeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gaë</forename><surname>Cemgil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Richard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Machine Learning (ICML)</title>
		<meeting>of the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="642" to="651" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Tail-Index Analysis of Stochastic Gradient Noise in Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Umut Ş Imşekli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mert</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gürbüzbalaban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Machine Learning (ICML)</title>
		<meeting>of the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">An Adaptive Empirical Bayesian Method for Sparse Deep Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faming</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bayesian Sampling Using Stochastic Gradient Thermostats</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youhan</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Babbush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changyou</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">D</forename><surname>Skeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartmut</forename><surname>Neven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3203" to="3211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On the Infinite Swapping Limit for Parallel Tempering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Dupuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuria</forename><surname>Plattner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Doll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Multiscale Modeling &amp; Simulation</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Parallel Tempering: Theory, Applications, and New Perspectives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Earl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">W</forename><surname>Deem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Chem. Chem. Phys</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="3910" to="3916" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Understanding Exponential Smoothing via Kernel Regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irène</forename><surname>Gijbels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alun</forename><surname>Pope</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><forename type="middle">P</forename><surname>Wand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society, Series B</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="39" to="50" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mimicking the One-dimensional Marginal Distributions of Processes Having an Ito Differential</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gyöngy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Probability Theory and Related Fields</title>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="501" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Optimization by Simulated Annealing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Kirkpatrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gelatt</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><forename type="middle">P</forename><surname>Vecchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">220</biblScope>
			<biblScope unit="issue">4598</biblScope>
			<biblScope unit="page" from="671" to="680" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Austerity in MCMC Land: Cutting the Metropolis-Hastings Budget</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anoop</forename><surname>Korattikara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Machine Learning (ICML)</title>
		<meeting>of the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Beyond Log-concavity: Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holden</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Risteski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Preconditioned Stochastic Gradient Langevin Dynamics for Deep Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changyou</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Carlson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Carin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the National Conference on Artificial Intelligence (AAAI)</title>
		<meeting>of the National Conference on Artificial Intelligence (AAAI)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1788" to="1794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Stochastic Runge-Kutta Accelerates Langevin Monte Carlo and Beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuechen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lester</forename><surname>Mackey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murat</forename><forename type="middle">A</forename><surname>Erdogdu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7746" to="7758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hybrid Parallel Tempering and Simulated Annealing Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaohang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><forename type="middle">A</forename><surname>Protopopescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikita</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Gorin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">212</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="216" to="228" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stochastic Approximation in Monte Carlo Computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faming</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanhai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><forename type="middle">J</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page" from="305" to="320" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">A Complete Recipe for Stochastic Gradient MCMC</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-An</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><forename type="middle">B</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Convex Optimization with Unbounded Nonconvex Oracles using Simulated Annealing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Mangoubi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nisheeth</forename><forename type="middle">K</forename><surname>Vishnoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conference on Learning Theory (COLT)</title>
		<meeting>of Conference on Learning Theory (COLT)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Simulated Tempering: A New Monte Carlo Scheme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Marinari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Parisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Europhysics Letters (EPL)</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="451" to="458" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Orthogonal Parallel MCMC Methods for Sampling and Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Elvira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luengo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Corander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Louzada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Signal Processing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="64" to="84" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><forename type="middle">K</forename><surname>Nicholls</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><forename type="middle">Muir</forename><surname>Watt</surname></persName>
		</author>
		<title level="m">Coupled MCMC with a Randomized Acceptance Probability. ArXiv e-prints</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Speeding Up MCMC by Efficient Data Subsampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matias</forename><surname>Quiroz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mattias</forename><surname>Villani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Ngoc</forename><surname>Tran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="831" to="843" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Non-convex Learning via Stochastic Gradient Langevin Dynamics: a Nonasymptotic Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Raginsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Rakhlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matus</forename><surname>Telgarsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conference on Learning Theory (COLT)</title>
		<meeting>of Conference on Learning Theory (COLT)</meeting>
		<imprint>
			<date type="published" when="2017-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A Stochastic Approximation Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sutton</forename><surname>Monro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="407" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunus</forename><surname>Saatci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew G Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gan</forename><surname>Bayesian</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3622" to="3631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Approximation Analysis of Stochastic Gradient Langevin Dynamics by using Fokker-Planck Equation and Itô Process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Issei</forename><surname>Sato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Nakagawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Machine Learning (ICML)</title>
		<meeting>of the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="982" to="990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">An Efficient Minibatch Acceptance Test for Metropolis-Hastings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Seita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Canny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>of the Conference on Uncertainty in Artificial Intelligence (UAI)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Replica Monte Carlo Simulation of Spin-Glasses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian-Sheng</forename><surname>Swendsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys. Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="2607" to="2609" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Consistency and Fluctuations for Stochastic Gradient Langevin Dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Thiéry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Vollmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1" to="33" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Bayesian Learning via Stochastic Gradient Langevin Dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee Whye</forename><surname>Teh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the International Conference on Machine Learning (ICML)</title>
		<meeting>of the International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="681" to="688" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Dynamic Weighting in Monte Carlo and Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hung</forename><surname>Wing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faming</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci</title>
		<meeting>Natl. Acad. Sci</meeting>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="14220" to="14224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinghui</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Difan</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanquan</forename><surname>Gu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Hybrid Switching Diffusions: Properties and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A Hitting Time Analysis of Stochastic Gradient Langevin Dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moses</forename><surname>Charikar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Conference on Learning Theory (COLT)</title>
		<meeting>of Conference on Learning Theory (COLT)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1980" to="2022" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
