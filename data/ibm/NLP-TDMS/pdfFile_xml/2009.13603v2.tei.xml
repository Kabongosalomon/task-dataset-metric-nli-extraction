<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Visual Pivoting for (Unsupervised) Entity Alignment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyu</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Language Technology Lab</orgName>
								<orgName type="institution" key="instit1">TAL</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhao</forename><surname>Chen</surname></persName>
							<email>muhaoche@usc.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Viterbi School of Engineering</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
							<email>danroth@seas.upenn.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer and Information Science</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Collier</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Language Technology Lab</orgName>
								<orgName type="institution" key="instit1">TAL</orgName>
								<orgName type="institution" key="instit2">University of Cambridge</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Visual Pivoting for (Unsupervised) Entity Alignment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T11:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This work studies the use of visual semantic representations to align entities in heterogeneous knowledge graphs (KGs). Images are natural components of many existing KGs. By combining visual knowledge with other auxiliary information, we show that the proposed new approach, EVA , creates a holistic entity representation that provides strong signals for cross-graph entity alignment. Besides, previous entity alignment methods require human labelled seed alignment, restricting availability. EVA provides a completely unsupervised solution by leveraging the visual similarity of entities to create an initial seed dictionary (visual pivots). Experiments on benchmark data sets DBP15k and DWY15k show that EVA offers state-of-the-art performance on both monolingual and cross-lingual entity alignment tasks. Furthermore, we discover that images are particularly useful to align long-tail KG entities, which inherently lack the structural contexts that are necessary for capturing the correspondences. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Knowledge graphs (KGs) such as DBpedia <ref type="bibr" target="#b36">(Lehmann et al. 2015)</ref>, YAGO <ref type="bibr" target="#b53">(Rebele et al. 2016)</ref> and Freebase <ref type="bibr" target="#b4">(Bollacker et al. 2008</ref>) store structured knowledge that is crucial to numerous knowledge-driven applications including question answering <ref type="bibr" target="#b14">(Cui et al. 2017)</ref>, entity linking <ref type="bibr" target="#b51">(Radhakrishnan, Talukdar, and Varma 2018)</ref>, text generation <ref type="bibr" target="#b34">(Koncel-Kedziorski et al. 2019</ref>) and information extraction <ref type="bibr" target="#b25">(Hoffmann et al. 2011</ref>). However, most KGs are independently extracted from separate sources, or contributed by speakers of one language, therefore limiting the coverage of knowledge. It is important to match and synchronise the independently built KGs and seek to provide NLP systems the benefit of complementary information contained in different KGs <ref type="bibr" target="#b2">(Bleiholder and Naumann 2009;</ref><ref type="bibr" target="#b6">Bryl and Bizer 2014)</ref>. To remedy this problem, the Entity Alignment (EA) 2 task aims at building cross-graph mappings to match entities having the same real-world identities, therefore integrating knowledge from different sources into a common space.</p><p>Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.</p><p>1 Code release: https://github.com/cambridgeltl/ eva.</p><p>Project page: http://cogcomp.org/page/ publication_view/927. <ref type="bibr">2</ref> The entity in EA refers to real-world objects and concepts.</p><p>A major bottleneck for training EA models is the scarce cross-graph pivots 3 available as alignment signals <ref type="bibr" target="#b12">(Chen et al. 2017;</ref><ref type="bibr" target="#b61">Sun et al. 2018)</ref>. Besides, the sparsity of KGs is usually accompanied with weak structural correspondence, posing an even greater challenge to EA. To mitigate this problem, recent works have attempted to retrieve auxiliary supervision signals from the supplementary information of entities, such as attributes <ref type="bibr" target="#b60">(Sun, Hu, and Li 2017;</ref><ref type="bibr" target="#b68">Trisedya, Qi, and Zhang 2019;</ref><ref type="bibr" target="#b79">Yang et al. 2020;</ref><ref type="bibr" target="#b41">Liu et al. 2020b</ref>) and descriptions . However, existing EA approaches are still limited in their capabilities. Our study proposes to leverage images, a natural component of entity profiles in many KGs <ref type="bibr" target="#b36">(Lehmann et al. 2015;</ref><ref type="bibr" target="#b69">Vrandečić and Krötzsch 2014;</ref><ref type="bibr" target="#b40">Liu et al. 2019)</ref>, for better EA. Images have been used to enrich entity representations for KG completion in a single-graph scenario <ref type="bibr" target="#b75">(Xie et al. 2017;</ref><ref type="bibr">Mousselly-Sergieh et al. 2018;</ref><ref type="bibr" target="#b50">Pezeshkpour, Chen, and Singh 2018)</ref>. However, the visual modality is yet to be explored for cross-graph tasks such as EA.</p><p>Our study stands upon several advantages that the visual modality brings to EA. First, the visual concept of a named entity is usually universal, regardless of the language or the schema of the KG. Therefore, given a well-designed algorithm, images should provide the basis to find a set of reliable pivots. Second, images in KGs are freely-available and of high quality. Crucially, they are mostly manually verified and disambiguated. These abundant gold visual attributes in KGs render EA an ideal application scenario for visual representations. Third, images offer the possibility to enhance the representation of rare KG entities with impoverished structural contexts <ref type="bibr" target="#b9">(Cao et al. 2020;</ref><ref type="bibr" target="#b76">Xiong et al. 2018;</ref><ref type="bibr" target="#b20">Hao et al. 2019)</ref>. Images can be particularly beneficial in this setting, as entities of lower frequencies tend to be more concrete concepts <ref type="bibr" target="#b22">(Hessel, Mimno, and Lee 2018)</ref> with stable visual representations <ref type="bibr" target="#b23">Hewitt et al. 2018)</ref>. To demonstrate the benefit from injecting images, we present a challenging example in <ref type="figure">Fig. 1</ref>. Without images, it is harder to infer the correspondence between DWAYNE JOHNSON and its counterpart 巨石強森 ("The Rock Johnson") due to their dissimilar neighbourhoods in the two KGs. An alignment can be more easily induced by detecting visual similarity.</p><p>In this work, we propose EVA (Entity Visual Alignment), which incorporates images along with structures, relations and attributes to align entities in different KGs. During training, a learnable attention weighting scheme helps the alignment model to decide on the importance of each modality, and also provides interpretation for each modality's contribution. As we show, an advantage of our approach is that the model is able to be trained on either a small set of seed alignment labels as in previous methods (semi-supervised setting), or using only a set of automatically induced visual pivots (unsupervised setting). Iterative learning (IL) is applied to expand the set of training pivots under both settings. On two large-scale standard benchmarks, i.e. DBP15k for crosslingual EA and DWY15k for monolingual EA, EVA variants with or without alignment labels consistently outperform competitive baseline approaches.</p><p>The contributions of this work are three-fold: (i) We conduct the first investigation into the use of images as part of entity representations for EA, and achieve state-of-the-art (SOTA) performance across all settings. (ii) We leverage visual similarities to propose a fully unsupervised EA setting, avoiding reliance on any gold labels. Our model under the unsupervised setting performs closely to its semi-supervised results, even surpassing the previous best semi-supervised methods. (iii) We offer interpretability in our study by conducting ablation studies on the contributions from each modality and a thorough error analysis. We also provide insights on images' particular impact on long-tail KG entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Our work is connected to two research topics. Each has a large body of work which we can only provide as a highly selected summary. Entity alignment. While early work employed symbolic or schematic methods to address the EA problem <ref type="bibr" target="#b72">(Wijaya, Talukdar, and Mitchell 2013;</ref><ref type="bibr" target="#b59">Suchanek, Abiteboul, and Senellart 2011)</ref>, more recent attention has been paid to embeddingbased methods. A typical method of such is MTRANSE <ref type="bibr" target="#b12">(Chen et al. 2017)</ref>, which jointly trains a translational embedding model <ref type="bibr" target="#b5">(Bordes et al. 2013)</ref> to encode language-specific KGs in separate embedding spaces, and a transformation to align counterpart entities across embeddings. Following this methodology, later works span the following three lines of studies to improve on this task. The first is to use alternatives of embedding learning techniques. Those include more advanced relational models such as contextual translations , residual recurrent networks (RSN, <ref type="bibr" target="#b19">Guo, Sun, and Hu 2019)</ref> and relational reflection transformation <ref type="bibr" target="#b43">(Mao et al. 2020)</ref>, as well as variants of graph neural networks (GNNs) such as GCN <ref type="bibr" target="#b78">Yang et al. 2019;</ref><ref type="bibr">Wu et al. 2019a,b)</ref>, GAT <ref type="bibr" target="#b63">(Sun et al. 2020a;</ref><ref type="bibr" target="#b82">Zhu et al. 2019)</ref> and multi-channel GNNs . The second line of research focuses on capturing the alignment of entities with limited labels, therefore incorporating semi-supervised or metric learning techniques such as bootstrapping <ref type="bibr" target="#b61">(Sun et al. 2018)</ref>, co-training <ref type="bibr" target="#b79">Yang et al. 2020</ref>) and optimal transport <ref type="bibr" target="#b49">(Pei, Yu, and Zhang 2019)</ref>. Besides, to compensate for limited supervision signals in alignment learning, another line of recent works retrieves auxiliary supervision from side information of entities. Such information include numerical attributes <ref type="bibr" target="#b60">(Sun, Hu, and Li 2017;</ref><ref type="bibr" target="#b68">Trisedya, Qi, and Zhang 2019)</ref>, literals <ref type="bibr" target="#b48">Otani et al. 2018)</ref> and descriptions of entities <ref type="bibr" target="#b17">Gesese et al. 2019)</ref>. A recent survey by <ref type="bibr" target="#b64">Sun et al. (2020b)</ref> has systemati-cally summarised works in these lines.</p><p>The main contribution of this paper is relevant to the last line of research. To the best of our knowledge, this is the first attempt to incorporate the visual modality for EA in KGs. It also presents an effective unsupervised solution to this task, without the need of alignment labels that are typically required in previous works. Multi-modal KG embeddings. While incorporating perceptual qualities has been a hot topic for language representation learning for many years, few attempts have been made towards building multi-modal KG embeddings. <ref type="bibr" target="#b75">Xie et al. (2017)</ref> and <ref type="bibr" target="#b67">Thoma, Rettinger, and Both (2017)</ref> are among the first to incorporate translational KG embedding methods <ref type="bibr" target="#b5">(Bordes et al. 2013</ref>) with external visual information. However, they mostly explore the joint embeddings on intrinsic tasks like word similarity and link prediction. Mousselly-Sergieh et al. <ref type="bibr" target="#b46">(2018)</ref> improve the model of Xie et al. to incorporate both visual and linguistic features under a unified translational embedding framework. <ref type="bibr" target="#b50">Pezeshkpour, Chen, and Singh (2018)</ref> and <ref type="bibr" target="#b47">Oñoro-Rubio et al. (2019)</ref> also model the interplay of images and KGs. However, Pezeshkpour, Chen, and Singh focus specifically on KG completion. Oñoro-Rubio et al. treat images as first class citizens for tasks like answering visionrelational queries instead of building joint representation for images and entities. The aforementioned works all focus on single KG scenarios. As far as we know, we are the first to use the intermediate visual space for EA between KGs.</p><p>Note that in the context of embedding alignment, many studies have incorporated images in lexical or sentential representations to solve cross-lingual tasks such as bilingual lexicon induction <ref type="bibr" target="#b70">(Vulić et al. 2016;</ref><ref type="bibr" target="#b54">Rotman, Vulić, and Reichart 2018;</ref><ref type="bibr" target="#b56">Sigurdsson et al. 2020)</ref> or cross-modal matching tasks such as text-image retrieval <ref type="bibr" target="#b16">(Gella et al. 2017;</ref><ref type="bibr" target="#b33">Kiros, Chan, and Hinton 2018;</ref><ref type="bibr" target="#b31">Kiela, Wang, and Cho 2018)</ref>. Beyond embedding alignment, the idea of visual pivoting is also popular in the downstream task of machine translation <ref type="bibr" target="#b7">(Caglayan et al. 2016;</ref><ref type="bibr" target="#b27">Huang et al. 2016;</ref><ref type="bibr" target="#b24">Hitschler, Schamoni, and Riezler 2016;</ref><ref type="bibr" target="#b57">Specia et al. 2016;</ref><ref type="bibr" target="#b8">Calixto and Liu 2017;</ref><ref type="bibr" target="#b0">Barrault et al. 2018;</ref><ref type="bibr" target="#b58">Su et al. 2019</ref>), but it is beyond the scope of this study. All of these works are not designed to deal with relational data that are crucial to performing EA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>We start describing our method by formulating the learning resources. A KG (G) can be viewed as a set of triplets that are constructed with an entity vocabulary (E) and a relation vocabulary (R), i.e. G = {(e 1 , r, e 2 ) : r ∈ R; e 1 , e 2 ∈ E} where a triplet records the relation r between the head and tail entities e 1 , e 2 . Let G s = E s × R s × E s , G t = E t × R t × E t denote two individual KGs (to be aligned). Given a pair of entities e s ∈ E s from source KG and e t ∈ E t from target KG, the goal of EA is to learn a function f (·, ·; θ) : E s × E t → R parameterised by θ that can estimate the similarity of e s and e t . f (e s , e t ; θ) should be high if e s , e t are describing the same identity and low if they are not. Note that E s and E t ensure 1-to-1 alignment <ref type="bibr" target="#b61">Sun et al. 2018)</ref>, as to be congruent to the design of mainstream KBs <ref type="bibr" target="#b36">(Lehmann et al. 2015;</ref><ref type="bibr" target="#b53">Rebele et al. 2016)</ref> where disambiguation of entities is granted. To build joint representation for entities, we consider auxiliary information including images, relations and attributes. Let I denote the set of all images; R ∈ R N ×d R , A ∈ R N ×d A denote the matrices of relation and attribute features.</p><p>To tackle the EA task, our method jointly conducts two learning processes. A multi-modal embedding learning process aims at encoding both KGs G s and G t in a shared embedding space. Each entity in the embedding space is characterised based on both the KG structures and auxiliary information including images. In the shared space, the alignment learning process seeks to precisely capture the correspondence between counterpart entities by Neighbourhood Component Analysis (NCA, <ref type="bibr" target="#b18">Goldberger et al. 2005;</ref><ref type="bibr" target="#b39">Liu et al. 2020a</ref>) and iterative learning. Crucially, the alignment learning process can be unsupervised, i.e. pivots are automatically inferred from the visual representations of entities without the need of EA labels. The rest of this section introduces the technical details of both learning processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Multi-modal KG Embeddings</head><p>Given entities from two KGs G s and G t , and the auxiliary data I, R, A, this section details how they are embedded into low-dimensional vectors. Graph structure embedding. To model the structural similarity of G s and G t , capturing both entity and relation proximity, we use Graph Convolutional Network (GCN) proposed by <ref type="bibr" target="#b32">Kipf and Welling (2017)</ref>. Formally, a multi-layer GCN's operation on the l-th layer can be formulated as:</p><formula xml:id="formula_0">H (l+1) = [D − 1 2MD − 1 2 H (l) W (l) ] + ,<label>(1)</label></formula><p>where [·] + is the ReLU activation;M = M + I N is the adjacency matrix of G s ∪ G 2 plus an identity matrix (selfconnection);D is a trainable layer-specific weight matrix; H (l) ∈ R N ×D is the output of the previous GCN layer where N is number of entities and D is the feature dimension; H (0) is randomly initialised. We use the output of the last GCN layer as the graph structure embedding F G . Visual embedding. We use RESNET-152 <ref type="bibr" target="#b21">(He et al. 2016</ref>), pre-trained on the ImageNet <ref type="bibr" target="#b15">(Deng et al. 2009</ref>) recognition task, as the feature extractor for all images. For each image, we do a forward pass and take the last layer's output before logits as the image representation (the RESNET itself is not fine-tuned). The feature is sent through a trainable feed-forward layer for the final image embedding:</p><formula xml:id="formula_1">F I = W I · RESNET(I) + b I .<label>(2)</label></formula><p>The CNN-extracted visual representation is expected to capture both low-level similarity and high-level semantic relatedness between images <ref type="bibr" target="#b28">(Kiela and Bottou 2014)</ref>. <ref type="bibr">4</ref> Relation and attribute embeddings. <ref type="bibr" target="#b78">Yang et al. (2019)</ref> showed that modelling relations and attributes with GCNs could pollute entity representations due to noise from neighbours. Following their investigation, we adopt a simple feedforward network for mapping relation and attribute features into low-dimensional spaces:</p><formula xml:id="formula_2">F R = W R · R + b R ; F A = W A · A + b A .<label>(3)</label></formula><p>Modality fusion. We first l 2 -normalise each feature matrix by row and then fuse multi-modal features by trainable weighted concatenation:</p><formula xml:id="formula_3">F J = n i=1 e wi n j=1 e wj · F i ,<label>(4)</label></formula><p>where n is the number of modalities; w i is an attention weight for the i-th modality. They are sent to a softmax before being multiplied to each modality's l 2 -normalised representation, ensuring that the normalised weights sum to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Alignment Learning</head><p>On top of the multi-modal embeddings F J for all entities, we compute the similarity of all bi-graph entity pairs and align them using an NCA loss. The training set is expanded using iterative learning.</p><p>Embedding similarity. Let F s J , F t J denote embeddings of the source and target entities E s and E t respectively. We compute their cosine similarity matrix S = F s J , F t J ∈ R |Es|×|Et| , where each entry S ij corresponds to the cosine similarity between the i-th entity in E s and the j-th in E t . NCA loss. Inspired by the NCA-based text-image matching approach proposed by <ref type="bibr" target="#b39">Liu et al. (2020a)</ref>, we adopt an NCA loss of a similar form. It uses both local and global statistics to measure importance of samples and punishes hard negatives with a soft weighting scheme. This seeks to mitigate the hubness problem <ref type="bibr" target="#b52">(Radovanović, Nanopoulos, and Ivanović 2010)</ref> in an embedding space. The loss is formulated below:</p><formula xml:id="formula_4">L = 1 N N i=1 1 α log 1 + m =i e αSmi + 1 α log 1 + n =i e αSin − log 1 + βS ii ,<label>(5)</label></formula><p>where α, β are temperature scales; N is the number of pivots within the mini-batch. We apply such loss on each modality separately and also on the merged multi-modal representation as specified in eq. (4). The joint loss is written as:</p><formula xml:id="formula_5">L Joint = n i L i + L Multi-modal<label>(6)</label></formula><p>where L i represents the loss term for aligning the i-th modality; L Multi-modal is applied on the merged representation F J and is used for training the modality weights only. The reason for having separate terms for different modalities is that we use different hyper-parameters to accommodate their drastically distinct feature distributions. For all terms we used β = 10, but we picked different α's: α = 5 for L G ; α = 15 for L R , L A , L I , L J . Iterative learning. To improve learning with very few training pivots, we incorporate an iterative learning (IL) strategy to propose more pivots from unaligned entities. In contrast to previous work <ref type="bibr" target="#b61">(Sun et al. 2018)</ref>, we add a probation technique. In detail, for every K e epochs, we make a new round of proposal. Each pair of cross-graph entities that are mutual nearest neighbours is proposed and added into a candidate list. If a proposed entity pair remains mutual nearest neighbours throughout K s consecutive rounds (i.e. the probation phase), we permanently add it into the training set. Therefore, the candidate list refreshes every K e · K s epochs. In practice, we find that the probation technique has made the pivot discovery process more stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Unsupervised Visual Pivoting</head><p>Previous EA methods require annotated pivots that may not be widely available across KGs <ref type="bibr" target="#b83">(Zhuang et al. 2017;</ref><ref type="bibr" target="#b12">Chen et al. 2017</ref>). Our method, however, can naturally extend to an unsupervised setting where visual similarities are leveraged to infer correspondence between KGs, and no annotated crossgraph pivots are required. All cross-graph supervision comes from an automatically induced visual dictionary (visual pivots) containing the most visually alike cross-graph entities. Specifically, we first compute cosine similarities of all crossgraph entities' visual representations in the data set. Then we sort the cosine similarity matrix from high to low. We collect visual pivots starting from the most similar pairs. Once a pair of entities is collected, all other links associated with the two entities are discarded. In the end, we obtain a cross-graph pivot list that records the top-k visually similar entity pairs without repetition of entities. From these visual pivots, we apply iterative learning ( §3.2) to expand the training set. The algorithm of obtaining visual pivots is formally described in Algorithm 1. Let n be the number of entities in one language, the algorithm takes O(n 2 log(n 2 ) + n 2 ) = O(n 2 log n).</p><p>Our approach is related to some recent efforts on word translation with images <ref type="bibr" target="#b1">(Bergsma and Van Durme 2011;</ref><ref type="bibr" target="#b30">Kiela, Vulić, and Clark 2015;</ref><ref type="bibr" target="#b23">Hewitt et al. 2018)</ref>. However, those efforts focus on obtaining cross-lingual parallel signals from web-crawled images provided by search engines (e.g. Google Image Search). This can result in noisy data caused by issues like ambiguity in text. For example, for a query <ref type="table">Table 1</ref>: Cross-lingual EA results on DBP15k. Comparison with related works with and without using IL. "-" means not reported by the original paper. " * " indicates our reproduced results for which any use of machine translation or cross-lingual alignment labels other than those provided in the benchmark are removed. Bold numbers are the best models and underline marks statistical significance (p-value&lt; 0.05). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we conduct experiments on two benchmark data sets ( §4.1), under both semi-and unsupervised settings ( §4.2). We also provide detailed ablation studies on different model components ( §4.3), and study the impact of incorporating visual representations on long-tail entities ( §4.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Settings</head><p>Data sets. The experiments are conducted on DBP15k <ref type="bibr" target="#b60">(Sun, Hu, and Li 2017)</ref> and DWY15k . DBP15k is a widely used cross-lingual EA benchmark. It contains four language-specific KGs from DBpedia, and has three bilingual EA settings, i.e., French-English (FR-EN), Japanese-English (JA-EN) and Chinese-English (ZH-EN). DBpedia has also released images for English, French and Japanese versions. Note that since Chinese images are not released in DBpedia, we extracted them from the raw Chinese Wikipedia dump with the same process as described by <ref type="bibr" target="#b36">Lehmann et al. (2015)</ref>. DWY15k is a monolingual data set, focusing on EA for DBpedia-Wikidata and DBpedia-YAGO. It has two subsets, DWY15k-norm and DWY15kdense, whereof the former is much sparser. As YAGO does not have image components, we experiment on DBpedia-Wikidata only. Note that not all but ca. 50-85% entities have images, as shown in Tab. 6. For an entity without an image, we assign a random vector sampled from a normal distribution, parameterised by the mean and standard deviation of other images. As for relation and attribute features, we extract them in the same way as <ref type="bibr" target="#b78">Yang et al. (2019)</ref>.</p><p>Model configurations. The GCN has two layers with input, hidden and output dimensions of 400, 400, 200 respectively. Attribute and relation features are mapped to 100-d. Images are transformed to 2048-d features by RESNET and then mapped to 200-d. For model variants without IL, training is limited to 500 epochs. Otherwise, after the first 500 epochs, IL is conducted for another 500 epochs with the configurations K e = 5, K s = 10 as described in §3.2. We train all models using a batch size of 7,500. The models are optimised using AdamW (Loshchilov and Hutter 2019) with a learning rate of 5e-4 and a weight decay of 1e-2. More implementation details are available in Appendix A <ref type="bibr" target="#b38">(Liu et al. 2021</ref>).</p><p>Evaluation protocols. Following convention, we report three metrics on both data sets, including H@{1,10} (the proportion of ground truth being ranked no further than top {1,10}), and MRR (mean reciprocal rank). During inference, we use Cross-domain Similarity Local Scaling (CSLS; Lample et al. <ref type="bibr" target="#b46">2018</ref>) to post-process the cosine similarity matrix, which is employed by default in some recent works <ref type="bibr" target="#b63">(Sun et al. , 2020a</ref>. k = 3 is used for defining local neighbourhood of CSLS. All models are run for 5 times with 5 different random seeds and the average with variances are reported. Bold numbers in tables come from the best models and underline means with statistical significance (p-value &lt; 0.05 in t-test). The baseline results on DBP15k come from ten methods with IL, and three without. We accordingly report the results by EVA with and without IL. Note that a few methods may incorporate extra cross-lingual alignment labels by initialising training with machine translation <ref type="bibr" target="#b74">(Wu et al. 2019b;</ref><ref type="bibr" target="#b78">Yang et al. 2019)</ref> or pre-aligned word vectors . For fair comparison in this study, we report results from the versions of these methods that do not use any alignment signals apart from the training data. On DWY15k, there are also  two settings in the literature, different in whether to use the surface form embeddings of monolingual entities <ref type="bibr" target="#b79">(Yang et al. 2020)</ref> or not . We report results from EVA with and without using surface forms 5 , and compare with five SOTA baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Main Results</head><p>Semi-supervised EA. Tab. 1 reports the results on semisupervised cross-lingual EA. This setting compares EVA with baseline methods using the original data split of DBP15k, i.e., using 30% of the EA labels for training. Consequently, EVA achieves SOTA performance and surpasses baseline models drastically both with or without IL. Specifically, in the W/O IL setting, EVA leads to 12.3-17.6% absolute improvement in H@1 over the best baseline. When incorporating IL, EVA gains 11.9-12.5% absolute improvement in H@1 over the best IL-based baseline method. This indicates that incorporating the visual representation competently improves the cross-lingual entity representations for inferring their correspondences, without the need of additional supervision labels. The results on monolingual EA generally exhibit similar observations. As reported in Tab. 2, without incorporating surface form information, EVA surpasses the strongest baseline method by 16.8% in H@1 on the normal split and 4.2% on the dense split. With surface forms considered, EVA offers near-perfect results, outperforming the SOTA method by 26.8% in H@1 on the normal split and 6.6% in H@1 on the dense split. The experiments here indicate that, EVA is able to substantially improve SOTA EA systems under both monolingual and cross-lingual settings. Unsupervised EA. We also use the visual pivoting technique ( §3.3) with EVA to conduct unsupervised EA, without using any annotated alignment labels. We compare EVA's best unsupervised and semi-supervised results in Tab. 3. The unsupervised EVA yields 1.9-6.3% lower H@1 than the semisupervised version, but still notably outperforms the best semi-supervised baseline (Tab. 1) by 5.6-10.1%. We change the number of visual seeds by adjusting the threshold n in Algorithm 1, and test the model's sensitiveness to the threshold. As shown in <ref type="figure">Fig. 2</ref>, the optimal seed size is 4k on FR→EN 5 When incorporating surface form, we use FASTTEXT <ref type="bibr" target="#b3">(Bojanowski et al. 2017)</ref> to embed surface strings into low-dimensional vectors S ∈ R N ×ds (ds = 300), and learn a linear transformation to obtain final representations in 100-d: FS = WS · S + bS. We merge and train the surface form modality in the same way as the other modalities.  <ref type="bibr" target="#b61">(Sun et al. 2018)</ref> .323 .631 .420 .678 .912 .760 GCN  .177 .378 .250 .431 .713 .530 JAPE <ref type="bibr" target="#b60">(Sun, Hu, and Li 2017)</ref> . <ref type="bibr">219 .501 .310 .393 .705</ref> .500 RSN  . <ref type="bibr">388 .657 .490 .763 .924</ref> .830 COTSAE <ref type="bibr" target="#b79">(Yang et al. 2020)</ref> . <ref type="bibr">423 .703 .510 .823 .954 .870 .593 .775 .655 .874 .962</ref> .908 EVA W/O SF ±.004 ±.005 ±.003 ±.002 ±.003 ±.002 W/ SF COTSAE <ref type="bibr" target="#b79">(Yang et al. 2020)</ref> . <ref type="bibr">709 .904 .770 .922 .983 .940</ref> .985 .995 .989 .994 1.0 .996 EVA W/ SF ±.001 ±.000 ±.001 ±.001 ±.001 ±.000 . <ref type="bibr">731 .909 .792 .737 .890 .791 .752 .895 .804</ref> ±.004 ±.003 ±.003 ±.008 ±.004 ±.006 ±.006 ±.004 ±.005</p><p>Semi-sup.</p><p>. <ref type="bibr">793 .942 .847 .762 .913 .817 .761 .907 .814</ref> ±.003 ±.002 ±.004 ±.008 ±.004 ±.006 ±.004 ±.006 ±.003 and 6k on JA→EN and ZH→EN. It is worth noticing that a good alignment (H@1&gt;55%) can be obtained using as few as a hundred visual seeds. As the number of seeds grows, the model gradually improves, reaching &gt;70% H@1 with more than 3k seeds. Then the scores plateau for a period and start to decrease with more than 4k (on FR→EN) or 6k <ref type="figure">(JA→EN, ZH→EN)</ref> seeds. This is because a large visual seed dictionary starts to introduce noise. Empirically, we find that a 0.85 cosine similarity threshold is a good cut-off point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ablation Study</head><p>We report an ablation study of EVA in Tab. 4 using DBP15k (FR→EN). As shown, IL brings ca. 8% absolute improvement. This gap is smaller than what has been reported previously <ref type="bibr" target="#b61">(Sun et al. 2018)</ref>. This is because the extra visual supervision in our method already allows the model to capture fairly good alignment in the first 500 epochs, leaving smaller room for further improvement from IL. CSLS gives  minor but consistent improvement to all metrics during inference. While CSLS is mainly used to reduce hubs in a dense space such as textual embeddings <ref type="bibr" target="#b35">(Lample et al. 2018)</ref>, we suspect that it cannot bring substantial improvement to our sparse multi-modal space. Besides, the hubness problem is already partly tackled by our NCA loss. The sparseness of multi-modal space can also explain our choice of k = 3, which we found to be better than the previous k = 10.</p><p>Regarding the impact from different modalities, structure remains the most important for our model. Dropping structural embedding decreases H@1 from ca. 80% to below 40%, cutting the performance by half. This is in line with the findings by <ref type="bibr" target="#b78">Yang et al. (2019)</ref>. Image, attributes and relations are of similar importance. The removal of images and attributes decrease H@1 by 4-5% while removing relations causes ca. 3% drop in H@1. This general pattern roughly corresponds to the modality attention weights. On DBP15k, while all weights start at 0.25, after training, they become ca. 0.45, 0.21, 0.17 and 0.16 for structures, images, relations and attributes respectively.</p><p>In addition, we explore several other popular options of pre-trained visual encoder architectures including ResNet <ref type="bibr" target="#b21">(He et al. 2016)</ref>, GoogLeNet <ref type="bibr" target="#b65">(Szegedy et al. 2015)</ref>, DenseNet <ref type="bibr" target="#b26">(Huang et al. 2017)</ref> and Inception v3 <ref type="bibr" target="#b66">(Szegedy et al. 2016)</ref> as feature extractors for images. One of the variants, ResNet (Places365) <ref type="bibr" target="#b81">(Zhou et al. 2017)</ref>, is pre-trained on a data set from the outdoor-scene domain and is expected to be better at capturing location-related information. In general, we found little difference in model performance with different visual encoders. As suggested in Tab. 5, variances from different models across different metrics are generally &lt; 1%. All numbers reported in the paper have been using ResNet152 as it is one of the most widely used visual feature extractor. It is also possible to fine-tune the visual encoder with the full model in an end-to-end fashion. However, the computation cost would be extremely large under our setting. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis on Long-tail Entities</head><p>Like lexemes in natural languages, the occurrence of entities in KG triplets also follow a long-tailed distribution <ref type="figure">(Fig. 3)</ref>. Long-tail entities are poorly connected to others in the graph and thus have less structural information for inducing reliable representation and alignment. We argue that images might remedy the issue by providing alternative sources of signal for representing these long-tail entities. To validate our hypothesis, we stratify the test set of DBP15k (FR→EN) into five splits of entity pairs based on their degree centrality in the graphs. Specifically, for all entity pairs (e s , e t ) ∈ G s × G t in the test set, we sort them by their degree sum, i.e., DegSum(e s , e t ) := deg(e s ) + deg(e t ), and split them into five sets of equal sizes, corresponding to five ranges of DegSum partitioned by 14, 18, 23 and 32, respectively. Across the five splits, we compare the performance by EVA (W/O IL) against its variant where visual inputs are disabled. The results in <ref type="figure">Fig. 4</ref> suggest that entities in the lower ranges of degree centrality benefit more from the visual representations. This demonstrates that the visual modality particularly enhances the match of long-tail entities which gain less information from other modalities.</p><p>As an example, in DBP15k (FR→EN), the long-tail entity Stade olympique de Munich has only three occurrences in French. The top three retrieved entities in English by EVA w/o visual representation are Olympic Stadium (Amsterdam), Friends Arena and Olympiastadion (Munich). The embed-  ding without visual information was only able to narrow down the answer to European stadiums, but failed to correctly order the specific stadiums <ref type="figure" target="#fig_2">(Fig. 5</ref>). With the visual cues, EVA is able to rank the correct item as the top 1. Note that in <ref type="figure">Fig. 4</ref>, the split of the most frequent entities (80-100% quantiles) generally displays worse performance than the second most frequent split (60-80% quantiles), suggesting that, a denser neighbourhood does not always lead to better alignment. This is consistent with <ref type="bibr" target="#b63">Sun et al. (2020a)</ref>'s observation that, entities with high degree centrality may be affected by the heterogeneity of their neighbourhood.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Error Analysis</head><p>On the monolingual setting (DBP15k-WD), EVA has reached near-perfect performance. On the cross-lingual setting (DBP15k), however, there is still a &gt;20% gap from perfect alignment. One might wonder why the involvement of images has not solved the remaining 20% errors. By looking into the errors made by EVA (W/O IL) on DBP15k (FR→EN), we observe that among the 2955 errors, 1945 (i.e., ca. 2/3) of them are entities without valid images. In fact, only 50-70% of entities in our study have images, according to Tab. 6. This is inherent to knowledge bases themselves and cannot be easily resolved without an extra step of linking the entities to some external image database. For the remaining 1k errors, ca. 40% were wrongly predicted regardless of with or without images. The other 60% were correctly predicted before injecting visual information, but were missed when images were present. Such errors can be mainly attributed to the consistency/robustness issues in visual representations especially for more abstract entities as they tend to have multiple plausible visual representations. Here is a real example: Université de Varsovie (French) has the photo of its front gate in the profile while its English equivalent University of Warsaw uses its logo in the profile. The drastically different visual representations cause a misalignment. While images are in most cases helpful for the alignment, it requires further investigation for a mechanism to filter out the small fraction of unstable visual representations. This is another substantial research direction for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We propose a new model EVA that uses images as pivots for aligning entities in different KGs. Through an attentionbased modality weighting scheme, we fuse multi-modal information from KGs into a joint embedding and allow the alignment model to automatically adjust modality weights. Besides experimenting with the traditional semi-supervised setting, we present an unsupervised approach, where EVA leverages visual similarities of entities to build a seed dictionary from scratch and expand the dictionary with iterative learning. The semi-supervised EVA claims new SOTA on two EA benchmarks, surpassing previous methods by large margins. The unsupervised EVA achieves &gt;70% accuracy, being close to its performance under the semi-supervised setting, and outperforming the previous best semi-supervised baseline. Finally, we conduct thorough ablation studies and error analysis, offering insights on the benefits of incorporating images for long-tail KG entities. The implication of our work is that perception is a crucial element in learning entity representation and associating knowledge. In this way, our work also highlights the necessity of fusing different modalities in developing intelligent learning systems <ref type="bibr" target="#b44">(Mooney 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A More Implementation Details</head><p>Tab. 8 lists hyper-parameter search space for obtaining the set of used numbers. Instead of always choosing the best performing model, we balance the memory limit and model performance. We train &amp; evaluate all our models on a machine with the specifications listed in Tab. 7. On this machine, the full training process of EVA (1,000 epochs) takes 10-15 minutes, depending on the data set. The full model for DBP15k has ca. 16M; for DWY15k has ca. 13M trainable parameters. The difference comes from the different sizes of entity embedding layers. The numbers reported in this paper in general are highly stable and should be easily replicated using our provided code. DBP15k and DWY15k are open benchmark data sets.  Tab. 9 is the same data as <ref type="figure">Fig. 2</ref> but presented using a table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Plottings of Normalised Modality Weights</head><p>We plot the change of normalised modality weights throughout the training process in <ref type="figure">Fig. 6</ref>. It is shown that on DBP15k, images are the second important (after graph structure); on DWY15k (norm), they are the third important (after graph structure and surface form), for almost the whole time of training. Interestingly, on DBP15k, images' weight slightly increases a bit after the starting phase, then starts to decrease once entering iterative learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Descriptions of Baseline Methods</head><p>The baseline methods for cross-lingual EA are in two categories: with or without iterative learning (IL). Ten of those are without IL. Specifically, MTRANSE <ref type="bibr" target="#b12">(Chen et al. 2017</ref>) represents a pioneering method of this topic. It jointly learns a translational embedding model <ref type="bibr" target="#b5">(Bordes et al. 2013</ref>) and an alignment model that captures the correspondence of counterpart entities via transformations or distances of the embedding representations.</p><p>Based on this methodology, <ref type="bibr" target="#b71">Wang et al. (2018)</ref> use GCN <ref type="bibr" target="#b32">(Kipf and Welling 2017)</ref> to substitute the translational embedding model to better capture the corresponding entities based on their neighbourhood structures. MUGNN ) combines multiple channels of GNNs to achieve entity representations that are more robust to parameter initialisation. MECG ) extends the vanilla GCN with a regularisation term based on relational translation, aiming at differentiating neighbouring entities that participate in different relations. GCN-JE <ref type="bibr" target="#b74">(Wu et al. 2019b</ref>) extends the same architecture with additional embedding calibration on the relation schemata. To handle the heterogeneity of neighbourhood entities in different KGs, ALINET employs an attention neighbourhood aggregation, with a gated message passing mechanism to cope with the noises caused by heterogeneous neighbourhood information. Instead of employing a GNN, RSN (Guo, Sun, and Hu 2019) uses a residual recurrent network, seeking to capture the long-term dependency of entities on relation paths. Besides, JAPE <ref type="bibr" target="#b60">(Sun, Hu, and Li 2017)</ref> leverages entity attributes to enhance the proximity measure of entities, and HMAN <ref type="bibr" target="#b78">(Yang et al. 2019)</ref> incorporates weighted combination of different side information excluding visual modalities.</p><p>For the three methods that are trained with IL, BOOTEA <ref type="bibr" target="#b61">(Sun et al. 2018)</ref> incorporates the basic bootstrapping approach in MTRANSE. MMEA <ref type="bibr" target="#b55">(Shi and Xiao 2019)</ref> and NAEA <ref type="bibr" target="#b82">(Zhu et al. 2019</ref>) are GCN and GAT based, respectively, with the latter using additionally mutual nearest neighbour constraint in proposing new alignment labels.</p><p>The monolingual EA setting contains several of those methods that have been reported on the cross-lingual setting at above. The additional baseline method is COTSAE <ref type="bibr" target="#b79">(Yang et al. 2020)</ref>, which employs an iterative co-training method on the structural and attribute views of entities, similar to the learning process that is employed by KDCOE ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Future Research Directions</head><p>Investigation of alignment difficulties across different language pairs. We observe different patterns of model performance for different language pairs. For example, in <ref type="figure">Fig. 2, H@1</ref> for FR→EN plateaus much earlier than JA→EN and ZH→EN. Understanding these cross-lingual differences requires a more thorough investigation into the distributions of images within each language and how such distributions have influenced cross-lingual mapping. Extending to low-resource languages. Our study so far has only focused on aligning entities between high-resource languages. However, EVA can be particularly promising for enhancing knowledge representations in low-resource languages which could benefit the most from knowledge synchronisation with other languages. While the KGs and the alignment information in low-resource languages can be very sparse <ref type="bibr" target="#b64">(Sun et al. 2020b)</ref>, EVA can leverage crucial side information of entities (ie. images) to facilitate the alignment. In the same context, it could also be promising to consider combining multiple sources of high-resource knowledge to jointly learn both the alignment and knowledge transfer to a low-resource KG <ref type="bibr" target="#b13">(Chen et al. 2020</ref>). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>2: Unsupervised EVA vs. semi-supervised EVA. Plotting H@1 against number of induced visual seeds for jump-starting the training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>Long-tailed distribution of entity appearances in KG triplets, using 100 randomly sampled entities in DBP15k (FR-EN). Plotting H@1 against different test splits on FR-EN (frequency low-to-high from left to right). Models w/ or w/o visual information are compared. The plot suggests that visual information has improved long-tail entities' alignment more.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>EVA w/o images ranks (b) at top 1, (c) and (d) at top 2 and 3 respectively. Through visual disambiguation, EVA ranks the correct concept (d) at top 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Algorithm 1: Visual pivot induction. :visual embeddings from entities in the two graphs (F 1 I , F 2 I ); pivot dictionary size (n) output :pivot dictionary 1 M ← F 1 I , F 2</figDesc><table><row><cell></cell><cell>I</cell><cell></cell><cell>get similarity matrix</cell></row><row><cell cols="3">2 ms ← sort(M)</cell><cell>sort elements of M</cell></row><row><cell cols="2">3 S ← {}</cell><cell></cell><cell>initialise seed dictionary</cell></row><row><cell cols="3">4 Ru ← {}; Cu ← {}</cell><cell>for recording used row/column</cell></row><row><cell cols="3">5 while |S|! = n do</cell></row><row><cell>6</cell><cell cols="2">m ← ms.pop()</cell><cell>get the highest ranked score</cell></row><row><cell>7</cell><cell cols="3">if m.ri ∈ Ru &amp; m.ci ∈ Cu then</cell></row><row><cell>8</cell><cell cols="3">S ← S ∪ (m.ri, m.ci)</cell><cell>store the pair</cell></row><row><cell>9</cell><cell cols="3">Ru ← Ru ∪ m.ci</cell></row><row><cell>10</cell><cell cols="2">Cu ← Cu ∪ m.ri</cell></row><row><cell>11</cell><cell>end</cell><cell></cell></row><row><cell>12 end</cell><cell></cell><cell></cell></row><row><cell cols="2">13 return S</cell><cell cols="2">return the obtained visual pivot dictionary</cell></row></table><note>input</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Monolingual EA results on DWY15k-DW (N: normal split; D: dense split). EVA using IL is compared with related works with and without using surface forms (W/ SF &amp; W/O SF).</figDesc><table><row><cell>model</cell><cell>DBP→WD (N)</cell><cell>DBP→WD (D)</cell></row><row><cell></cell><cell>H@1 H@10 MRR</cell><cell>H@1 H@10 MRR</cell></row><row><cell>BOOTEA</cell><cell></cell><cell></cell></row><row><cell>W/O SF</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Comparing unsupervised and semi-supervised EVA re-</figDesc><table><row><cell cols="2">sults on DBP15k.</cell><cell></cell><cell></cell></row><row><cell>setting</cell><cell>FR→EN</cell><cell>JA→EN</cell><cell>ZH→EN</cell></row><row><cell></cell><cell>H@1 H@10 MRR</cell><cell>H@1 H@10 MRR</cell><cell>H@1 H@10 MRR</cell></row><row><cell>Unsup.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Ablation study of EVA based on DBP15k (FR→EN). O structure .391 ±.004 .514 ±.003 .423 ±.004 W/O image .749 ±.002 .929 ±.002 .817 ±.001 W/O attribute .750 ±.003 .927 ±.001 .813 ±.003 W/O relation .763 ±.006 .928 ±.003 .823 ±.004 W/O IL .715 ±.003 .936 ±.002 .795 ±.004 W/O CSLS .786 ±.005 .928 ±.001 .838 ±.003 full model .793 ±.003 .942 ±.002 .847 ±.004</figDesc><table><row><cell>model</cell><cell>H@1</cell><cell>H@10</cell><cell>MRR</cell></row><row><cell>W/</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Comparing visual encoders. Results are obtained on ±.003 .938 ±.002 .794 ±.003 ResNet50 (places365) .710 ±.002 .937 ±.002 .792 ±.002 ResNet152 .715 ±.003 .936 ±.002 .795 ±.004 DenseNet201 .716 ±.005 .935 ±.002 .796 ±.003 Inception v3 .711 ±.002 .936 ±.002 .792 ±.002</figDesc><table><row><cell cols="2">DBP15k (FR→EN) using EVA W/O IL.</cell><cell></cell><cell></cell></row><row><cell>visual encoder</cell><cell>H@1</cell><cell>H@10</cell><cell>MRR</cell></row><row><cell>ResNet50</cell><cell>.713</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 :</head><label>6</label><figDesc>Image coverage statistics on DBP15k and DWY15k. The image coverage of DBP15k (ca. 65-85%) is generally better than DWY15k</figDesc><table><row><cell>(ca. 50-60%).</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">FR↔EN</cell><cell cols="2">JA↔EN</cell><cell cols="2">ZH↔EN</cell><cell cols="2">DBP↔WD (norm)</cell><cell cols="2">DBP↔WD (dense)</cell></row><row><cell></cell><cell>FR</cell><cell>EN</cell><cell>JA</cell><cell>EN</cell><cell>ZH</cell><cell>EN</cell><cell>DBP</cell><cell>WD</cell><cell>DBP</cell><cell>WD</cell></row><row><cell cols="3">image covered 14,174 13,858</cell><cell cols="2">12,739 13,741</cell><cell cols="2">15,912 14,125</cell><cell>8,517</cell><cell>8,791</cell><cell>7,744</cell><cell>7,315</cell></row><row><cell>all entities</cell><cell cols="2">19,661 19,993</cell><cell cols="2">19,814 19,780</cell><cell cols="2">19,388 19,572</cell><cell>15,000</cell><cell>15,000</cell><cell>15,000</cell><cell>15,000</cell></row><row><cell cols="4">(a) Query (French): Stade olympique de Munich</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>(b) Olympic Stadium (Amsterdam)</cell><cell cols="2">(c) Friends Arena</cell><cell cols="2">(d) Olympiastadion (Munich)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 :</head><label>7</label><figDesc>Hardware specifications of the used machine.</figDesc><table><row><cell>hardware</cell><cell>specification</cell></row><row><cell>RAM</cell><cell>192 GB</cell></row><row><cell>CPU</cell><cell>AMD ® Ryzen 9 3900X 12-core 24-thread</cell></row><row><cell>GPU</cell><cell>NVIDIA ® GeForce RTX 2080 Ti (11 GB) × 2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 :</head><label>8</label><figDesc>This table lists the search space for hyper-parameters used.</figDesc><table><row><cell>hyper-parameters</cell><cell>search space</cell></row><row><cell>learning rate</cell><cell>{1e-3, 5e-4, 1e-4}</cell></row><row><cell>GCN input &amp; hidden dimension</cell><cell>{100, 200, 400}</cell></row><row><cell>feature dimension of each modality</cell><cell>{50, 100, 200}</cell></row><row><cell>training epochs (before IL)</cell><cell>{300, 500, 1000}</cell></row><row><cell>training epochs (total)</cell><cell>{1000, 1500, 2000}</cell></row><row><cell>Ke (for IL)</cell><cell>{3, 5, 10}</cell></row><row><cell>Ks (for IL)</cell><cell>{3, 5, 10}</cell></row><row><cell>α in Equation (5)</cell><cell>{5, 10, 15, 20}</cell></row><row><cell>β in Equation (5)</cell><cell>{5, 10, 15, 20}</cell></row><row><cell>k in CSLS</cell><cell>{1, 3, 5, 10}</cell></row><row><cell cols="2">B Full Table for the Unsupervised Setting</cell></row><row><cell cols="2">Results</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 :</head><label>9</label><figDesc>Quantitative results on DBP15k. Unsupervised setting.</figDesc><table><row><cell>seed</cell><cell>FR→EN</cell><cell></cell><cell></cell><cell>JA→EN</cell><cell></cell><cell></cell><cell>ZH→EN</cell><cell></cell></row><row><cell>H@1</cell><cell>H@10</cell><cell>MRR</cell><cell>H@1</cell><cell>H@10</cell><cell>MRR</cell><cell>H@1</cell><cell>H@10</cell><cell>MRR</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">In this paper, pivot is used interchangeably with seed alignment between cross-graph entities; visual pivoting means to use the visual space as intermediate to find seed alignment.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">We compared several popular pre-trained visual encoders but found no substantial difference ( §4.3).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We appreciate the anonymous reviewers for their insightful comments and suggestions. </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Findings of the Third Shared Task on Multimodal Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="304" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning bilingual lexicons using the visual similarity of labeled web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bergsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Data fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bleiholder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Naumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="41" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enriching Word Vectors with Subword Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TACL</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGMOD</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Translating embeddings for modeling multirelational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Yakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2787" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Learning conflict resolution strategies for cross-language wikipedia data fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Bryl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1129" to="1134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Does Multimodality Help Human and Machine for Translation and Image Captioning? In WMT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Caglayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Aransa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Masana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>García-Martínez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van De Weijer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="627" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Incorporating Global Visual Features into Attention-based Neural Machine Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Calixto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="992" to="1003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Open Knowledge Enrichment for Long-tail Entities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WWW</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="384" to="394" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Multi-Channel Graph Neural Network for Entity Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1452" to="1461" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Co-training embeddings of knowledge graphs and entity descriptions for cross-lingual entity alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3998" to="4004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multilingual knowledge graph embeddings for cross-lingual knowledge alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1511" to="1517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Multilingual knowledge graph completion via ensemble knowledge transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Uppunda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zaniolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">KBQA: learning question answering over QA corpora and knowledge bases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="565" to="576" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ImageNet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Image Pivoting for Learning Multilingual Multimodal Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2839" to="2845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Gesese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sack</surname></persName>
		</author>
		<title level="m">A Survey on Knowledge Graph Embeddings with Literals: Which model links better Literal-ly? Semantic Web Journal</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Neighbourhood components analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Learning to Exploit Longterm Relational Dependencies in Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2505" to="2514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">KDD</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1709" to="1719" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Quantifying the Visual Concreteness of Words and Topics in Multimodal Datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hessel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2194" to="2205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning translations via images with a massively multilingual image dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hewitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ippolito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Callahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kriz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Wijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2566" to="2576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Multimodal Pivots for Image Caption Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hitschler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schamoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Riezler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2399" to="2409" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Knowledge-based weak supervision for information extraction of overlapping relations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Weld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL-HLT</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="541" to="550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Attention-based multimodal neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-R</forename><surname>Shiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning image embeddings using convolutional neural networks for improved multi-modal semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="36" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improving multi-modal representations using image dispersion: Why less is sometimes more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Korhonen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="835" to="841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Visual Bilingual Lexicon Induction with Transferred ConvNet Features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="148" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic Meta-Embeddings for Improved Sentence Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Illustrative language understanding: Large-scale visual grounding with image search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="922" to="933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Text Generation from Knowledge Graphs with Graph Transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bekal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2284" to="2293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Word translation without parallel data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jégou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">DBpedia-a large-scale, multilingual knowledge base extracted from Wikipedia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Morsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Van Kleef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="167" to="195" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Semi-supervised Entity Alignment via Joint Knowledge Embedding Model and Cross-graph Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2723" to="2732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Collier</surname></persName>
		</author>
		<title level="m">Visual Pivoting for (Unsupervised) Entity Alignment</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">MMKG: Multi-modal Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garcia-Duran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Onoro-Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Rosenblum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ESWC</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="459" to="474" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Exploring and Evaluating Attributes, Values, and Structure for Entity Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-S</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6355" to="6364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Decoupled Weight Decay Regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Relational Reflection Entity Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1095" to="1104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Learning to Connect Language and Perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Mooney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1598" to="1601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mousselly-Sergieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Botschen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">A multimodal translation-based approach for knowledge graph representation learning</title>
	</analytic>
	<monogr>
		<title level="m">*SEM</title>
		<imprint>
			<biblScope unit="page" from="225" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Oñoro-Rubio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Niepert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>García-Durán</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>González-Sánchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>López-Sastre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AKBC</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Cross-lingual Knowledge Projection Using Machine Translation and Target-side Knowledge Base Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Otani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kiyomaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kawahara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kurohashi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">COLING</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1508" to="1520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Improving cross-lingual entity alignment via optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3231" to="3237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Embedding Multimodal Relational Data for Knowledge Base Completion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pezeshkpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3208" to="3218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">ELDEN: Improved entity linking using densified knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NAACL</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Hubs in space: Popular nearest neighbors in high-dimensional data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Radovanović</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nanopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ivanović</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="2487" to="2531" />
			<date type="published" when="2010-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">YAGO: A multilingual knowledge base from wikipedia, wordnet, and geonames</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rebele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Biega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kuzey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="177" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Bridging languages through images with deep partial canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rotman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Reichart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="910" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Modeling Multi-mapping Relations for Precise Cross-lingual Entity Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="813" to="822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Visual Grounding in Video for Unsupervised Word Translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Sigurdsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nematzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Smaira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Blunsom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A shared task on multimodal machine translation and crosslingual image description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sima&amp;apos;an</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Elliott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WMT</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="543" to="553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Unsupervised multi-modal neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><forename type="middle">J</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">PARIS: probabilistic alignment of relations, instances, and schema</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Abiteboul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Senellart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PVLDB</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="157" to="168" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Cross-lingual entity alignment via joint attribute-preserving embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="628" to="644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Bootstrapping Entity Alignment with Knowledge Graph Embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">TransEdge: Translating Relation-Contextualized Embeddings for Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="612" to="629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Knowledge Graph Alignment Network with Gated Multi-hop Neighborhood Aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">A Benchmarking Study of Embedding-based Entity Alignment for Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Akrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>PVLDB 13</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Towards holistic concept representations: Embedding relational knowledge, visual attributes, and distributional word semantics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thoma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Both</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ISWC</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="694" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Entity alignment between knowledge graphs using attribute embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Trisedya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Wikidata: a free collaborative knowledgebase</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vrandečić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Krötzsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="78" to="85" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Multi-modal representations for improved bilingual lexicon learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vulić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="188" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Cross-lingual knowledge graph alignment via graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="349" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">PIDGIN: ontology alignment using web text as interlingua</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wijaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CIKM</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="589" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Relation-aware entity alignment for heterogeneous knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5278" to="5284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Jointly Learning Entity and Relation Representations for Entity Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="240" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Image-embodied knowledge representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3140" to="3146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">One-Shot Relational Learning for Knowledge Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1980" to="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Cross-lingual Knowledge Graph Alignment via Graph Matching Neural Network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3156" to="3161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Aligning Cross-Lingual Entities with Multi-Aspect Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP-IJCNLP</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4422" to="4432" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">COT-SAE: CO-Training of Structure and Attribute Embeddings for Entity Alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Multi-view knowledge graph embedding for entity alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5429" to="5435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Places: A 10 million Image Database for Scene Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Neighborhoodaware attentional representation for multilingual knowledge graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<idno>1917-1926. 100 .600 ±.008 .819 ±.009 .676 ±.008 .576 ±.005 .783 ±.010 .648 ±.006 .609 ±.007 .809 ±.009 .679 ±.007 1,000 .656 ±.005 .856 ±.002 .725 ±.003 .624 ±.003 .817 ±.014 .690 ±.005 .626 ±.007 .798 ±.008 .686 ±.008 2,000 .692 ±.004 .879 ±.003 .756 ±.001 .671 ±.011 .845 ±.020 .731 ±.013 .657 ±.003 .820 ±.007 .714 ±.005 3,000 .720 ±.005 .897 ±.006 .781 ±.001 .703 ±.014 .864 ±.017 .759 ±.015 .683 ±.006 .837 ±.008 .737 ±.006 4,000 .731 ±.004 .909 ±.003 .792 ±.003 .715 ±.006 .868 ±.012 .769 ±.008 .710 ±.005 .859 ±.006 .762 ±.004 5,000 .726 ±.006 .901 ±.003 .786 ±.007 .727 ±.003 .881 ±.003 .782 ±.002 .735 ±.005 .882 ±.004 .787 ±.004 6,000 .731 ±.004 .903 ±.002 .791 ±.005 .737 ±.008 .890 ±.004 .791 ±.006 .752 ±.006 .895 ±.004 .804 ±.005 7,000 .708 ±.002 .896 ±.001 .773 ±.002 .672 ±.020 .859 ±.010 .738 ±.017 .704 ±.003 .870 ±.011 .763 ±.005</idno>
		<title level="m">Hike: A hybrid human-machine method for entity alignment in large-scale knowledge bases</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>CIKM</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
				<title level="m">Normalised weights on DBP15k. (b) Normalised weights (W/ SF) on DWY15k</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Figure 6: Normalised weights against number of epochs</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
