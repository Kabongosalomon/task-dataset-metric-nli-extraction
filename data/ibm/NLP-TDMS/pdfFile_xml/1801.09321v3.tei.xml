<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Document Image Classification with Intra-Domain Transfer Learning and Stacked Generalization of Deep Convolutional Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-08">Aug 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Das</surname></persName>
							<email>arindam.das@valeo.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saikat</forename><surname>Roy</surname></persName>
							<email>saikatroy@uni-bonn.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ujjwal</forename><surname>Bhattacharya</surname></persName>
							<email>ujjwal@isical.ac.in</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swapan</forename><forename type="middle">K</forename><surname>Parui</surname></persName>
							<email>swapan@isical.ac.in</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">CDA DVS Valeo India Pvt. Ltd. Chennai</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Institute for Informatics</orgName>
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<settlement>Bonn</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">CVPR Unit Indian Statistical Institute Kolkata</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">CVPR Unit Indian Statistical Institute Kolkata</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<settlement>Neural</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Document Image Classification with Intra-Domain Transfer Learning and Stacked Generalization of Deep Convolutional Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-08">Aug 2018</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-25T22:06+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this article, a region-based Deep Convolutional</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Documents can be classified into various classes based on their text contents and/or their structural properties. During a manual search for a particular document from a large collection of documents, knowledge about the type or structure of the document helps reduce the time necessary for the search. However, the automatic accomplishment of the same is a challenging task. In an early study <ref type="bibr" target="#b0">[1]</ref>, it was observed that a real-life document can be viewed in different ways, in both geometric and logical structure spaces. The authors observed that effective understanding of the document structure can be realized through the use of an expert system and pattern classification methods.</p><p>Automatic classification of document images is an effective initial step of various Document Image Processing (DIP) tasks such as document retrieval, information extraction and text recognition, among others. The performance of a DIP system may be enhanced through efficient initial classification of an Preprint Copy. Accepted in 24th International Conference in Pattern Recognition (ICPR), <ref type="bibr">Beijing, China, 2018.</ref> input document into a number of pre-determined categories. Automatic classification also has a significant role in indexing the documents of a Digital Library. It has been seen that any large volume of documents from different categories can be better organized provided these are first classified into several categories based on their structures <ref type="bibr" target="#b1">[2]</ref>.</p><p>With increased usage of digital means of document exchange and the growth in volume of digitized documents, the requirement of an automatic system capable of understanding their logical structures is felt significantly for better management of these documents including their efficient archiving, retrieval, information mining and so on. However, the development of an automatic system for classification of arbitrary document images into their respective true categories is computationally a non-trivial task in contrast to the case of human beings. The complexity of this task is increased due to inter-class similarity and intra-class variability issues in documents. For example, an advertisement may look like a news item or a form may be very dense with items arranged in multiple columns while another form may have only a few items with each item in a distinct horizontal row and the rows are separated wide apart. This is demonstrated by the examples shown in <ref type="figure">Fig. 1</ref>.</p><p>Intuitively, from the perspective of a classifier, documents can be characterized by their text content or structural information <ref type="bibr" target="#b2">[3]</ref>. Document classifiers based on text contents use optical character recognition (OCR) techniques to extract the texts in the document image and thus are susceptible to OCR errors. On the other hand, there are OCR systems which follow a structural analysis approach by first determining the class of the document image based on which an appropriate OCR module is employed <ref type="bibr" target="#b3">[4]</ref>. The effectiveness of such systems hinges on that of the structure classification techniques employed and hence speaks for the utility of structure learning as an important aspect of document understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Contribution</head><p>The proliferation and subsequent effectiveness of deep learning techniques in a wide spectrum of tasks in machine</p><formula xml:id="formula_0">(a) (b) (c) (d) (e) (f ) (g) (h) (i) (j) (k) (l) (m) (n) (o) (p) Fig. 1.</formula><p>Three samples from each of the sixteen classes of the RVL-CDIP database after resizing, preserving only document structure:</p><formula xml:id="formula_1">(a) Letter, (b) Memo, (c) Email, (d) Folder, (e) Form, (f ) Handwritten, (g) Invoice, (h) Advertisement, (i) Budget, (j) News, (k) Presentation, (l) Scientific Publication (m) Questionnaire, (n) Resume, (o) Scientific Report (p) Specification.</formula><p>learning over the last decade has been spoken of extensively in the literature <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Deep neural networks have been used to provide unparalleled results in multiple domains including document image classification. In the present work, deep convolutional neural networks (DCNN) are used for automatically understanding the structural aspects of a document for the purpose of classification. While DCNN based approaches are not new to this area <ref type="bibr" target="#b6">[7]</ref>- <ref type="bibr" target="#b8">[9]</ref>, the present study distinguishes itself by studying the rapid training of effective document region based classifiers. To achieve the same, multiple levels of transfer learning are used. The unique nature of the region based approach to document classification is utilized to make a case for both inter-domain and intra-domain transfer learning for this problem. Integration of the predictions from region based classifiers are done by performing a thorough study into meta-classification using stacked generalization. Finally, the proposed techniques are validated experimentally by achieving state-of-the-art results on the popular RVL-CDIP dataset containing 400,000 document image samples of 16 different categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Several studies on automatic document classification have been made in the recent past. A related survey work can be found in <ref type="bibr" target="#b2">[3]</ref>. An approach to automatic generation of a decision tree for logical labeling of business letters was proposed in <ref type="bibr" target="#b9">[10]</ref>. A 3-step approach based on certain GTree was studied in <ref type="bibr" target="#b10">[11]</ref> for partitioning a document image into its logical objects. INFOCLAS, an early prototype system for indexing and classifying printed business letters, was described in <ref type="bibr" target="#b11">[12]</ref>. In <ref type="bibr" target="#b12">[13]</ref> a machine learning based approach was proposed for automatic discovery of knowledge, that is, the relevant features for document classifiers.</p><p>Further, in <ref type="bibr" target="#b13">[14]</ref> a modified X-Y tree was used to describe a document page and its hierarchical structure provided a fixed length feature vector for a multilayer perceptron (MLP) for classification. In <ref type="bibr" target="#b14">[15]</ref>, structural classifiers in addition to k-Nearest Neighbours (kNN) and MLP classifiers were used for classification of form document images. In <ref type="bibr" target="#b15">[16]</ref>, Hidden Markov Models (HMM) were considered to be robust and suitable for handling uncertainties and noise in input document image samples. In <ref type="bibr" target="#b16">[17]</ref>, interval coding was considered to compute spatial layout of input document images and the resulting fixed length feature vector was used for its classification based on such an HMM.</p><p>In another study <ref type="bibr" target="#b1">[2]</ref>, a supervised classifier was trained using given examples from each underlying class and exploited visual similarity of document layout structure for their classification. Similarly <ref type="bibr" target="#b16">[17]</ref> also proposed document classification based on the layout similarity. In contrast, <ref type="bibr" target="#b17">[18]</ref> used a recursive representation of document structure to preserve relationship among its different parts. Also recently, in <ref type="bibr" target="#b18">[19]</ref>, certain multi- Deep learning techniques which have been popular across multiple domains such as object recognition have also been used in document structure learning tasks. Deep Convolutional Neural Networks (DCNN) are deeper variants of convolutional neural networks <ref type="bibr" target="#b19">[20]</ref> and have recently exhibited their exceptional performance in object recognition tasks <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>. In <ref type="bibr" target="#b6">[7]</ref>, a deep CNN architecture with rectified linear units was trained using dropout <ref type="bibr" target="#b22">[23]</ref> for a 10-class document image classification task, popularly known as the Tobacco3482 dataset <ref type="bibr" target="#b23">[24]</ref>. Later, in <ref type="bibr" target="#b7">[8]</ref>, the concept of Transfer Learning <ref type="bibr" target="#b24">[25]</ref> was used to improve the recognition accuracy on the same standard dataset by using a CNN pre-trained on a ImageNet dataset <ref type="bibr" target="#b25">[26]</ref>. Another work in the area which used transfer learning includes <ref type="bibr" target="#b8">[9]</ref> which also introduced region based modelling and introduced the larger 16 class RVL-CDIP dataset. In <ref type="bibr" target="#b26">[27]</ref>, a committee of lightweight supervised layerwise trained models on Tobacco3482 achieved decent results without any transfer learning. In <ref type="bibr" target="#b27">[28]</ref>, extensive exploration was done on the variation of components such as architectures, image size, aspect ratio preservation, spatial pyramidal pooling, training set size among others using the AlexNet architecture and the RVL-CDIP and ANDOC datasets. In <ref type="bibr" target="#b28">[29]</ref>, run-length and fisher vector representations trained on an MLP were compared to AlexNet and GoogLeNet architectures on the RVL-CDIP dataset with deep models showing better performance. Also, in <ref type="bibr" target="#b29">[30]</ref> AlexNet, VGG-16, GoogLeNet and ResNet-50 models were tested using Transfer Learning on the RVL-CDIP and Tobacco3482 datasets. In comparison, [?] concentrated on speed by replacing the fully connected portion of the VGG architecture with extreme learning machines (ELM).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Deep Convolutional Neural Network Architecure</head><p>DCNNs are currently one of the most popular models for deep learning. DCNNs use many of the ideas used by conventional MLPs such as feed-forward connections, non-linear activations, gradient descent and backpropagation. However, <ref type="figure">Fig. 3</ref>. Illustration of characteristic differences between the Header and Footer regions in Scientific Publication and Advertisement classes their concept of shared weights and more recently activation functions like the rectified linear unit, f (x) = max(0, x) make them resistant to the vanishing gradient problem and effective as deep learning architectures. Also, their multi-filter weight sharing concept help them discover robust features in input spaces like images and audio data making them powerful supervised classifiers. <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b30">[31]</ref> As seen earlier, they have found use in the task of document image classification utilizing images containing just the structural framework of a document without much, if any, content being legible.</p><p>From <ref type="bibr" target="#b27">[28]</ref>- <ref type="bibr" target="#b29">[30]</ref>, it was shown that the VGG16 model <ref type="bibr" target="#b31">[32]</ref> performs better on a document classification task than other DCNN models. This information is utilized by us to select the VGG16 model for our base classifier model for this task. The general architecture is shown in <ref type="figure" target="#fig_0">Fig. 2</ref> with the Adam Optimizer <ref type="bibr" target="#b32">[33]</ref> being used for training along with a learning rate decay tuned based on the accuracy on the validation set. The initial weights used are transferred from a model trained on the ImageNet object recognition dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Region based modelling for Document Classification</head><p>A combination of holistic and region based modelling for document image classification was introduced in <ref type="bibr" target="#b8">[9]</ref>. The general idea consists of training multiple machine learning models to capture influences of holistic as well as regionspecific visual cues of various document classes. For example, a scientific publication or a letter contains distinctively informative header sections than, say, an advertisement as seen in <ref type="figure">Fig 3.</ref> In contrast, the central region of a memo can be very different from that of a resume. This supports the fact that a modelling technique governed by combination of features from multiple document image regions can be effective in their classification. As in <ref type="bibr" target="#b8">[9]</ref> and <ref type="bibr" target="#b26">[27]</ref>, the various sections used for our purposes in this work include Holistic (entire image), Header, Footer, Left Body and Right Body.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Intra-Domain Transfer Learning of Region DCNNs</head><p>Transfer Learning involves the transfer of experience obtained by a machine learning model in one domain into another related domain <ref type="bibr" target="#b24">[25]</ref>. While document classification and In this work, a VGG16 model, trained on ImageNet, is used as initial weights of our holistic model thus constituting an initial level-1 (L1) transfer of weights. The L1 transfer, of course, originates from a different domain and is the regular inter-domain form of transfer learning. However, the holistic model trained on whole images of the RVL-CDIP dataset can be thought of as a generalized document feature extractor. The training sets for the region based models, although containing images of document regions and at a different scale, are still essentially images of documents. Thus, this concept is utilized by setting up another level (L2) of transfer learning in which the region based models are initialized with weights from the holistic model instead of the original VGG16 model.</p><p>The DCNN models trained are illustrated in <ref type="figure" target="#fig_1">Fig.4</ref> and can be summarized as follows: The L2 transfer is shown to demonstratively provide dividends by needing only a few iterations of fine tuning to provide excellent results. In this work, each region based model was only fine tuned for 4 iterations after L2 transfer with merely a decaying learning rate. In contrast, the VGG16-Holistic model took 25 iterations after an L1 transfer to provide equivalent convergence. This demonstrates a significant benefit for the intra-domain transfer learning approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Stacked Generalization Schemes for Model Aggregation</head><p>The strategy of stacking or stacked generalization was introduced by Wolpert <ref type="bibr" target="#b33">[34]</ref>. It is an ensemble learning technique for machine learning models designed to produce a reduced generalization error than the same of its individual base models. The idea has been used to a limited extent in the literature to combine DCNN models. It was shown in <ref type="bibr" target="#b26">[27]</ref> that stacked generalization performs significantly better than the simple winner-takes-all approaches. Stacked generalization works by training a meta-classifier on predictions of the base classifiers on a hold-out dataset to learn the final set of predictions.</p><p>In the present study, the region-based DCNN models were considered to be the base models for stacked generalization. The concatenation of the base class softmax predictions on the validation set for each base model are used to train the meta-classifier while the same on the test sets are used to get the final prediction.</p><p>Generalizing, let Q j i be the c-dimensional vector consisting of predicted probability values of the i th classifier for the j th data sample corresponding to all of the underlying c classes. If f (.) be a meta-classifier and n is the number of base classifier models, then a meta-classifier can be said to learn the mapping f : R c×n → R</p><p>The domain of f , that is, the feature space for the metaclassifier is basically just an aggregate space of the softmax outputs for each base DCNN model. Infact, the meta-feature for a sample j is simply Q j 1 ∧ Q j 2 ∧ ... ∧ Q j n where ∧ represents concatenation of the prediction vectors from the base classifiers.</p><p>For this work, c = 16 and n = 5. The three schemes studied here for generation of the meta classifier are detailed below.</p><p>The meta-classifiers used in the proposed method include:</p><p>1) Linear Regression: Involves learning a linear mapping of the input to predict the output.  In case of regression techniques used under this scheme, a simple argmax(.) was used on the output in a multivariate regression problem. The meta-classifiers were chosen to be as lightweight as possible, so as to not add further to the computational cost of training the system. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset</head><p>The developed model was tested on a subset of the IIT-CDIP Test Collection known as the RVL-CDIP dataset. The dataset consists of scanned grayscale images of documents from lawsuits against American Tobacco companies and is segregated into 16 categories or classes. A sample of the dataset can be seen in <ref type="figure">Fig. 1</ref>. The dataset is subdivided into Training, Validation and Test Sets each containing 320000, 40000 and 40000 images respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Preprocessing</head><p>The preprocessing for holistic and section-based datasets were only marginally different. The images for the Holistic dataset were initially resized to 224 × 224. For the regionbased images, the regions were extracted exactly as in <ref type="bibr" target="#b8">[9]</ref>, for the ease of comparison. The extracted regions were further resized to 224 × 224. Following the resizing, all datasets were standardized and the single image channel was duplicated to 3 channels for VGG16 compatibility.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation</head><p>It is seen in <ref type="table" target="#tab_0">Table II</ref> that the VGG16-Holistic model with L1 transfer by itself achieves a state of the art accuracy on the RVL-CDIP dataset with Adam optimizer and gradual learning rate decay based on the validation set accuracy. Of course, the stacked generalized ensemble performs even better setting a benchmark at 92.21%. However, if the region models were trained simply with L1 transfer, the gain could be argued to be too less given the computational cost of training multiple large models (each model having 130 million parameters).</p><p>As mentioned earlier, while the holistic model took about 25 iterations after the L1 transfer to converge, the VGG16-Region models took only 4 iterations after L2 transfer to show comparable results. The performance can be further evaluated by referring to <ref type="table" target="#tab_0">Table I</ref>. Every region based model in this work after only a few iterations of training (or fine tuning) easily surpasses the slightly smaller AlexNet models trained in <ref type="bibr" target="#b8">[9]</ref> by L1 type transfer learning. The effectiveness of the L2 transfer significantly reduces training time for the region based models and eases the computational cost of training multiple models, while preserving benefits characterized by the gain in accuracy.</p><p>Finally, extensive experiments into meta-classifiers for stacked generalization demonstrate that fully connected MLNNs, otherwise known as MLPs, are the clear favorite as the second level meta-classifier. The second best performance, perhaps unsurprisingly, is by Bagging since it is itself an ensemble technique utilizing the second best individual metaclassifier in this work, that is, SVMs. <ref type="figure" target="#fig_4">Fig. 5</ref> demonstrates the comparative predictive performance of the various metaclassifiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this work, rapid training of region based DCNNs has been explored with multiple levels of transfer learning. The similarity between region based and the holistic input spaces facilitates the usage of intra-domain transfer learning in addition to the general inter-domain variant. This allows fast convergence and feasibility of region based models in what would otherwise be an unnecessarily unwieldy machine learning problem. Also, a thorough experimentation of stacked generalization has been performed with multiple meta-classification algorithms. Finally, a state-of-the-art result was not only set on the holistic model at 91.11% but also on the final stacked generalized model at 92.21% accuracy on the RVL-CDIP dataset, representing a significant gain over the existing methods. In the future, faster but less accurate models such as <ref type="bibr" target="#b29">[30]</ref> could be explored as with region based intra-domain transfer for building effective ensemble models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>VGG16 Architecture with Softmax layer replaced used as the base model for each classifier scale run length histograms for representation of document images and a generative classifier model for efficient classification were proposed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 4 .</head><label>4</label><figDesc>Flowchart of Proposed Model for Document Image Classification with L1 and L2 Transfer Learning object classification apparently seem like divergent domains, architectures trained on the 1000 class ImageNet dataset have proven to function as generalized feature extractors. Region based training of document recognizers on an architecture such as the VGG architectures creates an infeasible learning problem due to the sheer training time of such a model. For example, each VGG16 model contains more than 130 million trainable parameters. This makes training from scratch (VGG16 on ImageNet weights) on each region-based model computationally prohibitive. However, the nature of training region based models creates a unique scenario that can be used to bypass this predicament.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>-</head><label></label><figDesc>VGG16-Holistic: Trained with whole images from the RVL-CDIP dataset. The initial weights transferred (L1) from the VGG16 model trained on the ImageNet dataset. -VGG16-Header/Footer/LeftBody/RightBody: Trained with the Header/Footer/Left Body/Right Body section of RVL-CDIP images. The initial weights are transferred (L2) from the fully trained VGG16-Holistic model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>2 )</head><label>2</label><figDesc>Ridge Regression: Linear regression with l2regularization. 3) K-Nearest Neighbours (kNN): Instance space learning algorithm which classifies a point by the majority of the labels of its k nearest neighbours. Values of k tested were 32, 64 and 128. 4) Support Vector Machine (SVM): SVMs are popular supervised learning models which are maximum margin separators. Here, an SVM with an RBF kernel was used.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Comparison of Accuracies for different meta-classifiers in Stacked Generalization</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I COMPARISON</head><label>I</label><figDesc>OF ACCURACY % BETWEEN HARLEY ET AL. AND PROPOSED METHOD (ROUNDED OFF TO 1 DECIMAL PLACE) ON THE RVL-CDIP TEST SET</figDesc><table><row><cell>DCNN Model</cell><cell cols="2">Harley et al.</cell><cell>Proposed Work</cell></row><row><cell>Holistic</cell><cell></cell><cell>89.8</cell><cell>91.1</cell></row><row><cell>Header</cell><cell></cell><cell>84.9</cell><cell>86.0</cell></row><row><cell>Footer</cell><cell></cell><cell>79.4</cell><cell>81.2</cell></row><row><cell>Left Body</cell><cell></cell><cell>82.7</cell><cell>85.2</cell></row><row><cell>Right Body</cell><cell></cell><cell>79.5</cell><cell>82.2</cell></row><row><cell cols="2">Ensemble of Models</cell><cell>89.3</cell><cell>92.2</cell></row><row><cell></cell><cell cols="2">TABLE II</cell></row><row><cell cols="4">COMPARISON OF ACCURACIES ON RVL-CDIP OF BEST MODELS FROM</cell></row><row><cell cols="4">DIFFERENT TECHNIQUES</cell></row><row><cell>Publication</cell><cell>Accuracy</cell><cell></cell><cell>Comments</cell></row><row><cell></cell><cell></cell><cell cols="2">Document section-based models</cell></row><row><cell>Harley et al. [9]</cell><cell>89.80%</cell><cell cols="2">with weight transfer from Alexnet</cell></row><row><cell></cell><cell></cell><cell cols="2">with max voting ensemble</cell></row><row><cell></cell><cell></cell><cell cols="2">Uses AlexNet architecture with</cell></row><row><cell>Tensmeyer et al. [28]</cell><cell>89.31%</cell><cell cols="2">spatial pyramidal pooling, without</cell></row><row><cell></cell><cell></cell><cell cols="2">transfer learning</cell></row><row><cell></cell><cell></cell><cell cols="2">Same architecture as above with</cell></row><row><cell>Tensmeyer et al. [28]</cell><cell>90.94%</cell><cell cols="2">images resized to 384 × 384 and</cell></row><row><cell></cell><cell></cell><cell cols="2">aspect ratio preservation</cell></row><row><cell></cell><cell></cell><cell cols="2">The GoogLeNet architecture was</cell></row><row><cell>Csurka et al. [29]</cell><cell>90.70%</cell><cell cols="2">used with ImageNet based transfer</cell></row><row><cell></cell><cell></cell><cell>learning</cell></row><row><cell></cell><cell></cell><cell cols="2">Weights transfer from AlexNet,</cell></row><row><cell>Afzal et al. [30]</cell><cell>90.97%</cell><cell cols="2">VGG-16, GoogLeNet and ResNet-</cell></row><row><cell></cell><cell></cell><cell>50</cell></row><row><cell></cell><cell></cell><cell cols="2">Trained on full document images</cell></row><row><cell>Proposed Work</cell><cell>91.11%</cell><cell cols="2">with weights transfer from VGG-</cell></row><row><cell></cell><cell></cell><cell cols="2">16 trained on Imagenet</cell></row><row><cell></cell><cell></cell><cell cols="2">MLNN based stacking of holistic</cell></row><row><cell>Proposed Work</cell><cell>92.21%</cell><cell cols="2">&amp; region-based models with inter</cell></row><row><cell></cell><cell></cell><cell cols="2">and intra-domain weights transfer</cell></row><row><cell cols="4">5) Bootstrap Aggregating (with SVM): Also known as</cell></row><row><cell cols="4">bagging, it is a meta-classifier which works by sampling</cell></row><row><cell cols="4">subsets (bags) of the input data and training multiple</cell></row><row><cell cols="4">base classifiers (SVM in this case) and aggregating</cell></row><row><cell cols="4">the results. Here, 30 bootstrap samples each with 7500</cell></row><row><cell cols="3">training examples were used.</cell></row><row><cell cols="4">6) Extreme Learning Machine (ELM): ELMs (described</cell></row><row><cell cols="4">simplistically) involve randomly assigning weights in</cell></row><row><cell cols="4">the hidden units and train extremely fast compared to</cell></row><row><cell cols="4">traditional neural networks. A hidden layer of 100 units</cell></row><row><cell cols="3">was used in our experiments.</cell></row><row><cell cols="4">7) Multilayer Neural Network (MLNN): A 3-layer fully</cell></row><row><cell cols="4">connected neural network (256-256-16) with ReLU ac-</cell></row><row><cell cols="4">tivation units and heavy dropout rate of 0.75 to control</cell></row><row><cell cols="4">overfitting between layers trained using Adam optimizer.</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Document analysis and understanding: A brief survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Suen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int. Conf. on Document Analysis and Recognition</title>
		<meeting>of Int. Conf. on Document Analysis and Recognition</meeting>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="page" from="17" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Classification of document pages using structure-based features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Doc. Anal. and Recognition</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="232" to="247" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey of document image classification: problem statement, classifier architecture and performance evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Blostein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Journal of Document Analysis and Recognition</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Automatic document classification and indexing in highvolume applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Appiani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cesarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Colla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Diligenti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. Journal of Document Analysis and Recognition</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="69" to="83" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="issue">7553</biblScope>
			<biblScope unit="page" from="436" to="444" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">22nd International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3168" to="3172" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Capobianco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 13th Int. Conf. on Document Analysis and Recognition (ICDAR)</title>
		<meeting>of the 13th Int. Conf. on Document Analysis and Recognition (ICDAR)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1111" to="1115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Evaluation of deep convolutional nets for document image classification and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ufkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Derpanis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Document Analysis and Recognition (ICDAR), 2015 13th International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="991" to="995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Initial learning of document structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of Int. Conf. on Document Analysis and Recognition</title>
		<meeting>of Int. Conf. on Document Analysis and Recognition</meeting>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="86" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">About the logical partitioning of document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<pubPlace>Nevada (United States</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Nevada University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. Rep</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Using ir techniques for text classification in document analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGIR &apos;94: Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>B. W. Croft and C. J. van Rijsbergen</editor>
		<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Evaluating ocr and non-ocr text representations for learning document classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Junker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hoch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th International Conference on Document Analysis and Recognition</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="1060" to="1066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Encoding of modified x-y trees for document classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cesarini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lastri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marinai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Soda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 6th Int. Conf. on Doc. Anal. and Recog</title>
		<meeting>of the 6th Int. Conf. on Doc. Anal. and Recog</meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="1131" to="1136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Classification method study for automatic form class identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Héroux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Diana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ribert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Trupin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of the 14th Int. Conf. on Patt. Recog</title>
		<meeting>of the 14th Int. Conf. on Patt. Recog</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="926" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A tutorial on hidden markov models and selected applications in speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Readings in Speech Recognition</title>
		<editor>A. Waibel and K.-F. Lee</editor>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1990" />
			<biblScope unit="page" from="267" to="296" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Comparison and classification of documents based on layout similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wilfong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="227" to="243" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Hidden tree markov models for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Diligenti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="519" to="523" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Large-scale document image retrieval and classification with runlength histograms and binary embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Valveny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1898" to="1905" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1106" to="1114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Dropout: A simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Structural similarity for document image classification and retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Doermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="119" to="126" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Knowl. and Data Eng</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. of IEEE Conf. on CVPR</title>
		<meeting>of IEEE Conf. on CVPR</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Generalized stacking of layerwise-trained deep convolutional neural networks for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bhattacharya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">23rd International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1273" to="1278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Analysis of convolutional neural networks for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tensmeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Martinez</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.03273</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">What is the right way to represent document images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Larlus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Almazan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01076</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Cutting the error by half: Investigation of very deep cnn and advanced training strategies for document image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kölsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liwicki</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.03557</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep convolutional neural networks for lvcsr</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Sainath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kingsbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ramabhadran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Acoustics, Speech and Signal Processing (ICASSP), 2013 IEEE International Conference on</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="8614" to="8618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Stacked generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
