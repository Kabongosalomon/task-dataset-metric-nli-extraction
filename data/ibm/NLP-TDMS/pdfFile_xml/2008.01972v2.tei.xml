<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ontology-driven weak supervision for clinical entity classification in electronic health records</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">A</forename><surname>Fries</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Biomedical Informatics Research</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Steinberg</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Biomedical Informatics Research</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<addrLine>April 7</addrLine>
									<postCode>2021</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saelig</forename><surname>Khattar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Stanford University</orgName>
								<address>
									<addrLine>April 7</addrLine>
									<postCode>2021</postCode>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">L</forename><surname>Fleming</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Biomedical Informatics Research</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jose</forename><surname>Posada</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Biomedical Informatics Research</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alison</forename><surname>Callahan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Biomedical Informatics Research</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigam</forename><forename type="middle">H</forename><surname>Shah</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Biomedical Informatics Research</orgName>
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Ontology-driven weak supervision for clinical entity classification in electronic health records</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the electronic health record, using clinical notes to identify entities such as disorders and their temporality (e.g. the order of an event relative to a time index) can inform many important analyses. However, creating training data for clinical entity tasks is time consuming and sharing labeled data is challenging due to privacy concerns. The information needs of the COVID-19 pandemic highlight the need for agile methods of training machine learning models for clinical notes. We present Trove, a framework for weakly supervised entity classification using medical ontologies and expert-generated rules. Our approach, unlike hand-labeled notes, is easy to share and modify, while offering performance comparable to learning from manually labeled training data. In this work, we validate our framework on six benchmark tasks and demonstrate Trove's ability to analyze the records of patients visiting the emergency department at Stanford Health Care for COVID-19 presenting symptoms and risk factors.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Analyzing text to identify concepts such as disease names and their associated attributes like negation are foundational tasks in medical natural language processing (NLP). Traditionally, training classifiers for named entity recognition (NER) and cue-based entity classification have relied on hand-labeled training data. However annotating medical corpora requires considerable domain expertise and money, creating barriers to using machine learning in critical applications <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref>. Moreover, hand-labeled datasets are static artifacts that are expensive to change. The recent COVID-19 pandemic highlights the need for machine learning tools that enable faster, more flexible analysis of clinical and scientific documents in response to rapidly unfolding events <ref type="bibr" target="#b2">[3]</ref>.</p><p>To address the scarcity of hand-labeled training data, machine learning practitioners increasingly turn to lower cost, less accurate label sources to rapidly build classifiers. Instead of requiring hand-labeled training data, weakly supervised learning relies on task-specific rules and other imperfect labeling strategies to programmatically generate training data. This approach combines the benefits of rule-based systems, which are easily shared, inspected and modified, with machine learning which typically improves performance and generalization properties. Weakly supervised methods have demonstrated success across a range of NLP and other settings <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref> .</p><p>Knowledge bases and ontologies provide a compelling foundation for building weakly supervised entity classifiers. Ontologies codify a vast amount of medical knowledge via taxonomies and example instances for millions of medical concepts. However, repurposing ontologies for weak supervision creates challenges when combining label information from multiple sources without access to ground truth labels. The hundreds of terminologies found in the Unified Medical Language System (UMLS) Metathesaurus <ref type="bibr" target="#b8">[9]</ref> and other sources <ref type="bibr" target="#b9">[10]</ref> typify the highly redundant, conflicting, and imperfect entity definitions found across medical ontologies. Naively combining such conflicting label assignments can cause substantial performance drops in weakly supervised classification <ref type="bibr" target="#b10">[11]</ref>; therefore, a key challenge is correcting for labeling errors made by individual ontologies when combining label information.</p><p>Rule-based systems for NER and cue detection <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref> are common in clinical text processing, where labeled corpora are difficult to share due to privacy concerns. Generating imperfect training labels from indirect sources (e.g., patient notes) is often used in analyzing medical images <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>. Recent work has explored learning the accuracies of sources to correct for label noise when using rule-based systems to generate training data for text classification <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b16">17]</ref>. Weakly supervised clinical applications have explored document and relation classification using task-specific rules <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19]</ref> or leveraging dependency parsing and compositional grammars to automate relation classification for standardizing clinical concepts <ref type="bibr" target="#b19">[20]</ref>. However these largely focus on relation and document classification via task-specific labeling rules or sourcing supervision from a single ontology and do not explore NER or automating labeling via multiple ontologies.</p><p>Prior research on weakly supervised NER has required complex preprocessing to identify possible entity spans <ref type="bibr" target="#b20">[21]</ref>, generated labels from a single source rather than combining multiple sources <ref type="bibr" target="#b21">[22]</ref>, or relied on ad hoc rule engineering <ref type="bibr" target="#b22">[23]</ref>. High impact application areas, such as clinical NER using weak supervision, are largely unstudied. Recent weak supervision frameworks such as Snorkel <ref type="bibr" target="#b10">[11]</ref> are domain and task-agnostic, introducing barriers to quickly developing and deploying labeling heuristics in complex domains such as medicine. Key questions remain about the extent to which we can automate weak supervision using existing medical ontologies and how much additional task-specific rule engineering is required for state-of-the-art performance. It is also unclear whether, and by how much, pre-trained language models such as BioBERT <ref type="bibr" target="#b23">[24]</ref> improve the ability to generalize from weakly labeled data and reduce the need for task-specific labeling rules.</p><p>We present a Trove, a framework for training weakly supervised medical entity classifiers using off-the-shelf ontologies as a source of reusable, easily automated labeling heuristics. Doing so transforms the work of using weak supervision from that of coding task-specific labeling rules to defining a target entity type and selecting ontologies with sufficient coverage for a target dataset, which is a common interface for popular biomedical annotation tools such as NCBO BioPortal and MetaMap <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b24">25]</ref>. We examine whether ontology-based weak supervision, coupled with recent pre-trained language models such as BioBERT, reduces the engineering cost of creating entity classifiers while matching performance of prior, more expensive, weakly supervised approaches. We further investigate how ontology-based labeling functions can be extended when we need to incorporate additional, task-specific rules. The overall pipeline is shown in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>In this work, we demonstrate the utility of Trove through six benchmark tasks for clinical and scientific text, reporting state-of-the-art weakly supervised performance (i.e., using no hand-labeled training data) on NER datasets for chemical/disease and drug tagging. We further present weakly supervised baselines for two tasks in clinical text: disorder tagging and event temporality classification. Using ablation analyses, we characterize the performance trade-offs of training models with labels generated from easily automated ontology-based weak supervision vs. more expensive, task-specific rules. Finally, we present a case study deploying Trove for COVID-19 symptom tagging and risk factor monitoring using a daily data feed of Stanford Health Care emergency department notes.</p><p>Weakly supervised learning is an umbrella term referring to methods for training classifiers using imperfect, indirect, or limited labeled data and includes techniques such as distant supervision <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b26">27]</ref>, co-training <ref type="bibr" target="#b27">[28]</ref> and others <ref type="bibr" target="#b28">[29]</ref>. Prior approaches for weakly supervised NER such as co-training use a small set of labeled seed examples <ref type="bibr" target="#b29">[30]</ref> which are iteratively expanded through bootstrapping or self-training <ref type="bibr" target="#b30">[31]</ref>. Semi-supervised methods also use some amount of labeled training data and incorporate unlabeled data by imposing constraints on properties such as expected label distributions <ref type="bibr" target="#b31">[32]</ref>. Distant supervision requires no labeled training data, but typically focuses on a single source for labels such as AutoNER <ref type="bibr" target="#b21">[22]</ref>, which used phrase mining and a tailored dictionary of canonical entity names to construct a more precise labeler, rather than unifying labels assigned using heterogeneous sources of unknown quality. Crowdsourcing methods combine labels from multiple human annotators with unknown accuracy <ref type="bibr" target="#b32">[33]</ref>. However compared to human labelers, programmatic label assignment has different correlation and scaling properties which create technical challenges when combining sources. Data programming <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b16">17]</ref> formalizes theory for combining multiple label sources with different coverage and unknown accuracy as well as correlation structure to correct for labeling errors.</p><p>In the setting of weakly supervised NER and sequence labeling, SwellShark <ref type="bibr" target="#b20">[21]</ref> uses a variant of data programming to train a generative model using labels from multiple dictionary and rule-based sources. However this approach required task-specific preprocessing to identify candidate entities a priori to achieve competitive performance. Safranchik et al. <ref type="bibr" target="#b22">[23]</ref> presented WISER, a linked hidden Markov model where weak supervision was defined separately over tags and tag transitions using linking rules derived from language models, ngram statistics, mined phrases and custom heuristics to train a BiLSTM-CRF. SwellShark and WISER both focused on hand-coded, task-specific labeling function design.</p><p>Trove advances weakly supervised medical entity classification by: (1) eliminating the requirement for identifying probable entity spans a priori by combining word-level weak supervision with contextualized word embeddings;</p><p>(2) developing general purpose, more easily automated ontology-based labeling functions which reduce the need for engineering hand-coded rules; (3) quantifying the relative contributions of sources of label assignment -such as pre-existing ontologies from the UMLS (low cost) and task-specific rule engineering (high cost) -to the achieved performance for a task; and (4) evaluating Trove in a deployed medical setting, tagging symptoms and risk factors of COVID-19.  Users specify: (I) a mapping of an ontology's class categories to entity classes; (II) a set of label sources (e.g., ontologies, task-specific rules) for weak supervision; and (III) a collection of unlabeled document sentences with which to build a training set. Ontologies instantiate labeling function templates which are applied to sentences to generate a label matrix. This matrix is used to train the label model which learns source accuracies and corrects for label noise to predict a consensus probability per word. Consensus labels are transformed into the probabilistic sequence label dataset which is used as training data for an end model (e.g., BioBERT). Alternatively, the label model can also be used as the final classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Train End Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment overview</head><p>After quantifying the performance of ontology-driven weak supervision in all our tasks, we performed four experiments. First, we examined performance differences by label source ablations, which compared ontologybased labeling functions against those incorporating task-specific rules. Second, we compared Trove to existing weakly supervised tagging methods. Third, we examined learning source accuracies for UMLS terminologies. Finally we report on a case study that used Trove to monitor emergency department notes for symptoms and risk factors associated with patients tested for COVID-19.</p><p>We evaluated four methods of combining labeling functions to train entity classifiers. (1) Majority vote (MV) is the majority class for each word predicted by all labeling functions. In cases of abstain or ties, predictions default to the majority class. For reference, we also included published F1 metrics for state-of-the-art (SOTA) supervised performance for each task, as determined to the best of our knowledge. Note some published SOTA benchmarks (e.g., BC5CDR in Lee et al. <ref type="bibr" target="#b23">[24]</ref>) use both the hand-labeled train and validation sets for training, so they are not directly comparable to our experimental setup. <ref type="table">Table 1</ref> reports F1 performance for weak supervision using ontology-based labeling functions and those incorporating additional, task-specific rules. For NER tasks, adding task-specific rules performed within 1.3 -4.9 F1 points (4.1%) of models trained on hand-labeled data and for span tasks within 3.4 -13.3 F1 points. The total number of task-specific labeling functions used ranged from 9 to 27. For ontology-based supervision, the label model improved performance over MV by 4.1 F1 points on average and BioBERT provided an additional average increase of 0.3 F1 points.  <ref type="table">Table 1</ref>: F1 scores for ontology and task-specific rule-based weak supervision. Models are majority vote (MV); label model (LM); weakly supervised BioBERT (WS); our fully supervised BioBERT (FS); and published state-of-the-art (SOTA). LFs denote labeling function counts or total added task-specific rules. Bold indicates the best score for each approach and task. Scores are the mean and ±1 SD of n=10 random weight initializations. A two-sided Wilcoxon signed-rank test was used to compute statistical significance. * denotes p &lt; 0.05 for difference between weakly supervised BioBERT (WS) and the label model (LM). For (chemical, disease, disorder, drug) exact p-values for ontologies were (0.0039, 0.0020, 0.0020, 0.0020) and for task-specific rules (0.0020, 0.3223, 0.0020, 0.0020). For Negation p=0.0273 and for DocTimeRel p=0.0020. † denotes p &lt; 0.05 for difference between the label model (LM) and majority vote (MV). Here all task p-values were 0.0020. ∼ Mowery et al. <ref type="bibr" target="#b37">[38]</ref> only reported accuracy for the negation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance of Trove in medical entity classification tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Labeling source ablations</head><p>For NER tasks, we examined five ablations, ordered by increasing cost of labeling effort. Tiers 1-4 are additive and include all prior levels. We initialized labeling function templates as follows:</p><p>For ontology-based labeling functions, we used the UMLS Semantic Network and corresponding Semantic Groups as our entity categories and defined a mapping of semantic types (STYs) to target class labels y ∈ {−1, 0, 1}. Non-UMLS ontologies that did not provide semantic type assignments (e.g., ChEBI) were mapped to a single class label. All UMLS terminologies v were ranked by term coverage on the unlabeled training set, defined as each term's document frequency summed by terminology, and the top s terminologies were used to initialize templates, where s was tuned with a validation set. The remaining (v s+1 , ..., v 92 ) UMLS terminologies were merged into a single labeling function to ensure all terms in the UMLS were included. UMLS synsets were constructed using concept unique identifiers (CUIs) and templates were initialized with the union of all terminologies and fixed across all NER tasks.</p><p>For task-specific labeling functions, we evaluated our ability to supplement ontology-based supervision with hand-coded labeling functions and estimated the relative performance contribution of adding these task-specific rules. All training set documents were preprocessed to tag entities using the ontology-based labeling functions outlined above and indexed to support search queries for efficient data exploration. The design of task-specific labeling functions is a mix of data exploration, i.e., looking at entities identified by ontology labeling functions to identify errors, and similarity search to identify common, out-of-ontology concept patterns. Only the training set was examined during this process and the test set was held out during all labeling function development and model tuning.</p><p>For NER, we used two rule types to label concepts: (1) pattern matching via regular expressions and small dictionaries of related terms (e.g., illegal drugs); and (2) bigram word co-occurrence graphs from ontologies to support fuzzy span matching. Pattern matching comprised the majority of our task-specific labeling functions. While task-specific labeling functions codify generalized patterns not captured by ontologies, we also note that a number of our task-specific labeling functions were necessary due to the idiosyncratic nature of ground truth labels in benchmark tasks. For example, in the i2b2/n2c2 drug tagging task, annotation guidelines included more complex, conditional entity definitions, such as not labeling negated or historical drug mentions. We incorporated these guidelines using the Negation and DocTimeRel labeling functions described below. See <ref type="figure" target="#fig_0">Supplementary Fig. 1</ref> and Supplementary Note for a more detailed example of designing task-specific labeling functions.</p><p>For span tasks, which classify Negation and DocTimeRel for pre-identified entities, we do not use ontology-based labeling functions directly for supervision. Instead, ontology-tagged entities were used to guide development of labeling functions that search left and right context windows around a target entity for cue phrases. Designing search patterns for left and right context windows is the same strategy used by NegEx/ConText <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b38">39]</ref> to assign negation and temporal status. For Negation, we built on NegEx by adding additional patterns found via exploration of the training documents. For DocTimeRel we used a heuristic based on the nearest explicit datetime mention (in token distance) to an event mention <ref type="bibr" target="#b39">[40]</ref>. Additional contextual pattern matching rules were added to detect other cues of event temporality, e.g., using section headers such as past medical history to identify events occurring before the note creation time.   Incorporating source accuracies into BioBERT training provided significant benefits when combining high precision sources with low precision/high recall sources. In the case of chemical tagging with MV, the UMLS tier (red) outperformed UMLS+Other (orange) by 1.8 F1 points (81.6 vs. 79.8). This was due to adding the ChEBI ontology which increased recall but only had 65% word-level precision. Majority vote cannot learn or utilize this information, so naively adding ChEBI labels hurt performance. However the label model learned ChEBI's accuracy to take advantage of the noisier, but higher coverage signal, thus the WS UMLS+Other (orange+white) outperformed UMLS ((red+white)) by 2.5 F1 points (88.0 vs 85.5). See <ref type="table" target="#tab_6">Supplementary Tables  1-4</ref> for complete performance metrics across all ablation tiers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparing Trove with existing weakly supervised methods</head><p>We compared Trove to three existing weakly supervised methods for NER and sequence labeling: SwellShark <ref type="bibr" target="#b20">[21]</ref>, AutoNER <ref type="bibr" target="#b21">[22]</ref>, and WISER <ref type="bibr" target="#b22">[23]</ref>. We compared performance on BC5CDR (the combination of disease and chemical tasks) against all methods and on the i2b2/n2c2 drug task for SwellShark. All performance numbers are for models trained on the original training set split, with the exception of SwellShark which is trained on an additional 25,000 weakly labeled documents. All weakly supervised methods use the labeling functions, preprocessing, and dictionary curation methods as described in the original manuscripts. <ref type="table">Table 2</ref> compares Trove with these existing weakly supervised methods. Our ontology-based approach outperformed AutoNER by 1.7 F1 points. For models incorporating task-specific rules, we outperformed the best weakly supervised model SwellShark by 1.9 F1 points. SwellShark reported F1 scores on the i2b2/n2c2 drug task of 78.3 for dictionaries and 83.4 for task-specific rules. Our best models achieved 79. <ref type="bibr" target="#b1">2</ref>   <ref type="table">Table 2</ref>: Comparison of Trove against existing weakly supervised NER methods. Precision (P), recall (R), and F1 scores for the BC5CDR task. Underlined numbers indicates the best weakly supervised score using only dictionaries/ontologies and bold indicates the best score using custom rules. For this task, ontology-based supervision alone outperformed existing weakly supervised methods except for SwellShark which required custom rules and candidate generation. Incorporating task-specific rules into Trove further improved performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UMLS terminologies as plug-and-play weak supervision</head><p>Biomedical annotators such as NCBO BioPortal require selecting a set of target ontologies/terminologies to use for labeling. Since Trove is capable of automatically combining noisy terminologies, given a shared semantic type definition, we tested the ability to avoid selecting specific UMLS terminologies for use as supervision sources. This is challenging because estimating accuracies with the label model requires observing agreement and disagreement among multiple label sources, however it is non-obvious how to partition the UMLS, which contains many terminologies, into labeling functions. The naive extremes are to either create a single labeling function from the union of all terminologies or include all terminologies as individual labeling functions.</p><p>To explore how partitioning choices impact label model performance, we held all non-UMLS labeling functions fixed across all ablation tiers and computed performance across s = (1, ..., 92) partitions of the UMLS by terminology. All scores were normalized to the best global majority vote score per tier, selected using the best s choice evaluated on the validation set, to assess the impact of correcting for label noise. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case study in rapidly building clinical classifiers</head><p>We deployed Trove to monitor emergency departments for patients undergoing COVID-19 testing, analyzing clinical notes for presenting symptoms/disorders and risk factors <ref type="bibr" target="#b40">[41]</ref>. This required identifying disorders and defining a novel classification task for exposure to a confirmed COVID-19 positive individual, a risk factor informing patient contact tracing. The dataset consisted of daily dumps of emergency department notes from Stanford Health Care (SHC), beginning in March 2020. Our study was approved by the Stanford University Administrative Panel on Human Subjects Research, protocol #24883 and included a waiver of consent. All included patients from SHC signed a privacy notice which informs them that their records may be used for research purposes given approval by the IRB, with study procedures in place to protect patient confidentiality.</p><p>We manually annotated a gold test set of 20 notes for all mentions of disorders and 776 notes for mentions of a positive COVID exposure. Two clinical experts generated gold annotations which were adjudicated for disagreements by authors AC and JAF. As a baseline for disorder tagging, we used the fully supervised ShARe/CLEF disorder tagger. This reflects a readily available, but out-of-distribution training set (MIMIC-II <ref type="bibr" target="#b41">[42]</ref> vs. SHC). We used the same disorder labeling function set as our prior experiments, adding one additional dictionary of COVID terms <ref type="bibr" target="#b42">[43]</ref>. BioBERT was trained using 2482 weakly-labeled documents. Custom labeling functions were written for the exposure task and models were trained on 14k sentences.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Our experiments demonstrate the effectiveness of using weakly supervised methods to train entity classifiers using off-the-shelf ontologies and without requiring hand-labeled training data. Medical ontologies are freely available sources of weak supervision for NLP applications <ref type="bibr" target="#b43">[44]</ref> and in several NER tasks, our ontology-only weakly supervised models matched or outperformed more complex weak supervision methods in the literature. Our work also highlights how domain-aware language models, such as BioBERT, can be combined with weak supervision to build low-cost and highly performant medical NLP classifiers.</p><p>Rule-based approaches are common tools in scientific literature analysis and clinical text processing <ref type="bibr" target="#b44">[45]</ref>.</p><p>Our results suggest that engineering task-specific rules in addition to labels provided by ontologies provides strong performance for several NER tasks -in some cases approaching the performance of systems built using hand-labeled data. We further demonstrated how leveraging the structure inherent in knowledge bases such as the UMLS to estimate source accuracies and correct for label noise provides substantial performance benefits. We find that the classification performance of the label model alone is strong, with BioBERT providing modest gains of 1.0 F1 points on average. Since the label model is orders of magnitude more computationally efficient to train than BERT-based models, in many settings (e.g., limited access to high-end GPU hardware) the label model alone may suffice.</p><p>Our tasks reflect a wide range of difficulty. Clinical tasks required more task-specific rules to address the increased complexity of entity definitions and other non-grammatical, sub-language phenomena <ref type="bibr" target="#b45">[46]</ref>. Here custom rules improved clinical tasks an average of 8.1 F1 points vs. 2.1 points for scientific literature. Moreover, adding non-UMLS ontologies to PubMed tasks consistently improved overall performance while providing littleto-no benefit for our clinical tasks. Annotation guidelines for our clinical tasks also increased complexity. The i2b2/n2c2 drug task combines several underlying classification problems (e.g., filtering out negated medications, patient allergies, and historical medications) into a single tagging formulation. This extends beyond entity typing and requires more complex, cue-driven rule design.</p><p>Manually labeling training data is time consuming and expensive, creating barriers to using machine learning for new medical classification tasks. Sometimes, there is a critical need to rapidly analyze both scientific literature and unstructured electronic health record data -as in the case of the COVID-19 pandemic when we need to understand the full repertoire of symptoms, outcomes, and risk factors at short notice <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48]</ref>. However, sharing patient notes and constructing labeled training sets presents logistical challenges, both in terms of patient privacy and in developing infrastructure to aggregate patient records <ref type="bibr" target="#b48">[49]</ref>. In contrast, labeling functions can be easily shared, edited, and applied to data across sites in a privacy preserving manner to rapidly construct classifiers for symptom tagging and risk factor monitoring.</p><p>This work has several limitations. Our task-specific labeling functions were not exhaustive and only reflect lowcost rules easily generated by domain experts. Additional rule development could lead to improved performance. In addition, we did not explore data augmentation or multi-task learning in the BioBERT model, which may further mitigate the need to engineer task-specific rules. There is considerable prior work developing machine learning models for tagging disease, drug, and chemical entities that could be incorporated as labeling functions. However, our goal was to explore performance tradeoffs in settings where existing machine learning models are not available. Our framework leverages the wide range of medical ontologies available for English language settings, which provides considerable advantages for weakly supervised methods. Additional work is needed to characterize the extent to which the framework can benefit tasks in non-English settings.</p><p>Combining labels from multiple ontology sources violates an independence assumption of data programming as used in this work, because for any pair of source ontologies we may have correlated noise. This restriction applies to all label sources, but is more prevalent in cases with extremely similar label sources, as can occur with ontologies. In our experiments, for a small number of sources, the impact was minor, however performance tended to decrease after including more than 20 ontologies. Additional research into unsupervised methods for structure learning <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b50">51]</ref>, i.e., learning dependencies among sources from unlabeled data, could further improve performance or mitigate the need to limit the number of included ontologies.</p><p>Identifying named entities and attributes such as negation are critical tasks in medical natural language processing. Manually labeling training data for these tasks is time consuming and expensive, creating a barrier to building classifiers for new tasks. The Trove framework provides ontology-driven weak supervision for medical entity classification and achieves state-of-the-art weakly supervised performance in the NER tasks of recognizing chemicals, diseases, and drugs. We further establish new weakly supervised baselines for disorder tagging and classifying the temporal order of an event entity relative to its document timestamp. The weakly supervised NER classifiers perform within 1.3 -4.9 F1 points of classifiers trained with hand-labeled data. Modeling the accuracies of individual ontologies and rules to correct for label noise improved performance in all of our entity classification tasks. Combining pre-trained language models such as BioBERT with weak supervision results in an additional improvement in most tasks.</p><p>The Trove framework demonstrates how classifiers for a wide range of medical NLP tasks can be quickly constructed by leveraging medical ontologies and weak supervision without requiring manually labeled training data. Weakly supervised learning provides a mechanism for combining the generalization capabilities of state-of-the-art machine learning with the flexibility and inspectability of rule-based approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets and tasks</head><p>We analyze two categories of medical tasks using six datasets: (1) NER; and (2) span classification where entities are identified a priori and classified for cue-driven attributes such as negation or document relative time i.e., the order of an event entity relative to the parent document's timestamp. Both categories of tasks are formalized as token classification problems, either tagging all words in a sequence (NER) or just the head words for an entity set (span classification). <ref type="table" target="#tab_6">Table 4</ref> contains summary statistics for all six datasets. All documents were preprocessed using a spaCy <ref type="bibr" target="#b51">[52]</ref> pipeline optimized for biomedical tokenization and sentence boundary detection <ref type="bibr" target="#b18">[19]</ref>.</p><p>Our COVID-19 case study used a daily feed of emergency department notes from Stanford Health Care (SHC), beginning in March 2020. Our study was approved by the Stanford University Administrative Panel on Human Subjects Research, protocol #24883 and included a waiver of consent. All included patients from SHC signed a privacy notice which informs them that their records may be used for research purposes given approval by the IRB, with study procedures in place to protect patient confidentiality.</p><p>We used 99 label sources covering a broad range of medical ontologies. We used the 2018AA release of the UMLS Metathesaurus, removing non-English and zoonotic source terminologies as well as sources containing fewer than 500 terms, resulting in 92 sources. Additional sources included the 2019 SPECIALIST abbreviations <ref type="bibr" target="#b55">[56]</ref>; Disease Ontology <ref type="bibr" target="#b56">[57]</ref>; Chemical Entities of Biological Interest (ChEBI) <ref type="bibr">[</ref>  Database (CTD) <ref type="bibr" target="#b58">[59]</ref>; the seed vocabulary used in AutoNER <ref type="bibr" target="#b21">[22]</ref>; ADAM abbreviations database <ref type="bibr" target="#b59">[60]</ref>; and word sense abbreviation dictionaries used by the clinical abbreviation system CARD <ref type="bibr" target="#b60">[61]</ref>.</p><p>We applied minimal preprocessing to all source ontologies, filtering out English stopwords and numbers, applying a letter case normalization heuristic to preserve abbreviations, and removing all single character terms. We did not incorporate UMLS term type information, such as filtering out terms explicitly denoted as suppressible within a terminology, since this information is not typically available in non-UMLS ontologies. Our overall goal was to impose as few assumptions as possible when importing terminologies, evaluating their ability to function as plug-and-play sources for weak supervision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Formulation of the labeling problem</head><p>We assume a sequence labeling problem formulation, where we are given a dataset D = {X i } N i=1 of N sequences X i = (x i,1 , ..., x i,t ) consisting of words x from a fixed vocabulary. Each sequence is mapped to a corresponding sequence of latent class variables Y i = (y i,1 , ..., y i,t ), where y ∈ {0, ..., k} for k tag classes. Since Y is not observable, our primary technical challenge is estimating Y from multiple, potentially conflicting label sources of unknown quality to construct a probabilistically labeled datasetD = {X i ,Ŷ i } N i=1 . This dataset can then be used for training classification models such as deep neural networks. Such a labeling regimen is typically low-cost, but less accurate than the hand-curated labels used in traditional supervised learning, hence this paradigm is referred to as weakly supervised learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unifying and denoising sources with a label model</head><p>When using biomedical annotators such as MetaMap or NCBO BioPortal, users specify a target set of entity classes and a set of terminology sources with which to generate labeled concepts. Consider the example outlined in <ref type="figure" target="#fig_7">Fig. 4</ref>, where we want to train an entity tagger for disease names using labels generated from four terminologies. Here we are interested in generating a consensus set of entities using each terminology's labeled output. A straightforward unification method is majority votê</p><formula xml:id="formula_0">y = argmax y∈{1,...,k} m i=1 1 k (λ i (x) = y)<label>(1)</label></formula><p>where our m terminologies are represented as individual labeling functions λ i . Labeling functions encode an underlying heuristic such as matching strings against a dictionary and given an input instance (e.g., a document or entity span) assign a label in the domain {−1, 0, ..., k} where -1 denotes abstain, i.e., not assigning any class label. Majority vote simply takes the mode of all labeling function outputs for each word, emitting the majority class in the case of ties or abstains.</p><p>Majority vote weights sources equally when combining labels, an assumption that does not hold in practice, which introduces noise into the labeling process. Sources have unknown, task-dependent accuracies and often make systematic labeling errors. Failing to account for these accuracies can negatively impact classification performance. To correct for such label noise, we use data programming <ref type="bibr" target="#b33">[34]</ref> to estimate accuracies of each source and ensemble the sources via a label model which assigns a consensus probabilistic label per word.</p><p>To learn the label model, m label sources are parameterized as labeling functions λ 1 , ....λ m . The vector of m labeling functions applied to n instances forms the label matrix Λ ∈ {−1, 0, ..., k} m×n . A key finding of data programming is that we can use Λ to recover the latent class-conditional accuracy of each label source without ground truth labels by observing the rates of agreement and disagreement across all pairs of labeling functions λ i , λ j <ref type="bibr" target="#b33">[34]</ref>. This leverages the fact that while the accuracy a i = E[λ i Y ] (the expectation of the labeling function output λ i multiplied by the true label) is not directly observable, the product of</p><formula xml:id="formula_1">a i a j = E[λ i Y λ j Y ] = E[λ i Y ]E[λ j Y ]</formula><p>is the rate at which labeling functions vote together, which is observable via Λ. Assuming independent noise among labeling functions, accuracies are then recoverable up to a sign by solving accuracies for disjoint sets of triplets. We refer readers to <ref type="bibr" target="#b16">Ratner et al. (2019)</ref>  <ref type="bibr" target="#b16">[17]</ref> for more details.</p><p>We use the weak supervision framework Snorkel <ref type="bibr" target="#b10">[11]</ref> to train a probabilistic label model which captures the relationship between the true label and label sources P (Y, Λ). Here the training input is the label matrix Λ, generated by applying labeling functions λ 1 , ....λ m to the unlabeled dataset D. Formally, P (Y, Λ) can be encoded as a factor graph-based model with m accuracy factors between λ 1 , ..., λ m and our true (unobserved) label y <ref type="figure" target="#fig_0">(Fig. 1, step 3)</ref>.</p><formula xml:id="formula_2">θ Acc j (Λ i , y i ) := y i Λ ij (2) p θ (Y, Λ) ∝ exp m i=1 n j=1 θ Acc j φ Acc j (Λ i , y i )<label>(3)</label></formula><p>Snorkel implements a matrix completion formulation of data programming which enables faster estimation of model parameters θ using stochastic gradient descent rather than relying on Gibbs sampling-based approaches <ref type="bibr" target="#b16">[17]</ref>. The label model estimates P (Y|Λ) to provide denoised consensus label predictionsŶ and generates our probabilistically labeled datasetD.  <ref type="figure" target="#fig_7">Figure 4</ref>: An example of combining ontology-based labeling functions. Here four ontology labeling functions (MTH, CHV, LNC, SNOMEDCT) are used to label a sequence of words X i containing the entity diabetes type 2. Majority vote estimates Y i as a word-level sum of positive class labels, weighing each equally (a MV ). The label model learns a latent class-conditional accuracy (a LM ) for each ontology, which is used to reweight labels to generate a more accurate consensus prediction of Y i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Labeling function templates</head><p>In this work, a labeling function λ j accepts an unlabeled sequence X i as input and emits a vector of predicted labelsỸ i,j = (ỹ j,1 , ...,ỹ j,t ), i.e., a labelỹ j ∈ {−1, 0, ..., k} for each word in X i . A typical labeling function serves as a wrapper for an underlying, potentially task-specific labeling heuristic such as pattern matching with a regular expression or a more complex rule system. Since these labeling functions are not easily automated and require hand coding, we refer to them as task-specific labeling functions. These are analogous to the rule-based approaches used in 48% of recent medical concept recognition publications <ref type="bibr" target="#b44">[45]</ref>.</p><p>In contrast, medical ontologies can be automatically transformed into labeling functions with little-to-no custom coding by defining reusable labeling function templates. Templates only require specifying a set of target entity categories and providing a collection of terminologies mapped to those categories. These categories are easily derived from knowledge bases such as the UMLS Metathesaurus (where the UMLS Semantic Network <ref type="bibr" target="#b61">[62]</ref> provides a consistent categorization of UMLS concepts) or other domain-specific taxonomies. In this work, we use UMLS Semantic Groups <ref type="bibr" target="#b62">[63]</ref> (mappings of semantic types into simpler, non-hierarchical categories such as disorders) as the basis for our concept categories.</p><p>We explore two types of ontology-based labeling functions, which leverage knowledge codified in medical ontologies for term semantic types and synonymy.</p><p>Semantic type labeling functions require a set of terms (single or multi-word entities) t ∈ T mapped to semantic types, where a term may be mapped to multiple entity classes. This mapping is converted to a k-dimensional probability vector where k is the number of entity classes t i → [p 1 , ..., p k ]. Given input sequence X i , use string matching to find all longest term matches (in token length) and assign each match to its most probable entity classỹ = max(t i ), abstaining on ties. Using the longest match is a heuristic which helps disambiguates nested terms (lung as anatomy vs lung cancer as disease). Matching optionally includes a set of slot-filled patterns to capture simple compositional mentions (e.g., {*} ({*}) → Tylenol (Acetaminophen)).</p><p>Synonym (synset) labeling functions require synsets (collections of synonymous terms) {t 1 , ...,t n } ∈T and terms T mapped to a semantic types. Given input sequence X i and it's parent context (e.g., document) search for &gt;1 unique synonym matches from a target synset and label all matchesỹ = max(t i ). This is useful for disambiguating abbreviations (e.g, Duchenne muscular dystrophy → DMD) , where a long form of an abbreviated term appears elsewhere in a document. Matches can be unconstrained, e.g., any tuple found anywhere in a context, or subject to matching rules e.g., using Schwartz-Hearst abbreviation disambiguation <ref type="bibr" target="#b63">[64]</ref> to identify out-of-dictionary abbreviations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training the BioBERT end model</head><p>The output of the label model is a set of probabilistically labeled words, which we transform back into sequenceŝ</p><formula xml:id="formula_3">D = {X i ,Ŷ i } N i=1</formula><p>. While probabilistic labels may be used directly for classification, this suffers from a key limitation: the label model cannot generalize beyond the direct output of labeling functions. Rules alone can miss common error cases such as out-of-dictionary synonyms or misspellings. Therefore, to improve coverage we train a discriminative end model, in this case a deep neural network, to transform the output of labeling functions into learned feature representations. Doing so leverages the inductive bias of pre-trained language models <ref type="bibr" target="#b64">[65]</ref> and provides additional opportunities for injecting domain knowledge via data augmentation <ref type="bibr" target="#b65">[66]</ref> and multi-task learning <ref type="bibr" target="#b66">[67]</ref> to improve classification performance.</p><p>We use the transformer-based BioBERT <ref type="bibr" target="#b23">[24]</ref>, a language model fine-tuned on biomedical text. We also evaluated ClinicalBERT <ref type="bibr" target="#b67">[68]</ref> for clinical tasks, and found its performance to be the same as BioBERT. BioBERT is trained as a token-level classifier with a max sequence length of 512 tokens. We follow Devlin et al. <ref type="bibr" target="#b64">[65]</ref> for sequence labeling formulation, using the last BERT layer of each word's head wordpiece token as the contextualized embedding. Since sequence labels may be incomplete (i.e., cases where all labeling functions abstain on a word), we mask all abstained tokens when computing the loss during training. We modified BioBERT to support a noise-aware binary cross entropy loss function <ref type="bibr" target="#b33">[34]</ref> which minimizes the expected value with respect toŶ to take advantage of the more informative probabilistic labels.</p><formula xml:id="formula_4">w = argmin w 1 N N i=1 Eŷ ∼Ŷ [L(w, x i ,ŷ)]<label>(4)</label></formula><p>Hyperparameter tuning for the label and end models All models were trained using weakly-labeled versions of the original training splits, i.e., no hand-labeled instances. We used a hand-labeled validation and test set for hyperparameter tuning and model evaluation, respectively. Result metrics are reported using the test set. The label model was tuned for learning rate, training epochs, L2 regularization, and a uniform accuracy prior used to initialize labeling function accuracies. BioBERT weights were fine-tuned, and end models were tuned for learning rate and training epochs. We used a linear decay learning rate schedule with a 10% warmup period. See <ref type="table" target="#tab_9">Supplementary Tables 5-6</ref> for hyperparameter grids.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics</head><p>We report precision, recall, and F1-score for all tasks. DocTimeRela is reported using micro-averaging. NER metrics are computed using exact span matching <ref type="bibr" target="#b68">[69]</ref>. Each NER task is trained separately as a binary classifier using IO (inside, outside) tagging to simplify labeling function design, with predicted tags converted to BIO (beginning, inside, outside) to properly count errors detecting head words. Span task metrics are calculated assuming access to gold test set spans, as per the evaluation protocol of the original challenges. Label model and BioBERT scores are reported as the mean and standard deviation of 10 runs with different random seeds. A two-sided Wilcoxon signed-rank test with an alpha level of 0.05 was used to calculate statistical significance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data availability</head><p>All primary data that support the findings of this study are available via public benchmark datasets (BC5CDR            </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Tables</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Note</head><p>Task-specific Rule Design: After using Trove to combine multiple ontologies to label entities, we often want to incorporate additional supervision signal to capture more out-of-ontology entities and further improve classification performance. While any existing rule-based system can be used as a labeling functions, either treated as a gestalt, black box labeler or broken down into more modular rules, in this work we largely focus on regular expression labeling functions. Regular expressions are flexible, map to a simple supervision paradigm where users are writing search queries, and correspond to how many rule-based systems are designed in practice <ref type="bibr" target="#b44">[45]</ref>.</p><p>In <ref type="figure" target="#fig_10">Supplementary Fig. 5</ref> we illustrate an example workflow for developing a labeling pattern which relies on a mix of data exploration and writing search queries. We assume all documents are queryable via a search index backend such as Elasticsearch <ref type="bibr">[? ]</ref>. First, a user browses a random sample of notes to identify common missing or incorrect entity spans, as generated by our initial ontology-based labeling functions. Second, once a target set of missing entities is identified, the user creates a search query to find similar entity mentions, e.g., "ST-T wave changes" in the example below. Finally, the set of retrieved results is used to expand upon a set of regular expressions, which is then mapped to a class label for use as a labeling function.</p><p>Since labeling functions consisting of a single pattern generally have low coverage and often low conflict among other labelers, we typically bundle multiple, related regular expressions into a single labeling function to increase coverage. This process is repeated until the overall label model performance reaches a target performance threshold.</p><p>Additional dataset preprocessing: For the DocRelaTime and Negation tasks, labeling functions assume access to explicit datetime mentions (TIMEX3) and clinical event entities (e.g. disorders, drugs, procedures). However, our experiments assume machine-learning based entity taggers are not available for these subtasks. Instead, we use a dictionary of clinical events derived from the UMLS to tag possible event entities, which are used to generate noisy candidate entities for both Negation and DocRelaTime tasks. TIMEX3 entities are tagged using regular expressions and normalized into abstractions supporting datetime math. Labeling functions are applied to these candidates to train the label model, with the resulting probabilistic labels used to train our BioBERT models. For the ShARe/CLEF tasks we report scores on a subset of the overall disorder entity set, removing non-contiguous, relational-style disorders spans, which comprised 7.9% (628) of test set mentions.</p><p>Guideline annotation examples: These examples are provided directly in annotation guideline documents.</p><p>• Chemical (BioCreative V CDR Task -Data Annotation Guidelines) </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Trove pipeline for ontology-driven weak supervision for medical entity classification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 2 )</head><label>2</label><figDesc>Label model (LM) is the default data programming model. Abstain and ties default to the majority class. (3) Weakly Supervised (WS) is BioBERT trained on the probabilistic dataset generated by the label model. (4) Fully supervised (FS) is BioBERT trained on the original expert-labeled training set, tuned to match current published state-of-the-art performance, and using the validation set for early stopping.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>( 1 )</head><label>1</label><figDesc>Guidelines, a dictionary of all positive and negative examples explicitly provided in annotation guidelines, including dictionaries for punctuation, numbers, and English stopwords. (2) +UMLS, all terminologies available in the UMLS. (3) +Other, additional ontologies or existing dictionaries not included in the UMLS. (4) +Rules, task-specific rules including regular expressions, small dictionaries, and other heuristics. (5) Hand-labeled, supervised learning using the expert-labeled training split.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>Ablation study of F1 performance by labeling source. Majority vote (MV) vs. weakly supervised BioBERT (WS) vs. fully supervised (FS) for all labeling source ablations showing the absolute F1-score for all labeling tiers. The colored region of each bar indicates MV performance and the white regions denote performance improvements of WS over MV. The mean performance of FS is indicated by the green lines and square points. WS and FS consist of n=10 experiment replicates using different random initialization seeds, presented as the mean with error bars ± SD. MV is deterministic and does not include replicates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2 reports</head><label>2</label><figDesc>F1 scores across all ablation tiers. In all settings, the weakly supervised BioBERT models outperformed MV. Gains of 8.0 to 34.7 F1 points are seen in the guideline-only tier and 1.3 to 8.2 points in other tiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 3 Figure 3 :</head><label>33</label><figDesc>shows the impact of partitioning the UMLS into s different labeling functions. Modeling source accuracy consistently outperformed MV across all tiers, in some cases by 2-8 F1 points. The best performing partition size s ranged from 1-10 by task. The naive baseline approaches -collapsing the UMLS into a single labeling function or treating all terminologies as individual labeling functions -generally did not perform best overall. The relationship between the number of UMLS partitions and label model performance. a BC5CDR chemical entities. b BC5CDR disease entities. c ShARe/CLEF 2014 disorder entities. d i2b2/n2c2 2009 drug entities. The UMLS is partitioned into s terminologies (x-axis, log-scale) ordered by term coverage on the unlabeled training set. Red (MV) and blue (LM) lines are the mean difference in F1 performance (y-axis) of n=5 random weight initializations. Error bars are represented using the solid colored line to denote the mean value of data points and the shaded regions corresponding to ±SD. The grey region indicates performance worse than the best possible MV, discovered via the validation set. Across virtually all partitioning choices, modeling source accuracies outperformed MV, with k =1 to 10 performing best overall.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 4</head><label>4</label><figDesc>shows how data programming provides a principled way to synthesize a label when there is disagreement across label sources about what constitutes an entity span. The disease mention diabetes type 2 is not found in Metathesaurus Names (MTH) or SNOMED Clinical Terms (SNOMEDCT) which leads to disagreement and label errors. Using a majority vote of labeling functions misses the complete entity span, while the label model learns to account for systematic errors made by each ontology to generate a more accurate consensus label prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Title</head><label></label><figDesc>Ontology-driven weak supervision for clinical entity classification in electronic health recordsSupplementary Information Supplementary FiguresModest nonspecific ST-T wave changes are suggested but baseline artifact makes assessment di cult . Since previous tracing of 2018-06-02 , sinus tachycardia and slight ST-T wave changes present 2018-06-19 CXR : Lung volumes are low with several bibasilar areas of atelectasis. Non-specific ST-T wave changes . Compared to the previous tracing of 2016-03-25 the rate is slower and the ST-T wave changes are less prominent. Di use non-specific ST-T wave changes . Compared to the previous tracing left ventricular hypertrophy and di use ST-T wave changes are new.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>r'''((ST((or|[-])T)*\s*)|T)( wave\s*)*(change[s]*|abnormalit(y|ies)''' 02405-069810-ECG_REPORT.txt a b c wave (change[s]*|abnormalit(y|ies)) SEARCH Explore Ontology-based Labeling Function Output Formulate Search Queries to Identify Missing Entity Patterns Develop Regular Expression Labeling Function</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 5 :</head><label>5</label><figDesc>Example workflow for developing task-specific labeling functions. a Users examine documents tagged by our ontology-based labeling functions and search for common, out-of-ontology entity mentions, in this case "T wave changes" in ECGs. b Users create a search query to identify similar missing mention patterns in other documents. c Based on the set of documents returned via the search query, users refine their entity pattern into a regular expression which can automatically be used as a labeling function when coupled with a target class label (ShARe/CLEF 2014 disorders in this example).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>categories with classes y \ in {0 ,1} categories = { name :0 if name not in en tity_cl asses else en tity_cla sses [ name ] for name in umls . sema ntic_ty pes () } # build ontology ( t \ rightarrow [ p_1 ,... , p_k ]) and synsets ({\ hat { t } _1 ,... ,\ hat { t } _n }) ontology = b u i l d _ e n t i t y _ m a p ( umls [ " SNOMEDCT_US " ] , categories ) synsets = b u i l d _ s y n s e t _ m a p ( umls [ " SNOMEDCT_US " ] , categories ) # labeling functions lfs = [ S e m a n t i c T y p e L a b e l i n g F u n c t i o n ( name = " LF_SNOMED " , ontology ) , S y n S e t L a b e l i n g F u n c t i o n ( name = " L F _ S N O M E D _ s y n s e t s " , synsets ) ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 6 :Figure 7 :</head><label>67</label><figDesc>Example ontology-based labeling functions. Semantic type and synset labeling functions do not require that users manually code rules, only that they specify ontologies with sufficient coverage for an entity class of interest. These examples initialize labeling functions for a simple definition of "drug" using the SNOMEDCT US terminology from the UMLS.rgxs = [ r " ( ACEi | ACE inhibitor [ s ]*) " , r " ([ l ][ -]( glutathione | arginine ) ) " , r " ([ A -Z ]) {2}[0 -9]{3 ,} " , r " (( alpha | beta | gamma ) [ -][ T ]) " ] lf = R e g e x L a b e l i n g F u n c t i o n ( name = " L F _ c h e m i ca l s _ r g x " , rgxs = rgxs , label =1) ) rgxs = [ r " \ b ([ A -Za -z0 -9]+?[ rlntd ] ase [ s ]*) \ b " , r " [A -Za -z0 -9]+ factor [ s ]* " , r " \ b ( anti [a -z ]+) \ b " ] lf = R e g e x L a b e l i n g F u n c t i o n ( name = " L F _ n o t _ c h e m i c a l s _ r g x " , rgxs = rgxs , label =0) ) Example task-specific labeling functions. Regular expression labeling functions are developed by manually inspecting unlabeled data and identifying common patterns for the entity of interest. These examples are for chemical tagging in B5CDR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>and 88.4 F1 respectively.</figDesc><table><row><cell>Supervision Method</cell><cell>Label Source</cell><cell cols="2">#Train Docs End Model</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>Fully Supervised</cell><cell>Hand-labeled</cell><cell>500</cell><cell>BioBERT</cell><cell>87.6</cell><cell>89.3</cell><cell>88.7</cell></row><row><cell>Fully Supervised</cell><cell>Hand-labeled</cell><cell>500</cell><cell cols="2">BiLSTM-CRF 87.2</cell><cell>87.9</cell><cell>87.5</cell></row><row><cell>SwellShark</cell><cell>Dictionaries</cell><cell>25,500</cell><cell cols="2">BiLSTM-CRF 84.6</cell><cell>74.1</cell><cell>79.0</cell></row><row><cell>AutoNER</cell><cell>Dictionaries</cell><cell>500</cell><cell cols="2">BiLSTM-CRF 83.2</cell><cell>81.1</cell><cell>82.1</cell></row><row><cell cols="2">Ours (Trove+Snorkel) Dictionaries</cell><cell>500</cell><cell>BioBERT</cell><cell>81.6</cell><cell>86.1</cell><cell>83.7</cell></row><row><cell>SwellShark</cell><cell cols="2">Custom Rules 25,500</cell><cell cols="3">BiLSTM-CRF 86.1 82.4</cell><cell>84.2</cell></row><row><cell>WISER</cell><cell cols="2">Custom Rules 500</cell><cell cols="2">BiLSTM-CRF 82.7</cell><cell>83.3</cell><cell>83.0</cell></row><row><cell cols="3">Ours (Trove+Snorkel) Custom Rules 500</cell><cell>BioBERT</cell><cell cols="3">85.5 86.8 86.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3</head><label>3</label><figDesc>contains our COVID case study results. The label model provided up to 5.2 F1 points improvement over majority vote and performed best overall for disorder tagging. Our best weakly supervised model outperformed the disorder tagger trained on hand-labeled MIMIC-II data by 2.3 F1 points. For exposure classification, the label model provided no benefit, but the weakly supervised end model provided a 6.9% improvement (+5.2 F1 points) over the rules alone.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>MV</cell><cell></cell><cell></cell><cell>LM</cell><cell></cell><cell></cell><cell>WS</cell><cell></cell><cell></cell><cell>FS</cell><cell></cell></row><row><cell>Supervision</cell><cell>Task</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>Hand-labeled</cell><cell>Disorder</cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell></cell><cell cols="3">68.0 74.5 71.1</cell></row><row><cell>Ontologies</cell><cell cols="10">Disorder 64.4 66.4 65.3 69.3 71.7 70.5 67.1 72.3 69.6</cell><cell></cell><cell>-</cell><cell></cell></row><row><cell cols="11">+Task-specific Disorder 69.1 70.4 69.8 73.0 73.9 73.4 70.5 74.8 72.6</cell><cell></cell><cell>-</cell><cell></cell></row><row><cell>Task-specific</cell><cell cols="10">Exposure 82.6 69.1 75.2 82.6 69.1 75.2 87.2 74.5 80.4</cell><cell></cell><cell>-</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>COVID-19 presenting symptoms/disorders and risk factors evaluated on Stanford HealthCare emergency department notes. Bold and underlined scores indicate the best score in symptom/disorder</figDesc><table /><note>tagging and COVID exposure classification respectively. Ontology-based weak supervision performed almost as well as the out-of-distribution, hand-labeled MIMIC-II data used for FS. Adding task-specific rules, even though they were developed without seeing Stanford data, outperformed the hand-labeled FS model by 2.3 F1 points.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Dataset summary statistics. There are (k) classes per task. The (Documents) and (Entities) columns indicate counts for train/validation/test splits.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>, https://biocreative.bioinformatics.udel.edu/tasks/biocreative-v/track-3-cdr/) or are otherwise available per data use agreements with the respective data owners (ShARe/CLEF 2014, https://physionet. org/content/shareclefehealth2014task2/1.0/; THYME, https://healthnlp.hms.harvard.edu/center/ pages/data-sets.html; i2b2/n2c2 2009, https://portal.dbmi.hms.harvard.edu/projects/n2c2-nlp/). The data that support the findings of the clinical case study are available on request from the corresponding author JAF. These data are not publicly available because they contain information that could compromise patient privacy.Trove requires access to the UMLS, which is available by license from National Library of Medicine, Department of Health and Human Services, https://www.nlm.nih.gov/research/umls/index.html. Open source ontologies used in this study are available at: SPECIALIST Lexicon, https://lsg3.nlm.nih.gov/LexSysGroup/ Summary/lexicon.html; Disease Ontology, https://bioportal.bioontology.org/ontologies/DOID; Chemical Entities of Biological Interest (ChEBI), ftp://ftp.ebi.ac.uk/pub/databases/chebi/; Comparative Toxicogenomics Database (CTD), http://ctdbase.org; AutoNER core dictionary, https://github.com/ shangjingbo1226/AutoNER/blob/master/data/BC5CDR/dict_core.txt; ADAM abbreviations database, http: //arrowsmith.psych.uic.edu/arrowsmith_uic/adam.html; and the Clinical Abbreviation Recognition and Disambiguation (CARD) framework, https://sbmi.uth.edu/ccb/resources/abbreviation.htm.</figDesc><table><row><cell>Code availability</cell></row><row><cell>Trove is written in Python v3.6, spaCy 2.3.4 was used for NLP preprocessing, and Snorkel v0.9.5 was used</cell></row><row><cell>for training the label model. BioBERT-Base v1.1, Transformers v2.8 [70], and PyTorch v1.1.0 were used to</cell></row><row><cell>train all discriminative models. Trove is open source software and publicly available at https://github.com/</cell></row><row><cell>som-shahlab/trove; https://doi.org/10.5281/zenodo.4497214 [71]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>±0.0 76.8 ±0.0 81.6 ±0.0</figDesc><table><row><cell>Task</cell><cell cols="2">Method Ablation Tier</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell></row><row><cell>Chemical</cell><cell>MV</cell><cell>Guidelines</cell><cell cols="2">90.7 ±0.0 3.1 ±0.0</cell><cell>6.0 ±0.0</cell></row><row><cell cols="6">Chemical 87.0 Chemical MV Guidelines+UMLS MV Guidelines+UMLS+Other 74.6 ±0.0 85.7 ±0.0 79.8 ±0.0</cell></row><row><cell>Chemical</cell><cell>MV</cell><cell cols="4">Guidelines+UMLS+Other+Rules 78.3 ±0.0 84.2 ±0.0 81.1 ±0.0</cell></row><row><cell>Chemical</cell><cell>LM</cell><cell>Guidelines</cell><cell cols="2">90.7 ±0.0 3.1 ±0.0</cell><cell>6.0 ±0.0</cell></row><row><cell>Chemical</cell><cell>LM</cell><cell>Guidelines+UMLS</cell><cell cols="3">89.0 ±0.2 82.3 ±0.2 85.5 ±0.1</cell></row><row><cell>Chemical</cell><cell>LM</cell><cell>Guidelines+UMLS+Other</cell><cell cols="3">91.0 ±0.2 85.2 ±0.2 88.0 ±0.1</cell></row><row><cell>Chemical</cell><cell>LM</cell><cell cols="4">Guidelines+UMLS+Other+Rules 90.8 ±0.4 87.7 ±0.4 89.2 ±0.2</cell></row><row><cell>Chemical</cell><cell>WS</cell><cell>Guidelines</cell><cell cols="3">76.0 ±6.7 7.8 ±3.1 14.0 ±5.0</cell></row><row><cell>Chemical</cell><cell>WS</cell><cell>Guidelines+UMLS</cell><cell cols="3">87.0 ±0.1 84.6 ±0.2 85.8 ±0.1</cell></row><row><cell>Chemical</cell><cell>WS</cell><cell>Guidelines+UMLS+Other</cell><cell cols="3">85.7 ±0.3 91.5 ±0.2 88.5 ±0.2</cell></row><row><cell>Chemical</cell><cell>WS</cell><cell cols="4">Guidelines+UMLS+Other+Rules 91.0 ±0.4 91.2 ±0.3 91.1 ±0.1</cell></row><row><cell>Chemical</cell><cell>FS</cell><cell>Supervised</cell><cell cols="3">92.1 ±0.4 92.6 ±0.7 92.4 ±0.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5 :</head><label>5</label><figDesc>Complete performance metrics for BC5CDR chemical tagging for all supervision tiers. Scores are the mean and ±1 SD of 5 random weight initializations. ±0.4 86.5 ±0.2 84.5 ±0.2</figDesc><table><row><cell>Task</cell><cell cols="2">Method Ablation Tier</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell></row><row><cell>Disease</cell><cell>MV</cell><cell>Guidelines</cell><cell cols="3">58.5 ±0.0 6.8 ±0.0 12.3 ±0.0</cell></row><row><cell>Disease</cell><cell>MV</cell><cell>Guidelines+UMLS</cell><cell cols="3">67.8 ±0.0 65.2 ±0.0 66.5 ±0.0</cell></row><row><cell>Disease</cell><cell>MV</cell><cell>Guidelines+UMLS+Other</cell><cell cols="3">71.9 ±0.0 77.8 ±0.0 74.7 ±0.0</cell></row><row><cell>Disease</cell><cell>MV</cell><cell cols="4">Guidelines+UMLS+Other+Rules 74.1 ±0.0 78.7 ±0.0 76.4 ±0.0</cell></row><row><cell>Disease</cell><cell>LM</cell><cell>Guidelines</cell><cell cols="3">58.5 ±0.0 6.8 ±0.0 12.3 ±0.0</cell></row><row><cell>Disease</cell><cell>LM</cell><cell>Guidelines+UMLS</cell><cell cols="3">70.8 ±0.9 71.3 ±0.1 71.0 ±0.4</cell></row><row><cell>Disease</cell><cell>LM</cell><cell>Guidelines+UMLS+Other</cell><cell cols="3">80.9 ±0.9 77.0 ±0.7 78.9 ±0.1</cell></row><row><cell>Disease</cell><cell>LM</cell><cell cols="4">Guidelines+UMLS+Other+Rules 81.8 ±1.1 78.0 ±0.7 79.8 ±0.3</cell></row><row><cell>Disease</cell><cell>WS</cell><cell>Guidelines</cell><cell cols="3">40.9 ±6.8 51.9 ±4.8 45.1 ±3.1</cell></row><row><cell>Disease</cell><cell>WS</cell><cell>Guidelines+UMLS</cell><cell cols="3">69.4 ±0.4 75.2 ±0.4 72.1 ±0.4</cell></row><row><cell>Disease</cell><cell>WS</cell><cell>Guidelines+UMLS+Other</cell><cell cols="3">76.9 ±0.4 79.7 ±0.3 78.3 ±0.2</cell></row><row><cell>Disease</cell><cell>WS</cell><cell cols="4">Guidelines+UMLS+Other+Rules 78.0 ±0.4 81.9 ±0.1 79.9 ±0.2</cell></row><row><cell>Disease</cell><cell>FS</cell><cell>Supervised</cell><cell>82.6</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Complete performance metrics for BC5CDR disease tagging for all supervision tiers. Scores are the mean and ±1 SD of 5 random weight initializations. ±0.0 57.8 ±0.0 65.7 ±0.0 Disorder MV Guidelines+UMLS+Other 74.2 ±0.0 62.4 ±0.0 67.8 ±0.0 Disorder MV Guidelines+UMLS+Other+Rules 77.0 ±0.0 66.3 ±0.0 71.2 ±0.0 ±1.4 63.3 ±0.5 68.3 ±0.3 Disorder LM Guidelines+UMLS+Other+Rules 79.4 ±0.8 71.1 ±0.4 75.0 ±0.2</figDesc><table><row><cell>Task</cell><cell cols="2">Method Ablation Tier</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell></row><row><cell>Disorder</cell><cell>MV</cell><cell>Guidelines</cell><cell cols="2">69.2 ±0.0 3.8 ±0.0</cell><cell>7.2 ±0.0</cell></row><row><cell cols="5">Disorder 76.1 Disorder MV Guidelines+UMLS LM Guidelines 69.2 ±0.0 3.8 ±0.0</cell><cell>7.2 ±0.0</cell></row><row><cell>Disorder</cell><cell>LM</cell><cell>Guidelines+UMLS</cell><cell cols="3">73.2 ±0.0 61.6 ±0.0 66.9 ±0.0</cell></row><row><cell cols="6">Disorder 74.1 Disorder LM Guidelines+UMLS+Other WS Guidelines 35.0 ±5.0 53.9 ±5.5 41.9 ±2.7</cell></row><row><cell>Disorder</cell><cell>WS</cell><cell>Guidelines+UMLS</cell><cell cols="3">74.1 ±0.3 64.8 ±0.5 69.1 ±0.3</cell></row><row><cell>Disorder</cell><cell>WS</cell><cell>Guidelines+UMLS+Other</cell><cell cols="3">70.8 ±0.2 67.5 ±0.3 69.1 ±0.2</cell></row><row><cell>Disorder</cell><cell>WS</cell><cell cols="4">Guidelines+UMLS+Other+Rules 79.4 ±0.2 73.4 ±0.3 76.3 ±0.1</cell></row><row><cell>Disorder</cell><cell>FS</cell><cell>Supervised</cell><cell cols="3">77.7 ±0.5 81.7 ±0.1 79.6 ±0.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Complete performance metrics for ShARe/CLEF 2014 disorder tagging for all supervision tiers. Scores are the mean and ±1 SD of 5 random weight initializations. ±0.0 14.8 ±0.0 24.8 ±0.0 Drug MV Guidelines+UMLS 70.1 ±0.0 81.9 ±0.0 75.5 ±0.0 Drug MV Guidelines+UMLS+Other 69.5 ±0.0 82.0 ±0.0 75.3 ±0.0 Drug MV Guidelines+UMLS+Other+Rules 81.6 ±0.0 82.9 ±0.0 82.2 ±0.0 ±0.0 15.0 ±0.0 25.2 ±0.0 Drug LM Guidelines+UMLS 75.5 ±0.1 79.7 ±0.0 77.5 ±0.1 Drug LM Guidelines+UMLS+Other 75.9 ±0.1 81.5 ±0.2 78.6 ±0.1 Drug LM Guidelines+UMLS+Other+Rules 86.2 ±0.3 85.4 ±0.7 85.8 ±0.4 ±5.9 83.0 ±1.0 43.7 ±6.2 Drug WS Guidelines+UMLS 72.6 ±0.3 83.5 ±0.1 77.7 ±0.2 Drug WS Guidelines+UMLS+Other 75.7 ±0.2 83.0 ±0.3 79.2 ±0.2 Drug WS Guidelines+UMLS+Other+Rules 88.1 ±0.2 88.5 ±0.3 88.3 ±0.3 ±0.3 92.7 ±0.4 93.2 ±0.3</figDesc><table><row><cell>Task Method Ablation Tier</cell><cell>Precision</cell><cell>Recall</cell><cell>F1</cell></row><row><cell cols="2">Drug 76.2 Drug MV Guidelines LM Guidelines 77.5 Drug WS Guidelines 30.0 Drug FS Supervised 93.7</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :Table 9 :</head><label>89</label><figDesc>Complete performance metrics for i2b2/n2c2 2009 drug tagging for all supervision tiers. Scores are the mean and ±1 SD of 5 random weight initializations. Label model hyperparameter grid.</figDesc><table><row><cell>Parameter</cell><cell>Values</cell></row><row><cell cols="2">learning rate [0.01, 0.005, 0.001, 0.0001]</cell></row><row><cell>l2</cell><cell>[0.001, 0.0001]</cell></row><row><cell>epochs</cell><cell>[50, 100, 200, 600, 700, 1000]</cell></row><row><cell cols="2">precision init [0.6, 0.7, 0.8, 0.9]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 10 :</head><label>10</label><figDesc>BioBERT hyperparameter grid.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>-</head><label></label><figDesc>Positive [ATP, Ca, DCE, Fe, K, Li, NO, O2, amino acid, angiotensin II, angiotensin ii, antidepressant, antidepressant drug, antidepressive agent, cAMP, carbidopa, estrogen, estrogen receptor agonist, estrogenic agent, estrogenic compound, estrogenic effect, ethanolic extract of daucus carota seed, fatty acid, glucose, grape seed proanthocyanidin extract, levodopa, low-dose oral contraceptive, nitric oxide, oral contraceptive, phasic oral contraceptive, polyethylene glycol, saturated fatty acid, steroid, sucrose, thymoanaleptics, thymoleptics] -Negative [DNA, adrenergic, anti-HIV agent, anticholinesterase drug, anticoagulant, anticonvulsant, antipsychotic, atom, cellulose, collagen, glucagon, glucocorticoid, glycogen, gold standard, insulin, ion, juice, lipid, lipopolysaccharide, mRNA, molecular, muscarinic, nucleic acid polymer, oligosaccharide, opiate, opioid, opioid alkaloids, opium poppy plant, papaver somniferum, polypeptide, polysaccharide, prolactin, protein, purinergic, saline, starch, water]</figDesc><table /><note>• Disease (BioCreative V CDR Task -Data Annotation Guidelines)</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was funded under NLM R01-LM011369-05. Thank you to Birju Patel and Keith Morse who did our COVID-19 clinical annotations and to Daisy Ding and Adrien Coulet who helped refine experimental hypotheses during the early stages of this project. Computational resources were provided by Nero, a shared big data computing platform made possible by the Stanford School of Medicine Research Office and Stanford Research Computing Center. Additional thanks to reader feedback from Stephen Pfohl, Erin Craig, Conor Corbin, and Jennifer Wilson. This is a post-peer-review, pre-copyedit version of an article published in Nature Communications. The final authenticated version is available online at: https://doi.org/10.1038/s41467-021-22328-4</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author contributions</head><p>JAF conceived the initial study. JAF, ES, SK, SF, JP, AC wrote code and conducted experimental analysis of machine learning models. AC, JAF managed and adjudicated clinical text annotations. JAF, ES, NHS contributed ideas and experimental designs. NHS supervised the project. All authors contributed to writing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing Interests</head><p>The authors declare no competing interests.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep learning for health informatics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ravì</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="4" to="21" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A guide to deep learning in healthcare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Med</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="24" to="29" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">CORD-19: The COVID-19 open research dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.nlpcovid19-acl.1" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 1st Workshop on NLP for COVID-19 at ACL 2020</title>
		<meeting>the 1st Workshop on NLP for COVID-19 at ACL 2020<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A machine-compiled database of genome-wide association studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kuleshov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">3341</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Weakly supervised classification of aortic valve malformations using unlabeled cardiac MRI sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Fries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">3111</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Multi-frame weak supervision to label wearable sensor data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khattar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Time Series Workshop at ICML 2019</title>
		<meeting>the Time Series Workshop at ICML 2019</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-resolution weak supervision for sequential data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Varma</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/8313-multi-resolution-weak-supervision-for-sequential-data" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>Wallach, H. M. et al.</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-14" />
			<biblScope unit="page" from="192" to="203" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Cross-Modal data programming enables rapid medical machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Dunnmon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Patterns</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">100019</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The unified medical language system (UMLS): integrating biomedical terminology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="267" to="70" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The open biomedical annotator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jonquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Musen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Summit Transl Bioinform</title>
		<imprint>
			<biblScope unit="page" from="56" to="60" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Snorkel: Rapid training data creation with weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ratner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings VLDB Endowment</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="269" to="282" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple algorithm for identifying negated findings and diseases in discharge summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bridewell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Buchanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="301" to="310" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">NegBio: a high-performance tool for negation and uncertainty detection in radiology reports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AMIA Jt Summits Transl Sci Proc</title>
		<imprint>
			<biblScope unit="page" from="188" to="196" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.369</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2017.369" />
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="3462" to="3471" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS Med</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">1002686</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Machine-Learning-Based multiple abnormality prediction with Large-Scale chest computed tomography volumes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Draelos</surname></persName>
		</author>
		<idno>2002.04752</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Training complex models with Multi-Task weak supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ratner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. AAAI Artif. Intell</title>
		<meeting>Conf. AAAI Artif. Intell</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4763" to="4771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A clinical text classification paradigm using weak supervision and deep representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMC Med. Inform. Decis. Mak</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Medical device surveillance with electronic health records</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Callahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ Digit Med</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">94</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A corpus-driven standardization framework for encoding clinical problems with HL7 FHIR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page">103541</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">A generative model for biomedical named entity recognition without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Swellshark</surname></persName>
		</author>
		<idno>1704.06360</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning named entity tagger using domain-specific dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D18-1230" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2054" to="2064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Thirty-Second Innovative Applications of Artificial Intelligence Conference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Safranchik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<ptr target="https://aaai.org/ojs/index.php/AAAI/article/view/6009" />
	</analytic>
	<monogr>
		<title level="m">The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="5570" to="5578" />
		</imprint>
	</monogr>
	<note>The Thirty-Fourth AAAI Conference on Artificial Intelligence</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">An overview of metamap: historical perspective and recent advances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-M</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="229" to="236" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Constructing biological knowledge bases by extracting information from text sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Craven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kumlien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Int. Conf. Intell. Syst. Mol. Biol</title>
		<imprint>
			<biblScope unit="page" from="77" to="86" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Distant supervision for relation extraction without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bills</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Snow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</title>
		<meeting>the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1003" to="1011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Combining labeled and unlabeled data with co-training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
		<idno type="DOI">10.1145/279943.279962</idno>
		<ptr target="https://doi.org/10.1145/279943.279962" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh Annual Conference on Computational Learning Theory</title>
		<editor>Bartlett, P. L. &amp; Mansour, Y.</editor>
		<meeting>the Eleventh Annual Conference on Computational Learning Theory<address><addrLine>Madison, Wisconsin, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998-07-24" />
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Label embedding for zero-shot fine-grained named entity typing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="171" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Unsupervised models for named entity classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">1999 Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora</title>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Weakly supervised learning for hedge classification in scientific literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Medlock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Briscoe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 45th annual meeting of the association of computational linguistics</title>
		<meeting>the 45th annual meeting of the association of computational linguistics</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="992" to="999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Generalized expectation criteria for Semi-Supervised learning with weakly labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning from noisy singly-labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khetan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Anandkumar</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=H1sUHgb0Z" />
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings (OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Data programming: Creating large training sets, quickly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>De Sa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Selsam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inf. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3567" to="3575" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Medication and adverse event extraction from noisy text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Paris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Australasian Language Technology Association Workshop</title>
		<meeting>the Australasian Language Technology Association Workshop</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="79" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Enhancing clinical concept extraction with contextual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Si</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1297" to="1304" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Multilayered temporal modeling for the clinical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Savova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="387" to="395" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Task 2: ShARe/CLEF ehealth evaluation lab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Mowery</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-1180/CLEF2014wn-eHealth-MoweryEt2014.pdf" />
	</analytic>
	<monogr>
		<title level="m">Working Notes for CLEF 2014 Conference</title>
		<editor>Cappellato, L., Ferro, N., Halvey, M. &amp; Kraaij, W.</editor>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-09-15" />
			<biblScope unit="volume">1180</biblScope>
			<biblScope unit="page" from="31" to="42" />
		</imprint>
		<respStmt>
			<orgName>CEUR-WS.org</orgName>
		</respStmt>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Context: an algorithm for determining negation, experiencer, and temporal status from clinical reports</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Harkema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Dowling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Thornblade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="839" to="851" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Brundlefly at semeval-2016 task 12: Recurrent neural networks vs. joint inference for clinical temporal information extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Fries</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/s16-1198</idno>
		<ptr target="https://doi.org/10.18653/v1/s16-1198" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2016</title>
		<editor>Bethard, S. et al.</editor>
		<meeting>the 10th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2016<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1274" to="1279" />
		</imprint>
		<respStmt>
			<orgName>The Association for Computer Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Estimating the efficacy of symptom-based screening for COVID-19</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Callahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Digital Medicine</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">95</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Multiparameter intelligent monitoring in intensive care II (MIMIC-II): a public-access intensive care unit database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saeed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Critical care medicine</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page">952</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hanauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Project</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Emerse</surname></persName>
		</author>
		<ptr target="http://project-emerse.org/synonyms_covid19.html.http://project-emerse.org/synonyms_covid19.html" />
		<imprint>
			<biblScope unit="page">19</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Biomedical ontologies: a functional perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">F</forename><surname>Noy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brief. Bioinform</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="75" to="90" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Clinical concept extraction: A methodology review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page">103526</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Two biomedical sublanguages: a description based on the theories of zellig harris</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rzhetsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Biomed. Inform</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="222" to="235" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Augmented curation of clinical notes from a massive ehr system reveals symptoms of impending covid-19 diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.58227</idno>
		<ptr target="https://doi.org/10.7554/eLife.58227" />
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">58227</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">COVID-19 SignSym: A fast adaptation of general clinical NLP tools to identify and normalize COVID-19 signs and symptoms to OMOP common data model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Manion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rouhizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title/>
		<ptr target="https://ncats.nih.gov/n3c" />
	</analytic>
	<monogr>
		<title level="j">National COVID cohort collaborative</title>
		<imprint>
			<biblScope unit="issue">N3C</biblScope>
			<biblScope unit="page" from="2020" to="2027" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning the structure of generative models without labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v70/bach17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>Precup, D. &amp; Teh, Y. W.</editor>
		<meeting>the 34th International Conference on Machine Learning<address><addrLine>Sydney, NSW, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017-06-11" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="273" to="282" />
		</imprint>
	</monogr>
	<note>of Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning dependency structures for weak supervision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Varma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ré</surname></persName>
		</author>
		<ptr target="http://proceedings.mlr.press/v97/varma19a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<editor>Chaudhuri, K. &amp; Salakhutdinov, R.</editor>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019-06-15" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="6418" to="6427" />
		</imprint>
	</monogr>
	<note>of Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Industrial-strength Natural Language Processing in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Montani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Van Landeghem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spacy</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.1212303</idno>
		<ptr target="https://doi.org/10.5281/zenodo.1212303" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Assessing the state of the art in biomedical relation extraction: overview of the biocreative V chemical-disease relation (CDR) task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<idno type="DOI">10.1093/database/baw032</idno>
		<ptr target="https://doi.org/10.1093/database/baw032" />
	</analytic>
	<monogr>
		<title level="j">Database J. Biol. Databases Curation</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Extracting medication information from clinical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Uzuner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Solti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cadag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="514" to="518" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Semeval-2016 task 12: Clinical tempeval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/s16-1165</idno>
		<ptr target="https://doi.org/10.18653/v1/s16-1165" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2016 (The Association for Computer Linguistics</title>
		<editor>Bethard, S. et al.</editor>
		<meeting>the 10th International Workshop on Semantic Evaluation, SemEval@NAACL-HLT 2016 (The Association for Computer Linguistics</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<title level="m">SPECIALIST Lexicon and Lexical Tools</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>National Library of Medicine</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Disease ontology: a backbone for disease semantic integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">M</forename><surname>Schriml</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="940" to="946" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">ChEBI: a database and ontology for chemical entities of biological interest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Degtyarenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="344" to="50" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">The comparative toxicogenomics database&apos;s 10th year anniversary: update 2015</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nucleic Acids Res</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="914" to="934" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">ADAM: another database of abbreviations in MEDLINE</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">I</forename><surname>Torvik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Smalheiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="2813" to="2818" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A long journey to short abbreviations: developing an open-source framework for clinical abbreviation recognition and disambiguation (CARD)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Am. Med. Inform. Assoc</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">An upper-level ontology for the biomedical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comparative and Functional Genomics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="80" to="84" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Aggregating umls semantic types for reducing conceptual complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Burgun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Studies in health technology and informatics</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="page">216</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">A simple algorithm for identifying abbreviation definitions in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Hearst</surname></persName>
		</author>
		<ptr target="http://psb.stanford.edu/psb-online/proceedings/psb03/schwartz.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th Pacific Symposium on Biocomputing, PSB</title>
		<editor>Altman, R. B., Dunker, A. K., Hunter, L. &amp; Klein, T. E.</editor>
		<meeting>the 8th Pacific Symposium on Biocomputing, PSB</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bert</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-1423" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">EDA: Easy data augmentation techniques for boosting performance on text classification tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zou</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D19-1670" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6382" to="6388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">A survey on Multi-Task learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<idno>1707.08114</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Publicly available clinical BERT embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alsentzer</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W19-1909" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Clinical Natural Language Processing Workshop</title>
		<meeting>the 2nd Clinical Natural Language Processing Workshop<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="72" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Introduction to the CONLL-2000 shared task: Chunking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tjong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Buchholz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth Conference on Computational Natural Language Learning and of the Second Learning Language in Logic Workshop</title>
		<meeting>the Fourth Conference on Computational Natural Language Learning and of the Second Learning Language in Logic Workshop<address><addrLine>Lissabon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2000-09" />
			<biblScope unit="page" from="127" to="132" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.emnlp-demos.6" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Positive [akathisis, auditory toxicity, bone marrow oedema, cancer, cardiac toxicity, death, dyskinesia, erythroblastocytopenia, hepatitis, hypertension, hypertensive, liver toxicity, ototoxicity, ovarian and peritoneal cancer, pain, partial seizures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Fries</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.4497214</idno>
		<ptr target="https://doi.org/10.5281/zenodo.4497214" />
	</analytic>
	<monogr>
		<title level="j">Zenodo</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note>Ontology-driven weak supervision for clinical entity classification in electronic health records. peritoneal cancer, toxicity, tumor, visual toxicity] -Negative [cancerogenesis, complication, deficiencies, deficiency, disease, syndrome, tumorigenesis</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Guidelines for the Annotation of Disorders in Clinical Notes) -Positive [bowel obstruction, chest pain, chronic gingivitis, colon cancer, crohn, facial droop, lower extremity DVT, lupus, numbness, pain, rash, schizophrenia, severe pre-eclampsia, small bowel obstruction, stroke, tumor, tumor of the skin</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><surname>Disorder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ShARe/CLEF eHealth 2013 Shared Task</title>
		<imprint/>
	</monogr>
	<note>watering of the eye</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">NITROGLYCERIN 1/150, NTG, POTASSIUM CHLORIDE, TPN, TYLENOL ( ACETAMINOPHEN ), TYLENOL ( AC-ETAMINOPHEN ), acetaminophen, asa, aspirin, atenolol, avapro, bb, caltrate plus D, caltrate plus D, novolog, diuretic, diuretics, fasting lipids sent, fluocinonide 0.5% cream, furosemide, glucophage, lasix, lasix, lasix, long acting nitrate, nephrotoxic meds, plavix, red blood cells, saline, saline solution, this medication</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">•</forename><surname>Drug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; Citalopram</forename><surname>Hydrobromide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ecasa</forename><surname>Czi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ecasa ( Aspirin</forename><surname>Enteric Coated )</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lisinopril</forename><surname>Rel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niferex</forename><surname>Tablet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">i2b2 Medication Extraction Challenge Preliminary Annotation Guidelines) -Positive</title>
		<imprint/>
	</monogr>
	<note>total parenteral nutrition, tylenol, tylenol 3, nitroglycerin 1/150, vitamin A, vitamin C, vitamin D, vitamin E, vitamin E, vitamins, vitamins A, vitamins C, vitamins D, vitamins E] -Negative NONE</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
