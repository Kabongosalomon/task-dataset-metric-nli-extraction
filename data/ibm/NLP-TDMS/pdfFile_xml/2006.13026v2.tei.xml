<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Polynomial Neural Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grigorios</forename><forename type="middle">G</forename><surname>Chrysos</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stylianos</forename><surname>Moschoglou</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Bouritsas</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Panagakis</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
						</author>
						<title level="a" type="main">Deep Polynomial Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2021-06-26T07:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Polynomial neural networks</term>
					<term>tensor decompositions</term>
					<term>high-order polynomials</term>
					<term>generative models</term>
					<term>discriminative models</term>
					<term>face verification !</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep Convolutional Neural Networks (DCNNs) are currently the method of choice both for generative, as well as for discriminative learning in computer vision and machine learning. The success of DCNNs can be attributed to the careful selection of their building blocks (e.g., residual blocks, rectifiers, sophisticated normalization schemes, to mention but a few). In this paper, we propose Π-Nets, a new class of function approximators based on polynomial expansions. Π-Nets are polynomial neural networks, i.e., the output is a high-order polynomial of the input. The unknown parameters, which are naturally represented by high-order tensors, are estimated through a collective tensor factorization with factors sharing. We introduce three tensor decompositions that significantly reduce the number of parameters and show how they can be efficiently implemented by hierarchical neural networks. We empirically demonstrate that Π-Nets are very expressive and they even produce good results without the use of non-linear activation functions in a large battery of tasks and signals, i.e., images, graphs, and audio. When used in conjunction with activation functions, Π-Nets produce state-of-the-art results in three challenging tasks, i.e. image generation, face verification and 3D mesh representation learning. The source code is available at https://github.com/grigorisg9gr/polynomial_nets.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Deep Convolutional Neural Networks (DCNNs) <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref> have demonstrated impressive results in a number of tasks the last few years <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>. Arguably, the careful selection of architectural pipelines, e.g. skip connections <ref type="bibr" target="#b4">[5]</ref>, normalization schemes <ref type="bibr" target="#b5">[6]</ref> etc., is significant, however the core structure relies on compositional functions of linear and nonlinear operators. Both theoretical <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref> and empirical studies reveal the limitations of the existing structure.</p><p>Recent empirical <ref type="bibr" target="#b8">[9]</ref> and theoretical <ref type="bibr" target="#b9">[10]</ref> results support that multiplicative interactions expand the classes of functions that can be approximated. Motivated by these findings, we study a new class of function approximators, which we coin Π´nets, where the output is a polynomial function of the input. Specifically, we model a vector-valued function Gpzq : R d Ñ R o by a high-order multivariate polynomial of the input z, whose unknown parameters are naturally represented by high-order tensors. The number of parameters required to accommodate all higher-order correlations of the input explodes with the desired order of the polynomial. To that end, we cast polynomial parameters estimation as a coupled tensor factorization <ref type="bibr" target="#b10">[11]</ref> that jointly factorizes all the polynomial parameters tensors. We introduce three joint decompositions with shared factors and exhibit the resulting hierarchical structures (i.e., architectures of neural networks).</p><p>In our preliminary works <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, we introduced the concept of higher-order expansions for both generative and discriminative networks. In this work, our improvements are threefold. The concepts and the motivation behind each model are elaborated; the new intuitions will enable practitioners to devise <ref type="figure">Fig. 1</ref>: In this paper we introduce a class of networks called Π´nets, where the output is a polynomial of the input. The input in this case, z, can be either the latent space of Generative Adversarial Network for a generative task or an image in the case of a discriminative task. Our polynomial networks can be easily implemented.</p><p>new models tailored to their specific tasks. In addition, we extend the experimental results, e.g. include experiment in the challenging task of face verification and identification. Lastly, we conduct a thorough discussion on several challenging topics that require further work on this new class of neural networks.</p><p>In particular, the paper bears the following contributions: ‚ A new family of neural networks (called Π´nets) where the output is a high-order polynomial of the input is introduced.</p><p>To avoid the combinatorial explosion in the number of parameters of polynomial activation functions <ref type="bibr" target="#b14">[15]</ref>, our Π´nets cast polynomial parameters estimation as a coupled tensor factorization with shared factors (please see <ref type="figure">Fig. 1</ref> for an indicative schematic representation). <ref type="bibr" target="#b1">2</ref> Additionally, the polynomial architectures are used to learn high-dimensional distributions without non-linear activation functions. <ref type="bibr">‚</ref> We convert state-of-the-art baselines using the proposed Π´nets and show how they can largely improve the performance of the baseline. We demonstrate it conclusively in a battery of tasks (i.e., generation, classification and face verification/identification). Our architectures are applicable to many different signals (e.g. images, meshes, and audio) and outperform the prior art.</p><p>The rest of the paper is organized as follows: Sec. 2 summarizes the related work. In Sec. 3 we introduce the polynomial networks and showcase the resulting architectures for three decompositions. The core experimental evaluation is conducted in Sec. 4, while a number of experiments are deferred to the supplementary. The existing limitations and future directions of the polynomial networks are discussed in Sec. 5, while Sec. 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK AND NOTATION</head><p>Expressivity of (deep) neural networks: The last few years, (deep) neural networks have been applied to a wide range of applications with impressive results. The performance boost can be attributed to a host of factors including: a) the availability of massive datasets <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b16">[17]</ref>, b) the machine learning libraries <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b18">[19]</ref> running on massively parallel hardware, c) training improvements. The training improvements include a) optimizer improvement <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, b) augmented capacity of the network <ref type="bibr" target="#b21">[22]</ref>, c) regularization tricks <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b24">[25]</ref>. However, the paradigm for each layer remains largely unchanged for several decades: each layer is composed of a linear transformation and an element-wise activation function. Despite the variety of linear transformations <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b25">[26]</ref> and activation functions <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref> being used, the effort to extend this paradigm has not drawn much attention to date.</p><p>Recently, hierarchical models have exhibited stellar performance in learning expressive generative models <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>. For instance, the recent BigGAN <ref type="bibr" target="#b28">[29]</ref> performs a hierarchical composition through skip connections from the noise z to multiple resolutions of the generator. A similar idea emerged in StyleGAN <ref type="bibr" target="#b8">[9]</ref>, which is an improvement over the Progressive Growing of GANs (ProGAN) <ref type="bibr" target="#b30">[31]</ref>. As ProGAN, StyleGAN is a highly-engineered network that achieves compelling results on synthesized 2D images. In order to provide an explanation on the improvements of StyleGAN over ProGAN, the authors adopt arguments from the style transfer literature <ref type="bibr" target="#b31">[32]</ref>. We believe that these improvements can be better explained under the light of our proposed polynomial function approximation. Despite the hierarchical composition proposed in these works, we present an intuitive and mathematically elaborate method to achieve a more precise approximation with a polynomial expansion. We also demonstrate that such a polynomial expansion can be used in both image generation (as in <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b28">[29]</ref>), image classification, and graph representation learning.</p><p>Polynomial networks: Polynomial relationships have been investigated in two specific categories of networks: a) self-organizing networks with hard-coded feature selection, b) pi-sigma networks.</p><p>The idea of learnable polynomial features can be traced back to Group Method of Data Handling (GMDH) <ref type="bibr" target="#b32">[33]</ref> 1 . GMDH learns partial descriptors that capture quadratic correlations between two 1. This is often referred to as the first deep neural network <ref type="bibr" target="#b33">[34]</ref>. predefined input elements. In <ref type="bibr" target="#b34">[35]</ref>, more input elements are allowed, while higher-order polynomials are used. The input to each partial descriptor is predefined (subset of the input elements), which does not allow the method to scale to high-dimensional data with complex correlations.</p><p>Shin et al. <ref type="bibr" target="#b35">[36]</ref> introduce the pi-sigma network, which is a neural network with a single hidden layer. Multiple affine transformations of the data are learned; a product unit multiplies all the features to obtain the output. Improvements in the pi-sigma network include regularization for training in <ref type="bibr" target="#b36">[37]</ref> or using multiple product units to obtain the output in <ref type="bibr" target="#b37">[38]</ref>. The pi-sigma network is extended in sigma-pi-sigma neural network (SPSNN) <ref type="bibr" target="#b38">[39]</ref>. The idea of SPSNN relies on summing different pi-sigma networks to obtain each output. SPSNN also uses a predefined basis (overlapping rectangular pulses) on each pi-sigma sub-network to filter the input features. Even though such networks use polynomial features or products, they do not scale well in high-dimensional signals. In addition, their experimental evaluation is conducted only on signals with known ground-truth distributions (and with up to 3 dimensional input/output), unlike the modern generative models where only a finite number of samples from high-dimensional ground-truth distributions is available.</p><p>Convolutional arithmetic circuits (ConvACs) are also related to our work. Arithmetic circuits are networks with two types of nodes: sum nodes (weighted sum of their inputs), and product nodes (computing the product of their inputs). Those two types of nodes are sufficient to express a polynomial expansion. On <ref type="bibr" target="#b39">[40]</ref>, the authors want to characterize the depth efficiency of (deep) convolutional neural networks. The CP decomposition is used to factorize the weights of a shallow convolutional network, while the hierarchical Tucker decomposition is used for the deep network. In <ref type="bibr" target="#b40">[41]</ref>, the authors generalize their previous results by inserting nonlinear activation functions (only linear activation functions were considered in <ref type="bibr" target="#b39">[40]</ref>). The aforementioned works have a complementary role to our work, since their intent is to characterize (the depth efficiency of) convolutional neural networks, while our goal is to use polynomial expansion to approximate the target function.</p><p>Another instance of such polynomial networks is through multiplicative interactions. Recently, there is a surge of methods <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref> reporting superior performance through multiplicative interactions. The work of <ref type="bibr" target="#b9">[10]</ref> provides a theoretical understanding on why such connections might be beneficial. The aforementioned works model interactions of second or third order. Polynomial networks can be seen as high-order generalizations of such multiplicative interactions <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation</head><p>Tensors 2 are symbolized by calligraphic letters, e.g., X , while matrices (vectors) are denoted by uppercase (lowercase) boldface letters e.g., X, (x). A set of M real matrices (vectors) of varying dimensions is denoted by tX rms P R ImˆN u M m"1 ptx rms P R Im u M m"1 q. Products: The Hadamard product of A P R IˆN and B P R IˆN is defined as A˚B and is equal to A pi,jq B pi,jq for the pi, jq element. The Khatri-Rao product of matrices A P R IˆN and B P R JˆN is denoted by AdB and yields a matrix of dimensions 2. Further details on the tensor notation are deferred to the supplementary.   pIJqˆN . For a set of matrices tA rms P R ImˆN u M m"1 the Khatri-Rao product is denoted by:</p><formula xml:id="formula_0">A r1s d A r2s d¨¨¨d A rM s . " M ä m"1 A rms<label>(1)</label></formula><p>Tensors: Each element of an M th order tensor X is addressed by M indices, i.e., pX q i1,i2,...,i M</p><p>. " x i1,i2,...,i M . An M thorder real-valued tensor X is defined over the tensor space R I1ˆI2ˆ¨¨¨ˆI M , where I m P Z for m " 1, 2, . . . , M . The modem vector product of X with a vector u P R Im , denoted by Xˆm u P R I1ˆI2ˆ¨¨¨ˆIm´1ˆIm`1ˆ¨¨¨ˆI M , results in a tensor of order M´1:</p><formula xml:id="formula_1">pXˆm uq i1,...,im´1,im`1,...,i M " Im ÿ im"1 x i1,i2,...,i M u im . (2) Furthermore, we denote Xˆ1 u p1qˆ2 u p2qˆ3¨¨¨ˆM u pM q . " X ś m m"1ˆm u pmq .</formula><p>A core tool in our analysis is the CP decomposition that factorizes a tensor into a sum of component rank-one tensors <ref type="bibr" target="#b44">[45]</ref>. By considering the mode-1 unfolding of an M th -order tensor X , the CP decomposition can be written in matrix form as <ref type="bibr" target="#b44">[45]</ref>: X p1q</p><p>. " U r1sˆÄ 2 m"M U rms˙T where tU rms u M m"1 are the factor matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHOD</head><p>We want to learn a function approximator where each element of the output x j , with j P r1, os, is expressed as a polynomial 3 of all the input elements z i , with i P r1, ds. That is, we want to learn a function G : R d Ñ R o of order N P N, such that:</p><formula xml:id="formula_2">x j " Gpzq j " β j`w r1s j T z`z T W r2s j zẀ r3s jˆ1 zˆ2 zˆ3 z`¨¨¨`W rN s j N ź n"1ˆn z<label>(3)</label></formula><p>where β j P R, and W rns j P R ś n m"1ˆm d ( N n"1 are parameters for approximating the output x j . The correlations (of the input elements z i ) up to N th order emerge in <ref type="bibr" target="#b2">(3)</ref>. A more compact expression of (3) is obtained by vectorizing the outputs:</p><formula xml:id="formula_3">x " Gpzq " N ÿ n"1ˆW rns n`1 ź j"2ˆj z˙`β<label>(4)</label></formula><p>where β P R o and W rns P R oˆś n m"1ˆm d ( N n"1 are the learnable parameters. This form of (4) allows us to approximate <ref type="bibr" target="#b2">3</ref>. The theorem of <ref type="bibr" target="#b45">[46]</ref> guarantees that any smooth function can be approximated by a polynomial. The approximation of multivariate functions is covered by an extension of the Weierstrass theorem, e.g., in <ref type="bibr" target="#b46">[47]</ref> (pg 19). any smooth function (for large N ), however the parameters grow with Opd N q.</p><p>A variety of methods, such as pruning <ref type="bibr" target="#b47">[48]</ref>, <ref type="bibr" target="#b48">[49]</ref>, special linear operators <ref type="bibr" target="#b49">[50]</ref> with reduced parameters, parameter sharing/prediction <ref type="bibr" target="#b50">[51]</ref>, <ref type="bibr" target="#b51">[52]</ref>, can be employed to reduce the parameters. The aforementioned approaches are post-processing techniques, i.e., given a (pre-trained) network, they reduce the parameters of the specific network. Instead, we design two principled ways which allow an efficient implementation. The first method relies on performing an off-the-shelf tensor decomposition on (4), while the second considers the final polynomial as the product of lowerdegree polynomials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Single polynomial</head><p>A tensor decomposition on the parameters is a natural way to reduce the parameters and to implement (4) with a neural network. Below, we demonstrate how three such decompositions result in novel architectures for a neural network training. The main symbols are summarized in <ref type="table" target="#tab_0">Table 1</ref>, while the equivalence between the recursive relationship and the polynomial is analyzed in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model 1: CCP (Coupled CP decomposition)</head><p>Instead of factorizing each parameter tensor W rns individually we propose to jointly factorize all the parameter tensors using a coupled CP decomposition <ref type="bibr" target="#b44">[45]</ref> with a specific pattern of factor sharing. To illustrate the factorization, we assume a third order approximation (N " 3), and then provide the recursive relationship that can scale to arbitrary expansion.</p><p>Let us assume that the parameter tensors admit the following coupled CP decomposition with the factors corresponding to lowerorder levels of approximation being shared across all parameters tensors. That is:</p><formula xml:id="formula_4">‚ Let W r1s " CU T</formula><p>r1s , be the parameters for first level of approximation. ‚ Let W r2s being a superposition of of two weights tensors, namely W r2s " W r2s 1:2`W r2s 1:3 , with W r2s i:j denoting parameters associated with the second order interactions across the i th and j th order of approximation. By enforcing the CP decomposition of the above tensors to share the factor with tensors corresponding to lower-order of approximation we obtain in matrix form:</p><formula xml:id="formula_5">W r2s p1q " CpU r3s d U r1s q T`C pU r2s d U r1s q T . ‚</formula><p>Similarly, we enforce the third-order parameters tensor to admit the following CP decomposition (in matrix form) W r3s p1q " CpU r3s d U r2s d U r1s q T . Note that all but the U r3s factor matrices are shared in the factorization of tensors capturing polynomial parameters for the first and second order of approximation.</p><p>The parameters are C P R oˆk , U rms P R dˆk for m " 1, 2, 3. Then, (4) for N " 3 is written as:</p><formula xml:id="formula_6">Gpzq " β`CU T r1s z`C´U r3s d U r1s¯T pz d zqC´U r2s d U r1s¯T pz d zqC´U r3s d U r2s d U r1s¯T pz d z d zq<label>(5)</label></formula><p>Using the Lemma 1 (provided in the supplementary), we can transform the (5) into a neural network as depicted in <ref type="figure" target="#fig_1">Fig. 2</ref>.</p><p>The CCP factorization generalizes to N th order expansion. The recursive relationship for the N th order approximation is:</p><formula xml:id="formula_7">x n "´U T rns z¯˚x n´1`xn´1<label>(6)</label></formula><p>for n " 2, . . . , N with </p><formula xml:id="formula_8">x 1 " U T r1s z and x " Cx N`β . The parameters C P R oˆk , U rns P R dˆk for n " 1, . . . , N are learnable. z U [1] * + U [2] G(z) * + U [3] * + C β</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model 2: NCP (Nested coupled CP decomposition)</head><p>Instead of explicitly separating the interactions between layers, we can utilize a joint hierarchical decomposition on the polynomial parameters. Let us first introduce learnable hyper-parameters b rns P R ω ( N n"1 , which act as scaling factors for each parameter tensor. Therefore, we modify (4) to:</p><formula xml:id="formula_9">Gpzq " N ÿ n"1ˆW rnsˆ2 b rN`1´ns n`2 ź j"3ˆj</formula><p>z˙`β, <ref type="bibr" target="#b6">(7)</ref> with W rns P R oˆωˆś n m"1ˆm d ( N n"1 . Similarly to CCP, we demonstrate the decomposition assuming a third order approximation (N " 3), and then provide the general recursive relationship.</p><p>To estimate the parameters (in N " 3 expansion) we jointly factorize all parameter tensors by employing nested CP decomposition with parameter sharing as follows (in matrix form):</p><formula xml:id="formula_10">‚ First order parameters : W r1s p1q " CpA r3s d B r3s q T . ‚ Second order parameters: W r2s p1q " C " A r3s d "´A r2s d B r2s¯Sr3s * T . ‚</formula><p>Third order parameters:</p><formula xml:id="formula_11">W r3s p1q " C " A r3s d "ˆA r2s d !´A r1s d B r1s¯Sr2s )˙S r3s * T with C P R oˆk , A rns P R dˆk , S rns P R kˆk , B rns P R ωˆk for n " 1, .</formula><p>. . , N . Altogether, <ref type="bibr" target="#b6">(7)</ref> for N " 3 is written as:</p><formula xml:id="formula_12">Gpzq " β`CpA r3s d B r3s q T pz d b r3s qC " A r3s d "´A r2s d B r2s¯Sr3s * T´z d z d b r2s¯C " A r3s d "ˆA r2s d !´A r1s d B r1s¯Sr2s )˙S r3s * T µ<label>(8)</label></formula><p>with µ "´z d z d z d b r1s¯. Using Lemma1 and further algebraic operations (see Sec. 3.2 in the supplementary), (8) can be implemented by a neural network as depicted in <ref type="figure" target="#fig_0">Fig. 3</ref>.</p><p>The recursive relationship for N th order approximation is defined as: The expressiveness of NCP can be further extended using a skip connection (motivated by CCP). The new model uses a nested coupled decomposition and has the following recursive expression:</p><formula xml:id="formula_13">x n "´A T rns z¯˚´S T rns x n´1`B T rns b rns¯( 9) for n " 2, . . . , N with x 1 "´A T r1s z¯˚´B T r1s b r1s¯a nd x " Cx N`β . The parameters C P R oˆk , A rns P R dˆk , S rns P R kˆk , B rns P R ωˆk , b rns P R ω for n " 1, . . . , N , are learnable. b[1] B[1] * S[2] + * S[3] + * C + A[1] A[2] A[3] z B[2] B[3] b[2] b[3] β G(z)</formula><formula xml:id="formula_14">x n "´A T rns z¯˚´S T rns x n´1`B T rns b rns¯`Vrns x n´1 (10)</formula><p>for n " 2, . . . , N with x 1 "´A T r1s z¯˚´B T r1s b r1s¯a nd x " Cx N`β . The parameters V rns P R kˆk are learnable, while the rest parameters are the same as in NCP. The difference in the recursive form results in a different polynomial expansion and thus architecture.  Comparison between the models All three models (see <ref type="table" target="#tab_1">Table 2</ref> for names and schematics) are based on a polynomial expansion, however their recursive forms and employed decompositions differ.</p><formula xml:id="formula_15">+ * C + A[1] A[2] A[3] z B[2] B[3] b[2] b[3] β G(z) + + V[2] V[3]</formula><p>CCP is a straightforward coupled decomposition and is a proof of concept that polynomials can learn high-dimensional distributions. NCP illustrates how to convert a popular CNN/linear model of the form x k " S T rks x k´1`brks to a polynomial (i.e., x k " pA T rks zq˚pS T rks x k´1`brks q). Similarly, NCP-Skip demonstrates how a residual network can be transformed into a polynomial. <ref type="bibr" target="#b4">5</ref> An illustrative comparison of the three decompositions is conducted below. The challenging task of synthesizing images is selected. Each model is implemented using the respective decomposition, i.e., CCP, NCP, NCP-Skip. Following the derivations of the previous few paragraphs, we train a generator without activation functions between the blocks; a single hyperbolic tangent is used in the output space as a normalization <ref type="bibr" target="#b3">4</ref> . The generator is trained with an adversarial loss, i.e., using Generative Adversarial Nets (GANs) <ref type="bibr" target="#b52">[53]</ref>. GANs typically consist of two deep networks, namely a generator G and a discriminator D. G is a decoder, which receives as input a random noise vector z P R d and outputs a sample x " Gpzq. D receives as input both Gpzq and real samples and tries to differentiate the fake and the real samples. During training, both G and D compete against each other.</p><p>The three models are originally compared in fashion image generation. The outcomes, visualized in <ref type="figure">Fig. 5</ref>, demonstrate similar generation properties.</p><p>In <ref type="figure" target="#fig_5">Fig. 6</ref>, samples of the three models are synthesized when trained facial images. All three models can generate faces without activation functions between the layers, while the three models share similar generation quality.</p><p>In the remainder of the paper, for comparison purposes we use the NCP by default for the image generation and NCP-Skip for the image classification. In all cases, to mitigate stability issues that might emerge during training, we employ certain normalization schemes that constrain the magnitude of the gradients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Product of polynomials</head><p>Instead of using a single polynomial, we express the function approximation as a product of polynomials. The product is implemented as successive polynomials where the output of the i th polynomial is used as the input for the pi`1q th polynomial. The concept is visually depicted in <ref type="figure">Fig. 7</ref>; each polynomial expresses a second order expansion. Stacking N such polynomials results in an overall order of 2 N . Trivially, if the approximation of each polynomial is B and we stack N such polynomials, the total order is B N . The product does not necessarily demand the same order in each polynomial, the model and the expansion order of each polynomial can be different and dependent on the task. For instance, for generative tasks that the resolution increases progressively, the expansion order could increase in the last polynomials. In all cases, the final order will be the product of each polynomial power.</p><p>There are two main benefits of the product over the single polynomial: a) it allows using different decompositions (e.g., like in Sec. 3.1) and expansion order for each polynomial; b) it requires much fewer parameters for achieving the same order of approximation. Given the benefits of the product of polynomials, we assume below that a product of polynomials is used, unless explicitly mentioned otherwise. The respective model of product polynomials is called ProdPoly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Task-dependent input/output</head><p>The aforementioned polynomials are a function x " Gpzq, where the input/output are task-dependent. For a generative task, e.g., learning a decoder, the input z is typically some low-dimensional noise, while the output is a high-dimensional signal, e.g., an image. For a discriminative task the input z is an image; for a domain <ref type="bibr" target="#b3">4</ref>. Further experiments without activation functions are deferred to the supplementary.  <ref type="bibr" target="#b55">[56]</ref> generation. The scores of <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b60">[61]</ref> are added from the respective papers as using similar residual based generators. The scores of <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b63">[64]</ref>  adaptation task the signal z denotes the source domain and x the target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>We conduct four experiments against state-of-the-art models in three diverse tasks 5 : image generation, image classification, face verification/identification and graph representation learning. In each case, the baseline considered is converted into an instance of our family of Π-nets and the two models are compared. Experiments on image generation and image classification without using activation functions between the layers are deferred to the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Image generation</head><p>The robustness of ProdPoly in image generation is assessed in two different architectures/datasets below. SNGAN on CIFAR10: In the first experiment, the architecture of SNGAN <ref type="bibr" target="#b3">[4]</ref> is selected as a strong baseline on CIFAR10 <ref type="bibr" target="#b55">[56]</ref>. The baseline includes 3 residual blocks in the generator and the discriminator.</p><p>The generator is converted into a Π-net, where each residual block is a single order of the polynomial. We implement two versions, one with a single polynomial (NCP) and one with product of polynomials (where each polynomial uses NCP). In our implementation A rns is a thin FC layer, pB rns q T b rns is a bias vector and S rns is the transformation of the residual block. Other than the aforementioned modifications, the hyper-parameters (e.g., discriminator, learning rate, optimization details) are kept the same as in SNGAN <ref type="bibr" target="#b3">[4]</ref>.</p><p>Each network was run for 10 times and the mean and variance are reported. The popular Inception Score (IS) <ref type="bibr" target="#b56">[57]</ref> and the Frechet Inception Distance (FID) <ref type="bibr" target="#b57">[58]</ref> are used for quantitative evaluation. Both scores extract feature representations from a pre-trained classifier (the Inception network <ref type="bibr" target="#b58">[59]</ref>).</p><p>The quantitative results are summarized in <ref type="table" target="#tab_3">Table 3</ref>. In addition to SNGAN and our two variations with polynomials, we have added the scores of <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b60">[61]</ref>, <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b63">[64]</ref> as reported in the respective papers. Note that the single polynomial already outperforms the baseline, while the ProdPoly boosts the performance further and achieves a substantial improvement over the original SNGAN.</p><p>StyleGAN on FFHQ: StyleGAN <ref type="bibr" target="#b8">[9]</ref> is the state-of-the-art architecture in image generation. The generator is composed of two parts, namely: (a) the mapping network, composed of 5. The source code is available in https://github.com/grigorisg9gr/ polynomial_nets.  Order 2 N * * <ref type="figure">Fig. 7</ref>: Abstract illustration of the ProdPoly. The input variable z on the left is the input to a 2 nd order expansion; the output of this is used as the input for the next polynomial (also with a 2 nd order expansion) and so on. If we use N such polynomials, the final output Gpzq expresses a 2 N order expansion. In addition to the high order of approximation, the benefit of using the product of polynomials is that the model is flexible, in the sense that each polynomial can be implemented as a different decomposition of Sec. 3.1. <ref type="bibr" target="#b30">[31]</ref> and progressively learns to synthesize high quality images. The sampled noise is transformed by the mapping network and the resulting vector is then used for the synthesis network. As discussed in the introduction, StyleGAN is already an instance of the Π-net family, due to AdaIN. Specifically, the k th AdaIN layer is h k " pA T k wq˚npcph k´1 qq, where n is a normalization, c the convolution operator and w is the transformed noise w " M LP pzq (mapping network). This is equivalent to our NCP model by setting S T rks as the convolution operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">FC layers, and (b) the synthesis network, which is based on ProGAN</head><p>In this experiment we illustrate how simple modifications, using our family of products of polynomials, further improve the representation power. We make a minimal modification in the mapping network, while fixing the rest of the hyper-parameters. In particular, we convert the mapping network into a polynomial (specifically a NCP), which makes the generator a product of two polynomials.</p><p>The Flickr-Faces-HQ Dataset (FFHQ) dataset <ref type="bibr" target="#b8">[9]</ref> which includes 70, 000 images of high-resolution faces is used. All the images are resized to 256ˆ256. The best FID scores of the two methods (in 256ˆ256 resolution) are 6.82 for ours and 7.15 for the original StyleGAN, respectively. That is, our method improves the results by 5%. Synthesized samples of our approach are visualized in <ref type="figure">Fig. 8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Classification</head><p>We perform two experiments on classification: a) audio classification, b) image classification. Residual Network (ResNet) <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b42">[43]</ref> and its variants <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b64">[65]</ref>, <ref type="bibr" target="#b65">[66]</ref>, <ref type="bibr" target="#b66">[67]</ref>, <ref type="bibr" target="#b67">[68]</ref> have been applied to diverse tasks including object detection and image generation <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b59">[60]</ref>, <ref type="bibr" target="#b60">[61]</ref>. The core component of ResNet is the residual block; the t th residual block is expressed as z t`1 " z t`C z t for input z t . Each residual block is adapted (using NCP-Skip) to express a higher-order expansion; this is achieved by using V rns " I`S rns in (10), where I is an identity matrix. The output of each residual block is the input for the next residual block, which makes our ResNet a product of polynomials.</p><p>Audio classification: The goal of this experiment is to reduce the number of residual blocks (of higher-order polynomial expansion) without sacrificing the performance of the original ResNet, while validating the performance of the proposed method in a distribution that differs from that of natural images.</p><p>The performance of ResNet is evaluated on the Speech Commands dataset <ref type="bibr" target="#b68">[69]</ref>. The dataset includes 60, 000 audio files; each audio contains a single word of a duration of one second. There are 35 different words (classes) with each word having 1, 500´4, 100 recordings. Every audio file is converted into a mel-spectrogram of resolution 32ˆ32. Each method is trained for 70 epochs with SGD and initial learning rate of 0.01. The learning rate is reduced if the validation accuracy does not improve for two consecutive epochs.</p><p>The baseline is a ResNet34 architecture; we use secondorder residual blocks to build the Prodpoly-ResNet to match the performance of the baseline. The quantitative results are added in <ref type="table" target="#tab_5">Table 4</ref>. The two models share the same accuracy, however Prodpoly-ResNet includes 38% fewer parameters. This result validates our assumption that Π-nets can achieve the same performance with less parameters than the baseline. Classification on CIFAR: The performance of the polynomial networks is also assessed on CIFAR10 and CIFAR100 classification. The goal is to reduce the number of residual blocks (of higher-order polynomial expansion) without sacrificing the performance of the original ResNet.</p><p>We select the ResNet18 and ResNet34 as baselines. Each method is trained for 120 epochs with batch size 128. The SGD optimizer is used with initial learning rate of 0.1. The learning rate is multiplied with a factor of 0.1 in epochs 40, 60, 80, 100. In <ref type="table" target="#tab_6">Table 5</ref> the two different ResNet baselines are compared against Prodpoly-ResNet on CIFAR10; the respective Prodpoly-ResNet models have the same accuracy. However, each Prodpoly-ResNet has " 40% less parameters than the respective baseline. In addition, we visualize the test accuracy for ResNet18 and the respective Prodpoly-ResNet in <ref type="figure" target="#fig_7">Fig. 9</ref>. The test error of the two models is similar throughout the training.</p><p>The same experiment is repeated on CIFAR100 with ResNet34 as the baseline. <ref type="table" target="#tab_7">Table 6</ref> exhibits a similar pattern. That is, the test accuracy of ResNet34 and Prodpoly-ResNet is similar, however Prodpoly-ResNet has " 30% less parameters. Classification on ImageNet: We perform a large-scale classification experiment on ImageNet <ref type="bibr" target="#b69">[70]</ref>. Models are trained on a DGX station with 4 Tesla V100 (32GB) GPUs. To stabilize the training, the second order of each residual block is normalized with a hyperbolic tangent unit. SGD with momentum 0.9, weight decay 10´4 and a mini-batch size of 512 is used. The initial learning rate is set to 0.2 and decreased by a factor of 10 at 30, 60, and 80 epochs. Models are trained for 90 epochs from scratch, using linear warm-up of the learning rate during first five epochs according to <ref type="bibr" target="#b70">[71]</ref>.</p><p>The Top-1 and Top-5 error throughout the training is visualized in <ref type="figure" target="#fig_8">Fig. 10</ref>, while the validation results are added in <ref type="table" target="#tab_8">Table 7</ref>. For a fair comparison, we report the results from our training in both the original ResNet and Prodpoly-ResNet 6 . Prodpoly-ResNet consistently improves the performance with a negligible increase in computational complexity. Remarkably, Prodpoly-ResNet50 achieves a single-crop Top-1 validation error of 22.827% and Top-5 validation error of 6.431%, exceeding ResNet50 by 0.719% and 0.473%, respectively. <ref type="bibr" target="#b5">6</ref>. The performance of the original ResNet <ref type="bibr" target="#b4">[5]</ref> is inferior to the one reported here and in <ref type="bibr" target="#b71">[72]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Face verification and identification</head><p>We scrutinize the performance of the Π-nets on the challenging task of face recognition. The architecture of the current state-of-the-art method of ArcFace <ref type="bibr" target="#b72">[73]</ref> is a ResNet, which we can convert into a polynomial network using the NCP-Skip.</p><p>Training Data: The data of MS1M-RetinaFace dataset <ref type="bibr" target="#b73">[74]</ref>, <ref type="bibr" target="#b74">[75]</ref> consist the training images; all face images inside MS1M-RetinaFace are pre-processed to the size of 112ˆ112 based on the five facial landmarks predicted by RetinaFace <ref type="bibr" target="#b75">[76]</ref>. In total, there are 5.1M images of 93K identities. Testing Data: The performance is compared on widely used face verification data-sets (e.g., LFW <ref type="bibr" target="#b76">[77]</ref>, CFP <ref type="bibr" target="#b77">[78]</ref>, AgeDB <ref type="bibr" target="#b78">[79]</ref>, CPLFW <ref type="bibr" target="#b79">[80]</ref>, CALFW <ref type="bibr" target="#b80">[81]</ref> and RFW <ref type="bibr" target="#b81">[82]</ref>). Besides, we also extensively test the proposed method on large-scale benchmarks (e.g., IJB-B <ref type="bibr" target="#b82">[83]</ref>, IJB-C <ref type="bibr" target="#b83">[84]</ref> and MegaFace <ref type="bibr" target="#b84">[85]</ref>); the fundamental statistics of all the datasets are summarized in <ref type="table" target="#tab_9">Table 8</ref>. To get the embedding features for templates (e.g., IJB-B <ref type="bibr" target="#b82">[83]</ref> and IJB-C <ref type="bibr" target="#b83">[84]</ref>), we simply calculate the feature center of all images from the template or all frames from the video.</p><p>Training Details: For the baseline embedding network, we employ the widely used CNN architecture, ResNet50. Specifically, we follow <ref type="bibr" target="#b72">[73]</ref> to set the feature scale s to 64 and choose the angular margin m at 0.5. The batch size is set to 512 with momentum 0.9 and weight decay 5e´4, while we decrease the learning rate in iterations 100K, 160K, 220K. The training finishes after 30 epochs. The implementation is by MXNet <ref type="bibr" target="#b72">[73]</ref>, <ref type="bibr" target="#b85">[86]</ref> and the models are trained on 8 NVIDIA 2080ti (11GB) GPUs.</p><p>The baseline residual block is converted into a second-order residual block to build the Prodpoly-ResNet, while we keep all the other settings exactly the same as the baseline. After training, we only keep the feature embedding network without the fully connected layer (174.5MB for ResNet50 and 181.8MB for Prodpoly-ResNet50) and extract the 512-D features (5.76 ms/face for ResNet50 and 6.02 ms/face for Prodpoly-ResNet50) for  <ref type="bibr" target="#b77">[78]</ref> consists of collected images of celebrities in frontal and profile views. On CFP, there are two evaluation protocols: CFP-Frontal-Frontal and CFP-Frontal-Profile. CFP-Frontal-Profile is very challenging as the pose gap within positive pairs is around 90˝. CPLFW <ref type="bibr" target="#b79">[80]</ref> was collected by crowd-sourcing efforts to seek the pictures of people in LFW with pose gap as large as possible from the Internet. CALFW <ref type="bibr" target="#b80">[81]</ref> is similar to CALFW, but from the perspective of age difference. AgeDB <ref type="bibr" target="#b78">[79]</ref> contains manually annotated images.</p><p>In this paper, we use the evaluation protocol with 30 years gap <ref type="bibr" target="#b72">[73]</ref>. RFW <ref type="bibr" target="#b81">[82]</ref> is a benchmark for measuring racial bias, which consists of four test subsets, namely Caucasian, Indian, Asian and African. The quantitative results of the comparisons are exhibited in <ref type="table" target="#tab_10">Table 9</ref>. On LFW and CFP-FP, the results of ResNet50 and Prodpoly-ResNet50 are similar to face verification on semi-frontal faces is saturated. Nevertheless, Prodpoly-ResNet50 significantly outperforms ResNet50 on CFP-FP, CPLFW, AgeDB-30, CALFW and RFW, indicating that the proposed method can enhance the robustness of the embedding features under pose variations, age In <ref type="figure">Figure 11</ref>, ROC curves of ResNet50 and Prodpoly-ResNet50 under 1:1 verification protocol on IJB-B and IJB-C is plotted. On IJB-B, there are 12, 115 templates with 10, 270 genuine matches and 8M impostor matches. On IJB-C, there are 23, 124 templates with 19, 557 genuine matches and 15, 639K impostor matches. The proposed method surpasses the baseline by a clear margin. The comparison of TAR in <ref type="table" target="#tab_0">Table 10</ref> illustrates that Prodpoly-ResNet50 improves the TAR (@FAR=1e-4) by 0.46% and 0.41% on IJB-B and IJB-C, respectively. <ref type="table" target="#tab_0">Table 11</ref> compares ResNet50 and Prodpoly-ResNet50 under the 1:N end-to-end mixed protocol, which contains both still images and full-motion videos. On IJB-B, there are 10, 270 probe templates containing 60, 758 still images and video frames. On IJB-C, there are 19, 593 probe templates containing 127, 152 still images and video frames. Prodpoly-ResNet50 outperforms ResNet50 by 0.23% and 0.34% on IJB-B and IJB-C rank-1 face identification.   Results on MegaFace. The MegaFace dataset <ref type="bibr" target="#b84">[85]</ref> includes 1M images of 690K different individuals as the gallery set and 100K photos of 530 unique individuals from FaceScrub <ref type="bibr" target="#b86">[87]</ref> as the probe set. On MegaFace, there are two testing protocols (e.g., identification and verification). <ref type="table" target="#tab_0">Table 12</ref> show the identification and verification results on MegaFace dataset. In particular, the proposed Prodpoly-ResNet50 achieve 0.50% improvement at the Rank-1@1e6 identification rate and 0.31% improvement at the verification TPR@FAR=1e-6 rate over the baseline ResNet50. In <ref type="figure" target="#fig_1">Figure 12</ref>, Prodpoly-ResNet50 shows superiority over ResNet50 and forms an upper envelope under both identification and verification scenarios. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">3D Mesh representation learning</head><p>Below, we evaluate higher order correlations in graph related tasks. We experiment with 3D deformable meshes of fixed topology <ref type="bibr" target="#b87">[88]</ref>, i.e., the connectivity of the graph G " tV, Eu remains the same and each different shape is defined as a different signal x on the vertices of the graph: x : V Ñ R d . As in the previous experiments, we extend a state-of-the-art operator, namely spiral convolutions <ref type="bibr" target="#b88">[89]</ref>, with the ProdPoly formulation and test our method on the task of autoencoding 3D shapes. We use the existing architecture and hyper-parameters of <ref type="bibr" target="#b88">[89]</ref>, thus showing that ProdPoly can be used as a plug-and-play operator to existing models, turning the aforementioned one into a Spiral Π-Net. Our implementation uses a product of polynomials (referred as ProdPoly full), where each layer is a N th order polynomial instantiated as a specific case of (9) or (10):</p><formula xml:id="formula_16">NCP: x n "´A T rns x 1¯˚´S T rns x n´1¯`A T rns x 1 NCP-Skip: x n "´A T rns x 1¯˚´S</formula><p>T rns x n´1¯`A T rns x 1`xn´1 , x " x N`β , where A rns , S rns are spiral convolutions written in matrix form, β is a bias vector, x 1 , x is the input (which is equal to the output of the previous layer) and the output of the layer respectively. Stability of the optimization is ensured by applying vertex-wise instance normalization on the 2 nd order term of the recursive formulation.</p><p>Additionally, we evaluate our formulation with a simpler model (ProdPoly simple) that allows for an attractive trade-off between increased expressivity and constrained parameter budget. In specific, we can create higher-order polynomials without adding new blocks in the original architecture as follows:</p><formula xml:id="formula_17">x N " ř N n"2´S T x 1¯˚´S T x 1¯¨¨¨´S T x 1l oooooooooooooooooooomoooooooooooooooooooon n times`S T x 1`β .</formula><p>We use the same normalization scheme as before, by independently normalizing each higher order term. Note that here we only use one learnable operator S (spiral convolution) per layer. It is interesting to notice that this model can be also re-interpreted as a learnable polynomial activation function as in <ref type="bibr" target="#b14">[15]</ref>, which is a specific case of ProdPoly. Polynomial activation functions lead to increased expressivity per se, but are less expressive when compared to richer multiplicative interactions as introduced by our NCP and NCPskip models. In addition, as can be seen in <ref type="figure" target="#fig_0">Fig. 13</ref>, experimental evidence suggests that such interactions also lead to improved empirical performance.   In <ref type="figure" target="#fig_0">Fig. 13</ref>, we compare the reconstruction error of the proposed method to the baseline spiral convolutions along with other popular graph learnable operators, i.e., the Graph Attention Network (GAT) <ref type="bibr" target="#b89">[90]</ref>, FeastNet <ref type="bibr" target="#b90">[91]</ref>, Mixture model CNNs (MoNet) <ref type="bibr" target="#b91">[92]</ref>, Convolutional Mesh Autoencoders (COMA) <ref type="bibr" target="#b87">[88]</ref> which are based on the spectral graph filters of ChebNet <ref type="bibr" target="#b92">[93]</ref>, as well as with Principal Component Analysis (PCA), which is quite popular in shape analysis applications <ref type="bibr" target="#b93">[94]</ref>. The evaluation is performed on two popular 3D deformable shape benchmarks, COMA <ref type="bibr" target="#b87">[88]</ref> and DFAUST <ref type="bibr" target="#b94">[95]</ref>, that depict facial expressions and body poses respectively. Π-nets outperform all published methods even when discarding the activation functions across the entire network. Similar patterns emerge in both datasets: NCP and NCP-Skip behave similarly regardless of the absence of activation functions or not, leading to an increased performance when the order of the polynomial increases, i.e. empirical performance improves along with expressivity. Moreover, the simple model provides a boost in performance as well, although we observe a decrease for the 3 rd and 4 th order of the linear model, which might be attributed to overfitting (similarly to the linear experiments in Sec. 5 in the supplementary material). Overall, we showcase that performance may seamlessly improve by converting the existing architecture to a polynomial, without having to increase the depth or width of the architecture as frequently done by ML practitioners, and with small sacrifices in terms of inference time (see Sec. 6, supplementary) and parameter count.</p><p>Finally, in <ref type="figure" target="#fig_3">Fig. 14</ref> we assess how the order of the polynomial qualitatively reflects in the reconstruction of an exemplary mesh. In particular, we color code the per vertex reconstruction error on the reconstructed meshes (right) and compare them with the input (left). Notice that the overall shape resembles the input more as we increase the order of the polynomial (especially in the head), while body parts with strong articulations (e.g. hands) are reconstructed with higher fidelity. <ref type="figure" target="#fig_0">Fig. 13</ref>: ProdPoly vs 1 st order graph learnable operators for mesh autoencoding. Note that even without using activation functions the proposed methods significantly improve upon the state-of-the-art.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">FUTURE DIRECTIONS</head><p>The new class of Π´nets has strong experimental results and few empirical theoretical results already. We expect in the following years new works that improve our results and extend our formulation. To that end, we summarize below several fundamental topics that are open for interested practitioners.</p><p>The generalization of the Π´nets is a crucial topic. In our evaluation without activation functions, we noticed that polynomials might be prone to overfitting (e.g., in the classification setting without activation functions in the supplementary). When we add the non-linear activation functions we did not observe such a consistent pattern. In this work, we created a link between different decompositions and the resulting architectures (the three decompositions resulted in three different architectures). The relationship between neural architecture search and the tensor decomposition can be further nurtured.</p><p>Reducing the network redundancy is also an exciting topic. The theoretical properties of multiplicative interactions along with our experiments, exhibit how polynomial neural networks can be used to reduce the network redundancy. Additional post-processing techniques, such as pruning, or exploiting tools from the tensor methods, such as low-rank constraints, might be beneficial in this context.</p><p>Lastly, Π´nets inherit the properties of polynomials, e.g., higher-order terms might result in unbounded gradients. That makes studying normalization schemes of paramount significance. There might be normalization techniques that obtain a superior performance to the batch/instance normalization we employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>In this work, we have introduced a new class of DCNNs, called Π-Nets, that perform function approximation using a polynomial neural network. Our Π-Nets can be efficiently implemented via a special kind of skip connections that lead to high-order polynomials, naturally expressed with tensorial factors. The proposed formulation extends the standard compositional paradigm of overlaying linear operations with activation functions. We motivate our method by a sequence of experiments without activation functions that showcase the expressive power of polynomials, and demonstrate that Π-Nets are effective in both discriminative, as well as generative tasks. Trivially modifying state-of-the-art architectures in image generation, image and audio classification, face verification/identification as well as mesh representation learning, the performance consistently improves.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>3</head><label>3</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :</head><label>2</label><figDesc>Schematic illustration of the CCP (for third order approximation). Symbol˚refers to the Hadamard product.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Schematic illustration of the NCP (for third order approximation). Symbol˚refers to the Hadamard product.Model 3: NCP-Skip (Nested coupled CP decomposition with skip)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 :</head><label>4</label><figDesc>Schematic illustration of the NCP-Skip (for third order approximation). The difference fromFig. 3is the skip connections added in this model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>6 ( 5 :</head><label>65</label><figDesc>Comparison of the proposed models in fashion image<ref type="bibr" target="#b53">[54]</ref> generation without activation functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>6 :</head><label>6</label><figDesc>Comparison of the proposed models in facial image<ref type="bibr" target="#b54">[55]</ref> generation without activation functions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>7 Fig. 8 :</head><label>78</label><figDesc>Samples synthesized from ProdPoly (trained on FFHQ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>9 :</head><label>9</label><figDesc>The test accuracy of (a) ResNet18 and (b) the respective Prodpoly-ResNet are plotted (CIFAR10 training). The two models perform similarly throughout the training, while ours has 46% less parameters. The width of the highlighted region denotes the standard deviation of each model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>10 :</head><label>10</label><figDesc>Top-1 and Top-5 error curves on the ImageNet dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>10</head><label>10</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>(</head><label></label><figDesc>b) ROC for IJB-C Fig. 11: ROC curves of ResNet50 and Prodpoly-ResNet50 under 1:1 verification protocol on the IJB-B and IJB-C dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>12 :</head><label>12</label><figDesc>CMC and ROC curves of ResNet50 and the proposed Prodpoly-ResNet50 on MegaFace. Results are evaluated on the refined MegaFace dataset<ref type="bibr" target="#b72">[73]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 14 :</head><label>14</label><figDesc>Color coding of the per vertex reconstruction error on an exemplary human body mesh. From left to right: ground truth mesh, 1st order SpiralGNN, 2 nd , 3 rd and 4 th order Spiral ProdPoly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 :</head><label>1</label><figDesc>Input to the polynomial approximator. C, β R oˆk , R o Parameters in all decompositions. A rns , S rns , B rns R dˆk , R kˆk , R ωˆk Matrix parameters in the hierarchical decomposition.</figDesc><table><row><cell></cell><cell></cell><cell>Nomenclature</cell></row><row><cell>Symbol</cell><cell>Dimension(s)</cell><cell>Definition</cell></row><row><cell>n, N</cell><cell>N</cell><cell>Polynomial term order, total approximation order.</cell></row><row><cell>k</cell><cell>N</cell><cell>Rank of the decompositions.</cell></row><row><cell cols="2">d,˚-</cell><cell>Khatri-Rao product, Hadamard product.</cell></row></table><note>z Rd</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="3">: Single polynomial</cell></row><row><cell cols="2">models (Sec. 3.1)</cell><cell></cell></row><row><cell>Name</cell><cell>Schematic</cell><cell>Recursive eq.</cell></row><row><cell>CCP</cell><cell>Fig. 2</cell><cell>(6)</cell></row><row><cell>NCP</cell><cell>Fig. 3</cell><cell>(9)</cell></row><row><cell>NCP-Skip</cell><cell>Fig. 4</cell><cell>(10)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3 :</head><label>3</label><figDesc>IS/FID scores on CIFAR10</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>represent alternative generative models. ProdPoly outperforms the compared methods in both metrics.</figDesc><table><row><cell cols="3">Image generation on CIFAR10</cell></row><row><cell>Model</cell><cell>IS (Ò)</cell><cell>FID (Ó)</cell></row><row><cell>SNGAN</cell><cell>8.06˘0.10</cell><cell>19.06˘0.50</cell></row><row><cell>NCP(Sec. 3.1)</cell><cell>8.30˘0.09</cell><cell>17.65˘0.76</cell></row><row><cell>ProdPoly</cell><cell>8.49˘0.11</cell><cell>16.79˘0.81</cell></row><row><cell>CSGAN-[60]</cell><cell>7.90˘0.09</cell><cell>-</cell></row><row><cell>WGAN-GP-[61]</cell><cell>7.86˘0.08</cell><cell>-</cell></row><row><cell>CQFG-[64]</cell><cell>8.10</cell><cell>18.60</cell></row><row><cell>EBM [62]</cell><cell>6.78</cell><cell>38.2</cell></row><row><cell>GLANN [63]</cell><cell>-</cell><cell>46.5˘0.20</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4 :</head><label>4</label><figDesc>Speech classification with ResNet. The accuracy of the compared methods is similar, but Prodpoly-ResNet has 38% fewer parameters. The symbol '# par' abbreviates the number of parameters (in millions).</figDesc><table><row><cell cols="4">Speech Commands classification with ResNet</cell></row><row><cell>Model</cell><cell># blocks</cell><cell># par</cell><cell>Accuracy</cell></row><row><cell>ResNet34</cell><cell>r3, 4, 6, 3s</cell><cell>21.3</cell><cell>0.951˘0.002</cell></row><row><cell>Prodpoly-ResNet</cell><cell>r3, 3, 3, 2s</cell><cell>13.2</cell><cell>0.951˘0.002</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 5 :</head><label>5</label><figDesc>Image classification on CIFAR10 with ResNet. The # abbreviates 'number of', while the parameters are measured in millions. The term 'block' abbreviates a 'residual block'. Note that each baseline, e.g. ResNet18, has the same performance with the respective Prodpoly-ResNet, but significantly more parameters.</figDesc><table><row><cell cols="3">CIFAR10 classification with ResNet</cell><cell></cell></row><row><cell>Model</cell><cell># blocks</cell><cell># params (M)</cell><cell>Accuracy</cell></row><row><cell>ResNet18</cell><cell>r2, 2, 2, 2s</cell><cell>11.2</cell><cell>0.945˘0.000</cell></row><row><cell>Prodpoly-ResNet</cell><cell>r2, 2, 1, 1s</cell><cell>6.0</cell><cell>0.945˘0.001</cell></row><row><cell>ResNet34</cell><cell>r3, 4, 6, 3s</cell><cell>21.3</cell><cell>0.948˘0.001</cell></row><row><cell>Prodpoly-ResNet</cell><cell>r3, 3, 2, 2s</cell><cell>13.0</cell><cell>0.949˘0.002</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 6 :</head><label>6</label><figDesc>CIFAR100 classification with ResNet. The accuracy of the compared methods is similar, but Prodpoly-ResNet has 30% less parameters.</figDesc><table><row><cell cols="3">CIFAR100 classification with ResNet</cell><cell></cell></row><row><cell>Model</cell><cell># blocks</cell><cell># params (M)</cell><cell>Accuracy</cell></row><row><cell>ResNet34</cell><cell>r3, 4, 6, 3s</cell><cell>21.3</cell><cell>0.769˘0.003</cell></row><row><cell>Prodpoly-ResNet</cell><cell>r3, 4, 3, 2s</cell><cell>14.7</cell><cell>0.769˘0.001</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE 7 :</head><label>7</label><figDesc>ImageNet classification results of ResNet50 and the proposed Prodpoly-ResNet50. "Throughput" denotes the total Images Per Second (IPS) during training.</figDesc><table><row><cell>Model</cell><cell>Top-1 error (%)</cell><cell>Top-5 error (%)</cell><cell>Throughput</cell></row><row><cell>ResNet50</cell><cell>23.546</cell><cell>6.904</cell><cell>1625</cell></row><row><cell>Prodpoly-ResNet50</cell><cell>22.827 (Ó 0.719)</cell><cell>6.431 (Ó 0.473)</cell><cell>1531</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE 8 :</head><label>8</label><figDesc>Face datasets for training and testing. "(P)" and "(G)" refer to the probe and gallery set, respectively.</figDesc><table><row><cell>Datasets</cell><cell>#Identity</cell><cell>#Image</cell></row><row><cell>MS1MV2</cell><cell>93K</cell><cell>5.1M</cell></row><row><cell>LFW [77]</cell><cell>5,749</cell><cell>13,233</cell></row><row><cell>CFP [78]</cell><cell>500</cell><cell>7,000</cell></row><row><cell>AgeDB [79]</cell><cell>568</cell><cell>16,488</cell></row><row><cell>CPLFW [80]</cell><cell>5,749</cell><cell>11,652</cell></row><row><cell>CALFW [81]</cell><cell>5,749</cell><cell>12,174</cell></row><row><cell>RFW [82]</cell><cell>11,430</cell><cell>40,607</cell></row><row><cell>RFW-Caucasian [82]</cell><cell>2,959</cell><cell>10,196</cell></row><row><cell>RFW-Indian [82]</cell><cell>2,984</cell><cell>10,308</cell></row><row><cell>RFW-Asian [82]</cell><cell>2,492</cell><cell>9,688</cell></row><row><cell>RFW-African [82]</cell><cell>2,995</cell><cell>10,415</cell></row><row><cell>MegaFace [85]</cell><cell>530 (P)</cell><cell>1M (G)</cell></row><row><cell>IJB-B [83]</cell><cell>1,845</cell><cell>76.8K</cell></row><row><cell>IJB-C [84]</cell><cell>3,531</cell><cell>148.8K</cell></row><row><cell cols="3">each normalised face. Compared to ResNet50, Prodpoly-ResNet50</cell></row><row><cell cols="3">obviously boosts the performance only by a negligible increase in</cell></row><row><cell>model size and latency.</cell><cell></cell><cell></cell></row><row><cell cols="3">Results on LFW, CFP-FF, CFP-FP, CPLFW, AgeDB-30,</cell></row><row><cell cols="3">CALFW and RFW. LFW [77] contains 13,233 web-collected</cell></row><row><cell cols="3">images from 5,749 different identities, with limited variations</cell></row><row><cell cols="3">in pose, age, expression and illuminations. CFP</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE 9 :</head><label>9</label><figDesc></figDesc><table><row><cell cols="3">Verification performance (%) of ResNet50 and the proposed</cell></row><row><cell cols="3">Prodpoly-ResNet50 on LFW, CFP-FF, CFP-FP, CPLFW, AgeDB-30,</cell></row><row><cell cols="3">CALFW and RFW (Caucasian, Indian, Asian and African).</cell></row><row><cell>Method</cell><cell>ResNet50</cell><cell>Prodpoly-ResNet50</cell></row><row><cell>LFW</cell><cell>99.733˘0.309</cell><cell>99.833˘0.211 (Ò 0.100)</cell></row><row><cell>CFP-FF</cell><cell>99.871˘0.135</cell><cell>99.886˘0.178 (Ò 0.015)</cell></row><row><cell>CFP-FP</cell><cell>98.800˘0.249</cell><cell>98.986˘0.274 (Ò 0.186)</cell></row><row><cell>CPLFW</cell><cell>92.433˘1.245</cell><cell>93.317˘1.343 (Ò 0.884)</cell></row><row><cell>AgeDB-30</cell><cell>98.233˘0.655</cell><cell>98.467˘0.623 (Ò 0.234)</cell></row><row><cell>CALFW</cell><cell>95.917˘1.209</cell><cell>96.233˘1.114 (Ò 0.316)</cell></row><row><cell>RFW-Caucasian</cell><cell>99.333˘0.307</cell><cell>99.700˘0.100 (Ò 0.367)</cell></row><row><cell>RFW-Indian</cell><cell>98.567˘0.507</cell><cell>99.300˘0.296 (Ò 0.733)</cell></row><row><cell>RFW-Asian</cell><cell>98.333˘0.435</cell><cell>98.950˘0.350 (Ò 0.617)</cell></row><row><cell>RFW-African</cell><cell>98.650˘0.329</cell><cell>99.417˘0.227 (Ò 0.767)</cell></row><row><cell cols="2">variations and racial variations.</cell><cell></cell></row><row><cell cols="3">Results on IJB-B and IJB-C. The IJB-B dataset [83] contains</cell></row><row><cell cols="3">1, 845 subjects with 21.8K still images and 55K frames from</cell></row><row><cell cols="3">7, 011 videos. The IJB-C dataset [83] is a further extension of</cell></row><row><cell cols="3">IJB-B, having 3, 531 subjects with 31.3K still images and 117.5K</cell></row><row><cell cols="3">frames from 11, 779 videos. On IJB-B and IJB-C datasets, there</cell></row><row><cell cols="3">are two evaluation protocols, 1:1 verification and 1:N identification.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE 10 :</head><label>10</label><figDesc>1:1 verification TAR on the IJB-B and IJB-C datasets. ResNet50 43.46 (Ò 6.18) 91.95 (Ò 1.22) 95.19 (Ò 0.46) 96.67 (Ò 0.04) 90.77 (Ò 0.30) 95.16 (Ò 0.88) 96.58 (Ò 0.41) 97.66 (Ò 0.09)</figDesc><table><row><cell>Methods (%)</cell><cell></cell><cell cols="2">IJB-B</cell><cell></cell><cell></cell><cell cols="2">IJB-C</cell><cell></cell></row><row><cell></cell><cell>FAR=1e´6</cell><cell>FAR=1e´5</cell><cell>FAR=1e´4</cell><cell>FAR=1e´3</cell><cell>FAR=1e´6</cell><cell>FAR=1e´5</cell><cell>FAR=1e´4</cell><cell>FAR=1e´3</cell></row><row><cell>ResNet50</cell><cell>37.28</cell><cell>90.73</cell><cell>94.73</cell><cell>96.63</cell><cell>90.47</cell><cell>94.28</cell><cell>96.17</cell><cell>97.57</cell></row><row><cell>Prodpoly-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 11 :</head><label>11</label><figDesc>1:N (mixed media) Identification on the IJB-B and IJB-C datasets. False positive identification rate (FPIR) is the proportion of non-mated searches returning any (1 or more) candidates at or above a threshold.(Ò 0.88) 94.69 (Ò 0.68) 95.52 (Ò 0.23) 97.16 (Ò 0.02) 93.60 (Ò 0.73) 95.93 (Ò 0.65) 96.86 (Ò 0.34) 97.79 (Ò 0.10)</figDesc><table><row><cell>Methods (%)</cell><cell></cell><cell>IJB-B</cell><cell></cell><cell></cell><cell></cell><cell>IJB-C</cell><cell></cell><cell></cell></row><row><cell></cell><cell>FPIR=0.01</cell><cell>FPIR=0.1</cell><cell>Rank 1</cell><cell>Rank 5</cell><cell>FPIR=0.01</cell><cell>FPIR=0.1</cell><cell>Rank 1</cell><cell>Rank 5</cell></row><row><cell>ResNet50</cell><cell>84.70</cell><cell>94.01</cell><cell>95.29</cell><cell>97.14</cell><cell>92.87</cell><cell>95.28</cell><cell>96.52</cell><cell>97.69</cell></row><row><cell>Prodpoly-ResNet50</cell><cell>85.58</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>TABLE 12 :</head><label>12</label><figDesc>Face identification and verification evaluation of ResNet50 and the proposed Prodpoly-ResNet50 on MegaFace Challenge1 using FaceScrub as the probe set. "Id" refers to the rank-1 face identification accuracy with 1M distractors, and "Ver" refers to the face verification TAR at 10´6 FAR. Results are evaluated on the refined MegaFace dataset<ref type="bibr" target="#b72">[73]</ref>.</figDesc><table><row><cell>Methods</cell><cell>Id (%)</cell><cell>Ver (%)</cell></row><row><cell>ResNet50</cell><cell>98.28</cell><cell>98.64</cell></row><row><cell>Prodpoly-ResNet50</cell><cell>98.78 (Ò 0.50)</cell><cell>98.95 (Ò 0.31)</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">ACKNOWLEDGEMENTS</head><p>GC conducted this work while at Imperial College London. The work of SM, and GB was partially funded by an Imperial College DTA. The work of JD was partially funded by Imperial President's PhD Scholarship. The work of SZ was partially funded by the EPSRC Fellowship DEFORM: Large Scale Shape Analysis of Deformable Models of Humans (EP/S010203/1) and a Google Faculty Award.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Spectral normalization for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kataoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoshida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A convergence analysis of gradient descent for deep linear neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Golowich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Minimax estimation of neural net distance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3845" to="3854" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A style-based generator architecture for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Multiplicative interactions and where to find them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">W</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pascanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Tensor decomposition for signal processing and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>De Lathauwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Papalexakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="3551" to="3582" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Polygan: High-order polynomial generators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chrysos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moschoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.06571</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Newton residual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chrysos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<idno>2019. 1</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chrysos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moschoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bouritsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<title level="m">π´nets: Deep polynomial neural networks,&quot; in Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">On the expressive power of deep polynomial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kileel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Trager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3730" to="3738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Chainer: a next-generation open source framework for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tokui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Oono</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clayton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS Workshops</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Automatic differentiation in PyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>in NeurIPS Workshops</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">On the convergence of adam and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics (AISTATS)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Instance normalization: The missing ingredient for fast stylization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.08022</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukushima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological cybernetics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="193" to="202" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Searching for activation functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.05941</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="807" to="814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Large scale gan training for high fidelity natural image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning hierarchical features from deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4091" to="4099" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Progressive growing of gans for improved quality, stability, and variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Karras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lehtinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Arbitrary style transfer in real-time with adaptive instance normalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1501" to="1510" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Polynomial theory of complex systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Ivakhnenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="364" to="378" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Deep learning in neural networks: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="85" to="117" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Polynomial neural networks architecture: analysis and design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-K</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Pedrycz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-J</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Electrical Engineering</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="703" to="725" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The pi-sigma network: An efficient higher-order neural network for pattern classification and function approximation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="1991" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Training pi-sigma network by online gradient algorithm with penalty for small weight update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3356" to="3368" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Ridge polynomial networks in pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Voutriaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">G</forename><surname>Mertzios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EURASIP Conference focused on Video/Image Processing and Multimedia Communications</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="519" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A sigma-pi-sigma neural network (spsnn)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Processing Letters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">On the expressive power of deep learning: A tensor analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sharir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on learning theory</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="698" to="728" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Convolutional rectifier networks as generalized tensor decompositions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shashua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="955" to="963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neural machine translation by jointly learning to align and translate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Highway networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning to disentangle factors of variation with manifold interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning (ICML)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1431" to="1439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">G</forename><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM review</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="455" to="500" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The generalized weierstrass approximation theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics Magazine</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="237" to="254" />
			<date type="published" when="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Analysis III: Spaces of Differentiable Functions, ser. Encyclopaedia of Mathematical Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">The lottery ticket hypothesis: Finding sparse, trainable neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Frankle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning both weights and connections for efficient neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1135" to="1143" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Circnn: accelerating and compressing deep neural networks using block-circulant weight matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture</title>
		<meeting>the 50th Annual IEEE/ACM International Symposium on Microarchitecture</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="395" to="408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Sharing residual units through collective tensor factorization in deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yunpeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xiaojie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bingyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jiashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shuicheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conferences on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Predicting parameters in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Denil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shakibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N. De</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="2148" to="2156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">From few to many: Illumination cone models for face recognition under variable lighting and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Georghiades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Kriegman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="page" from="643" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">The cifar-10 dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="http://www.cs.toronto.edu/kriz/cifar.html" />
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">55</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Improved techniques for training gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Gans trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Class-splitting generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Grinblat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Uzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Granitto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.07359</idno>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Improved training of wasserstein gans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Implicit generation and generalization in energybased models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Mordatch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Non-adversarial image synthesis with generative latent nearest neighbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hoshen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5811" to="5819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Adversarial training of partially invertible variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lucas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shmelkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Alahari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.01091</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Mixed link networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conferences on Artificial Intelligence (IJCAI)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Residual networks of residual networks: Multilevel residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1303" to="1314" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07146</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Speech commands: A dataset for limited-vocabulary speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Warden</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.03209</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Arcface: Additive angular margin loss for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Ms-celeb-1m: A dataset and benchmark for large-scale face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="87" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Lightweight face recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPRW</publisher>
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Retinaface: Single-stage dense face localisation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kotsia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Labeled faces in the wild: A database forstudying face recognition in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mattar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Frontal to profile face verification in the wild,&quot; in WACV</note>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Agedb: The first manually collected in-the-wild age database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moschoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Papaioannou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sagonas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kotsia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Cross-pose lfw: A database for studying crosspose face recognition in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technical Report</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Cross-age lfw: A database for studying cross-age face recognition in unconstrained environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.08197</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Racial faces in the wild: Reducing racial bias by information maximization adaptation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Iarpa janus benchmark-b face dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Whitelam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Taborsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Blanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Kalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Allen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshop</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Iarpa janus benchmark-c: Face dataset and protocol</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Niggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cheney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICB</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">The megaface benchmark: 1 million faces for recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kemelmacher-Shlizerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Seitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1512.01274</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">A data-driven approach to cleaning large face datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-W</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Winkler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICIP</title>
		<imprint>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Generating 3d faces using convolutional mesh autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ranjan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sanyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Neural 3d morphable models: Spiral convolutional networks for 3d shape representation learning and generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bouritsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bokhnyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ploumpis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veličković</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liò</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Feastnet: Feature-steered graph convolutions for 3d shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Boyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Geometric deep learning on graphs and manifolds using mixture model cnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boscaini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Masci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rodola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<idno>2017. 10</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">A morphable model for the synthesis of 3d faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th annual conference on Computer graphics and interactive techniques (SIGGRAPH)</title>
		<meeting>the 26th annual conference on Computer graphics and interactive techniques (SIGGRAPH)</meeting>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Dynamic faust: Registering human bodies in motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<idno>2017. 10</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
