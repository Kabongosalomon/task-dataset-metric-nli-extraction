<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THE KFIOU LOSS FOR ROTATED OBJECT DETECTION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of CSE</orgName>
								<orgName type="department" key="dep2">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhou</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of EE</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gefan</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of CSE</orgName>
								<orgName type="department" key="dep2">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirui</forename><surname>Yang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University of Chinese Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of CSE</orgName>
								<orgName type="department" key="dep2">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of CSE</orgName>
								<orgName type="department" key="dep2">MoE Key Lab of Artificial Intelligence</orgName>
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Huawei Inc</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Huawei Inc</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">THE KFIOU LOSS FOR ROTATED OBJECT DETECTION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Preprint 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:10+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differing from the well-developed horizontal object detection area whereby the computing-friendly IoU based loss is readily adopted and well fits with the detection metrics. In contrast, rotation detectors often involve a more complicated loss based on SkewIoU which is unfriendly to gradient-based training. In this paper, we propose an effective approximate SkewIoU loss based on Gaussian modeing and Kalman filter, which mainly consists of two items. The first term is a scaleinsensitive center point loss, which is used to quickly get the center points between bounding boxes closer to assist the second term. In the distance-independent second term, Kalman filter is adopted to inherently mimic the mechanism of SkewIoU by its definition, and show its alignment with the SkewIoU loss at trend-level within a certain distance (i.e. within 9 pixels). This is in contrast to recent Gaussian modeling based rotation detectors e.g. GWD loss and KLD loss that involve a human-specified distribution distance metric which require additional hyperparameter tuning that vary across datasets and detectors. The resulting new loss called KFIoU loss is easier to implement and works better compared with exact SkewIoU loss, thanks to its full differentiability and ability to handle the nonoverlapping cases. We further extend our technique to the 3-D case which also suffers from the same issues as 2-D detection. Extensive results on various public datasets (2-D/3-D, aerial/text/face images) with different base detectors show the effectiveness of our approach.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Figure 1: For rotation detection , there is a notable inconsistency between the final detection metric i.e. mAP (largely depending on SkewIoU) and l n loss. Rotated object detection is an relatively emerging but challenging area, due to the difficulties of locating the arbitrary-oriented objects and separating them effectively from the background, such as aerial images <ref type="bibr" target="#b47">(Yang et al., 2018a;</ref><ref type="bibr" target="#b48">Yang et al., 2018b;</ref>, scene text <ref type="bibr" target="#b12">(Jiang et al., 2017;</ref><ref type="bibr" target="#b63">Zhou et al., 2017;</ref><ref type="bibr" target="#b24">Ma et al., 2018)</ref>. Though considerable progresses have been recently made, for practical settings, there still exist challenges for rotating objects with large aspect ratio, dense distribution.</p><p>The Skew Intersection over Union (SkewIoU) score between large aspect ratio objects is sensitive to the deviations of the object positions. This causes the negative impact of the inconsistency between metric (dominated by SkewIoU) and regression loss (e.g. l n -norms), which is common in horizontal detection, and is further amplified in rotation detection. The red and orange arrows in <ref type="figure">Fig. 1</ref> show the inconsistency between Preprint 2022 SkewIoU and Smooth L1 Loss. Specifically, when the angle deviation is fixed (red arrow), SkewIoU will decrease sharply as the aspect ratio increases, while the Smooth L1 loss is unchanged (mainly from the angle difference). Similarly, when SkewIoU does not change (orange arrow), Smooth L1 loss increases as the angle deviation increases. Solution for inconsistency between the metric and regression loss has been extensively discussed in horizontal detection by using IoU loss and related variants, such as GIoU loss <ref type="bibr" target="#b35">(Rezatofighi et al., 2019)</ref> and DIoU loss <ref type="bibr" target="#b60">(Zheng et al., 2020b)</ref>. However, the applications of these solutions to rotation detection are blocked because the analytical solution of the SkewIoU calculation process is not easy to be provided due to the complexity of intersection between two rotated boxes . Especially, there exist some custom operations (intersection of two edges and sorting the vertexes etc.) whose derivative functions have not been implemented in the existing deep learning frameworks <ref type="bibr" target="#b0">(Abadi et al., 2016;</ref><ref type="bibr" target="#b31">Paszke et al., 2017)</ref>. Based on the above analysis, developing an easy-to-implement approximate SkewIoU loss is meaningful and several works <ref type="bibr" target="#b59">Zheng et al., 2020a;</ref><ref type="bibr">d)</ref> have been proposed.</p><p>This paper aims to find an easy-to-implement and better-performing alternative. We design a novel and effective alternative to SkewIoU loss based on Kalman filter, named KFIoU loss, which can be easily implemented by the existing operations of the deep learning framework without the need for additional acceleration (e.g. C++/CUDA). Specifically, we convert the rotated bounding box into a Gaussian distribution, which can avoid the well-known boundary discontinuity and square-like problems <ref type="bibr" target="#b32">Qian et al., 2021a;</ref> in rotation detection. Then we use a center point loss to narrow the distance between the center of the two Gaussian distributions, follow by calculating the overlap area under the new position through Kalman filter. By calculating the error variance and comparing the final performance of different methods (including L1 loss, KLD loss, GWD loss and KFIoU loss etc.), we find trend-level alignment with the SkewIoU loss is critical for solving the inconsistency between metric and loss, and further improving the performance. Furthermore, compared to best-tuned Gaussian distance metric based methods, our proposed method achieves more competitive performance without hyperparameter tuning. The highlights are as follows: 1) For rotation detection, instead of exactly computing the SkewIoU loss which is tedious and unfriendly to differentiable learning, we propose our new approximate loss -KFIoU loss. It follows the protocol of Gaussian modeling for objects <ref type="bibr">d)</ref>, yet innovatively uses Kalman filter to mimic SkewIoU's computing mechanism within a looser distance.</p><p>2) Compared with plain SkewIoU loss, our KFIoU loss is easy-to-implement, and works better due to fully differentiable and able to handle the non-overlapping cases. Compared to Gaussian-based losses (GWD loss, KLD loss) that try to approximate SkewIoU loss by specifying a distance which requiry extra hyperparameters tuning and metric selection that vary across datasets and detectors, our mechanism level simulation to SkewIoU is more interpretable and natural, and free from hyperparameter tuning.</p><p>3) Compared with GWD loss and KLD loss, we show that KFIoU loss achieves the best trend-level alignment with SkewIoU loss within a certain distance, where the trend deviation is measured by our devised error variance. The effectiveness of such a trend-level alignment strategy is verified by comparing KFIoU loss with ideal SkewIoU loss. On extensive benchmarks (aerial images, scene texts, face), our approach also outperforms other best-tuned SOTA alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4)</head><p>We further extend the Gaussian modeling and KFIoU loss from 2-D to 3-D rotation detection, with notable improvement compared with baselines. To our best knowledge, this is the first 3-D rotation detector based on Gaussian modeling which also verifies its effectiveness, which is in contrast to <ref type="bibr">d)</ref> focusing on 2-D rotation detection. The source code is available at AlphaRotate 1 and MMRotate 2 . <ref type="figure">Figure 2</ref>: SkewIoU loss approximation process in two-dimensional space based on Kalman filter. Compared with GWD loss  and KLD loss <ref type="bibr" target="#b53">(Yang et al., 2021d)</ref>, our approach follows the calculation process of SkewIoU without introducing additional hyperparameters. We believe such a design is more mathematically rigorous and more in line with SkewIoU loss. rotation case by adopting the rotated bounding boxes. Aerial images and scene text are popular application scenarios of rotation detector. For aerial images, objects are often arbitrary-oriented and dense-distributed with large aspect ratios. To this end, <ref type="bibr">ICN (Azimi et al., 2018)</ref>, ROI-Transformer , SCRDet , Mask OBB , Gliding Vertex , ReDet <ref type="bibr" target="#b9">(Han et al., 2021b)</ref> are two-stage mainstreamed approaches whose pipeline is inherited from Faster <ref type="bibr">RCNN (Ren et al., 2015)</ref>, while DRN <ref type="bibr" target="#b30">(Pan et al., 2020)</ref>, DAL , R 3 Det , RSDet <ref type="bibr" target="#b32">(Qian et al., 2021a;</ref><ref type="bibr">b)</ref> and S 2 A-Net <ref type="bibr" target="#b8">(Han et al., 2021a)</ref> are based on single-stage methods for faster detection speed. For scene text detection, RRPN <ref type="bibr" target="#b24">(Ma et al., 2018)</ref> employs rotated RPN to generate rotated proposals and further perform rotated bounding box regression. TextBoxes++ <ref type="bibr" target="#b16">(Liao et al., 2018a)</ref> adopts vertex regression on SSD <ref type="bibr" target="#b20">(Liu et al., 2016)</ref>. RRD <ref type="bibr" target="#b17">(Liao et al., 2018b)</ref> improves TextBoxes++ by decoupling classification and bounding box regression on rotation-invariant and rotation sensitive features, respectively. The regression loss of the above algorithms are rarely SkewIoU loss due to the complexity of implementing SkewIoU.</p><p>Variants of IoU-based Loss. The inconsistency between metric and regression loss is a common issue for both horizontal detection and rotation detection. Solution for this inconsistency has been extensively discussed in horizontal detection by using IoU related loss. For instance, Unitbox <ref type="bibr" target="#b58">(Yu et al., 2016)</ref> proposes an IoU loss which regresses the four bounds of a predicted box as a whole unit. More works <ref type="bibr" target="#b35">(Rezatofighi et al., 2019;</ref><ref type="bibr" target="#b60">Zheng et al., 2020b)</ref> extend the idea of Unitbox by introducing GIoU <ref type="bibr" target="#b35">(Rezatofighi et al., 2019)</ref> and DIoU <ref type="bibr" target="#b60">(Zheng et al., 2020b)</ref> for bounding box regression. However, their applications to rotation detection are blocked due to the hard-to-implement of the SkewIoU. Recently, some approximate methods for SkewIoU loss have been proposed. Box/Polygon based: SCRDet  propose IoU-Smooth L1, which partly circumvents the need for SkewIoU loss with gradient backpropagation by combining IoU and Smooth L1 loss. To tackle the uncertainty of convex caused by rotation, the work <ref type="bibr" target="#b59">(Zheng et al., 2020a)</ref> proposes a projection operation to estimate the intersection area for both 2-D/3-D object detection. PolarMask <ref type="bibr" target="#b40">(Xie et al., 2020)</ref> proposes Polar IoU loss that can largely ease the optimization and considerably improve the accuracy. CFA  proposes convex hull based CIoU loss for optimization of point based detectors. Pixel based: PIoU  calculates the SkewIoU directly by accumulating the contribution of interior overlapping pixels. Gaussian based: GWD  and KLD <ref type="bibr" target="#b53">(Yang et al., 2021d)</ref> simulate SkewIoU by Gaussian distance measurement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">BACKGROUND ON GAUSSIAN MODELING</head><p>This section presents the preliminary according to , for how to convert an arbitrary-oriented 2-D/3-D bounding box to a Gaussian distribution G(?, ?).</p><formula xml:id="formula_0">? =R?R , ? = (x, y, (z))<label>(1)</label></formula><p>where R represents the rotation matrix, and ? represents the diagonal matrix of eigenvalues.  (2) and for 3-D object B 3d (x, y, z, w, h, l, ?),</p><formula xml:id="formula_1">R = ? ? cos ? ? sin ? 0 sin ? cos ? 0 0 0 1 ? ? , ? = ? ? ? w 2 4 0 0 0 h 2 4 0 0 0 l 2 4 ? ? ?<label>(3)</label></formula><p>and l, w, h represent the length, width, and height of the 3-D bounding box, respectively.</p><p>It is worth noting that the recent works GWD loss  and KLD loss <ref type="bibr" target="#b53">(Yang et al., 2021d</ref>) also belong to the Gaussian modeling based. Compared with our work, their difference is that they use the nonlinear transformation of distribution distance to approximate SkewIoU loss. In this process, additional hyperparameters are introduced. Since Gaussian modeling has the natural advantages of being immune to boundary discontinuity and square-like problems, in this paper, we will take another perspective to approximate the SkewIoU loss to better train the detector without any extra hyperparameter, which can be more in line with SkewIoU calculation. Tab. 1 shows the comparison of properties between different losses. It should be noted that the results presented in our experiments of GWD loss and KLD loss are obtained by best-tuned hyperparameters in DOTA, but not optimal in others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">PROPOSED METHOD</head><p>In this section, we present our main approach. <ref type="figure">Fig. 2</ref> shows the approximate process of SkewIoU loss in two-dimensional space based on Kalman filtering. Briefly, we first convert the bounding box to a Gaussian distribution as discussed in Sec. 3, and move the center points of the two Gaussian distributions to make them close. Then, the distribution function of the overlapping area is obtained by Kalman filtering. Finally, the obtained distribution function is inverted into a rotated bounding box to calculate the overlapping area and the SkewIoU and loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">SKEWIOU BASED ON KALMAN FILTERING</head><p>First of all, we can easily calculate the volume of the corresponding rotating box based on its covariance (V B (?)), when we obtain a new Gaussian distribution:</p><formula xml:id="formula_2">VB(?) = 2 n eig(?) = 2 n ? |? 1 2 | = 2 n ? |?| 1 2<label>(4)</label></formula><p>where n denotes the number of dimensions.</p><p>To obtain the final SkewIoU, calculating the area of overlap is critical. For two Gaussian distributions (G 1 and G 2 ), we use Kalman filter 3 to get the distribution function of the overlapping area:</p><formula xml:id="formula_3">?G kf (?, ?) = G1(?1, ?1)G2(?2, ?2)<label>(5)</label></formula><p>Note here ? is written by:</p><formula xml:id="formula_4">? = G?(?2, ?1 + ?2) = 1 det(2?(?1 + ?2)) e ? 1 2 (? 1 ?? 2 ) (? 1 +? 2 ) ?1 (? 1 ?? 2 ) (6) where ? = ? 1 + K(? 2 ? ? 1 ), ? = ? 1 ? K? 1 , and K is the Kalman gain, K = ? 1 (? 1 + ? 2 ) ?1 .</formula><p>We observe that ? is only related to the covariance (? 1 and ? 2 ) of the given two Gaussian distributions, which means that no matter how the two Gaussian distributions move, as long as the covariance is fixed, the area calculated by Eq. 4 will not change (distance-independent). This is obviously not in line with intuition: the overlapping area should be reduced when the two Gaussian distributions are far away. The main reason is ?G kf (?, ?) is not a standard Gaussian distribution (probability sum is not 1), we cannot directly use ? to calculate the area of the current overlap by Eq. 4 without considering ?. Eq. 6 shows that ? is related to the distance between the center points (? 1 ? ? 2 ) of the two Gaussian distributions. Based on the above findings, we can first use a center point loss L c to narrow the distance between the center of the two Gaussian distributions. In this way, ? can be approximated as a constant, and the introduction of the L c also allows the entire loss to continue to optimize the detector in non-overlapping cases. Then, calculate the overlap area under the new position by Eq. 4. According to <ref type="figure">Fig. 2</ref>, overlap area is calculated as follow:</p><formula xml:id="formula_5">KFIoU = VB 3 (?) VB 1 (?1) + VB 2 (?2) ? VB 3 (?)<label>(7)</label></formula><p>where B 1 , B 2 and B 3 refer to the three different bounding boxes shown in the right part of <ref type="figure">Fig. 2</ref>.</p><p>In the appendix, we prove that the upper bounds of KFIoU in n-dimensional space is 1 2 n 2 +1 ?1 . For 2-D/3-D detection, the upper bounds are 1 3 and 1 ? 32?1 respectively when n = 2 and n = 3. We can easily stretch the range of KFIoU to [0, 1] by linear transformation according to the upper bound, and then compare it with IoU for consistency. <ref type="figure" target="#fig_0">Fig. 3</ref>(a)-3(b) show the curves of five loss forms for two bounding boxes with the same center in different cases. Note that we have expanded KFIoU by 3 times so that its value range is [0, 1] like SkewIoU. <ref type="figure" target="#fig_0">Fig. 3</ref>(a) depicts the relation between angle difference and loss functions. Though they all bear monotonicity, obviously the Smooth L1 loss curve is more distinctive. <ref type="figure" target="#fig_0">Fig. 3(b)</ref> shows the changes of the five loss under different aspect ratio conditions. It can be seen that the Smooth L1 loss of the two bounding boxes are constant (mainly from the angle difference), but other losses will change drastically as the aspect ratio varies. Regardless of the case in <ref type="figure" target="#fig_0">Fig. 3(c)</ref>, KFIoU loss can maintain the best trend-level alignment with the SkewIoU loss within 5 pixels devariation. This conclusion still holds at 9 pixels, which is already quite a distance, especially for aerial image.</p><p>To further explore the behavior of different approximate SkewIoU losses, we design the metrics of error mean (EMean) and error variance (EVar) as follows:</p><formula xml:id="formula_6">EMean = 1 N N i=1 (SkewIoU plain ? SkewIoUapp), EVar = 1 N N i=1 (SkewIoUapp ? EMean) 2<label>(8)</label></formula><p>where EVar measures the trend-level consistency between the designed loss and the SkewIoU loss.</p><p>Tab. 1 calculates the EVar of different losses in <ref type="figure" target="#fig_0">Fig. 3(c)</ref>. In general, EVar L kf iou +Lc &lt; EVar L kld &lt; EVar L gwd &lt; EVar L1 . In our analysis, this is probably due to the fundamental inconsistency between the distribution distance as used in GWD/KLD and the definition of similarity in SkewIoU. Moreover, for GWD such inconsistency is more pronouced, because it has no scale invariance under the same IoU, and a case with a larger scale will get a larger loss value, it can greatly magnify its trend inconsistency with SkewIoU loss. The results in Tab. 1 also verifies our analysis. In contrast, the calculation process of KFIoU loss is essentially the calculation of the overlap rate, so it does not require hyperparameters and can maintain a high trend-level consistency with SkewIoU loss.</p><p>Combined with the corresponding performance on three datasets, smaller EVars tend to have better performance in a general level. When EVar is small enough, which implies sufficient consistency, the performance difference of different methods (e.g. KLD loss and KFIoU loss) is close. Therefore, we come to the conclusion that the key to maintaining the consistency between metric and regression loss lies in the trend-level consistency between approximate and exact SkewIoU loss rather than value-level consistency. The reason why the Gaussian-based losses (e.g. KFIoU loss, KLD loss, GWD loss) outperform the plain SkewIoU loss is due to the advanced parameter optimization mechanism, effective measurement for non-overlapping cases, and complete derivation. However, the introduction of hyperparameters makes KLD loss and GWD loss less stable than KFIoU loss in terms of Evar and performance. Compared with GWD and KLD, which use the distribution distance to approximate SkewIoU, KFIoU is physically more reasonable (in line with the calculation process of SkewIoU) and simpler, as well as empirically more effective than best-tuned GWD and KLD. In addition, KFIoU implementation is much simpler than plain SkewIoU and can be easily implemented by the existing operations of the deep learning framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">THE PROPOSED KFIOU LOSS</head><p>We take 2-D object detection as the main example for notation brevity, though our experiments further cover the 3-D case. We use the one-stage detector RetinaNet <ref type="bibr" target="#b19">(Lin et al., 2017b)</ref> as the baseline. Rotated rectangle is represented by five parameters (x, y, w, h, ?). First, we shall clarify that the network has not changed the output of the original regression branch, that is, it is not directly predicting the parameters of the Gaussian distribution. The whole training process of detector is summarized as follows: i) predict offset (t * x , t * y , t * w , t * h , t * ? ); ii) decode prediction box; iii) convert prediction box and target ground-truth into Gaussian distribution; iv) calculate L c and L kf of two Gaussian distributions. Therefore, the inference time remains unchanged. The regression equation of (x, y, w, h) is as follows: tx = (x ? xa)/wa, ty = (y ? ya)/ha, tw = log(w/wa), t h = log(h/ha)</p><formula xml:id="formula_7">t * x = (x * ? xa)/wa, t * y = (y * ? ya)/ha, t * w = log(w * /wa), t * h = log(h * /ha)<label>(9)</label></formula><p>where x, y, w, h denote the box's center coordinates, width and height, respectively. x, x a , x * are for ground-truth box, anchor box, and predicted box (likewise for y, w, h).</p><p>For the regression of ?, we use two forms as the baselines:</p><p>i) Direct regression, marked as Reg. (??). The model directly predicts the angle offset t * ? :</p><p>cos ?</p><p>The multi-task loss is:</p><formula xml:id="formula_9">L total = ?1 Npos<label>n=1</label></formula><p>Lreg (G(bn), G(gtn)) + ?2 N N n=1 L cls (pn, tn) where N and N pos indicates the number of all anchors and that of positive anchors. b n denotes the n-th predicted bounding box, gt n is the n-th target ground-truth. G(?) is Gaussian transfer function. t n represents the label of the n-th object, p n is the n-th probability distribution of classes calculated by sigmoid function. ? 1 , ? 2 control the trade-off and are set to {0.01, 1}. The classification loss L cls is set as the focal loss <ref type="bibr" target="#b19">(Lin et al., 2017b)</ref>. The regression loss is set by</p><formula xml:id="formula_11">L reg = L c + L kf , where L kf (?1, ?2) = e 1?KFIoU ? 1<label>(14)</label></formula><p>See more ablation experiments on the functional form of L kf (? 1 , ? 2 ) in the Appendix. For center point loss L c , this paper provides two different forms:</p><p>1) The loss adopted in Faster RCNN <ref type="bibr" target="#b18">(Lin et al., 2017a)</ref> </p><formula xml:id="formula_12">(default): L c (t, t * ) = i?(x,y) l n (t i , t * i ).</formula><p>2) The first term of KLD <ref type="bibr">(Yang et al., 2021d) (advanced)</ref>, which has an advanced center point optimization mechanism: L c (? 1 , ? 2 , ? 1 ) = ln (? 2 ? ? 1 ) ? ?1 1 (? 2 ? ? 1 ) + 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">EXPERIMENTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">DATASETS AND IMPLEMENTATION DETAILS</head><p>Aerial image dataset: DOTA <ref type="bibr" target="#b39">(Xia et al., 2018)</ref> is one of the largest datasets for oriented object detection in aerial images with three released versions: DOTA-v1.0, DOTA-v1.5 and DOTA-v2.0. DOTA-v1.0 contains 15 common categories, 2,806 images and 188,282 instances. DOTA-v1.5 uses the same images as DOTA-v1.0, but extremely small instances (less than 10 pixels) are also annotated. Moreover, a new category, containing 402,089 instances in total is added in this version. While DOTA-v2.0 contains 18 common categories, 11,268 images and 1,793,658 instances. We divide the images into 600 ? 600 subimages with an overlap of 150 pixels and scale it to 800 ? 800. HRSC2016 <ref type="bibr" target="#b22">(Liu et al., 2017)</ref> contains images from two scenarios with ships on sea and close inshore. The training, validation and test set include 436, 181 and 444 images. Face dataset: FDDB <ref type="bibr" target="#b11">(Jain &amp; Learned-Miller, 2010</ref>) is a dataset designed for unconstrained face detection, in which faces have a wide variability of face scales, poses, and appearance. This dataset contains annotations for 5,171 faces in a set of 2,845 images. We manually use 70% as the training set and the rest as the validation set.</p><p>We use AlphaRotate <ref type="bibr" target="#b54">(Yang et al., 2021e)</ref> for implementation, where many advanced rotation detectors are integrated. Experiments are performed on a server with GeForce RTX 3090 Ti and 24G memory. Experiments are initialized by ResNet50 <ref type="bibr" target="#b10">(He et al., 2016)</ref> by default unless otherwise specified. We perform experiments on two aerial benchmarks, two scene text benchmarks and one face benchmark to verify the generality of our techniques. Weight decay and momentum are set 0.0001 and 0.9, respectively. We employ MomentumOptimizer over 4 GPUs with a total of 4 images per mini-batch (1 image per GPU). All the used datasets are trained by 20 epochs, and learning We use PointPillar <ref type="bibr" target="#b15">(Lang et al., 2019)</ref> implemented in MMDetection3D <ref type="bibr" target="#b2">(Chen et al., 2019)</ref> as the baseline, and the training schedule inherited from SECOND <ref type="bibr" target="#b44">(Yan et al., 2018)</ref>: ADAM optimizer with a cosine-shaped cyclic learning rate scheduler that spans 160 epochs. The learning rate starts from 1e-4 and reaches 1e-3 at the 60th epoch, and then goes down gradually to 1e-7 finally. In the development phase, the experiments are conducted with a single model for 3-class joint detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">ABLATION STUDY AND FURTHER COMPARISON</head><p>Ablation study on different center point losses. Tab. 1 compares the two different center point losses proposed in Sec. 4.2 on three versions of DOTA datasets. Even with the most commonly used L c (t, t * ), KFIoU loss achieves competitive performance, significantly better than GWD loss and comparable to KLD loss. For a fairer comparison, after adopting the same center point loss term as KLD loss L c (? 1 , ? 2 , ? 1 ), the performance of KFIoU loss is further improved, which is better than KLD loss thanks to a better center point optimization mechanism. Ablation study of KFIoU loss on 3-D detection. We generalize the KFIoU loss from 2-D to 3-D, with results in Tab. 3. It involves 3-D detection and BEV detection on KITTI val split, and  <ref type="bibr" target="#b41">(Xie et al., 2017)</ref> and Hourglass-104 <ref type="bibr" target="#b29">(Newell et al., 2016)</ref>. Red and blue: top two performances. <ref type="table" target="#tab_4">PL  BD  BR  GTF  SV  LV  SH  TC  BC  ST  SBF  RA  HA  SP  HC  mAP50</ref> Single-stage Comparison with peer methods. Methods in Tab. 4 are based on the same baseline RetinaNet, and initialized by ResNet50 <ref type="bibr" target="#b10">(He et al., 2016)</ref> without using data augmentation and multi-scale training/testing. They are trained/tested under the same environment and hyperparameters. These methods are all published solutions to the boundary discontinuity in rotation detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method Backbone</head><p>First, we conduct ablation experiments on anchor form (horizontal and rotating anchors), rotated bounding box definition form (OpenCV definition and Long Edge definition), and angle regression form (direct regression and indirect regression) based on RetinaNet. Rotating anchors provides accurate prior, which makes the model show strong performance in large aspect ratio objects (e.g. SV, LV, SH). However, the large number of anchors makes it time-consuming. Therefore, we use horizontal anchors by default to balance accuracy and speed. OpenCV definition (D oc )  and Long Edge definition (D le ) <ref type="bibr" target="#b24">(Ma et al., 2018)</ref> are two popular methods for defining bounding boxes with different angles. Experiments show that D oc is slightly better than D le on the three versions of DOTA. Angle direct regression (Reg.) always suffers from the standing boundary discontinuity problem as widely studied recently  In particular, Modulated Loss achieves the third highest performance on DOTA-v1.5/v2.0. CSL and DCL convert the angle prediction from regression to classification, cleverly eliminating the boundary discontinuity problem caused by the angle periodicity. GWD loss, KLD loss and KFIoU loss are three different regression losses based on Gaussian distribution. The results presented in our experiments of GWD loss and KLD loss are obtained by best-tuned hyperparameters. In contrast, KFIoU loss is free from hyperparameter tuning and has a more stable performance increase due to a more consistent calculation process with SkewIoU loss as the center point gets closer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">COMPARISON WITH THE STATE-OF-THE-ART</head><p>Tab. 5 compares recent detectors on DOTA-v1.0, as categorized by single-, refine-, and two-stage based methods. Since different methods use different image resolution, network structure, training strategies and various tricks, we cannot make absolutely fair comparisons. In terms of overall performance, our method has achieved the best performance so far, at around 77.35%/81.03%/80.93%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We have presented a trend-level consistent approximate to the ideal but gradient-training unfriendly SkewIoU loss for rotation detection, and we call it KFIoU loss as the Kalman filter is adopted to directly mimic the computing mechanism of SkewIoU loss by definition. This design differs from the distribution distance based losses including GWD loss and KLD loss which in our analysis have fundamental difficulty in achieving trend-level alignment with SkewIoU loss without tuning hyperparameters. Moreover, KFIoU is easier to implement and works better than plain SkewIoU due to the effective measurement for non-overlapping cases and complete derivation. Experimental results on both 2D and 3D cases, on various datasets, show the effectiveness of our approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A PROOF OF KFIOU UPPER BOUND</head><p>For an n-dimensional Gaussian distribution, its volume is:</p><formula xml:id="formula_13">V = 2 n ? |? 1 2 | = 2 n ? |?| 1 2<label>(15)</label></formula><p>For ? kf , we have</p><formula xml:id="formula_14">|? kf | =|?1 ? ?1(?1 + ?2) ?1 ?1| =|?1(?1 + ?2) ?1 ?2| = |?1| ? |?1| |?1 + ?2|<label>(16)</label></formula><p>According to Minkowski's inequality:</p><formula xml:id="formula_15">|? 1 + ? 2 | 1 n ? |? 1 | 1 n + |? 2 | 1 n</formula><p>(17) Simultaneous mean inequalities:</p><formula xml:id="formula_16">|?1 + ?2| 1 n ? |?1| 1 n | + |?2| 1 n ? 2 ? |?1| 1 2n ? |?2| 1 2n<label>(18)</label></formula><p>Thus:</p><formula xml:id="formula_17">|? 1 | 1 2n ? |? 2 | 1 2n |? 1 + ? 2 | 1 n ? 1 2 |? 1 | 1 2 ? |? 2 | 1 2 |? 1 + ? 2 | ? 1 2 n<label>(19)</label></formula><p>and</p><formula xml:id="formula_18">|? kf | = |? 1 | ? |? 1 | |? 1 + ? 2 | ? |? 1 | 1 2 ? |? 2 | 1 2 2 n |? kf | 1 2 ? |? 1 | 1 4 ? |? 2 | 1 4 2 n 2<label>(20)</label></formula><p>Combine the mean inequalities again:</p><formula xml:id="formula_19">|? kf | 1 2 ? |? 1 | 1 4 ? |? 2 | 1 4 2 n 2 ? |? 1 | 1 2 + |? 2 | 1 2 2 n 2 +1<label>(21)</label></formula><p>According to Eq. 15, we have</p><formula xml:id="formula_20">V kf ? V 1 + V 2 2 n 2 +1<label>(22)</label></formula><p>Therefore, the upper bound of KFIoU is</p><formula xml:id="formula_21">KFIoU = V kf V 1 + V 2 ? V kf ? 1 2 n 2 +1 ? 1<label>(23)</label></formula><p>When n = 2 and n = 3, the upper bounds are 1 3 and 1 ? 32?1 respectively.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B SUPPLEMENTARY EXPERIMENT</head><p>Ablation study of three forms of KFIoU loss on two detectors. We use two different detectors and three different KFIoU based loss functions to verify its effectiveness, as shown in Tab. 6. RetinaNetbased detector will have a large number of low-SkewIoU prediction bounding box in the early stage of training, and will produce very large loss after the log function, which weakens the improvement of the model. Compared with the linear function, the derivative of the exp-based function will pay more attention to the training of difficult samples, so it has a higher performance, at 70.64%. In contrast, R 3 Det-based detector can generate high-quality prediction box at the beginning of training by adding refinement stages, so it will not suffer the same troubles as RetinaNet. Due to the same mechanism of focusing on difficult samples, log and exp-based functions are both better than linear functions, and the best performance is achieved on the log-based function, about 72.28%. We also expand KFIoU by 3 times to make its range truly consistent with the IoU loss, at [0, 1]. However, this consistency do not bring any additional gains, so the following experiments are all use the KFIoU before non-expansion.</p><p>Ablation study of training strategies and tricks. We reimplement KFIoU based on the more powerful benchmark, MMRotate <ref type="bibr">(Zhou et al., 2022)</ref>. We use a single GeForce RTX 3090 Ti with a total batch size of 2 for training. For ResNet <ref type="bibr" target="#b10">(He et al., 2016)</ref>, SGD optimizer is adopted with an initial learning rate of 0.0025. The momentum and weight decay are 0.9 and 0.0001, respectively. For Swin Transformer , AdamW <ref type="bibr" target="#b14">(Kingma &amp; Ba, 2014;</ref><ref type="bibr" target="#b23">Loshchilov &amp; Hutter, 2018)</ref> optimizer is adopted with an initial learning rate of 0.0001. The weight decay is 0.05. In addition, we adopt learning rate warmup for 500 iterations, and the learning rate is divided by 10 at each decay step. Tab. 7 performs ablation experiments on four detectors: RetinaNet <ref type="bibr" target="#b19">(Lin et al., 2017b)</ref>, S 2 A-Net <ref type="bibr" target="#b8">(Han et al., 2021a)</ref>, R 3 Det , and RoI Transformer .</p><p>The experimental results prove that KFIoU can stably enhance the performance of the detector. In order to further improve the performance of the model on DOTA, we verified many commonly used training strategies and tricks, including backbone, training schedule, data augmentation and multiscale training and testing, as shown in Tab. 7.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C VISUALIZATION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E LIMITATIONS</head><p>Note that the Gaussian modeling has a limitation that it cannot be directly applied to quadrilateral/polygon detection  which is also an important task in the applications of aerial images <ref type="bibr" target="#b47">(Yang et al., 2018a;</ref><ref type="bibr" target="#b26">Ming et al., 2021b)</ref>, scene text <ref type="bibr" target="#b63">(Zhou et al., 2017;</ref><ref type="bibr" target="#b12">Jiang et al., 2017;</ref><ref type="bibr" target="#b24">Ma et al., 2018;</ref><ref type="bibr" target="#b17">Liao et al., 2018b)</ref>, etc. The technical difficulty is how to convert the point set into a Gaussian distribution, and potential techniques include maximum likelihood estimation. We leave it for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Behavior comparison of different losses in different cases. (a) depicts the relation between angle difference and loss functions. (b) shows the changes of the five loss under different aspect ratio condition. (c) gives scatter plot between approximate losses and SkewIoU loss, 1,000 examples regardless of the case by randomly generating box pairs with the close centers (within 5 pixels). For 2-D object B 2d (x, y, w, h, ?),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Scene text dataset: ICDAR2015<ref type="bibr" target="#b13">(Karatzas et al., 2015)</ref> includes 1,000 training images and 500 testing images. MSRA-TD500<ref type="bibr" target="#b56">(Yao et al., 2012)</ref> has 300 training images and 200 testing images. They are popular for oriented scene text detection and spotting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4</head><label>4</label><figDesc>ad Fig. 5 show the visual comparison of three different loss functions on the different kinds of datasets. Compared with Smooth L1 Loss, KFIoU loss is significantly better.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Visual comparison between Smooth L1 loss-based (left), GWD-based (middle) and the KFIoU-based (right) detectors on DOTA (2-D) and KITTI (3-D). For 3-D object detection, red and blue box denotes ground-truth and predict bounding box, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Visual comparison between Smooth L1 loss-based (left), GWD-based (middle) and the KFIoU-based (right) detectors on FDDB. D TREND CONSISTENCY SIMULATION Fig. 6(a) and Fig. 6(b) show the impact of center deviation and object scale on the trend consistency of each loss function. Note that each data in the figure is calculated from the average of 1,000 random aspect ratio and rotation angle examples. Two conclusions can be drawn: i) the smaller the center deviation, the better trend consistency of the KFIoU loss; ii) KLD loss and KFIoU loss are insensitive to scale changes. (a) Impact of center deviation on the trend consistency of each loss function. (b) Impact of object scale on the trend consistency of each loss function under a 5 pixels center deviations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of the properties and performance of different regression losses. Base model is RetinaNet. BC and HP denote Boundary Continuity and Hyperparameter. ? indicates that the first term of KLD is taken as the center point loss, i.e. L c (? 1 , ? 2 , ? 1 ).</figDesc><table><row><cell>Loss</cell><cell cols="4">Representation Implement BC Consistency</cell><cell>HP</cell><cell>EVar ?</cell><cell cols="3">DOTA-v1.0 DOTA-v1.5 DOTA-v2.0</cell></row><row><cell>Smooth L1</cell><cell>bbox</cell><cell>easy</cell><cell>?</cell><cell>?</cell><cell>(?)</cell><cell>0.073201718</cell><cell>64.17</cell><cell>56.10</cell><cell>43.06</cell></row><row><cell>plain SkewIoU</cell><cell>bbox</cell><cell>hard</cell><cell></cell><cell></cell><cell>?</cell><cell>-</cell><cell>68.27</cell><cell>59.01</cell><cell>45.87</cell></row><row><cell>GWD</cell><cell>Gaussian</cell><cell>easy</cell><cell></cell><cell>?</cell><cell cols="2">(? , f ) 0.019041297</cell><cell>68.93</cell><cell>60.03</cell><cell>46.65</cell></row><row><cell>KLD</cell><cell>Gaussian</cell><cell>easy</cell><cell></cell><cell></cell><cell cols="2">(? , f ) 0.007653582</cell><cell>71.28</cell><cell>62.50</cell><cell>47.69</cell></row><row><cell>KFIoU (ours)</cell><cell>Gaussian</cell><cell>easy</cell><cell></cell><cell></cell><cell>?</cell><cell>0.002348353</cell><cell>70.64</cell><cell>62.71</cell><cell>48.04</cell></row><row><cell>KFIoU  ? (ours)</cell><cell>Gaussian</cell><cell>easy</cell><cell></cell><cell></cell><cell>?</cell><cell>0.002264243</cell><cell>71.60</cell><cell>63.75</cell><cell>48.94</cell></row><row><cell cols="2">(a) Angle difference case.</cell><cell></cell><cell></cell><cell cols="2">(b) Aspect ratio case.</cell><cell></cell><cell cols="3">(c) Regardless of the case.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Ablation study on various 2-D datasets with different base detectors. 'R', 'F' and 'G' indicate random rotation, flipping, and graying. ? indicates that the first term of KLD is taken as the center point loss, i.e. L c (? 1 , ? 2 , ? 1 ). Base detector is RetinaNet. Data Aug. Reg. Loss Hmean/AP 50 Hmean/AP 60 Hmean/AP 75 Hmean/AP 85 Hmean/AP 50:95</figDesc><table><row><cell>Dataset</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>HRSC2016</cell><cell>R+F+G</cell><cell>Smooth L1 KFIoU</cell><cell>84.28 84.41 (+0.13)</cell><cell>74.74 82.23 (+7.49)</cell><cell>48.42 58.32 (+9.90)</cell><cell>12.56 18.34 (+5.78)</cell><cell>47.76 51.29 (+3.53)</cell></row><row><cell>MSRA-TD500</cell><cell>R+F</cell><cell>Smooth L1 KFIoU</cell><cell>70.98 76.30 (+5.32)</cell><cell cols="3">62.42 69.84 (+7.42) 47.58 (+10.85) 19.21 (+6.65) 36.73 12.56</cell><cell>37.89 44.96 (+7.07)</cell></row><row><cell>ICDAR2015</cell><cell></cell><cell>Smooth L1 KFIoU</cell><cell>69.78 75.90 (+6.12)</cell><cell>64.15 69.28 (+5.13)</cell><cell>36.97 40.03 (+3.06)</cell><cell>8.71 9.18 (+0.47)</cell><cell>37.73 41.17 (+3.44)</cell></row><row><cell>FDDB</cell><cell>F</cell><cell>Smooth L1 KFIoU</cell><cell>95.92 97.25 (+1.33)</cell><cell cols="3">87.50 94.89 (+7.39) 77.38 (+21.57) 25.62 (+12.93) 55.81 12.67</cell><cell>52.77 63.25 (+10.48)</cell></row><row><cell></cell><cell></cell><cell>Smooth L1</cell><cell>65.00</cell><cell>57.84</cell><cell>33.68</cell><cell>11.39</cell><cell>35.16</cell></row><row><cell>DOTA-v1.0</cell><cell></cell><cell>KFIoU</cell><cell>67.68 (+2.68)</cell><cell>62.18 (+4.34)</cell><cell>37.30 (+3.62)</cell><cell>14.21 (+2.82)</cell><cell>38.51 (+3.35)</cell></row><row><cell></cell><cell></cell><cell>KFIoU  ?</cell><cell>68.23 (+3.23)</cell><cell>63.23 (+5.39)</cell><cell>38.34 (+4.66)</cell><cell>13.72 (+2.33)</cell><cell>38.80 (+3.64)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Results on KITTI val split 3D detection. Hard PointPillars 61.34 85.66 75.48 68.39 55.46 48.69 43.71 79.37 59.84 55.92</figDesc><table><row><cell cols="2">mAP Mod. Easy Mod. Hard Car -3D Detection Easy Mod. + KFIoU Ped. -3D Detection Cyc. -3D Detection Method Easy Mod. Hard 64.98 86.45 76.49 74.41 58.11 54.22 49.53 82.68 64.23 60.07</cell></row><row><cell>Method</cell><cell>mAP Car -BEV Detection Ped. -BEV Detection Cyc. -BEV Detection Mod. Easy Mod. Hard Easy Mod. Hard Easy Mod. Hard</cell></row><row><cell cols="2">PointPillars 68.16 89.89 86.97 79.64 61.04 54.94 49.26 81.76 62.56 60.54</cell></row><row><cell>+ KFIoU</cell><cell>70.91 89.59 86.81 83.21 63.34 58.43 54.80 84.61 67.50 64.52</cell></row><row><cell cols="2">rate is reduced tenfold at 12 epochs and 16 epochs, respectively. The initial learning rate is 1e-3.</cell></row><row><cell cols="2">The number of image iterations per epoch for DOTA-v1.0, DOTA-v1.5, DOTA-v2.0, HRSC2016,</cell></row><row><cell cols="2">ICDAR2015, MSRA-TD500 and FDDB are 54k, 64k, 80k, 10k, 10k, 5k and 4k respectively, and</cell></row><row><cell cols="2">doubled if data augmentation (e.g. random graying and rotation) or multi-scale training are enabled.</cell></row></table><note>KITTI (Geiger et al., 2012) contains 7,481 training and 7,518 testing samples for 3-D object detec- tion. The training samples are generally divided into the train split (3,712 samples) and the val split (3,769 samples). The evaluation is classified into Easy, Moderate or Hard according to the object size, occlusion and truncation. All results are evaluated by the mean average precision with a rotated IoU threshold 0.7 for cars and 0.5 for pedestrian and cyclists. To evaluate the model's performance on KITTI val split, we train our model on the train set and report the results on the val set.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Accuracy (%) comparison on DOTA. The bold red and blue indicate the top two performances. D oc and D le denotes OpenCV Definition (? ? [?90 ? , 0 ? )) and Long Edge Definition (? ? [?90 ? , 90 ? )) of RBox. 'H' and 'R' denote the horizontal and rotating anchors, respectively. ? indicates that the first term of KLD is taken as the center point loss, i.e. L c (? 1 , ? 2 , ? 1 ).</figDesc><table><row><cell>Ablation study on various 2-D</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>datasets with different detectors.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tab. 2 compares Smooth L1 loss and</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>KFIoU loss by indicators with different</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>IoU thresholds. For HRSC2016 con-</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>taining a large number of ships with</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>large aspect ratios, KFIoU loss has a</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9.90% improvement over Smooth L1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>on AP 75 . For the scene text datasets</cell><cell>Method</cell><cell cols="4">Box Def. DOTA-v1.0 DOTA-v1.5 DOTA-v2.0</cell></row><row><cell>MSRA-TD500 and ICDAR2015, KFIoU achieves 7.07% and 3.44%</cell><cell>RetinaNet-H (Reg.) (2017b) RetinaNet-H (Reg.) (2017b) RetinaNet-H (Reg.  *  ) (2017b)</cell><cell>Doc Dle Dle</cell><cell>65.73 64.17 65.78</cell><cell>58.87 56.10 57.17</cell><cell>44.16 43.06 43.92</cell></row><row><cell>improvements on Hmean 50:95 , reach-ing 44.96% and 41.17% respectively.</cell><cell>RetinaNet-R (Reg.) (2017b) PIoU (2020) IoU-Smooth L1 (2019)</cell><cell>Doc Doc Doc</cell><cell>67.25 65.85 66.99</cell><cell>56.50 57.65 59.16</cell><cell>42.04 45.23 46.31</cell></row><row><cell>The same conclusion can be reached</cell><cell>Modulated Loss (2021a) Modulated Loss (2021a)</cell><cell>Doc Quad.</cell><cell>66.05 67.20</cell><cell>57.75 61.42</cell><cell>45.17 46.71</cell></row><row><cell>on FDDB and DOTA-v1.0 datasets.</cell><cell>RIL (2021c) CSL (2020)</cell><cell>Quad. Dle</cell><cell>66.06 67.38</cell><cell>58.91 58.55</cell><cell>45.35 43.34</cell></row><row><cell></cell><cell>DCL (BCL) (2021a)</cell><cell>Dle</cell><cell>67.39</cell><cell>59.38</cell><cell>45.46</cell></row><row><cell></cell><cell>plain SkewIoU (2019)</cell><cell>Doc</cell><cell>68.27</cell><cell>59.01</cell><cell>45.87</cell></row><row><cell></cell><cell>GWD (2021c)</cell><cell>Doc</cell><cell>68.93</cell><cell>60.03</cell><cell>46.65</cell></row><row><cell></cell><cell>KLD (2021d)</cell><cell>Doc</cell><cell>71.28</cell><cell>62.50</cell><cell>47.69</cell></row><row><cell></cell><cell>KFIoU (Ours)</cell><cell>Doc</cell><cell>70.64</cell><cell>62.71</cell><cell>48.04</cell></row><row><cell></cell><cell>KFIoU  ? (Ours)</cell><cell>Doc</cell><cell>71.60</cell><cell>63.75</cell><cell>48.94</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>AP of different objects on DOTA-v1.0. R-101 denotes ResNet-101 (likewise for R-50, R-152). RX-101 and H-104 denotes ResNeXt101</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>). In contrast, angle indirect regression (Reg * .) is a simpler way to avoid above issues and brings performance boost according to Tab. 4.</figDesc><table><row><cell>PIoU calculates the SkewIoU by accumulating the contribution of interior overlapping pixels but the</cell></row><row><cell>effect is not significant. IoU-Smooth L1 partly circumvents the need for SkewIoU loss with gradient</cell></row><row><cell>backpropagation by combining IoU and Smooth L1 loss. Although IoU-Smooth L1 has achieved</cell></row><row><cell>an improvement of 1.26%/0.29%/2.15% on DOTA-v1.0/v1.5/v2.0, the gradient is still dominated by</cell></row><row><cell>Smooth L1 but still worse than plain SkewIoU loss. Modulated Loss and RIL implement ordered and</cell></row><row><cell>disordered quadrilateral detection respectively, and the more accurate representation makes them</cell></row><row><cell>both have a considerable performance improvement.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Ablation study of different KFIoU loss forms with different detectors on DOTA-v1.0. Smooth L1 ? ln(KFIoU + ) 1 ? KFIoU e 1?KFIoU ? 1 e 1?3KFIoU ? 1 ? ln(3KFIoU + ) RetinaNet 65.73 69.80 (+4.07) 70.19 (+4.46) 70.64 (+4.91) 69.64 (+3.91) -R 3 Det 70.66 72.28 (+1.62) 71.09 (+0.43) 71.58 (+0.92) -71.77 (+1.11)</figDesc><table><row><cell>Method</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 :</head><label>7</label><figDesc>Ablation study of training strategies and tricks. Rotate and MS indicate rotation augmentation and multi-scale training and testing.</figDesc><table><row><cell>Method</cell><cell cols="2">KFIoU Backbone Sched. MS Rotate</cell><cell>PL</cell><cell>BD</cell><cell>BR</cell><cell>GTF</cell><cell>SV</cell><cell>LV</cell><cell>SH</cell><cell>TC</cell><cell>BC</cell><cell>ST</cell><cell>SBF</cell><cell>RA</cell><cell>HA</cell><cell>SP</cell><cell>HC</cell><cell>mAP50</cell></row><row><cell>RetinaNet</cell><cell>R-50 R-50</cell><cell>12e 12e</cell><cell cols="15">87.76 72.61 43.86 66.61 69.70 56.61 74.15 90.86 75.27 79.09 47.81 64.60 58.93 63.37 26.58 88.90 80.68 47.12 70.40 72.20 62.49 74.84 90.91 79.63 79.73 58.54 66.40 63.67 67.13 45.33</cell><cell>65.19 69.86</cell></row><row><cell>S 2 A-Net</cell><cell>R-50 R-50</cell><cell>12e 12e</cell><cell cols="15">89.18 79.35 49.11 72.97 79.08 78.03 86.67 90.91 85.90 85.04 64.06 65.64 66.71 67.60 48.08 89.24 83.46 51.44 70.88 78.70 76.31 86.90 90.90 82.22 84.81 61.67 66.93 65.62 67.99 57.05</cell><cell>73.89 74.27</cell></row><row><cell></cell><cell>R-50</cell><cell>12e</cell><cell cols="15">89.02 81.71 53.84 71.65 79.00 77.76 87.85 90.90 87.04 85.70 61.73 64.55 75.06 71.71 62.38</cell><cell>75.99</cell></row><row><cell></cell><cell>R-50</cell><cell>12e</cell><cell cols="15">89.08 82.62 53.90 71.78 78.73 77.91 87.97 90.90 86.68 85.37 63.17 67.65 74.30 71.19 61.35</cell><cell>76.17</cell></row><row><cell>RoI Trans.</cell><cell>Swin-T Swin-T</cell><cell>12e 12e</cell><cell cols="15">88.96 82.81 53.34 76.55 78.66 83.54 88.00 90.90 86.95 86.47 41.94 64.17 76.29 72.87 63.95 88.9 83.77 53.98 77.63 78.83 84.22 88.15 90.91 87.21 86.14 67.79 65.73 75.80 73.68 63.30</cell><cell>77.18 77.74</cell></row><row><cell></cell><cell>R-50</cell><cell>24e</cell><cell cols="15">89.12 84.54 60.73 78.86 79.65 85.79 88.45 90.90 87.03 88.28 69.15 70.28 78.88 81.54 70.05</cell><cell>80.22</cell></row><row><cell></cell><cell>Swin-T</cell><cell>12e</cell><cell cols="15">89.44 84.41 62.22 82.51 80.10 86.07 88.68 90.90 87.32 88.38 72.80 71.95 78.96 74.95 75.27</cell><cell>80.93</cell></row><row><cell></cell><cell>R-50</cell><cell>12e</cell><cell cols="15">89.02 74.52 47.93 69.64 77.02 74.07 82.56 90.90 79.39 83.67 59.02 62.51 63.56 65.06 37.22</cell><cell>70.41</cell></row><row><cell></cell><cell>R-50</cell><cell>12e</cell><cell cols="15">89.06 73.89 49.82 68.39 78.13 75.35 86.65 90.89 82.57 83.84 59.63 62.03 66.16 66.22 47.98</cell><cell>72.04</cell></row><row><cell></cell><cell>R-50</cell><cell>12e</cell><cell cols="15">89.06 82.49 55.91 81.04 80.14 83.24 88.56 90.90 84.61 86.83 66.25 71.50 75.60 77.64 63.66</cell><cell>78.50</cell></row><row><cell>R 3 Det</cell><cell>Swin-T R-50</cell><cell>12e 12e</cell><cell cols="15">89.41 83.66 56.92 79.76 80.45 84.34 88.71 90.91 85.69 87.64 67.69 72.88 76.34 73.63 72.21 89.33 84.19 58.78 81.30 80.48 84.49 88.85 90.84 85.56 87.57 69.14 70.79 77.33 80.82 66.51</cell><cell>79.35 79.73</cell></row><row><cell></cell><cell>R-101</cell><cell>12e</cell><cell cols="15">89.28 83.32 59.40 80.29 80.43 84.70 88.85 90.87 84.51 87.95 71.86 71.60 78.31 79.42 66.60</cell><cell>79.83</cell></row><row><cell></cell><cell>Swin-T</cell><cell>12e</cell><cell cols="15">89.24 83.75 59.77 79.40 80.95 84.61 88.84 90.84 86.86 87.93 71.71 71.17 76.79 77.42 71.59</cell><cell>80.06</cell></row><row><cell></cell><cell>Swin-T</cell><cell>24e</cell><cell cols="15">89.50 84.26 59.90 81.06 81.74 85.45 88.77 90.85 87.03 87.79 70.68 74.31 78.17 81.67 72.37</cell><cell>80.90</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We model predicted boxes, ground truth boxes, and overlapping regions into predicted values, observed values, and uncertainties, respectively. It should be emphasized that we only borrow the technique of multiplying Gaussian distributions in Kalman filter, and the rest (e.g. iterative process) is not introduced.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t ? = (? ? ?a) ? ?/180, t * ? = (? * ? ?a) ? ?/180(10)ii) Indirect regression, marked as Reg. * (sin ?, cos ?). The model predicts two vectors (t * sin ? and t * cos ? ) to match the two targets from the ground truth (t sin ? and t cos ? ):t sin ? = sin (? ? ?/180), t cos ? = cos (? ? ?/180), t * sin ? = sin (? * ? ?/180), t * cos ? = cos (? * ? ?/180)(11)To ensure that t * 2 sin ? +t * 2 cos ? = 1 is satisfied, we will perform the following normalization processing:t * sin ? = t * sin ? t * 2 sin ? + t * 2cos ? , t * cos ? = t * cos ? t * 2 sin ? + t * 2</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for largescale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">12th {USENIX} symposium on operating systems design and implementation ({OSDI} 16)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="265" to="283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Towards multi-class object detection in unconstrained remote sensing imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleonora</forename><surname>Seyed Majid Azimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Vig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Bahmanyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>K?rner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reinartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="150" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dazhi</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenchen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qijie</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07155</idno>
		<title level="m">Chen Change Loy, and Dahua Lin. MMDetection: Open mmlab detection toolbox and benchmark</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Piou loss: Towards accurate oriented object detection in complex environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiming</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kean</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>See</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="195" to="211" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Learning roi transformer for oriented object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qikai</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2849" to="2858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the kitti vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3354" to="3361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Beyond bounding-box: Convex-hull feature adaptation for oriented and densely packed object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaosong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8792" to="8801" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Align deep features for oriented object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Redet: A rotation-equivariant detector for aerial object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2786" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Fddb: A benchmark for face detection in unconstrained settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidit</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>Learned-Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">R2cnn: rotational region cnn for orientation robust scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuli</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbo</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.09579</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Icdar 2015 competition on robust reading</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimosthenis</forename><surname>Karatzas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lluis</forename><surname>Gomez-Bigorda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anguelos</forename><surname>Nicolaou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suman</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Bagdanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masakazu</forename><surname>Iwamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><forename type="middle">Ramaseshan</forename><surname>Chandrasekhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shijian</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 13th International Conference on Document Analysis and Recognition</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1156" to="1160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pointpillars: Fast encoders for object detection from point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex H</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourabh</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Beijbom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="12697" to="12705" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Textboxes++: A single-shot oriented scene text detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoguang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3676" to="3690" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Rotation-sensitive regression for oriented scene text detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoguang</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5909" to="5918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ssd: Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Yang</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A high resolution optical satellite image dataset for ship recognition and some new baselines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zikun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubin</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiping</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Pattern Recognition Applications and Methods</title>
		<meeting>the International Conference on Pattern Recognition Applications and Methods</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="324" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Arbitrary-oriented scene text detection via rotation proposals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyuan</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingbin</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3111" to="3122" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Cfc-net: A critical feature capturing network for arbitrary-oriented object detection in remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjuan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Dong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.06849</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sparse label assignment for oriented object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjuan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page">2664</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Optimization for arbitraryoriented object detection via representation invariance loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjuan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Dynamic anchor learning for arbitrary-oriented object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingjuan</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linhao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2355" to="2363" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="483" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dynamic refinement network for oriented and densely packed object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingjia</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqiang</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kekai</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haolei</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongyang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changsheng</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11207" to="11216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning modulated loss for rotated object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2458" to="2466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Rsdet++: Point-based modulated loss for more accurate rotated object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silong</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiujuan</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.11906</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generalized intersection over union: A metric and a loss for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamid</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathan</forename><surname>Tsoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyoung</forename><surname>Gwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Sadeghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Mask obb: A semantic attention-based mask oriented bounding box representation for multi-category object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haowen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wensheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page">2930</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning center probability map for detecting objects in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng-Chao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="4307" to="4323" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Oriented objects as pairs of middle lines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhonghan</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="268" to="279" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dota: A large-scale dataset for object detection in aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Datcu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcello</forename><surname>Pelillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangpei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3974" to="3983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Polarmask: Single shot instance segmentation with polar representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peize</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoge</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuebo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12193" to="12202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Oriented r-cnn for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingxing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gong</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiabao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiwen</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junwei</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3520" to="3529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Gliding vertex on the horizontal bounding box for multi-oriented object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongchao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingtao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qimeng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gui-Song</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1452" to="1459" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Second: Sparsely embedded convolutional detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">3337</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Arbitrary-oriented object detection with circular smooth label</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="677" to="694" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">On the arbitrary-oriented object detection: Classification based approaches revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1340" to="1365" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Automatic ship detection in remote sensing images from google earth of complex scenes based on multiscale rotation dense feature pyramid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">132</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Position detection and direction prediction for arbitrary-oriented ships via multitask rotation region convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="50839" to="50849" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Scrdet: Towards more robust detection for small, cluttered and rotated objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8232" to="8241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Dense label encoding for boundary discontinuity free rotation detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liping</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15819" to="15829" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">R3det: Refined single-stage detector with feature refinement for rotating object</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziming</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="3163" to="3171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Rethinking rotated object detection with gaussian wasserstein distance loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaopeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11830" to="11841" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Learning high-precision bounding box for rotated object detection via kullback-leibler divergence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jirui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Ming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Alpharotate: A rotation detection benchmark using tensorflow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.06677</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Scrdet++: Detecting small, cluttered and rotated objects via instance-level feature denoising and rotation loss smoothing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xue</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junchi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenlong</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Detecting texts of arbitrary orientations in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1083" to="1090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Oriented object detection in aerial images with box boundary-aware vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingru</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengxiang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiaoying</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2150" to="2159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Unitbox: An advanced object detection network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhimin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM international conference on Multimedia</title>
		<meeting>the 24th ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="516" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Rotation-robust intersection over union for 3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="464" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Distance-iou loss: Faster and better learning for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinze</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongguang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwei</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12993" to="13000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Iou loss for 2d/3d object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingfu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xibin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenye</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchao</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruigang</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on 3D Vision</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Arbitrary-oriented object detection in remote sensing images based on polar coordinates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoran</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzhe</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="223373" to="223384" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">East: an efficient and accurate scene text detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuchang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiran</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5551" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
