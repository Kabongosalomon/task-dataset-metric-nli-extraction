<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Contrastive Learning Inverts the Data Generating Process</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><forename type="middle">S</forename><surname>Zimmermann</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yash</forename><surname>Sharma</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steffen</forename><surname>Schneider</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
						</author>
						<title level="a" type="main">Contrastive Learning Inverts the Data Generating Process</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T07:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Contrastive learning has recently seen tremendous success in self-supervised learning. So far, however, it is largely unclear why the learned representations generalize so effectively to a large variety of downstream tasks. We here prove that feedforward models trained with objectives belonging to the commonly used InfoNCE family learn to implicitly invert the underlying generative model of the observed data. While the proofs make certain statistical assumptions about the generative model, we observe empirically that our findings hold even if these assumptions are severely violated. Our theory highlights a fundamental connection between contrastive learning, generative modeling, and nonlinear independent component analysis, thereby furthering our understanding of the learned representations as well as providing a theoretical foundation to derive more effective contrastive losses. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>With the availability of large collections of unlabeled data, recent work has led to significant advances in selfsupervised learning. In particular, contrastive methods have been tremendously successful in learning representations for visual and sequential data <ref type="bibr">(Logeswaran &amp; Lee, 2018;</ref><ref type="bibr">Wu et al., 2018;</ref><ref type="bibr">Oord et al., 2018;</ref><ref type="bibr" target="#b16">H?naff, 2020;</ref><ref type="bibr">Tian et al., 2019;</ref><ref type="bibr" target="#b17">Hjelm et al., 2019;</ref><ref type="bibr" target="#b0">Bachman et al., 2019;</ref><ref type="bibr">He et al., 2020a;</ref><ref type="bibr" target="#b6">Chen et al., 2020a;</ref><ref type="bibr">Schneider et al., 2019;</ref><ref type="bibr" target="#b1">Baevski et al., 2020a;</ref><ref type="bibr">Ravanelli et al., 2020)</ref>. While a number of explanations have been provided as to why contrastive learning leads to such informative representations, existing theoretical predictions and empirical observations appear to be at odds with each other <ref type="bibr">(Tian et al., 2019</ref>  <ref type="bibr" target="#b15">Wu et al., 2020;</ref><ref type="bibr">Saunshi et al., 2019)</ref>.</p><p>In a nutshell, contrastive methods aim to learn representations where related samples are aligned (positive pairs, e.g. augmentations of the same image), while unrelated samples are separated (negative pairs) <ref type="bibr" target="#b6">(Chen et al., 2020a)</ref>. Intuitively, this leads to invariance to irrelevant details or transformations (by decreasing the distance between positive pairs), while preserving a sufficient amount of information about the input for solving downstream tasks (by increasing the distance between negative pairs) <ref type="bibr">(Tian et al., 2020)</ref>. This intuition has recently been made more precise by <ref type="bibr">(Wang &amp; Isola, 2020)</ref>, showing that a commonly used contrastive loss from the InfoNCE family <ref type="bibr" target="#b13">(Gutmann &amp; Hyv?rinen, 2012;</ref><ref type="bibr">Oord et al., 2018;</ref><ref type="bibr" target="#b6">Chen et al., 2020a)</ref> asymptotically converges to a sum of two losses: an alignment loss that pulls together the representations of positive pairs, and a uniformity loss that maximizes the entropy of the learned latent distribution.</p><p>We show that an encoder learned with a contrastive loss from the InfoNCE family can recover the true generative factors of variation (up to rotations) if the process that generated the data fulfills a few weak statistical assumptions. This theory bridges the gap between contrastive learning, nonlinear independent component analysis (ICA) and generative modeling (see <ref type="figure">Fig. 1</ref>). Our theory reveals implicit assumptions encoded in the InfoNCE objective about the generative process underlying the data. If these assumptions are violated, we show a principled way of deriving alternative contrastive objectives based on assumptions regarding the positive pair distribution. We verify our theoretical findings with controlled experiments, providing evidence that our theory holds true in practice, even if the assumptions on the ground-truth generative model are partially violated.</p><p>To the best of our knowledge, our work is the first to analyze under what circumstances representation learning methods used in practice provably represent the data in terms of its underlying factors of variation. Our theoretical and empirical results suggest that the success of contrastive learning in many practical applications is due to an implicit and approximate inversion of the data generating process, which explains why the learned representations are useful in a wide range of downstream tasks.</p><p>In summary, our contributions are: arXiv:2102.08850v4 <ref type="bibr">[cs.</ref>LG] 7 Apr 2022 <ref type="figure">Figure 1</ref>. We analyze the setup of contrastive learning, in which a feature encoder f is trained with the InfoNCE objective <ref type="bibr" target="#b13">(Gutmann &amp; Hyv?rinen, 2012;</ref><ref type="bibr">Oord et al., 2018;</ref><ref type="bibr" target="#b6">Chen et al., 2020a)</ref> using positive samples (green) and negative samples (orange). We assume the observations are generated by an (unknown) injective generative model g that maps unobservable latent variables from a hypersphere to observations in another manifold. Under these assumptions, the feature encoder f implictly learns to invert the ground-truth generative process g up to linear transformations, i.e., f = Ag ?1 with an orthogonal matrix A, if f minimizes the InfoNCE objective.</p><p>? We establish a theoretical connection between the In-foNCE family of objectives, which is commonly used in self-supervised learning, and nonlinear ICA. We show that training with InfoNCE inverts the data generating process if certain statistical assumptions on the data generating process hold.</p><p>? We empirically verify our predictions when the assumed theoretical conditions are fulfilled. In addition, we show successful inversion of the data generating process even if these theoretical assumptions are partially violated.</p><p>? We build on top of the CLEVR rendering pipeline <ref type="bibr" target="#b24">(Johnson et al., 2017b)</ref> to generate a more visually complex disentanglement benchmark, called 3DIdent, that contains hallmarks of natural environments (shadows, different lighting conditions, a 3D object, etc.). We demonstrate that a contrastive loss derived from our theoretical framework can identify the ground-truth factors of such complex, high-resolution images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Contrastive Learning Despite the success of contrastive learning (CL), our understanding of the learned representations remains limited, as existing theoretical explanations yield partially contradictory predictions. One way to theoretically motivate CL is to refer to the InfoMax principle <ref type="bibr" target="#b33">(Linsker, 1988)</ref>, which corresponds to maximizing the mutual information (MI) between different views <ref type="bibr">(Oord et al., 2018;</ref><ref type="bibr" target="#b0">Bachman et al., 2019;</ref><ref type="bibr" target="#b17">Hjelm et al., 2019;</ref><ref type="bibr" target="#b6">Chen et al., 2020a;</ref><ref type="bibr">Tian et al., 2020)</ref>. However, as optimizing a tighter bound on the MI can produce worse representations <ref type="bibr">(Tschan-nen et al., 2020)</ref>, it is not clear how accurate this motivation describes the behavior of CL.</p><p>Another approach aims to explain the success by introducing latent classes <ref type="bibr">(Saunshi et al., 2019)</ref>. While this theory has some appeal, there exists a gap between empirical observations and its predictions, e.g. the prediction that an excessive number of negative samples decreases performance does not corroborate with empirical results <ref type="bibr">(Wu et al., 2018;</ref><ref type="bibr">Tian et al., 2019;</ref><ref type="bibr">He et al., 2020a;</ref><ref type="bibr" target="#b6">Chen et al., 2020a)</ref>. However, recent work has suggested some empirical evidence for said theoretical prediction, namely, issues with the commonly used sampling strategy for negative samples, and have proposed ways to mitigate said issues as well <ref type="bibr" target="#b8">(Robinson et al., 2020;</ref><ref type="bibr" target="#b8">Chuang et al., 2020)</ref>.</p><p>More recently, the behavior of CL has been analyzed from the perspective of alignment and uniformity properties of representations, demonstrating that these two properties are correlated with downstream performance <ref type="bibr">(Wang &amp; Isola, 2020)</ref>. We build on these results to make a connection to cross-entropy minimization from which we can derive identifiability results.</p><p>Nonlinear ICA Independent Components Analysis (ICA) attempts to find the underlying sources for multidimensional data. In the nonlinear case, said sources correspond to a welldefined nonlinear generative model g, which is assumed to be invertible (i.e., injective) <ref type="bibr" target="#b21">(Hyv?rinen et al., 2001;</ref><ref type="bibr" target="#b25">Jutten et al., 2010)</ref>. In other words, nonlinear ICA solves a demixing problem: Given observed data x = g(z), it aims to find a model f that equals the inverse generative model g ?1 , which allows for the original sources z to be recovered. <ref type="bibr" target="#b22">Hyv?rinen et al. (2019)</ref> show that the nonlinear demixing problem can be solved as long as the independent compo-nents are conditionally mutually independent with respect to some auxiliary variable. The authors further provide practical estimation methods for solving the nonlinear ICA problem <ref type="bibr" target="#b18">(Hyv?rinen &amp; Morioka, 2016;</ref>, similar in spirit to noise contrastive estimation (NCE; <ref type="bibr" target="#b13">Gutmann &amp; Hyv?rinen, 2012)</ref>. Recent work has generalized this contribution to VAEs <ref type="bibr" target="#b26">(Khemakhem et al., 2020a;</ref><ref type="bibr">Locatello et al., 2020;</ref><ref type="bibr">Klindt et al., 2021)</ref>, as well as (invertible-by-construction) energy-based models <ref type="bibr" target="#b27">(Khemakhem et al., 2020b)</ref>. We here extend this line of work to more general feed-forward networks trained using InfoNCE <ref type="bibr">(Oord et al., 2018)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Theory</head><p>We will show a connection between contrastive learning and identifiability in the form of nonlinear ICA. For this, we introduce a feature encoder f that maps observations x to representations. We consider the widely used InfoNCE loss, which often assumes L 2 normalized representations <ref type="bibr">(Wu et al., 2018;</ref><ref type="bibr" target="#b15">He et al., 2020b;</ref><ref type="bibr">Tian et al., 2019;</ref><ref type="bibr" target="#b0">Bachman et al., 2019;</ref><ref type="bibr" target="#b6">Chen et al., 2020a)</ref>,</p><formula xml:id="formula_0">L contr (f ; ?, M ) := (1) E (x,x)?ppos {x ? i } M i=1 i.i.d. ? p data ? ? ? ? ? log e f (x) T f (x)/? e f (x) T f (x)/? + M i=1 e f (x) T f (x ? i )/? ? ? ? ? .</formula><p>Here M ? Z + is a fixed number of negative samples, p data is the distribution of all observations and p pos is the distribution of positive pairs. This loss was motivated by the InfoMax principle <ref type="bibr" target="#b33">(Linsker, 1988)</ref>, and has been shown to be effective by many recent representation learning methods <ref type="bibr">(Logeswaran &amp; Lee, 2018;</ref><ref type="bibr">Wu et al., 2018;</ref><ref type="bibr">Tian et al., 2019;</ref><ref type="bibr">He et al., 2020a;</ref><ref type="bibr" target="#b17">Hjelm et al., 2019;</ref><ref type="bibr" target="#b0">Bachman et al., 2019;</ref><ref type="bibr" target="#b6">Chen et al., 2020a;</ref><ref type="bibr" target="#b2">Baevski et al., 2020b)</ref>. Our theoretical results also hold for a loss function whose denominator only consists of the second summand across the negative samples (e.g., the SimCLR loss <ref type="bibr" target="#b6">(Chen et al., 2020a)</ref>).</p><p>In the spirit of existing literature on nonlinear ICA <ref type="bibr" target="#b20">(Hyv?rinen &amp; Pajunen, 1999;</ref><ref type="bibr" target="#b14">Harmeling et al., 2003;</ref><ref type="bibr">Sprekeler et al., 2014;</ref><ref type="bibr" target="#b18">Hyv?rinen &amp; Morioka, 2016;</ref><ref type="bibr" target="#b13">Gutmann &amp; Hyv?rinen, 2012;</ref><ref type="bibr" target="#b22">Hyv?rinen et al., 2019;</ref><ref type="bibr" target="#b26">Khemakhem et al., 2020a)</ref>, we assume that the observations x ? X are generated by an invertible (i.e., injective) generative process g : Z ? X , where X ? R K is the space of observations and Z ? R N with N ? K denotes the space of latent factors. Influenced by the commonly used feature normalization in InfoNCE, we further assume that Z is the unit hypersphere S N ?1 (see Appx. A.1.1). Additionally, we assume that the ground-truth marginal distribution of the latents of the generative process is uniform and that the conditional distribution (under which positive pairs have high density) is a von Mises-Fisher (vMF) distribution:</p><formula xml:id="formula_1">p(z) = |Z| ?1 , p(z|z) = C ?1 p e ?z z with<label>(2)</label></formula><p>C p : = e ?z z dz = const., x = g(z),x = g(z).</p><p>Given these assumptions, we will show that if f minimizes the contrastive loss L contr , then f solves the demixing problem, i.e., inverts g up to orthogonal linear transformations.</p><p>Our theoretical approach consists of three steps: (1) We demonstrate that L contr can be interpreted as the crossentropy between the (conditional) ground-truth and inferred latent distribution.</p><p>(2) Next, we show that encoders minimizing L contr maintain distance, i.e., two latent vectors with distance ? in the ground-truth generative model are mapped to points with the same distance ? in the inferred representation.</p><p>(3) Finally, we leverage distance preservation to show that minimizers of L contr invert the generative process up to orthogonal transformations. Detailed proofs are given in Appx. A.1.2.</p><p>Additionally, we will present similar results for general convex bodies in R N and more general similarity measures, see Sec. 3.3. For this, the detailed proofs are given in Appx. A.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Contrastive learning is related to cross-entropy minimization</head><p>From the perspective of nonlinear ICA, we are interested in understanding how the representations f (x) which minimize the contrastive loss L contr (defined in Eq. (1)) are related to the ground-truth source signals z. To study this relationship, we focus on the map h = f ? g between the recovered source signals h(z) and the true source signals z. Note that this is merely for mathematical convenience; it does not necessitate knowledge regarding neither g nor the ground-truth factors during learning (beyond the assumptions stated in the theorems).</p><p>A core insight is a connection between the contrastive loss and the cross-entropy between the ground-truth latent distribution and a certain model distribution. For this, we expand the theoretical results obtained by Wang &amp; Isola (2020):</p><p>Theorem 1 (L contr converges to the cross-entropy between latent distributions). If the ground-truth marginal distribution p is uniform, then for fixed ? &gt; 0, as the number of negative samples M ? ?, the (normalized) contrastive loss converges to</p><formula xml:id="formula_2">lim M ?? L contr (f ; ?, M ) ? log M + log |Z| = E z?p(z) [H(p(?|z), q h (?|z))] (3)</formula><p>where H is the cross-entropy between the ground-truth conditional distribution p over positive pairs and a conditional distribution q h parameterized by the model f ,</p><formula xml:id="formula_3">q h (z|z) = C h (z) ?1 e h(z) T h(z)/? with C h (z) : = e h(z) T h(z)/? dz,<label>(4)</label></formula><p>where C h (z) ? R + is the partition function of q h (see Appx. A.1.1).</p><p>Next, we show that the minimizers h * of the crossentropy (4) are isometries in the sense that ?z z = h * (z) h * (z) for all z andz. In other words, they preserve the dot product between z andz.</p><p>Proposition 1 (Minimizers of the cross-entropy maintain the dot product). Let Z = S N ?1 , ? &gt; 0 and consider the ground-truth conditional distribution of the form p(z|z) = C ?1 p exp(?z z). Let h map onto a hypersphere with radius ? ? ?. 2 Consider the conditional distribution q h parameterized by the model, as defined above in Theorem 1, where the hypothesis class for h (and thus f ) is assumed to be sufficiently flexible such that p(z|z) and q h (z|z) can match. If h is a minimizer of the cross-entropy E p(z|z) [? log q h (z|z)], then p(z|z) = q h (z|z) and ?z,z : ?z z = h(z) h(z).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Contrastive learning identifies ground-truth factors on the hypersphere</head><p>From the strong geometric property of isometry, we can now deduce a key property of the minimizers h * :</p><p>Proposition 2 (Extension of the Mazur-Ulam theorem to hyperspheres and the dot product). Let Z = S N ?1 and Z = S N ?1 r be the hyperspheres with radius 1 and r &gt; 0, respectively. If h : R N ? Z is differentiable in the vicinity of Z and its restriction to Z maintains the dot product up to a constant factor, i.e., ?z,z ? Z : r 2 z z = h(z) h(z), then h is an orthogonal linear transformation scaled by r for all z ? Z.</p><p>In the last step, we combine the previous propositions to derive our main result: the minimizers of the contrastive loss L contr solve the demixing problem of nonlinear ICA up to linear transformations, i.e., they identify the original sources z for observations g(z) up to orthogonal linear transformations. For a hyperspherical space Z these correspond to combinations of permutations, rotations and sign flips.</p><p>Theorem 2. Let Z = S N ?1 , the ground-truth marginal be uniform, and the conditional a vMF distribution (cf. Eq. 2). Let the restriction of the mixing function g to Z be injective and h be differentiable in a vicinity of Z. If the assumed form of q h , as defined above, matches that of p, and if f is differentiable and minimizes the CL loss as defined in Eq. (1), then for fixed ? &gt; 0 and M ? ?, h = f ? g is linear, i.e., f recovers the latent sources up to an orthogonal linear transformation and a constant scaling factor.</p><p>Note that we do not assume knowledge of the ground-truth generative model g; we only make assumptions about the conditional and marginal distribution of the latents. On real data, it is unlikely that the assumed model distribution q h can exactly match the ground-truth conditional. We do, however, provide empirical evidence that h is still an affine transformation even if there is a severe mismatch, see Sec. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Contrastive learning identifies ground-truth factors on convex bodies in R N</head><p>While the previous theoretical results require Z to be a hypersphere, we will now show a similar theorem for the more general case of Z being a convex body in R N . Note that the</p><formula xml:id="formula_4">hyperrectangle [a 1 , b 1 ] ? . . . ? [a N , b N ] is an example of such a convex body.</formula><p>We follow a similar three step proof strategy as for the hyperspherical case before: (1) We begin again by showing that a properly chosen contrastive loss on convex bodies corresponds to the cross-entropy between the ground-truth conditional and a distribution parametrized by the encoder. For this step, we additionally extend the results of Wang &amp; Isola (2020) to this latent space and loss function.</p><p>(2) Next, we derive that minimizers of the loss function are isometries of the latent space. Importantly, we do not limit ourselves to a specific metric, thus the result is applicable to a family of contrastive objectives.</p><p>(3) Finally, we show that these minimizers must be affine transformations. For a special family of conditional distributions (rotationally asymmetric generalized normal distributions (Subbotin, 1923)), we can further narrow the class of solutions to permutations and sign-flips. For the detailed proofs, see Appx. A.2.</p><p>As earlier, we assume that the ground-truth marginal distribution of the latents is uniform. However, we now assume that the conditional distribution is exponential:</p><formula xml:id="formula_5">p(z) = |Z| ?1 , p(z|z) = C ?1 p e ??(z,z) with C p (z) : = e ??(z,z) dz, x = g(z),x = g(z),<label>(5)</label></formula><p>where ? is a metric induced by a norm (see Appx. A.2.1).</p><p>To reflect the differences between this conditional distribution and the one assumed for the hyperspherical case, we need to introduce an adjusted version of the contrastive loss in (1): Definition 1 (L ?-contr objective). Let ? : Z ? Z ? R be a metric on Z. We define the general InfoNCE loss, which uses ? as a similarity measure, as</p><formula xml:id="formula_6">L ?-contr (f ; ?, M ) := (6) E (x,x)?ppos {x ? i } M i=1 i.i.d. ? p data ? log e ??(f (x),f (x))/? e -?(f (x),f (x))/? + M i=1 e -?(f (x),f (x - i ))/? .</formula><p>Note that this is a generalization of the InfoNCE criterion in Eq. (1). In contrast to the objective above, the representations are no longer assumed to be L 2 normalized, and the dot-product is replaced with a more general similarity measure ?.</p><p>Analogous to the previously demonstrated case for the hypersphere, for convex bodies Z, minimizers of the adjusted L ?-contr objective solve the demixing problem of nonlinear ICA up to invertible linear transformations: Theorem 5. Let Z be a convex body in R N , h = f ? g : Z ? Z, and ? be a metric or a semi-metric (cf. Lemma 1 in Appx. A.2.4), induced by a norm. Further, let the groundtruth marginal distribution be uniform and the conditional distribution be as Eq. (5). Let the mixing function g be differentiable and injective. If the assumed form of q h matches that of p, i.e.,</p><formula xml:id="formula_7">q h (z|z) = C ?1 q (z)e ??(h(z),h(z))/? with C q (z) : = e ??(h(z),h(z))/? dz,<label>(7)</label></formula><p>and if f is differentiable and minimizes the L ?-contr objective in Eq. (6) for M ? ?, we find that h = f ? g is invertible and affine, i.e., we recover the latent sources up to affine transformations.</p><p>Note that the model distribution q h , which is implicitly described by the choice of the objective, must be of the same form as the ground-truth distribution p, i.e., both must be based on the same metric. Thus, identifying different ground-truth conditional distributions requires different contrastive L ?-contr objectives. This result can be seen as a generalized version of Theorem 2, as it is valid for any convex body Z ? R N , allowing for a larger variety of conditional distributions.</p><p>Finally, under the mild restriction that the ground-truth conditional distribution is based on an L p similarity measure for p ? 1, p = 2, h identifies the ground-truth generative factors up to generalized permutations. A generalized permutation matrix A is a combination of a permutation and element-wise sign-flips, i.e., ?z : (Az) i = ? i z ?(i) with ? i = ?1 and ? being a permutation.</p><p>Theorem 6. Let Z be a convex body in R N , h : Z ? Z, and ? be an L ? metric or semi-metric (cf. Lemma 1 in Appx. A.2.4) for ? ? 1, ? = 2. Further, let the groundtruth marginal distribution be uniform and the conditional distribution be as Eq. <ref type="formula" target="#formula_5">(5)</ref>, and let the mixing function g be differentiable and invertible. If the assumed form of q h (?|z) matches that of p(?|z), i.e., both use the same metric ? up to a constant scaling factor, and if f is differentiable and minimizes the L ?-contr objective in Eq. (6) for M ? ?, we find that h = f ? g is a composition of input independent permutations, sign flips and rescaling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Validation of theoretical claim</head><p>We validate our theoretical claims under both perfectly matching and violated conditions regarding the groundtruth marginal and conditional distributions. We consider source signals of dimensionality N = 10, and sample pairs of source signals in two steps: First, we sample from the marginal p(z). For this, we consider both uniform distributions which match our assumptions and non-uniform distributions (e.g., a normal distribution) which violate them. Second, we generate the positive pair by sampling from a conditional distribution p(z|z). Here, we consider matches with our assumptions on the conditional distribution (von Mises-Fisher for Z = S N ?1 ) as well as violations (e.g. normal, Laplace or generalized normal distribution for Z = S N ?1 ). Further, we consider spaces beyond the hypersphere, such as the bounded box (which is a convex body) and the unbounded R N .</p><p>We generate the observations with a multi-layer perceptron (MLP), following previous work <ref type="bibr" target="#b18">(Hyv?rinen &amp; Morioka, 2016;</ref>. Specifically, we use three hidden layers with leaky ReLU units and random weights; to ensure that the MLP g is invertible, we control the condition number of the weight matrices. For our feature encoder f , we also use an MLP with leaky ReLU units, where the assumed space is denoted by the normalization, or lack thereof, of the encoding. Namely, for the hypersphere (denoted as Sphere) and the hyperrectangle (denoted as Box) we apply an L 2 and L ? normalization, respectively. For flexibility in practice, we parameterize the normalization magnitude of the Box, including it as part of the encoder's learnable parameters. On the hypersphere we optimize L contr and on the hyperrectangle as well as the unbounded space we optimize L ?-contr . For further details, see Appx. A.3.</p><p>To test for identifiability up to affine transformations, we fit a linear regression between the ground-truth and recovered sources and report the coefficient of determination (R 2 ). To test for identifiability up to generalized permutations, we leverage the mean correlation coefficient (MCC), as used in previous work <ref type="bibr" target="#b18">(Hyv?rinen &amp; Morioka, 2016;</ref>. For further details, see Appx. A.3.</p><p>We evaluate both identifiability metrics for three different model types. First, we ensure that the problem requires nonlinear demixing by considering the identity function for model f , which amounts to scoring the observations against the sources (Identity Model). Second, we ensure that the problem is solvable within our model class by training our model f with supervision, minimizing the mean-squared error between f (g(z)) and z (Supervised Model). Third, we fit our model without supervision using a contrastive loss (Unsupervised Model).</p><p>Tables 1 and 2 show results evaluating identifiability up to affine transformations and generalized permutations, respectively. When assumptions match (see column M.), CL recovers a score close to the empirical upper bound. Mismatches in assumptions on the marginal and conditional do not lead to a significant drop in performance with respect to affine identifiability, but do for permutation identifiability compared to the empirical upper bound. In many practical scenarios, we use the learned representations to solve a downstream task, thus, identifiability up to affine transformations is often sufficient. However, for applications where identification of the individual generative factors is desirable, some knowledge of the underlying generative process is required to choose an appropriate loss function and feature normalization. Interestingly, we find that for convex bodies, we obtain identifiability up to permutation even in the case of a normal conditional, which likely is due to the axis-aligned box geometry of the latent domain. Finally, note that the drop in performance for identifiability up to permutations in the last group of Tab. 2 is a natural consequence of either the ground-truth or the assumed conditional being rotationally symmetric, e.g., a normal distribution, in an unbounded space. Here, rotated versions of the latent space are indistinguishable and, thus, the model cannot align the axes of the reconstruction with that of the ground-truth latent space, resulting in a lower score.</p><p>To zoom in on how violations of the uniform marginal assumption influence the identifiability achieved by a model in practice, we perform an ablation on the marginal distribution by interpolating between the theoretically assumed uniform distribution and highly locally concentrated distributions. In particular, we consider two cases: (1) a sphere (S 9 ) with a vMF marginal around its north pole for different concentration parameters ?;</p><p>(2) a box ([0, 1] 10 ) with a normal marginal around the box's center for different standard deviations ?. For both cases, <ref type="figure" target="#fig_0">Fig. 2</ref> shows the R 2 score as a function of the concentration ? and 1/? 2 respectively (black). As a reference, the concentration of the used conditional distribution is highlighted as a dashed line. In addition, we also display the probability mass (0-100%)  that needs to be moved for converting the used marginal distribution (i.e., vMF or normal) into the assumed uniform marginal distribution (blue) as an intuitive measure of the mismatch (i.e., 1 2 |p(z)?p uni | dz). While, we observe significant robustness to mismatch, in both cases, we see performance drop drastically once the marginal distribution is more concentrated than the conditional distribution of positive pairs. In such scenarios, positive pairs are indistinguishable from negative pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Extensions to image data</head><p>Previous studies have demonstrated that representation learning using constrastive learning scales well to complex natural image data <ref type="bibr" target="#b6">(Chen et al., 2020a;</ref><ref type="bibr" target="#b16">H?naff, 2020)</ref>. Unfortunately, the true generative factors of natural images are inaccessible, thus we cannot evaluate identifiability scores.</p><p>We consider two alternatives. First, we evaluate on the recently proposed benchmark KITTI Masks <ref type="bibr">(Klindt et al., 2021)</ref>, which is composed of segmentation masks of natural videos. Second, we contribute a novel benchmark (3DIdent; cf. <ref type="figure" target="#fig_1">Fig. 3</ref>) which features aspects of natural scenes, e.g. a complex 3D object and different lighting conditions, while still providing access to the continuous ground-truth factors. For further details, see Appx. A.4.1. 3DIdent is available at zenodo.org/record/4502485.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">KITTI MASKS</head><p>KITTI Masks <ref type="bibr">(Klindt et al., 2021)</ref> is composed of pedestrian segmentation masks extracted from an autonomous driving vision benchmark KITTI-MOTS <ref type="bibr" target="#b11">(Geiger et al., 2012)</ref>, with natural shapes and continuous natural transitions. We compare to SlowVAE <ref type="bibr">(Klindt et al., 2021)</ref>, the state-of-the-art on the considered dataset. In our experiments, we use the same training hyperparameters (for details see Appx. A.3) and (encoder) architecture as <ref type="bibr">Klindt et al. (2021)</ref>. The positive <ref type="table">Table 1</ref>. Identifiability up to affine transformations. Mean ? standard deviation over 5 random seeds. Note that only the first row corresponds to a setting that matches () our theoretical assumptions, while the others show results for violated assumptions (; see column M.). Note that the identity score only depends on the ground-truth space and the marginal distribution defined for the generative process, while the supervised score additionally depends on the space assumed by the model. pairs consist of nearby frames with a time separation ?t.</p><formula xml:id="formula_8">Generative process g Model f R 2 Score [%] Space p(?) p(?|?) Space q h (?|?) M.</formula><p>As argued and shown in <ref type="bibr">Klindt et al. (2021)</ref>, the transitions in the ground-truth latents between nearby frames is sparse. Unsurprisingly then, <ref type="table" target="#tab_4">Table 3</ref> shows that assuming a Laplace conditional as opposed to a normal conditional in the contrastive loss leads to better identification of the underlying factors of variation. SlowVAE also assumes a Laplace conditional <ref type="bibr">(Klindt et al., 2021)</ref> but appears to struggle if the frames of a positive pair are too similar (?t = 0.05s). This degradation in performance is likely due to the limited expressiveness of the decoder deployed in SlowVAE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">3DIDENT</head><p>Dataset description We build on <ref type="bibr" target="#b24">(Johnson et al., 2017b)</ref> and use the Blender rendering engine (Blender Online Com-  munity, 2021) to create visually complex 3D images (see <ref type="figure" target="#fig_1">Fig. 3</ref>). Each image in the dataset shows a colored 3D object which is located and rotated above a colored ground in a 3D space. Additionally, each scene contains a colored spotlight focused on the object and located on a half-circle around the scene. The observations are encoded with an RGB color space, and the spatial resolution is 224 ? 224 pixels.</p><p>The images are rendered based on a 10-dimensional latent, where: (1) three dimensions describe the XYZ position, (2) three dimensions describe the rotation of the object in Euler angles, (3) two dimensions describe the color of the object and the ground of the scene, respectively, and (4) two dimensions describe the position and color of the spotlight. We use the HSV color space to describe the color of the object and the ground with only one latent each by having the latent factor control the hue value. For more details on the dataset see Sec. A.4.</p><p>The dataset contains 250 000 observation-latent pairs where the latents are uniformly sampled from the hyperrectangle Z. To sample positive pairs (z,z) we first sample a valu? z from the data conditional p(z |z), and then use nearestneighbor matching 3 implemented by FAISS <ref type="bibr" target="#b23">(Johnson et al., 2017a)</ref> to find the latentz closest toz (in L 2 distance) for which there exists an image rendering. In addition, unlike previous work <ref type="bibr" target="#b12">(Locatello et al., 2019)</ref>, we create a hold-out test set with 25 000 distinct observation-latent pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments and Results</head><p>We train a convolutional feature encoder f composed of a ResNet18 architecture <ref type="bibr">(He 3</ref> We used an Inverted File Index (IVF) with Hierarchical Navigable Small World (HNSW) graph exploration for fast indexing. et al., 2016) and an additional fully-connected layer, with a LeakyReLU nonlinearity as the hidden activation. For more details, see Appx. A.3. Following the same methodology as in Sec. 4.1, i) depending on the assumed space, the output of the feature encoder is normalized accordingly and ii) in addition to the CL models, we also train a supervised model to serve as an upper bound on performance. We consider normal and Laplace distributions for positive pairs. Note, that due to the finite dataset size we only sample from an approximation of these distributions.</p><p>As in Tables 1 and 2, the results in <ref type="table">Table 4</ref> demonstrate that CL reaches scores close to the topline (supervised) performance, and mismatches between the assumed and ground-truth conditional distribution do not harm the performance significantly. However, if the hypothesis class of the encoder is too restrictive to model the ground-truth conditional distribution, we observe a clear drop in performance, i.e., mapping a box onto a sphere. Note, that this corresponds to the InfoNCE objective for L 2 -normalized representations, commonly used for self-supervised representation learning <ref type="bibr">(Wu et al., 2018;</ref><ref type="bibr" target="#b15">He et al., 2020b;</ref><ref type="bibr">Tian et al., 2019;</ref><ref type="bibr" target="#b0">Bachman et al., 2019;</ref><ref type="bibr" target="#b6">Chen et al., 2020a)</ref>.</p><p>Finally, the last result shows that leveraging image augmentations <ref type="bibr" target="#b6">(Chen et al., 2020a)</ref> as opposed to sampling from a specified conditional distribution of positive pairs p(?|?) results in a performance drop. For details on the experiment, see Appx. Sec. A.3. We explain this with the greater mismatch between the conditional distribution assumed by the model and the conditional distribution induced by the augmentations. In all, we demonstrate validation of our theoretical claims even for generative processes with higher visual complexity than those considered in Sec. 4.1. <ref type="table">Table 4</ref>. Identifiability up to affine transformations on the test set of 3DIdent. Mean ? standard deviation over 3 random seeds. As earlier, only the first row corresponds to a setting that matches the theoretical assumptions for linear identifiability; the others show distinct violations. Supervised training with unbounded space achieves scores of R 2 = (98.67 ? 0.03)% and MCC = (99.33 ? 0.01)%. The last row refers to using the image augmentations suggested by <ref type="bibr" target="#b6">Chen et al. (2020a)</ref> to generate positive image pairs. For performance on the training set, see Appx. <ref type="table">Table 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Model </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We showed that objectives belonging to the InfoNCE family, the basis for a number of state-of-the-art techniques in self-supervised representation learning, can uncover the true generative factors of variation underlying the observational data. To succeed, these objectives implicitly encode a few weak assumptions about the statistical nature of the underlying generative factors. While these assumptions will likely not be exactly matched in practice, we showed empirically that the underlying factors of variation are identified even if theoretical assumptions are severely violated.</p><p>Our theoretical and empirical results suggest that the representations found with contrastive learning implicitly (and approximately) invert the generative process of the data. This could explain why the learned representations are so useful in many downstream tasks. It is known that a decisive aspect of contrastive learning is the right choice of augmentations that form a positive pair. We hope that our framework might prove useful for clarifying the ways in which certain augmentations affect the learned representations, and for finding improved augmentation schemes.</p><p>Furthermore, our work opens avenues for constructing more effective contrastive losses. As we demonstrate, imposing a contrastive loss informed by characteristics of the latent space can considerably facilitate inferring the correct semantic descriptors, and thus boost performance in downstream tasks. While our framework already allows for a variety of conditional distributions, it is an interesting open question how to adapt it to marginal distributions beyond the uniform implicitly encoded in InfoNCE. Also, future work may extend our theoretical framework by incorporating additional assumptions about our visual world, such as compositionality, hierarchy or objectness. Accounting for such inductive biases holds enormous promise in forming the basis for the next generation of self-supervised learning algorithms.</p><p>Taken together, we lay a strong theoretical foundation for not only understanding but extending the success of stateof-the-art self-supervised learning techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author contributions</head><p>The project was initiated by WB. <ref type="bibr">RSZ</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1. Extended Theory for Hyperspheres</head><p>A.1.1. ASSUMPTIONS Generative Process Let the generator g : R N ? X with X ? R K and K ? N . Further, let the restriction of g to the space Z = S N ?1 ? R N be injective and g be differentiable in the vicinity of Z. We assume that the marginal distribution p(z) over latent variables z ? Z is uniform:</p><formula xml:id="formula_9">p(z) = 1 |Z| .<label>(8)</label></formula><p>Further, we assume that the conditional distribution over positive pairs p(z|z) is a von Mises-Fisher (vMF) distribution</p><formula xml:id="formula_10">p(z|z) = C ?1 p e ?z z<label>(9)</label></formula><p>with C p : = e ?? z dz,</p><p>where ? is a parameter controlling the width of the distribution and ? is any vector on the hypersphere. Finally, we assume that during training one has access to observations x, which are samples from these distributions transformed by the generator function g. </p><p>where C q (z) is the partition function and ? &gt; 0 is a scale parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.2. PROOFS FOR SEC. 3</head><p>We begin by recalling a result of Wang &amp; Isola (2020), where the authors show an asymptotic relation between the contrastive loss L contr and two loss functions, the alignment loss L align and the uniformity loss L uni :</p><p>Proposition A (Asymptotics of L contr , Wang &amp; Isola, 2020). </p><p>where</p><formula xml:id="formula_14">L align (f ; ? ) := ? 1 ? E (z,z)?p(z,z) (f ? g)(z) T (f ? g)(z) L uni (f ; ? ) := E z?p(z) log ? z?p(z) e (f ?g)(z) T (f ?g)(z)/? .<label>(13)</label></formula><p>Proof. See Theorem 1 of <ref type="bibr">Wang &amp; Isola (2020)</ref>. Note that they originally formulated the losses in terms of observations x and not in terms of the latent variables z. However, this modified version simplifies notation in the following.</p><p>Based on this result, we show that the contrastive loss L contr asymptotically converges to the cross-entropy between the ground-truth conditional p and our assumed model conditional distribution q h , up to a constant. This is notable, because given the correct model specification for q h , it is well-known that the cross-entropy is minimized iff q h = p, i.e., the ground-truth conditional distribution and the model distribution will match.</p><p>Theorem 1 (L contr converges to the cross-entropy between latent distributions). If the ground-truth marginal distribution p is uniform, then for fixed ? &gt; 0, as the number of negative samples M ? ?, the (normalized) contrastive loss converges to</p><formula xml:id="formula_15">lim M ?? L contr (f ; ?, M ) ? log M + log |Z| = E z?p(z) [H(p(?|z), q h (?|z))]<label>(14)</label></formula><p>where H is the cross-entropy between the ground-truth conditional distribution p over positive pairs and a conditional distribution q h parameterized by the model f , and C h (z) ? R + is the partition function of q h (see Appendix A.1.1):</p><formula xml:id="formula_16">q h (z|z) = C h (z) ?1 e h(z) T h(z)/? with C h (z) : = e h(z) T h(z)/? dz.<label>(15)</label></formula><p>Proof. The cross-entropy between the conditional distributions p and q h is given by</p><formula xml:id="formula_17">E z?p(z) [H(p(?|z), q h (?|z))] (16) = E z?p(z) ? z?p(z|z) [? log q h (z|z)] (17) = ? z,z?p(z,z) ? 1 ? h(z) h(z) + log C h (z) (18) = ? 1 ? ? z,z?p(z,z) h(z) h(z) + E z?p(z) [log C h (z)] .<label>(19)</label></formula><p>Using the definition of C h in Eq. (15) we obtain</p><formula xml:id="formula_18">= ? 1 ? ? z,z?p(z,z) h(z) h(z) (20) + E z?p(z) log Z e h(z) h(z)/? dz .<label>(21)</label></formula><p>By assumption the marginal distribution is uniform, i.e., p(z) = |Z| ?1 . We expand by |Z||Z| ?1 and estimate the integral by sampling from p(z) = |Z| ?1 , yielding</p><formula xml:id="formula_19">= ? 1 ? ? z,z?p(z,z) h(z) h(z) (22) + E z?p(z) log |Z| ? z?p(z) e h(z) h(z)/? (23) = ? 1 ? ? z,z?p(z,z) h(z) h(z) (24) + E z?p(z) log ? z?p(z) e h(z) h(z)/? + log |Z|.<label>(25)</label></formula><p>By inserting the definition h = f ? g,</p><formula xml:id="formula_20">= ? 1 ? ? z,z?p(z,z) (f ? g)(z) (f ? g)(z) (26) + E z?p(z) log ? z?p(z) e (f ?g)(z) (f ?g)(z)/? (27) + log |Z|,<label>(28)</label></formula><p>we can identify the losses introduced in Proposition A,</p><formula xml:id="formula_21">=L align (f ; ? ) + L uni (f ; ? ) + log |Z|,<label>(29)</label></formula><p>which recovers the original alignment term and the uniformity term for maximimizing entropy by means of a von Mises-Fisher KDE up to the constant log |Z|. According to Proposition A this equals</p><formula xml:id="formula_22">= lim M ?? L contr (f ; ?, M ) ? log M + log |Z|,<label>(30)</label></formula><p>which concludes the proof.</p><p>Proposition 1 (Minimizers of the cross-entropy maintain the dot product). Let Z = S N ?1 , ? &gt; 0 and consider the ground-truth conditional distribution of the form p(z|z) = C ?1 p exp(?z z). Let h map onto a hypersphere with radius ? ? ?. 4 Consider the conditional distribution q h parameterized by the model, as defined above in Theorem 1, where the hypothesis class for h is assumed to be sufficiently flexible such that p(z|z) and q h (z|z) can match. If h is a minimizer of the cross-entropy E p(z|z) [? log q h (z|z)], then p(z|z) = q h (z|z) and ?z,z : ?z z = h(z) h(z).</p><p>Proof. By assumption, q h (z|z) is powerful enough to match p(z|z) for the correct choice of h -in particular, for h(z) = ? ? ?z. The global minimum of the cross-entropy between two distributions is reached if they match by value and have the same support. Thus, this means</p><formula xml:id="formula_23">p(z|z) = q h (z|z).<label>(31)</label></formula><p>This expression also holds true forz = z; additionally using that h maps from a unit hypersphere to one with radius ? ? ? yields p(z|z) = q h (z|z) (32)</p><formula xml:id="formula_24">? C ?1 p e ?z z = C h (z) ?1 e h(z) h(z)/? (33) ? C ?1 p e ? = C h (z) ?1 e ? (34) ? C p = C h .<label>(35)</label></formula><p>As the normalization constants are identical we get for all z,z ? Z</p><formula xml:id="formula_25">e ?z z = e h(z) h(z) ? ?z z = h(z) h(z).<label>(36)</label></formula><p>Proposition 2 (Extension of the Mazur-Ulam theorem to hyperspheres and the dot product). Let Z = S N ?1 and Z = S N ?1 r be the hyperspheres with radius 1 and r &gt; 0, respectively. If h : R N ? Z is differentiable in the vicinity of Z and its restriction to Z maintains the dot product up to a constant factor, i.e., ?z,z ? Z : r 2 z z = h(z) h(z), then h is an orthogonal linear transformation scaled by r for all z ? Z. Proof. First, we begin with the case r = 1. As h maintains the dot product we have:</p><formula xml:id="formula_26">?z,z ? Z : z z = h(z) h(z).<label>(37)</label></formula><p>We consider the partial derivative w.r.t. z and obtain:</p><formula xml:id="formula_27">?z,z ? Z :z = J h (z)h(z).<label>(38)</label></formula><p>Taking the partial derivative w.r.t.z yields ?z,z ? Z :</p><formula xml:id="formula_28">I = J h (z)J h (z).<label>(39)</label></formula><p>We can now conclude</p><formula xml:id="formula_29">?z,z ? Z : J h (z) ?1 = J h (z).<label>(40)</label></formula><p>which implies a constant Jacobian matrix J h (z) = J h as the identity holds on all points in Z, and further that the Jacobian J h is orthogonal. Hence, ?z ? Z : h(z) = J h z is an orthogonal linear transformation.</p><p>Finally, for r = 1 we can leverage the previous result by introducing h (z) := h(z)/r. For h the previous argument holds, implying that h is an orthogonal transformation. Therefore, the restriction of h to Z is an orthogonal linear transformation scaled by r 2 .</p><p>Taking all of this together, we can now prove Theorem 2:</p><p>Theorem 2. Let Z = S N ?1 , the ground-truth marginal be uniform, and the conditional a vMF distribution (cf. Eq. 2). Let the restriction of the mixing function g to Z be injective and h be differentiable in a vicinity of Z. If the assumed form of q h , as defined above, matches that of p, and if f is differentiable and minimizes the CL loss as defined in <ref type="figure">Eq.</ref> (1), then for fixed ? &gt; 0 and M ? ?, h = f ? g is linear, i.e., f recovers the latent sources up to an orthogonal linear transformation and a constant scaling factor.</p><p>Proof. As f minimzes the contrastive loss L contr we can apply Theorem 1 to see that f also minimizes the crossentropy between p(z|z) and q h (z|z) for any point z on Z. This means, we can apply Proposition 1 to show that the concatenation h = f ? g is an isometry with respect to the dot product. Finally, according to Proposition 2, h must then be a composition of an orthogonal linear transformation and a constant scaling factor. Thus, f recovers the latent sources up to orthogonal linear transformations, concluding the proof.</p><p>A.2. Extension of theory to subspaces of R N Here, we show how one can generalize the theory above from Z = S N ?1 to Z ? R N . Under mild assumptions regarding the ground-truth conditional distribution p and the model distribution q h , we prove that all minimizers of the cross-entropy between p and q h are linear functions, if Z is a convex body. Note that the hyperrectangle [a 1 , b 1 ] ? . . . ? [a N , b N ] is an example of such a convex body.</p><p>A.2.1. ASSUMPTIONS First, we restate the core assumptions for this proof. The main difference to the assumptions for the hyperspherical case above is that we assume different conditional distributions: instead of rotation-invariant von Mises-Fisher distributions, we use translation-invariant distributions (up to restrictions determined by the finite size of the space) of the exponential family.</p><p>Generative process Let g : Z ? X be an injective function between the two spaces Z ? R N and X ? R K with K ? N and where Z is a convex body (e.g., a hyperrectangle). Further, let the marginal distribution be uniform, i.e., p(z) = |Z| ?1 . We assume that the conditional distribution over positive pairs p(z|z) is an exponential distribution</p><formula xml:id="formula_30">p(z|z) = C ?1 p (z)e ???(z,z) with C p (z) : = e ???(z,z) dz,<label>(41)</label></formula><p>where ? &gt; 0 a parameter controlling the width of the distribution and ? is a (semi-)metric. If ? is a semi-metric, i.e., it does not fulfill the triangle inequality, there must exist a metric ? such that ? can be written as the composition of a continuously invertible map j : R ?0 ? R ?0 with j(0) = 0 and the metric, i.e., ? = j ? ? . Finally, we assume that during training one has access to samples from both of these distributions.</p><p>Note that unlike for the hypersphere, when sampling positive pairs z,z ? p(z)p(z|z), it is no longer guaranteed that the marginal distributions of z andz are the same. When referencing the density functions -or using them in expectation values -p(?) will always denote the same marginal density, no matter if the argument is z orz. Specifically, p(z) does not refer to p(z)p(z|z)dz.</p><p>Model Let Z be a subset of R N that is a convex body and let f : X ? Z be the model whose parameters are optimized. We associate a conditional distribution q h (z|z) with our model f through</p><formula xml:id="formula_31">q h (z|z) = C ?1 q (z)e ??(h(z),h(z))/? with C q (z) : = e ??(h(z),h(z))/? dz,<label>(42)</label></formula><p>where C q (z) is the partition function and ? is defined above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2. MINIMIZING THE CROSS-ENTROPY</head><p>In a first step, we show the analogue of Proposition A for Z being a convex body: Proposition 3. For fixed ? &gt; 0, as the number of negative samples M ? ?, the L ?-contr loss converges to</p><formula xml:id="formula_32">lim M ?? L ?-contr (f ; ?, M ) ? log M = L ?-align (f ; ? ) + L ?-uni (f ; ? ),<label>(43)</label></formula><p>where</p><formula xml:id="formula_33">L ?-align (f ; ? ) := 1 ? E z?p(z) z?p(z|z) [?(h(z), h(z)))] L ?-uni (f ; ? ) := E z?p(z) log ? z?p(z) e ??(h(z),h(z))/? ,<label>(44)</label></formula><p>and L ?-contr (f ; ?, M ) is as defined in Eq. (6).</p><p>Proof. This proof is adapted from Wang &amp; Isola (2020). By the Continuous Mapping Theorem and the law of large numbers, for any x,x and { x ? i } M i=1 it follows almost surely </p><p>Next, we derive a property similar to Theorem 1, which suggests a practical method to find minimizers of the crossentropy between the ground-truth p and model conditional q h . This property is based on our previously introduced objective function in Eq. (6), which is a modified version of the InfoNCE objective in Eq. (1).</p><p>Theorem 3. Let ? be a semi-metric and ?, ? &gt; 0 and let the ground-truth marginal distribution p be uniform. Consider a ground-truth conditional distribution p(z|z) = C ?1 p (z) exp <ref type="figure">(???(z, z)</ref>) and the model conditional distribution</p><formula xml:id="formula_35">q h (z|z) = C ?1 h (z)e ??(h(z),h(z))/? with C h (z) : = Z e ??(h(z),h(z))/? dz.<label>(48)</label></formula><p>Then the cross-entropy between p and q h is given by</p><formula xml:id="formula_36">lim M ?? L ?-contr (f ; ?, M ) ? log M + log |Z| = E z?p(z) [H(p(?|z), q h (?|z)] ,<label>(49)</label></formula><p>which can be implemented by sampling data from the accessible distributions.</p><p>Proof. We use the definition of the cross-entropy to write [log(q h (z|z))] .</p><p>We insert the definition of q h and get</p><formula xml:id="formula_38">= ? E z?p(z) ? z?p(z|z) log(C ?1 h (z)) ? 1 ? ?(h(z), h(z))) (52) = E z?p(z) ? z?p(z|z) log(C h (z)) + 1 ? ?(h(z), h(z))) .<label>(53)</label></formula><p>As C h (z) does not depend onz it can be moved out of the inner expectation value, yielding</p><formula xml:id="formula_39">= E z?p(z) 1 ? ? z?p(z|z) [?(h(z), h(z)))] + log(C h (z)) ,<label>(54)</label></formula><p>which can be written as</p><formula xml:id="formula_40">= 1 ? E z?p(z) z?p(z|z) [?(h(z), h(z)))] + E z?p(z) [log(C h (z))] .<label>(55)</label></formula><p>Inserting the definition of C h gives</p><formula xml:id="formula_41">= 1 ? E z?p(z) z?p(z|z) [?(h(z), h(z)))] (56) + E z?p(z) log e ??(h(z),h(z))/? dz .<label>(57)</label></formula><p>Next, the second term can be expanded by 1 = |Z||Z| ?1 , yielding</p><formula xml:id="formula_42">= 1 ? E z?p(z) z?p(z|z) [?(h(z), h(z)))]<label>(58)</label></formula><formula xml:id="formula_43">+ E z?p(z) log |Z| |Z| e ??(h(z),h(z))/? dz . (59)</formula><p>Finally, by using that the marginal is uniform, i.e., p(z) = |Z| ?1 , this can be simplified as</p><formula xml:id="formula_44">= 1 ? E z?p(z) z?p(z|z) [?(h(z), h(z)))]<label>(60)</label></formula><formula xml:id="formula_45">+ E z?p(z) log ? z?p(z) e ??(h(z),h(z))/? (61) + log |Z| (62) = lim M ?? L ?-contr (f ; ?, M ) ? log M + log p|Z|.<label>(63)</label></formula><p>A.2.3. CROSS-ENTROPY MINIMIZERS ARE ISOMETRIES Now we show a version of Proposition 1, that is generalized from hyperspherical spaces to (subsets of) R N .</p><p>Proposition 4 (Minimizers of the cross-entropy are isometries). Let ? be a semi-metric. Consider the conditional distributions of the form p(z|z) = C ?1 p (z) exp(??(z, z)/?) and</p><formula xml:id="formula_46">q h (z|z) = C ?1 h (z)e ??(h(z),h(z))/? with C h (z) : = Z e ??(h(z),h(z))/? dz,<label>(64)</label></formula><p>where the hypothesis class for h is assumed to be sufficiently flexible such that p(z|z) and q h (z|z) can match for any point z. If h is a minimizer of the cross-entropy L CE = E p(z|z) [? log q h (z|z)], then h is an isometry, i.e., ?z,z ? Z : ?? ?(z,z) = ?(h(z), h(z)).</p><p>Proof. Note that q h (z|z) is powerful enough to match p(z|z) for the correct choice of h, e.g. the identity. The global minimum of cross-entropy between two distributions is reached if they match by value and have the same support. Hence, if p is a regular density, q h will be a regular density, i.e., q h is continuous and has only finite values 0 ? q h &lt; ?.</p><p>As the two distributions match, this means</p><formula xml:id="formula_47">p(z|z) = q h (z|z).<label>(65)</label></formula><p>This expression also holds true forz = z; additionally using the property ?(z, z) = 0 yields</p><formula xml:id="formula_48">p(z|z) = q h (z|z) (66) ? C ?1 p (z)e ??(z,z)/? = C ?1 h (z)e ??(h(z),h(z))/? (67) ? C p (z) = C h (z).<label>(68)</label></formula><p>As the normalization constants are identical, we obtain for all z,z ? Z</p><formula xml:id="formula_49">e ??(z,z)/? = e ??(h * (z),h * (z))/? (69) ? ?(z, z) = ? ? ?(h * (z), h * (z)).<label>(70)</label></formula><p>By introducing a new semi-metric ? := ?? ?1 ?, we can write this as ?(z, z) = ? (h(z), h(z)), which shows that h is an isometry. If there is no model mismatch, i.e., ? = ? , this means ?(z,z) = ?(h(z), h(z)).</p><p>Note, that this result does not depend on the choice of Z but just on the class of conditional distributions allowed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.4. CROSS-ENTROPY MINIMIZATION IDENTIFIES THE</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GROUND-TRUTH FACTORS</head><p>Before we continue, let us recall a Theorem by <ref type="bibr">Mankiewicz (1972)</ref>: <ref type="bibr">Mankiewicz, 1972)</ref>. Let X and Y be normed linear spaces and let V be a convex body in X and W a convex body in Y. Then every surjective isometry between V and W can be uniquely extended to an affine isometry between X and Y.</p><formula xml:id="formula_50">Theorem C (</formula><p>Proof. See Mankiewicz <ref type="bibr">(1972)</ref>.</p><p>In addition, it is known that isometries on closed spaces are bijective:</p><p>Lemma A. Assume h is an isometry of the closed space Z into itself, i.e., ?z,z : ?(z,z) = ?(h(z), h(z)). Then h is bijective.</p><p>Proof. See Lemma (2.6) in <ref type="bibr" target="#b5">Ca?ka (1982)</ref> for surjectivity. We show the injectivity by contradiction. Assume h is not injective. Then we can find a pointz = z where h(z) = h(z). But then ?(z,z) &gt; ?(z, z) and ?(h(z), h(z)) = ?(h(z), h(z)) = 0 by the properties of ?. Hence, h is injective.</p><p>Before continuing, we need to generalize the class of functions we consider as distance measures:</p><p>Lemma 1. Let ? be a the composition of a continuously invertible function j : R ?0 ? R ?0 with j(0) = 0 and a metric ?, i.e., ? := j ? ?. Then, (i) ? is a semi-metric and (ii) if a function h : R n ? R n is an isometry of a space with the semi-metric ? , it is also an isometry of the space with the metric ?.</p><p>Proof. (i) Let z,z ? Z. Per assumption j must be strictly monotonically increasing on R ?0 . Since ? is a metric it follows ?(z,z) ? 0 ? ? (z,z) = j(?(z,z)) ? 0, with equality iff z =z. Furthermore, since ? is a metric it is symmetric in its arguments and, hence, ? is symmetric in its arguments. Thus, ? is a semi-metric.</p><p>(ii) h is an isometry of a space with the semi-metric ? , allowing to derive that for all z,z ? Z,</p><formula xml:id="formula_51">? (h(z), h(z)) = ? (z,z) (71) j(?(h(z), h(z))) = j(?(z,z))<label>(72)</label></formula><p>and, applying the inverse j ?1 which exists by assumption, yields</p><formula xml:id="formula_52">?(h(z), h(z)) = ?(z,z),<label>(73)</label></formula><p>concluding the proof.</p><p>By combining the properties derived before we can show that h is an affine function:</p><p>Theorem 4. Let Z = Z be a convex body in R N . Let the mixing function g be differentiable and invertible. If the assumed form of q h as defined in Eq. (42) matches that of p, and if f is differentiable and minimizes the cross-entropy between p and q h , then we find that h = f ? g is affine, i.e., we recover the latent sources up to affine transformations. Proof. According to Proposition 4 h is an isometry and q h is a regular probability density function. If the distance ? used in the conditional distributions p and q h is a semi-metric as in Lemma 1, it follows that h is also an isometry for a proper metric. This also means that h is bijective according to Lemma A. Finally, Theorem C says that h is an affine transformation.</p><p>We use the assumption that the marginal p(z) is uniform, to show Theorem 5. Let Z be a convex body in R N , h = f ? g : Z ? Z, and ? be a metric or a semi-metric as defined in Lemma 1. Further, let the ground-truth marginal distribution be uniform and the conditional distribution be as (5). Let the mixing function g be differentiable and injective. If the assumed form of q h matches that of p, i.e.,</p><formula xml:id="formula_53">q h (z|z) = C ?1 q (z)e ??(h(z),h(z))/? with C q (z) : = e ??(h(z),h(z))/? dz,<label>(74)</label></formula><p>and if f is differentiable and minimizes the L ?-contr objective in (6) for M ? ?, we find that h = f ? g is invertible and affine, i.e., we recover the latent sources up to affine transformations.</p><p>Proof. According to Theorem 3 h minimizes the crossentropy between p and q h as defined in Eq. (4). Then according to Theorem 4, h is an affine transformation.</p><p>This result can be seen as a generalized version of Theorem 2, as it is valid for any convex body Z ? R N and allows a larger variety of conditional distributions. A missing step is to extend this theory beyond uniform marginal distributions. This will be addressed in future work.</p><p>Under some assumptions we can further narrow down possible forms of h, thus, showing that h in fact solves the nonlinear ICA problem only up to permutations and elementwise transformations.</p><p>For this, let us first repeat a result from <ref type="bibr" target="#b32">Li &amp; So (1994)</ref>, that shows an important property of isometric matrices:</p><p>Theorem D. Suppose 1 ? ? ? ? and ? = 2. An n ? n matrix A is an isometry of L ? -norm if and only if A is a generalized permutation matrix, i.e., ?z : (Az) i = ? i z ?(i) , with ? i = ?2 and ? being a permutation.</p><p>Proof. See <ref type="bibr" target="#b32">Li &amp; So (1994)</ref>. Note that this can also be concluded from the Banach-Lamperti Theorem <ref type="bibr" target="#b30">(Lamperti et al., 1958)</ref>.</p><p>Leveraging this insight, we can finally show:</p><p>Theorem 6. Let Z be a convex body in R N , h : Z ? Z, and ? be an L ? metric for ? ? 1, ? = 2 or the ?-th power of such an L ? metric. Further, let the ground-truth marginal distribution be uniform and the conditional distribution be as in Eq. (5), and let the mixing function g be differentiable and invertible. If the assumed form of q h (?|z) matches that of p(?|z), i.e., both use the same metric ? up to a constant scaling factor, and if f is differentiable and minimizes the L ?-contr objective in Eq. (6) for M ? ? we find that h = f ? g is a composition of input independent permutations, sign flips and rescalings. Proof. First, we prove the case where both conditional distributions use exactly the same metric. By Theorem 5 h is an affine transformation. Moreover, according to Proposition 4 is an isometry. Thus, by Theorem D, h is a generalized permutation matrix, i.e., a composition of permutations and sign flips.</p><p>Finally, for the case that ? matches the similarity measure in the ground-truth conditional distribution defined in Eq. (5) (denoted as ? * ) only up to a constant rescaling factor r, we know ?z,z : ? * (z,z) = ?(h(z), h(z))</p><formula xml:id="formula_54">? ? * (z,z) = ? * 1 r h(z), 1 r h(z) .<label>(75)</label></formula><p>Thus, 1 r h is a ? * isometry and the same argument as above holds, concluding the proof. <ref type="table">Table 5</ref>. Identifiability up to affine transformations on the training set of 3DIdent. Mean ? standard deviation over 3 random seeds. As earlier, only the first row corresponds to a setting that matches the theoretical assumptions for linear identifiability; the others show distinct violations. Supervised training with unbounded space achieves scores of R 2 = (99.98 ? 0.01)% and MCC = (99.99 ? 0.01)%. The last row refers to using the SimCLR <ref type="bibr" target="#b6">(Chen et al., 2020a)</ref> augmentations to generate positive pairs. The last row refers to using the image augmentations suggested by <ref type="bibr" target="#b6">Chen et al. (2020a)</ref> to generate positive image pairs; for details see Sec. A.3. In contrast to <ref type="table">Table 4</ref>, the scores here are reported on the same data the models were trained on.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Model </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3. Experimental details</head><p>For the experiments presented in Sec. 4.1 we train our feature encoder for 300 000 iterations with a batch size of 6144 utilizing Adam <ref type="bibr" target="#b28">(Kingma &amp; Ba, 2015)</ref> with a learning rate of 10 ?4 . Like <ref type="bibr" target="#b18">Hyv?rinen &amp; Morioka (2016;</ref>, for the mixing network, we i) use 0.2 for the angle of the negative slope 5 , ii) use L 2 normalized weight matrices with minimum condition number of 25 000 uniformly distributed samples. For the encoder, we i) use the default (0.01) negative slope ii) use 6 hidden layers with dimensionality [N ?10, N ?50, N ?50, N ?50, N ?50, N ?10] and iii) initialize the normalization magnitude as 1. We sample 4096 latents from the marginal for evaluation. For MCC <ref type="bibr" target="#b18">(Hyv?rinen &amp; Morioka, 2016;</ref> we use the Pearson correlation coefficient 6 ; we found there to be no difference with Spearman 7 .</p><p>For the experiments presented in Sec. 4.2.1, we use the same architecture as the encoder in <ref type="bibr">(Klindt et al., 2021)</ref>. As in <ref type="bibr">(Klindt et al., 2021)</ref>, we train for 300 000 iterations with a batch size of 64 utilizing Adam <ref type="bibr" target="#b28">(Kingma &amp; Ba, 2015)</ref> with a learning rate of 10 ?4 . For evaluation, as in <ref type="bibr">(Klindt et al., 2021)</ref>, we use 10 000 samples and the Spearman correlation coefficient.</p><p>For the experiments presented in Sec. 4.2.2, we train the feature encoder for 200 000 iterations using Adam with a learning rate of 10 ?4 . For the encoder we use a ResNet18 <ref type="bibr">(He et al., 2016)</ref>   <ref type="bibr" target="#b6">Chen et al. (2020a)</ref> to sample positive pairs. To be precise, we used a random crop and resize operation followed by a color distortion augmentation. The random crops had a uniformly distributed size (between 8% and 100% of the original image area) and a random aspect ration (between 3/4 and 4/3); subsequently, they were resized to the original image dimension (224 ? 224) again. The color distortion operation itself combined color jittering (i.e., random changes of the brightness, contrast, saturation and hue) with color dropping (i.e., random grayscale conversations). We used the same parameters for these augmentations as recommended by <ref type="bibr" target="#b6">Chen et al. (2020a)</ref>.</p><p>The experiments in Sec. 4.1 took on the order of 5-10 hours on a GeForce RTX 2080 Ti GPU, the experiments on KITTI Masks took 1.5 hours on a GeForce RTX 2080 Ti GPU and those on 3DIdent took 28 hours on four GeForce RTX 2080 Ti GPUs. The creation of the 3DIdent dataset additionally required approximately 150 hours of compute time on a GeForce RTX 2080 Ti.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4. Details on 3DIdent</head><p>We build on the rendering pipeline of <ref type="bibr" target="#b24">Johnson et al. (2017b)</ref> and use the Blender engine (Blender Online Community, 2021), as of version 2.91.0, for image rendering. The scenes depicted in the dataset show a rotated and translated object onto which a spotlight is directed. The spotlight is located on a half-circle above the scene and shines down. The scenes can be described by 10 parameters: the position of the object along the X-, Y-and Z-axis, the rotation of the object described by Euler angles (3), the position of the spotlight described by a polar angle, and the hue of the object, the ground and the spotlight. The value range is [?3, 3] for all position parameters, and is [??/2, ?/2] for the remaining parameters. The parameters are sampled from a 10-dimensional unit hyperrectangle, then rescaled to their corresponding value range. This ensures that the variance of the latent factors is the same for all latent dimensions.</p><p>To ensure that the generative process is injective, we take two measures: First, we use a non-rotationally symmetric object <ref type="bibr">(Utah tea pot, Newell, 1975)</ref>, thus the rotation information is unambiguous. Second, we use different levels of color saturation for the object, the spotlight and the ground (1.0, 0.8 and 0.6, respectively), thus the object is always distinguishable from the ground.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4.1. COMPARISON TO EXISTING DATASETS</head><p>The proposed dataset contains high-resolution renderings of an object in a 3D scene. It features some aspects of natural scenes, e.g. complex 3D objects, different lighting conditions and continuous variables. Existing benchmarks <ref type="bibr">(Klindt et al., 2021;</ref><ref type="bibr">Burgess &amp; Kim, 2018;</ref><ref type="bibr" target="#b12">Gondal et al., 2019;</ref><ref type="bibr">Dittadi et al., 2021)</ref> for disentanglement in 3D scenes differ in important aspects to 3DIdent. KITTI Masks <ref type="bibr">(Klindt et al., 2021)</ref> only enables evaluating identification of the two-dimensional position and scale of the object instance. In addition, the observed segmentation masks are significantly lower resolution than examples in our dataset. 3D Shapes <ref type="bibr">(Burgess &amp; Kim, 2018)</ref> and MPI3D <ref type="bibr" target="#b12">(Gondal et al., 2019)</ref> are rendered at the same resolution (64 ? 64) as KITTI Masks. Whereas the dataset contributed by <ref type="bibr">(Dittadi et al., 2021)</ref> is rendered at 2? that resolution (128 ? 128), our dataset is rendered at 3.5? that resolution (224 ? 224), the resolution at which natural image classification is typically evaluated <ref type="bibr" target="#b9">(Deng et al., 2009)</ref>. With that being said, we do note that KITTI Masks is unique in containing frames of natural video, and we thus consider it complementary to 3DIdent. <ref type="bibr">Burgess &amp; Kim (2018)</ref>, <ref type="bibr">Dittadi et al. (2021)</ref>, and <ref type="bibr" target="#b12">Gondal et al. (2019)</ref> contribute datasets which contain variable object rotations around one, one, and two rotation axes, respectively, while 3DIdent contains variable object rotation around all three rotation axes as well as variable lighting conditions. Furthermore, each of these datasets were generated by sampling latent factors from an equidistant grid, thus only covering a limited number values along each axis of variation, effectively resulting in a highly coarse discretization of naturally continuous variables. As 3DIdent instead samples the latent factors uniformly in the latent space, this better reflects the continuous nature of the latent dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5. Effects of the Uniformity Loss</head><p>In previous work, Wang &amp; Isola (2020) showed that a part of the contrastive (InfoNCE) loss -the uniformity losseffectively ensures that the encoded features are uniformly distributed over a hypersphere. We now show that this part is crucial to ensure that the mapping is bijective. More precisely, we demonstrate that if the distribution of the encoded/reconstructed latents h(z) has the same support as the distribution of z, and both distributions are regular, i.e., their densities are non-zero and finite, then the transformation h is bijective.</p><p>First, we focus on the more general case of a map between manifolds:</p><p>Proposition 5. Let M, N be simply connected and oriented C 1 manifolds without boundaries and h : M ? N be a differentiable map. Further, let the random variable z ? M be distributed according to z ? p(z) for a regular density function p, i.e., 0 &lt; p &lt; ?. If the pushforward p #h (z) of p through h is also a regular density, i.e., 0 &lt; p #h &lt; ?, then h is a bijection. Proof. We begin by showing by contradiction that the Jacobian determinant of h does not vanish, i.e., | det J h | &gt; 0:</p><p>Suppose that the Jacobian determinant | det J h | vanishes for some z ? M. Then the inverse of the Jacobian determinant goes to infinity at this point and so does the density of h(z) according to the well-known transformation of probability densities. By assumption, both p and p #h must be regular density functions and, thus, be finite. This contradicts the initial assumption and so the Jacobian determinant | det J h | cannot vanish.</p><p>Next, we show that the mapping h is proper. Note that a map is called proper if pre-images of compact sets are compact <ref type="bibr">(Ruzhansky &amp; Sugimoto, 2015)</ref>. Firstly, a continuous mapping between M and N is also closed, i.e., pre-images of closed subsets are also closed <ref type="bibr" target="#b31">(Lee, 2013)</ref>. In addition, it is well-known that continuous functions on compact sets are bounded. Lastly, according to the Heine-Borel theorem, compact subsets of R D are closed and bounded. Taken together, this shows that h is proper.</p><p>Finally, according to Theorem 2.1 in (Ruzhansky &amp; Sugimoto, 2015) a proper h with non-vanishing Jacobian determinant is bijective, concluding the proof.</p><p>This theorem directly applies to the case of hyperspheres, which are simply connected and oriented manifolds without boundary. This yields:</p><p>Corollary 1. Let Z be a hypersphere and h : Z ? Z be a differentiable map. Further, let the marginal distribution p(z) of the variable z ? Z be a regular density function, i.e., 0 &lt; p &lt; ?. If the pushforward p #h of p through h is also a regular density, i.e., 0 &lt; p #h &lt; ?, then h is a bijection.</p><p>Therefore, we can conclude that a loss term ensuring that the encoded features are distributed according to a regular density function, such as the uniformity term, makes the map h bijective and prevents an information loss. Note that this does not assume that the marginal distribution of the ground-truth latents p(z) is uniform but only that it is regular and non-vanishing.</p><p>Note that while the proposition shows that the uniformity loss is sufficient to ensure bijectivity, we can construct counterexamples if its assumptions (like differentiability) are violated even in just a single point. For instance, the requirement of h being fully differentiable is most likely violated in large unregularized neural networks with ReLU nonlinearities. Here, one might need the full contrastive loss to ensure bijectivity of h.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ArXiv Changelog</head><p>? Current Version: Thanks to feedback from readers, we fixed a few inconsistencies in our notation. We also added a considerably simplified proof for Proposition 2.</p><p>? June 21, 2021: We studied violations of the uniformity assumption in greater details, and added <ref type="figure" target="#fig_0">Figure 2</ref>. We thank the anonymous reviewers at ICML for their suggestions. This is also the version available in the proceedings of ICML 2021.</p><p>? May 25, 2021: Extensions of the theory: We added additional propositions for the effects of the uniformity loss.</p><p>? February 17, 2021: First pre-print.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Varying degrees of violation of the uniformity assumption for the marginal distribution. The figure shows the R 2 score measuring identifiability up to linear transformations (black) as well as the difference between the used marginal and assumed uniform distribution in terms of probability mass (blue) as a function of the marginal's concentration. The black dotted line indicates the concentration of the used conditional distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>3DIdent. Influence of the latent factors z on the renderings x. Each column corresponds to a traversal in one of the ten latent dimensions while the other dimensions are kept fixed.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Model</head><label></label><figDesc>Let f : X ? S N ?1 r , where S N ?1 r denotes a hypersphere with radius r. The parameters of this model are optimized using contrastive learning. We associate a conditional distribution q h (z|z) with our model f through h = f ? g and q h (z|z) = C ?1 q (z)e h(z) h(z)/? with C q (z) : = e h(z) h(z)/? dz,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>For fixed ? &gt; 0, as the number of negative samples M ? ?, the (normalized) contrastive loss converges to lim M ?? L contr (f ; ?, M ) ? log M = L align (f ; ? ) + L uni (f ; ? ),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>e ??(h(z),h(z))/? = L ?-align (f ; ? ) + L ?-uni (f ; ? ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Joint supervision 1 University of T?bingen, T?bingen, Germany 2 IMPRS for Intelligent Systems, T?bingen, Germany 3 EPFL, Geneva, Switzerland. Correspondence to: Roland S. Zimmermann &lt;roland.zimmermann@unituebingen.de&gt;. Proceedings of the 38 th International Conference on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s).</figDesc><table><row><cell>; Bachman</cell></row></table><note>* Equal contribution.?1 Online version and code: brendel-group.github.io/cl-ica/ et al.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Identifiability up to generalized permutations, averaged over 5 runs. Note that while Theorem 6 requires the model latent space to be a convex body and p(?|?) = q h (?|?), we find that empirically either is sufficient. The results are grouped in four blocks corresponding to different types and degrees of violation of assumptions of our theory showing identifiability up to permutations: (1) no violation, violation of the assumptions on either the (2) space or (3) the conditional distribution, or (4) both.</figDesc><table><row><cell>Identity</cell><cell>Supervised</cell><cell>Unsupervised</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>KITTI Masks. Mean ? standard deviation over 10 random seeds. ?t indicates the average temporal distance of frames used.</figDesc><table><row><cell></cell><cell>Model</cell><cell cols="2">Model Space MCC [%]</cell></row><row><cell></cell><cell cols="2">SlowVAE Unbounded</cell><cell>66.1 ? 4.5</cell></row><row><cell></cell><cell>Laplace</cell><cell>Unbounded</cell><cell>77.1 ? 1.0</cell></row><row><cell>?t = 0.05s</cell><cell>Laplace</cell><cell>Box</cell><cell>74.1 ? 4.4</cell></row><row><cell></cell><cell>Normal</cell><cell>Unbounded</cell><cell>58.3 ? 5.4</cell></row><row><cell></cell><cell>Normal</cell><cell>Box</cell><cell>59.9 ? 5.5</cell></row><row><cell></cell><cell cols="2">SlowVAE Unbounded</cell><cell>79.6 ? 5.8</cell></row><row><cell></cell><cell>Laplace</cell><cell>Unbounded</cell><cell>79.4 ? 1.9</cell></row><row><cell>?t = 0.15s</cell><cell>Laplace</cell><cell>Box</cell><cell>80.9 ? 3.8</cell></row><row><cell></cell><cell>Normal</cell><cell>Unbounded</cell><cell>60.2 ? 8.7</cell></row><row><cell></cell><cell>Normal</cell><cell>Box</cell><cell>68.4 ? 6.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>. In Chaudhuri, K. and Salakhutdinov, R. (eds.), Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pp. 4114-4124. PMLR, 2019. Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pp. 5628-5637. PMLR, 2019.Schneider, S.,Baevski, A., Collobert, R., and Auli, M.   </figDesc><table><row><cell></cell><cell>wav2vec: Unsupervised pre-training for speech recog-</cell></row><row><cell>Locatello, F., Poole, B., R?tsch, G., Sch?lkopf, B., Bachem,</cell><cell>nition. CoRR, abs/1904.05862, 2019.</cell></row><row><cell>O., and Tschannen, M. Weakly-supervised disentangle-ment without compromises. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18 July 2020, Virtual Event, volume 119 of Pro-ceedings of Machine Learning Research, pp. 6348-6359.</cell><cell>Sprekeler, H., Zito, T., and Wiskott, L. An extension of slow feature analysis for nonlinear blind source separation. The Journal of Machine Learning Research, 15(1):921-947, 2014.</cell></row><row><cell>PMLR, 2020.</cell><cell>Subbotin, M. F. On the law of frequency of error. Mat. Sb.,</cell></row><row><cell>Logeswaran, L. and Lee, H. An efficient framework for</cell><cell>31(2):296-301, 1923.</cell></row><row><cell>learning sentence representations. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 -May 3, 2018, Confer-</cell><cell>, StS and WB jointly derived the theory. RSZ and YS implemented and executed the experiments. The 3DIdent dataset was created by RSZ Tian, Y., Krishnan, D., and Isola, P. Contrastive multiview coding. arXiv preprint arXiv:1906.05849, 2019.</cell></row><row><cell>ence Track Proceedings. OpenReview.net, 2018.</cell><cell>with feedback from StS, YS, WB and MB. RSZ, YS, StS Tian, Y., Sun, C., Poole, B., Krishnan, D., Schmid, C., and</cell></row><row><cell>Mankiewicz, P. Extension of isometries in normed lin-ear spaces. Bulletin de l'Academie polonaise des sci-</cell><cell>and WB contributed to the final version of the manuscript. Isola, P. What makes for good views for contrastive learning, 2020.</cell></row><row><cell>ences: Serie des sciences mathematiques, astronomiques</cell><cell></cell></row><row><cell>et physiques, 20(5):367-+, 1972.</cell><cell></cell></row><row><cell>Oord, A. v. d., Li, Y., and Vinyals, O. Representation learn-ing with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018.</cell><cell>Wang, T. and Isola, P. Understanding contrastive represen-tation learning through alignment and uniformity on the hypersphere. In Proceedings of the 37th International Conference on Machine Learning, ICML 2020, 13-18</cell></row><row><cell>Ravanelli, M., Zhong, J., Pascual, S., Swietojanski, P.,</cell><cell>July 2020, Virtual Event, volume 119 of Proceedings</cell></row><row><cell>Monteiro, J., Trmal, J., and Bengio, Y. Multi-task</cell><cell>of Machine Learning Research, pp. 9929-9939. PMLR,</cell></row><row><cell>self-supervised learning for robust speech recognition.</cell><cell>2020.</cell></row><row><cell>In 2020 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2020, Barcelona, Spain, May 4-8, 2020, pp. 6989-6993. IEEE, 2020. doi: 10.1109/ICASSP40776.2020.9053569.</cell><cell>Wu, M., Zhuang, C., Yamins, D., and Goodman, N. On the importance of views in unsupervised representation learning. 2020.</cell></row><row><cell>Robinson, J., Chuang, C.-Y., Sra, S., and Jegelka, S. Con-trastive learning with hard negative samples. arXiv preprint arXiv:2010.04592, 2020. Roeder, G., Metz, L., and Kingma, D. P. On linear iden-arXiv:2007.00810, 2020. tifiability of learned representations. arXiv preprint</cell><cell>He, K., Zhang, X., Ren, S., and Sun, J. Deep residual Wu, Z., Xiong, Y., Yu, S. X., and Lin, D. Unsupervised feature learning via non-parametric instance discrimina-tion. In 2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt Lake City, UT, learning for image recognition. In 2016 IEEE Conference USA, June 18-22, 2018, pp. 3733-3742. IEEE Computer on Computer Vision and Pattern Recognition, CVPR 2016, IEEE Computer Society, 2016. doi: 10.1109/CVPR.2016. Las Vegas, NV, USA, June 27-30, 2016, pp. 770-778. Society, 2018. doi: 10.1109/CVPR.2018.00393.</cell></row><row><cell>Ruzhansky, M. and Sugimoto, M. On global inversion of</cell><cell>90.</cell></row><row><cell>homogeneous maps. Bulletin of Mathematical Sciences, 5(1):13-18, 2015.</cell><cell>He, K., Fan, H., Wu, Y., Xie, S., and Girshick, R. B. Mo-mentum contrast for unsupervised visual representation</cell></row></table><note>learning. In 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, Seattle, WA, USA, June 13-19, 2020, pp. 9726-9735. IEEE, 2020a.doi: 10.1109/CVPR42600.2020.00975.representationsNewell, M. E. The Utilization of Procedure Models in Digital Image Synthesis. PhD thesis, The University of Utah, 1975. AAI7529894.Saunshi, N., Plevrakis, O., Arora, S., Khodak, M., and Khandeparkar, H. A theoretical analysis of contrastive unsupervised representation learning. In Chaudhuri, K. and Salakhutdinov, R. (eds.),Tschannen, M., Djolonga, J., Rubenstein, P. K., Gelly, S., and Lucic, M. On mutual information maximization for representation learning. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net, 2020.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>architecture followed by a single hidden layer with dimensionality N ? 10 and LeakyReLU activation function using the default (0.01) negative slope. The scores on the training set are evaluated on 10% of the whole training set, 25 000 random samples. The test set consists of 25 000 samples not included in the training set. For the 5 See e.g. https://pytorch.org/docs/stable/ generated/torch.nn.LeakyReLU.html 6 See e.g. https://numpy.org/doc/stable/ reference/generated/numpy.corrcoef.html 7 See e.g. https://docs.scipy.org/doc/scipy/ reference/generated/scipy.stats.spearmanr. html last row of Tab. 4 and Tab. 5 we used the best-working combination of image augmentations found by</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Note that in practice this can be implemented as a learnable rescaling operation as the last operation of the network f .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Note that in practice this can be implemented as a learnable rescaling operation of the network f .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Muhammad Waleed Gondal </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">; H M</forename><surname>Buchwalter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Buc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>B., and Garnett, R.</editor>
		<meeting><address><addrLine>NeurIPS; BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="15509" to="15519" />
		</imprint>
	</monogr>
	<note>Wallach,</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">vq-wav2vec: Selfsupervised learning of discrete speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Auli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">wav2vec 2.0: A framework for self-supervised learning of speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<editor>H.</editor>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Blender -a 3D modelling and rendering package. Blender Foundation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Blender Online Community</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2021</biblScope>
			<pubPlace>Blender Institute, Amsterdam</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>3d shapes dataset</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Local isometries of compact metric spaces. Proceedings of the</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ca?ka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>American Mathematical Society</publisher>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="643" to="647" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
	<note>Virtual Event</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<editor>Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.</editor>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Debiased contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Balcan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<editor>Lin, H.</editor>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2009.5206848</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Miami, Florida, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009-06" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">On the transfer of disentangled representations in realistic settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dittadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tr?uble</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>W?thrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the KITTI vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2012.6248074</idno>
	</analytic>
	<monogr>
		<title level="m">2012 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Providence, RI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3354" to="3361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the transfer of inductive bias from simulation to the real world: a new disentanglement dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Gondal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wuthrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Miladinovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Breidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Volchkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Akpo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bachem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<editor>Wallach, H. M., Larochelle, H., Beygelzimer, A., d&apos;Alch?-Buc, F., Fox, E. B., and Garnett, R.</editor>
		<meeting><address><addrLine>NeurIPS; Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="15714" to="15725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation of unnormalized statistical models, with applications to natural image statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">U</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="307" to="361" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Kernel-based nonlinear blind source separation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ziehe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1089" to="1124" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR42600.2020.00975</idno>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="9726" to="9735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Data-efficient image recognition with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">J</forename><surname>H?naff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="4182" to="4192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised feature extraction by time-contrastive learning and nonlinear ICA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Morioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems</title>
		<editor>Lee, D. D., Sugiyama, M., von Luxburg, U., Guyon, I., and Garnett, R.</editor>
		<meeting><address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-12-05" />
			<biblScope unit="page" from="3765" to="3773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Nonlinear ICA of temporally dependent stationary sources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Morioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th International Conference on Artificial Intelligence and Statistics</title>
		<editor>Singh, A. and Zhu, X. J.</editor>
		<meeting>the 20th International Conference on Artificial Intelligence and Statistics<address><addrLine>Fort Lauderdale, FL, USA</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017-04-22" />
			<biblScope unit="page" from="460" to="469" />
		</imprint>
	</monogr>
	<note>Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Nonlinear independent component analysis: Existence and uniqueness results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pajunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="429" to="439" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Independent Component Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Wiley Interscience</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nonlinear ICA using auxiliary variables and generalized contrastive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<editor>Chaudhuri, K. and Sugiyama, M.</editor>
		<meeting><address><addrLine>Naha, Okinawa, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019-04-18" />
			<biblScope unit="volume">2019</biblScope>
			<biblScope unit="page" from="859" to="868" />
		</imprint>
	</monogr>
	<note>AISTATS</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Billion-scale similarity search with gpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.08734</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2017.215</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2017-07-21" />
			<biblScope unit="page" from="1988" to="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Nonlinear mixtures. Handbook of Blind Source Separation, Independent Component Analysis and Applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jutten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Babaie-Zadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Karhunen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="549" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Variational autoencoders and nonlinear ICA: A unifying framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 23rd International Conference on Artificial Intelligence and Statistics</title>
		<editor>Chiappa, S. and Calandra, R.</editor>
		<meeting><address><addrLine>Online [Palermo, Sicily, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020-08-28" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="2207" to="2217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Ice-beem: Identifiable conditional energy-based deep models based on nonlinear ICA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Khemakhem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<editor>Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.</editor>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<editor>Bengio, Y. and LeCun, Y.</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Towards nonlinear disentanglement in natural data with temporal sparse coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Klindt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ustyuzhaninov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bethge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paiton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">On the isometries of certain functionspaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lamperti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific J. Math</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="459" to="466" />
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Smooth manifolds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Introduction to Smooth Manifolds</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="606" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Isometries of p -norm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>So</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Mathematical Monthly</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="452" to="453" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Self-organization in a perceptual network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Linsker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="105" to="117" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Locatello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>R?tsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bachem</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Challenging common assumptions in the unsupervised learning of disentangled</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
