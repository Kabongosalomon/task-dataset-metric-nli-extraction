<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Disentangling Label Distribution for Long-tailed Visual Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngkyu</forename><surname>Hong</surname></persName>
							<email>youngkyu.hong@hpcnt.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungju</forename><surname>Han</surname></persName>
							<email>seungju.han@hpcnt.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwanghee</forename><surname>Choi</surname></persName>
							<email>kwanghee.choi@hpcnt.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seokjun</forename><surname>Seo</surname></persName>
							<email>seokjun.seo@hpcnt.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beomsu</forename><surname>Kim</surname></persName>
							<email>beomsu.kim@hpcnt.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buru</forename><surname>Chang</surname></persName>
							<email>buru.chang@hpcnt.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hyperconnect</surname></persName>
						</author>
						<title level="a" type="main">Disentangling Label Distribution for Long-tailed Visual Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The current evaluation protocol of long-tailed visual recognition trains the classification model on the longtailed source label distribution and evaluates its performance on the uniform target label distribution. Such protocol has questionable practicality since the target may also be long-tailed. Therefore, we formulate long-tailed visual recognition as a label shift problem where the target and source label distributions are different. One of the significant hurdles in dealing with the label shift problem is the entanglement between the source label distribution and the model prediction. In this paper, we focus on disentangling the source label distribution from the model prediction. We first introduce a simple but overlooked baseline method that matches the target label distribution by post-processing the model prediction trained by the cross-entropy loss and the Softmax function. Although this method surpasses state-of-the-art methods on benchmark datasets, it can be further improved by directly disentangling the source label distribution from the model prediction in the training phase. Thus, we propose a novel method, LAbel distribution DisEntangling (LADE) loss based on the optimal bound of Donsker-Varadhan representation. LADE achieves state-of-the-art performance on benchmark datasets such as CIFAR-100-LT, Places-LT, ImageNet-LT, and iNaturalist 2018. Moreover, LADE outperforms existing methods on various shifted target label distributions, showing the general adaptability of our proposed method.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Based on large-scale datasets such as ImageNet <ref type="bibr" target="#b49">[50]</ref>, COCO <ref type="bibr" target="#b33">[34]</ref>, and Places <ref type="bibr" target="#b63">[64]</ref>, deep neural networks have achieved significant progress in various visual recognition tasks, including classification <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b51">52]</ref>, object detection <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b17">18]</ref>, and segmentation <ref type="bibr" target="#b47">[48]</ref>. In contrast to these relatively balanced datasets, real-world data often exhibit * Equal contribution. Author ordering determined by coin flip. ? Corresponding author. After training with the cross-entropy loss, the model prediction gets entangled with the source label distribution p s (y), which causes a discrepancy with the target label distribution p t (y) during the inference phase. Our proposed LADE disentangles p s (y) from the model prediction so that it can adapt to the arbitrary target probability by injecting p t (y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-entropy</head><p>long-tailed distribution where head (major) classes occupy most of the data, while tail (minor) classes have a handful of samples <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b37">38]</ref>. Unfortunately, the performance of state-of-the-art classification models degrades on datasets following the long-tailed distribution <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b59">60]</ref>.</p><p>To tackle this problem, many long-tailed visual recognition methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b8">9]</ref> have been proposed. These methods compare their effectiveness by (1) training on the long-tailed source label distribution p s (y) and (2) evaluating on the uniform target label distribution p t (y). However, we argue that this evaluation protocol is often impractical as it is natural to assume that p t (y) could be the arbitrary distribution such as uniform distribution <ref type="bibr" target="#b49">[50]</ref> and long-tailed distribution <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b9">10]</ref>.</p><p>From this perspective, we are motivated to explore a new method that adapts the model to the arbitrary p t (y). In this paper, we borrow the concept of the label distribution shift problems <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b55">56]</ref> to the long-tailed visual recognition  <ref type="figure">Figure 2</ref>: The average probability for each class calculated on the balanced test set. The model is ResNet-32 <ref type="bibr" target="#b21">[22]</ref> trained on CIFAR-100-LT <ref type="bibr" target="#b8">[9]</ref>, which has uniform target label distribution p t (y) while the source dataset has longtailed distribution p s (y). (a) depicts the average probability when trained with the cross-entropy loss, which shows average probability correlates with p s (y), resulting in the discrepancy with p t (y). (b) depicts the average probability when trained and inferred with LADE, which shows the ability of LADE on adapting to p t (y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>task.</head><p>However, it is problematic to directly use the model prediction p(y|x; ?) which is fitted to the source probability p s (y|x), as the target probability p t (y|x) is shifted from p s (y) to p t (y) <ref type="figure" target="#fig_0">(Figure 1</ref>). <ref type="figure">Figure 2a</ref> shows the entanglement between the model prediction and p s (y) when the model is trained by the cross-entropy (CE) loss and the Softmax function. To alleviate this problem, we focus on disentangling p s (y) from the model outputs so that the shifted target label distribution p t (y) can be injected to estimate the target probability.</p><p>We shed light on a simple yet strong baseline, called Post-Compensated Softmax (PC Softmax) that postprocesses the model prediction to disentangle p s (y) from p(y|x; ?) and then incorporate p t (y) to the disentangled model output probability. Despite the simplicity of the method, PC Softmax outperforms state-of-the-art methods in long-tailed visual recognition (will be described in Section 4). Although this observation demonstrates the effectiveness of the disentanglement in the inference phase, PC Softmax can be further improved by directly disentangling p s (y) in the training phase.</p><p>Thus, we propose a novel method, LAbel distribution DisEntangling (LADE) loss. LADE utilizes the Donsker-Varadhan (DV) representation <ref type="bibr" target="#b14">[15]</ref> to directly disentangle p s (y) from p(y|x; ?). <ref type="figure">Figure 2b</ref> shows that LADE disentangles p s (y) from p(y|x; ?). We claim that the disentanglement in the training phase shows even better performance on adapting to arbitrary target label distributions.</p><p>We conduct several experiments to compare our proposed method with existing long-tailed visual recognition methods, and show that LADE achieves state-of-the-art performance on benchmark datasets such as CIFAR-100-LT <ref type="bibr" target="#b29">[30]</ref>, Places-LT <ref type="bibr" target="#b37">[38]</ref>, ImageNet-LT <ref type="bibr" target="#b37">[38]</ref>, and iNaturalist 2018 <ref type="bibr" target="#b56">[57]</ref>. Moreover, we demonstrate that the classification model trained with LADE can cope with arbitrary p t (y) by evaluating the performance on datasets with various shifted p t (y). We further show that our proposed LADE can also be effective in terms of confidence calibration. Our contributions in this paper are summarized as follows:</p><p>? We introduce a simple yet strong baseline method, PC Softmax, which outperforms state-of-the-art methods in long-tailed visual recognition benchmark datasets.</p><p>? We propose a novel loss called LADE that directly disentangles the source label distribution in the training phase so that the model effectively adapts to arbitrary target label distributions.</p><p>? We show that LADE achieves state-of-the-art performance in long-tailed visual recognition on various target label distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work 2.1. Long-tailed visual recognition</head><p>Most long-tailed visual recognition methods can be divided into two strategies: modifying the data sampler to balance the class frequency during optimization <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b50">51]</ref>, and modifying the class-wise weights of the classification loss to increase the importance of tail classes in terms of empirical risk minimization <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b6">7]</ref>.</p><p>Both strategies suffer from under-representation of head classes or memorization of tail classes <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b8">9]</ref>. To overcome these problems, <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b62">63]</ref> introduce strategies for preventing deteriorated representation learning caused by rebalancing. <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b37">38]</ref> utilize knowledge from head classes to learn tail classes. <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b58">59]</ref> augment tail class samples while preserving the diversity of dataset. <ref type="bibr" target="#b23">[24]</ref> applies domain adaptation on learning tail class representation.</p><p>Recent approaches introduce advanced re-balancing methods for better accommodation of tail class samples. <ref type="bibr" target="#b12">[13]</ref> calculates the effective number of samples per each class to re-balance the loss. <ref type="bibr" target="#b8">[9]</ref> enforces a greater margin from the decision boundary for tail classes. <ref type="bibr" target="#b54">[55]</ref> disentangles feature learning from the confounding effect in momentum by backdoor adjustment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Label distribution shift</head><p>In this paper, we cope with long-tailed visual recognition as one of the label distribution shift problems. We summarize recently proposed studies in label distribution shift problems that assume p s (y) = p t (y) and p s (x|y) = p t (x|y). <ref type="bibr" target="#b35">[36]</ref> estimates the degree of label shift using a black box predictor. <ref type="bibr" target="#b15">[16]</ref> extends the work of <ref type="bibr" target="#b35">[36]</ref> with the expectation-maximization algorithm. <ref type="bibr" target="#b1">[2]</ref> introduces a domain adaptation to handle label distribution shifts by estimating importance weights. <ref type="bibr" target="#b45">[46]</ref> adjusts the logits before applying the Softmax function by the frequency of each class considering the uniform target label distribution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Donsker-Varadhan representation</head><p>Donsker-Varadhan (DV) representation <ref type="bibr" target="#b14">[15]</ref> is the dual variational representation of Kullback-Leibler (KL) divergence <ref type="bibr" target="#b31">[32]</ref>. It is proven that the optimal bound of the DV representation is the log-likelihood ratio of two distributions of the KL divergence <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>. The usefulness of the DV representation has been broadly shown in the area including mutual information estimation <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b44">45]</ref> or generative models <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b43">44]</ref>. However, <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b40">41]</ref> have pointed out the instability of directly using the DV representation. To avoid the issue, we use the regularized DV representation from <ref type="bibr" target="#b11">[12]</ref> to approximate network logits as the log-likelihood ratio log(p(x|y)/p(x)). To the best of our knowledge, this is the first attempt to utilize the optimal bound inside the DV representation in the long-tailed visual recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><p>We start by revisiting the most common loss for training the Softmax regression (also known as the multinomial logistic regression) model <ref type="bibr" target="#b4">[5]</ref>, namely the CE loss:</p><formula xml:id="formula_0">p(y|x; ?) = e f ? (x)[y] c e f ? (x)[c]</formula><p>(1)</p><formula xml:id="formula_1">L CE (f ? (x), y) = ? log(p(y|x; ?)),<label>(2)</label></formula><p>where x is the input image and y is the target label, p s (x, y) and p t (x, y) are the source (train) and target (test) data distributions, and f ? (x)[y] is the logit of class y of the model. The Softmax regression model estimates p s (y|x) and works well when the source and the target label distribution are the same, i.e. p s (y) = p t (y). However, we focus on the label shift problem <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b35">36]</ref> where the target label distribution is shifted from the source label distribution, i.e. p s (x|y) = p t (x|y) but p s (y) = p t (y). Since the model prediction estimates p s (y|x), it cannot be used to predict the shifted distribution. This is due to the strong coupling between p s (y|x) and p s (y), as justified from the Bayes' rule: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">PC Softmax: Post-Compensated Softmax</head><p>The straightforward way to handle the label distribution shift is by replacing p s (y) with p t (y). We introduce a postcompensation (PC) strategy that modifies the logit in the inference phase: </p><formula xml:id="formula_2">f P C ? (x)[y] = f ? (x)[y] ? log p s (y) + log p t (y) (4)</formula><p>where p s (y) is the distribution which the model logits are entangled with, and p t (y) is the target distribution that the model tries to incorporate with.</p><p>Note that the concept of the PC strategy is not entirely new since <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b25">26]</ref> previously covered as a different form of multiplying p t (y)/p s (y) to the output probability. However, our PC strategy does not violate the categorical probability assumption, i.e. c p t (y = c|x) = 1.</p><p>We apply the PC strategy to the Softmax regression model, which we call Post-Compensated Softmax (PC Softmax). For the Softmax regression model, the PC strategy is the proper adjustment for estimating target data distribution.</p><p>Theorem 1 (Post-Compensated Softmax). Let p s (x, y) and p t (x, y) be the source and target data distributions, respectively. If f ? (x)[y] is the logit of class y from the Softmax regression model estimating p s (y|x), then the estimation of p t (y|x) is formulated as:</p><formula xml:id="formula_3">p t (y|x; ?) = pt(y) ps(y) ? e f ? (x)[y] c pt(c) ps(c) ? e f ? (x)[c] (5) = e (f ? (x)[y]?log ps(y)+log pt(y)) c e (f ? (x)[c]?log ps(c)+log pt(c)) (6) = e f P C ? (x)[y] c e f P C ? (x)[c] .<label>(7)</label></formula><p>Proof. See the Supplementary Material.</p><p>We emphasize that PC Softmax becomes a strong baseline that surpasses previous state-of-the-art long-tailed visual recognition methods. However, recent literature does not consider this as a baseline.</p><p>PC Softmax can also be viewed as an extension of Balanced Softmax <ref type="bibr" target="#b45">[46]</ref>, which modifies the Softmax function to accommodate the uniform target label distribution in the training phase. In contrast, PC Softmax modifies the model logits in the inference phase to match the arbitrary target label distribution p t (y).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">LADER: LAbel distribution DisEntangling Regularizer</head><p>Performance gain from the PC strategy shows the efficacy of disentangling the source label distribution. However, the PC strategy does not involve the disentanglement in the training phase, which we claim as the ingredient for better adaptability to arbitrary target label distributions. To achieve this, we design a new modeling objective that works as a substitute for p s (y|x). We derive the new objective in two steps: (1) detaching p s (y) from p s (y|x), which results in p s (x|y)/p s (x), and (2) replacing p s (y) in p s (x) with the uniform prior p u (y), i.e. p u (y = c) = 1/C, where C is the total number of classes.</p><p>Finally, the modeling objective for the model logits is:</p><formula xml:id="formula_4">f ? (x)[y] = log p u (x|y) p u (x) .<label>(8)</label></formula><p>We utilize the optimal form of the regularized Donsker-Varadhan (DV) representation <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b11">12]</ref> to model the log-likelihood ratio above explicitly.</p><p>Theorem 2 (Optimal form of the regularized DV representation). Let P, Q be arbitrary distributions with supp(P) ? supp(Q). Suppose for every function T : ? ? R on some domain ?, the function T that minimizes the regularized DV representation is the log-likelihood ratio of P and Q:</p><formula xml:id="formula_5">log dP dQ = arg max T :??R (E P [T ] ? log(E Q [e T ]) ??(log(E Q [e T ])) 2 ),<label>(9)</label></formula><p>for any ? ? R + when the expectations are finite.</p><p>Proof. See Subsection 7.2 from <ref type="bibr" target="#b11">[12]</ref>.</p><p>By plugging P = p u (x|y) and Q = p u (x) into Equation 9 and choosing the function family of T : ? ? R to be parametrized by the logits of the deep neural network, the optimal f ? (x)[y] approaches to the target objective in Equation <ref type="bibr" target="#b7">8</ref>:</p><formula xml:id="formula_6">log p u (x|y) p u (x) ? arg max f ? (E x?pu(x|y) [f ? (x)[y]] ? log E x?pu(x) [e f ? (x)[y]) ] ??(log(E x?pu(x) [e f ? (x)[y]) ])) 2 ).<label>(10)</label></formula><p>Since the exact estimations of the expectation with respect to p u (x|y) and p u (x) are intractable, we use the Monte Carlo approximation <ref type="bibr" target="#b48">[49]</ref> using a single batch:</p><formula xml:id="formula_7">E x?pu(x|c) [f ? (x)[c]] ? 1 N c N i=1 1 yi=c ? f ? (x i )[c] (11) E x?pu(x) [e f ? (x)[c] ] = E (x,y)?ps(x,y) [ p u (y) p s (y) e f ? (x)[c] ] (12) ? 1 N N i=1 p u (y i ) p s (y i ) ? e f ? (xi)[c] ,<label>(13)</label></formula><p>where x i and y i are i-th sample and label, respectively, N is the total number of samples, and N c is the number of samples for class c. In Equation 12, importance sampling <ref type="bibr" target="#b26">[27]</ref> is used to approximate the expectation with respect to p u (x) using samples from p s (x):</p><formula xml:id="formula_8">p u (x) p s (x) = c p u (x|c)p u (c) c p s (x|c)p s (c) = p u (y) p s (y) ,<label>(14)</label></formula><p>for the sample label pair (x, y) ? p s (x, y), where we assume p s (x|c) = 0 for c = y. Finally, we derive a novel loss that regularizes the logits to approach Equation 8 by applying <ref type="bibr">Equation 11,</ref><ref type="bibr" target="#b11">12</ref>, and 13 to Equation 10: </p><formula xml:id="formula_9">L LADERc = ? 1 N c N i=1 1 yi=c ? f ? (x i )[c] + log( 1 N N i=1 p u (y i ) p s (y i ) ? e f ? (xi)[c] ) + ?(log( 1 N N i=1 p u (y i ) p s (y i ) ? e f ? (xi)[c] )) 2 (15) L LADER = c?S ? c ? L LADERc ,<label>(16)</label></formula><p>with nonnegative hyperparameters ?, ? 1 , . . . , ? C , where C is total number of classes, N c is the number of samples of class c and S is the set of classes existing inside the batch.</p><p>Empirically, we find out that regularizing the head classes more strongly than the tail classes is more effective. Thus, we apply ? c = p s (y = c) as the weight for the regularizer of class c, L LADERc in Equation 16.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Deriving the conditional probability from disentangled logits</head><p>LADER regularizes the logits to be log(p u (x|y)/p u (x)) to ensure the logits are explicitly disentangled from the source label distribution p s (y). To estimate the conditional probability p t (y|x) of the arbitrary data distribution p t (x, y) from the regularized logits, we use the modified Softmax function derived from the Bayes' rule with the assumption of p t (x|y) = p u (x|y):</p><formula xml:id="formula_10">p t (y|x; ?) = p t (y)p t (x|y; ?) c p t (c)p t (x|c; ?) = p t (y)p u (x|y; ?) c p t (c)p u (x|c; ?) = p t (y) ? e f ? (x)[y] c p t (c) ? e f ? (x)[c] .<label>(17)</label></formula><p>Similar to this, we can estimate p s (y|x) by swapping p t (y) of Equation <ref type="bibr" target="#b16">17</ref> with p s (y), so that p s (y|x; ?) can be optimized by the CE loss. Thus, we can combine LADER with the CE loss as our final loss for training: </p><formula xml:id="formula_11">L LADE?CE (f ? (x), y) = ? log(p s (y|x; ?)) (18) = ? log( p s (y) ? e f ? (x)[y] c p s (c) ? e f ? (x)[c] )<label>(19)</label></formula><p>L</p><formula xml:id="formula_12">LADE (f ? (x), y) = L LADE?CE (f ? (x), y) +? ? L LADER (f ? (x), y),<label>(20)</label></formula><p>where ? is a nonnegative hyperparameter, which determines the regularization strength of L LADER .</p><p>Note that Balanced Softmax <ref type="bibr" target="#b45">[46]</ref> is equivalent to LADE with ? = 0, but LADE is derived from an entirely different perspective of directly regularizing the logits. Furthermore, Balanced Softmax only covers the uniform target label distribution, while our method is designed to cover arbitrary target label distributions without re-training.</p><p>In the inference phase, we inject the target label distribution as in Equation 17.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We compare PC Softmax and LADE with current stateof-the-art methods. First, we evaluate the performance on the uniform target label distribution, which is the prevalent evaluation scheme of long-tailed visual recognition. Then, we assess the performance on variously shifted target label distributions. Finally, we conduct further analysis to show that LADE successfully disentangles the source label distribution and improves confidence calibration. We provide source codes 1 of LADE for the reproduction of the experiments conducted in this paper. Details of the hyperparameter tuning process and the results of the ablation test are reported in the Supplementary Material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental setup</head><p>Long-tailed dataset We follow the common evaluation protocol <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b54">55]</ref> in long-tailed visual recognition, which trains classification models on the long-tailed source label distribution and evaluates their performance on the uniform target label distribution. We use four benchmark datasets with at least 100 classes to simulate the real-world long-tailed data distribution: CIFAR-100-LT <ref type="bibr" target="#b8">[9]</ref>, Places-LT <ref type="bibr" target="#b37">[38]</ref>, ImageNet-LT <ref type="bibr" target="#b37">[38]</ref>, and iNaturalist 2018 <ref type="bibr" target="#b56">[57]</ref>. We define the imbalance ratio as N max /N min , where N is the number of samples in each class. CIFAR-100-LT has three variants with controllable data imbalance ratios 10, 50, and 100. The details of datasets are summarized in <ref type="table" target="#tab_0">Table 1.</ref> 1 https://github.com/hyperconnect/LADE Comparison with other methods. We compare PC Softmax and LADE with three categories of methods:</p><p>? Baseline methods. For our baseline, we use Softmax (Equation 1), Focal loss (Focal) <ref type="bibr" target="#b32">[33]</ref>, OLTR <ref type="bibr" target="#b37">[38]</ref>, CB-Focal <ref type="bibr" target="#b12">[13]</ref>, and LDAM <ref type="bibr" target="#b8">[9]</ref>.</p><p>? Two-stage training. To demonstrate our method's efficiency and effectiveness, we compare our method with two-staged state-of-the-art methods that employ a finetuning strategy. LDAM+DRW <ref type="bibr" target="#b8">[9]</ref> applies a fine-tuning step with loss re-weighting. Decouple <ref type="bibr" target="#b27">[28]</ref> re-balances the classifier during the fine-tuning stage.</p><p>? Other state-of-the-art methods. BBN <ref type="bibr" target="#b62">[63]</ref>, Causal Norm <ref type="bibr" target="#b54">[55]</ref>, and Balanced Softmax <ref type="bibr" target="#b45">[46]</ref> are recently proposed state-of-the-art methods on long-tail visual recognition. BBN uses an extra additional network branch to deal with an imbalanced training set. Causal Norm utilizes backdoor adjustment to remove indirect causal effect caused by imbalanced source label distribution.</p><p>Evaluation Protocol. We report evaluation results using top-1 accuracy. Following <ref type="bibr" target="#b37">[38]</ref>, for ImageNet-LT and Places-LT, we categorize the classes into three groups depending on the number of samples of each class and further report each group's evaluation results. The three groups are defined as follows: Many covering classes with &gt; 100 images, Medium covering classes with ? 20 and ? 100 images, Few covering classes with &lt; 20 images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results on balanced test label distribution</head><p>Evaluation results on CIFAR-100-LT, Places-LT, ImageNet-LT, and iNaturalist 2018 are shown in <ref type="table">Table 2</ref>, 3, 4, and 5, respectively. All the datasets have a uniform target label distribution. PC Softmax shows comparable or better results than the previous state-of-the-art results on benchmark datasets. This result is quite surprising considering the simplicity of PC Softmax. Our proposed method, LADE, achieves even better performance in longtailed visual recognition on all four benchmark datasets, advancing the state-of-the-art even further. <ref type="table">Table 2</ref>: Top-1 accuracy on CIFAR-100-LT with different imbalance ratios. Rows with ? denote results directly borrowed from <ref type="bibr" target="#b54">[55]</ref>. We use the same backbone network with <ref type="bibr" target="#b54">[55]</ref>.   <ref type="table">Table 2</ref> shows the evaluation results on CIFAR-100-LT. As shown in the table, in CIFAR-100-LT, LADE outperforms all the baselines over all the imbalance ratios. PC Softmax also shows better performance than other methods except for Balanced Softmax and our proposed LADE. <ref type="table" target="#tab_2">Table 3</ref> shows the experimental results. LADE achieves a new state-of-the-art of 38.8% top-1 overall accuracy, without using a two-stage training as in Decouple-? -norm <ref type="bibr" target="#b27">[28]</ref>. PC Softmax shows yet another promising result by surpassing the previous state-of-the-art, while Softmax offers poor results. This result is quite impressive since both models are the same, and the only difference occurs in the inference phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-100-LT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Places-LT We further evaluate PC Softmax and LADE on Places-LT, and</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet-LT We conduct experiments on ImageNet-LT</head><p>to demonstrate the effectiveness of LADE in the large-scale dataset. We observe that the model is under-fitting at 90 epochs when using LADE. Previous works <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b62">63]</ref> train model for longer epochs to deal with under-fitting. Thus, we  also report the evaluation results at both 90 and 180 epochs, respectively, and this is different from <ref type="bibr" target="#b54">[55]</ref> where they train the baseline methods during 90 epochs.  with LADE for 200 epochs and report the test accuracy at 200 epochs, following <ref type="bibr" target="#b27">[28]</ref>. <ref type="table" target="#tab_4">Table 5</ref> shows the top-1 accuracy over all classes on iNaturalist 2018. LADE reaches the best accuracy 70.0% among the other methods, even without any branch structure of fine-tuning as BBN <ref type="bibr" target="#b62">[63]</ref>, nor a two-stage training scheme as <ref type="bibr" target="#b27">[28]</ref>. Further, LADE surpasses PC Softmax with a large gap, +0.7%, where PC Softmax still shows a competitive result compared to other methods. This result indicates that PC Softmax is effective for small datasets but performance worsens for larger datasets, while LADE scales well on large datasets as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on variously shifted test label distributions</head><p>Test sets are rarely well-balanced in real-world scenarios. To simulate and compare the performance of various state-of-the-art methods in the wild, we propose a more realistic evaluation protocol. We first train the model on the long-tailed source label distribution. Then we examine the performance on a range of target label distributions, from distributions that resemble the source label distributions to radically different distributions, similar to <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b35">36]</ref>.</p><p>We choose the ImageNet-LT from Section 4.2 as the source dataset. The test set of ImageNet-LT is uniformly distributed, and each class has 50 samples; hence the maximum imbalance ratio is 50. Similar to constructing the CIFAR-LT training dataset <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b8">9]</ref>, we additionally design two types of test datasets. Let us assume ImageNet-LT classes are sorted by descending values of the number of samples per class. Then the shifted test dataset is defined as follows: (1) Forward. n j = N ? ? (j?1)/C . As the imbalance ratio increases, it becomes similar to the source label distribution. (2) Backward. n j = N ? ? (C?j)/C . The order is flipped so that it gets more different as the imbalance ratio increases. Here ? is the imbalance ratio, N is the number of samples per class in the original ImageNet-LT test set (= 50), C is the number of classes, j is the class index and 1 ? j ? C, and n j is the number of samples in class j for the shifted test set.</p><p>We compare LADE with Softmax, Balanced Softmax, and Causal Norm on this evaluation protocol. For a fair comparison, we apply our PC strategy to state-of-the-art methods: log p t (y) ? log p u (y) is added to the logits before applying the softmax function for Balanced Softmax, and Causal Norm, as both methods target the uninformative prior. Theorem 1 is used for the Softmax instead. <ref type="table" target="#tab_6">Table 6</ref> shows the top-1 accuracy in the range of test datasets between the Forward-and Backward-type datasets. Our PC strategy shows consistent performance gain, which indicates the benefits of plug-and-play target label distributions. Moreover, LADE outperforms all the other methods in every imbalance settings, and the performance gap between LADE and PC Softmax gets wider as the dataset gets more imbalanced. These results demonstrate the general adaptability of our proposed method on real-world scenarios, where the target label distribution is variously shifted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Further analysis</head><p>Visualization of the logit values In this subsection, we visualize the logit values of each class in order to demonstrate the effect of LADE. By disentangling the source label distribution with LADE as described in Section 3.3, the logit value f ? (x)[y] should converge to log C for the positive samples:</p><formula xml:id="formula_13">f ? (x)[y] = log p u (x|y) p u (x) = log p u (y|x) p u (y) = log C,<label>(21)</label></formula><p>where we assume perfectly separable case, i.e. p u (y|x) = 1 for (x, y) ? p u (x, y) and C is the number of classes. <ref type="figure">Figure 3</ref> shows how the logits are distributed for each class. The hyperparameter ? represents the regularization strength for LADER. As ? increases, the logit values gradually converge to the theoretical value y = log C = log 100 (dotted line in the figure), reconfirming Theorem 2. This result indicates that LADER successfully regularizes the logit values as we intended.</p><p>Confidence calibration Previous literature claims that the confidence of the neural network classifier does not represent its true accuracy <ref type="bibr" target="#b19">[20]</ref>. We regard a classifier is well- calibrated when its predictive probability, max y p(y|x), represents the true probability <ref type="bibr" target="#b19">[20]</ref>. For example, when a calibrated classifier predicts the label y with predictive probability 0.75, it has a 75% chance of being correct. It will be catastrophic if we cannot trust the confidence of the neural network in the domain of medical diagnosis <ref type="bibr" target="#b10">[11]</ref> and self-driving car <ref type="bibr" target="#b5">[6]</ref>.</p><p>[42] suspect the endlessly growing logit values induced by a combination of naive CE loss and the Softmax function as the culprit of over-confidence. Since LADER regularizes the logit size, we expect that using LADE prevents the model from being over-confident. Through experiments, we observe that LADE improves calibration. <ref type="figure">Figure 4</ref> shows the reliability diagrams with 20-bins. Using expected calibration error (ECE) <ref type="bibr" target="#b42">[43]</ref>, we quantitatively measure the miscalibration rate of the model trained on ImageNet-LT. We compare our LADE with PC Softmax and the current state-of-the-art methods, Causal Norm <ref type="bibr" target="#b54">[55]</ref>, and Balanced Softmax <ref type="bibr" target="#b45">[46]</ref>. Results show that LADE produces a more calibrated classifier than other methods, with the ECE of 0.0346, which confirms our expectation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we suggest that disentangling the source label distribution from the model prediction is useful for long-tailed visual recognition. To disentangle the source label distribution, we first introduce a simple yet strong baseline, called PC Softmax, that matches the target label distribution by post-processing the model prediction trained by the cross-entropy loss and the Softmax function. We further propose a novel loss, LADE, that directly disentangles the source label distribution in the training phase based on the optimal bound of Donsker-Varadhan representation. Experiment results demonstrate that PC Softmax and our proposed LADE outperform state-of-the-art long-tailed visual recognition methods on real-world benchmark datasets. Furthermore, LADE achieves state-of-the-art performance on various shifted target label distributions. Lastly, further experiments show that our proposed LADE is also effective in terms of confidence calibration. We plan to extend our research to other vision domain problems that suffer from long-tailed distributions, such as object detection and segmentation.</p><p>jitter. For validation and test set, images are center cropped to 224 ? 224 without any augmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Ablation study</head><p>To verify the effectiveness of the regularizer term for DV representation (Equation 9) and LADER (Equation <ref type="bibr" target="#b15">16</ref>), we conduct an ablation test. <ref type="table" target="#tab_7">Table 8</ref> shows how the top-1 accuracy changes when removing the regularizer term for the DV representation (? = 0) or removing LADER (? = 0), respectively.  <ref type="bibr" target="#b11">[12]</ref> introduces ? to control the instability induced from directly using the DV representation. The model suffers a severe performance drop on ImageNet-LT and iNaturalist 2018 when the regularizer term for DV representation is not used (? = 0). ? represents the regularization strength of LADER on logits, as mentioned in Section 4.4. Without LADER (? = 0), performance degradation is observed, demonstrating the efficacy of LADER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">Additional results on variously shifted test label distributions</head><p>In Section 4.3, we show that our LADE achieves stateof-the-art performance on variously shifted test label distribution with ImageNet-LT, which is the large-scale longtailed dataset. We further conduct experiments on the smallscale dataset, CIFAR-100-LT, to ensure the consistent effectiveness of our LADE loss. For the training set, we use CIFAR-100-LT with an imbalance ratio of 50. The shifted test set is constructed by the same setting in Section 4.3. As shown in <ref type="table" target="#tab_8">Table 9</ref>, LADE outperforms all the other methods, which is consistent with the results on ImageNet-LT <ref type="table" target="#tab_6">(Table  6</ref>). We can also reconfirm the effectiveness of the PC strategy. These results from CIFAR-100-LT and ImageNet-LT imply that our PC strategy and LADE work well on both small-scale and large-scale datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Additional confidence calibration results</head><p>We report the additional results of LADE against other methods in the perspective of confidence calibration, using the same datasets from the section above, CIFAR-100-LT with an imbalance ratio of 50 for the small-scale dataset and ImageNet-LT for the large-scale dataset. Following <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b30">31]</ref>, we estimate the quality of calibration on two datasets with four metrics:</p><p>? Expected Calibration Error</p><formula xml:id="formula_14">ECE = 1 N M m=1 |B m | ? |acc(B m ) ? conf (B m )|,<label>(28)</label></formula><p>? Classwise Expected Calibration Error </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Classwise-ECE</head><p>? Brier Score</p><formula xml:id="formula_16">Brier = N i=1 C c=1 (p(y i = c|x i ; ?) ? 1(y i = c)) 2 ,<label>(30)</label></formula><p>? Negative Log Likelihood</p><formula xml:id="formula_17">NLL = ? N i=1 log p(y i |x i ; ?),<label>(31)</label></formula><p>where N is the total number of test samples (x i , y i ), C is the total number of classes, M (= 20) is the total number of bins, each bin B m is the set of indices of test samples where m?1 M &lt; p(y i |x i ; ?) ? m M , |B m | is the total number of samples inside the bin B m , acc(B m ) = 1 |Bm| i?Bm 1(arg max yj p(y j |x i ; ?) = y i ), and conf (B m ) = 1 |Bm| i?Bm p(y i |x i ; ?). The bin B m,j is the set of indices of test samples where the class for the samples is j, and the other definitions |B m,j |, acc(B m,j ) and conf (B m,j ) are exactly same as the above. <ref type="table" target="#tab_0">Table 10</ref> and 11 summarize the calibration results on CIFAR-100-LT and ImageNet-LT datasets, respectively. For all the evaluation metrics, LADE shows better overall calibration results than baseline methods. These observations demonstrate that our proposed LADE is effective in terms of calibration on both small-scale (CIFAR-100-LT) and large-scale (ImageNet-LT) datasets.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>A comparison between the cross-entropy loss and our proposed LADE loss in long-tailed visual recognition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>p s (y|x) = p s (y)p s (x|y) p s (x) = p s (y)p s (x|y) c p s (c)p s (x|c).(3)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Definition 3 . 1 (</head><label>31</label><figDesc>Post-Compensation Strategy) The Post-Compensation strategy modifies model logits as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Definition 3 . 2 (</head><label>32</label><figDesc>LADER) For a single batch of samplelabel pairs (x i , y i ) with i = 1, ..., N , LAbel distribution DisEntangling Regularizer (LADER) is defined as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Definition 3 . 3 (</head><label>33</label><figDesc>LADE) LAbel distribution DisEntangling (LADE) loss is defined as follows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3 :Figure 4 :</head><label>34</label><figDesc>ResNet-32 model logits correspond to each class, where the model is trained on CIFAR-100-LT with an imbalance ratio of 100. For each class c, positive samples denote the sample corresponds to class c, and negative samples denote the other. The colored area denotes the variance of logit values, while the line indicates the mean. Reliability diagrams of ResNeXt-50-32x4d [61] on ImageNet-LT. The average confidence of the model trained by LADE nearly matches its accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>j | ? |acc(B m,j ) ? conf (B m,j )|</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 6 :</head><label>6</label><figDesc>Reliability diagrams of ResNet-32 [22] on CIFAR-100-LT with imbalance ratio of 50.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>The details of the training set of long-tailed datasets.</figDesc><table><row><cell>Dataset</cell><cell cols="3"># of classes # of samples Imbalance ratio</cell></row><row><cell>CIFAR-100-LT</cell><cell>100</cell><cell>50K</cell><cell>{10, 50, 100}</cell></row><row><cell>Places-LT</cell><cell>365</cell><cell>62.5K</cell><cell>996</cell></row><row><cell>ImageNet-LT</cell><cell>1K</cell><cell>186K</cell><cell>256</cell></row><row><cell>iNaturalist 2018</cell><cell>8K</cell><cell>437K</cell><cell>500</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table><row><cell>Method</cell><cell cols="2">Many Medium</cell><cell>Few</cell><cell>All</cell></row><row><cell>Focal Loss  ?</cell><cell>41.1</cell><cell>34.8</cell><cell>22.4</cell><cell>34.6</cell></row><row><cell>OLTR  ?</cell><cell>44.7</cell><cell>37.0</cell><cell>25.3</cell><cell>35.9</cell></row><row><cell>Decouple-? -norm  ?</cell><cell>37.8</cell><cell>40.7</cell><cell>31.8</cell><cell>37.9</cell></row><row><cell>Decouple-LWS  ?</cell><cell>40.6</cell><cell>39.1</cell><cell>28.6</cell><cell>37.6</cell></row><row><cell>Causal Norm</cell><cell>23.8</cell><cell>35.8</cell><cell>40.4</cell><cell>32.4</cell></row><row><cell>Balanced Softmax</cell><cell>42.0</cell><cell>39.3</cell><cell>30.5</cell><cell>38.6</cell></row><row><cell>Softmax</cell><cell>46.4</cell><cell>27.9</cell><cell>12.5</cell><cell>31.5</cell></row><row><cell>PC Softmax</cell><cell>43.0</cell><cell>39.1</cell><cell>29.6</cell><cell>38.7</cell></row><row><cell>LADE</cell><cell>42.8</cell><cell>39.0</cell><cell>31.2</cell><cell>38.8</cell></row></table><note>The performances on Places-LT [38], starting from an ImageNet pre-trained ResNet-152. Rows with ? denote results directly borrowed from [28].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>The performances on ImageNet-LT<ref type="bibr" target="#b37">[38]</ref>. Rows with ? denote results directly borrowed from<ref type="bibr" target="#b54">[55]</ref>.</figDesc><table><row><cell>Method</cell><cell cols="2">Many Medium</cell><cell>Few</cell><cell>All</cell></row><row><cell>90 epochs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Focal Loss  ?</cell><cell>64.3</cell><cell>37.1</cell><cell>8.2</cell><cell>43.7</cell></row><row><cell>OLTR  ?</cell><cell>51.0</cell><cell>40.8</cell><cell cols="2">20.8 41.9</cell></row><row><cell>Decouple-cRT  ?</cell><cell>61.8</cell><cell>46.2</cell><cell cols="2">27.4 49.6</cell></row><row><cell>Decouple-? -norm  ?</cell><cell>59.1</cell><cell>46.9</cell><cell cols="2">30.7 49.4</cell></row><row><cell>Decouple-LWS  ?</cell><cell>60.2</cell><cell>47.2</cell><cell cols="2">30.3 49.9</cell></row><row><cell>Causal Norm  ?</cell><cell>62.7</cell><cell>48.8</cell><cell cols="2">31.6 51.8</cell></row><row><cell>Balanced Softmax</cell><cell>62.2</cell><cell>48.8</cell><cell cols="2">29.8 51.4</cell></row><row><cell>Softmax</cell><cell>65.1</cell><cell>35.7</cell><cell>6.6</cell><cell>43.1</cell></row><row><cell>PC Softmax</cell><cell>60.4</cell><cell>46.7</cell><cell cols="2">23.8 48.9</cell></row><row><cell>LADE</cell><cell>62.3</cell><cell>49.3</cell><cell cols="2">31.2 51.9</cell></row><row><cell>180 epochs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Causal Norm</cell><cell>65.2</cell><cell>47.7</cell><cell cols="2">29.8 52.0</cell></row><row><cell>Balanced Softmax</cell><cell>63.6</cell><cell>48.4</cell><cell cols="2">32.9 52.1</cell></row><row><cell>Softmax</cell><cell>68.1</cell><cell>41.9</cell><cell cols="2">14.4 48.2</cell></row><row><cell>PC Softmax</cell><cell>63.9</cell><cell>49.1</cell><cell cols="2">34.3 52.8</cell></row><row><cell>LADE</cell><cell>65.1</cell><cell>48.9</cell><cell cols="2">33.4 53.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Top-1 accuracy over all classes on iNaturalist 2018. Rows with ? denote results directly borrowed from<ref type="bibr" target="#b27">[28]</ref> and denotes the result directly borrowed from<ref type="bibr" target="#b62">[63]</ref>.</figDesc><table><row><cell>Method</cell><cell>Top-1 Accuracy</cell></row><row><cell>CB-Focal  ?</cell><cell>61.1</cell></row><row><cell>LDAM  ?</cell><cell>64.6</cell></row><row><cell>LDAM+DRW  ?</cell><cell>68.0</cell></row><row><cell>Decouple-? -norm  ?</cell><cell>69.3</cell></row><row><cell>Decouple-LWS  ?</cell><cell>69.5</cell></row><row><cell>BBN</cell><cell>69.6</cell></row><row><cell>Causal Norm</cell><cell>63.9</cell></row><row><cell>Balanced Softmax</cell><cell>69.8</cell></row><row><cell>Softmax</cell><cell>65.0</cell></row><row><cell>PC Softmax</cell><cell>69.3</cell></row><row><cell>LADE</cell><cell>70.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4</head><label>4</label><figDesc>presents the performance of our method on ImageNet-LT. LADE yields 53.0% top-1 overall accuracy with 180 epochs, which is better than the previous state-of-the-art, including Causal Norm trained with 180 epochs. PC Softmax also shows a favorable result, 52.8%, where it also outperforms the previous state-of-the-art-results. Besides, LADE still achieves the best result compared to the methods when LADE and the methods are trained for 90 epochs.</figDesc><table /><note>iNaturalist 2018 To show the scalability of LADE on a large-scale dataset, we evaluate our methods in the real- world long-tailed dataset, iNaturalist 2018. Since iNatural- ist 2018 does not contain a validation set, we train the model</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Top-1 accuracy over all classes on test time shifted ImageNet-LT. All models are trained for 180 epochs.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell></cell><cell>Forward</cell><cell></cell><cell></cell><cell>Uniform</cell><cell></cell><cell></cell><cell>Backward</cell><cell></cell><cell></cell></row><row><cell>Imbalance ratio</cell><cell>50</cell><cell>25</cell><cell>10</cell><cell>5</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>5</cell><cell>10</cell><cell>25</cell><cell>50</cell></row><row><cell>Causal Norm</cell><cell cols="5">64.1 62.5 60.1 57.8 54.6</cell><cell>52.0</cell><cell cols="5">49.3 45.8 43.4 40.4 38.4</cell></row><row><cell>Balanced Softmax</cell><cell cols="5">62.5 60.9 58.8 57.0 54.4</cell><cell>52.1</cell><cell cols="5">49.6 46.5 44.1 41.4 39.7</cell></row><row><cell>Softmax</cell><cell cols="5">66.3 63.9 60.4 57.1 52.3</cell><cell>48.2</cell><cell cols="5">44.2 38.9 35.0 30.5 27.9</cell></row><row><cell>PC Causal Norm</cell><cell cols="5">66.7 64.3 60.9 58.1 54.6</cell><cell>52.0</cell><cell cols="5">49.8 47.9 47.0 46.7 46.7</cell></row><row><cell cols="6">PC Balanced Softmax 65.5 63.1 59.9 57.3 54.3</cell><cell>52.1</cell><cell cols="5">50.2 48.8 48.3 48.5 49.0</cell></row><row><cell>PC Softmax</cell><cell cols="5">66.6 63.9 60.6 58.1 55.0</cell><cell>52.8</cell><cell cols="5">51.0 49.3 48.8 48.5 49.0</cell></row><row><cell>LADE</cell><cell cols="5">67.4 64.8 61.3 58.6 55.2</cell><cell>53.0</cell><cell cols="5">51.2 49.8 49.2 49.3 50.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Ablation study for LADE on the long-tailed benchmark datasets. LADE (Ours) shows the best evaluation performance, and ? = 0 and ? = 0 denote the performance with the same settings except for the DV representation regularization or LADER, respectively.</figDesc><table><row><cell>Dataset</cell><cell cols="2">LADE (Ours) ? = 0</cell><cell>? = 0</cell></row><row><cell>CIFAR-100-LT (IB 10)</cell><cell>61.7</cell><cell>61.5</cell><cell>61.6</cell></row><row><cell>CIFAR-100-LT (IB 50)</cell><cell>50.5</cell><cell>49.5</cell><cell>49.9</cell></row><row><cell>CIFAR-100-LT (IB 100)</cell><cell>45.4</cell><cell>45.2</cell><cell>45.1</cell></row><row><cell>Places-LT</cell><cell>38.8</cell><cell>38.5</cell><cell>38.6</cell></row><row><cell>ImageNet-LT</cell><cell>53.0</cell><cell>47.0</cell><cell>52.1</cell></row><row><cell>iNaturalist 2018</cell><cell>70.0</cell><cell>58.3</cell><cell>69.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 :</head><label>9</label><figDesc>Top-1 accuracy over all classes on test time shifted CIFAR-100-LT with imbalance ratio of 50.</figDesc><table><row><cell>Dataset</cell><cell></cell><cell></cell><cell>Forward</cell><cell></cell><cell></cell><cell>Uniform</cell><cell></cell><cell></cell><cell>Backward</cell><cell></cell><cell></cell></row><row><cell>Imbalance ratio</cell><cell>50</cell><cell>25</cell><cell>10</cell><cell>5</cell><cell>2</cell><cell>1</cell><cell>2</cell><cell>5</cell><cell>10</cell><cell>25</cell><cell>50</cell></row><row><cell>Causal Norm</cell><cell cols="5">63.7 61.6 58.7 55.9 51.5</cell><cell>48.1</cell><cell cols="5">44.7 41.2 38.3 35.6 33.6</cell></row><row><cell>Balanced Softmax</cell><cell cols="5">59.6 58.5 56.9 54.8 52.2</cell><cell>49.9</cell><cell cols="5">47.5 45.1 42.7 40.9 39.9</cell></row><row><cell>Softmax</cell><cell cols="5">65.9 63.4 59.7 55.6 50.1</cell><cell>45.5</cell><cell cols="5">40.8 35.2 30.5 26.8 23.9</cell></row><row><cell>PC Causal Norm</cell><cell cols="5">66.1 62.9 58.8 55.6 51.2</cell><cell>48.1</cell><cell cols="5">45.7 44.2 43.4 44.3 44.9</cell></row><row><cell cols="4">PC Balanced Softmax 65.9 63.1 59.5</cell><cell cols="2">56.3 52.2</cell><cell>49.9</cell><cell cols="5">47.9 46.9 46.4 47.3 48.4</cell></row><row><cell>PC Softmax</cell><cell cols="5">66.0 63.2 59.2 55.9 52.4</cell><cell>49.5</cell><cell cols="5">47.5 46.7 46.2 47.4 49.0</cell></row><row><cell>LADE</cell><cell cols="5">67.4 64.7 60.2 56.3 52.8</cell><cell>50.5</cell><cell cols="5">48.2 47.4 46.6 48.1 49.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 10 :</head><label>10</label><figDesc>Confidence calibration results on CIFAR-100-LT with imbalance ratio of 50.</figDesc><table><row><cell>Method</cell><cell>Accuracy</cell><cell>ECE</cell><cell>Classwise ECE</cell><cell>Brier</cell><cell>NLL</cell></row><row><cell>Causal Norm</cell><cell>48.1</cell><cell>0.150</cell><cell>0.00483</cell><cell>0.689</cell><cell>2.13</cell></row><row><cell>Balanced Softmax</cell><cell>49.9</cell><cell>0.168</cell><cell>0.00461</cell><cell>0.673</cell><cell>2.07</cell></row><row><cell>Softmax</cell><cell>45.5</cell><cell>0.249</cell><cell>0.00680</cell><cell>0.769</cell><cell>2.50</cell></row><row><cell>PC Softmax</cell><cell>49.5</cell><cell>0.174</cell><cell>0.00472</cell><cell>0.678</cell><cell>2.10</cell></row><row><cell>LADE</cell><cell>50.5</cell><cell>0.148</cell><cell>0.00434</cell><cell>0.658</cell><cell>2.02</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 11 :</head><label>11</label><figDesc>Confidence calibration results on ImageNet-LT.</figDesc><table><row><cell>Method</cell><cell>Accuracy</cell><cell>ECE</cell><cell>Classwise ECE</cell><cell>Brier</cell><cell>NLL</cell></row><row><cell>Causal Norm</cell><cell>52.0</cell><cell>0.108</cell><cell>0.000461</cell><cell>0.634</cell><cell>2.42</cell></row><row><cell>Balanced Softmax</cell><cell>52.1</cell><cell>0.061</cell><cell>0.000406</cell><cell>0.621</cell><cell>2.20</cell></row><row><cell>Softmax</cell><cell>48.2</cell><cell>0.140</cell><cell>0.000603</cell><cell>0.688</cell><cell>2.47</cell></row><row><cell>PC Softmax</cell><cell>52.8</cell><cell>0.057</cell><cell>0.000411</cell><cell>0.615</cell><cell>2.17</cell></row><row><cell>LADE</cell><cell>53.0</cell><cell>0.035</cell><cell>0.000406</cell><cell>0.611</cell><cell>2.18</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix 6.1. Proof to Theorem 1 Assume p t (y|x) to be the target conditional probability and p s (y|x) to be the source conditional probability. We start with p s (y|x) formulated with logits f ? (x)[y]:</p><p>By applying the log function on both sides,</p><p>where C x and C x can be regarded as constants for a fixed x as follows:</p><p>Let us derive the post-compensated logit f P C ? (Definition 3.1) from f ? :</p><p>Re-calculating the Softmax function yields:</p><p>which ends the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Implementation details</head><p>For all the experiments over multiple datasets, we use the SGD optimizer with momentum ? = 0.9 and weight decay 5 ? 10 ?4 to optimize the network if not specified. We use the same random seed throughout the whole experiment for a fair comparison. For image classification on CIFAR-100-LT and ImageNet-LT, we follow most of the details from <ref type="bibr" target="#b54">[55]</ref>, and on Places-LT and iNaturalist 2018, we follow <ref type="bibr" target="#b27">[28]</ref>. All the models are trained on 4 GPUs, except CIFAR-100-LT, where we use 1 GPU. We find the optimal hyperparameters based on a grid search with the validation set. However, as the iNaturalist 2018 dataset does not contain the validation set, we use the same ? and ? searched on the ImageNet-LT dataset since it has a similar number of classes and samples compared to the iNaturalist 2018 dataset. Detailed experiment settings for LADE are summarized in <ref type="table">Table 7</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR-100-LT [30]</head><p>On the CIFAR-100-LT dataset, we use ResNet-32 <ref type="bibr" target="#b21">[22]</ref> as the backbone network for all the experiments, following the implementation of <ref type="bibr" target="#b54">[55]</ref>. We train for 200 epochs and apply the linear warm-up learning rate schedule <ref type="bibr" target="#b18">[19]</ref> to the first five epochs. The learning rate is initialized as 0.2, and it is decayed at the 120th and 160th epoch by 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Places-LT [64]</head><p>We use ResNet-152 <ref type="bibr" target="#b21">[22]</ref> as the backbone network with pretraining on the ImageNet-2012 <ref type="bibr" target="#b13">[14]</ref> dataset. We use 0.05 and 0.001 for the initial learning rate of the classifier and the feature extractor. We train for 30 epochs with a learning rate decay of 0.1 every 10 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ImageNet-LT [14]</head><p>On the ImageNet-LT dataset, we utilize ResNeXt-50-32x4d <ref type="bibr" target="#b60">[61]</ref> as the backbone network for all the experiments. We use the cosine learning rate schedule <ref type="bibr" target="#b38">[39]</ref> decaying from 0.05 to 0.0 during 180 epochs.</p><p>iNaturalist 2018 <ref type="bibr" target="#b56">[57]</ref> For the iNaturalist 2018 dataset, we use ResNet-50 <ref type="bibr" target="#b21">[22]</ref> as the backbone network for all experiments. We use cosine learning rate scheduling <ref type="bibr" target="#b38">[39]</ref> decaying from 0.1 to 0.0 during 200 epochs, following <ref type="bibr" target="#b27">[28]</ref>.</p><p>Data Pre-processing We follow <ref type="bibr" target="#b37">[38]</ref> for the details on image preprocessing. For the training set, images are resized to 256 ? 256 and randomly cropped to 224 ? 224. After cropping, we augment images with random horizontal flip with probability p = 0.5 and apply random color</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Applying support vector machines to imbalanced datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rehan</forename><surname>Akbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Kwek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Japkowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on machine learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="39" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Regularized learning for domain adaptation under label shifts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamyar</forename><surname>Azizzadenesheli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanny</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Animashree</forename><surname>Anandkumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On bayesian bounds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arindam</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd international conference on Machine learning</title>
		<meeting>the 23rd international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Mutual information neural estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Ishmael</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aristide</forename><surname>Baratin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sai</forename><surname>Rajeshwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bishop</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">End to end learning for self-driving cars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mariusz</forename><surname>Bojarski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Davide</forename><forename type="middle">Del</forename><surname>Testa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Dworakowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Firner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beat</forename><surname>Flepp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasoon</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathew</forename><surname>Jackel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urs</forename><surname>Monfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiakai</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.07316</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A systematic study of the class imbalance problem in convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Buda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsuto</forename><surname>Maki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maciej A</forename><surname>Mazurowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">What is the effect of importance weighting in deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Byrd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="872" to="881" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Learning imbalanced datasets with labeldistribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaidi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrien</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengyu</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1567" to="1578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A short note about kinetics-600</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andras</forename><surname>Banki-Horvath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chloe</forename><surname>Hillier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1808.01340</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Intelligible models for healthcare: Predicting pneumonia risk and hospital 30-day readmission</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Gehrke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Sturm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noemie</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 21th ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1721" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Regularized mutual information neural estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwanghee</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyeong</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.07932,2020.3</idno>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglin</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Large deviations for stationary gaussian processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Md Donsker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Varadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications in Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A unified view of label shift estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sivaraman</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020</title>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<meeting><address><addrLine>NeurIPS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">High-resolution breast cancer screening with multi-view deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krzysztof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stacey</forename><surname>Geras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Gene</forename><surname>Wolfson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linda</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Moy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cho</surname></persName>
		</author>
		<idno>abs/1703.07047</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Fast r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1440" to="1448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">On calibration of modern neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1321" to="1330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning from imbalanced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibo</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Edwardo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1263" to="1284" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yining</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="5375" to="5384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Rethinking classbalanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammad</forename><forename type="middle">Abdullah</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7610" to="7619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The class imbalance problem: A systematic study. Intelligent data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathalie</forename><surname>Japkowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaju</forename><surname>Stephen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="429" to="449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Survey on deep learning with class imbalance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Justin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Use of different monte carlo sampling techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herman</forename><surname>Kahn</surname></persName>
		</author>
		<idno>1955. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Decoupling representation and classifier for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyi</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Gordo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">M2m: Imbalanced classification via major-to-minor translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaehyung</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongheon</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13896" to="13905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meelis</forename><surname>Kull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miquel</forename><forename type="middle">Perello</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>K?ngsepp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Telmo</forename><surname>Silva Filho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Flach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">On information and sufficiency. The annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Solomon</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leibler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Indranil</forename><surname>Sur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajay</forename><surname>Nastase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Divakaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">R</forename><surname>Hasson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.03319</idno>
		<title level="m">Dataefficient mutual information neural estimator</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Detecting and correcting for label shift with black box predictors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<editor>Jennifer G. Dy and Andreas Krause</editor>
		<meeting>the 35th International Conference on Machine Learning<address><addrLine>Stockholmsm?ssan, Stockholm, Sweden</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="3128" to="3136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The influence of class imbalance on cost-sensitive learning: An empirical study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth International Conference on Data Mining (ICDM&apos;06)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="970" to="974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongqi</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">SGDR: stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">When does imbalanced data require more than cost-sensitive learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Margineantu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI&apos;2000 Workshop on Learning from Imbalanced Data Sets</title>
		<meeting>the AAAI&apos;2000 Workshop on Learning from Imbalanced Data Sets</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Formal limitations on the measurement of mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Mcallester</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="875" to="884" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">When does label smoothing help?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rafael</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4694" to="4703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Obtaining well calibrated probabilities using bayesian binning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahdi Pakdaman Naeini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milos</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hauskrecht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the... AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence</title>
		<meeting>the... AAAI Conference on Artificial Intelligence. AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>NIH Public Access</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">2015</biblScope>
			<biblScope unit="page">2901</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">fgan: Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Botond</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryota</forename><surname>Tomioka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="271" to="279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">On variational bounds of mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A?ron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Balanced meta-softmax for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cunjun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="4175" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Simulation and the Monte Carlo method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Reuven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><forename type="middle">P</forename><surname>Rubinstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kroese</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>John Wiley &amp; Sons</publisher>
			<biblScope unit="volume">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Relay backpropagation for effective learning of deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhouchen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingming</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="467" to="482" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Can you trust your model&apos;s uncertainty? evaluating predictive uncertainty under dataset shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasper</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaniv</forename><surname>Ovadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emily</forename><surname>Fertig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balaji</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sebastian Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">V</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nado</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<meeting><address><addrLine>NeurIPS; BC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Vancouver</publisher>
			<date type="published" when="2019-12-08" />
			<biblScope unit="page" from="13969" to="13980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Understanding the limitations of variational mutual information estimators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ermon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Longtailed classification by keeping the good and removing the bad momentum causal effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaihua</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianqiang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Posterior re-calibration for imbalanced datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjiao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Cheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Glaser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yen-Chang</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zsolt</forename><surname>Kira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The inaturalist species classification and detection dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oisin</forename><forename type="middle">Mac</forename><surname>Grant Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Aodha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">The devil is in the tails: Fine-grained classification in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grant</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.01450</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Deep generative model for robust imbalance classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilin</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liping</forename><surname>Jing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14124" to="14133" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martial</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7029" to="7039" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Rethinking the value of labels for improving class-imbalanced learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Bbn: Bilateral-branch network with cumulative learning for long-tailed visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quan</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu-Shen</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhao-Min</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Training cost-sensitive neural networks with methods addressing the class imbalance problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu-Ying</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on knowledge and data engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="77" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
