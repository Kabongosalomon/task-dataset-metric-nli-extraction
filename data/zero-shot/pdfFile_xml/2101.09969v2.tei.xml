<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CHOLAN: A Modular Approach for Neural Entity Linking on Wikipedia and Wikidata</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manoj</forename><surname>Prabhakar</surname></persName>
							<email>manoj.prabhakar@hpi.de</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kannan</forename><surname>Ravi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Hasso Plattner Institute</orgName>
								<orgName type="institution">University of Potsdam</orgName>
								<address>
									<settlement>Potsdam</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Singh</surname></persName>
							<email>kuldeep.singh1@cerence.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Zerotha Research and Cerence GmbH</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaiah</forename><forename type="middle">Onando</forename><surname>Mulang&amp;apos;</surname></persName>
							<email>mulang@cs.uni-bonn.de</email>
							<affiliation key="aff1">
								<orgName type="department">Smart Data Analytics</orgName>
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<settlement>Bonn</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeedeh</forename><surname>Shekarpour</surname></persName>
							<email>sshekarpour1@udayton.edu</email>
							<affiliation key="aff3">
								<orgName type="institution">University of Dayton</orgName>
								<address>
									<settlement>Dayton</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
							<email>johannes.hoffart@gs.com</email>
							<affiliation key="aff4">
								<orgName type="department">Goldman Sachs</orgName>
								<address>
									<settlement>Frankfurt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
							<email>jens.lehmann@cs.uni-bonn.de</email>
							<affiliation key="aff1">
								<orgName type="department">Smart Data Analytics</orgName>
								<orgName type="institution">University of Bonn</orgName>
								<address>
									<settlement>Bonn</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">CHOLAN: A Modular Approach for Neural Entity Linking on Wikipedia and Wikidata</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose CHOLAN, a modular approach to target end-to-end entity linking (EL) over knowledge bases. CHOLAN consists of a pipeline of two transformerbased models integrated sequentially to accomplish the EL task. The first transformer model identifies surface forms (entity mentions) in a given text. For each mention, a second transformer model is employed to classify the target entity among a predefined candidates list. The latter transformer is fed by an enriched context captured from the sentence (i.e. local context), and entity description gained from Wikipedia. Such external contexts have not been used in state of the art EL approaches. Our empirical study was conducted on two well-known knowledge bases (i.e., Wikidata and Wikipedia). The empirical results suggest that CHOLAN outperforms state-of-the-art approaches on standard datasets such as CoNLL-AIDA, MSNBC, AQUAINT, ACE2004, and T-REx.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The explicit schema, graph-based structure, and interlinking nature of information represented in publicly available knowledge graphs (KGs) e.g., DBpedia <ref type="bibr" target="#b1">(Auer et al., 2007)</ref>, Freebase <ref type="bibr" target="#b2">(Bollacker et al., 2007)</ref>, Wikidata <ref type="bibr" target="#b34">(Vrandecic, 2012)</ref> or knowledge bases (KBs) such as Wikipedia; introduce a new landscape of features, as well as structured knowledge and embeddings. Researchers have developed several techniques to align information available in unstructured text to the concepts of these KGs <ref type="bibr" target="#b37">(Wu et al., 2019b;</ref><ref type="bibr" target="#b3">Broscheit, 2019)</ref>.</p><p>End-to-end Entity Linking (hereafter EL) task follows this direction; such that, given a sentence EL first identifies the entity mention in the sentence, then maps these mentions to the most likely KG/KB entities. The EL comprises of a threestep process. With respect to the given example sentence Soccer: Late Goals Give Japan win Over Syria, the first step called mention detection (MD) identifies the surface forms Japan and Syria. The next step is candidate generation (CG) aiming to find a list of possible entity candidates in the KG/KB for each entity mention. For example, the candidates list for entity mention Japan consists in part of Japan national football team, Japan (country), Japan (Band) and for Syria is Syria (Roman province), Syria national football team, Greater Syria. Finally, the third step deals with the entity disambiguation (ED) which employs the coreference and contextual features to discriminate the most likely entity from the candidates list e.g., Japan national football team and Syria national football team are correct entities.</p><p>Entity Linking approaches are broadly categorised into three categories. The initial attempts <ref type="bibr" target="#b18">(Hoffart et al., 2011;</ref><ref type="bibr" target="#b27">Piccinno and Ferragina, 2014)</ref> solve MD and ED as independent sub-tasks of EL (i.e., a pipeline based system). However, these approaches exhibit a behaviour where errors propagate from MD to ED hence might downgrade the overall performance of the system. The second category has emerged in an attempt to mitigate these errors, where researchers focused on jointly modelling MD and ED, emphasising the importance of the mutual dependency of the two sub-tasks <ref type="bibr" target="#b20">(Kolitsas et al., 2018)</ref>. These two EL approaches depend on an intermediate candidate generation step and rely on a pre-computed list of entity candidates. For example, <ref type="bibr" target="#b20">(Kolitsas et al., 2018)</ref> propose a joint MD and ED model and inherits the candidate list from <ref type="bibr" target="#b15">(Ganea and Hofmann, 2017)</ref>. The third approach combines the three sub-steps in a joint model and illustrates that each of those tasks is interdependent <ref type="bibr" target="#b11">(Durrett and Klein, 2014;</ref><ref type="bibr" target="#b3">Broscheit, 2019)</ref>.</p><p>The recent EL approaches focus on jointly modelling two or three subtasks <ref type="bibr" target="#b31">(Sevgili et al., 2020)</ref>. Furthermore, the NLP research community has extensively used transformers in end-to-end models for entity linking <ref type="bibr" target="#b3">(Broscheit 2019</ref><ref type="bibr" target="#b26">, Peters et al. 2019</ref><ref type="bibr" target="#b14">, and F?vry et al. 2020</ref>. Nevertheless, these works report less performance than <ref type="bibr" target="#b20">(Kolitsas et al., 2018)</ref>, which is a bi-LSTM based model. The observations regarding the limited performance of transformer-based models for the EL motivate our work, and in this paper, our focus is to understand the bottlenecks in the entity linking process. We argue that the less studied task in literature, i.e., candidate generation, has an essential role in the EL models' performance, which has not been a focus in the recently proposed transformer-based entity linking models.</p><p>In this paper, we hypothesise that the transformer models, though trained on a large corpus, may require additional task-specific contexts. Furthermore, inducing the context at the entity disambiguation step may positively impact the overall performance, which has not been utilised in the state of the art methods due to monolithic implementations <ref type="bibr" target="#b20">(Kolitsas et al., 2018;</ref><ref type="bibr" target="#b26">Peters et al., 2019;</ref><ref type="bibr" target="#b3">Broscheit, 2019;</ref><ref type="bibr" target="#b14">F?vry et al., 2020)</ref>. Subsequently, we deviate from the joint modelling of two or three subtasks of the EL and revert to the methodology opted by earlier EL systems in 2011 <ref type="bibr" target="#b18">(Hoffart et al., 2011)</ref>, i.e. treat each subtask independently. As such, we study the research question: RQ: what is the impact of each sub-task (aka component) on the overall outcome of the transformer-based entity linking approach?</p><p>We propose an intuitive novel approach named CHOLAN, comprising a modular architecture of two transformer models to solve MD and ED independently. In the first step, CHOLAN employs BERT  model to identify mentions of the entities in an input sentence. The second step involves expanding each mention with a list of KB entity candidates. Finally, the en-tity mention, sentence (local context), an entity candidate, and entity Wikipedia description (entity context) are fed as input sequences in the second BERT based model to predict the correct KB entity (cf. <ref type="figure" target="#fig_0">Figure 1</ref>). We train MD and ED steps independently during training, and while testing, we run the CHOLAN pipeline end-to-end for predicting the KB entity. The following are the novel features of CHOLAN:</p><p>? The core focus of the approach is to flexibly induce external context and candidate lists in a transformer-based model to improve the EL performance. CHOLAN is independent of a particular candidate list and additional background context. We study four different configurations of CHOLAN to demonstrate the impact of candidate generation step and background knowledge (i.e. entity and sentential context) induced in the model. CHOLAN achieves a new state of the art performance on several datasets: T-REx (ElSahar et al., 2018) for Wikidata; AIDA-B, MSBC, AQUAINT, and ACE2004 for Wikipedia <ref type="bibr" target="#b18">(Hoffart et al., 2011;</ref><ref type="bibr" target="#b17">Guo and Barbosa, 2018</ref>). ? CHOLAN is the first approach which is empirically demonstrated to be transferable across KBs having completely different underlying structure and schema i.e., on semistructured Wikipedia and fully structured Wikidata.</p><p>The implementation is publicly available 1 . The paper is structured as follows: next section summarises the related work. Section 3 describes the problem statement and approach. Section 4 explains the experimental settings followed by results in 5. We conclude in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Mention Detection (MD): The first attempt to organise a named entity recognition (NER) task traced back to 1996 <ref type="bibr" target="#b16">(Grishman and Sundheim, 1996)</ref>. Since then, numerous attempts have been made ranging from conditional random fields (CRFs) with features constructed from dictionaries <ref type="bibr" target="#b28">(Rockt?schel et al., 2013)</ref> or feature-inferring neural networks <ref type="bibr" target="#b7">(Collobert and Weston, 2008)</ref>.  Recently, contextual embedding based models achieve state of the art for NER/MD task <ref type="bibr" target="#b0">(Akbik et al., 2018;</ref>. We point to the survey by <ref type="bibr" target="#b38">Yadav and Bethard (2018)</ref> for details about NER. Few early EL models have performed MD task independently <ref type="bibr" target="#b6">(Ceccarelli et al., 2013;</ref><ref type="bibr" target="#b8">Cornolti et al., 2016)</ref>. Candidate Generation (CG): There are four prominent approaches for candidate generation. First is a direct matching of entity mentions with a pre-computed candidate set <ref type="bibr" target="#b42">(Zwicklbauer et al., 2016)</ref>. The second approach is the dictionary lookup, where a dictionary of the associated aliases of entity mentions is compiled from several knowledge base sources (e.g. Wikipedia, Wordnet) <ref type="bibr" target="#b31">(Sevgili et al., 2020;</ref><ref type="bibr" target="#b13">Fang et al., 2019;</ref><ref type="bibr" target="#b5">Cao et al., 2017)</ref>. The third approach is to generate entity candidates using empirical probabilistic entity-map p(e|m). The p(e|m) is a precalculated prior probability of correspondence between positive mentions and entities. A widely used entity map was built by (Ganea and Hofmann, 2017) from Wikipedia hyperlinks, Crosswikis (Spitkovsky and Chang, 2012) and YAGO <ref type="bibr" target="#b18">(Hoffart et al., 2011)</ref> dictionaries. End-to-end EL approaches such as <ref type="bibr" target="#b20">(Kolitsas et al., 2018;</ref><ref type="bibr" target="#b4">Cao et al., 2018)</ref> relies on the entity map built by Ganea and Hofmann. The next approach for generating the candidates is proposed by <ref type="bibr" target="#b29">(Sakor et al., 2019)</ref>. Authors build a local KG by expanding entity mentions using Wikidata and DBpedia entity labels and associated aliases. The local KG can be queried using BM25 ranking algorithm <ref type="bibr" target="#b21">(Logeswaran et al., 2019)</ref>. The modular architecture of CHOLAN gives us the flexibility to experiment with several ways of generating entity candidates. Hence, we reused candidate list proposed by (Ganea and Hofmann, 2017) and built a new CG approach based on <ref type="bibr" target="#b29">(Sakor et al., 2019)</ref>. End to End EL: Few EL approaches accomplish MD and ED tasks jointly. <ref type="bibr" target="#b25">(Nguyen et al., 2016)</ref> propose joint recognition and disambiguation of named-entity mentions using a graphical model and show that it improves EL. The work in <ref type="bibr" target="#b20">(Kolitsas et al., 2018)</ref> also proposes a joint model for MD and ED. Authors use a bi-LSTM based model for mention detection and computes the similarity between the entity mention embedding and set of predefined entity candidates. The work in <ref type="bibr" target="#b3">(Broscheit, 2019)</ref> employs BERT to jointly model three subtasks of the EL. Author employ an entity vocabulary of 700K top most frequent entities to train the model. Work in <ref type="bibr" target="#b14">(F?vry et al., 2020)</ref> uses a Transformer architecture with large scale pre-training from Wikipedia links for EL. For CG, authors train the model to predict BIO-tagged mention boundaries to disambiguate among all entities. For Wikidata KG, Opentapioca is an entity linking approach which relies on a heuristic-based model for disambiguation of the mentions in a text to the Wikidata entities <ref type="bibr" target="#b9">(Delpeuch, 2020)</ref>. Arjun <ref type="bibr" target="#b24">(Mulang et al., 2020)</ref> is the most similar to our approach CHOLAN and trains two independent neural models for MD and ED. It generates candidates on the fly using a Wikidata entity alias map. Arjun does not induce any context in the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Problem Statement and Approach</head><p>We formally define EL task as follows:</p><p>given an input sequence of words W = {w 1 , w 2 , w 3 , . . . , w n }, and a set of entities denoted by E from a KG/KB. The EL task aligns the text into a subset of entities represented as ? : W ? E where E ? E. We formulate the EL task as a three step process in which the first step is the mention detection (MD). The MD is a function ? 1 : W ? M, where the set of mentions is denoted by M = (m 1 , m 2 , ..., m k ) (k ? n) and each mention m x is a sequence of words starting from i to end position j: m</p><formula xml:id="formula_0">(i,j) x = (w i , w i+1 , ..., w j ) (0 &lt; i, j ? n).</formula><p>The next task is candidate generation where for each mention m x a set of candidates C(m x )= {e x 1 , ..., e x n |e x i ? E} is derived. Finally, the entity disambiguation (ED) task aims to map each mention m x ? M to the most likely entity from its list of candidates. In our case, we model the ED task as a classification task and augment the input with extra signals as context. For every candidate entity c i ? C(m x ), the model estimates a probability p i , thus the most likely entity is the one with the highest probability as</p><formula xml:id="formula_1">? = arg max p i {P(p i | m x , c x i , W, C)}</formula><p>where W and C are the input representations respectively for the given sentence (local context) and the context derived from KG/KB. As such the probability of score p i is conditioned not only on m x and c x i but also on W and C as contextual parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CHOLAN Approach</head><p>The CHOLAN architecture comprises of three main modules as illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Mention Detection (MD)</head><p>We adapt the vanilla BERT  model for the task of entity mention detection in an unstructured text. For each input sentence, we append the special tokens <ref type="bibr">[CLS]</ref> and <ref type="bibr">[SEP]</ref> to the beginning and end of the sentence, respectively. This is then used as input to the model which learns a representation of the tokens in the sentence. We then introduce a (logistic regression based) classification layer on top of the BERT model to determine named entity tags for each token following the BIO format <ref type="bibr" target="#b30">(Sang and Meulder, 2003)</ref>. Our BERT ? model is initialised using publicly available weights from the pretrained BERT BASE model and is fine-tuned to the specific dataset for detecting a mention m i . Please note that BERT BASE model is the latest approach which successfully outperformed in various NLP tasks, including MD. Thus, we reuse this model for the completion of our approach.</p><formula xml:id="formula_2">m i = BERT ? (w i )<label>(1)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Candidate Generation (CG)</head><p>One of the critical focus of CHOLAN is to understand the bottleneck at the CG step. Hence, we reuse the DCA candidate list and propose a novel candidate list to understand the candidate generation impact on overall EL performance. DCA Candidates: <ref type="bibr" target="#b40">(Yang et al., 2019)</ref> adapts the probabilistic entity-map p(e|m) created by (Ganea and Hofmann, 2017) (cf. section 2) to calculate the prior probabilities of candidate entities for a given mention. In the probabilistic entitymap, each entity mention has 30 potential entity candidates. Yang and colleagues also provide associated Wikipedia description of each entity. In CHOLAN, we reuse candidate set C(m) provided by <ref type="bibr" target="#b40">(Yang et al., 2019)</ref> and further consider associated Wikipedia entity descriptions. Falcon Candidates: <ref type="bibr" target="#b29">(Sakor et al., 2019)</ref> created a local index of KG items from Wikidata entities expanded with entity aliases. For example, in Wikidata the entity Q33 2 has the label "Finland". Sakor and colleagues expanded the entity label with other aliases from Wikidata such as "Finlande", "Finnia", "Land of Thousand Lakes", "Suomi", and "Suomen tasavalta". We adopt this local KG index to generate entity candidates per entity mention in the employed datasets. The local KG has a querying mechanism using BM25 ? algorithm (cf. equation <ref type="formula" target="#formula_3">(2)</ref>) and ranked by the calculated score. We build a predefined candidate set using the top 30 Wikidata entity candidates in C F alcon(m) for each entity mention. We enrich the candidates set obtained from Wikidata by the correspondence from Wikipedia. We also add the first paragraph of Wikipedia as entity descriptions (only if Wikidata entity has corresponding Wikipedia page) to the hyperlinks. By selecting two different candidate list, our idea is to understand the impact of candidate generation step on end-to-end entity linking performance.</p><formula xml:id="formula_3">e i = BM 25 ? (m i )<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Entity Disambiguation (ED)</head><p>In order to use the power of the transformers, we propose "WikiBERT" to perform the ED task. In WikiBERT, our novel methodological contribution is the induction of local sentential context and global entity context at the ED step in a transformer model, which has not been used in the recent EL models. WikiBERT is derived from the vanilla BERT BASE model and fine-tuned on the two EL datasets (CoNLL-AIDA and T-REx). We view the ED task as sequence classification task.</p><p>The input to our model is a combination of two sequences. The first sequence S 1 concatenates the entity mention m ? M and sentence W where the sentence acts as a local context. The second sequence S 2 is a concatenation of entity candidate e ? C(m)/C F alcon(m)(obtained from Equation 2) and its corresponding Wikipedia description (entity context ct i ). The two sequences are paired together with special start and separator tokens: ([CLS] S 1 [SEP] S 2 [SEP]). The sequences are fed into the model which in turn learns the input representations according to the architecture of BERT . Any given token (local context word, entity mention, or entity context words) is a summation of the three embeddings : i. Token embedding: refers to the embedding of the corresponding token. We make note here on specific tokens that comprises the input representations for our model more specialised as compared to other fine-tuning tasks. The entity mention tokens appended at the beginning of S 1 and separated from the sentence context tokens by a single vertical token bar |, likewise, for the entity context sequence S 2 , we prepend the entity title tokens from the KB before adding the descriptions. ii. Segment embedding: each of the sequences receive a single representation such that the segment embedding for the local con-text E LC refers to the representation for S 1 whereas E EC is the representation of S 2 iii. Position embedding: represents the position of the token in an input sequence. A token appearing at the i-th position in the input sequence is represented with E i To train the model, we use the negative sampling approach similar to <ref type="bibr" target="#b39">Yamada and Shindo (2019)</ref>. The candidate list is generated for each identified mention. The desired entity candidate item is labelled as one, and the rest of the incorrect candidate items (from candidate list) are labelled as zero for a given mention. This process iterates over all the identified mentions using Equation 1.</p><p>The training process fine-tunes BERT using the contextual input from sentence and Wikipedia resulting into the WikiBERT model (Equation <ref type="formula" target="#formula_4">(3)</ref>). The model predicts the relatedness of the two sequences by classifying it as either positive or negative.  <ref type="bibr" target="#b18">(Hoffart et al., 2011)</ref> and MSNBC, AQUAINT, ACE2004 datasets from <ref type="bibr" target="#b17">(Guo and Barbosa, 2018)</ref>.</p><formula xml:id="formula_4">e i = W ikiBERT (m i , e i , ct i )<label>(3</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Models for Comparison</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Baselines over Wikidata</head><p>We now briefly explain Wikidata baselines. 1. OpenTapioca <ref type="bibr" target="#b9">(Delpeuch, 2020)</ref>: is a heuristicbased end-to-end approach that depends on topic similarity and mapping coherence for linking Wikidata entity in an input text. 2. Arjun <ref type="bibr" target="#b24">(Mulang et al., 2020)</ref>: is a pipeline of two attentive neural networks employed for MD and ED. Arjun is the SotA, and we take baseline values from Arjun's paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Baselines over Wikipedia</head><p>1. <ref type="bibr" target="#b18">(Hoffart et al., 2011)</ref>: build a weighted graph of entity mentions and candidate entities. Then, the model computes a dense subgraph that predicts the best joint mention-entity mapping. 2. DBpedia Spotlight <ref type="bibr" target="#b22">(Mendes et al., 2011)</ref> proposes a probabilistic model and relies on the context of the text to link the entities. 3. KEA <ref type="bibr" target="#b33">(Steinmetz and Sack, 2013</ref>) employs a linguistic pipeline coupled with metadata generated from several Web sources. The candidates are ranked using a heuristic approach. 4. Babelfy <ref type="bibr" target="#b23">(Moro et al., 2014)</ref> is a graph-based approach that uses loose identification of candidate meanings coupled with the densest subgraph heuristic to link the entities. 5. <ref type="bibr" target="#b27">Piccinno and Ferragina (2014)</ref>: to solve entity linking, authors focus on mentions recognition and annotations pruning to propose a voting algorithm for entity candidates using PageRank. 6. <ref type="bibr" target="#b20">Kolitsas et al. (2018)</ref> train MD and ED task jointly using word and character-level embeddings. The model reuses candidate set from (Ganea and Hofmann, 2017) and generates a global voting score to rank the entity candidates. 7. <ref type="bibr" target="#b26">Peters et al. (2019)</ref> induce multiple KBs into a large pretrained BERT model with a knowledge attention mechanism. 8. <ref type="bibr" target="#b3">Broscheit (2019)</ref> trains MD, CG, ED task jointly using a BERT-based model. Besides, an entity vocabulary containing 700K most frequent entities in English Wikipedia was utilised. 9. <ref type="bibr" target="#b14">F?vry et al. (2020)</ref> consider large scale pretraining from Wikipedia links as the context for a transformer model to predict KB entities. In Wikipedia-based experiments, we report values from <ref type="bibr" target="#b14">(F?vry et al., 2020)</ref> and <ref type="bibr" target="#b20">(Kolitsas et al., 2018)</ref> for AIDA-B test set. On MSNBC (MSB), AQUAINT (AQ), and ACE2004 (ACE) test datasets, only <ref type="bibr" target="#b20">(Kolitsas et al., 2018)</ref>, DBpedia Spotlight <ref type="bibr" target="#b22">(Mendes et al., 2011)</ref>, KEA <ref type="bibr" target="#b33">(Steinmetz and Sack, 2013)</ref>, and Babelfy <ref type="bibr" target="#b23">(Moro et al., 2014)</ref> report the values and we compare against them.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Metrics and Hyper-parameters</head><p>On Wikidata-based experiments, we employ standard metrics of accuracy i.e., precision (P), recall (R), and F-score (F) same as <ref type="bibr" target="#b24">(Mulang et al., 2020)</ref>. For Wikipedia-based datasets, we use Micro-F1 score in strong matching setting <ref type="bibr" target="#b20">(Kolitsas et al., 2018)</ref>. The strong matching needs exactly predicting the gold mention (i.e. target entity mention) boundaries and its corresponding entity annotation in the KB. To compare the recalls of two CG approaches, we report the performance on gold recall. Gold recall is the percentage of entity mentions for which the candidate set contain the ground truth entity <ref type="bibr" target="#b41">(Yao et al., 2019)</ref>. We have implemented all our models in PyTorch 3 and optimized using Adam <ref type="bibr" target="#b19">(Kingma and Ba, 2015)</ref>. We used the pre-trained BERT models from the Transformers library <ref type="bibr" target="#b35">(Wolf et al., 2019)</ref>. We ran all the experiments on a single GeForce GTX 1080 Ti GPU with 11GB size. <ref type="table" target="#tab_3">Table 1</ref> outlines the hyper-parameters used in the fine-tuning on both the datasets. We followed the standard settings suggested by . The average run time is 9.31 hours/epoch for CHOLAN and without description, it was 7.23 hours/epoch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We study the following research question:what is the impact of each sub-task (aka component) on the overall outcome of the transformer-based entity linking approach? We further investigate a sub-research question: how do the external context and the candidate generation step impact the overall performance of CHOLAN? Our every experiment systematically studies the research questions in different settings.   <ref type="table" target="#tab_5">Table 2</ref> summarises CHOLAN performance on T-REx dataset. CHOLAN-Wikidata configuration outperforms the baselines. We dig deeper into our reported values. We observe that for MD task, our F-score is 94.3 (compared to 77 F-score of Arjun <ref type="bibr" target="#b24">(Mulang et al., 2020)</ref>). However, the gold recall for CG step is 81.2. We generate the entity candidates using an information retrieval approach (BM25 ? algorithm) to get the top 30 candidates based on the confidence score. The Wikidata KG is challenging, and many labels share the same name. It contributes to a large loss in the F-score for the CG step. For instance, the entity mention "National Highway" matches exactly with four Wikidata ID labels while 2,055 other entities contain the full mention in their labels. Please note that we did not perform retraining of <ref type="bibr" target="#b20">(Kolitsas et al., 2018)</ref> (SOTA on Wikipedia EL) on the T-REx dataset since we determined that the model is tightly coupled and relies on pre-computed Wikipedia candidate list from (Ganea and Hofmann, 2017).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Results on Wikidata dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Ablation Study on Wikidata</head><p>We study the impact of local context on the performance of CHOLAN. Therefore, we exclude the sentence as input in the ED step at training and testing time. Hence, the inputs to the ED model are only entity mention and the entity candidates gained from the CG step. We observe that the performance drops when the local sentential context is not fed (cf.    <ref type="table" target="#tab_11">Table 5</ref> also approves transferability of CHOLAN when we apply cross-domain experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results on Wikipedia datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Ablation Study on Wikipedia</head><p>We conducted three ablation studies to understand the behaviour of CHOLAN's configurations over Wikipedia datasets. The first study    <ref type="bibr" target="#b29">(Sakor et al., 2019)</ref> we observe a drop in the Gold recall as reported in <ref type="table" target="#tab_13">Table 6</ref>. CG plays a crucial role in trading off precision and recall. We conclude that more robust CG approaches likely impact overall performance. The second ablation study is about to calculate the performance of our configurations for ED step, i.e., running WikiB-ERT in isolation. Here, we assume that all entities are truly recognised; thus, our focus of the study is the ED model. We report the impact of various candidate generation approaches on the ED model in <ref type="table" target="#tab_14">Table 7</ref>. The significant jump in the performance from "CHOLAN-Wiki+FC Vs CHOLAN" contributes to the additional background knowledge provided in CHOLAN as entity candidate descriptions. The third ablation study tests the impact of sentential context fed into two configurations on a Wikipedia dataset. <ref type="table">Table 8</ref> reports the achieved performance after excluding sentence as the additional context. Obviously, the performance decreases. The model shows similar be-haviour on T-REx in <ref type="table" target="#tab_6">Table 3</ref>. These observations confirm our hypothesis as the ED model is enhanced using additional contexts.    <ref type="table">Table 8</ref>: Ablation study on AIDA-B. We observe that when local sentential context is removed from ED step, the performance drops. Best values in bold. WLC ? denotes model without local context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>In the last two years, the NLP research community has extensively tried transformer-based models for the EL task. However, the performance remained lower than <ref type="bibr" target="#b20">Kolitsas et al. (2018)</ref>. This paper combines the traditional software engineering principle of modular architecture with the contextinduced transformers to effectively solve the EL task. Our reason to deviate from an end-to-end architecture was to provide full flexibility to our system in terms of candidate generation list, underlying KG, and induction of the context at the ED step. We attribute CHOLAN's outperformance to the following reasons: 1) the modular architecture, which brings flexibility and interoperability as CHOLAN can treat each task independently. <ref type="bibr" target="#b20">Kolitsas et al. (2018)</ref> reports that shifting towards joint modelling of MD and ED tasks helps mitigate error propagation from MD to ED. However, the performance of BERT BASE for the MD task is significantly high (92.3 on AIDA-B and 94.3 F1-score on T-REX calculated by us) remarkably reducing the errors in MD. CHOLAN leverages this capability in the MD subtask, placing more focus on CG and ED tasks.</p><p>2) The flexibility in architecture further permits us to induce sentence and entity descriptions as additional contexts. Furthermore, using candidate list in plug and play manner has resulted in a significant increase in the performance. In earlier transformer approaches, the implementation is monolithic and context is not utilised. There are scopes for improvement in our approach. <ref type="bibr" target="#b36">Wu et al. (2019a)</ref> introduces a novel CG method that retrieves candidates in a dense space defined by a bi-encoder and can be used as alternate CG approach. We aim for scaling CHOLAN to multilingual entity linking as a viable next step.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>CHOLAN has three building blocks: i) BERT-based Mention Detection that identifies entity mentions in the text ii) Candidate Generation that retrieves a set of entities for the mention iii) Entity Disambiguation: employs BERT transformer model powered by background knowledge from KB and local sentential context.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1 :</head><label>1</label><figDesc>Hyper-parameters during fine-tuning.</figDesc><table><row><cell>4.3 CHOLAN Configurations</cell></row><row><cell>We configure CHOLAN model applying various</cell></row><row><cell>candidate generation approaches detailed below.</cell></row><row><cell>CHOLAN-Wikidata: we train the model using T-</cell></row><row><cell>REx dataset and employ C F alcon(m) candidate</cell></row><row><cell>set. The ED model (WikiBERT) is fed with the</cell></row><row><cell>sentential context but not with entity description</cell></row><row><cell>as not all Wikidata entities have a corresponding</cell></row><row><cell>Wikipedia entity.</cell></row><row><cell>CHOLAN-Wiki+FC: is trained on CoNLL-</cell></row><row><cell>AIDA (Hoffart et al., 2011). For CG step, we em-</cell></row><row><cell>ploy Falcon candidate set C F alcon(m). Here,</cell></row><row><cell>the ED model (WikiBERT) is only fed with the</cell></row><row><cell>sentential context.</cell></row><row><cell>CHOLAN-Wiki+DCA: We train the MD and ED</cell></row><row><cell>models on CoNLL-AIDA. The CG step involves</cell></row><row><cell>DCA candidate set C(m). During ED step (Wik-</cell></row><row><cell>iBERT), Wikipedia descriptions associated with</cell></row><row><cell>each entity is fed along with sentential context.</cell></row><row><cell>CHOLAN: inherits CHOLAN-Wiki+FC but in</cell></row><row><cell>addition, Wikipedia entity description is induced</cell></row><row><cell>into the ED model (WikiBERT).</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Comparison on T-REx test set for Wikidata EL. Best values in bold.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>). It justifies our choice to feed the model by the sentence during the ED task.</figDesc><table><row><cell>Model</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>CHOLAN-Wikidata</cell><cell>75</cell><cell>76</cell><cell>75.4</cell></row><row><cell cols="2">CHOLAN-Wikidata (WLC  ? ) 72</cell><cell cols="2">73.5 72.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3 :</head><label>3</label><figDesc>The ablation study on T-REx test set for Wikidata EL. Best values in bold. WLC ? denotes model without local context. When the local sentential context is excluded from ED, the performance drops.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell>reports the performance of CHOLAN's</cell></row><row><cell>configurations on AIDA-B test set. The first</cell></row><row><cell>configuration is "CHOLAN-Wiki+ FC" in which</cell></row><row><cell>MD and ED models are trained using CoNLL-</cell></row><row><cell>AIDA. We notice a clear jump in the perfor-</cell></row><row><cell>mance. We then replaced the Falcon candidate</cell></row><row><cell>list C F alcon(m) with DCA candidates C(m) re-</cell></row><row><cell>sulting into "CHOLAN-Wiki+ DCA". In DCA</cell></row><row><cell>candidates, the description of entities is attached.</cell></row><row><cell>The performance is increased when an additional</cell></row><row><cell>background knowledge as an entity description is</cell></row><row><cell>fed. Our next configuration is CHOLAN where we</cell></row><row><cell>attached Wikipedia entity descriptions in Falcon</cell></row><row><cell>candidate list C F alcon(m) (as a modification of</cell></row><row><cell>"CHOLAN-Wiki+ FC"). This setting outperforms</cell></row><row><cell>all the existing baselines and previous CHOLAN</cell></row><row><cell>configurations. Our experiments illustrate the im-</cell></row><row><cell>pact of CG step and background knowledge on</cell></row><row><cell>end-to-end EL performance. The improvement of</cell></row><row><cell>CHOLAN continues to the other three test datasets</cell></row><row><cell>where the jump is significantly higher compared</cell></row><row><cell>to the baselines (cf. Table 5). Reported values in</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4 :</head><label>4</label><figDesc>Comparison on AIDA-B. Best value in bold and previous SOTA value is underlined.</figDesc><table><row><cell>Model</cell><cell cols="2">MSB AQ</cell><cell>ACE</cell></row><row><cell>Mendes et al. 2011</cell><cell>40.6</cell><cell>45.2</cell><cell>60.5</cell></row><row><cell>Steinmetz and Sack 2013</cell><cell>30.9</cell><cell>35.9</cell><cell>40.3</cell></row><row><cell>Moro et al. 2014</cell><cell>39.7</cell><cell>35.8</cell><cell>17.8</cell></row><row><cell>Kolitsas et al. 2018</cell><cell>72.4</cell><cell>40.4</cell><cell>68.3</cell></row><row><cell>CHOLAN-Wiki+ FC</cell><cell>77.8</cell><cell>70</cell><cell>85.7</cell></row><row><cell>CHOLAN-Wiki+ DCA</cell><cell>78.3</cell><cell>75.9</cell><cell>71.3</cell></row><row><cell>CHOLAN</cell><cell>83.4</cell><cell>76.8</cell><cell>86.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc>The micro F1 scores are listed from the comparative study over three datasets (out of domain). The model is trained over CoNLL-AIDA dataset. Best value in bold and previous SOTA value is underlined.</figDesc><table><row><cell>is to calculate the Gold recall values for vari-</cell></row><row><cell>ous datasets. CHOLAN uses the candidates from</cell></row><row><cell>C F alcon(m) candidate set for each entity men-</cell></row><row><cell>tion. While generating the candidate set from lo-</cell></row><row><cell>cal KG of</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 6 :</head><label>6</label><figDesc>Gold Recall for Candidate Generation techniques over Wikipedia test datasets.</figDesc><table><row><cell>Model</cell><cell>Micro F1</cell></row><row><cell>Kolitsas et al. 2018</cell><cell>83.8</cell></row><row><cell>CHOLAN-Wiki+ FC</cell><cell>78.4</cell></row><row><cell>CHOLAN-Wiki+ DCA</cell><cell>79.1</cell></row><row><cell>CHOLAN</cell><cell>85.7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 7 :</head><label>7</label><figDesc>Comparison on AIDA-B for ED. Best score in bold and previous SOTA value is underlined.</figDesc><table><row><cell>Model</cell><cell>Micro F1</cell></row><row><cell>CHOLAN-Wiki+ DCA</cell><cell>77.5</cell></row><row><cell>CHOLAN-Wiki+ DCA (WLC  ? )</cell><cell>71.2</cell></row><row><cell>CHOLAN</cell><cell>83.1</cell></row><row><cell>CHOLAN (WLC  ? )</cell><cell>79.6</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/ManojPrabhakar/ CHOLAN</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">https://www.wikidata.org/wiki/Q33</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://pytorch.org/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Contextual string embeddings for sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">DBpedia: A Nucleus for a Web of Open Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?ren</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><forename type="middle">G</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Semantic Web, 6th International Semantic Web Conference, 2nd Asian Semantic Web Conference</title>
		<meeting><address><addrLine>Busan, Korea</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-11-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Freebase: A Shared Database of Structured General Human Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><forename type="middle">D</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">P</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Tufts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Investigating entity knowledge in bert with simple neural end-to-end entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><surname>Broscheit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)</title>
		<meeting>the 23rd Conference on Computational Natural Language Learning (CoNLL)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="677" to="685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Neural collective entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="675" to="686" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Bridge text and knowledge by learning multi-prototype entity mention embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juanzi</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1623" to="1633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dexter: an open source framework for entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ceccarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claudio</forename><surname>Lucchese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Orlando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaele</forename><surname>Perego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salvatore</forename><surname>Trani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the sixth international workshop on Exploiting semantic annotations in information retrieval</title>
		<meeting>the sixth international workshop on Exploiting semantic annotations in information retrieval</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A unified architecture for natural language processing: Deep neural networks with multitask learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="160" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A piggyback system for joint entity mention detection and linking in web queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cornolti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Ferragina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimiliano</forename><surname>Ciaramita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>R?d</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hinrich</forename><surname>Sch?tze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th International Conference on World Wide Web</title>
		<meeting>the 25th International Conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="567" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Opentapioca: Lightweight entity linking for wikidata. The 1st Wikidata Workshop co-located with International Semantic Web Conference 2020</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonin</forename><surname>Delpeuch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A joint model for entity analysis: Coreference, typing, and linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the association for computational linguistics</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="477" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">T-rex: A large scale alignment of natural language with knowledge base triples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hady</forename><surname>Elsahar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavlos</forename><surname>Vougiouklis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arslen</forename><surname>Remaci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christophe</forename><surname>Gravier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><forename type="middle">S</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?rique</forename><surname>Laforest</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Simperl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">LREC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Joint entity linking with deep reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongjie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="438" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Empirical evaluation of pretraining strategies for supervised entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thibault</forename><surname>F?vry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Livio Baldini</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Kwiatkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Automated Knowledge Base Construction</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Deep joint entity disambiguation with local neural attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eugen</forename><surname>Octavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2619" to="2629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Message understanding conference-6: A brief history</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sundheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 16th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>COLING</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Robust named entity disambiguation with random walks. Semantic Web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaochen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denilson</forename><surname>Barbosa</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="459" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Robust disambiguation of named entities in text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><forename type="middle">Amir</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilaria</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hagen</forename><surname>F?rstenau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manfred</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilyana</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, UK</addrLine></address></meeting>
		<imprint>
			<publisher>John McIntyre Conference Centre</publisher>
			<date type="published" when="2011-07-31" />
			<biblScope unit="page" from="782" to="792" />
		</imprint>
	</monogr>
	<note>A meeting of SIGDAT, a Special Interest Group of the ACL</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">End-to-end neural entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Kolitsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Octavian-Eugen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd Conference on Computational Natural Language Learning</title>
		<meeting>the 22nd Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="519" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Zero-shot entity linking by reading entity descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lajanugen</forename><surname>Logeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3449" to="3460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">DBpedia spotlight: shedding light on the web of documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andr?s</forename><surname>Garc?a-Silva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<editor>I-SEMANTICS</editor>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Entity linking meets word sense disambiguation: a unified approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Raganato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="231" to="244" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Encoding knowledge graph entity aliases in an attentive neural networks for wikidata entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Isaiah Onando Mulang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akhilesh</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeedeh</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename><surname>Shekarpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><forename type="middle">Esther</forename><surname>Sakor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soren</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Web Information System and Engineering</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">J-nerd: joint named entity recognition and disambiguation with rich linguistic features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Dat Ba Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerhard</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="215" to="229" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Knowledge enhanced contextual word representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Logan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidur</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah A</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="43" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">From tagme to wat: a new entity annotator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesco</forename><surname>Piccinno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Ferragina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the first international workshop on Entity recognition &amp; disambiguation</title>
		<meeting>the first international workshop on Entity recognition &amp; disambiguation</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Wbi-ner: The impact of domain-specific features on the performance of identifying and classifying mentions of drugs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rockt?schel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torsten</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Weidlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulf</forename><surname>Leser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Seventh International Workshop on Semantic Evaluation</title>
		<meeting>the Seventh International Workshop on Semantic Evaluation</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="356" to="363" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (* SEM)</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Old is gold: Linguistic driven approach for entity and relation linking of short text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmad</forename><surname>Sakor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isaiah</forename><forename type="middle">Onando</forename><surname>Mulang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuldeep</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeedeh</forename><surname>Shekarpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria-Esther</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?ren</forename><surname>Auer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2336" to="2346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Introduction to the conll-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">F</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien</forename><surname>De Meulder</surname></persName>
		</author>
		<idno>cs.CL/0306050</idno>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Neural entity linking: A survey of models based on deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozge</forename><surname>Sevgili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Shelmanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikhail</forename><surname>Arkhipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Biemann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A cross-lingual dictionary for english wikipedia concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Valentin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angel X</forename><surname>Spitkovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Semantic multimedia information retrieval based on contextual descriptions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadine</forename><surname>Steinmetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harald</forename><surname>Sack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Extended Semantic Web Conference</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="382" to="396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Wikidata: a new platform for collaborative data collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denny</forename><surname>Vrandecic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21st World Wide Web Conference</title>
		<meeting>the 21st World Wide Web Conference<address><addrLine>Lyon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-04-16" />
			<biblScope unit="page" from="1063" to="1064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R&amp;apos;emi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Brew</surname></persName>
		</author>
		<idno>abs/1910.03771v5</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Josifoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03814</idno>
		<title level="m">Zeroshot entity linking with dense entity retrieval</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Improving distantly supervised relation extraction with neural noise converter and conditional optimal selector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanchan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Third AAAI Conference on Artificial Intelligence, AAAI 2019</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7273" to="7280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A survey on recent advances in named entity recognition from deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vikas</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2145" to="2158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Pretraining of deep contextualized embeddings of words and entities for named entity disambiguation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikuya</forename><surname>Yamada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroyuki</forename><surname>Shindo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.00426</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning dynamic context augmentation for global entity linking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotao</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siliang</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueting</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoping</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="271" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengsheng</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.03193</idno>
		<title level="m">Kg-bert: Bert for knowledge graph completion</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Robust and collective entity disambiguation through semantic embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Zwicklbauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christin</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="425" to="434" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
