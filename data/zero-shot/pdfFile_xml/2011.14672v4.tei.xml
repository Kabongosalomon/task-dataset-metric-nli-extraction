<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D Human Pose and Shape Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicun</forename><surname>Chen</surname></persName>
							<email>zhicunchen@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyuan</forename><surname>Bian</surname></persName>
							<email>biansiyuan@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixin</forename><surname>Yang</surname></persName>
							<email>siriusyang@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
							<email>lucewu@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D Human Pose and Shape Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:47+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Model-based 3D pose and shape estimation methods reconstruct a full 3D mesh for the human body by estimating several parameters. However, learning the abstract parameters is a highly non-linear process and suffers from image-model misalignment, leading to mediocre model performance. In contrast, 3D keypoint estimation methods combine deep CNN network with the volumetric representation to achieve pixel-level localization accuracy but may predict unrealistic body structure. In this paper, we address the above issues by bridging the gap between body mesh estimation and 3D keypoint estimation. We propose a novel hybrid inverse kinematics solution (HybrIK). HybrIK directly transforms accurate 3D joints to relative body-part rotations for 3D body mesh reconstruction, via the twistand-swing decomposition. The swing rotation is analytically solved with 3D joints, and the twist rotation is derived from the visual cues through the neural network. We show that HybrIK preserves both the accuracy of 3D pose and the realistic body structure of the parametric human model, leading to a pixel-aligned 3D body mesh and a more accurate 3D pose than the pure 3D keypoint estimation methods. Without bells and whistles, the proposed method surpasses the state-of-the-art methods by a large margin on various 3D human pose and shape benchmarks. As an illustrative example, HybrIK outperforms all the previous methods by 13.2 mm MPJPE and 21.9 mm PVE on 3DPW dataset. Our code is available at https://github.com/Jeff-sjtu/HybrIK.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recovering the 3D surface from a monocular RGB image is a fundamentally ill-posed problem. It has a wide rage of application scenarios <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b7">8]</ref>. With the development of the parametric statistical human body shape ? Cewu Lu is the corresponding author. He is the member of Qing Yuan Research Institute, Qi Zhi Institute and MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China.  models <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b48">49]</ref>, a realistic and controllable 3D mesh of human body can be generated from only a few parameters, e.g. shape parameters and relative rotations of body parts. Recent studies develop the model-based methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24]</ref> to obtain these parameters from the monocular RGB input and produce 3D pose and shape of human bodies. Most of the model-based methods can be categorized into two classes: optimization-based approach and learning-based approach. Optimization-based approaches <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b48">49]</ref> estimate the body pose and shape by an iterative fitting process. The parameters of the statistical model are tuned to reduce the error between its 2D projection and 2D observations, e.g. 2D joint locations and silhouette. However, the optimization problem is non-convex and takes a long time to solve. The results are sensitive to the initialization. These issues shift the spotlight towards the learning-based approaches. With a parametric body model, learning-based approaches use neural networks to regress the model parameters directly <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b19">20]</ref>. But the parameter space in the statistical model is abstract, making it difficult for the networks to learn the mapping function.</p><p>This challenge prompts us to look into the field of 3D keypoint estimation. Instead of the direct regression, previ-ous methods <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b61">62]</ref> adopt volumetric heatmap as the target representation to learn 3D joint locations and have achieved impressive performance. This inspires us to build a collaboration between the 3D joints and the body mesh ( <ref type="figure" target="#fig_1">Fig. 1</ref>). On the one hand, the accurate 3D joints facilitate the 3D body mesh estimation. On the other hand, the shape prior in parametric body model in turn fixes the unrealistic body structure issue of the 3D keypoint estimation methods. Since the current 3D keypoint estimation methods lack explicit modelling of the distribution of body bone length, it may predict unrealistic body structures like left-right asymmetry and abnormal proportions of limbs. By leveraging the parametric body model, the presented human shape better conforms to the actual human body.</p><p>In this work, we propose a hybrid analytical-neural inverse kinematics solution (HybrIK) to bridge the gap between 3D keypoint estimation and body mesh estimation. Inverse kinematics (IK) process is the mathematical process of finding the relative rotations to produce the desired locations of body joints. It is an ill-posed problem because there is no unique solution. The core of our approach is to propose an innovative IK solution via twist-and-swing decomposition. The relative rotation of a skeleton part is decomposed into twist and swing, i.e. a longitudinal rotation and an in-plane rotation. In HybrIK, we composite the entire rotation recursively along the kinematic tree by analytically calculating swing rotation and predicting twist rotation. A critical characteristic of our approach is that the relative rotation estimated by HybrIK is naturally aligned with the 3D skeleton, without the need for additional optimization procedures in the previous approaches <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b23">24]</ref>. All operations in HybrIK are differentiable, which allows us to simultaneously train 3D joints and human body mesh in an end-to-end manner. Besides, experiments indicate that Hy-brIK raises the performance of body mesh estimation to the same level as 3D keypoint estimation and takes a step forward. The proposed approach is benchmarked in various 3D human pose and shape datasets, and it significantly outperforms state-of-the-art approaches <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b39">40]</ref> by 21.9 mm PVE on 3DPW [69], 6.6 mm PA-MPJPE on Human3.6M <ref type="bibr" target="#b15">[16]</ref> and 10.8 AUC on MPI-INF-3DHP <ref type="bibr" target="#b34">[35]</ref>.</p><p>The contributions of our approach can be summarized as follows:</p><p>? We propose HybrIK, a hybrid analytical-neural IK solution that converts the accurate 3D joint locations to full 3D human body mesh. HybrIK is differentiable and allows end-to-end training.</p><p>? Our approach closes the loop between the 3D skeleton and the parametric model. It fixes the alignment issue of current model-based body mesh estimation methods and the unrealistic body structure problem of 3D keypoint estimation methods at the same time.</p><p>? Our approach achieves state-of-the-art performance across various 3D human pose and shape benchmarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>3D Keypoint Estimation. Many works formulate 3D human pose estimation as the problem of locating the 3D joints of the human body. Previous studies can be divided into two categories: single-stage and two-stage approaches.</p><p>Single-stage approaches <ref type="bibr" target="#b50">[51,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b75">76,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b70">71]</ref> directly estimate the 3D joint locations from the input image. Various representations are developed, including 3D heatmap <ref type="bibr" target="#b50">[51]</ref>, location-map <ref type="bibr" target="#b35">[36]</ref> and 2D heatmap + z regression <ref type="bibr" target="#b75">[76]</ref>. Two-stage approaches first estimate 2D pose and then lift them to 3D joint locations by a learned dictionary of 3D skeleton <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b77">78,</ref><ref type="bibr" target="#b78">79]</ref> or regression <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b72">73,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b60">61]</ref>. Two-stage approaches highly rely on the accurate 2D pose estimators, which have achieved impressive performance by the combination of powerful backbone network <ref type="bibr" target="#b59">[60,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref> and the 2D heatmap. These privileged forms of supervision contribute to the recent performance leaps of 3D keypoint estimation. However, the human structural information is modelled implicitly by the neural network, which can not ensure the output 3D skeletons to be realistic. Our approach combines the advantages of both the 3D skeleton and parametric model to predict accurate and realistic human pose and shape.</p><p>Model-based 3D Pose and Shape Estimation. Pioneer works on the model-based 3D pose and shape estimation methods use parametric human body model <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b48">49]</ref> as the output target because they capture the statistics prior of body shape. Compared with the model-free methods <ref type="bibr" target="#b66">[67,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b39">40]</ref>, the model-based methods directly predict controllable body mesh, which can facilitate many downstream tasks for both computer graphics and computer vision. Bogo et al. <ref type="bibr" target="#b6">[7]</ref> propose SMPLify, a fully automatic approach, without manual user intervention <ref type="bibr" target="#b58">[59,</ref><ref type="bibr" target="#b12">13]</ref>. This optimization paradigm was further extended with silhouette cues <ref type="bibr" target="#b26">[27]</ref>, volumetric grid <ref type="bibr" target="#b66">[67]</ref>, multiple people <ref type="bibr" target="#b74">[75]</ref> and whole-body parametric model <ref type="bibr" target="#b48">[49]</ref>.</p><p>With the advances of the deep learning networks, there are increasing studies that focus on the learning-based methods, using a deep network to estimate the pose and shape parameters. Since the mapping from RGB image to shape space and relative body-part rotation is hard to learn, many works use some form of intermediate representation to alleviate this problem, such as keypoints and silhouettes <ref type="bibr" target="#b51">[52]</ref>, semantic part segmentation <ref type="bibr" target="#b44">[45]</ref> and 2D heatmap input <ref type="bibr" target="#b64">[65]</ref>. Kanazawa et al. <ref type="bibr" target="#b17">[18]</ref> use an adversarial prior and an iterative error feedback (IEF) loop to reduce the difficulty of regression. Arnab et al. <ref type="bibr" target="#b3">[4]</ref> and Kocabas et al. <ref type="bibr" target="#b19">[20]</ref> exploit temporal context, while Guler et al. <ref type="bibr" target="#b13">[14]</ref> use a part-voting expression and test-time post-processing to improve the regression network. Kolotouros et al. <ref type="bibr" target="#b23">[24]</ref> leverage the optimization paradigm to provide extra 3D supervision from unlabeled images.</p><p>In this work, we address this challenging learning problem by a transformation from the pixel-aligned 3D joints to the relative body-part rotations.</p><p>Body-part Rotation in Pose Estimation. The core of our approach is to calculate the relative rotation of human body parts through a hybrid IK process. There are several works that estimate the relative rotations in the 3D pose estimation literature. Zhou et al. <ref type="bibr" target="#b76">[77]</ref> use the network to predict the rotation angle of each body joint, followed by an FK layer to generate the 3D joint coordinates. Pavllo et al. <ref type="bibr" target="#b52">[53]</ref> switch to quaternions, while Yoshiyasu et al. <ref type="bibr" target="#b73">[74]</ref> directly predict the 3 ? 3 rotation matrices. Mehta et al. <ref type="bibr" target="#b36">[37]</ref> first estimate the 3D joints and then use a fitting procedure to find the rotation Euler angles. Previous approaches are either limited to a hard-to-learn problem or require an additional fitting procedure. Our approach recovers the body-part rotation from 3D joint locations in a direct, accurate and feedforward manner.</p><p>Inverse Kinematics Process. The inverse kinematics (IK) problem has been extensively studied during recent decades. Numerical solutions <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b71">72,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b69">70,</ref><ref type="bibr" target="#b8">9]</ref> are simple ways to implement the IK process, but they suffer from time-consuming iterative optimization. Heuristic methods are efficient solutions to the IK problem. For example, CDC <ref type="bibr" target="#b31">[32]</ref>, FABRIK <ref type="bibr" target="#b2">[3]</ref> and IK-FA <ref type="bibr" target="#b56">[57]</ref> have a low computational cost for each heuristic iteration. In some special cases, there exist analytical solutions to the IK problem. Tolani et al. <ref type="bibr" target="#b63">[64]</ref> propose a reliable algorithm by the combination of analytical and numerical methods. Kallmann et al. <ref type="bibr" target="#b16">[17]</ref> solve the IK for arm linkage, i.e. a threejoint system. Recently, researchers have been interested in using neural networks to solve the IK problem in robotic control <ref type="bibr" target="#b9">[10]</ref>, motion retargeting <ref type="bibr" target="#b67">[68]</ref> and hand pose estimation <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b22">23]</ref>.</p><p>In this work, we combine the interpretable characteristic of analytical solution and the flexibility of the neural network, introducing a feed-forward hybrid IK algorithm with twist-and-swing decomposition. Twist-and-swing decomposition is introduced by Baerlocher et al. <ref type="bibr" target="#b4">[5]</ref>. The twist angles are limited based on the particular body joint. In our works, the twist angles are estimated by neural networks, which is more flexible and can be generalized to all body joints. Compared with previous analytical solutions <ref type="bibr" target="#b16">[17]</ref> designed for specific joint linkage, our algorithm can be applied to the entire body skeleton in a direct and differentiable manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In this section, we present our hybrid analytical-neural inverse kinematics solution that boosts 3D human pose and shape estimation ( <ref type="figure">Fig. 2</ref>). First, in ?3.1, we briefly describe the forward kinematics process, the inverse kinematics process and the SMPL model. In ?3.2, we introduce the proposed inverse kinematics solution, HybrIK. Then, in ?3.3, we present the overall learning framework to estimate the pixel-aligned body mesh and realistic 3D skeleton. Finally, we provide the necessary implementation details in ?3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminary</head><p>Forward Kinematics. Forward kinematics (FK) for human pose usually refers to the process of computing the reconstructed pose Q = {q k } K k=1 , with the rest pose template</p><formula xml:id="formula_0">T = {t k } K k=1 and the relative rotations R = {R pa(k),k } K k=1</formula><p>as input:</p><formula xml:id="formula_1">Q = FK(R, T),<label>(1)</label></formula><p>where K is the number the body joints, q k ? R 3 denotes the reconstructed 3D location of the k-th joint, t k ? R 3 denotes the k-th joint location of the rest pose template, pa(k) return the parent's index of the k-th joint, and R pa(k),k is the relative rotation of k-th joint with respect to its parent joint. FK can be performed by recursively rotating the template body part from the root joint to the leaf joints:</p><formula xml:id="formula_2">q k = R k (t k ? t pa(k) ) + q pa(k) ,<label>(2)</label></formula><p>where R k ? SO(3) is the global rotation of the k-th joint with respect to the canonical rest pose space. The global rotation can be calculated recursively:</p><formula xml:id="formula_3">R k = R pa(k) R pa(k),k .<label>(3)</label></formula><p>For the root joint that has no parent, we have q 0 = t 0 .</p><p>Inverse Kinematics. Inverse kinematics (IK) is the reverse process of FK, computing relative rotations R that can generate the desired locations of input body joints P = {p k } K k=1 . This process can be formulated as:</p><formula xml:id="formula_4">R = IK(P, T),<label>(4)</label></formula><p>where p k denotes the k-th joint of the input pose. Ideally, the resulting rotations should satisfy the following condition:</p><formula xml:id="formula_5">p k ? p pa(k) = R k (t k ? t pa(k) ) ?1 ? k ? K. (5)</formula><p>Similar to the FK process, we have p 0 = t 0 for the root joint that has no parent. While the FK problem is well-posed, the IK problem is ill-posed because there is either no solution or because there are many solutions to fulfill the target joint locations.</p><formula xml:id="formula_6">CNN deconv HybrIK ? ? ? M(?, ?) Input Image Regressed Pose Reconstructed Mesh Rest Pose P T Reconstructed Pose M FK or Regressor Q fully-connected Figure 2.</formula><p>Overview of the proposed framework. A 3D heatmap is generated by the deconvolution layers and used to regress the 3D joints P. The shape parameters ? and the twist angle ? are learned from the visual cues through the fully-connected layers. These results are then sent to the HybrIK process to solve the relative rotation, i.e. the pose parameters ?. Finally, with the pose and shape parameters, we can obtain the reconstructed body mesh M , and the reconstructed pose Q via a further FK process or linear regression. SMPL Model. In this work, we employ the SMPL <ref type="bibr" target="#b30">[31]</ref> parametric model for human body representation. SMPL allows us to use shape parameters and pose parameters to control the full human body mesh. The shape parameters ? ? R 10 are parameterized by the first 10 principal components of the shape space. The pose parameters ? are modelled by relative 3D rotation of K = 23 joints, ? = (? 1 , ? 2 , ? ? ? , ? K ). SMPL provides a differentiable function M(?, ?) that takes the pose parameters ? and the shape parameters ? as input and outputs a triangulated mesh M ? R N ?3 with N = 6980 vertices. Conveniently, the reconstructed 3D joints Q smpl can be obtained by an FK process, i.e. Q smpl = FK(R, T). Also, the joints of Human3.6M <ref type="bibr" target="#b15">[16]</ref> can be obtained by a linear combination of the mesh vertices through a linear regressor W , i.e. Q h36m = W M .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Hybrid Analytical-Neural Inverse Kinematics</head><p>Estimating the human body mesh by direct regression of the relative rotations is too difficult <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b19">20]</ref>. Here, we propose a hybrid analytical-neural inverse kinematics solution (HybrIK) to leverage 3D keypoints estimation to boost 3D body mesh estimation. Since 3D joints cannot uniquely determine the relative rotation, we decompose the original rotation into twist and swing. The 3D joints are utilized to calculate the swing rotation analytically, and we exploit the visual cues by a neural network to estimate the 1-DoF twist rotation. In HybrIK, the relative rotations are solved recursively along the kinematic tree. We conduct error analysis and further develop an adaptive solution to reduce the reconstruction error.</p><p>Twist-and-Swing Decomposition. In the analytical IK formulation, some body joints are usually assigned lower degree-of-freedom (DoFs) to simplify the problem, e.g. 1 or 2 DoFs <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b63">64,</ref><ref type="bibr" target="#b16">17]</ref>. In this work, we consider a gen-  eral case where each body joint is assumed to have full 3 DoFs. As illustrated in <ref type="figure" target="#fig_3">Fig. 3</ref>, a rotation R ? SO(3) can be decomposed into a twist rotation R tw and a swing rotation R sw . Given the start template body-part vector t and the target vector p, the solution process of R can be formulated as:</p><formula xml:id="formula_7">R = D( p, t, ?) = D sw ( p, t)D tw ( t, ?) = R sw R tw ,<label>(6)</label></formula><p>where ? is the twist angle that estimated by a neural network, D sw (?) is a closed-form solution of the swing rotation, and D tw (?) transforms ? to the twist rotation. Here, R should satisfy the condition in Eq. 5, i.e. p = R t.</p><p>-Swing: The swing rotation has the axis n that is perpendicular to t and p. Therefore, it can be formulated as:</p><formula xml:id="formula_8">n = t ? p t ? p ,<label>(7)</label></formula><p>and the swing angle ? satisfies:</p><formula xml:id="formula_9">cos ? = t ? p t p , sin ? = t ? p t p .<label>(8)</label></formula><p>Hence, the closed-form solution of the swing rotation R sw can be derived by the Rodrigues formula:</p><formula xml:id="formula_10">R sw = D sw ( p, t) = I + sin ?[ n] ? + (1 ? cos ?)[ n] 2 ? ,<label>(9)</label></formula><p>where [ n] ? is the skew symmetric matrix of n and I is the 3 ? 3 identity matrix.</p><p>-Twist: The twist rotation is rotating around t itself. Thus, with t itself the axis and ? the angle, we can determine twist rotation R tw :</p><formula xml:id="formula_11">R tw = D tw ( t, ?) = I + sin ? t [ t] ? + (1 ? cos ?) t 2 [ t] 2 ? ,<label>(10)</label></formula><p>where [ t] ? is the skew symmetric matrix of t.</p><p>Note that function D sw and D tw are fully differentiable, which allows us to integrate the twist-and-swing decomposition into the training process. Although we need a neural network to learn the twist angle, the difficulty of learning is significantly reduced. Compared with the 3-DoF rotation that is directly regressed in previous work <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b19">20]</ref>, the twist angle is only a 1-DoF variable. Moreover, due to the physical limitation of the human body, the twist angle has a small range of variation. Therefore, it is much easier for the networks to learn the mapping function. We further analyze its variation in ?4.2.</p><p>Naive HybrIK. The IK process can be performed recursively along the kinematic tree like the FK process. First of all, we need to determine the global root rotation R 0 , which has a closed-form solution using the locations of spine, left hip, right hip and Singular Value Decomposition (SVD). Detailed mathematical proof is provided in the supplemental document. Then, in each step, e.g. the k-th step, we assume the rotation of the parent joint R pa(k) is known. Hence, we can reformulate Eq. 5 with Eq. 3 as:</p><formula xml:id="formula_12">R ?1 pa(k) (p k ? p pa(k) ) = R pa(k),k (t k ? t pa(k) ).<label>(11)</label></formula><p>Let p k = R ?1 pa(k) (p k ? p pa(k) ) and t k = (t k ? t pa(k) ), we can solve the relative rotation via Eq. 6:</p><formula xml:id="formula_13">R pa(k),k = D( p k , t k , ? k ),<label>(12)</label></formula><p>where ? k is the network predicting twist angle for the k-th joint. The set of twist angle is denoted as ? = {? k } K k=1 . Since the rotation matrices are orthogonal, their inverse equals to their transpose, i.e. R ?1 pa(k) = R T pa(k) , which keeps the solving process differentiable.</p><p>The whole process is named Naive HybrIK and summarized in Alg. 1. Note that we solve the relative rotation Algorithm 1: Naive HybrIK Input: P, T, ? Output: R 1 Determine R 0 ; 2 for k along the kinematic tree do</p><formula xml:id="formula_14">3 p k ? R ?1 pa(k) (p k ? p pa(k) ); 4 t k ? (t k ? t pa(k) ); 5 R sw pa(k),k ? D sw ( p k , t k ); 6 R tw pa(k),k ? D tw ( t k , ? k ); 7 R pa(k),k ? R sw pa(k),k R tw pa(k),k ;</formula><p>R pa(k),k instead of the global rotation R k . The reason is that if we directly decompose the global rotation, the resulting twist angle will depend on all ancestors' rotations along the kinematic tree, which increases the variation of the distal limb joints and the difficulty for the network to learn.</p><p>Adaptive HybrIK. Although the Naive HybrIK process seems effective, it follows an unstated hypothesis: p k ? p pa(k) = t k ? t pa(k) . Otherwise, there is no solution for Eq. 5. Unfortunately, in our case, the body-parts predicted by the 3D keypoint estimation method are not always consistent with the rest pose template. In Naive HybrIK, Eq. 6 can still be solved because the condition is turned into:</p><formula xml:id="formula_15">p k ? p pa(k) = R k (t k ? t pa(k) ) + k ,<label>(13)</label></formula><p>where k denotes the error in the k-th step, which has the same direction of p k ? p pa(k) and k = | p k ? p pa(k) ? t k ? t pa(k) |. To analyze the reconstruction error, we compare the difference between the input pose P and the reconstructed pose Q:</p><formula xml:id="formula_16">P ? Q ? K k=1 p k ? q k ,<label>(14)</label></formula><p>where Q = FK(R, T) = FK(IK(P, T), T). Combining Eq. 2 and Eq. 13, we have:</p><formula xml:id="formula_17">p k ? q k = p pa(k) ? q pa(k) + k = p pa 2 (k) ? q pa 2 (k) + pa(k) + k = . . . = i?A(k) i ,<label>(15)</label></formula><p>where pa 2 (k) denotes the parent index of the pa(k)-th joint, and A(k) denotes the set of ancestors of the k-th joint. That means the difference between the input joint p k and the reconstructed joint q k will accumulate along the kinematic tree, which brings more uncertainty to the distal joint.</p><p>To address this error accumulation problem, we further propose Adaptive HybrIK. In Adaptive HybrIK, the target Naive HybrIK</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adaptive HybrIK</head><p>Network-predicted 3D Joints</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reconstructed Joints from Adaptive HybrIK</head><p>Reconstructed Joints from Naive HybrIK</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rest Pose Template</head><p>Step 1</p><p>Step 2</p><p>Step 1</p><p>Step <ref type="formula" target="#formula_2">2</ref>   <ref type="figure">Figure 4</ref>. Example of the reconstruction error. The rest pose is rotated to q1 and q2 by two steps. In the first step, due to the bonelength inconsistency, the reconstruction error is 1. In the second step, Naive HybrIK takes p2 ? p1 as the target direction, resulting in the accumulation of error 1 + 2. Instead, Adaptive HybrIK selects the reconstructed joint q1 to form the target direction p2 ? q1, which reduces the error to only 2.</p><p>vector is adaptively updated by the newly reconstructed parent joints. Let p k = R ?1 pa(k) (p k ? q pa(k) ) and t k the same as the one in the naive solution. In this way, the condition in Adaptive HybrIK can be formulated as:</p><formula xml:id="formula_18">p k ? q pa(k) = R k (t k ? t pa(k) ) + k .<label>(16)</label></formula><p>Therefore, we have:</p><formula xml:id="formula_19">p k ? q pa(k) = q k ? q pa(k) + k ? p k ? q k = k .<label>(17)</label></formula><p>Compared to the naive solution (Eq. 15), the reconstructed error of the adaptive solution only depends on the current joint and will not accumulate from its ancestors. As illustrated in <ref type="figure">Fig. 4</ref>, in Naive HybrIK, once the parent joint is out of position, its children will continue this mistake. Instead, in Adaptive HybrIK, the solved relative rotation is always pointing towards the target joint and reduce the error. We conduct empirical experiments in ?4.2 to validate its robustness. Note that an iterative global optimization process can further reduce the error, but it is non-differentiable and does not allow end-to-end training. Adaptive HybrIK is robust enough and remains differentiable. The whole process is summarized in Alg. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Learning Framework</head><p>The overall framework of our approach is illustrated in <ref type="figure">Fig. 2</ref>. Firstly, a neural network is utilized to predict 3D joints P, the twist angle ? and the shape parameters ?. Secondly, the shape parameters are used to obtain the rest pose T by the SMPL model. Then, by combining P, T and ?, we perform HybrIK to solve the relative rotations R of the 3D pose, i.e. the pose parameters ?. Finally, with the function M(?, ?) provided by the SMPL model, the body mesh M is obtained. The reconstructed pose Q can be obtained from M by FK or a regressor, which is guaranteed to be realistic. Since the HybrIK process is differentiable, the whole framework is trained in an end-to-end manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2: Adaptive HybrIK</head><p>Input: P, T, ? Output: R 1 Determine R 0 ; 2 for k along the kinematic tree do</p><formula xml:id="formula_20">3 q pa(k) ? R pa(k) (t pa(k) ? t pa 2 (k) ) + q pa 2 (k) ; 4 p k ? R ?1 pa(k) (p k ? q pa(k) ); 5 t k ? (t k ? t pa(k) ); 6 R sw pa(k),k ? D sw ( p k , t k ); 7 R tw pa(k),k ? D tw ( t k , ? k ); 8 R pa(k),k ? R sw pa(k),k R tw pa(k),k ;</formula><p>3D Keypoint Estimation. We adopt a simple yet effective architecture to estimate the 3D body keypoints. Following <ref type="bibr" target="#b61">[62]</ref>, we use ResNet as our backbone and 3 deconvolution layers followed by a 1 ? 1 convolution to generate the 3D heatmaps. The soft-argmax operation is used to obtain 3D pose from the heatmap in a differentiable manner. We supervise the predicted pose coordinates with 1 loss:</p><formula xml:id="formula_21">L pose = 1 K K k=1 p k ?p k 1 ,<label>(18)</label></formula><p>wherep k denotes the ground-truth joint.</p><p>Twist Angle Estimation. Instead of the direct regression of scalar value ? k , we choose to learn a 2-dimensional vector (c ? k , s ? k ) that represents cos ? k and sin ? k to avoid the discontinuity problem. The 2 loss is applied:</p><formula xml:id="formula_22">L tw = 1 K K k=1 (c ? k , s ? k ) ? (cos? k , sin? k ) 2 ,<label>(19)</label></formula><p>where? k denotes the ground-truth twist angle.</p><p>Collaboration with SMPL. The SMPL model allows us to obtain the rest pose skeleton with the additive offsets according to the shape parameters ?:</p><formula xml:id="formula_23">T = W (M T + B S (?)),<label>(20)</label></formula><p>whereM T is the mesh vertices of mean rest pose, and B S (?) is the blend shapes function provided by SMPL. Then the pose parameters ? are calculated by HybrIK in a differentiable manner. In the training phase, we supervise the shape parameters ?:</p><formula xml:id="formula_24">L shape = ? ?? 2 ,<label>(21)</label></formula><p>and the rotation parameters ?: The overall loss of the learning framework is formulated as:</p><formula xml:id="formula_25">L rot = ? ?? 2 .<label>(22)</label></formula><formula xml:id="formula_26">L = L pose + ? 1 L shape + ? 2 L rot + ? 3 L tw ,<label>(23)</label></formula><p>where ? 1 , ? 2 and ? 3 are weights of the loss items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Implementation Details</head><p>Here we elaborate more implementation details. We use ResNet-34 <ref type="bibr" target="#b14">[15]</ref> as the network backbone, initialized with ImageNet pre-trained weights. The ResNet output is divided into two branches. The first branch is to generate 3D heatmaps. The second branch consists of an average pooling, two fully-connected layers with 1024 neurons (each with a dropout layer in between) and a final layer of 56 neurons (10 for ?, 46 for ?). The input image is resized to 256 ? 192. The learning rate is set to 1 ? 10 ?3 at first and reduced by a factor of 10 at the 90th and 120th epoch. We use the Adam solver and train for 140 epochs, with a mini-batch size of 32 per GPU and 8 GPUs in total. In all experiments, ? 1 = 1 and ? 2 = ? 3 = 1 ? 10 ?2 . In the testing phase, the absolute depth of the root joint is obtained from RootNet <ref type="bibr" target="#b38">[39]</ref>. Implementation is in PyTorch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Empirical Evaluation</head><p>In this section, we first describe the datasets employed for training and quantitative evaluation. Next, ablation experiments are conducted to evaluate the proposed HybrIK. Finally, we report our results and compare the proposed method with state-of-the-art approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets</head><p>3DPW: It is a challenging outdoor benchmark for 3D pose and shape estimation. We use this dataset for both training and evaluation. MPI-INF-3DHP: It consists of both constrained indoor and complex outdoor scenes. Following <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24]</ref>, we use its train set for training and evaluate on its test set. Human3.6M: It is an indoor benchmark for 3D pose estimation. Following <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24]</ref>, we use 5 subjects (S1, S5, S6, S7, S8) for training and 2 subjects (S9, S11) for evaluation. MSCOCO: It is a large-scale in-the-wild 2D human pose datasets. We incorporate its train set for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Study</head><p>In this study, we evaluate the effectiveness of the twistand-swing decomposition and the HybrIK algorithm. All evaluation is conducted on the 3DPW test set as it contains challenging in-the-wild scenes to demonstrate the strength of our model. More experimental results are provided in the supplemental document.</p><p>Analysis of the twist rotation. To demonstrate the effectiveness of twist-and-swing decomposition, we first count the distribution of the twist angle in the 3DPW test set. The distribution is illustrated in <ref type="figure" target="#fig_5">Fig. 5</ref>. As expected, due to the physical limitation, only neck, elbow and wrist have a wide range of variations. All other joints have a limited range of twist angle (less than 30 ? ). It indicates that the twist angle can be reliably estimated.</p><p>Besides, we develop an experiment to see how the twist angles affect the reconstructed pose and shape. We take the ground-truth 24 SMPL joints and shape parameters as the input of the HybrIK process. As for the twist angle, we compare random values in [??, ?] and the values estimated by the network. We evaluation the mean error of the reconstructed 24 SMPL joints, the 14 LSP joints, the body mesh and the twist angle. Here, following previous works <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b23">24]</ref>, the 14 LSP joints are regressed from the body mesh by a pretrained regressor. Quantitative results are reported in Tab. 1. It shows that the accurate regressed twist angles significantly reduce the error on the mesh vertices and the LSP joints that regressed from the mesh. Since most of the twist angles are close to zeros, the zero twist angles produce acceptable performance. Notice that the wrong twist angles do not affect the reconstructed SMPL joints. Only the swing rotations change the joint locations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Robustness of HybrIK.</head><p>To demonstrate the superiority of Adaptive HybrIK over Naive HybrIK, we compare the reconstructed joints error of these two algorithms. First, we feed the ground-truth joints, twist angle and shape parameters to the two IK algorithms to see whether they will introduce extra error. Then we add jitters to the input to observe the performance of the HybrIK algorithm with the Error correction capability of HybrIK. In this experiment, we examine the error correction capability of the HybrIK algorithm. The HybrIK algorithm is fed with the 3D joints, twist angles and shape parameters that predicted by the neural network. Additionally, we apply the SM-PLify <ref type="bibr" target="#b6">[7]</ref> algorithm on the predicted pose and compare it to our method. As shown in Tab. 4, the error of reconstructed joints after HybrIK is reduced the error to 79.2mm, while SMPLify raises the error to 114.3 mm. The error correction capability of HybrIK comes from the fact that the network may predict unrealistic body pose, e.g. left-right asymmetry and abnormal limbs proportions. In contrast, the rest pose is generated by the parametric statistical body model, which guarantees that the reconstructed pose is consistent with the realistic body shape distribution. Since our proposed framework is agnostic to the way we obtain 3D joints, we can improve the performance of any single-stage 3D keypoint estimation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison with the State-of-the-art</head><p>To make a fair comparison with previous 3D human pose and shape estimation methods, we use a regressor to obtain the 14 LSP joints from the body mesh for the evaluation on 3DPW and Human3.6M datasets and 17 joints for In Tab. 2, we compare our method with previous 3D human pose and shape estimation methods, including both model-based and model-free methods, on 3DPW, Hu-man3.6M and MPI-INF-3DHP datasets. Without bells and whistles, our method surpasses all previous state-of-the-art methods by a large margin on all three datasets. It is worth noting that our method improve 21.9 mm PVE on 3DPW dataset, which shows that it is accurate and reliable to recover body mesh through inverse kinematics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we bridge the gap between 3D keypoint estimation and body mesh estimation via a novel hybrid analytical-neural inverse kinematics solution, HybrIK. It transforms the 3D joint locations to a pixel-aligned accurate human body mesh, and then obtains a more accurate and realistic 3D skeleton from the reconstructed 3D mesh, closing the loop between the 3D skeleton and the parametric body model. Our method is fully differentiable and allows simultaneously training of 3D joints and human body mesh in an end-to-end manner. We demonstrate the effectiveness of our method on various 3D pose and shape datasets. The proposed method surpasses state-of-the-art methods by a large margin. Besides, comprehensive analyses demonstrate that HybrIK is robust and has error correction capability. We hope HybrIK can serve as a solid baseline and provide a new perspective for the 3D human pose and shape estimation task.</p><p>Note that U , V and R are orthogonal matrices, so M = V T RU is also an orthogonal matrix. Then, for all 1 ? j ? we have:</p><formula xml:id="formula_27">m T j m j = 1 = 3 i=1 m 2 ij ? m 2 ij ? 1 ? |m ij | ? 1.<label>(31)</label></formula><p>Besides, ? is a diagonal matrix with non-negative values, i.e. ? 1 , ? 2 , ? 3 ? 0. Therefore:</p><p>trace(?V T RU ) = trace(?M )</p><formula xml:id="formula_28">= 3 i=1 ? i m ii ? 3 i=1 ? i .<label>(32)</label></formula><p>The trace is maximized if m ii = 1, ?1 ? i ? 3. That means M = I, where I is the identity matrix. Finally, the optimal rotation R 0 is:  <ref type="table">Table 5</ref>. Reconstruction error with different shape parameters ?.</p><formula xml:id="formula_29">V T R 0 U = I ? R 0 = V U T .<label>(33</label></formula><p>Effect of ? In this experiment, we analyze the effect of the shape parameters ? in Tab. 5. Using the ground-truth ? brings 5 mm improvement of MPJPE and PVE on 3DPW dataset. Using zero ? brings 1 mm error. It shows that there are lots of room for improvement by estimating more accurate ?.</p><p>Comparison with Baseline Models In this experiment, we compare HybrIK with two baselines to validate its effectiveness. Firstly, we want th compare with the model that directly predicts SMPL parameters without any auxiliary loss. This model is a degraded version of HMR <ref type="bibr" target="#b17">[18]</ref>. We find it is hard to train and the model learns limited information. The model achieves over 100 mm error on Hu-man3.6M <ref type="bibr" target="#b15">[16]</ref>. Secondly, we add 3D keypoint prediction to help the network to extract features. The model still learns to predict SMPL parameters directly. However, still over 100 mm error achieves on Human3.6M <ref type="bibr" target="#b15">[16]</ref> dataset. Error correction capability of HybrIK In this experiment, we examine the error correction capability of HybrIK on 3DPW <ref type="bibr" target="#b68">[69]</ref> and Human3.6M <ref type="bibr" target="#b15">[16]</ref> datasets. Quantitative results are reported in Tab. 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Qualitative Results</head><p>Fig <ref type="figure" target="#fig_6">. 6</ref> provides qualitative results of our approach from the different datasets involved in our experiments (LSP, MPI-INF-3DHP, Human3.6M, 3DPW). <ref type="figure" target="#fig_7">Fig. 7</ref> includes typical failure cases that are attributed to erroneous bone length estimation (shape parameters ?) and 3D keypoint estimation, which lead to misalignment and unnatural joint bending, respectively.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Closing the loop between the 3D skeleton and the parametric model via HybrIK. A 3D skeleton predicted by the neural network can be transformed into a parametric body mesh by inverse kinematics without loss of accuracy. The parametric body mesh can generate structural realistic 3D skeleton by forward kinematics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Twist-and-Swing Decompostiont p p = R t p = R sw R tw t</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of the twist-and-swing decomposition. (a) The original rotation turns the right palm-down hand to the front and the palm to the left in one step. (b) With twist-and-swing decomposition, the rotation can be divided into two steps: First, turn the palm 90 ? , and then move the entire hand to the front.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Distribution of the twist angle. Only a few joints have a range over 30 ? . Other joints have a limited range of twist angle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Qualitative results from various datasets, LSP (rows 1-3), MPI-INF-3DHP (row 4), 3DPW (rows 5-6), H36M (rows 7-8).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 7 .</head><label>7</label><figDesc>Erroneous reconstructions of our method. Typical failure cases can be attributed to inaccurate bone length estimation (shape parameters ?) and 3D keypoint estimation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>jts 14 jts Vert. 24 jts 14 jts Vert. 24 jts 14 jts Vert. Reconstruction error with different twist angle. The accurate twist angles significantly reduce the reconstruction error.</figDesc><table><row><cell>Random Twist</cell><cell cols="2">Estimated Twist</cell><cell>Zero Twist</cell></row><row><cell cols="2">24 Error 0.1 40.0 67.3 0.1</cell><cell cols="2">6.1 10.0 0.1</cell><cell>6.8 12.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>MPJPE ? PVE ? PA-MPJPE ? MPJPE ? PCK ? AUC ? MPJPE ? Naive vs. Adaptive with different input joints. MPJPE of 24 joints is reported. Adaptive HybrIK is more robust to the jitters. noisy joints. As shown in Tab. 3, when the input joints are correct, both HybrIK algorithms introduce negligible errors. For noisy joints input, the Naive HybrIK algorithm accumulates errors along the kinematic tree, while the Adaptive HybrIK algorithm is more robust to the noise.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>3DPW</cell><cell></cell><cell cols="2">Human3.6M</cell><cell></cell><cell>MPI-INF-3DHP</cell></row><row><cell cols="4">Method PA-MPJPE ? SMPLify [7] -</cell><cell>-</cell><cell>-</cell><cell>82.3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>HMR [18]</cell><cell></cell><cell></cell><cell>81.3</cell><cell>130.0</cell><cell>-</cell><cell>56.8</cell><cell>88.0</cell><cell>72.9</cell><cell>36.5</cell><cell>124.2</cell></row><row><cell>Kolotouros et al. [26]</cell><cell></cell><cell></cell><cell>70.2</cell><cell>-</cell><cell>-</cell><cell>50.1</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Pavlakos et al. [52]</cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>75.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Arnab et al. [4]</cell><cell></cell><cell></cell><cell>72.2</cell><cell>-</cell><cell>-</cell><cell>54.3</cell><cell>77.8</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>SPIN [24]</cell><cell></cell><cell></cell><cell>59.2</cell><cell>96.9</cell><cell>116.4</cell><cell>41.1</cell><cell>-</cell><cell>76.4</cell><cell>37.1</cell><cell>105.2</cell></row><row><cell>I2L [41]  *</cell><cell></cell><cell></cell><cell>58.6</cell><cell>93.2</cell><cell>-</cell><cell>41.7</cell><cell>55.7</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">Mesh Graphormer [30] w. 3DPW</cell><cell></cell><cell>45.6</cell><cell>74.7</cell><cell>87.7</cell><cell>41.2</cell><cell>34.5</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PARE [21] w. 3DPW</cell><cell></cell><cell></cell><cell>46.4</cell><cell>74.7</cell><cell>87.7</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Ours (Naive HybrIK)</cell><cell></cell><cell></cell><cell>49.0</cell><cell>80.2</cell><cell>94.6</cell><cell>35.3</cell><cell>55.8</cell><cell>85.9</cell><cell>41.7</cell><cell>91.5</cell></row><row><cell cols="2">Ours (Adaptive HybrIK)</cell><cell></cell><cell>48.8</cell><cell>80.0</cell><cell>94.5</cell><cell>34.5</cell><cell>54.4</cell><cell>86.2</cell><cell>42.2</cell><cell>91.0</cell></row><row><cell cols="3">Ours (Adaptive HybrIK) w. 3DPW</cell><cell>45.0</cell><cell>74.1</cell><cell>86.5</cell><cell>33.6</cell><cell>55.4</cell><cell>87.5</cell><cell>46.9</cell><cell>93.9</cell></row><row><cell cols="10">Table 2. Benchmark of state-of-the-art models on 3DPW, Human3.6M and MPI-INF-3DHP datasets. " * " denotes the method is</cell></row><row><cell cols="6">trained on different datasets. "-" shows the results that are not available.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">GT Joints ?10 mm ?20 mm ?30 mm</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Naive HybrIK</cell><cell>0.1</cell><cell>16.2</cell><cell>34.0</cell><cell>53.4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Adaptive HybrIK</cell><cell>0.1</cell><cell>9.8</cell><cell>20.2</cell><cell>31.2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 4 .</head><label>4</label><figDesc>Error correction capability of HybrIK. HybrIK improves the results predicted by the 3D keypoint estimation method. MPI-INF-3DHP dataset. Procrustes aligned mean per joint position error (PA-MPJPE), mean per joint position error (MPJPE), Percentage of Correct Keypoints (PCK) and Area Under Curve (AUC) are reported to evaluate the 3D pose results. We also report Per Vertex Error (PVE) to evaluate the entire estimated body mesh.</figDesc><table><row><cell></cell><cell cols="3">Predicted Pose HybrIK SMPLify [7]</cell></row><row><cell>MPJPE (24 jts) ?</cell><cell>88.2 mm</cell><cell>79.2 mm</cell><cell>114.3 mm</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 6 .</head><label>6</label><figDesc>Error correction capability of HybrIK on 3DPW and Human3.6M.</figDesc><table><row><cell></cell><cell>Human3.6M</cell><cell></cell><cell>3DPW</cell><cell></cell></row><row><cell></cell><cell cols="4">Predicted Pose HybrIK Predicted Pose HybrIK</cell></row><row><cell>MPJPE (24 jts) ?</cell><cell>51.3</cell><cell>48.1</cell><cell>88.2</cell><cell>79.2</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Rigid Registration of Global Rotation</head><p>In the SMPL model <ref type="bibr" target="#b30">[31]</ref>, the pose parameters ? control the rotations of the rigid body parts. The three joints named spine, left hip and right hip form a rigid body part, which is controlled by the global root rotation. Therefore, the global rotation can be determined by registering the rest pose template of spine, left hip and right hip to the predicted locations of these three joints. Let t 1 , t 2 and t 3 denote their locations in the rest pose template, and p 1 , p 2 and p 3 denote the predicted locations. Our goal is to find a rigid rotation that optimally aligns the two sets of joints. Here, we assume the root joint of the predicted pose and the rest pose are aligned. Hence, the problem is formulated as:</p><p>This formula can be written in matrix form:</p><p>where ? F denotes the Frobenius norm,P 0 denotes [p 0 p 1 p 2 ], and T 0 denotes [t 0 t 1 t 2 ]. Let us simplify the expression in Eq. 25 as:</p><p>Note that P T 0 P 0 and T T 0 T 0 are independent of R. Thus the original problem is equivalent to:</p><p>Further, we can leverage the property of the matrix trace,</p><p>Then, we apply Singular Value Decomposition (SVD) to the joint locations:</p><p>The problem is equivalent to: arg max R?SO 3 trace(RT 0 P T 0 )</p><p>? arg max R?SO 3 trace(RU ?V T ) ? arg max <ref type="bibr">R?SO 3</ref> trace(?V T RU ).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pose-conditioned joint angle limits for 3d human pose reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ijaz</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Scape: shape completion and animation of people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Rodgers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fabrik: A fast, iterative solver for the inverse kinematics problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Aristidou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><surname>Lasenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graphical Models</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploiting temporal context for 3d human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Parametrization and range of motion of the ball-and-socket joint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Baerlocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Boulic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Deformable avatars</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Robust control of robotic manipulators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Balestrino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giuseppe</forename><forename type="middle">De</forename><surname>Maria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sciavicco</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IFAC Proceedings Volumes</title>
		<imprint>
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Keep it smpl: Automatic estimation of 3d human pose and shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Integration of motion control techniques for virtual human and avatar real-time animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Boulic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>B?cheiraz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Emering</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Thalmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Selectively damped least squares for inverse kinematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin-Su</forename><surname>Buss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Graphics tools</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On solving the inverse kinematics problem using neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akos</forename><surname>Csiszar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Eilers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Verl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">M2VIP</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Learning pose grammar to encode human body configuration for 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoshu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Computational modeling for the computer animation of legged figures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Girard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony A</forename><surname>Maciejewski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Estimating human shape and pose from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Alexandru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Holopose: Holistic 3d human reconstruction in-the-wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alp</forename><surname>Riza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Guler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Human3.6m: Large scale datasets and predictive methods for 3D human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Analytical inverse kinematics with body posture control. Computer animation and virtual worlds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcelo</forename><surname>Kallmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Review of pseudoinverse control for use with kinematically redundant manipulators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hsiang</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Vibe: Video inference for human body pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Athanasiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Pare: Part attention regressor for 3d human body estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Hao P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Complete analytical inverse kinematics for nao</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kofinas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanouil</forename><surname>Orfanoudakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michail</forename><forename type="middle">G</forename><surname>Lagoudakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICARSC</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning to estimate pose and shape of hand-held objects from rgb images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mia</forename><surname>Kokic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danica</forename><surname>Kragic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeannette</forename><surname>Bohg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IROS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to reconstruct 3d human pose and shape via model-fitting in the loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Convolutional mesh regression for single-image human shape reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Convolutional mesh regression for single-image human shape reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Unite the people: Closing the loop between 3d and 2d human representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Kiefel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Detailed 2d-3d joint representation for human-object interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong-Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinpeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pastanet: Toward human activity knowledge engine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong-Lu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinpeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xijie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao-Shu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mesh graphormer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Smpl: A skinned multiperson linear model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
		<imprint>
			<publisher>TOG</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Linear and nonlinear programming</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinyu</forename><surname>David G Luenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ye</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning features combination for human action recognition from skeleton sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hedi</forename><surname>Diogo Carbonera Luvizon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tabia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">A simple yet effective baseline for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Monocular 3D human pose estimation in the wild using improved cnn supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<idno>3DV</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Monocular 3d human pose estimation in the wild using improved cnn supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<idno>3DV</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Xnect: Real-time multi-person 3d human pose estimation with a single rgb camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elgharib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.00837</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Single-shot multi-person 3d pose estimation from monocular rgb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Camera distance-aware top-down approach for 3d multiperson pose estimation from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">I2l-meshnet: Imageto-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kyoung Mu Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">I2L-meshnet: Image-to-lixel prediction network for accurate 3d human pose and mesh estimation from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kyoung Mu Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">3d human pose estimation from a single image via distance matrix regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesc</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Real-time hand tracking under occlusion from an egocentric rgb-d sensor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Stacked hourglass networks for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Newell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Neural body fitting: Unifying deep learning and model based human pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep rnn framework for visual sequential applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwen</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Complex sequential understanding through the awareness of spatial and temporal concepts. Nature Machine Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwen</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">3d human pose estimation using convolutional neural networks with 2d pose information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungheon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihye</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nojun</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Expressive body capture: 3d hands, face, and body from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Coarse-to-fine volumetric prediction for single-image 3D human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Coarse-to-fine volumetric prediction for single-image 3d human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Derpanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Learning to estimate 3d human pose and shape from a single color image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Quaternet: A quaternion-based recurrent model for human motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Pavllo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">3d skeleton-based human action classification: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liliana</forename><forename type="middle">Lo</forename><surname>Presti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><forename type="middle">La</forename><surname>Cascia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Reconstructing 3d human pose from 2d image landmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Ramakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Lcr-net: Localization-classification-regression for human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Ik-fa, a new heuristic inverse kinematics solver using firefly algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nizar</forename><surname>Rokbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alicia</forename><surname>Casals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adel</forename><forename type="middle">M</forename><surname>Alimi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computational Intelligence Applications in Modeling and Control</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Bayesian image based 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marta</forename><surname>Sanzari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valsamis</forename><surname>Ntouskos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fiora</forename><surname>Pirri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Combined discriminative and generative articulated pose and non-rigid shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandru</forename><surname>Balan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Compositional human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxiang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Integral human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Integral human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Real-time inverse kinematics techniques for anthropomorphic limbs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Tolani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambarish</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Norman</forename><forename type="middle">I</forename><surname>Badler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graphical models</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Self-supervised learning of motion capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Yu</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Wei</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Fragkiadaki</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Adversarial inverse graphics networks: Learning 2d-to-3d lifting and image-to-image translation from unpaired supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hsiao-Yu Fish</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">W</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Seto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Fragkiadaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Bodynet: Volumetric inference of 3d human body shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gul</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ersin</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Neural kinematic networks for unsupervised motion retargetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruben</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Recovering accurate 3d human pose in the wild using imus and a moving camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Timo Von Marcard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Bodo Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pons-Moll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Manipulator inverse kinematic solutions based on vector formulations and damped least-squares methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wampler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Hmor: Hierarchical multi-person ordinal relations for monocular multi-person 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A computational technique for inverse kinematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wolovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Elliott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CDC</title>
		<imprint>
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">A dual-source approach for 3d pose estimation from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hashim</forename><surname>Yasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umar</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Skeleton transformer networks: 3d human pose and skinned mesh from single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuke</forename><surname>Yoshiyasu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryusuke</forename><surname>Sagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ko</forename><surname>Ayusawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akihiko</forename><surname>Murai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Monocular 3d pose and shape estimation of multiple people in natural scenes-the importance of multiple scene constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Towards 3d human pose estimation in the wild: a weakly-supervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Deep kinematic pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Sparse representation for 3d shape estimation: A convex relaxation approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Spyridon Leonardos, and Kostas Daniilidis</title>
		<imprint>
			<publisher>TPAMI</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Sparseness meets deepness: 3d human pose estimation from monocular video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyridon</forename><surname>Leonardos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Konstantinos G Derpanis, and Kostas Daniilidis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
