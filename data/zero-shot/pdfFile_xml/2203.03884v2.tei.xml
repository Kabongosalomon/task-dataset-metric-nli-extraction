<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchao</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochen</forename><surname>Wang</surname></persName>
							<email>wanghaochen0409@sjtu.edu.cn</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Shen</surname></persName>
							<email>shenyujun0302@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">The Chinese University of Hong Kong</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Fei</surname></persName>
							<email>feijingjing1@sensetime.com</email>
							<affiliation key="aff2">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
							<email>liwei1@sensetime.com</email>
							<affiliation key="aff2">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqiang</forename><surname>Jin</surname></persName>
							<email>jinguoqiang@sensetime.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wu</surname></persName>
							<email>wuliwei@sensetime.com</email>
							<affiliation key="aff2">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhao</surname></persName>
							<email>zhaorui@sensetime.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyi</forename><surname>Le</surname></persName>
							<email>lexinyi@sjtu.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Shanghai Jiao Tong University</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">SenseTime Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Semi-Supervised Semantic Segmentation Using Unreliable Pseudo-Labels</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The crux of semi-supervised semantic segmentation is to assign adequate pseudo-labels to the pixels of unlabeled images. A common practice is to select the highly confident predictions as the pseudo ground-truth, but it leads to a problem that most pixels may be left unused due to their unreliability. We argue that every pixel matters to the model training, even its prediction is ambiguous. Intuitively, an unreliable prediction may get confused among the top classes (i.e., those with the highest probabilities), however, it should be confident about the pixel not belonging to the remaining classes. Hence, such a pixel can be convincingly treated as a negative sample to those most unlikely categories. Based on this insight, we develop an effective pipeline to make sufficient use of unlabeled data. Concretely, we separate reliable and unreliable pixels via the entropy of predictions, push each unreliable pixel to a category-wise queue that consists of negative samples, and manage to train the model with all candidate pixels. Considering the training evolution, where the prediction becomes more and more accurate, we adaptively adjust the threshold for the reliable-unreliable partition. Experimental results on various benchmarks and training settings demonstrate the superiority of our approach over the stateof-the-art alternatives. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Semantic segmentation is a fundamental task in the computer vision field, and has been significantly advanced along 1 Project: https://haochen-wang409.github.io/U2PL. * Corresponding author. This work is sponsored by National Natural Science Foundation of China (62176152). ? Equal contribution, and this work is done during the internship at SenseTime Research. ? Rui Zhao is also with Qing Yuan Research Institute, Shanghai Jiao Tong University.  Model is trained using 732 labeled images on PASCAL VOC 2012 <ref type="bibr" target="#b13">[14]</ref> and evaluated on the remaining 9, 850 images.</p><p>with the rise of deep neural networks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b45">46]</ref>. Existing supervised approaches rely on large-scale annotated data, which can be too costly to acquire in practice. To alleviate this problem, many attempts <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b47">48]</ref> have been made towards semi-supervised semantic segmentation, which learns a model with only a few labeled samples and numerous unlabeled ones. Under such a setting, how to adequately leverage the unlabeled data becomes critical. A typical solution is to assign pseudo-labels to the pixels without annotations. Concretely, given an unlabeled image, prior arts <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b40">41]</ref> borrow predictions from the model trained on labeled data, and use the pixel-wise prediction as the "ground-truth" to in turn boost the supervised model. To mitigate the problem of confirmation bias <ref type="bibr" target="#b1">[2]</ref>, where the model may suffer from incorrect pseudo-labels, existing approaches propose to filter the predictions with their confidence scores <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51]</ref>. In other words, only the highly confident predictions are used as the pseudo-labels, while the ambiguous ones are discarded.</p><p>However, one potential problem caused by only using reliable predictions is that some pixels may never be learned in the entire training process. For example, if the model cannot satisfyingly predict some certain class (e.g., chair in <ref type="figure" target="#fig_1">Fig. 1</ref>), it becomes difficult to assign accurate pseudolabels to the pixels regarding such a class, which may lead to insufficient and categorically imbalanced training. From this perspective, we argue that, to make full use of the unlabeled data, every pixel should be properly utilized.</p><p>As discussed above, directly using the unreliable predictions as the pseudo-labels will cause the performance degradation <ref type="bibr" target="#b1">[2]</ref>. In this paper, we propose an alternative way of Using Unreliable Pseudo-Labels. We call our framework as U 2 PL. First, we observe that, an unreliable prediction usually gets confused among only a few classes instead of all classes. Taking <ref type="figure" target="#fig_3">Fig. 2</ref> as an instance, the pixel with white cross receives similar probabilities on class motorbike and person, but the model is pretty sure about this pixel not belonging to class car and train. Based on this observation, we reconsider the confusing pixels as the negative samples to those unlikely categories. Specifically, after getting the prediction from an unlabeled image, we employ the per-pixel entropy as the metric (see <ref type="figure" target="#fig_3">Fig. 2a</ref>) to separate all pixels into two groups, i.e., a reliable one and an unreliable one. All reliable predictions are used to derive positive pseudo-labels, while the pixels with unreliable predictions are pushed into a memory bank, which is full of negative samples. To avoid all negative pseudo-labels only coming from a subset of categories, we employ a queue for each category. Such a design ensures that the number of negative samples for each class is balanced. Meanwhile, considering that the quality of pseudo-labels becomes higher along with the model gets more and more accurate, we come up with a strategy to adaptively adjust the threshold for the partition of reliable and unreliable pixels.</p><p>We evaluate the proposed U 2 PL on PASCAL VOC 2012 <ref type="bibr" target="#b13">[14]</ref> and Cityscapes <ref type="bibr" target="#b9">[10]</ref> under a wide range of training settings, where our approach surpasses the stateof-the-art competitors. Furthermore, through visualizing the segmentation results, we find that our method achieves much better performance on those ambiguous regions (e.g., the border between different objects), thanks to our adequate use of the unreliable pseudo-labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Semi-Supervised Learning has two typical paradigms: consistency regularization <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b41">42]</ref> and entropy minimization <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16]</ref>. Recently, a more intuitive but effective framework: self-training <ref type="bibr" target="#b26">[27]</ref>, has become the mainstream. Several methods <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref> utilize strong data augmentation such as CutOut <ref type="bibr" target="#b12">[13]</ref>, CutMix <ref type="bibr" target="#b44">[45]</ref>, and ClassMix <ref type="bibr" target="#b30">[31]</ref> based on self-training. However, these methods do not pay much attention to the characteristics of semantic segmentation, while our method focuses on those  unreliable pixels which will be filtered out by most of selftraining based methods <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref>. Pseudo-Labeling is applied to prevent overfitting to incorrect pseudo-labels when generating predictions of input images from the teacher network <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b26">27]</ref>. FixMatch <ref type="bibr" target="#b36">[37]</ref> utilizes a confidence threshold to select reliable pseudolabels. UPS <ref type="bibr" target="#b33">[34]</ref>, a method based on FixMatch <ref type="bibr" target="#b36">[37]</ref>, takes model uncertainty and data uncertainty into consideration. However, in semi-supervised semantic segmentation, our experiments show including unreliable pixels into training can boost performance. Model Uncertainty in computer vision is mostly measured by Bayesian deep learning approaches <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b29">30]</ref>. In our settings, we do not focus on how to measure uncertainty. We simply use the entropy of pixel-wise probability distribution to be the metric. Contrastive Learning is applied by many successful works in self-supervised learning <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b16">17]</ref>. In semantic segmentation, contrastive learning has become a promising new paradigm <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b48">49]</ref>. However, these methods ignore the common false negative samples in semi-supervised segmentation, and unreliable pixels may be wrongly pushed away in contrastive loss. Discriminating the unlikely categories of unreliable pixels can addresses this problem. Negative Learning aims at decreasing the risk of incorrect information by lowering the probability of negative samples <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b38">39]</ref>, but those negative samples are selected with high confidence. In other words, these methods still utilizes pixels with reliable predictions. By contrast, we propose to make sufficient use of those unreliable predictions for learning instead of filtering them out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>In this section, we establish our problem mathematically and give an overview of our proposed method in Sec. 3.1 first. Our strategies about filtering reliable pseudo-labels are introduced in Sec. 3.2. Finally, we describe how to use unreliable pseudo-labels in Sec. 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Overview</head><p>Given a labeled set D l = (x l i , y l i )</p><formula xml:id="formula_0">N l i=1 and a much larger unlabeled set D u = {x u i } Nu i=1</formula><p>, our goal is to train a semantic segmentation model by leveraging both a large amount of unlabeled data and a smaller set of labeled data. <ref type="figure">Fig. 3</ref> gives an overview of U 2 PL, which follows the typical self-training framework with two models of the same architecture, named teacher and student respectively. The two models differ only when updating their weights. The student model's weights ? s are updated consistent with the common practice while the teacher model's weights ? t are exponential moving average (EMA) updated by the student model's weights. Each model consists of a CNNbased encoder h, a decoder with a segmentation head f , and a representation head g. At each training step, we equally sample B labeled images B l and B unlabeled images B u . For every labeled image, our goal is to minimize the standard cross-entropy loss in Eq. <ref type="bibr" target="#b1">(2)</ref>. As for each unlabeled image, we first take it into the teacher model and get predictions. Then, based on pixel-level entropy, we ignore unreliable pixel-level pseudo-labels when computing unsupervised loss in Eq. (3). This part will be introduced in section Sec. 3.2 in detail. Finally, we use the contrastive loss to make full use of the unreliable pixels excluded in the unsupervised loss, which will be introduced in Sec. 3.3.</p><p>Our optimization target is to minimize the overall loss, which can be formulated as:</p><formula xml:id="formula_1">L = L s + ? u L u + ? c L c ,<label>(1)</label></formula><p>where L s and L u represent supervised loss and unsupervised loss applied on labeled images and unlabeled images respectively, and L c is the contrastive loss to make full use of unreliable pseudo-labels. ? u and ? c are weights of unsupervised loss and contrastive loss respectively. Both L s and L u are cross-entropy (CE) loss:</p><formula xml:id="formula_2">L s = 1 |B l | (x l i ,y l i )?B l ce (f ? h(x l i ; ?), y l i ),<label>(2)</label></formula><formula xml:id="formula_3">L u = 1 |B u | x u i ?Bu ce (f ? h(x u i ; ?),? u i ),<label>(3)</label></formula><p>where y l i represents the hand-annotated mask label for the i-th labeled image, and? u i is the pseudo-label for the i-th unlabeled image. f ? h is the composition function of h and f , which means the images are first fed into h and then f to get segmentation results. L c is the pixel-level InfoNCE <ref type="bibr" target="#b31">[32]</ref> loss defined as:</p><formula xml:id="formula_4">L c = ? 1 C ? M C?1 c=0 M i=1 log ? ? e zci,z + ci /? e zci,z + ci /? + N j=1 e zci,z ? cij /? ? ? ,<label>(4)</label></formula><p>where M is the total number of anchor pixels, and z ci denotes the representation of the i-th anchor of class c. Each anchor pixel is followed with a positive sample and N negative samples, whose representations are z + ci and z ? cij respectively. Note that z = g ? h(x) is the output of the representation head. ?, ? is the cosine similarity between features from two different pixels, whose range is limited between ?1 to 1, hence the need of temperature ? . Following <ref type="bibr" target="#b27">[28]</ref>, we set M = 50, N = 256 and ? = 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Pseudo-Labeling</head><p>To avoid overfitting incorrect pseudo-labels, we utilize entropy of every pixel's probability distribution to filter high quality pseudo-labels for further supervision. Specifically, we denote p ij ? R C as the softmax probabilities generated by the segmentation head of the teacher model for the ith unlabeled image at pixel j, where C is the number of classes. Its entropy is computed by:</p><formula xml:id="formula_5">H(p ij ) = ? C?1 c=0 p ij (c) log p ij (c),<label>(5)</label></formula><p>where p ij (c) is the value of p ij at c-th dimension. Then, we define pixels whose entropy on top ? t as unreliable pseudo-labels at training epoch t. Such unreliable pseudo-labels are not qualified for supervision. Therefore, we define the pseudo-label for the i-th unlabeled image at pixel j as:</p><formula xml:id="formula_6">y u ij = arg max c p ij (c), if H(p ij ) &lt; ? t ,</formula><p>ignore, otherwise,   <ref type="figure">Figure 3</ref>. An overview of our proposed U 2 PL method. U 2 PL contains a student network and a teacher network, where the teacher is momentum-updated with the student. Labeled data is directly fed into the student network for supervised training. Given an unlabeled image, we first use the teacher model to make a prediction, and then separate the pixels into reliable ones and unreliable ones based on their entropy. Such a process is formulated as Eq. <ref type="formula" target="#formula_7">(6)</ref>. The reliable predictions are directly used as the pseudo-labels to advise the student, while each unreliable prediction is pushed into a category-wise memory bank. Pixels in each memory bank are regarded as the negative samples to the corresponding class, which is formulated as Eq. <ref type="formula" target="#formula_4">(4)</ref>.</p><formula xml:id="formula_8">J 6 F W R b p t q p b g Q V J H j X E E v b M a E w = " &gt; A A A B 9 H i c b V C 7 S g N B F L 0 b X z G + o p Y 2 g 0 G w C r s i a h m w s b C I Y B 6 Q L G F 2 c p M M m Z 1 d Z 2 Y D Y c l 3 2 F g o Y u v H 2 P k 3 z i Z b a O K B g c M 5 9 3 L P n C A W X B v X / X Y K a + s b m 1 v F 7 d L O 7 t 7 + Q f n w q K m j R D F s s E h E q h 1 Q j Y J L b B h u B L Z j h T Q M B L a C</formula><p>where ? t represents the entropy threshold at t-th training step. We set ? t as the quantile corresponding to ? t , i.e.,</p><formula xml:id="formula_9">? t =np.percentile(H.flatten(),100 * (1-? t )),</formula><p>where H is per-pixel entropy map. We adopt the following adjustment strategies in the pseudo-labeling process for better performance. Dynamic Partition Adjustment. During the training procedure, the pseudo-labels tend to be reliable gradually. Base on this intuition, we adjust unreliable pixels' proportion ? t with linear strategy every epoch:</p><formula xml:id="formula_10">? t = ? 0 ? 1 ? t total epoch ,<label>(7)</label></formula><p>where ? 0 is the initial proportion and is set to 20%, and t is the current training epoch. Adaptive Weight Adjustment. After obtaining reliable pseudo-labels, we involve them in the unsupervised loss in Eq. (3). The weight ? u for this loss is defined as the reciprocal of the percentage of pixels with entropy smaller than threshold ? t in the current mini-batch multiplied by a base weight ?:</p><formula xml:id="formula_11">? u = ? ? |B u | ? H ? W |Bu| i=1 H?W j=1 1 ? u ij = ignore ,<label>(8)</label></formula><p>where 1(?) is the indicator function and ? is set to 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Using Unreliable Pseudo-Labels</head><p>In semi-supervised learning tasks, discarding unreliable pseudo-labels or reducing their weights is widely used to prevent degradation of model's performance <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b49">50]</ref>.</p><p>We follow this intuition by filtering out unreliable pseudolabels based on Eq. (6).</p><p>However, such contempt for unreliable pseudo-labels may result in information loss. It is obvious that unreliable pseudo-labels can provide information for better discrimination. For example, the white cross in <ref type="figure" target="#fig_3">Fig. 2</ref>, is a typical unreliable pixel. Its distribution demonstrates model's uncertainty to distinguish between class person and class motorbike. However, this distribution also demonstrates model's certainty to not to discriminate this pixel as class car, class train, class bicycle and so on. Such characteristic gives us the main insight to propose our U 2 PL to use unreliable pseudo-labels for semi-supervised semantic segmentation. U 2 PL, with a goal to use the information of unreliable pseudo-labels for better discrimination, coincides with recent popular contrastive learning paradigm in distinguishing representation. But due to the lack of labeled images in semi-supervised semantic segmentation tasks, our U 2 PL is built on more complicated strategies. U 2 PL has three components, named anchor pixels, positive candidates and negative candidates. These components are obtained in a sampling manner from certain sets to alleviate huge computational cost. Next, we will introduce how to selecting: (a) anchor pixels (queries); (b) positive samples for each anchor; (c) negative samples for each anchor. Anchor Pixels. During training, we sample anchor pixels (queries) for each class that appears in the current mini batch. We denote the set of features of all labeled candidate anchor pixels for class c as A l c ,</p><formula xml:id="formula_12">A l c = {z ij | y ij = c, p ij (c) &gt; ? p } ,<label>(9)</label></formula><p>where y ij is the ground-truth for the j-th pixel of labeled image i, and ? p denotes the positive threshold for a particular class and is set to 0.3 following <ref type="bibr" target="#b27">[28]</ref>. z ij means the representation of the j-th pixel of labeled image i. For unlabeled data, counterpart A u c can be computed as:</p><formula xml:id="formula_13">A u c = {z ij |? ij = c, p ij (c) &gt; ? p } .<label>(10)</label></formula><p>It is similar to A l c , and the only difference is that we use pseudo-label? ij based on Eq. (6) rather than handannotated label, which implies that qualified anchor pixels are reliable, i.e., H(p ij ) ? ? t . Therefore, for class c, the set of all qualified anchors is</p><formula xml:id="formula_14">A c = A l c ? A u c .<label>(11)</label></formula><p>Positive Samples. The positive sample is the same for all anchors from the same class. It is the center of all possible anchors:</p><formula xml:id="formula_15">z + c = 1 |A c | zc?Ac z c .<label>(12)</label></formula><p>Negative Samples. We define a binary variable n ij (c) to identify whether the j-th pixel of image i is qualified to be negative samples of class c.</p><formula xml:id="formula_16">n ij (c) = n l ij (c), if image i is labeled, n u ij (c), otherwise,<label>(13)</label></formula><p>where n l ij (c) and n u ij (c) are indicators of whether the j-th pixel of labeled and unlabeled image i is qualified to be negative samples of class c respectively.</p><p>For i-th labeled image, a qualified negative sample for class c should be: (a) not belonging to class c; (b) difficult to distinguish between class c and its groundtruth category. Therefore, we introduce the pixel-level category order O ij = argsort(p ij ). Obviously, we have O ij (arg max p ij ) = 0 and O ij (arg min p ij ) = C ? 1.</p><formula xml:id="formula_17">n l ij (c) = 1 [y ij = c] ? 1 [0 ? O ij (c) &lt; r l ] ,<label>(14)</label></formula><p>where r l is the low rank threshold and is set to 3. The two indicators reflect feature (a) and (b) respectively.</p><p>For i-th unlabeled image, a qualified negative sample for class c should: (a) be unreliable; (b) probably not belongs to class c; (c) not belongs to most unlikely classes. Similarly, we also use O ij to define n u ij (c):</p><formula xml:id="formula_18">n u ij (c) = 1 [H(p ij ) &gt; ? t ] ? 1 [r l ? O ij (c) &lt; r h ] ,<label>(15)</label></formula><p>where r h is the high rank threshold and is set to 20. Finally, the set of negative samples of class c is</p><formula xml:id="formula_19">N c = {z ij | n ij (c) = 1} .<label>(16)</label></formula><p>Category-wise Memory Bank. Due to the long tail phenomenon of the dataset, negative candidates in some Get probabilities:</p><formula xml:id="formula_20">p i ? f ? h(x i ; ? t ); 5 Get representations: z i ? g ? h(x i ; ? s ); 6 for c ? 0 to C ? 1 do 7</formula><p>Get anchors A c based on Eq. (11); In order to maintain a stable number of negative samples, we use category-wise memory bank Q c (FIFO queue) to store the negative samples for class c. Finally, the whole process to use unreliable pseudolabels is shown in Algorithm 1. All features of anchors are attach to gradient, come from student hence, while features of positive and negative samples are from teacher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Setup</head><p>Datasets. PASCAL VOC 2012 <ref type="bibr" target="#b13">[14]</ref> Dataset is a standard semantic segmentation benchmark with 20 semantic classes of objects and 1 class of background. The training set and the validation set include 1, 464 and 1, 449 images respectively. Following <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b42">43]</ref>, we use SBD <ref type="bibr" target="#b17">[18]</ref> as the augmented set with 9, 118 additional training images. Since the SBD <ref type="bibr" target="#b17">[18]</ref> dataset is coarsely annotated, PseudoSeg <ref type="bibr" target="#b49">[50]</ref> takes only the standard 1, 464 images as the whole labeled set, while other methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21]</ref> take all 10, 582 images as candidate labeled data. Therefore, we evaluate our method on both the classic set (1, 464 candidate labeled images) and the blender set (10, 582 candidate labeled images). Cityscapes <ref type="bibr" target="#b9">[10]</ref>, a dataset designed for urban scene understanding, consists of 2, 975 training images with fine-annotated masks and 500 validation images. For each dataset, we compare U 2 PL with other methods under 1/2, 1/4, 1/8, and 1/16 partition protocols. Network Structure. We use ResNet-101 <ref type="bibr" target="#b18">[19]</ref> pre-trained on ImageNet <ref type="bibr" target="#b10">[11]</ref> as the backbone and DeepLabv3+ <ref type="bibr" target="#b5">[6]</ref> as the decoder. Both of the segmentation head and the rep- <ref type="table">Table 1</ref>. Comparison with state-of-the-art methods on classic PASCAL VOC 2012 val set under different partition protocols. The labeled images are selected from the original VOC train set, which consists of 1, 464 samples in total. The fractions denote the percentage of labeled data used for training, followed by the actual number of images. All the images from SBD <ref type="bibr" target="#b17">[18]</ref> are regarded as unlabeled data. "SupOnly" stands for supervised training without using any unlabeled data. ? means we reproduce the approach.  <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b47">48]</ref>, the images are center cropped into a fixed resolution for PASCAL VOC 2012. For Cityscapes, previous methods apply slide window evaluation, so do we. Then we adopt the mean of Intersection over Union (mIoU) as the metric to evaluate these cropped images. All results are measured on the val set on both Cityscapes <ref type="bibr" target="#b9">[10]</ref> and PASCAL VOC 2012 <ref type="bibr" target="#b13">[14]</ref>. Ablation studies are conducted on the blender PASCAL VOC 2012 <ref type="bibr" target="#b13">[14]</ref> val set under 1/4 and 1/8 partition protocol. Implementation Details. For the training on the blender and classic PASCAL VOC 2012 dataset, we use stochastic gradient descent (SGD) optimizer with initial learning rate 0.001, weight decay as 0.0001, crop size as 513 ? 513, batch size as 16 and training epochs as 80. For the training on the Cityscapes dataset, we also use stochastic gradient descent (SGD) optimizer with initial learning rate 0.01, weight decay as 0.0005, crop size as 769 ? 769, batch size as 16 and training epochs as 200. In all experiments, the decoder's learning rate is ten times that of the backbone. We use the poly scheduling to decay the learning rate during the training process: lr = lr base ? 1 ? iter total iter 0.9 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison with Existing Alternatives</head><p>We compare our method with following recent semisupervised semantic segmentation methods: Mean Teacher (MT) <ref type="bibr" target="#b37">[38]</ref>, CCT <ref type="bibr" target="#b32">[33]</ref>, GCT <ref type="bibr" target="#b21">[22]</ref>, PseudoSeg <ref type="bibr" target="#b49">[50]</ref>, Cut-Mix <ref type="bibr" target="#b14">[15]</ref>, CPS <ref type="bibr" target="#b8">[9]</ref>, PC 2 Seg <ref type="bibr" target="#b47">[48]</ref>, AEL <ref type="bibr" target="#b20">[21]</ref>. We reimplement MT <ref type="bibr" target="#b37">[38]</ref>, CutMix <ref type="bibr" target="#b44">[45]</ref> for a fair comparison. For Cityscapes <ref type="bibr" target="#b9">[10]</ref>, we also reproduce CPS <ref type="bibr" target="#b8">[9]</ref> and AEL <ref type="bibr" target="#b20">[21]</ref>. All results are equipped with the same network architecture (DeepLabv3+ as decoder and ResNet-101 as encoder). It is <ref type="table">Table 2</ref>. Comparison with state-of-the-art methods on blender PASCAL VOC 2012 val set under different partition protocols. All labeled images are selected from the augmented VOC train set, which consists of 10, 582 samples in total. "SupOnly" stands for supervised training without using any unlabeled data. ? means we reproduce the approach.  Note that when labeled data is extremely limited, e.g., when we only have 92 labeled data, our U 2 PL outperforms previous methods by a large margin (+10.98% under 1/16 split for classic PASCAL VOC 2012), proofing the efficiency of using unreliable pseudo-labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Studies</head><p>Effectiveness of Using Unreliable Pseudo-Labels. To prove our core insight, i.e., using unreliable pseudolabels promotes semi-supervised semantic segmentation, we conduct experiments about selecting negative candidates (Sec. 3.3) with different reliability. Tab. 4 demonstrates the mIoU results on PASCAL VOC 2012 val set. "Unreliable" outperforms other options, proving using unreliable pseudo-labels does help. Appendix B shows the effectiveness of using unreliable pseudo-labels on Cityscapes. Effectiveness of Probability Rank Threshold. Sec. 3.3 proposes to use probability rank threshold to balance informativeness and confusion caused by unreliable pixels. Tab. 5 provides a verification that such balance promotes the performance. r l = 3 and r h = 20 outperform other options by a large margin. When r l = 1, false negative candidates would not be filtered out, causing the intra-class features of pixels incorrectly distinguished by L c . When r l = 10, negative candidates tend to become irrelevant with corresponding anchor pixels in semantic, making such discrimination less informative. Appendix D.2 studies PRT and ? 0 on Cityscapes. <ref type="table">Table 4</ref>. Ablation study on using pseudo pixels with different reliability, which is measured by the entropy of pixel-wise prediction (see Sec. 3.3). "Unreliable" denotes selecting negative candidates from pixels with top 20% highest entropy scores. "Reliable" denotes the bottom 20% counterpart. "All" denotes sampling regardless of entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Unreliable</head><p>Reliable All  <ref type="table">Table 7</ref>. Ablation study on ?0 in Eq. <ref type="bibr" target="#b6">(7)</ref>, which controls the initial proportion between reliable and unreliable pixels.  <ref type="formula" target="#formula_10">(7)</ref>), which is simple yet efficient.  For Probability Rank Threshold (PRT) component, we set corresponding parameter according to Tab. 5. Without high entropy filtering, the improvement decreased significantly at +4.55%. Finally, when adding all the contribution together, our method achieves state-of-the-art result under 1/4 partition protocol with mIoU of 79.30%. Following this result, we apply these components and corresponding parameters in all experiments on Tab. 2 and Tab. 1.</p><p>Ablation Study on Hyper-parameters. We ablate following important parameter for U 2 PL. Tab. 7 studies the impact of different initial reliable-unreliable partition. This parameter ? 0 have a certain impact on performance. We find ? 0 = 20% achieves the best performance. Small ? 0 will introduce incorrect pseudo labels for supervision, and large ? 0 will make the information of some high-confidence samples underutilized. Other hyper-parameters are studied in Appendix D.1. <ref type="figure" target="#fig_8">Fig. 4</ref> shows the results of different methods on the PASCAL VOC 2012 val set. Benefiting from using unreliable pseudo-labels, U 2 PL outperforms other methods. Note that using contrastive learning without filtering those unreliable pixels, sometimes does harm to the model (see row 2 and row 4 in <ref type="figure" target="#fig_8">Fig. 4</ref>), leading to worse results than those when the model is trained only by labeled data. Furthermore, through visualizing the segmentation results, we find that our method achieves much better performance on those ambiguous regions (e.g., the border between different objects). Such visual difference proves that our method finally makes the reliability of unreliable prediction labels stronger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Qualitative Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>We propose a semi-supervised semantic segmentation framework U 2 PL by including unreliable pseudo-labels into training, which outperforms many existing state-ofthe-art methods, suggesting our framework provide a new promising paradigm in semi-supervised learning research. Our ablation experiments proves the insight of this work is quite solid. Qualitative result gives a visual proof for its effectiveness, especially the better performance on borders between semantic objects or other ambiguous regions.</p><p>The training of our method is time-consuming compared with fully-supervised methods <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b45">46]</ref>, which is a common disadvantage for semi-supervised learning tasks <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b47">48]</ref>. Due to the extreme lack of labels, the semi-supervised learning frameworks commonly need to pay a price in time for higher accuracy. More in-depth exploration could be conducted on their training optimization in the future. 50]. Our memory queue is category-specific. For the background category, the length of the queue is set to be 50, 000. For foreground categories, the length of the queue is all 30, 000. All baselines i.e., "SupOnly", "MT", and "CutMix" are re-implemented by ourselves, where the only difference between "MT" and "CutMix" is that the latter applies CutMix <ref type="bibr" target="#b44">[45]</ref> augmentation for unlabeled images. The hyper-parameters used in this work are listed in Tab. A1. Among them, M, N, ? p are used for contrastive learning, for which we simply follow <ref type="bibr" target="#b27">[28]</ref>. ? c , ?, ? are training-related, while ? 0 , r l , r h are additionally introduced by our U 2 PL.   <ref type="figure" target="#fig_1">Fig. A1</ref>), leading to worse results than those when the model is trained only by labeled data. Such visual difference proves that our method finally makes the reliability of unreliable prediction labels stronger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Alternative of Contrastive Learning</head><p>Our proposed U 2 PL is not limited by contrastive learning. Binary classification is also a sufficient way to use unreliable pseudo-labels, i.e., using binary cross-entropy loss (BCE) L b other than contrastive loss. For i-th anchor z ci belongs to class c, we simply use its negative samples (a) Supervised Only (b) U 2 PL <ref type="figure" target="#fig_3">Figure A2</ref>. Visualization of the feature spaces learned by our U 2 PL and its supervised counterpart, using t-SNE <ref type="bibr" target="#b25">[26]</ref>. The training set is the 1/4 partition protocol (2646) in blender VOC PASCAL 2012 Dataset. {z ? cij } N j=1 and positive sample z + c to compute the BCE loss:</p><formula xml:id="formula_21">L b = ? 1 C ? M ? N C?1 c=0 M i=1 N j=1 log e zci,z + c /? e zci,z + c /? + e zci,z ? cij /? ,<label>(A1)</label></formula><p>where C, M , and N are the total number of classes, anchor pixels, and negative samples, respectively. ?, ? is the cosine similarity of two features, and ? represents the temperature. Tab. A3 and Tab. A4 are results of using unreliable pseudo-labels based on binary classification on Cityscapes <ref type="bibr" target="#b9">[10]</ref> and PASCAL VOC 2012 <ref type="bibr" target="#b13">[14]</ref> val set respectively. From Tab. A3 and Tab. A4, we can tell that our U 2 PL is not restricted by contrastive learning, a basic binary classification also does help. On Cityscapes val set, U 2 PL with L b can outperforms supervised only baseline by +3.77%, +0.40%, +1.48%, and +0.53% under 1/16, 1/8, 1/4, and 1/2 partial protocols. U 2 PL with L b can outperforms supervised only baseline by +7.49%, +5.07%, +3.84%, and +2.67% under 1/16, 1/8, 1/4, and 1/2 partial protocols on PASCAL VOC 2012 val set. Note that under the 1/4 partition protocol of blender PASCAL VOC 2012, the bianry classification based U 2 PL (w/ L b ) outperforms the contrastive learning based U 2 PL (w/ L c ) by +0.34%, which proves that contrastive learning is not the only efficient way of using unreliable pseudo-labels.  blender VOC PASCAL 2012 Dataset. We find that 0.001 outperforms other alternatives. Temperature. Tab. A6 gives a study on the effect of temperature ? . Temperature ? plays an important role to adjust the importance to hard samples When ? = 0.5, our U 2 PL achieves best results. Too large or too small of ? will have an adverse effect on overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D.2. Ablation Studies on Cityscapes</head><p>Probability Rank Threshold. Tab. A7 provides a verification that such balance promotes the performance. r l = 3 and r h = 20 outperform other options by a large margin. Initial Reliable-Unreliable Partition. Tab. A8 studies the impact of different ? 0 . When ? 0 = 20%, the model achieves the best performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Visualization on Feature Space</head><p>To have a better understanding of U 2 PL, we give an illustration on visualization of feature space. Two t-SNE <ref type="bibr" target="#b25">[26]</ref> plots are given respectively on the supervised only method and U 2 PL.</p><p>We can observe from <ref type="figure" target="#fig_3">Fig. A2</ref> that decision boundaries of features generated by the supervised only method are quite confusing, while U 2 PL has much more clear ones. This explains why U 2 PL works from a feature point of view.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>b a c k g r o u n d a e r o p la n e b ic y c le b ir d b o a t b o t t le b u s c a r c a t c h a ir c o w d in in g t a b le d o g h o r s e m o t o r b ik e p e r s o n p o t t e d p la n t s h e e p s o fa t r a in t v m o n it o</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Category-wise performance and statistics on number of pixels with reliable and unreliable predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(b) Pseudo-label after filtering.(c) Reliable prediction (yellow cross).(d) Unreliable prediction (white cross).(a) Input image with entropy map.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Illustration on unreliable pseudo-labels. (a) Pixelwise entropy predicted from an unlabeled image, where lowentropy pixels and high-entropy pixels indicate reliable and unreliable predictions, respectively. (b) Pixel-wise pseudo-labels from reliable predictions only, where pixels within the white region are not assigned a pseudo-label. (c) Category-wise probability of a reliable prediction (i.e., the yellow cross), which is confident enough for supervising the class person. (d) Category-wise probability of an unreliable prediction (i.e., the white cross), which hovers between motorbike and person, yet is confident enough of not belonging to car and train.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>t e x i t s h a 1 _ b a s e 6 4 = " I 9 T 7 u n 3 l c Y J 4 7 G f V m f p / d 1 A K e L g = " &gt; A A A B 9 H i c b V C 7 S g N B F L 0 b X z G + o p Y 2 g 0 G w C r s i a h m w s b C I Y B 6 Q L G F 2 c p M M m Z 1 d Z 2 Y D Y c l 3 2 F g o Y u v H 2 P k 3 z i Z b a O K B g c M 5 9 3 L P n C A W X B v X / X Y K a + s b m 1 v F 7 d L O 7 t 7 + Q f n w q K m j R D F s s E h E q h 1 Q j Y J L b B h u B L Z j h T Q M B L a C 8 W 3 m t y a o N I / k o 5 n G 6 I d 0 K P m A M 2 q s 5 H d D a k a M i v R + 1 t O 9 c s W t u n O Q V e L l p A I 5 6 r 3 y V 7 c f s S R E a Z i g W n c 8 N z Z + S p X h T O C s 1 E 0 0 x p S N 6 R A 7 l k o a o v b T e e g Z O b N K n w w i Z Z 8 0 Z K 7 + 3 k h p q P U 0 D O x k F l I v e 5 n 4 n 9 d J z O D G T 7 m M E 4 O S L Q 4 N E k F M R L I G S J 8 r Z E Z M L a F M c Z u V s B F V l B n b U 8 m W 4 C 1 / e Z U 0 L 6 r e V f X y 4 b J S c / M 6 i n A C p 3 A O H l x D D e 6 g D g 1 g 8 A T P 8 A p v z s R 5 c d 6 d j 8 V o w c l 3 j u E P n M 8 f E D S S P w = = &lt; / l a t e x i t &gt; L s Unlabeled Image &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " C</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>8 W 3 m t y a o N I / k o 5 n G 6 I d 0 K P m A M 2 q s 5 H d D a k a M i v R + 1 k t 6 5 Y p b d e c g q 8 T L S Q V y 1 H v l r 2 4 / Y k m I 0 j B B t e 5 4 b m z 8 l C r D m c B Z q Z t o j C k b 0 y F 2 L J U 0 R O 2 n 8 9 A z c m a V P h l E y j 5 p y F z 9 v Z H S U O t p G N j J L K R e 9 j L x P 6 + T m M G N n 3 I Z J w Y l W x w a J I K Y i G Q N k D 5 X y I y Y W k K Z 4 j Y r Y S O q K D O 2 p 5 I t w V v + 8 i p p X l S 9 q + r l w 2 W l 5 u Z 1 F O E E T u E c P L i G G t x B H R r A 4 A m e 4 R X e n I n z 4 r w 7 H 4 v R g p P v H M M f O J 8 / E z y S Q Q = = &lt; / l a t e x i t &gt; L u &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " C e x c W j u y g 9 i r 6 t 7 V R Q 5 5 z z z r z J k = " &gt; A A A B 9 H i c b V C 7 S g N B F L 0 b X z G + o p Y 2 g 0 G w C r s i a h m w s b C I Y B 6 Q L G F 2 c p M M m Z 1 d Z 2 Y D Y c l 3 2 F g o Y u v H 2 P k 3 z i Z b a O K B g c M 5 9 3 L P n C A W X B v X / X Y K a + s b m 1 v F 7 d L O 7 t 7 + Q f n w q K m j R D F s s E h E q h 1 Q j Y J L b B h u B L Z j h T Q M B L a C 8 W 3 m t y a o N I / k o 5 n G 6 I d 0 K P m A M 2 q s 5 H d D a k a M i v R + 1 m O 9 c s W t u n O Q V e L l p A I 5 6 r 3 y V 7 c f s S R E a Z i g W n c 8 N z Z + S p X h T O C s 1 E 0 0 x p S N 6 R A 7 l k o a o v b T e e g Z O b N K n w w i Z Z 8 0 Z K 7 + 3 k h p q P U 0 D O x k F l I v e 5 n 4 n 9 d J z O D G T 7 m M E 4 O S L Q 4 N E k F M R L I G S J 8 r Z E Z M L a F M c Z u V s B F V l B n b U 8 m W 4 C 1 / e Z U 0 L 6 r e V f X y 4 b J S c / M 6 i n A C p 3 A O H l x D D e 6 g D g 1 g 8 A T P 8 A p v z s R 5 c d 6 d j 8 V o w c l 3 j u E P n M 8 f 9 + W S L w = = &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>8 9 10 Push N c into memory bank Q c ; 11 Pop oldest ones out of Q c if necessary; 12 Sample 14 L</head><label>910111214</label><figDesc>Sample M anchors: B A ? sample (A c ); Get negatives N c based on Eq. (16); N negatives: B N ? sample (Q c ); 13 Get z + based on Eq. (12); ? L + (B A , B N , z + ) based on Eq. (4); 15 end 16 end Output: contrastive loss L c ? 1 |B|?C L particular categories are extremely limited in a mini-batch.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Ground-Truth (c) Supervised Only (d) Plain ? ! (e) U 2 PL</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 4 .</head><label>4</label><figDesc>Qualitative results on PASCAL VOC 2012 val set. All models are trained under the 1/4 partition protocol of blender set, which contains 2, 646 labeled images and 7, 396 unlabeled images. (a) Input images. (b) Hand-annotated labels for the corresponding image. (c) Only labeled images are used for training without any unlabeled data. (d) The vanilla contrastive learning framework, where all pixels are used as negative samples without entropy filtering. (e) Predictions from our U 2 PL. Yellow rectangles highlight the promotion of segmentation results by adequately using unreliable pseudo-labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Ground-Truth (c) Supervised Only (d) Plain ? ! (e) U 2 PL Figure A1. Qualitative results on Cityscapes val set. All models are trained under the 1/2 partition protocol, which contains 1, 488 labeled images and 1, 487 unlabeled images. (a) Input images. (b) Hand-annotated labels for the corresponding image. (c) Only labeled images are used for training. (d) The vanilla contrastive learning framework, where all pixels are used as negative samples without entropy filtering. (e) Predictions from our U 2 PL. Yellow rectangles highlight the promotion by adequately using unreliable pseudo-labels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>D</head><label></label><figDesc>. More Ablation Studies D.1. More Hyper-parameters on VOC Base Learning Rate. The impact of the base learning rate is shown in Tab. A5. Results are based on U 2 PL on</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Comparison with state-of-the-art methods on Cityscapes val set under different partition protocols. All labeled images are selected from the Cityscapes train set, which consists of 2, 975 samples in total. "SupOnly" stands for supervised training without using any unlabeled data. ? means we reproduce the approach.PL  (w/ CutMix) 70.30 (+3.24) 74.37 (+2.54) 76.47 (+0.11) 79.05 (+0.80) U 2 PL (w/ AEL) 74.90 (+0.45) 76.48 (+0.93) 78.51 (+1.03) 79.12 (+0.11) important to note the classic PASCAL VOC 2012 Dataset and blender PASCAL VOC 2012 Dataset only differ in training set. Their validation set are the same common one with 1, 449 images. Results on classic PASCAL VOC 2012 Dataset. Tab. 1 compares our method with the other state-of-the-art methods on classic PASCAL VOC 2012 Dataset. U 2 PL out-Our method U 2 PL outperform PC 2 Seg under all partition protocols by +10.98%, +2.87%, +3.88% and +3.11% under 1/16, 1/8, 1/4 and 1/2 partition protocols respectively. Even under full supervision, our method outperform PC 2 Seg by +5.34%. Results on blender PASCAL VOC 2012 Dataset. Tab. 2 shows the comparison results on blender PASCAL VOC 2012 Dataset. Our method U 2 PL outperforms all the other methods under most partition protocols. Compared with the baseline model (trained with only supervised data), U 2 PL achieves all improvements of +9.34%, +7.46%, +3.50% PL outperforms AEL by +1.44% and +1.24%. Results on Cityscapes Dataset. Tab. 3 illustrates the comparison results on the Cityscapes val set. U 2 PL achieves consistent performance gains over the supervised only baseline by +9.16%, +3.95%, +4.08% and +1.29%</figDesc><table><row><cell>Method</cell><cell>1/16 (186)</cell><cell>1/8 (372)</cell><cell>1/4 (744)</cell><cell>1/2 (1488)</cell></row><row><cell>SupOnly</cell><cell>65.74</cell><cell>72.53</cell><cell>74.43</cell><cell>77.83</cell></row><row><cell>MT  ? [38]</cell><cell>69.03</cell><cell>72.06</cell><cell>74.20</cell><cell>78.15</cell></row><row><cell>CutMix  ? [15]</cell><cell>67.06</cell><cell>71.83</cell><cell>76.36</cell><cell>78.25</cell></row><row><cell>CCT [33]</cell><cell>69.32</cell><cell>74.12</cell><cell>75.99</cell><cell>78.10</cell></row><row><cell>GCT [22]</cell><cell>66.75</cell><cell>72.66</cell><cell>76.11</cell><cell>78.34</cell></row><row><cell>CPS  ? [9]</cell><cell>69.78</cell><cell>74.31</cell><cell>74.58</cell><cell>76.81</cell></row><row><cell>AEL  ? [21]</cell><cell>74.45</cell><cell>75.55</cell><cell>77.48</cell><cell>79.01</cell></row><row><cell>U 2</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>performs the supervised baseline by +22.21%, +14.23%, +7.78% and +4.47% under 1/16, 1/8, 1/4 and 1/2 partition protocols respectively. For a fair comparison, we only list the methods tested on classic PASCAL VOC 2012.under 1/16, 1/8, 1/4 and 1/2 partition protocols. U 2 PL outperforms the existing state-of-the-art method by a no- table margin. In particular, U 2 PL outperforms AEL by +0.45%, +0.93%, +1.03% and +0.11% under 1/16, 1/8, 1/4 and 1/2 partition protocols.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Effectiveness of Components.We conduct experiments in Tab. 6 to ablate each component of U 2 PL step by step. For a fair comparison, all the ablations are under 1/4 partition protocol on blender PASCAL VOC 2012 Dataset. Above all, we use no L c trained model as our baseline, achieving mIoU of 73.02% (MT in Tab. 2). Simply adding L c without DPA strategy improves the baseline by +4.06%. Categorywise memory bank Q c , along with PRT and high entropy filtering brings an improvement by +5.47% to baseline.</figDesc><table><row><cell>? 0</cell><cell>40%</cell><cell>30%</cell><cell>20%</cell><cell>10%</cell></row><row><cell>1/8 (1323)</cell><cell>76.77</cell><cell>77.34</cell><cell>79.01</cell><cell>77.80</cell></row><row><cell>1/4 (2646)</cell><cell>76.92</cell><cell>77.38</cell><cell>79.30</cell><cell>77.95</cell></row></table><note>Dynamic Partition Adjustment (DPA) together with high entropy filtering, brings an improvement by +6.05% to baseline. Note that DPA is a linear adjustment without tuning (refer to Eq.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table A1 .</head><label>A1</label><figDesc>Summary of hyper-parameters used in U 2 PL. Tab. A2 demonstrates the mIoU results on Cityscapes val set. "Unreliable" outperforms other options, proving using unreliable pseudo-labels does help. U 2 PL fully mines the information of all pixels.</figDesc><table><row><cell cols="2">Symbol Description</cell><cell>Default Value</cell></row><row><cell cols="2">(M, N ) contrastive learning settings</cell><cell>(50, 256)</cell></row><row><cell>? p</cell><cell cols="2">confidence threshold of positive samples 0.3</cell></row><row><cell>(? c , ?)</cell><cell>loss weights</cell><cell>(0.1, 1)</cell></row><row><cell>?</cell><cell>loss temperature</cell><cell>0.5</cell></row><row><cell>? 0</cell><cell>initial proportion of unreliable pixels</cell><cell>20%</cell></row><row><cell>(r l , r h )</cell><cell>probability rank thresholds</cell><cell>(3, 20)</cell></row><row><cell cols="2">B. More Results on Cityscapes</cell><cell></cell></row><row><cell cols="2">Quantitative Results.</cell><cell></cell></row></table><note>Qualitative Results. Fig. A1 shows the results of different methods on the Cityscapes val set. Benefiting by using unreliable pseudo-labels, U 2 PL outperforms other methods. Note that using contrastive learning without filtering those</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table A2 .</head><label>A2</label><figDesc>Ablation study on using pseudo pixels with different reliability, which is measured by the entropy of pixel-wise prediction. "Unreliable" denotes selecting negative candidates from pixels with top 20% highest entropy scores. "Reliable" denotes the bottom 20% counterpart. "All" denotes sampling regardless of entropy. We prove this effectiveness under 1/2 and 1/4 partition protocol on Cityscapes val set.</figDesc><table><row><cell></cell><cell>Unreliable</cell><cell>Reliable</cell><cell>All</cell></row><row><cell>1/2 (1488)</cell><cell>79.05</cell><cell>77.19</cell><cell>76.96</cell></row><row><cell>1/4 (744)</cell><cell>76.47</cell><cell>75.16</cell><cell>74.51</cell></row><row><cell cols="4">unreliable pixels, sometimes does harm to the model (see</cell></row><row><cell cols="2">the 1-st row and the 4-th row in</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table A3 .Table A4 .</head><label>A3A4</label><figDesc>Using unreliable pseudo-labels based on binary classification on Cityscapes val set under different partition protocols. Using unreliable pseudo-labels based on binary classification on PASCAL VOC 2012 val set under different splits.</figDesc><table><row><cell>Method</cell><cell cols="4">1/16 (186) 1/8 (372) 1/4 (744) 1/2 (1488)</cell></row><row><cell>SupOnly</cell><cell>65.74</cell><cell>72.53</cell><cell>74.43</cell><cell>77.83</cell></row><row><cell>MT [38]</cell><cell>69.03</cell><cell>72.06</cell><cell>74.20</cell><cell>78.15</cell></row><row><cell>U 2 PL (w/ L c ) U 2 PL (w/ L b )</cell><cell>70.30 69.87</cell><cell>74.37 72.93</cell><cell>76.47 75.91</cell><cell>79.05 78.36</cell></row><row><cell>Method</cell><cell cols="4">1/16 (662) 1/8 (1323) 1/4 (2646) 1/2 (5291)</cell></row><row><cell>SupOnly</cell><cell>67.87</cell><cell>71.55</cell><cell>75.80</cell><cell>77.13</cell></row><row><cell>MT [38]</cell><cell>70.51</cell><cell>71.53</cell><cell>73.02</cell><cell>76.58</cell></row><row><cell>U 2 PL (w/ L c ) U 2 PL (w/ L b )</cell><cell>77.21 75.36</cell><cell>79.01 76.62</cell><cell>79.30 79.64</cell><cell>80.50 79.80</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table A5 .Table A6 .Table A7 .Table A8 .</head><label>A5A6A7A8</label><figDesc>Ablation study on base learning rate under 1/4 partition protocol (2646) in blender VOC PASCAL 2012 Dataset. Ablation study on temperature under 1/4 partition protocol (2646) in blender VOC PASCAL 2012 Dataset. Ablation study on PRT on Cityscapes val set. (372) 71.41 72.08 72.60 74.37 72.24 1/4 (744) 76.27 76.04 76.01 76.47 76.18 Ablation study on ?0 on Cityscapes val set.</figDesc><table><row><cell>lr base</cell><cell>10 ?1</cell><cell></cell><cell>10 ?2</cell><cell>10 ?3</cell><cell>10 ?4</cell><cell>10 ?5</cell></row><row><cell>mIoU</cell><cell>3.49</cell><cell></cell><cell>77.82</cell><cell>79.30</cell><cell>74.58</cell><cell>65.69</cell></row><row><cell>?</cell><cell>10</cell><cell></cell><cell>1</cell><cell>0.5</cell><cell>0.1</cell><cell>0.01</cell></row><row><cell>mIoU</cell><cell cols="2">78.88</cell><cell>78.91</cell><cell>79.30</cell><cell>79.22</cell><cell>78.78</cell></row><row><cell>r l</cell><cell cols="2">1</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>10</cell></row><row><cell>r h</cell><cell cols="2">3</cell><cell>20</cell><cell>10</cell><cell>20</cell><cell>20</cell></row><row><cell>1/8 ? 0</cell><cell></cell><cell cols="2">40%</cell><cell>30%</cell><cell>20%</cell><cell>10%</cell></row><row><cell cols="2">1/8 (372)</cell><cell cols="2">72.07</cell><cell>72.93</cell><cell>74.37</cell><cell>71.63</cell></row><row><cell cols="2">1/4 (744)</cell><cell cols="2">75.20</cell><cell>76.08</cell><cell>76.47</cell><cell>76.40</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. More Details for Reproducibility</head><p>For Cityscapes <ref type="bibr" target="#b9">[10]</ref>, we utilize OHEM which is the same as previous methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b20">21]</ref>. The temperature ? is set to 0.5 for both PASCAL VOC 2012 <ref type="bibr" target="#b13">[14]</ref> and Cityscapes <ref type="bibr" target="#b9">[10]</ref>. We use SGD optimizer for all experiments. For experiments in PASCAL VOC 2012 <ref type="bibr" target="#b13">[14]</ref>, the initial base learning rate is 0.001 and the weight decay is 0.0001. For experiments in Cityscapes <ref type="bibr" target="#b9">[10]</ref>, the initial base learning rate is 0.01 and the weight decay is 0.0005. In our experiments, we find if we train the model only with supervised loss for the initial a few epochs then apply U 2 PL, it can achieve better performance. We define such epoch as the warm start epoch, and the corresponding warm start epochs for PASCAL VOC 2012 and Cityscapes are 1 and 20 respectively.</p><p>To prevent overfitting, we apply random cropping, random horizontal flipping, and random scaling with the range of [0.5, 2.0] for both PASCAL VOC 2012 <ref type="bibr" target="#b13">[14]</ref> and Cityscapes <ref type="bibr" target="#b9">[10]</ref> following previous methods [9, 21, 48,   </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>We organize the Appendix as follows. Above all, more details for reproducing the results will be given in Appendix A. Then we will give more results on Cityscapes from two perspectives in Appendix B. We also provide an alternative of contrastive learning to prove our main insight does not only rely on contrastive learning in Appendix C. Besides, ablation studies on both PASCAL VOC 2012 and Cityscapes for more hyper-parameters are given in Appendix D. Finally, visualization on feature space gives a visual proof for the effectiveness of U 2 PL in Appendix E.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with pixel-level contrastive learning from a class-wise memory bank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Inigo</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Sabater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ferstl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Montesano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ana</forename><forename type="middle">C</forename><surname>Murillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pseudo-labeling and confirmation bias in deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E O&amp;apos;</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCNN</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ouais</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Doina</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation by improving prediction confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqiang</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">An empirical study of training self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis., 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with cross pseudo supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Aleatory or epistemic? does it matter? Structural Safety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armen</forename><surname>Der Kiureghian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ove</forename><surname>Ditlevsen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="105" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (voc) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation needs strong, varied perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>French</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuli</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Aila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Mackiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Finlayson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Brit. Mach. Vis. Conf., 2020. 1</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yves</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CAP</title>
		<imprint>
			<biblScope unit="volume">367</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="281" to="296" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Bootstrap your own latent: A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><forename type="middle">Daniel</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Azar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07733</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Semantic contours from inverse detectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Bharath Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Arbel?ez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Re-distributing biased pseudo labels for semi-supervised semantic segmentation: A baseline investigation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruifei</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation via adaptive equalization learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanzhe</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiwei</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinshi</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Guided collaborative training for pixel-wise semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhanghan</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaican</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rynson Wh</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">What uncertainties do we need in bayesian deep learning for computer vision?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Nlnl: Negative learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junho</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juseung</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Joint negative and positive learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juseung</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyounguk</forename><surname>Shon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
		<idno>2021. 3</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Visualizing data using t-sne</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">JMLR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Int. Conf. Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">896</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Bootstrapping semantic segmentation with regional contrast</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shikun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuaifeng</forename><surname>Zhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Johns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew J</forename><surname>Davison</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.04465</idno>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Evaluating bayesian deep learning methods for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jishnu</forename><surname>Mukhoti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yarin</forename><surname>Gal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.12709</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Classmix: Segmentation-based data augmentation for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Tranheden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juliano</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lennart</forename><surname>Svensson</surname></persName>
		</author>
		<idno>2021. 2</idno>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Semisupervised semantic segmentation with cross-consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yassine</forename><surname>Ouali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C?line</forename><surname>Hudelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myriam</forename><surname>Tami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">In defense of pseudo-labeling: An uncertainty-aware pseudo-label selection framework for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mamshad Nayeem Rizve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yogesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Rawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Int. Conf. Learn. Represent</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unet: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehran</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Tasdizen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ekin</forename><surname>Dogus Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Harri</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Adv. Neural Inform. Process. Syst</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Negative pseudo labeling using class proportion for semantic segmentation in pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroki</forename><surname>Tokunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><forename type="middle">Kenji</forename><surname>Iwana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Teramoto</surname></persName>
		</author>
		<idno>2020. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Eur. Conf. Comput. Vis</title>
		<imprint/>
	</monogr>
	<note>Akihiko Yoshizawa, and Ryoma Bise</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Exploring cross-image pixel contrast for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ender</forename><surname>Konukoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis., 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Self-training with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qizhe</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minh-Thang</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Dash: Semi-supervised learning with dynamic thresholding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinxing</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Feng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baigui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Int. Conf. Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">St++: Make self-training work better for semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lihe</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.05095</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A simple baseline for semi-supervised semantic segmentation with strong data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis., 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conf. Comput. Vis. Pattern Recog</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Contrastive learning for label efficient semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyun</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raviteja</forename><surname>Vemulapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><forename type="middle">Andrew</forename><surname>Mansfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boqing</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lior</forename><surname>Shapira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis., 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Pixel contrastive-consistent semi-supervised semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanyi</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodi</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Xiong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">C3-semiseg: Contrastive semi-supervised segmentation via cross-set learning and dynamic classbalancing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanning</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Int. Conf. Comput. Vis., 2021</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Pseudoseg: Designing pseudo labels for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuliang</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chun-Liang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Bian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Jia-Bin Huang, and Tomas Pfister</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simiao</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoming</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siawpeng</forename><surname>Er</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tuo</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyuan</forename><surname>Zha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.07049</idno>
		<title level="m">Self-training with differentiable teacher</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
