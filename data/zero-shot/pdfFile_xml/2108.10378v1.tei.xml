<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Lightweight Multi-person Total Motion Capture Using Sparse Multi-view Cameras</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation and BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation and BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>An</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation and BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengcheng</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation and BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation and BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation and BNRist</orgName>
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Lightweight Multi-person Total Motion Capture Using Sparse Multi-view Cameras</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multi-person total motion capture is extremely challenging when it comes to handle severe occlusions, different reconstruction granularities from body to face and hands, drastically changing observation scales and fast body movements. To overcome these challenges above, we contribute a lightweight total motion capture system for multi-person interactive scenarios using only sparse multiview cameras. By contributing a novel hand and face bootstrapping algorithm, our method is capable of efficient localization and accurate association of the hands and faces even on severe occluded occasions. We leverage both pose regression and keypoints detection methods and further propose a unified two-stage parametric fitting method for achieving pixel-aligned accuracy. Moreover, for extremely self-occluded poses and close interactions, a novel feedback mechanism is proposed to propagate the pixel-aligned reconstructions into the next frame for more accurate association. Overall, we propose the first light-weight total capture system and achieves fast, robust and accurate multi-person total motion capture performance. The results and experiments show that our method achieves more accurate results than existing methods under sparse-view setups.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Marker-less motion capture, due to its great potentials for behaviour understanding, sports analysis, human animation, video editing and virtual reality, has been a popular research topic in computer vision and graphics for decades. Within this research field, total motion capture, pioneered by <ref type="bibr" target="#b21">[22]</ref> using an extremely dense-view setup (hundreds of cameras), shows impressive results of simultaneous capture of multi-person total interactive behaviours including facial expressions, body and hand poses, and has aroused widespread interest in computer vision community. However, this work <ref type="bibr" target="#b21">[22]</ref> suffers from expensive and sophisticated hardware setup and low run-time efficiency.</p><p>Recently, to reduce the capture complexity, more and * Corresponding Author <ref type="figure">Figure 1</ref>. Our lightweight total capture system produces expressive human models with sparse multi-view cameras.</p><p>more researches try to perform total motion capture from only a single image or video <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b63">64]</ref>. By either optimizing a parametric models like SMPL-X <ref type="bibr" target="#b40">[41]</ref> and Adam <ref type="bibr" target="#b21">[22]</ref> ( <ref type="bibr" target="#b54">[55]</ref>) or regressing the model parameters directly from the input images <ref type="bibr" target="#b12">[13]</ref>, these methods even achieve real-time total motion capture performance for single-person <ref type="bibr" target="#b44">[45,</ref><ref type="bibr" target="#b63">64]</ref>. However, it remains difficult for the monocular methods to handle severe occlusions and challenging poses under multi-person interactive scenarios. To guarantee both lightweight setups and robust performance, we propose the first lightweight total capture system using only sparse multi-view cameras. However, extending the existing monocular total capture methods to sparse-view multi-person total capture is not trivial. Although the incorporation of multi-view observations may resolve the depth ambiguities for monocular methods, the severe occlusions caused by complex-poses and multi-person interactions will significantly deteriorate the performance for current total capture methods. Specifically, the main challenges include: i) hand/face association across multiple views under drastically changing observation scales and unstable detection results, ii) pixel-aligned fitting between the reconstructed 3D model and the input images, and iii) robust and accurate body association under severe occlusions even for close interactions. To resolve all the challenges above, we propose, as far as we know, the first method to achieve fast, robust and accurate multi-person total motion capture using only light-weight sparse-view cameras.</p><p>First of all, compared with the relatively fixed body part scales and satisfactory occlusion-free view point in monocular single-person total capture cases <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b63">64]</ref>, sparse multi-view setups suffer from hand/face fragments on account of severe occlusions, blurs on hands and even fingers by fast limb movements, and varying hand/face scales across different cameras. Moreover, it remains challenging to associate hands correctly when different hands are located very closely on an image. To resolve these challenges, we propose a novel hand and face bootstrapping algorithm to extract accurate body part features effectively from the sparse and multi-scale images for accurate association. Benefiting from the recent progress in multiperson skeleton pose capture <ref type="bibr" target="#b61">[62]</ref>, the skeleton-level results are utilized to guide the following object-detection network for more robust and accurate detection. Moreover, we introduce the cross-modality consistency and cross-scale consistency to filter unexpected detection results of fragments caused by occlusions or improper view points. Secondly, using only the pose-regression methods or the key-point detection methods cannot yet guarantee accurate parametric model fitting. Firstly, pose-regression methods <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b63">64]</ref> are able to reconstruct decent hand gestures in self-occlusion cases, but these one-shot methods cannot guarantee pixel level alignment with 2D joint positions on the image. On the other hand, keypoint-detection methods <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b54">55]</ref> are capable of providing pixel-aligned geometric features for visible joints, but may need heavy postprocessing optimizations, which is quite sensitive to the initialization and usually fails due to self-occlusion. To fully leverage the advantages of both categories and avoid their drawbacks, we propose a new unified two-stage parametric fitting method, in which we leverage the pose-regression result as the initial value to accelerate the convergence for parametric model fitting based on the detected keypoints, and finally achieves pixel-aligned fitting accuracy without losing the efficiency.</p><p>Last but not least, for extremely complex poses and close interactions, even 4D association <ref type="bibr" target="#b61">[62]</ref> may fail in the body association step, which is an inherent and natural limitation for sparse multi-view setups. To this end, we propose a feedback mechanism in which the reconstructed pixelaligned human parametric models in the previous frame are propagated into the current frame for enhancing soft visibility information and finally achieve accurate association result. Benefiting from this novel feedback mechanism, our method is able to capture accurate human behaviours even under scenarios with severe occlusions and close interactions.</p><p>Our contributions can be concluded as:</p><p>? A new hand and face bootstrapping method that involves the body-level skeleton guidance for more accurate body part localization and self-validated consistency scores to filter out the noise of fragmented detection results by unexpected view points or occlusion observations (Sec. 4).</p><p>? A new unified two-stage parametric fitting method that fully utilizes both pose-regression and keypoint-detection methods to produce accurate pixel-aligned 3D human models with expressive motion (Sec. 5). ? A new feedback mechanism that propagates the accurate reconstruction into the next frame to further improve the association accuracy especially on the severe occluded occasions (Sec. 6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Total Motion Capture</head><p>Total motion capture methods, which aim at markerless multi-scale human behaviour capture (including body motion, facial expressions and hand gestures), have shown great potentials in human 4D reconstruction and highfidelity neural rendering <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b62">63]</ref>. As the pioneering method of total motion capture, <ref type="bibr" target="#b21">[22]</ref> achieved promising human behaviours capture results under the setup of hundreds of cameras, however, this method relies on the expensive and sophisticated hardware and is therefore hard for applications. On the other end of the spectrum, to achieve lightweight and convenient capture, many works <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b63">64]</ref> focused on total capture from a monocular setup. Monocular total capture <ref type="bibr" target="#b54">[55]</ref> and SMPLify-X <ref type="bibr" target="#b40">[41]</ref> optimized parametric human models (SMPL-X <ref type="bibr" target="#b40">[41]</ref> and Adam <ref type="bibr" target="#b21">[22]</ref>) to fit with the 2D detected keypoints. Choutas et al. <ref type="bibr" target="#b12">[13]</ref> directly regressed the parameters of SMPL-X <ref type="bibr" target="#b40">[41]</ref> from a single RGB image and refined the captured results of head and hands subsequently. Pose2Pose <ref type="bibr" target="#b34">[35]</ref> combined global and local image features for more accurate prediction. FrankMocap <ref type="bibr" target="#b44">[45]</ref> regressed parameters of hand and body poses separately and finally integrated two parts into a unified whole body output. Zhou et al. <ref type="bibr" target="#b63">[64]</ref> exploited the motion relationship between body and hands to design the network and achieved real-time monocular capture. Overall, although current monocular methods could achieve plausible human total capture performance, they still suffer from depth ambiguity and occlusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Skeleton-based Pose Reconstruction</head><p>Single-view 2D and 3D pose estimation methods <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b59">60]</ref> have been widely explored in recent years, however, they suffer from severe occlusions and ambiguity and cannot produce highconfidence results. To alleviate the occlusion and produce more accurate reconstruction, many works aimed to reconstruct human poses from multi-view input. On the first branch of this direction, some approaches <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b39">40]</ref> preformed temporal skeleton-based tracking for each frame, but these methods suffer from imperfect initialization and accumulated errors. On another branch, cross-view matching methods associated correspondences (e.g., human instances and keypoints) from different viewpoints and finally reconstructed 3D pose for each performer.</p><p>Some works utilized 3DPS models to solve 3D joint positions implicitly by skeletal constraints <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> or body part detection <ref type="bibr" target="#b14">[15]</ref>. Joo et al. <ref type="bibr" target="#b20">[21]</ref> utilized 2D detection from dense multiple views to vote for possible 3D joint positions. Dong et al. <ref type="bibr" target="#b13">[14]</ref> proposed a multi-way matching algorithm to guarantee cycle consistency across all the views. Zhang et al. <ref type="bibr" target="#b61">[62]</ref> jointly formulated the temporal tracking and cross-view matching as a 4D association graph and achieved real-time performance. Tu et al. <ref type="bibr" target="#b50">[51]</ref> proposed to directly operate in the 3D space while avoiding incorrect decisions in each viewpoint. Lin et al. <ref type="bibr" target="#b29">[30]</ref> presented a plane-sweep-based approach to perform multi-view multiperson 3D pose estimation without the explicit cross-view matching. Even though these methods are able to capture 3D human poses using skeletons, they cannot reconstruct full body behaviours, i.e., facial expressions, hand motions, and body surfaces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">3D Hand Reconstruction</head><p>3D hand reconstruction is an essential sub-problem in total capture. Many works <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b36">37]</ref> that focused on 3D hand pose estimation from a single RGB image have been proposed. Recently, more and more works aimed at recovery of a 3D hand mesh <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b9">10]</ref> or directly regressing the pose and shape parameters of a parametric hand model (MANO <ref type="bibr" target="#b43">[44]</ref>) <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b65">66,</ref><ref type="bibr" target="#b10">11]</ref>. However, these methods only focused on single hand reconstruction while ignoring the interaction between hands. Moon et al. <ref type="bibr" target="#b35">[36]</ref> proposed InterHand2.6M, a large-scale two hand interaction dataset. Several researchers have explored the problem of pose estimation under two hand interacting situation <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b58">59]</ref>, but the problem of hand pose estimation under multi-person interacting scenario with more hands involved is still unsolved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Overview</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Main Pipeline</head><p>As shown in <ref type="figure">Fig. 2</ref>, given multiple synchronous and calibrated RGB videos as input, our pipeline works in a frameby-frame manner, and outputs a series of parametric human models naturally combining body posture, hand gesture and facial expressions by the following steps: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">4D Body Association</head><p>As a building block of our method, the 4D association <ref type="bibr" target="#b61">[62]</ref> contributes a real-time multi-person skeleton tracking framework with sparse multi-view video inputs. By taking the tracked 3D joints from the previous frame and the detected 2D key-points in current frames as graph nodes D j , 4D association algorithm introduces a series of connecting edges: single-view parsing edges E P , cross-view matching edges E V and temporal tracking edges E T , and finally formulate a unified association graph G 4D for optimizing the multi-view body association problem effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Hand and Face Bootstrapping</head><p>We introduce a hand and face bootstrapping method to (i) extract local body part regions of interest (RoI) and detection from full-body inputs and (ii) eliminate incorrectly associated matches using the proposed non-maximum suppression (NMS) method. Body-level semantic features, hand pose regressions and keypoint detections are integrated into our pipeline. Note that the proposed bootstrapping methods for hand and face are quite similar, but the interactive hand behaviour is much more frequent under practical multi-person scenarios. So in this section, we mainly introduce the hand bootstrapping method which is more representative, and the method for face is similar.</p><p>Specifically, given sparse multi-view image inputs at frame t, we firstly leverage the 4D association algorithm (Sec. 3.2) to get the associated 2D body keypoints in each view and the triangulated 3D body skeletons. Secondly, we indicate preliminary screened RoIs {RoI c ? } through body skeleton semantic information, then a lightweight objectdetection network is utilized for further localizing tight and reliable RoIs {RoI c ? } in these initiatory screened areas to boost the key point detection and parametric regression performance of hands. However, there may exist several RoI c ? corresponding to different hands in a single RoI c ? due to close interactions and bad view directions as shown in <ref type="figure" target="#fig_1">Fig. 4 (b)</ref>. This will lead to severe ambiguity in the later hand association step. To eliminate these ambiguous RoIs, we propose a double-check non-maximum suppression (NMS) method to guarantee both cross-modality (between key point detection and parametric regression of hands) and cross-scale (between body reconstruction and hand reconstruction) consistency. Next, we will introduce the 2D hand localization and association in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">2D Hand Localization</head><p>We conduct 2D hand localization in a coarse-to-fine manner: first generating initial bounding box for each hand <ref type="figure">Figure 2</ref>. Method overview. Initially, we take multi-view RGB sequences and body estimation results as our inputs. Skeletons of each individuals are constructed by 4D association(Sect. 3.2). After that, we utilize our limb bootstrapping framework to localize(Sect. 4.1) and associate(Sect. 4.2) body part. After that, we optimize parametric SMPL-X models from all these outputs(Sect. 5). Finally, our feedback mechanism(Sect. 6) is introduced to boost the body association performance in next frame with the reconstructed human model. according to the reconstructed 3D body skeleton and semantic information, and then refine the initial bounding boxes using the iterative hand detector <ref type="bibr" target="#b52">[53]</ref>. Note that this strategy helps us filter out the inconsequential areas efficiently at the coarse level, thus reducing unnecessary computation and accelerating the hand localization process.</p><p>For generating the initial bounding box for a hand, we leverage the reconstructed 3D body skeleton to interpolate the center of hand and construct a 3D bounding sphere with constant radius to handle size variations of hands on 2D images caused by perspective projection. We then generate the initial 2D bounding box according to the projected center and radius of the 3D bounding ball in each view. Specifically, we estimate {RoI c k,? } of person k in each view c under the guidance of the reconstructed body skeletons:</p><formula xml:id="formula_0">o c p = P c (O p ), r c p = f c ? R d c (O p ) , {RoI c k,? } = {Rect(o c p , r c p )|z c p = 1, p = 1, 2, ..., P },<label>(1)</label></formula><p>where O p and R is sphere center and radius. O p could be simply extrapolated from the 3D position of wrist and elbow, and R is a constant parameter defined in terms of realistic physical scale. o c p and r c p are the projected circle center and radius in view c, respectively. f c is the focal length of camera c, P c (?) is perspective projection function, and d c (?) is the distance to camera's image plane. An indicated variable z c p is introduced for whether the wrist joint of person p has been assigned a 2D keypoint detection in view c.</p><p>Since current hand keypoints detection and regression methods still rely on tight and accurate bounding boxes for achieving good performance, we further refine the initial bounding boxes using the iterative hand detector <ref type="bibr" target="#b52">[53]</ref>. As shown in <ref type="figure" target="#fig_0">Fig. 3</ref>, we utilize that one-pass hand detection network to further extract more precise RoIs {RoI c k,? }. We demonstrate that our two-step localization method outperforms the light-weight detector (e.g., 100DOH <ref type="bibr" target="#b45">[46]</ref> used in FrankMocap <ref type="bibr" target="#b44">[45]</ref>) on both the speed and accuracy <ref type="figure" target="#fig_7">(Fig. 11</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Hand Association</head><p>Since 2D body joints have been associated and 3D body skeletons of different subjects have been triangulated in previous steps, in this section, we mainly focusing on how to assign correct bounding boxes of hands to the 3D wrist joints in each view.</p><p>We leverage classical non-maximum suppression (NMS) <ref type="bibr" target="#b4">[5]</ref> algorithm but proposed two novel consistency scores to effectively filter out ambiguous RoIs. Specifically, crossmodality consistency score ? c k and cross-scale consistency score ? c k are proposed to judge which match will be finally retained. In practice, hands usually come close or even overlapped in some side views, and interactions among individuals will lead to more ambiguities. Specifically, considering the case that RoI c k1,? ? RoI c k2,? = ?, k 1 = k 2 , as illustrated in <ref type="figure" target="#fig_1">Fig. 4</ref>, RoI c k1,?2 (dark blue) and RoI c k2,? (red) share the same sub-region, which results in association ambiguities. Inspired by traditional NMS algorithms in object-detection pipeline, we come up with a self-validated association algorithm to filter out redundant RoI c ? and re- tain the correct match. Firstly, for each view c, we locate all redundant RoIs by calculating Intersection of Union (IoU) from total individuals' hands proposals. Secondly, we calculate cross-modality consistency score ? c k and cross-scale consistency score ? c k for each RoI proposal. The first metric, cross-modality consistency score ?, is used to penalize the inconsistency between different detection modalities. As shown in <ref type="figure" target="#fig_1">Fig. 4 (c)</ref>, (d) and (e), the heatmap-based feature is invariant with respect to flipping translation, but pose-regression network needs right chirality assurance for achieving reasonable results. This divergence can help us to distinguish the left or right association ambiguities. Denote J h = 21 as the hand joint number, S h regr ? R 2?J h as 2D hand joint positions from pose-regression network, S h dect ? R 2?J h as the output of keypoint-detection network, and w, h as the size of RoI ? . Then ? is formulated as</p><formula xml:id="formula_1">? = 1 J h J h j=1 max(0, 1 ? 2 S h regr,j ? S h dect,j 2 ? w 2 + h 2 ). (2)</formula><p>On the other hand, the second metric, cross-scale consistency score ?, is formulated to punish unreasonable wrist misalignment between the local hand estimator and global body estimator. Denote S b wrt ? R 2 as the associated 2D wrist position from full-body detections, S h dect,jw as wrist joint position by local hand keypoints detector. Finally, ? is defined as</p><formula xml:id="formula_2">? = max(0, 1 ? 2 S b wrt ? S h dect,jw 2 ? w 2 + h 2 ).<label>(3)</label></formula><p>Finally, we sum up these two scores as confidence measurements to apply the NMS algorithm to reserve the one with the highest score. We demonstrate that our double-check NMS method helps to improve the association accuracy in confusing situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Two-stage Parametric Fitting</head><p>We observe that previous methods usually utilize either parametric pose regression <ref type="bibr" target="#b44">[45]</ref> or heatmap-based keypoints <ref type="bibr" target="#b40">[41]</ref> for total motion capture. However, they do have their own limitations. On one hand, although pose-regression networks can produce plausible results even under occlusions, they can not guarantee accurate 2D alignment with the input image. On the other hand, heatmap-based networks provide accurate 2D detections for visible joints, but they are still suffer from depth ambiguities and are susceptible to local minima during optimization. In this paper, we unify them together in a two-stage parametric fitting scheme, which contains local initialization and total optimization, to boost the total motion capture performance. Local Initialization To accelerate convergence and prevent optimization deviation, it is essential to initialize the motion of each body part to a reasonable status. Specifically, for hand pose initialization, we pick a decent initial value from the semantic pose-regression gestures according to the hand association score ? (Eqn. 2) and ? (Eqn. 3). Besides, for body/head pose initialization, we solve the SMPL-X body pose by minimizing the following energy function directly to guarantee more accurate initialization:</p><formula xml:id="formula_3">E body = ? b3d E b3d + ? pri E pri + ? ? E ?<label>(4)</label></formula><p>Here, E b3d is the distance from parametric model's joints to the corresponding reconstructed 3D body skeletons. E pri and E ? are used to regularize natural pose and shape optimization as in SMPLify-X <ref type="bibr" target="#b40">[41]</ref>. Total Optimization In this stage, we leverage the accurate 2D hands keypoints and faces landmarkers to further optimize the initial SMPL-X model for accurate total capture:</p><formula xml:id="formula_4">E total = E data + E reg , E data = ? b3d E b3d + ? h2d E h2d + ? f 2d E f 2d , E reg = ? pri E pri + ? ? E ? + ? ?,h E ?,h + ? ? E ? ,<label>(5)</label></formula><p>where E h2d and E f 2d are 2D data terms to minimize the distances between the 2D projections of the SMPL-X joints and the detected 2D keypoints in all the valid viewpoints. ? e c h2d , where c is the view index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Feedback Mechanism</head><p>Last but not least, for severe occlusions and close interactions, we put forward a feedback mechanism to boost the tracking performance of the association algorithm in return. On one hand, detailed limb detector contributes to extremity reconstruction with higher precision, which are leveraged to refine the body skeleton results. On the other hand, we re-render the human model to each view for the next frame to extend the tracking edges E T of G 4D with additional visibility information. As shown in <ref type="figure" target="#fig_3">Fig. 6</ref>, we obtain the initial segmentation by rendering the optimized parametric models back to input images. Meanwhile, in order to enhance the robustness with body movements, we implement distance transformation to smooth the boundary of the rendered mask.</p><p>For a given 2D keypoint detection candidate c, we use the same denotation z k (c) in <ref type="bibr" target="#b61">[62]</ref> to refer the possibility to connect that candidate to person k. Benefiting from our feedback module, the tracking edges in 4D association <ref type="bibr" target="#b61">[62]</ref> (Sec. 3.2) are extended with visibility priors. We define the enhanced tracking edges z k (c) as:</p><formula xml:id="formula_5">z k (c) = ? k (c) K i=1 ? i (c) z k (c),<label>(6)</label></formula><p>where ? i (c) ? [0, 1] means the continuous occupancy of person i. As shown in <ref type="figure" target="#fig_3">Fig. 6 (d)</ref>, ? i (c) is negative interrelated to the distance to its binary mask, ? k (c) = 1 refers to the fully contained situation. As a result, our feed-back mechanism enhances skeleton tracking performance and reduces jittering in projection coincidence cases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Results</head><p>In <ref type="figure" target="#fig_4">Fig. 7</ref>, we demonstrate example results by our system. With the sparse multi-view setup, our method produces expressive human parametric models under multi-person interactive scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Implementation Details</head><p>Our light-weight total capture system are implemented with 6 synchronized RGB cameras (resolution 2048?2048) on a single PC (i5-6600K CPU, NVIDIA RTX 3090 GPU). We use Openpose <ref type="bibr" target="#b8">[9]</ref> as our body pose estimator, SRHand-Net <ref type="bibr" target="#b52">[53]</ref> as our hand instance detector and keypoint detector. We leverage the hand pose-regression network of Frankmocap <ref type="bibr" target="#b44">[45]</ref> gesture regressor. FaceAlignment <ref type="bibr" target="#b6">[7]</ref> are used for face keypoints extraction. Besides, we accelerate all neural network inference by implementing halfprecision arithmetic on NVIDIA TensorRT platform. The CNN performance is shown in <ref type="table">Table.</ref> 1. Besides, our body association backbone takes nearly 10ms to recover human skeletons, the limb localization and association method is fast enough to be neglected. Our parametric fitting workflow takes 150 ms for stage one and 350 ms for stage two (20 Gauss-Newton iterations and parallel for each person). On the whole, our system run-time depends on the captured individual number and view number. Empirically, our pipeline runs about 1 fps for 2 person with 6 views, and the processing speed slows down to 0.3 fps for 7 persons with 8 views. As for hyper-parameters, sphere radius R in hand localization is set to 0.15m, and association NMS threshold is 0.5. In two-stage parametric fitting, we set ? b3d = 10, ? h2d = 0.0001, ? f 2d = 0.0003, ? pri = ? ?,h = 0.01, and ? ? = ? ? = 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Network</head><p>Input Batchsize Speed(FPS) Openpose <ref type="bibr" target="#b8">[9]</ref> 368 ? 368 6 43.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Comparison</head><p>Since our method is the first to enable lightweight total capture from sparse multi-view, we compared our method with SOTA single view method FrankMocap <ref type="bibr" target="#b44">[45]</ref> in <ref type="figure" target="#fig_7">Fig. 11</ref> and ground truth from Total Capture <ref type="bibr" target="#b21">[22]</ref> in <ref type="figure">Fig. 9</ref>. What's more, MPJPE (Mean Per Joint Position Error) are provided for Total Capture dataset Tab. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Evaluation: Hand Bootstrapping</head><p>We compare our hand bootstrapping method with SOTA monocular total capture method Frankmocap <ref type="bibr" target="#b44">[45]</ref>. To ensure fairness as much as possible, we reduce our system to 2 close front view camera. <ref type="figure" target="#fig_7">Fig. 11 (a)</ref> shows the reconstruction failure of FrankMocap <ref type="bibr" target="#b44">[45]</ref> caused by mixing up left and right hands to the same region proposal. Thanks to the proposed NMS method in hand association, our method can robustly reconstruct more accurate hands in <ref type="figure" target="#fig_7">Fig. 11 (b)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.">Evaluation: Two-stage Parametric Fitting</head><p>We conduct ablation study of two-stage fitting metric on CMU dataset <ref type="bibr" target="#b54">[55]</ref> and demonstrate that our method makes different modality detectors benefit from each other. On the one hand, as shown in <ref type="figure" target="#fig_5">Fig. 8 (a)(d)</ref>, we perform our twostage fitting algorithm with only pose regression results, namely we leverage orthogonal projected joints from poseregression network to take over heatmap-based 2D correspondences in stage two. Misalignment artifacts are shown in detail as pose-regression detector could not guarantee pixel-aligned accuracy. One the other hand, keypointsdetection-only results are shown in <ref type="figure" target="#fig_5">Fig. 8 (b</ref>)(e). Without pose regression network to initialize hand poses with reasonable gestures, the optimization is easy to fall into a local minimum.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.">Evaluation: Feedback Mechanism</head><p>We evaluate our feedback module in Shelf dataset <ref type="bibr" target="#b2">[3]</ref>. As shown in <ref type="figure" target="#fig_6">Fig. 10(a)</ref>, the left elbow the of salmon person is distributed to the background green person without feed-  <ref type="formula">)</ref> and (e) are the results with keypoints-detection-only metric (salmon). (c) and (f) are the results with our two-stage fitting strategy combing both metrics (pink). Meanwhile, we visualize pose-regression network outputs and heatmap-based network outputs in right of (a) and (b), respectively. Red dots in right of (d) (e) (f) refer to the ground-truth 3D hand annotations. <ref type="figure">Figure 9</ref>. Comparison of our sparse-view method(8 view used) to ground truth from Total Capture Dataset <ref type="bibr" target="#b21">[22]</ref>. The mesh refers to our reconstructed parametric model (SMPL-X), and the red keypoints are the ground truth from the Total Capture dataset.   back. We show enhanced association results in <ref type="figure" target="#fig_6">Fig. 10</ref>(c) and prove that visibility informations provided by reconstructed human models help to eliminate that ambiguity.  <ref type="table">Table 3</ref>. Ablation study of feedback mechanism on Shelf dataset. Numbers are percentage of correct parts(PCP).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Discussion</head><p>Conclusion In this paper, we propose, as far as we know, the first multi-person total motion capture framework with only a sparse multi-view setup. Based on the proposed hand and face bootstrapping, two-stage parametric fitting and feedback mechanism, our method can enable lighweight, fast, robust and accurate capture of the body pose, hand gesture and facial expression of each character even under the scenarios with severe occlusions and close interactions. Limitation and Future Work We can mainly recover the facial expression by the jaw joint, and cannot reconstruct subtle facial expressions due to the low-resolution facial image input, which we leave for future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Illustration of hand localization and detection. (a) Reconstructed body skeletons using [62] in advance which will guide us to focus on key areas {RoI c k,? } (blue dotted line rectangle). (b) After that, a light-weight network is utilized for regressing more precise and tight bounding boxes {RoI c k,? }(red solid line rectangle). Then we clipped {RoI c k,? } from the full-body image and then feed them to both the pose-regression network and the keypoint-detection network. (c) The regressed hand gesture which is decent but not pixel-aligned accurate enough. (d) 2D Keypoints are accurate but suffer from depth ambiguity.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>Illustration of hand association algorithm. (a) Body skeletons obtained by [62]. (b) Association ambiguity may happen when RoI c k 1 ,? ? RoI c k 2 ,? = ?, k1 = k2. Blue and red dotted line rectangles are RoI c k 1 ,? and RoI c k 2 ,? , respectively. Then 3 tight bounding boxes RoI c k 1 ,? 1 (light blue), RoI c k 1 ,? 2 (dark blue) and RoI c k 2 ,? (red) are further extracted from the two initial rectangles. We can observe that the right hand lies in the overlapping area of RoI c k 1 ,? and RoI c k 2 ,? , leading to redundant proposals and confusing partition. (c) and (d) show that pose-regression network is specific for one chirality input. (e) is the result of heatmap-based detector which is invariant with chirality. (f) shows that after our double-check NMS procedure, the correct distributed RoI c k 1 ,? 1 are retained and the false one RoI c k 1 ,? 2 is discarded.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Illustration of two-stage parametric fitting. (a) Stage 1: we solve the body posture as well as arm kinematics and assign the gesture of pose regression with the highest association score ? and ?. (b) Stage 2: we then perform total optimization to achieve accurate total motion capture.E ?,h and E ? are L-2 norm to keep the optimized gestures and expressions within reasonable ranges. Note that we can additionally leverage the consistency scores ? and ? (Eqn. 2 and 3) to balance the detection results in different views, so E h2d = ? c ? c +? c 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Illustration of our feedback mechanism. (a) and (b) are the aligned parametric models. (c) Segmented results by rendering. (d) is the softened mask generated by distance transformation to enhance the robustness of association during fast motion.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Results by our system. From the left to right are input reference images, parametric model alignment, facial and hand alignment and 3D visualization from a novel view, respectively. (a) Results of the hand-object-interaction case from our captured data using 6 views, (b) results of a multi-person-interaction scenario using 6 views, (c) results on CMU dataset [22] using 8 views.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Qualitative evaluation of two-stage parametric fitting. (a) and (d) are the results with parametric-regression-only metric (blue). (b</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 10 .</head><label>10</label><figDesc>Qualitative evaluation of feedback mechanism. (a) shows the original association results of [62]. (b) are our reconstructed model of last frame. (c) shows that our feedback mechanism boosts body association performance with visibility prior.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 11 .</head><label>11</label><figDesc>Qualitative evaluation of hand bootstrapping &amp; comparison against SOTA monocular method, FrankMocap<ref type="bibr" target="#b44">[45]</ref>. (a) Results of Frankmocap<ref type="bibr" target="#b44">[45]</ref>, only single ROI are extracted for each view, and left hand (blue rectangle) and right hand (green rectangle) have been distributed to the same ROI proposal. (b) Results of our method, all hands are extracted and associated correctly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>1 .</head><label>1</label><figDesc>4D Body Association (Sec. 3.2): Given multi-view input, we associate the 2D keypoints and triangulate 3D body skeletons using 4D association [62]. 2. Hand and Face Bootstrapping (Sec. 4): With the body skeletons, we perform hand and face bootstrapping to extract their 2D bounding boxes efficiently and also associate them to different subjects among different views. 3. Two-stage Parametric Fitting (Sec. 5): Then we fit parametric human model SMPL-X [41] to these posture, gesture and expression features in a two-stage manner to achieve efficient and accurate pixel-level alignment. 4. Feedback Mechanism (Sec. 6): Finally, the tracked human models are propagated into the 4D association step of the next frame to further improve the association accuracy especially on severe occluded occasions.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Quantitative evaluation on Total Capture dataset. We calculate the MPJPE of body&amp;head joints on a video segment (750 frames) which involves both large variation movements and meticulous hand gestures (noted that hand annotations are few for challenge gestures) with 5 cameras for a comprehensive evaluation.</figDesc><table><row><cell>Type</cell><cell cols="4">Body Head LHand RHand</cell></row><row><cell cols="2">MPJPE(mm) 33.4</cell><cell>21.7</cell><cell>22.6</cell><cell>19.3</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Densepose: Dense human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>R?za Alp G?ler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Neverova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kokkinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Pushing the envelope for rgb-based dense 3d hand pose estimation via neural rendering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seungryul</forename><surname>Baek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang</forename><forename type="middle">In</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tae-Kyun</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1067" to="1076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bernt Schiele, Nassir Navab, and Slobodan Ilic. 3d pictorial structures for multiple human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sikandar</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Bernt Schiele, Nassir Navab, and Slobodan Ilic. 3d pictorial structures revisited: Multiple human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Belagiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sikandar</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Soft-nms -improving object detection with one line of code</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bodla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">3d hand shape and pose from images in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adnane</forename><surname>Boukhayma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>De Bem</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10843" to="10852" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How far are we from solving the 2d &amp; 3d face alignment problem? (and a dataset of 230,000 3d facial landmarks)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Bulat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Tzimiropoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Weakly-supervised 3d hand pose estimation from monocular rgb images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuhao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="666" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">OpenPose: realtime multi-person 2d pose estimation using part affinity fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gines</forename><surname>Hidalgo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-En</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Camera-space hand mesh recovery via semantic aggregation and adaptive 2d-1d registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufeng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongyang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huayan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13274" to="13283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Modelbased 3d hand reconstruction via self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhigang</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linchao</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuefei</forename><surname>Zhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10451" to="10460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cascaded Pyramid Network for Multi-Person Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Monocular expressive body regression through body-driven attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast and robust multi-person 3d pose estimation from multiple views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junting</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hujun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sara</forename><surname>Ershadi-Nasab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erfan</forename><surname>Noury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohreh</forename><surname>Kasaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Esmaeil</forename><surname>Sanaei</surname></persName>
		</author>
		<title level="m">Multiple human 3d pose estimation from multiview images. Multimedia Tools and Applications</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">RMPE: Regional multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuqin</forename><surname>Hao-Shu Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Motion capture using joint skeleton tracking and surface estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Stoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edilson</forename><forename type="middle">De</forename><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1746" to="1753" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">3d hand shape and pose estimation from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuhao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuncheng</forename><surname>Zhou Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="10833" to="10842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Hand pose estimation via latent 2.5 d heatmap regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umar</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavlo</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Breuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="118" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Panoptic studio: A massively multiview system for social interaction capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xulong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Godisart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Nabbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Matthews</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Total capture: A 3d deformation model for tracking faces, hands, and bodies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Weaklysupervised mesh-convolutional hand reconstruction in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Kulon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alp</forename><surname>Riza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Guler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Michael M Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4990" to="5000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Recursive bayesian filtering for multiple human pose tracking from multiple cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Oh-Hun Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Tanke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Crowdpose: Efficient crowded scenes pose estimation and a new benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiefeng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Can</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yihuan</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao-Shu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Shape and pose estimation for closely interacting persons using multi-view images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianhong</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyu</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CGF</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Posefusion: Pose-guided selective fusion for single-view human volumetric capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zerong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiwen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Twohand global 3d pose estimation using monocular rgb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fanqing</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connor</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tony</forename><surname>Martinez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2021-01" />
			<biblScope unit="page" from="2373" to="2381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multi-view multi-person 3d pose estimation with plane sweep stereo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahao</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gim Hee</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="11886" to="11895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Markerless motion capture of multiple characters using multiview image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Stoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qionghai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Markerless motion capture of interacting characters using multi-view image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Stoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Xnect: Real-time multi-person 3d motion capture with a single rgb camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Elgharib</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="82" to="83" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Single-shot multi-person 3d pose estimation from monocular rgb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Pose2pose: 3d positional pose-guided 3d rotational pose prediction for expressive 3d human pose and mesh estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kyoung Mu Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.11534</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Interhand2. 6m: A dataset and baseline for 3d interacting hand pose estimation from a single rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-I</forename><surname>Shoou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">He</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Shiratori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Ganerated hands for real-time 3d hand tracking from monocular rgb</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Real-time pose and shape reconstruction of two interacting hands with a single depth camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micah</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mickeal</forename><surname>Verschoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>Otaduy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM TOG</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Single-stage multi-person pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuecheng</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Synergetic reconstruction from 2d pose and 3d motion for wide-space multi-person video motion capture in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takuya</forename><surname>Ohashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yosuke</forename><surname>Ikegami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshihiko</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page">104028</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Expressive body capture: 3d hands, face, and body from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">A A</forename><surname>Osman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neural body: Implicit neural representations with structured latent codes for novel view synthesis of dynamic humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sida</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianqian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Shuai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hujun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9054" to="9063" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deepcut: Joint subset partition and labeling for multi person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eldar</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Embodied hands: Modeling and capturing hands and bodies together</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOG</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Frankmocap: Fast monocular 3d hand and body motion capture by regression and integration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Rong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Shiratori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.08324</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Understanding human hands in contact at internet scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dandan</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">F</forename><surname>Fouhey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9869" to="9878" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Hand keypoint detection in single images using multiview bootstrapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1145" to="1153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cross-modal deep variational hand pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Spurr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonwook</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>Hilliges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="89" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Neural free-viewpoint performance rendering under complex human-object interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoxing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anqi</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuheng</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingya</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyi</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Dynamical binary latent variable models for 3d human pose tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sigal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Voxelpose: Towards multi-camera 3d human pose estimation in wild environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanyue</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="197" to="212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Rgb2hands: real-time tracking of 3d hand interactions from monocular rgb video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiayi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suzanne</forename><surname>Sorli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neng</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>Otaduy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TOG</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Srhandnet: Real-time 2d hand pose estimation with simultaneous region localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baowen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TIP</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2977" to="2986" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Convolutional pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shih-En</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Ramakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Monocular total capture: Posing face, body, and hands in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donglai</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CVPR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Aligning latent spaces for 3d hand pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linlin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shile</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongheui</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2335" to="2343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Learning probabilistic non-linear latent variable models for tracking complex activities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angela</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Luc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep network for the integrated 3d sensing of multiple people in natural images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elisabeta</forename><surname>Marinoiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihai</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alin-Ionut</forename><surname>Popa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Interacting two-hand 3d pose and shape reconstruction from single color image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baowen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuixia</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongan</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Pymaf: 3d human pose and shape regression with pyramidal mesh alignment feedback loop</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yating</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenan</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">End-to-end hand mesh recovery from a monocular rgb image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2354" to="2364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">4d association graph for realtime multi-person motion capture using multiple video cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Deepmulticap: Performance capture of multiple characters using sparse multiview cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruizhi</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zerong</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qionghai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Monocular realtime full body capture with inter-part correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Habermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikhsanul</forename><surname>Habibie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayush</forename><surname>Tewari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Learning to estimate 3d hand pose from single rgb images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Freihand: A dataset for markerless capture of hand pose and shape from single rgb images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duygu</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bryan</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Argus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="813" to="822" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
