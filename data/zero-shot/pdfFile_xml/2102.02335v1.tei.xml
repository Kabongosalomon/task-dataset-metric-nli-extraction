<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Supervised Claim Identification for Automated Fact Checking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Archita</forename><surname>Pathak</surname></persName>
							<email>architap@buffalo.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University at Buffalo (SUNY) Buffalo</orgName>
								<address>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Abuzar</forename><surname>Shaikh</surname></persName>
							<email>mshaikh2@buffalo.edu</email>
							<affiliation key="aff1">
								<address>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohini</forename><forename type="middle">K</forename><surname>Srihari</surname></persName>
							<email>rohini@buffalo.edu</email>
							<affiliation key="aff2">
								<address>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Supervised Claim Identification for Automated Fact Checking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a novel, attention-based selfsupervised approach to identify "claimworthy" sentences in a fake news article, an important first step in automated factchecking. We leverage aboutness of headline and content using attention mechanism for this task. The identified claims can be used for downstream task of claim verification for which we are releasing a benchmark dataset of manually selected compelling articles with veracity labels and associated evidence. This work goes beyond stylistic analysis to identifying content that influences reader belief. Experiments with three datasets show the strength of our model 1 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The explosion of fake news on social media has resulted in global unrest and has been a major concern for governments and societies worldwide 2 . According to a recent Pew Research Study, Americans rate it as a larger problem than racism, climate change, or illegal immigration 3 . Since, it's inexpensive to create a website and easily disseminate content on the social media platforms, there is a rising need for automated fake news detection. Furthermore, AI solutions are also required to follow good practices, specifically avoiding censorship, violation of fundamental rights such as freedom of expression, and ensuring data privacy <ref type="bibr" target="#b5">(de Cock Buning, 2018)</ref>. However, to date, AI models proposed for fake news detection do not 1 Data and code available at: https://github.com/architapathak/Self-Supervised-ClaimIdentification 2 https://www.reuters.com/article/us-singapore-politicsfakenews-factbox/factbox-fake-news-laws-around-theworld-idUSKCN1RE0XN 3 https://www.journalism.org/2019/06/05/manyamericans-say-made-up-news-is-a-critical-problem-thatneeds-to-be-fixed/ scale for detecting real-time fake news 4 .</p><p>Much of the research on automated text-based fake news detection can be classified into three broad categories: (1) linguistic approach, which focuses on lexical, stylometric and pattern learning mechanisms <ref type="bibr" target="#b25">(Potthast et al., 2017;</ref><ref type="bibr" target="#b26">Rashkin et al., 2017;</ref><ref type="bibr" target="#b31">Wang, 2017;</ref><ref type="bibr" target="#b28">Singhania et al., 2017;</ref><ref type="bibr" target="#b24">P?rez-Rosas et al., 2018)</ref>; (2) network-based approach, which leverages features such as the speed and volume of propagation of fake news articles on social media platforms <ref type="bibr" target="#b4">(Castillo et al., 2011;</ref><ref type="bibr" target="#b33">Yang et al., 2012;</ref><ref type="bibr" target="#b17">Kwon et al., 2013;</ref><ref type="bibr" target="#b21">Ma et al., 2015;</ref><ref type="bibr" target="#b13">Jin et al., 2016;</ref><ref type="bibr" target="#b27">Ruchansky et al., 2017;</ref><ref type="bibr" target="#b32">Wu and Liu, 2018)</ref>; and (3) automated fact-checking approach, which is an effort to assist manual fact-checkers by automating some of their tasks such as detection and verification of claims <ref type="bibr" target="#b8">(Graves, 2018)</ref>.</p><p>While most work in automated fact-checking has been focused on claim verification task, very few methods have been proposed for detection of claims <ref type="bibr" target="#b9">(Hassan et al., 2017;</ref><ref type="bibr" target="#b12">Jaradat et al., 2018;</ref><ref type="bibr" target="#b15">Konstantinovskiy et al., 2018)</ref>. The approaches in these efforts are majorly related to political discourse. However, our focus is on fake news, which are broader than political discourse since (i) they are deliberately written with a divisive agenda to cause social unrest, (ii) they are not constrained to only politics, and (iii) the headline plays an equally important role in compelling people to read the article.</p><p>In this paper, we focus on articles where there is a deliberate intent to influence readers through fabricated or manipulated claims in the headline and the content. Such articles have a compelling writing style similar to the mainstream media. Hence, we build datasets containing these type of compelling articles along with veracity labels and associated evidence supporting the label of each arti-cle. We, then, use these datasets to identify "claimworthy" sentences. In our work, we define "claim" as "statements which are important to the point of the article but one would require to have them verified."</p><p>Our working hypothesis is that in fake news which are created to cause harm, these are the sentences most relevant to the headline. Exploiting the hypothesis that the essence of a news article is encapsulated in its headline (Jaime <ref type="bibr">Sis? and MER-CEDES, 2009;</ref><ref type="bibr" target="#b16">Kuiken et al., 2017;</ref><ref type="bibr" target="#b30">Wahl-Jorgensen and Hanitzsch, 2009)</ref>, we propose a self-supervised method to explore the aboutness of the content with the headline of the article to extract the most relevant sentences. <ref type="bibr" target="#b3">Bruza and Huibers (1996)</ref> defines aboutness as: an information carrier i will be said to be about information carrier j if the information borne by j holds in i. The idea is taken from Information Retrieval domain where it is used to signify implications between query and document, specifically to explore the underlying meaning or concept within the document and the query <ref type="bibr" target="#b2">(Azzopardi et al., 2009)</ref>. In our work, headline is modelled as a query while each of the sentences of the article acts as a document, and we use the concept of aboutness to find the relevant sentences. We show that attention-based mechanisms are able to successfully capture this concept in the news article.</p><p>Contribution: In this work: (i) we introduce a self-supervised representation learning model that eliminates the prerequisite that requires human to annotate data, which is a time consuming and costly task; (ii) the proposed headline-to-sentence attention-based approach for claim identification is novel; previous unsupervised approach for this task use weak supervisory signal which does not capture the context of the article efficiently; and (iii) we propose a benchmark dataset for evidence-based fake news detection. Our dataset contains evidence for each of the fake news articles that contributes to the overall degree of veracity of the article.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Claim Identification/Detection: The task of claim identification/detection was first introduced by  who, with the help of human annotators, provided a dataset and a fundamental approach in identifying context dependent claims. In their dataset, which was originally developed by , each statement indicates whether it should be considered as a context dependent claim (CDC) or not.  reported encouraging results obtained through a supervised learning algorithm using a cascade of classifiers. A rule-based model was introduced by Eckle- <ref type="bibr" target="#b6">Kohler et al. (2015)</ref> to bifurcate claim and premise statements in an argumentative discourse environment. However, these methods were generic to only a small set of corpora. Furthermore, <ref type="bibr" target="#b20">Levy et al. (2017)</ref> also introduced an unsupervised approach to detect claims, which involves a weak supervisory signal "that" for training. However, this approach does not capture the aboutness of the article to understand the context of "claim-worthy" sentences.</p><p>In 2017, <ref type="bibr" target="#b9">Hassan et al. (2017)</ref> introduced Claim-Buster, a platform developed by training a supervised learning model on a large annotated corpus of televised debates in the USA. Their model used SVM classifier to detect claim-worthy factual claims and produced a score of how important a claim is to factcheck. The 20,000 sentences in the corpus were annotated by human coders to distinguish between claim-worthy factual claims from opinions and boring statements. However, annotating a sentence as an important or unimportant claim is a non-trivial task as this decision changes depending on who's asking, political context and annotator's background <ref type="bibr" target="#b8">(Graves, 2018)</ref>.</p><p>The model proposed by <ref type="bibr" target="#b9">Hassan et al. (2017)</ref> only learns the labelled instances and does not explore the contextual information of the written text. A context-aware approach in the political discourse environment was introduced by <ref type="bibr" target="#b7">Gencheva et al. (2017)</ref> who created a rich representation of the sentences from 2016 US presidential debates. Their dataset was compiled by taking the outputs of factchecking of the debates from 9 factchecking organizations. Their models were created to predict if the claim would be highlighted by at least one or by a specific organization. However, the authors don't have any formal definition of claim in their paper, and their model is specific to certain organizations which led to several false positives.</p><p>Another context-aware approach for claim detection was proposed by <ref type="bibr" target="#b15">Konstantinovskiy et al. (2018)</ref> who used sentence embeddings, pre-trained on a large dataset of NLI. This work also created a crowd-sourced annotated dataset of sentences from UK political TV shows, annotated across 7 classes. However, their classifiers for the fine-grained clas-sification to detect 7 classes of sentences did not yield good results due to lack of enough annotated data, thus requiring more annotations which is a costly and time consuming task.</p><p>We build a model that can be trained in a selfsupervised setting to overcome the challenges associated with annotated dataset of claims. We also use attention-based approach to capture aboutness and rich contextual information between headline and all the sentences of the article. The performance on manually created test sets demonstrate promising results in identifying "claim-worthy" sentences even when no sentence-level annotation was used for training. Fake News Dataset: A variety of fake news datasets have been released in the recent years, most notably Buzzfeed 5 and Stanford <ref type="bibr" target="#b1">(Allcott and Gentzkow, 2017)</ref> datasets containing list of popular fake news articles from 2016 US presidential elections. However, these datasets only contain webpage URLs of the original article and majority of them don't exist anymore. Following this, several other datasets were published such as Fake news challenge dataset 6 which was used for the task of stance detection; Getting Real about Fake News Kaggle dataset 7 which was created by using BS detector tool; and FakeNewsCorpus 8 which is an open-source large scale collection of fake news articles. However, these articles are labelled as fake based on the domain of the websites they come from. Since, the content of these articles are not verified for degree of veracity, using them directly for training may lead to several false positives.</p><p>This problem was overcome by recently released large dataset, NELA-GT-2018 <ref type="bibr" target="#b22">(Norregaard et al., 2019)</ref>, which contains articles with ground truth ratings retrieved from 8 different assessment sites. However, the label definitions are not generic and dependent on the external organizations. <ref type="bibr" target="#b23">Pathak and Srihari (2019)</ref> also introduced intuitive ground truth labels based on the degree of veracity of the fake news articles, however, the dataset is not publicly available. Additionally, they also do not specify the relationship of their labels with the labels used by established fact-checking organizations. Furthermore, due to lack of evidence in these datasets, they cannot be used for downstream task of evidence-based verification, which is one of the motivations of this paper. We overcome all these limitations in our datasets described in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Datasets</head><p>We introduce two datasets of compelling fake news articles which have writing style similar to mainstream media. The first dataset, DNF-700, where DNF stands for DisiNFormation, contains articles on politics published within 4 months of 2016 US Presidential Elections from questionable sources (non-mainstream). To compile this dataset, we first extracted fake news articles from working web page URLs of Stanford dataset <ref type="bibr" target="#b1">(Allcott and Gentzkow, 2017)</ref>. However, majority of webpage URLs in this dataset are expired and we could extract only 26 fake news articles. Therefore, we then used "Getting real about fake news" Kaggle 8 dataset to sample more articles on politics. Since, most of the articles in this dataset contain anomalies (eg: incomplete article, social media comments labelled as fake etc.), we manually verified the writing style and discarded obvious fakes -articles with poor grammar and excessive usage of punctuations. However, the degree of veracity of each article in this dataset is not checked and some articles may contain personal opinions.</p><p>The second dataset, DNF-300, is more sophisticated subset of DNF-700, containing 290 compelling articles on Politics and 10 on Health/Medical news. Unlike other fake news datasets in which veracity and evidence for articles are not provided, DNF-300 contains articles associated with veracity labels as well as corresponding evidence. The process of annotating this dataset involves identifying sentences from each article based on their persuasive tone and relevance with the headline. These sentences were then queried on the web and top 10 results were considered to gather evidence from credible sources 9 . Based on the evidence found, we label the entire article into four categories: {(0) false; (1) partial truth;</p><p>(2) opinions stated as fact; (3) true}. These labels are inspired by <ref type="bibr" target="#b23">(Pathak and Srihari, 2019)</ref>; <ref type="table">Table-</ref>1 shows the description and distribution of these labels while the comparison with two popular factchecking websites is displayed in <ref type="figure">Figure-</ref>1. An 9 Credible sources were extracted from https://mediabiasfactcheck.com/ The sources range between left, center and right biased news sources  <ref type="table">Table 1</ref>: DNF-300 label description and distribution. Claims here are the sentences manually selected based on their persuasive tone and relevance with the headline. Interestingly, some of the articles, which were labelled as fake in other datasets due to the domain of publishing website, turned out to be true news.</p><p>example from the dataset is shown in This dataset is also a key contribution of this paper as the articles are manually read and verified. Additionally, the dataset contains two novel features which are essential for the fake news verification task: (i) generic veracity-based label set, independent of any external organization, and (ii) ground truth evidence corresponding to each label.</p><p>In addition to these two datasets, we also train our model for claim identification on the dataset introduced for context dependent claim detection (CDCD) by . Although this dataset (CDC) does not contain fake news articles, it has manually annotated sentences based on their relevance to a certain topic. These annotations were utilized for the evaluation of our self-supervised learning model described in the following section. More details on the datasets and examples can be found in Appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Architecture</head><p>Problem Definition: Given an article with a set of sentences S = {S 1 , S 2 , ...S i , ...S n } and a headline H, the task of our multihead attention claim identification network (MA-CIN) is to extract the sentence most relevant to the headline. Our selfsupervised model exploits the rich contextual information to extract the relevant sentences which are considered as "claim-worthy". Approach: For this task, we implement two types of attention: (i) self-attention on all sentence vectors so that each sentence S i is aware of all other sentences in S; (ii) cross-attention of headline vector on each sentence vector, so that all self-attended sentences are also aware of the headline's context. We then generate headline based on the contextaware sentences, and compare it with the original headline in three different settings as listed below:</p><p>1. Headline Vector (MA-CIN (HV)): In this setting, the original headline vector acts as the supervisory signal for self-supervised learning. We minimize the mean squared error (MSE) between the generated and the original headline vectors for training. 2. Headline One-Hot Word Vector (MA-CIN (OHWV)): In this setting, the words in the original headline act as the supervisory signal. We use LSTM <ref type="bibr" target="#b10">(Hochreiter and Schmidhuber, 1997)</ref> to predict at most 50 words, from a vocabulary of 20,000 words, to generate a one-hot-vector for each word of the new headline. We then minimize the categorical cross-entropy error (CCE) at each time step corresponding to each word in original and new headlines for training. 3. Combined HV &amp; OHWV (MA-CIN (Combined)): In this setting, both original headline vector and the words act as supervisory signal. Therefore, we combine the two loss functions mentioned above to train the model.</p><p>For this, we build several layers in our architecture (see <ref type="figure">Figure-</ref>2), which are delineated as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Sentence Embeddings</head><p>Each sentence S i ? S, and headline H are converted to a fixed length 300-dimensional vector, s i and h, such that</p><formula xml:id="formula_0">s i , h ? R 1?D , where D = 300.</formula><p>For uniformity, we calculate the maximum number of sentences L that an article can contain in the respective corpus. Next, we zero pad the difference in the quantity of sentence vectors in each article such that every article can be represented as a vector A ? R L?D .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">1D Convolution</head><p>To effectively capture local relevance, we leverage 1D-CNN <ref type="bibr" target="#b18">(LeCun et al., 1998)</ref> to extract the features from the article vector A. For our experiments the kernel size for each convolution layer is K ? D ? C, where K is kernel-width and C is the number of filters. This means the network will process K sentences at a time. The size of K and C is a hyper-parameter and as per our experiments, we set K = 4 with an assumption that not more than 4 consecutive sentences will be relevant to each other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Self Attention</head><p>Inspired by the attention implementation in <ref type="bibr" target="#b34">(Zhang et al., 2018;</ref><ref type="bibr" target="#b29">Vaswani et al., 2017)</ref>, to capture global relevance, the article features from the previous 1D-CNN layer are transformed into feature spaces q, k to calculate attention, where q(x) = W q x and</p><formula xml:id="formula_1">k(x) = W k x. ? j,i = exp(z ij ) N i=1 exp(z ij ) , where z ij = q(x i ) T k(x j )</formula><p>(1) ? ? R N ?N is the attention coefficient, which is the normalized relevance score between the sentence</p><formula xml:id="formula_2">x i and x j . ? is then matrix multiplied by v, where v(x) = W v x, to obtain the context rich output o j ? R C?1 . o j = N i=i ? j,i v(x i ), where o j ? {o 1 , o 2 , . . . , o N } (2)</formula><p>Finally, the output of the self-attention layer is o ? R C?N , which is computed as</p><formula xml:id="formula_3">o j = g(o j ), where, g(x) = W g x<label>(3)</label></formula><p>In the above equations, x ? R C?N is obtained after applying 1D convolution on sentence vectors,  R C?C and output o ? R C?N . Following the work by <ref type="bibr" target="#b34">(Zhang et al., 2018)</ref> we preferred the value of C = C 8 for computation effectiveness. We also multiply a ? and ?, learnable scale parameters, to the output of our attention module and input vector respectively to allow the network to choose between local and global sentences effectively.</p><formula xml:id="formula_4">W q ? R C?C , W k ? R C?C , W v ? R C?C , W g ? 1D</formula><formula xml:id="formula_5">o = ?x + ?o<label>(4)</label></formula><p>? is initialized to 1 and ? is initialized to 0, so as to allow the local context to be captured effectively during the early iterations and as the value of ? increases it allows the network to add more context to the representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Multihead Concatenation</head><p>In the architecture, we could apply self attention to the input x M times resulting into M attention heads. The output of one attention head is denoted by o. We concatenate the outputs o M to get a richer representation allowing the network to capture various relationships.</p><formula xml:id="formula_6">msa o = M i=1 o i = o 1 . . . o M<label>(5)</label></formula><p>where, msa o ? R M C?N is the long range context aware output of multihead self attention. Here, denotes concatenation across axis C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Cross Attention</head><p>The headline vector is transformed into a feature space h = W h h, where h ? R C?1 and then, it's relevance is calculated with msa o, obtained from the previous layer, by using equations defined in 4.3. Finally, after applying multihead concatenation using 5, we obtain headline-context aware representation, mca o ? R M C?N . We fix M = 4 for all our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Loss Function</head><p>To generate the headline vector d h as close to the input headline vector h, we apply Mean Squared Error between d h and h and calculate the headline vector generation loss L v</p><formula xml:id="formula_7">L v = 1 n ( n i=1 (d h i ? h i ) 2 )<label>(6)</label></formula><p>For estimating the probability of a word from the vocab in the predicted headline we calculate the cross-entropy between the predicted headline words d hw and input headline one-hot vector HW .</p><formula xml:id="formula_8">L w = ? i d hw i log(HW i )<label>(7)</label></formula><p>The total loss L total = L v + L w is then evaluated for all samples b ? B, where B is one batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Training Setup</head><p>We train our Multihead Attention model for Claim Identification, MA-CIN, on datasets mentioned in Section 3. The CDC dataset contains total of 522 articles. Amongst these, there are 47 articles with 8 or more annotated claim sentences which are considered as evaluation set (CDC Eval) for this dataset. Next, for DNF-300 and DNF-700, we asked two annotators to manually tag at least 5 sentences as "claim-worthy" in each of the 50 articles. Sentences which were consented by both  13 And though it is unlikely that anyone will be able to conclusively prove that Clinton was given the debate questions, it seems both logical and likely. GT PD 0.7 <ref type="figure">Figure 3</ref>: Interpretation of relevance of sentences with the headline of an example article from DNF-300. GT and PD indicate ground truth and top-5 predicted "claim-worthy" sentences, respectively. MA-CIN model was able to predict 3 most relevant sentences correctly. Last column shows the attention weights between headline and each of the sentences of the article. Sentence 2 has been correctly predicted as the most relevant while sentence 1 is the least relevant.</p><p>the annotators as "claim-worthy" were finalized as ground truth claims for these 50 articles, and used as testing set for evaluating the model performance on DNF datasets. The remaining 475 articles from CDC, 250 articles from DNF-300, and 650 articles from DNF-700 were split into 5 folds to train the model using a 5-Fold cross validation <ref type="bibr" target="#b14">(Kohavi, 1995)</ref>, where we use 4 folds for training and 1 fold for validation. Each of the three settings, described in In each setting, we use batch normalization, ReLU non-linearity as an activation function, and a dropout of 0.5 for every convolution operation. We trained all the models for 2000 epochs, where, for every training we used Adam optimizer with a learning rate lr = 0.0001, ? 1 = 0.99 and ? 2 = 0.0. There was no weight decay set as the model was trained in a self-supervised setting with finite epochs and an already small learning rate. Glove 300D word embedding was used for all our experiments and the number of input sentences was set to 500. The models were trained on three 11GiB Nvidia 1080Ti GPUs in parallel.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluation Metrics</head><p>We evaluate MA-CIN models on two evaluation sets, DNF Eval and CDC Eval. With self-supervised setting we first rank the sentences based on relevance with the headline and then extract the top five sentences along with their sentence ids as "claim-worthy" sentences. For evaluation on DNF Eval, we calculate the true positives(TP), false positives(FP) and false negatives(FN) from ground truth claim ids. To evaluate on CDC Eval, since we do not have ground truth claim ids, we calculate cosine similarity between the extracted sentences and the ground truth claims. We experiment with various similarity threshold to calculate TP, FP and FN, and set the final threshold to 0.95 to report best performing results. Finally, these metrics are used to report Precision@1, Recall@1 and F-1 scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results</head><p>Table-3 shows the performance of baseline (CDC)  and three variants of MA-CIN models. We report two baselines -(1) spacy, and (2)  using supervised learning method on CDC dataset which contains annotated claims. Since,  do not report Recall and F1 scores, we have reported their Preci-sion@1 score in this paper. We also train MA-CIN models on this dataset by removing all the annotations for self-supervised training. We observe that:</p><p>1. The combined variant of our self-supervised approach performs slightly better than the baseline on the CDC dataset. This shows that, MA-CIN models are able to learn similar properties as the baseline but without any sentence-level annotations. Thus, this eliminates the need to have an annotated dataset for claim identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">MA-CIN models give comparable results on</head><p>all three datasets. This shows the scalability of the models to identify "claim-worthy" sentences from any given article. 3. The combined variant of MA-CIN, which generates both the headline vector and the word in headline, performs better on all the datasets, except one: MA-CIN (OHWV) model trained on DNF-300 and evaluated on CDC Eval performs slightly better than the combined model, however, the difference in the performance is very small. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Analyzing Attention Weights</head><p>Attention weights help make the model interpretable to the end users by depicting relationship between all sentences as well as with the headline. From <ref type="figure">Figure-3</ref>, we can see that out of the top-5 predicted claims, 3 of them are present in the human evaluated test set. The last column, which contains attention coefficients between the headline and each sentence, depicts some interesting results -(i) based on the human evaluation, the sentence having the least relevance with the headline is sentence 1. While this sentence contains words also present in the headline, the underlying meaning is not the same. This has been successfully captured by MA-CIN model by predicting sentence 1 as the least relevant claim;</p><p>(ii) further, highly ranked sentences 2, 12, and 13 have been correctly predicted as relevant claims by the model. This shows the model's ability in learning the semantic relationship between the headline and the content of the article, and subsequently putting importance on sentences that are relevant to the headline's underlying meaning. This property, which is also called "aboutness", is efficiently exhibited by the model.</p><p>(iii) sentence 3, which is predicted by MA-CIN model as relevant with a score of 0.73, is not present in the ground truth. This indicates that the two annotators did not agree to have this sentence verified, even if it is relevant to the point of the article. To analyze this further, we plan to conduct user studies as one of the future avenues.</p><p>(iv) sentence 4 is also predicted as a relevant claim but it's missing from the ground truth since the annotators did not agree to have this verified. The reason for this prediction could be because selfattention is able to identify the premise of highly relevant sentences. Hence, sentence 4, which is the continuation of highly relevant sentence 3, is also given importance by the headline. This relevance between sentences 3 and 4 is depicted in <ref type="figure" target="#fig_1">Figure-4</ref>, where the attention weight between these two is the highest.</p><p>From <ref type="figure" target="#fig_1">Figure-4</ref>, we also observe that: (i) sentence 4 is highly relevant to sentences 3 to 8, which is intuitive, since the story of the intern forms the premise of the claims in the article;</p><p>(ii) sentences 2 and 4 have been shown to have the least relevance with each other which is also true as shown in <ref type="figure">Figure-3</ref>. The two sentences, if considered in isolation, make two different claims which are not related to each other;</p><p>(iii) the model has made sure that a sentence does not assign high relevance to itself as it would be counter-intuitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Limitations</head><p>Since, the evaluation methodologies for CDC dataset has not been explained clearly, in our paper, we have considered vector cosine similarity between the ground truth claim in the CDC Eval and the extracted claim from the model which may leave a margin of error in the evaluation scores. Additionally, ground truth in DNF Eval is manually generated and may contain subjective biases. Although these biases have been overcome by MA-CIN models, as explained in 6.1, but we also plan to enhance the ground truth judgement using crowdsourced annotation. We intend to use these annotations to fine-tune the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and Future Work</head><p>In this work, we build a novel, self-supervised approach to identify "claim-worthy" sentences -an important task for automated fact checking. The focus of this work is on fake news articles where there is a deliberate intent to influence people or cause social unrest. We have introduced novel datasets of such articles with features essential for the downstream task of fake news verification. Using powerful attention models, we explore the notion of aboutness of the headline and the content of the article to identify "claim-worthy" sentences. Experiments with three datasets show the strength of our model architecture in overcoming humaninduced biases, which is quite common when using sentence-level claim-annotated datasets. Based on the comparison with the baseline, which was implemented using annotated dataset, we show that our models do not require annotated claims for training to identify claim-worthy sentences efficiently. We have also showed that our model is scalable to any dataset with topic and content.</p><p>Future work involves increasing the robustness of the models presented in this paper. We plan to use crowdsourced annotation on the dataset released with this paper to measure the influence of the article on general readers and then use these indicators to fine-tune our models. Experimentation with more robust sentence encoders is another avenue of future work. Additionally, going forward, we plan to identify a maximum of 3 claims per article which will be used for evidence-based fake news detection. We also plan to expand the dataset, presented in this work, to include fake news articles on topics other than Politics and Health.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendices</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Definitions</head><p>Fake News: Articles where there is a deliberate intent to influence readers through fabricated or manipulated claims in the headline and the content. Such articles have a compelling writing style similar to the mainstream media. "Claim-worthy": Statements which are important to the point of the article but one would require to have them verified. Compelling Fake News Articles: Articles which make persuasive claims in headline and content, that may influence readers to believe a fabricated/manipulated story.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Word Generation</head><p>Architecture setting for generating Headline Vector Word Probabilities (OHWV) displayed in <ref type="figure" target="#fig_3">Figure-6</ref> A.3 DNF-700 Dataset Details Each article is identified by an id. The content of the article is stored in a separate text files having file name "article id", for example, article 122. A JSON file is also provided with the following fields:</p><p>id: Unique identifier of the article starting from 0. authors: Authors of the article. headline: Headline of the article. type: "fake" (articles from Stanford and Buzzfeed datasets which are already proven fake); and "questionable" (articles from Getting Real About Fake News Kaggle dataset which require manual verification of the degree of veracity) urls: Source/domain URL of the article.  evidence: URL of credible sources supporting or refuting the article. This field is empty when no evidence were found which talked about the claims made in this article. This means, the claims are innovated lies. In such cases, the type field is set as 0.</p><p>reason: Reason about the verdict. It can be one of the following: 1. Based on Snopes rating 'False' which means 'the primary elements of a claim are demonstrably false.' 2. Based on Snopes rating 'Unproven' which means 'insufficient evidence exists to establish the given claim as true, but the claim cannot be definitively proved false.' 3. Based on Snopes rating 'Mixture' which means 'a claim has significant elements of both truth and falsity to it such that it could not fairly be described by any other rating.' 4. Based on Snopes rating 'Mostly False' which means 'the primary elements of a claim are demonstrably false, but some of the ancillary details surrounding the claim may be accurate.' 5. The key claim is false (based on Snopes rating), however, the article also contains opinions stated as fact. 6. Snopes mentiones that a true story was manipulated to mislead people. 7. The key claims are true but exaggerated by adding personal opinions stated as fact. 8. No reports from trusted sources for the key claims. 9. True story manipulated to mislead readers by making unverifiable claims such as 'some claim'. 10. Article is fraught with opinions stated as fact about a true event. 11. Found evidence to refute key claims. 12. Article contains opinions stated as fact. 13. Evidence found to support key claims. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.5 Examples</head><p>We present examples for all 4 label types {False; Partial Truth; Opinion stated as fact; True} present in our dataset: DNF-300. Please refer <ref type="bibr">5,</ref><ref type="bibr">6,</ref><ref type="bibr">7.</ref> An annotated example from CDC dataset is displayed in <ref type="figure" target="#fig_4">Figure-7</ref> Headline: Clinton Received Debate Questions Week Before Debate The first presidential debate was held and Hillary Clinton was proclaimed the winner by the media. Indeed Clinton was able to turn in a strong debate performance, but did she do so fairly? Multiple reports and leaked information from inside the Clinton camp claim that the Clinton campaign was given the entire set of debate questions an entire week before the actual debate. Earlier last week an NBC intern was seen hand delivering a package to Clinton's campaign headquarters, according to sources. The package was not given to secretarial staff, as would normally happen, but the intern was instead ushered into the personal office of Clinton campaign manager Robert Mook. Members of the Clinton press corps from several media organizations were in attendance at the time, and a reporter from Fox News recognized the intern, but said he was initially confused because the NBC intern was dressed like a Fed Ex employee. The reporter from Fox questioned campaign staff about the intern, but campaign staff at first claimed ignorance and then claimed that it was just a Fed Ex employee who had already left. No reporters present who had seen the intern dressed as a Fed Ex employee go into Mook's office saw him leave by the same front entrance. The Fox reporter who recognized the intern also immediately looked outside of the campaign headquarters and noted that there were no Fed Ex vehicles parked outside. Clinton seemed to have scripted responses ready for every question she was asked at the first debate. She had facts and numbers memorized for specific questions that it is very doubtful she would have had without being furnished the questions beforehand. The entire mainstream media has specifically been trying to portray Trump as a racist and a poor candidate. By furnishing Clinton with the debate questions NBC certainly hoped to make Clinton appear much more knowledgeable and competent than Trump. And though it is unlikely that anyone will be able to conclusively prove that Clinton was given the debate questions, it seems both logical and likely. Type: 0 (False) Authors:Baltimore Gazette URLs: http://www.freemarketcentral.com/index.php/post/2503/report-clinton-received-debatequestions-a-week-before-debate Evidence: [https://www.snopes.com/fact-check/clinton-received-debate-questions-week-beforedebate/, https://www.truthorfiction.com/hillary-clinton-received-debate-questions-advance/] Reason: Based on Snopes rating 'False' which means 'the primary elements of a claim are demonstrably false.' Headline: Allergens in Vaccines Are Causing Life-Threatening Food Allergies It would probably surprise few people to hear that food allergies are increasingly common in U.S. children and around the world . According to one public health website , food allergies in children aged 0-17 in the U.S. increased by 50% from 1997 to 2011. Although food allergies are now so widespread as to have become almost normalized, it is important to realize that millions of American children and adults suffer from severe rapid-onset allergic reactions that can be life-threatening. Foods represent the most common cause of anaphylaxis among children and adolescents. The United Kingdom has witnessed a 700% increase in hospital admissions for anaphylaxis and a 500% increase in admissions for food allergy since 1990. The question that few are asking is why life-threatening food allergies have become so alarmingly pervasive. A 2015 open access case report by Vinu Arumugham in the Journal of Developing Drugs , entitled " Evidence that Food Proteins in Vaccines Cause the Development of Food Allergies and Its Implications for Vaccine Policy ," persuasively argues that allergens in vaccines-and specifically food proteins-may be the elephant in the room. As Arumugham points out, scientists have known for over 100 years that injecting proteins into humans or animals causes immune system sensitization to those proteins. And, since the 1940s, researchers have confirmed that food proteins in vaccines can induce allergy in vaccine recipients. Arumugham is not the first to bring the vaccine-allergy link to the public's attention. Heather Fraser makes a powerful case for the role of vaccines in precipitating peanut allergies in her 2011 book, The Peanut Allergy Epidemic: What's Causing It and How to Stop It. Type: 1 (Partial Truth) Authors:Admin -Orissa URLs: galacticconnection.com Evidence: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3890451/ Reason: The key claim is written in such a way so that it misleads people in thinking all the food related allergies in US are caused by vaccines. Found evidence which says these type of allergies are rare. Headline: George Soros: Trump Will Win Popular Vote by a Landslide but Clinton Victory a 'Done Deal' In recent weeks, Democrats have attempted to paint Republican presidential nominee Donald J. Trump as a lunatic for claiming that the election is going to be rigged in favor of his Democratic rival, Hillary Clinton. Even Republican politicians and former politicians are telling Trump to knock off such talk. But, as usual, Trump's shrewdness and defiance of standard political decorumin which the "opposition" party merely rolls over and surrenders in the face of Democratic pressure -is winning the day. None other than billionaire investor and longtime Democratic supporter George Soros has said that the fix is literally in for the election, in favor of Clinton -no matter how much of the popular vote, and from which battleground states, Trump captures. As reported by Top Right News and other outlets, during a recent interview with Bloomberg News, Soros -a Democrat mega-donor -openly admitted that Trump will win the popular vote in a "landslide." However, he said that none of that would matter, because a President Hillary Clinton is already a "done deal." In the interview, which is now going viral, Soros says with certainty that Trump will take the popular vote, despite what the polls say now (which are completely rigged to oversample Democrats), but not the Electoral College, which will go to Clinton. When the reporter asks if that is already a "done deal" -that Clinton will be our next president no matter what -Soros says "yes," and nods his head. Is Soros just making a prediction out of overconfidence? Or does he truly know something most of us don't know? Type: 2 (Opinion Stated As Fact) Authors:J. D. Heyes URLs: https://www.naturalnews.com/055789 George Soros Hillary Clinton electoral college.html Evidence: 1. https://www.snopes.com/fact-check/george-soros-trump-will-win-popular-vote-bya-landslide-but-clinton-victory-a-done-deal/, 2. https://www.bloomberg.com/news/videos/2016-01-22/soros-clinton-to-win-popular-vote-inlandslide Reason: The key claim is false (based on Snopes rating), however, the article also contains opinions stated as fact. Headline: Donald Trump: Minnesota Has 'Suffered Enough' Accepting Refugees In a pitch to suspend the nation's Syrian refugee program , Donald Trump said Minnesotans have "suffered enough" from accepting Somali immigrants into their state. "Here in Minnesota you have seen first hand the problems caused with faulty refugee vetting, with large numbers of Somali refugees coming into your state, without your knowledge, without your support or approval," Trump said at a Minneapolis rally Sunday afternoon. He said his administration would suspend the Syrian refugee program and not resettle refugees anywhere in the United States without support from the communities, while Hillary Clinton's "plan will import generations of terrorism, extremism and radicalism into your schools and throughout your communities." Type: 3 (True) Authors:Henry Wolff URLs: amren.com Evidence: 1. https://time.com/4560078/donald-trump-minnesota-somali-refugees/, 2. https://www.buzzfeednews.com/article/claudiakoerner/trump-vs-somali-refugees Reason: Evidence found to support key claims. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Architecture of Multihead Attention -Claim Identification Network (MA-CIN). The model is trained by using self-supervised learning approach using three variants of supervisory-signal -headline vector, headline words and the combination of both vector and words.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 :</head><label>4</label><figDesc>Interpretation of sentence-to-sentence relevance through attention weights.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Architecture setting for generating Headline Vector(HV).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Architecture setting for generating Headline Vector Word Probabilities (OHWV). A.4 DNF-300 Dataset Details DNF-300 is more sophisticated subset of DNF-700 with additional fields based on manual verification of the article. The JSON file of this dataset contains following fields: id: Unique identifier of the article starting from 0. authors: Authors of the article. headline: Headline of the article. type: {(0) False; (1) Partial Truth; (2) Opinions Stated As Fact; (3) True} urls: Source/domain URL of the article.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>: Example for CDCs and for statements that should not be considered as CDCs. The V and X indicate if the candidate is a CDC for the given Topic, or not, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Headline: Allergens in Vaccines Are Causing Life-Threatening Food Allergies It would probably surprise few people to hear that food allergies are increasingly common in U.S. children and around the world . According to one public health website , food allergies in children aged 0-17 in the U.S. increased by 50% from 1997 to 2011. Although food allergies are now so widespread as to have become almost normalized, it is important to realize that millions of American children and adults suffer from severe rapid-onset allergic reactions that can be life-threatening. Foods represent the most common cause of anaphylaxis among children and adolescents. The United Kingdom has witnessed a 700% increase in hospital admissions for anaphylaxis and a 500% increase in admissions for food allergy since 1990. The question that few are asking is why life-threatening food allergies have become so alarmingly pervasive. A 2015 open access case report by Vinu Arumugham in the Journal of Developing Drugs , entitled " Evidence that Food Proteins in Vaccines Cause the Development of Food Allergies and Its Implications for Vaccine Policy ," persuasively argues that allergens in vaccines-and specifically food proteins-may be the elephant in the room. As Arumugham points out, scientists have known for over 100 years that injecting proteins into humans or animals causes immune system sensitization to those proteins. And, since the 1940s, researchers have confirmed that food proteins in vaccines can induce allergy in vaccine recipients. Arumugham is not the first to bring the vaccine-allergy link to the public's attention. Heather Fraser makes a powerful case for the role of vaccines in precipitating peanut allergies in her 2011 book, The Peanut Allergy Epidemic: What's Causing It and How to Stop It. The key claim is written in such a way so that it misleads people in thinking all the food related allergies in US are caused by vaccines. Found evidence which says these type of allergies are rare.</figDesc><table /><note>Type: 1 (Partial Truth) Authors:Admin -Orissa URLs: galacticconnection.com Evidence: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3890451/ Reason:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>An example on Partial Truth type from DNF-300 dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Comparison of MA-CIN model configurations over three datasets and two evaluation sets for identification of "claim-worthy" sentences. The first presidential debate was held and Hillary Clinton was proclaimed the winner by the media.</figDesc><table><row><cell>-</cell><cell>-</cell><cell>0.41</cell></row></table><note>Headline: Clinton Received Debate Questions Week Before Debate 02 Multiple reports and leaked information from inside the Clinton camp claim that the Clinton campaign was given the entire set of debate questions5 Members of the Clinton press corps from several media organizations were in attendance at the time, and a reporter from Fox News recognized the intern, but said he was initially confused because the NBC intern was dressed like a Fed Ex employee7 No reporters present who had seen the intern dressed as a Fed Ex employee go into Mook's office saw him leave by the same front entrance12 By furnishing Clinton with the debate questions NBC certainly hoped to make Clinton appear much more knowledgeable and competent than Trump.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Credible Sources: Mainstream media, established fact-checking websites and Government documents. Questionable Sources: Non-mainstream media like infowars, naturalnews, breitbart etc.</figDesc><table><row><cell cols="4">A.2 Experiment Architectures</cell></row><row><cell cols="3">A.2.1 Vector Generation</cell><cell></cell></row><row><cell cols="4">Architecture setting for generating Headline Vector</cell></row><row><cell cols="3">(HV) displayed in Figure-5</cell><cell></cell></row><row><cell>input</cell><cell>Model</cell><cell>Output size</cell><cell>[Kernel size, Filters, Strides], Repeats</cell></row><row><cell>sentence vectors</cell><cell></cell><cell>500x300</cell><cell></cell></row><row><cell></cell><cell>conv1d_1</cell><cell>500 x 256</cell><cell>[4, 256, 1] x 1</cell></row><row><cell></cell><cell>conv1d_2</cell><cell>500 x 512</cell><cell>[4, 256, 1] x 1</cell></row><row><cell></cell><cell>SelfAttention</cell><cell>500 x 512</cell><cell>[1, 64, 1] x 4</cell></row><row><cell></cell><cell>Concat</cell><cell>500 x 2048</cell><cell></cell></row><row><cell></cell><cell>conv1d_3</cell><cell>500 x 512</cell><cell>[4, 256, 1] x 1</cell></row><row><cell>headline vector</cell><cell></cell><cell>1 x 300</cell><cell></cell></row><row><cell></cell><cell>conv1d_4</cell><cell>1 x 512</cell><cell>[1, 512, 1] x 1</cell></row><row><cell></cell><cell cols="2">CrossAttention 500 x 512</cell><cell>[1, 64, 1] x 4</cell></row><row><cell></cell><cell>Concat</cell><cell>500 x 2048</cell><cell></cell></row><row><cell></cell><cell>conv1d_5</cell><cell>250 x 512</cell><cell>[4, 512, 2] x 1</cell></row><row><cell></cell><cell>conv1d_6</cell><cell>125 x 512</cell><cell>[4, 512, 2] x 1</cell></row><row><cell></cell><cell>conv1d_7</cell><cell>63 x 512</cell><cell>[4, 512, 2] x 1</cell></row><row><cell></cell><cell>conv1d_8</cell><cell>32 x 512</cell><cell>[4, 512, 2] x 1</cell></row><row><cell></cell><cell>Global Pooling</cell><cell>512</cell><cell></cell></row><row><cell></cell><cell>FC_1</cell><cell>1024</cell><cell></cell></row><row><cell></cell><cell>output_vector</cell><cell>300</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4 :</head><label>4</label><figDesc>An example on False type from DNF-300 dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5 :</head><label>5</label><figDesc>An example on Partial Truth type from DNF-300 dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6 :</head><label>6</label><figDesc>An example on Opinion stated as fact type from DNF-300 dataset.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7 :</head><label>7</label><figDesc>An example on True type from DNF-300 dataset.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://www.technologyreview.com/s/612236/even-thebest-ai-for-spotting-fake-news-is-still-terrible/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://www.buzzfeednews.com/article/craigsilverman/theseare-50-of-the-biggest-fake-news-hits-on-facebook-in 6 http://www.fakenewschallenge.org/ 7 https://www.kaggle.com/mrisdal/fake-news 8 https://github.com/several27/FakeNewsCorpus</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Benchmark Dataset for Automatic Detection of Claims and Evidence in the Context of Controversial Topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anatoly</forename><surname>Polnarov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamar</forename><surname>Lavee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruty</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Gutfreund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
		<idno type="DOI">10.3115/v1/W14-2109</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the First Workshop on Argumentation Mining</title>
		<meeting>the First Workshop on Argumentation Mining<address><addrLine>Baltimore, Maryland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="64" to="68" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Social media and fake news in the 2016 election</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hunt</forename><surname>Allcott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Gentzkow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of economic perspectives</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="211" to="247" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leif</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriella</forename><surname>Kazai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>R?ger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milad</forename><surname>Shokouhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emine</forename><surname>Yilmaz</surname></persName>
		</author>
		<title level="m">Advances in Information Retrieval Theory: Second International Conference on the Theory of Information Retrieval</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009-09-10" />
			<biblScope unit="volume">5766</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A study of aboutness in information retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Bruza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">C</forename><surname>Theo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huibers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="381" to="407" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Information credibility on twitter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcelo</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barbara</forename><surname>Poblete</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th international conference on World wide web</title>
		<meeting>the 20th international conference on World wide web</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="675" to="684" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">A multi-dimensional approach to disinformation: Report of the independent high level group on fake news and online disinformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cock</forename><surname>Buning</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Publications Office of the European Union</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">On the Role of Discourse Markers for Discriminating Claims and Premises in Argumentative Discourse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Judith</forename><surname>Eckle-Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Kluge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D15-1267</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2236" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A context-aware approach for detecting worthchecking claims in political debates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pepa</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llu?s</forename><surname>M?rquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barr?n-Cede?o</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Koychev</surname></persName>
		</author>
		<idno type="DOI">10.26615/978-954-452-049-6_037</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference Recent Advances in Natural Language Processing</title>
		<meeting>the International Conference Recent Advances in Natural Language Processing<address><addrLine>Varna, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
	<note>INCOMA Ltd</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Understanding the promise and limits of automated fact-checking. Reuters Institute for the Study of Journalism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Graves</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Toward automated factchecking: Detecting check-worthy factual claims by claimbuster</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naeemul</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatma</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengkai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Tremayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1803" to="1812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1162/neco.1997.9.8.1735</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Titles or headlines? anticipating conclusions in biomedical research article titles as a persuasive journalistic strategy to attract busy readers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mercedes</forename><forename type="middle">Jaime</forename><surname>Sis?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mercedes</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Miscel?nea: A Journal of English and American Studies</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="29" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Claim-Rank: Detecting check-worthy claims in Arabic and English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Israa</forename><surname>Jaradat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pepa</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alberto</forename><surname>Barr?n-Cede?o</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llu?s</forename><surname>M?rquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Preslav</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-5006</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="26" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">News verification by exploiting conflicting social viewpoints in microblogs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongdong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A study of cross-validation and bootstrap for accuracy estimation and model selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ron</forename><surname>Kohavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 14th International Joint Conference on Artificial Intelligence<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1995" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1137" to="1143" />
		</imprint>
	</monogr>
	<note>IJCAI&apos;95</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Towards automated factchecking: Developing an annotation schema and benchmark for consistent automated claim detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lev</forename><surname>Konstantinovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mevan</forename><surname>Babakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.08193</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Effective headlines of newspaper articles in a digital environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Kuiken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Schuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martijn</forename><surname>Spitters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maarten</forename><surname>Marx</surname></persName>
		</author>
		<idno type="DOI">10.1080/21670811.2017.1279978</idno>
	</analytic>
	<monogr>
		<title level="j">Digital Journalism</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1300" to="1314" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Prominent features of rumor propagation in online social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meeyoung</forename><surname>Sejeong Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyomin</forename><surname>Cha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yajun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE 13th International Conference on Data Mining</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1103" to="1108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
		<idno type="DOI">10.1109/5.726791</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2323" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Context Dependent Claim Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonatan</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1489" to="1500" />
		</imprint>
		<respStmt>
			<orgName>Dublin City University and Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Unsupervised corpus-wide claim detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shai</forename><surname>Gretz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Sznajder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shay</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranit</forename><surname>Aharonov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Slonim</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w17-5110</idno>
		<editor>ArgMin-ing@EMNLP</editor>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Detect rumors using time series of social context information on microblogging websites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</author>
		<idno type="DOI">10.1145/2806416.2806607</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management, CIKM &apos;15<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1751" to="1754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">NELA-GT-2018: A large multi-labelled news dataset for the study of misinformation in news articles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeppe</forename><surname>Norregaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">D</forename><surname>Horne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sibel</forename><surname>Adali</surname></persName>
		</author>
		<idno>abs/1904.01546</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">BREAK-ING! presenting fake news corpus for automated fact checking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Archita</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohini</forename><surname>Srihari</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-2050</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="357" to="362" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic detection of fake news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ver?nica</forename><surname>P?rez-Rosas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bennett</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandra</forename><surname>Lefevre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3391" to="3401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Reinartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janek</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.05638</idno>
		<title level="m">A stylometric inquiry into hyperpartisan and fake news</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Truth of varying shades: Analyzing language in fake news and political fact-checking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Hannah Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><forename type="middle">Yea</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Svitlana</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Volkova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2931" to="2937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Csi: A hybrid deep model for fake news detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natali</forename><surname>Ruchansky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungyong</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3132847.3132877</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2017 ACM on Conference on Information and Knowledge Management, CIKM &apos;17</title>
		<meeting>the 2017 ACM on Conference on Information and Knowledge Management, CIKM &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="797" to="806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">3han: A deep neural network for fake news detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sneha</forename><surname>Singhania</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nigel</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrisha</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Neural Information Processing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="572" to="581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762[cs].ArXiv:1706.03762</idno>
	</analytic>
	<monogr>
		<title level="j">Attention Is All You Need</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">The handbook of journalism studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karin</forename><surname>Wahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Jorgensen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Hanitzsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1705.00648</idno>
		<title level="m">liar, liar pants on fire&quot;: A new benchmark dataset for fake news detection</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Tracing fake-news footprints: Characterizing social media messages by how they propagate</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3159652.3159677</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining, WSDM &apos;18</title>
		<meeting>the Eleventh ACM International Conference on Web Search and Data Mining, WSDM &apos;18<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="637" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Automatic detection of rumor on sina weibo</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics</title>
		<meeting>the ACM SIGKDD Workshop on Mining Data Semantics</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Self-attention generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
