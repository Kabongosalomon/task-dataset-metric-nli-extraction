<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Hyperbolic Vision Transformers: Combining Improvements in Metric Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Ermolov</surname></persName>
							<email>aleksandr.ermolov@unitn.it</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leyla</forename><forename type="middle">Mirvakhabova</forename><surname>Skoltech</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russia</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Khrulkov</surname></persName>
							<email>khrulkov.v@gmail.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandex</forename><forename type="middle">&amp;amp;</forename><surname>Skoltech</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russia</forename></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
							<email>niculae.sebe@unitn.it</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><forename type="middle">Oseledets</forename><surname>Skoltech</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russia</forename><surname>Airi</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Trento</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">I.Oseledets@skoltech.ru</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Hyperbolic Vision Transformers: Combining Improvements in Metric Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Metric learning aims to learn a highly discriminative model encouraging the embeddings of similar classes to be close in the chosen metrics and pushed apart for dissimilar ones. The common recipe is to use an encoder to extract embeddings and a distance-based loss function to match the representations -usually, the Euclidean distance is utilized. An emerging interest in learning hyperbolic data embeddings suggests that hyperbolic geometry can be beneficial for natural data. Following this line of work, we propose a new hyperbolic-based model for metric learning. At the core of our method is a vision transformer with output embeddings mapped to hyperbolic space. These embeddings are directly optimized using modified pairwise cross-entropy loss. We evaluate the proposed model with six different formulations on four datasets achieving the new state-of-the-art performance. The source code is available at https://github.com/htdt/hyp_metric.</p><p>The goal of the loss function is straightforward: we want to group the representations of similar objects in the embedding space while pulling away representations of dissimilar objects. Most loss functions can be divided into two categories: proxy-based and pair-based <ref type="bibr" target="#b22">[23]</ref>. Additionally to the network parameters, the first type of losses trains proxies, which represent subsets of the dataset <ref type="bibr" target="#b31">[32]</ref>. This proce-</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Metric learning task formulation is general and intuitive: the obtained distances between data embeddings must represent semantic similarity. It is a typical cognitive task to generalize similarity for new objects given some examples of similar and dissimilar pairs. Metric learning algorithms are widely applied in various computer vision tasks: content-based image retrieval <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47]</ref>, nearduplicate detection <ref type="bibr" target="#b64">[65]</ref>, face recognition <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b43">44]</ref>, person re-identification <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b62">63]</ref>, as a part of zero-shot <ref type="bibr" target="#b46">[47]</ref> or fewshot learning <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b49">50]</ref>.</p><p>Modern image retrieval methods can be decomposed into roughly two components: the encoder mapping the image to its compact representation and the loss function govern-* Skolkovo Institute of Science and Technology ing the training process. Encoders with backbones based on transformer architecture have been recently proposed as a competitive alternative to previously used convolutional neural networks (CNNs). Transformers lack some of CNN's inductive biases, e.g., translation equivariance, requiring more training data to achieve a fair generalization. On the other hand, it allows transformers to produce more general features, which presumably can be more beneficial for image retrieval <ref type="bibr">[3,</ref><ref type="bibr" target="#b7">8]</ref>, as this task requires generalization to unseen classes of images. To alleviate the issue above, several training schemes have been proposed: using a large dataset <ref type="bibr" target="#b6">[7]</ref>, heavily augmenting training dataset and using distillation <ref type="bibr" target="#b52">[53]</ref>, using self-supervised learning scenario <ref type="bibr">[3]</ref>.</p><p>The choice of the embedding space directly influences the metrics used for comparing representations. Typically, embeddings are arranged on a hypersphere, i.e. the output of the encoder is L 2 normalized, resulting in using cosine similarity as a distance. In this work, we propose to consider the hyperbolic spaces. Their distinctive property is the exponential volume growth with respect to the radius, unlike Euclidean spaces with polynomial growth. This feature makes hyperbolic space especially suitable for embedding tree-like data due to increased representation power. The paper <ref type="bibr" target="#b41">[42]</ref> shows that a tree can be embedded to Poincar? disk with an arbitrarily low distortion. Most of the natural data is intrinsically hierarchical, and hyperbolic spaces suit well for its representation. Another desirable property of hyperbolic spaces is the ability to use low-dimensional manifolds for embeddings without sacrificing the model accuracy and its representation power <ref type="bibr" target="#b33">[34]</ref>. dure can be seen from a perspective of a simple classification task: we train matching embeddings, which would classify each subset <ref type="bibr" target="#b32">[33]</ref>. At the same time, pair-based losses operate directly on the embeddings. The advantage of pairbased losses is that they can account for the fine-grained interactions of individual samples. Such losses do not require data labels: it is sufficient to have pair-based relationships. This property is crucial for a widely used pairwise crossentropy loss in self-supervised learning scenario <ref type="bibr">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b54">55]</ref>. Instead of labels, the supervision comes from a pretext task, which defines positive and negative pairs. Inspired by these works, we adopt pairwise cross-entropy loss for our experiments.</p><p>The main contributions of our paper are the following:</p><p>? We propose to project embeddings to the Poincar? ball and to use the pairwise cross-entropy loss with hyperbolic distances. Through extensive experiments, we demonstrate that the hyperbolic counterpart outperforms the Euclidean setting.</p><p>? We show that the joint usage of vision transformers, hyperbolic embeddings, and pairwise cross-entropy loss provides the best performance for the image retrieval task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Method</head><p>We propose a new metric learning loss that combines representative expressiveness of the hyperbolic space and the simplicity and generality of the cross-entropy loss. The suggested loss operates in the hyperbolic space encouraging the representatives of one class (positives) to be closer while pushing the samples from other categories (negatives) away.</p><p>The schematic overview of the proposed method is depicted at <ref type="figure" target="#fig_0">Figure 1</ref>. The remainder of the section is organized as follows. We start with providing the necessary preliminaries on hyperbolic spaces in Section 2.1, then we discuss the loss function in Section 2.2 and, finally, we briefly describe the architecture and discuss pretraining schemes in Section 2.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Hyperbolic Embeddings</head><p>Formally, the n-dimensional hyperbolic space H n is a Riemannian manifold of constant negative curvature. There exist several isometric models of hyperbolic space, in our work we stick to the Poincar? ball model (D n c , g D ) with the curvature parameter c (the actual curvature value is then ?c 2 ). This model is realized as a pair of an n-dimensinal ball D n = {x ? R n : c x 2 &lt; 1, c ? 0} equipped with the Riemannian metric g D = ? 2 c g E , where ? c = 2 1?c x 2 is the conformal factor and g E = I n is Euclidean metric tensor. This means, that local distances are scaled by the factor ? c approaching infinity near the boundary of the ball. This gives rise to the 'space expansion' property of hyperbolic spaces. While, in the Euclidean spaces, the volume of an object of a diameter r scales polynomially in r, in the hyperbolic space, such volumes scale exponentially with r. Intuitively, this is a continuous analogue of trees: for a tree with a branching factor k, we obtain O(k d ) nodes on the level d, which in this case serves as a discrete analogue of the radius. This property allows us to efficiently embed hierarchical data even in low dimensions, which is made precise by embedding theorems for trees and complex networks <ref type="bibr" target="#b41">[42]</ref>.</p><p>Hyperbolic spaces are not vector spaces; to be able to perform operations such as addition, we need to introduce a so-called gyrovector formalism <ref type="bibr" target="#b53">[54]</ref>. For a pair x, y ? D n c , their addition is defined as</p><formula xml:id="formula_0">x ? c y = (1 + 2c x, y + c y 2 )x + (1 ? c x 2 )y 1 + 2c x, y + c 2 x 2 y 2 . (1)</formula><p>The hyperbolic distance between x, y ? D n c is defined in the following manner:</p><formula xml:id="formula_1">D hyp (x, y) = 2 ? c arctanh( ? c ? x ? c y ).<label>(2)</label></formula><p>Note that with c ? 0 the distance function (2) reduces to Euclidean: lim c?0 D hyp (x, y) = 2 x ? y .</p><p>We also need to define a bijection from Euclidean space to the Poincar? model of hyperbolic geometry. This mapping is termed exponential while its inverse mapping from hyperbolic space to Euclidean is called logarithmic.</p><p>For some fixed base point x ? D n c , the exponential mapping is a function exp c x : R n ? D n c defined as:</p><formula xml:id="formula_2">exp c x (v) = x ? c tanh ? c ? c x v 2 v ? c v .<label>(3)</label></formula><p>The base point x is usually set to 0 which makes formulas less cumbersome and empirically has little impact on the obtained results. To train our model, we take a sample x i , pass it through the encoder and project the output to hyperbolic space; the resulted representation in hyperbolic space is denoted as z i . Since our pairwise cross-entropy loss is based on hyperbolic distances, we do not project z i back to Euclidean space and use only the exponential mapping.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Pairwise Cross-Entropy Loss</head><p>At each iteration, we sample N different categories of images and two samples per category. In this case, the total number of samples (batch size) is K = 2N consisting of N positive pairs.</p><p>Additionally to hyperbolic distance, we define the distance with the cosine similarity, implemented with a squared Euclidean distance between normalized vectors:</p><formula xml:id="formula_3">D cos (z i , z j ) = z i z i 2 ? z j z j 2 2 2 = 2 ? 2 z i , z j z i 2 ? z j 2</formula><p>(4) The loss function for a positive pair (i, j) is defined as</p><formula xml:id="formula_4">l i,j = ? log exp (?D(z i , z j )/? ) K k=1,k =i exp (?D(z i , z k )/? ) ,<label>(5)</label></formula><p>where D is a distance (D hyp or D cos ) and ? is a temperature hyperparameter. The total loss is computed for all positive pairs, both (i, j) and (j, i), in a batch. If the total number of categories is small and a larger batch size is more suitable from the optimization perspective, it is possible to sample more than two samples per category. In this case, we sample d images per each category, d ? 2. We divide the batch K = dN into d subsets with each subset consisting of N samples from different categories. Next, we obtain the loss value for each pair of subsets, as defined Equation <ref type="formula" target="#formula_4">(5)</ref>, summing them up for the final value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">?-hyperbolicity</head><p>While the curvature value of an underlying manifold for embedding is often neglected, a more efficient way is to estimate it for each dataset specifically. Following the analysis in <ref type="bibr" target="#b21">[22]</ref>, we estimate a 'measure' of the data hyperbolicity. This evaluation is made through the computation of the socalled Gromov ?. Its calculation requires first computing Gromov product for points x, y, z ? X :</p><formula xml:id="formula_5">(y, z) x = 1 2 (d(x, y) + d(x, z) ? d(y, z)),<label>(6)</label></formula><p>where (X , d) is an arbitrary metric space. For a set of points, we compute the matrix M of pairwise Gromov products <ref type="bibr" target="#b5">(6)</ref>. The ? value is then defined as the largest entry in the matrix (M ?M )?M . Here, ? denotes the min-max matrix product defined as (A ? B) ij = max k min{A ik , B kj } <ref type="bibr" target="#b9">[10]</ref>. Being rescaled between 0 and 1, the relative ?hyperbolicity reflects how close to the hyperbolic the hidden structure is: values tending to 0 show the higher degree of intrinsic data hyperbolicity. The ? value is related to the optimal radius of the Poincar? ball for embeddings through the following expression c(X) = ( 0.144 ? ) 2 . We adopt the procedure described in <ref type="bibr" target="#b21">[22]</ref> and evaluate ? for image embeddings extracted using three encoders: ViT-S, DeiT-S and DINO (described in Section 2.5). Tab. 1 highlights the obtained relative ? values for CUB-200, Cars-196, SOP and In-Shop datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Feature Clipping</head><p>The paper <ref type="bibr" target="#b14">[15]</ref> empirically shows that a hyperbolic neural network tends to have vanishing gradients since it pushes the embeddings close to the boundary of Poincar? ball, making the gradients of Euclidean parameters vanish. To avoid numerical errors when dealing with hyperbolic neural networks, the common approach is to perform clipping by norm on the points in the Poincar? ball; the standard norm value is 1 ? c (1 ? 10 ?5 ). Instead, the paper <ref type="bibr" target="#b14">[15]</ref> proposes to augment this procedure with an additional technique called feature clipping:</p><formula xml:id="formula_6">x E C = min 1, r x E ? x E ,<label>(7)</label></formula><p>where x E lies in the Euclidean space, x E C is its clipped counterpart and r is a new effective radius of the Poincar? ball. Intuitively, this allows us to push embeddings further away from the boundary and avoid the vanishing gradients problem; in the experiments of <ref type="bibr" target="#b14">[15]</ref> it led to a consistent improvement over baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Vision Transformers</head><p>In our experiments, we use ViT architecture introduced by <ref type="bibr" target="#b6">[7]</ref>. The input image is sliced into patches of size 16?16 pixels. Each patch is flattened and then linearly projected into an embedding. The resulting vectors are concatenated with position embeddings. Also, this set of vectors includes an additional "classification" token. Note that in our case, this token is used to obtain the image embedding, but we do not train a standard classifier as in <ref type="bibr" target="#b6">[7]</ref>. For consistency with previous literature, we name this token [class]. The set of resulting vectors is fed into a standard transformer encoder <ref type="bibr" target="#b55">[56]</ref>. It consists of several layers with multiheaded self-attention (MSA) and MLP blocks, with a LayerNorm before and a residual connection after each block. The output for the transformer encoder for the [class] token is used as the final image representation. For more details, we refer to <ref type="bibr" target="#b6">[7]</ref>.</p><p>ViT-S <ref type="bibr" target="#b47">[48]</ref> is a smaller version of ViT with 6 heads in MSA (base version uses 12 heads). This architecture is similar to ResNet-50 <ref type="bibr" target="#b17">[18]</ref> in terms of number of parameters (22M for ViT-S and 23M for ResNet-50) and computational requirements (8.4 FLOPS for ViT-S and 8.3 FLOPS for ResNet-50). This similarity makes it possible to fairly compare with previous works based on ResNet-50 encoder, for this reason, we employ this configuration for our experiments. A more thorough description is available in <ref type="bibr" target="#b47">[48]</ref>.</p><p>Vision transformers, compared to CNNs, require more training signal. One solution, as proposed in <ref type="bibr" target="#b6">[7]</ref>, is to use a large dataset. ImageNet-21k <ref type="bibr" target="#b5">[6]</ref> contains approximately 14M images classified into 21K categories. ViT-S, pretrained on ImageNet-21k, is publicly available <ref type="bibr" target="#b47">[48]</ref>; we include it in our experiments. Another solution, DeiT-S <ref type="bibr" target="#b52">[53]</ref>, is based on the same (ViT-S) architecture and is trained on a smaller ImageNet-1k dataset <ref type="bibr" target="#b40">[41]</ref> (a subset of ImageNet-21k consisting of about 1.3M training im-ages and 1K categories). An additional training signal is provided by teacher-student distillation, with a CNN-based teacher <ref type="bibr" target="#b52">[53]</ref>.</p><p>The third solution used in our experiments, DINO <ref type="bibr">[3]</ref>, is based on self-supervised training. In this case, the model ViT-S is trained on the ImageNet-1k dataset <ref type="bibr" target="#b40">[41]</ref> without labels. The encoder must produce consistent output for different parts of an image, obtained using augmentations (random crop, color jitter, and others). This training scheme is in line with the image retrieval task; in both cases, the encoder is explicitly trained to produce similar output for semantically similar input. However, the goal of these tasks is different: self-supervised learning provides pretrained features, which are then used for other downstream tasks, while for image retrieval resulting features are directly used for the evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiments</head><p>We follow a widely adopted training and evaluation protocol <ref type="bibr" target="#b22">[23]</ref> and compare several versions of our method with current state-of-the-art on four benchmark datasets for category-level retrieval. We include technical details of datasets, our implementation and training details, and finally, present empirical results. There are two types of experiments, first, we compare with the state-of-the-art, and then we investigate the impact of hyperparameters (encoder patch size, manifold curvature, embedding size and batch size). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Implementation Details</head><p>We use ViT-S <ref type="bibr" target="#b47">[48]</ref> as an encoder with three types of pretraining (ViT-S, DeiT-S and DINO), details are presented in Section 2.5. The linear projection for patch embeddings as a first basic operation presumably corresponds to lowlevel feature extraction, so we freeze it during fine-tuning. The encoder outputs a representation of dimensionality 384, which is further plugged into a head linearly projecting the features to the space of dimension 128. We initialize the biases of the head with constant 0 and weights with a (semi) orthogonal matrix <ref type="bibr" target="#b42">[43]</ref>. We include two versions of the head: with a projection to a hyperbolic space ("Hyp-") and with projection to a unit hypersphere ("Sph-"). In the first case, we use curvature parameter c = 0.1 (in Section 3.4 we investigate how it affects the method's performance), temperature ? = 0.2 and clipping radius (defined in Section 2.4) r = 2.3. For spherical embeddings, we use temperature ? = 0.1.</p><p>To evaluate the model performance, for the encoder, we compute the Recall@K metric for the output with distance D cos (Eq. (4)); for the head, we use D cos for "Sph-" version and hyperbolic distance D hyp (Eq. (2)) for "Hyp-" version. We resize the test images to 224 (256 for CUB) on the smaller side and take one 224 ? 224 center crop. Note that some methods use images of higher resolution for training and evaluations, e.g., ProxyNCA++ <ref type="bibr" target="#b51">[52]</ref> use 256 ? 256 crops indicating that smaller 227 ? 227 crops degrade the performance by 4.3% on CUB. However, 224 ? 224 is the default size for encoders considered in our work; moreover, some recent methods, such as IRT R <ref type="bibr" target="#b7">[8]</ref>, use this size for experiments.</p><p>We use the AdamW optimizer <ref type="bibr" target="#b28">[29]</ref> with a learning rate value 1 ? 10 ?5 for DINO and 3 ? 10 ?5 for ViT-S and DeiT-S. The weight decay value is 0.01, and the batch size equals 900. The number of optimizer steps depends on the dataset: 200 for CUB, 600 for Cars, 25000 for SOP, 2200 for In-Shop. The gradient is clipped by norm 3 for a greater stability. We apply commonly used data augmentations: random crop resizing the image to 224 ? 224 using bicubic interpolation combined with a random horizontal flip. We train with Automatic Mixed Precision in O2 mode 1 . All experiments are performed on one NVIDIA A100 GPU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Results</head><p>Tab. 2 highlights the experimental results for the 128dimensional head embedding and the results for 384dimensional encoder embedding are shown in Tab. 3. We include evaluation of the pretrained encoders without training on the target dataset in Tab. 3 for reference. On the CUB dataset, we can observe the solid performance of methods with ViT encoder; the gap between the second-1 https://github.com/NVIDIA/apex best method IRT R and Hyp-ViT is 9%. However, the main improvement comes from the dataset used for pretraining (ImageNet-21k), since Hyp-DINO and Hyp-DeiT demonstrate a smaller improvement, while baseline ViT-S without finetuning shows strong performance. We hypothesize that this is due to the presence of several bird classes in the ImageNet-21k dataset encouraging the encoder to separate them during the pretraining phase.</p><p>For the SOP and In-Shop datasets, the difference between Hyp-ViT and Hyp-DINO is minor, while, for Cars-196, Hyp-DINO outperforms Hyp-ViT with a significant margin. These results confirm that both pretraining schemes are suitable for the considered task. The versions with DeiT perform worse compared to ViT-and DINO-based encoders while outperforming CNN-based models. This observation confirms the significance of vision transformers in our architecture. The experimental results suggest that hyperbolic space embeddings consistently improve the performance compared to spherical versions. Hyperbolic space seems to be beneficial for the embeddings, and the distance in hyperbolic space suits well for the pairwise cross-entropy loss function. At the same time, our sphere-based versions perform well compared to other methods with CNN encoders. <ref type="figure">Figure 2</ref> illustrates how learned embeddings are arranged on the Poincar? disk. We use UMAP [31] method with the "hyperboloid" distance metric to reduce the dimensionality to 2D for visualization. For the training part, we can see that samples are clustered according to labels, and each cluster is pushed closer to the border of the disk, indicating that the encoder separates classes well. However, for the testing part, the structure is more complex. We observe that some of the samples tend to move towards the center and intermix, while others stay in clusters, showing possible hierarchical relationships. We can see that car images are grouped by several properties: pose, color, shape, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Impact of Hyperparameters</head><p>In this section, we investigate the impact of the values of the hyperparameters on the model performance.</p><p>Encoder patch size. ViT architecture does not process each pixel independently; for computational feasibility, the input image is sliced into patches projected into the initial embeddings. The default size of the patch is 16 ? 16, although considering other values is also possible. The experiments in <ref type="bibr">[3]</ref> have demonstrated a significant performance gain from smaller 8 ? 8 patches for self-supervised learning. In this case, the number of parameters of the encoder does not change; however, it requires processing 4? more embeddings, which allows the encoder to learn more complex dependencies between patches. We add an experiment with this setup in Tab. 4 demonstrating a substantial performance improvement (+4.4%) compared to the default configuration. In this case, we use the same training procedure,  <ref type="table">Table 3</ref>. Recall@K metric for four datasets, "Dim" column shows the dimensionality of embeddings. The 6 versions of our method are listed in the bottom section, evaluated for encoder embeddings, titles are described in <ref type="table">Table 2</ref>. Encoders by method: A-BIER, ABE, SM: GoogleNet <ref type="bibr" target="#b50">[51]</ref>; XBM, HTL, MS, SoftTriple, HORDE, Proxy-Anchor: Inception with batch normalization <ref type="bibr" target="#b18">[19]</ref>; NSoftmax, ProxyNCA++: ResNet-50 <ref type="bibr" target="#b17">[18]</ref>; IRTR: DeiT <ref type="bibr" target="#b52">[53]</ref>. ? pretrained encoders without training on the target dataset. ? pretrained on the larger ImageNet-21k <ref type="bibr" target="#b5">[6]</ref>. described in Section 3.2, with the batch size equal to 120. Manifold curvature. Tab. 5 shows the model performance depending on the curvature value c. We observe that the method is robust in the range (0.01, 0.3) while larger values lead to degradation. Notably, the accuracy of the head degrades faster since the hyperbolic distance is also used in the evaluation and the imprecision in this parameter immediately affects the output. The radius of the ball is inversely proportional to the c value. Intuitively, if the c value tends to 0, the radius tends to infinity, making the ball as flat as the Euclidean space; in contrast, larger c values correspond to a steeper configuration. Note that according to ? values (Tab. 1), the estimated value of c is close to 0.2, depending on the dataset and encoder. However, smaller values tend to provide better stability; we believe this is due to an optimisation process that can be improved for the hyperbolic space. For this reason, we adjusted the default value towards a smaller 0.1 (Section 3.2). Embedding size and batch size. As expected, lower output dimensionality leads to lower recall values. However, taking into account a high data variability <ref type="bibr">(3,</ref><ref type="bibr">985</ref> categories in the test set), the experimental results suggest that the method has a reasonable representation power even in the case of lower dimensions.</p><p>The batch size directly influences the number of negative examples during the training phase; thus, intuitively, larger values have to be more profitable for the model performance. However, as the experiments show (Tab. 5), the method is robust for batch size ? 400, having a minor accuracy degradation for batch size equal to 200. Therefore, for considered datasets, the method does not require distributed training with a large number of GPUs <ref type="bibr">[4]</ref> or specific solutions with a momentum network <ref type="bibr" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Related Work</head><p>Hyperbolic embeddings. Learning embeddings in hyperbolic spaces have emerged since this approach was proposed for NLP tasks <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35]</ref>. Shortly after that, hyperbolic neural networks were presented as a generalization of standard Euclidean operations allowing to learn the data representations directly in hyperbolic spaces <ref type="bibr" target="#b10">[11]</ref>. The authors generalized standard linear layers to hyperbolic counterparts, defined multinomial logistic regression and recurrent neural networks. Several studies showed the benefits of hyperbolic embeddings of visual data when applied to fewshot <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b21">22]</ref> and zero-shot learning <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b25">26]</ref>. In <ref type="bibr" target="#b21">[22]</ref>, the authors proposed a hybrid architecture with the main bulk of the layers operating in Euclidean space and only final layers operating in hyperbolic space. In <ref type="bibr" target="#b8">[9]</ref>, the authors instead focus on kernelization widely used in Euclidean space and generalize them for hyperbolic representations. The paper <ref type="bibr" target="#b25">[26]</ref> proposes a method directly incorporating the hierarchical relations for hyperbolic embeddings in application to zero-shot learning.</p><p>Vision transformers in metric learning. The paper <ref type="bibr" target="#b7">[8]</ref> has recently demonstrated beneficial properties of vision transformers for category-level and object retrieval tasks. The proposed IRT R employs the architecture and pretraining scheme of DeiT <ref type="bibr" target="#b52">[53]</ref>. The method is trained using the contrastive loss with cross-batch memory <ref type="bibr" target="#b58">[59]</ref> with momentum encoder <ref type="bibr" target="#b16">[17]</ref> in several experiments. Moreover, the method requires a sophisticated entropy regularization to spread the embeddings more uniformly on a hypersphere. The study performed in <ref type="bibr" target="#b56">[57]</ref> has shown that pairwise crossentropy loss, considered in our work, already possesses this property. Asymptotically, this loss can be decoupled into two components: one optimizes the alignment of positive pairs, while the second preserves overall uniformity. Furthermore, the exponential expansion of the volume in the hyperbolic space can facilitate uniform feature alignment.</p><p>Self-supervised learning is similar in spirit to metric learning: in both cases, the encoder is trained to produce similar representations for semantically similar images. Consequently, there are various relevant approaches in these domains. DINO <ref type="bibr">[3]</ref> is a recently proposed method, where vision transformer is trained in the self-supervised learning setting. This method shows a high k-NN classification accuracy for obtained representations while also performing well in the image retrieval task. These results suggest that both vision transformers and self-supervised pretraining are advantageous for metric learning and our experiments confirm this.</p><p>Metric learning loss functions. A contrastive loss <ref type="bibr" target="#b15">[16]</ref> and its popular variation triplet margin loss <ref type="bibr" target="#b59">[60]</ref> are classic metric learning loss functions. In the first case, the distance between positive pairs is optimized to be lower than some predefined threshold and larger for the negative pairs. The triplet margin loss penalizes the cases where negative examples are closer to each other than positives plus a margin m. Another variation of the contrastive loss is the lifted structure loss <ref type="bibr" target="#b46">[47]</ref> with LogSumExp applied to all negative pair distances. Similarly, NCA loss <ref type="bibr" target="#b13">[14]</ref> minimizes the distance between positives with respect to a set of negatives using exponential weighting. In essence, pairwise cross-entropy loss (Equation <ref type="formula" target="#formula_4">(5)</ref>) equals NCA when all batch samples are used as negatives.</p><p>A cross-entropy loss in the form of pairwise-distance loss for the metric learning was introduced by <ref type="bibr" target="#b45">[46]</ref> as N-pair loss. In addition, the paper [1] established a connection between the standard cross-entropy loss for classification and metric learning losses, proposing their own version of the pairwise cross-entropy loss. Recently, this loss function has seen overwhelming success in the self-supervised learning field <ref type="bibr">[4,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b54">55]</ref>. Popular implementations are InfoNCE <ref type="bibr" target="#b54">[55]</ref> and NT-Xent <ref type="bibr">[4]</ref>. However, most of these works only consider Euclidean distances between embeddings (generally L 2 -normalized). Our method extends this widely used loss function to the hyperbolic space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have combined several improvements for the metric learning task: pairwise cross-entropy loss with the hyperbolic distance function, vision transformers with several pretraining schemes. We empirically verified that each proposed component is crucial for the best performance. In deep learning tasks, it is often tricky to empirically distinguish the source of improvement between methodological contribution and a technical solution <ref type="bibr" target="#b32">[33]</ref>. To address this obstacle, we have presented several versions, comparing elements of our method in the equal setup. The Hyp-DINO version is of particular interest: it demonstrates that self-supervised learning and metric learning complement each other perfectly, resulting in a powerful metric with minimal supervision.</p><p>Limitations. In this work, we have considered only a vision domain with a category-level retrieval task. However, the proposed method is not limited to such applications. Hyperbolic embeddings <ref type="bibr" target="#b33">[34]</ref> and transformers <ref type="bibr" target="#b55">[56]</ref> were initially proposed for the natural language processing. The recently proposed method <ref type="bibr" target="#b38">[39]</ref> shows that combining visual and language domains gives rise to learning universal representation. At the same time, papers <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b29">30]</ref> demonstrate that one transformer architecture is suitable for many domains at once. Hence, combining multiple domains with a common semantic metric can be an interesting development of this work.</p><p>Broader Impact. Common applications in the field of metric learning are face recognition <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b43">44]</ref> and person reidentification <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b62">63]</ref>. Such systems can improve people's safety and quality of life, but there are also notorious cases based on gathering personal information. Another possible risk is learned social biases. While this topic is commonly studied in the NLP field, the situation with vision transformers is more subtle and far less explored.</p><p>A. Things we tried but they did not work</p><p>Our initial experiments were focused on self-supervised learning (SSL) in hyperbolic space. However, we noticed that the head output, which is usually ignored in SSL formulation, shows high performance, thus we switched to a more suitable metric learning formulation. During preliminary experiments, we tried our method with the ResNet-50 <ref type="bibr">[2]</ref> backbone. In this case, the hyperbolic version also outperforms the sphere-based version. However, we do not publish and compare CNN-based architecture with other methods, because the transformer backbone performs clearly better without drawbacks, and we focus on it. We had a modification of our method with the MoCo [1] loss. However, it performed similarly to plain cross-entropy loss, so we decided not to include it in the final version. Also, we tried our method with ProxyNCA [4] loss, which performed worse.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Datasets visualization</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FCFigure 1 .</head><label>1</label><figDesc>Overview of the proposed method. Two images representing one class (positives) are encoded with the vision transformer, projected into a space of a lower dimension with a fully connected (FC) layer, and then mapped to a hyperbolic space. Blue stars depict the resulting embeddings. Poincar? disk is shown with uniform triangle tiling on the background to illustrate the manifold curvature. Gray circles represent other samples from the batch (negatives). Finally, arrows in the disk represent distances used in the pairwise cross-entropy loss. Positives are pushed closer to each other, negative are pulled far apart.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figures 1 to 4 Figure 1 .</head><label>41</label><figDesc>illustrate how learned embeddings are arranged on the Poincar? disk. We use UMAP [3] method with the "hyperboloid" distance metric to reduce the dimensionality to 2D for visualization. Embeddings are obtained with Hyp-DINO configuration for CUB-200-2011 and Cars-196 datasets. Each point inside the disk corresponds to a sample, different colors indicate different classes. Figures 5 and 6 demonstrate actual images of the first 4000 samples of the evaluation split of CUB-200-2011 and Cars-196 datasets. We use the layout from Figures 2 and 4 projected to a uniform 2D grid, preserving neighborhood relations of samples. arXiv:2203.10833v2 [cs.CV] 22 Mar 2022 CUB-200-2011 train set Figure 2. CUB-200-2011 test set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Cars-196 train set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .Figure 6 .</head><label>46</label><figDesc>Cars-196 test setFigure 5. CUB-200-2011 test subset (4000 images) Cars-196 test subset (4000 images)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>CUB-200-2011 (CUB)<ref type="bibr" target="#b60">[61]</ref> includes 11,788 images with 200 categories of bird breeds. The training set corresponds to the first 100 classes with 5,864 images, and the remaining 100 classes with 5,924 images are used for testing. The images are very similar; some breeds can only be distinguished by minor details, making this dataset challenging and, at the same time, informative for the image retrieval task. Cars-196 (Cars)<ref type="bibr" target="#b24">[25]</ref> consists of 16,185 images representing 196 car models. First 98 classes (8,054 images) are used for training and the other 98 classes (8,131 images) are held out for testing. Stanford Online Product (SOP) [47] consists of 120,053 images of 22,634 products downloaded from eBay.com. We use the standard split: 11,318 classes (59,551 images) for training and remaining 11,316 classes (60,502 images) for testing. In-shop Clothes Retrieval (In-Shop) [28] consists of 7,986 categories of clothing items. First 3,997 categories (25,882 images) are for training, the remaining 3,985 categories are used for testing partitioned into a query set (14,218 images) and a gallery set (12,612 images).</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>] 56.5 69.6 79.9 87.6 81.6 88.7 93.4 96.3 75.2 88.7 95.2</figDesc><table><row><cell>Method</cell><cell cols="2">CUB-200-2011 (K) 1 2 4 8</cell><cell>1</cell><cell cols="2">Cars-196 (K) 2 4</cell><cell>8</cell><cell>1</cell><cell cols="2">SOP (K) 10 100 1000</cell><cell>1</cell><cell>In-Shop (K) 10 20</cell><cell>30</cell></row><row><cell cols="11">Margin [62] FastAP [2] NSoftmax [64-63.9 75.3 84.4 90.6 79.6 86.5 91.9 95.1 72.7 86.2 93.8 98.0 --------73.8 88.0 94.9 98.3 MIC [40] 66.1 76.8 85.6 -82.6 89.1 93.2 -77.2 89.4 94.6 -XBM [59] --------80.6 91.6 96.2 98.7 91.3 97.8 98.4 98.7 --------86.6 96.8 97.8 98.3 88.2 97.0 -98.0 IRT R [8] 72.6 81.9 88.7 92.8 ----83.4 93.0 97.0 99.0 91.1 98.1 98.6 99.0</cell></row><row><cell>Sph-DeiT Sph-DINO</cell><cell cols="10">73.3 82.4 88.7 93.0 77.3 85.4 91.1 94.4 82.5 93.1 97.3 99.2 89.3 97.0 97.9 98.4 76.0 84.7 90.3 94.1 81.9 88.7 92.8 95.8 82.0 92.3 96.9 99.1 90.4 97.3 98.1 98.5</cell></row><row><cell>Sph-ViT  ? Hyp-DeiT Hyp-DINO Hyp-ViT  ?</cell><cell cols="10">83.2 89.7 93.6 95.8 78.5 86.0 90.9 94.3 82.5 92.9 97.4 99.3 90.8 97.8 98.5 98.8 74.7 84.5 90.1 94.1 82.1 89.1 93.4 96.3 83.0 93.4 97.5 99.2 90.9 97.9 98.6 98.9 78.3 86.0 91.2 94.7 86.0 91.9 95.2 97.2 84.6 94.1 97.7 99.3 92.6 98.4 99.0 99.2 84.0 90.2 94.2 96.4 82.7 89.7 93.9 96.2 85.5 94.9 98.1 99.4 92.7 98.4 98.9 99.1</cell></row><row><cell>Method</cell><cell>Dim</cell><cell cols="2">CUB-200-2011 (K) 1 2 4 8</cell><cell>1</cell><cell cols="2">Cars-196 (K) 2 4</cell><cell>8</cell><cell>1</cell><cell cols="2">SOP (K) 10 100 1000 1</cell><cell>In-Shop (K) 10 20 30</cell></row><row><cell cols="11">A-BIER [36] ABE [24] SM [49] XBM [59] HTL [13] MS [58] SoftTriple [37] HORDE [20] Proxy-Anchor [23] 512 68.4 79.2 86.8 91.6 86.1 91.7 95.0 97.3 79.1 90.8 96.2 98.7 91.5 98.1 98.8 99.1 512 57.5 68.7 78.3 86.2 82.0 89.0 93.2 96.1 74.2 86.9 94.0 97.8 83.1 95.1 96.9 97.5 512 60.6 71.5 79.8 87.4 85.2 90.5 94.0 96.1 76.3 88.4 94.8 98.2 87.3 96.7 97.9 98.2 512 56.0 68.3 78.2 86.3 83.4 89.9 93.9 96.5 75.3 87.5 93.7 97.4 90.7 97.8 98.5 98.8 512 65.8 75.9 84.0 89.9 82.0 88.7 93.1 96.1 79.5 90.8 96.1 98.7 89.9 97.6 98.4 98.6 512 57.1 68.8 78.7 86.5 81.4 88.0 92.7 95.7 74.8 88.3 94.8 98.4 80.9 94.3 95.8 97.2 512 65.7 77.0 86.3 91.2 84.1 90.4 94.0 96.5 78.2 90.5 96.0 98.7 89.7 97.9 98.5 98.8 512 65.4 76.4 84.5 90.4 84.5 90.7 94.5 96.9 78.6 86.6 91.8 95.4 ----512 66.8 77.4 85.1 91.0 86.2 91.9 95.1 97.2 80.1 91.3 96.2 98.7 90.4 97.8 98.4 98.7 NSoftmax [64] 512 61.3 73.9 83.5 90.0 84.2 90.4 94.4 96.9 78.2 90.6 96.2 -86.6 97.5 98.4 98.8 ProxyNCA++ [52] 512 69.0 79.8 87.3 92.7 86.5 92.5 95.7 97.7 80.7 92.0 96.7 98.9 90.4 98.1 98.8 99.0 IRT R [8] 384 76.6 85.0 91.1 94.3 ----84.2 93.7 97.3 99.1 91.9 98.1 98.7 98.9</cell></row><row><cell>ResNet-50 [18]  ? DeiT-S [53]  ? DINO [3]  ? ViT-S [48]  ?  ?</cell><cell cols="10">2048 41.2 53.8 66.3 77.5 41.4 53.6 66.1 76.6 50.6 66.7 80.7 93.0 25.8 49.1 56.4 60.5 384 70.6 81.3 88.7 93.5 52.8 65.1 76.2 85.3 58.3 73.9 85.9 95.4 37.9 64.7 72.1 75.9 384 70.8 81.1 88.8 93.5 42.9 53.9 64.2 74.4 63.4 78.1 88.3 96.0 46.1 71.1 77.5 81.1 384 83.1 90.4 94.4 96.5 47.8 60.2 72.2 82.6 62.1 77.7 89.0 96.8 43.2 70.2 76.7 80.5</cell></row><row><cell>Sph-DeiT Sph-DINO</cell><cell cols="10">384 76.2 84.5 90.2 94.3 81.7 88.6 93.4 96.2 82.5 92.9 97.2 99.1 89.6 97.2 98.0 98.4 384 78.7 86.7 91.4 94.9 86.6 91.8 95.2 97.4 82.2 92.1 96.8 98.9 90.1 97.1 98.0 98.4</cell></row><row><cell>Sph-ViT  ? Hyp-DeiT Hyp-DINO Hyp-ViT  ?</cell><cell cols="10">384 85.1 90.7 94.3 96.4 81.7 89.0 93.0 95.8 82.1 92.5 97.1 99.1 90.4 97.4 98.2 98.6 384 77.8 86.6 91.9 95.1 86.4 92.2 95.5 97.5 83.3 93.5 97.4 99.1 90.5 97.8 98.5 98.9 384 80.9 87.6 92.4 95.6 89.2 94.1 96.7 98.1 85.1 94.4 97.8 99.3 92.4 98.4 98.9 99.1 384 85.6 91.4 94.8 96.7 86.5 92.1 95.3 97.3 85.9 94.9 98.1 99.5 92.5 98.3 98.8 99.1</cell></row></table><note>Table 2. Recall@K metric for four datasets for 128-dimensional embeddings. The 6 versions of our method are listed in the bottom section, evaluated for head embeddings. "Sph-" are versions with hypersphere embeddings optimised using Dcos (Eq. (4)), "Hyp-" are versions with hyperbolic embeddings optimised using D hyp (Eq. (2)). "DeiT", "DINO" and "ViT" indicate type of pretraining for the vision transformer encoder. Margin, FastAP, MIC, XBM, NSoftmax are based on ResNet-50 [18] encoder, IRTR is based on DeiT [53].? pretrained on the larger ImageNet-21k [6].</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>First two rows represent current best overall result for Cars-196 dataset with ResNet-50 encoder. Our method (Hyp-DINO) is presented with 8 ? 8 and 16 ? 16 patch sizes.</figDesc><table><row><cell>Test</cell><cell></cell><cell></cell><cell>Train</cell><cell></cell></row><row><cell cols="5">Figure 2. Hyp-DINO embeddings for Cars-196 dataset (training</cell></row><row><cell cols="5">and evaluation sets) on the Poincar? disk. Each point inside the</cell></row><row><cell cols="5">disk corresponds to a sample, different colors indicate different</cell></row><row><cell cols="5">classes. Images of cars are plotted preserving neighborhood rela-</cell></row><row><cell>tions of samples.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Method</cell><cell>Dim</cell><cell>1</cell><cell>Recall@K 2 4</cell><cell>8</cell></row><row><cell cols="5">NSoftmax [64] ProxyNCA++ [52] 2048 90.1 94.5 97.0 98.4 2048 89.3 94.1 96.4 98.0</cell></row><row><cell cols="5">Hyp-DINO 16 ? 16 128 86.0 91.9 95.2 97.2 Hyp-DINO 8 ? 8 128 90.4 94.7 97.0 98.2 Hyp-DINO 16 ? 16 384 89.2 94.1 96.7 98.1 Hyp-DINO 8 ? 8 384 92.8 96.2 97.8 98.8</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgments. This work was supported by the EU H2020 AI4Media Project under Grant 951911, by the Analytical center under the RF Government (subsidy agreement 000000D730321P5Q0002, Grant No. 70-2021-00145 02.11.2021). We thank Google Cloud Platform (GCP) for providing computing support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A unifying mutual information view of metric learning: cross-entropy vs. pairwise losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Malik</forename><surname>Boudiaf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?r?me</forename><surname>Rony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Imtiaz Masud Ziko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Pedersoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Piantanida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ben Ayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="548" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep metric learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih</forename><surname>Cakir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xide</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Sclaroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1861" to="1870" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Emerging properties in self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="9650" to="9660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR, 2020. 2</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Beyond triplet loss: a deep quadruplet network for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaotang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianguo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="403" to="412" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">ImageNet: A Large-Scale Hierarchical Image Database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR09</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. ICLR, 2021</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Training vision transformers for image retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alaaeldin</forename><surname>El-Nouby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Neverova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.05644</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Kernel methods in hyperbolic spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrtash</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lars</forename><surname>Petersson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10665" to="10674" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Computing the Gromov hyperbolicity of a discrete metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>Fournier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anas</forename><surname>Ismail</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Vigneron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Information Processing Letters</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">6-8</biblScope>
			<biblScope unit="page" from="576" to="579" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Octavian-Eugen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gary</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>B?cigneul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hofmann</surname></persName>
		</author>
		<title level="m">Hyperbolic neural networks. Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5345" to="5355" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Curvature generation in curved spaces for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunde</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehrtash</forename><surname>Harandi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8691" to="8700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep metric learning with hierarchical triplet loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weifeng</forename><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="269" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neighbourhood components analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Russ</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>L. Saul, Y. Weiss, and L. Bottou</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhui</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yubei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.11472</idno>
		<title level="m">Free hyperbolic neural networks with limited radii</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Metric learning with horde: High-order regularizer for deep embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Jacob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Picard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aymeric</forename><surname>Histace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6539" to="6548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Jaegle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Borgeaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Baptiste</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Skanda</forename><surname>Koppula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.14795</idno>
		<title level="m">Perceiver io: A general architecture for structured inputs &amp; outputs</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hyperbolic image embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentin</forename><surname>Khrulkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leyla</forename><surname>Mirvakhabova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniya</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Oseledets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="6418" to="6428" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Proxy anchor loss for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minsu</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Suha</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Attention-based ensemble for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonsik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhavya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunal</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungmin</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keunjoo</forename><surname>Kwon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="736" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">3d object representations for fine-grained categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2013 IEEE International Conference on Computer Vision Workshops</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="554" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Hyperbolic visual embedding learning for zero-shot recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoteng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangming</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong-Wah</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Gang</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9273" to="9281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Sphereface: Deep hypersphere embedding for face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiyang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhiksha</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="212" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deepfashion: Powering robust clothes recognition and retrieval with rich annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Grover</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.05247</idno>
		<title level="m">Pieter Abbeel, and Igor Mordatch. Pretrained transformers as universal computation engines</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Umap: Uniform manifold approximation and projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leland</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Grossberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">29</biblScope>
			<biblScope unit="page">861</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="360" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A metric learning reality check</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Musgrave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ser-Nam</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="681" to="699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Poincar? embeddings for learning hierarchical representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximillian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6338" to="6347" />
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning continuous hierarchies in the lorentz model of hyperbolic geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maximillian</forename><surname>Nickel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3779" to="3788" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deep metric learning with bier: Boosting independent embeddings robustly</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Opitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Waltner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Possegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horst</forename><surname>Bischof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="276" to="290" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Softtriple loss: Deep metric learning without triplet sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baigui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6450" to="6458" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Transductive episodic-wise adaptive metric for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limeng</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yemin</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghong</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3603" to="3612" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning transferable visual models from natural language supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jong</forename><forename type="middle">Wook</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hallacy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pamela</forename><surname>Mishkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Clark</surname></persName>
		</author>
		<idno>PMLR, 2021. 8</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="8748" to="8763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Mic: Mining interclass characteristics for improved metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Biagio</forename><surname>Brattoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Ommer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8000" to="8009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>Imagenet large scale visual recognition challenge</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Low distortion delaunay embedding of trees in hyperbolic plane</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rik</forename><surname>Sarkar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on Graph Drawing</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="355" to="366" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Exact solutions to the nonlinear dynamics of learning in deep linear neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">M</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Surya</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04-14" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Facenet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Improved deep metric learning with multiclass n-pair loss objective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kihyuk</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2008" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun Oh</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">How to train your vit? data, augmentation, and regularization in vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Wightman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.10270</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Stochastic class-based hard example mining for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yumin</forename><surname>Suh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonsik</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7244" to="7252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Learning to compare: Relation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Flood</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongxin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1199" to="1208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Proxynca++: Revisiting and revitalizing proxy neighborhood component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Terrance</forename><surname>Eu Wern Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham W</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="10347" to="10357" />
		</imprint>
	</monogr>
	<note>PMLR, 2021. 1, 4, 6, 8</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A gyrovector space approach to hyperbolic geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><forename type="middle">Albert</forename><surname>Ungar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Synthesis Lectures on Mathematics and Statistics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="194" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhe</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<title level="m">Representation learning with contrastive predictive coding. arXiv e-prints</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">1807</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<idno>PMLR, 2020. 8</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="9929" to="9939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Multi-similarity loss with general pair weighting for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengke</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5022" to="5030" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Cross-batch memory for embedding learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="6388" to="6397" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Y. Weiss, B. Sch?lkopf, and J. Platt</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Caltech-UCSD Birds 200</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<idno>CNS-TR-2010-001</idno>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">4</biblScope>
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Sampling matters in deep embedding learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2840" to="2848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Joint detection and identification feature learning for person search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bochao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="3415" to="3424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao-Yu</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.12649</idno>
		<title level="m">Classification is a strong baseline for deep metric learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Improving the robustness of deep neural networks via stability training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ieee conference on computer vision and pattern recognition</title>
		<meeting>the ieee conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4480" to="4488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Umap: Uniform manifold approximation and projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leland</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Grossberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">29</biblScope>
			<biblScope unit="page">861</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="360" to="368" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
