<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Answering Any-hop Open-domain Questions with Iterative Document Reranking</title>
			</titleStmt>
			<publicationStmt>
				<publisher>Canada</publisher>
				<availability status="unknown"><p>Copyright Canada</p>
				</availability>
				<date type="published" when="2021-07-11">2021. July 11-15, 2021. July 11-15, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyu</forename><surname>Nie</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Ramamurthy</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Song</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Peking University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Siemens Corporate Technology</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Georgia Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Answering Any-hop Open-domain Questions with Iterative Document Reranking</title>
					</analytic>
					<monogr>
						<title level="m">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;21)</title>
						<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR &apos;21)						</meeting>
						<imprint>
							<publisher>Canada</publisher>
							<date type="published" when="2021-07-11">2021. July 11-15, 2021. July 11-15, 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3404835.3462853</idno>
					<note>Event, Canada. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/ 3404835.3462853 * Both authors contributed equally to this work. ACM ISBN 978-1-4503-8037-9/21/07. . . $15.00</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing approaches for open-domain question answering (QA) are typically designed for questions that require either single-hop or multi-hop reasoning, which make strong assumptions of the complexity of questions to be answered. Also, multi-step document retrieval often incurs higher number of relevant but non-supporting documents, which dampens the downstream noise-sensitive reader module for answer extraction. To address these challenges, we propose a unified QA framework to answer any-hop open-domain questions, which iteratively retrieves, reranks and filters documents, and adaptively determines when to stop the retrieval process. To improve the retrieval accuracy, we propose a graph-based reranking model that perform multi-document interaction as the core of our iterative reranking framework. Our method consistently achieves performance comparable to or better than the state-of-the-art on both single-hop and multi-hop open-domain QA datasets, including Natural Questions Open, SQuAD Open, and HotpotQA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>? Information systems ? Question answering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KEYWORDS</head><p>open-domain question answering; iterative document reranking; multi-document interaction</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Open-domain question answering (QA) requires a system to answer factoid questions using a large text corpus (e.g., Wikipedia or the Web) without any pre-defined knowledge schema. Most state-ofthe-art approaches for open-domain QA follow the retrieve-andread pipeline initiated by Chen et al. <ref type="bibr" target="#b2">[3]</ref>, using a retriever module to retrieve relevant documents, and then a reader module to extract answer from the retrieved documents. These approaches achieve prominent results on single-hop QA datasets such as SQuAD <ref type="bibr" target="#b28">[27]</ref>, whose questions can be answered using a single supporting document. However, they are inherently limited to answering simple questions and not able to handle multi-hop questions, which require the system to retrieve and reason over evidence scattered among multiple documents. In the task of open-domain multi-hop QA <ref type="bibr" target="#b42">[41]</ref>, the documents with the answer can have little lexical overlap with the question and thus are not directly retrievable. Take the question in <ref type="figure">Figure 1</ref> as an example, the last paragraph contains the correct answer but cannot be directly retrieved using TF-IDF. In this example, the single-hop TF-IDF retriever is not able to retrieve the last supporting paragraph since it has no lexical overlap with the question, but this paragraph contains the answer and plays a critical role in the reasoning chain.</p><p>Recent studies on multi-hop QA attempt to perform iterative retrievals to improve the answer recall of the retrieved documents. However, several challenges are not solved yet by existing multihop QA methods: 1) The iterative retrieval rapidly increases the total number of retrieved documents and introduces much noise to the downstream reader module for answer extraction. Typically, the downstream reader module is noise-sensitive, which works poorly when taking noisy documents as input or missing critical supporting documents with the answer <ref type="bibr" target="#b23">[23]</ref>. This requires the QA system to reduce relevant but non-supporting documents fed into the reader module. However, to answer open-domain multi-hop questions, it is necessary to iteratively retrieve documents to increase the overall recall of supporting documents. This dilemma poses a challenge for the retrieval phase of open-domain QA systems; 2) Existing multi-hop QA methods such as MUPPET <ref type="bibr" target="#b11">[11]</ref> and Multi-step Reasoner <ref type="bibr" target="#b3">[4]</ref> perform a fixed number of retrieval steps, which make strong assumptions on the complexity of open-domain questions and perform fixed number of retrieval steps. In real-world scenarios, open-domain questions may require different number of reasoning steps; 3) The relevance of each retrieved document to the question is independently considered. As exemplified in <ref type="figure">Figure 1</ref>, ABR stands for ALBERT-base reranker, which serves as a reference <ref type="figure">Figure 1</ref>: An example open-domain multi-hop question from the HotpotQA dev set, where the question has only partial clues to retrieve supporting documents. The first and fourth paragraphs are gold supporting documents, and the remaining two paragraphs are relevant but non-supporting documents. ABR stands for ALBERT-base reranker, which serves as a reference of the retrieval performance of existing multi-hop QA methods that independently consider the relevance of each document to the question. The ? and ? symbols mark whether the retriever correctly identifies the document as a supporting / non-supporting one. Below each symbol, we annotate the output of the corresponding retriever with regard to the document, where "positive" ("negative") means that the retriever classifies it as a supporting (non-supporting) document.</p><p>of the retrieval performance of existing multi-hop QA methods that independently consider the relevance of each document to the question. Without considering multiple retrieved documents as a whole, these methods can be easily biased to the lexical overlap between each document and the question, and incorrectly classify non-supporting documents as supporting evidence (such as the middle two non-supporting paragraphs in <ref type="figure">Figure 1</ref>, which have decent lexical overlap with the question) and vice versa (such as the bottom paragraph in <ref type="figure">Figure 1</ref>, which has no lexical overlap with the question but is a critical supporting document that contains the answer).</p><p>To address the challenges above, we introduce a unified QA framework for answering any-hop open-domain questions named Iterative Document Reranking (IDR). Our framework learns to iteratively retrieve documents with updated question, rerank and filter documents, and adaptively determine when to stop the retrieval process. In this way, our method can significantly reduce the noise introduced by multi-round retrievals and handle open-domain questions that require different number of reasoning steps. To avoid the bias of lexical overlap in identifying supporting documents, our framework considers the question and retrieved documents as a whole and models the multi-document interactions to improve the accuracy of classifying supporting documents.</p><p>As illustrated in <ref type="figure" target="#fig_2">Figure 2</ref>, our method constructs a document graph linked by shared entities to propagate information using a graph attention network (GAT). By leveraging the multi-document information, our reranking model has more knowledge to differentiate supporting documents from irrelevant documents. After initial retrieval, our method updates the question at every retrieval step with a text span extracted from the retrieved documents, and then use the updated question as query to retrieve complementary documents, which are added to the document graph for a new round of interaction. The reranking model is reused to score the documents again and filter the most irrelevant ones. The maintained high-quality shortlist of remaining documents are then fed into the Reader Module to determine whether the answer exists in them. If so, the retrieval process ends and the QA system delivers the answer span extracted by the Reader Module as the predicted answer. Otherwise, the retrieval process continues to the next hop.</p><p>Our contributions are summarized as follows: ? Noise control for iterative retrieval: We propose a novel QA method to iteratively retrieve, rerank and filter documents, and adaptively determine when to stop the retrieval process. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">OVERVIEW 2.1 Problem Definition</head><p>Given a factoid question, the task of open-domain question answering (QA) is to answer it using a large corpus which can have millions of documents (e.g., Wikipedia) or even billions (e.g., the Web). Let the corpus C = { 1 , 2 , . . . , | C | } consist of |C| documents as the basic retrieval units 1 . Each document can be viewed as a sequence of tokens</p><formula xml:id="formula_0">( ) 1 , ( ) 2 , . . . , ( ) | | .</formula><p>Formally, given a question , the task is to find a text span For open-domain multi-hop QA, the final documents with the answer are typically multiple hops away from the question, i.e., the system is required to find seed documents and subsequent supporting documents in order of a chain or directed graph to locate the final documents. The retrieved documents are usually connected via shared entities or semantic similarities, and the formed chain or directed graph of documents can be viewed as the reasoning process for answering the question.  Given an open-domain question, IDR iteratively retrieves, reranks and filters documents, and adaptively determines when to stop the retrieval process. After the initial retrieval, IDR updates the question with an extracted text span as a new query to retrieve more documents at every iteration. Once the retrieval is done, the final highest-scoring documents are fed into the downstream reader module for answer extraction.</p><p>Note that the task of open-domain multi-hop QA that we describe above is much different from the few-document setting of multihop QA <ref type="bibr" target="#b26">[25]</ref>, where the QA system is provided with a tiny set of documents that consists of all the gold supporting documents together with several irrelevant "distractor" documents. The fewdocument setting is designed to test the system's capability of multihop reasoning given all of the gold supporting documents, but this is far from being realistic. A real-world open-domain QA system has to locate the necessary supporting documents from a large corpus on its own, which is especially challenging for multi-hop questions since the indirect supporting documents are not easily retrievable given the question itself.</p><p>The nature of multi-hop questions poses significant challenge for retrieving supporting documents, which is crucial to the downstream QA performance. To address this challenge, we argue that it is necessary to iteratively retrieve, rerank and filter documents, so that we can maintain a high-quality shortlist of documents. To this end, we propose the Iterative Document Reranking (IDR) method, which is introduced in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">System Overview</head><p>We illustrate the overview of our IDRQA system in <ref type="figure" target="#fig_2">Figure 2</ref>. The IDRQA system first uses a given question as query to retrieve top |D | documents using TF-IDF. To construct the document graph, IDR extracts the entities from the question and retrieved documents using an off-the-shelf Named Entity Recognition (NER) system and connects two documents if they have shared entities. The graphbased reranking model takes the document graph as input to score each document, filter the lowest-scoring documents, and adaptively determines whether to continue the retrieval process. At every future retrieval step, IDR updates the question with an extracted text 13 return a span from the retrieved documents as a new query to retrieve more documents. Once the retrieval is done, the final highest-scoring documents are concatenated to feed into the downstream reader module <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b16">16]</ref> for answer extraction.</p><p>To describe the pipeline of our IDRQA system more precisely, we provide a concise algorithm that summarizes the inference procedure of the iterative document reranking (IDR) phase, as in Algorithm 1. We maintain a set of retrieved documents D. For each retrieval step, we retrieve the top documents according to the question and then append all the newly retrieved documents to the current set of retrieved documents. Then we use the graphbased reranking model M to rerank those documents, get top of them, and filter the other ones. This shortlist of retrieved documents together with the question are then fed in to the downstream reader module R for answer extraction. Note that the reader module has the option to predict that there is no answer to be extracted from the provided documents. If the reader module does predict no answer, we use the question updater model U to update the question with an extracted span and move to the next hop of retrieval. The while loop continues until a valid answer is extracted by the reader module or the maximum number of retrieval hops H is reached.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">IDRQA SYSTEM 3.1 Graph-based Reranking Model</head><p>The graph-based reranking model ( <ref type="figure">Figure 3</ref>) is designed to precisely identify the supporting documents in the document graph. We present the components of this reranking model as follows.</p><p>Contextual Encoding. Given a question and |D| documents retrieved by TF-IDF, we concatenate the tokens of the question and each document to feed into the pre-trained language model as:</p><formula xml:id="formula_1">I , = [CLS] 1 . . . | | [SEP] ( ) 1 . . . ( ) | | [SEP],</formula><p>where | | and | | denote the number of tokens in the question and the document , respectively.</p><p>[CLS] and [SEP] are special tokens used in pre-trained language models such as BERT <ref type="bibr" target="#b6">[7]</ref> and ALBERT <ref type="bibr" target="#b16">[16]</ref>. Thus we independently encode each document along with the question to obtain the contextual representation vector v , ? R ?? , where is the maximum length of the input tokens I, and ? is the embedding size. For efficient batch computation, we pad or truncate the input tokens to the length of . We then concatenate all documents' contextual representation vectors as v ? R | D |?? .</p><p>Graph Attention. After we obtain the question-dependent encoding of each document, we employ a Graph Attention Network (GAT; Veli?kovi? et al. <ref type="bibr" target="#b32">[31]</ref>) to propagate information on the document graph, where two documents are connected if they have shared entities. To be more specific, for each shared entity in the document graph, we perform pooling over its token embeddings from v to produce the entity embedding as e = Pooling t ( )</p><formula xml:id="formula_2">1 , t ( ) 2 , . . . , t ( ) | | where t ( )</formula><p>is the embedding of the -th token in , and | | is the number of tokens in . We use both mean-and max-pooling, thus we have e ? R 2? . Inspired by Qiu et al. <ref type="bibr" target="#b27">[26]</ref>, we apply a dynamic soft mask on the entities, serving as the information "gatekeeper" which assigns more weights to entities pertaining to the question. The soft mask applied on each entity is computed as</p><formula xml:id="formula_3">= q e ? 2?</formula><p>(1)</p><formula xml:id="formula_4">g = e ,<label>(2)</label></formula><p>where q ? R 2? is the concatenated mean-and max-pooling of the question token embeddings, and ? R 2??2? is a linear projection matrix, (?) is the sigmoid function, and g is the masked entity embedding. We then use GAT to disseminate information between entities. Starting from g (0) = g , GAT iteratively updates the embedding of each entity with the information from its neighbors as</p><formula xml:id="formula_5">h ( ) = g ( ?1) + (3) g ( ) = ReLU( ?? ? ( ) ( ) , h ( ) ),<label>(4)</label></formula><p>where h ( ) denotes the hidden states of on the -th GAT layer, <ref type="bibr" target="#b0">1</ref> ? R ??2? is a linear projection matrix, is a bias term, ( ) is the set of neighbor entities of , and the entity-entity attention <ref type="bibr">( )</ref> , is computed as follows:</p><formula xml:id="formula_6">( ) , = LeakyReLU( 2 [h ( ) ; h ( ) ]) (5) ( ) , = exp( ( ) , ) exp( ( ) , ) ,<label>(6)</label></formula><p>where 2 ? R 2? is a linear projection matrix. We finally obtain the GAT updated entity embeddings g ( ) , where is the number of GAT layers.</p><p>Multi-document Fusion. To further propagate the information to non-entity tokens, we firs use the embedding of each entity token ast</p><formula xml:id="formula_7">( ) = 3 t ( ) ; g ( ) ,<label>(7)</label></formula><p>where 3 ? R ??3? is a linear projection matrix. Then we replace the corresponding vectors in v witht</p><formula xml:id="formula_8">( ) to obtainv ? R | D |?? .</formula><p>Finally,v is fed into a Transformer <ref type="bibr" target="#b31">[30]</ref> layer for multi-document fusion, which updates the representations of all the tokens and outputs the fused representation vectors? ? R | D |?? .</p><p>Document Filter. For each document, we use the [CLS] token embedding from? as the document representation, which is fed into a binary classifier to score the document's supporting level. In each retrieval hop, the top documents with the highest scores are selected and the rest are filtered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Question Updater</head><p>In open-domain multi-hop QA, the question seldom contains all the retrievable clues and one has to identify the missing information to proceed with further reasoning <ref type="bibr" target="#b42">[41]</ref>. To increase the recall of indirect supporting documents, we integrate the query generator of GoldEn Retriever <ref type="bibr" target="#b26">[25]</ref> into our system, which serves as the question updater at every retrieval step after the initial one. Question Updater comes after Reader module if no answer was found in top documents. It aims to generate the clue span other than the answer span from the reranked top documents given current question . Thus conceptually, this process is similar to the Reader Module which extracts answer span from retrieved documents. More specifically, following GoldEn Retriever <ref type="bibr" target="#b26">[25]</ref>, we use the same method for data construction to train a span extractor model, which extracts the clue span from retrieved documents by predicting its start and end tokens. Formally, given the question and the reranked top documents D = { 1 , 2 , . . . , }, the  <ref type="figure">Figure 3</ref>: As the core of our IDR framework, the Graph-based Reranking Model first encodes the question and each retrieved document with pre-trained language model to generate contextual representations, and uses the shared entities to propagate information using a Graph Attention Network (GAT). After the entity-entity interaction across multiple documents, the updated entity representations with the original contextual encodings are fed into the fusion layer for further interaction. Finally, the reranking model takes pooled document representations to score each document and filter low-scoring documents. The maintained high-quality shortlist of remaining documents are then fed into the Reader Module to determine whether the answer exists in them. If so, the retrieval process ends and the QA system delivers the answer span extracted by the Reader Module as the predicted answer. Otherwise, the retrieval process continues to the next hop.</p><formula xml:id="formula_9">+ Document Graph ??? Q ??? ??? Q ??? ! ??? Q ??? " ??? Pre-trained</formula><p>Question Updater generates the clue span and concatenate with the original question as</p><formula xml:id="formula_10">= U ( , D ) (8) = concatenate( , [SEP], ),<label>(9)</label></formula><p>where [SEP] is a special separator token. In order to train the Question Updater, we construct each training sample as a triple of &lt; , D , &gt;, where is the question, D = { 1 , 2 , . . . , } is the set of top retrieved documents reranked by our graph-based reranking model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Reader Module</head><p>In this work, we mainly focus on the retrieval phase, and use a standard span-based reader module as in BERT <ref type="bibr" target="#b6">[7]</ref> and ALBERT <ref type="bibr" target="#b16">[16]</ref>.</p><p>We concatenate the tokens of the question and the final top reranked documents to feed into the reader module. At inference time, the reader finds the best candidate answer span by arg max , , ? start end ,</p><p>where start , end denote the probability that the -th and -th tokens are the start and end positions in the concatenated text, respectively, of the answer span. During inference, there is no guarantee that the answer span exists in the reader's input text. To handle the no-answer cases, the reader predicts as the probability of having no answer span, and compares with max , , ? start end to determine the output between a special no-answer prediction and the best candidate answer span.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS 4.1 Experimental Settings</head><p>We conduct all the experiments on a GPU-enabled (Nvidia RTX 6000) Linux machine powered by Intel Xeon Gold 5125 CPU at 2.50GHz with 384 GB RAM. For the graph-based reranking model, we set the maximum token sequence length = 250, the number of retrieved documents |D| = 8, the maximum number of entities |E | = 120. The embedding size ? is 768 and 4, 096 for the ALBERTbase and ALBERT-xxlarge model, respectively. The graph attention module has = 2 GAT layers. The maximum number of retrieval hops H = 4. The top = 4 reranked paragraphs are sent into the downstream reader module. We implement our system based on HuggingFace's Transformers <ref type="bibr" target="#b38">[37]</ref>. Following the previous state-of-the-art method <ref type="bibr" target="#b10">[10]</ref>, we use ALBERT-xxlarge <ref type="bibr" target="#b16">[16]</ref> as the pre-trained language model. We use AdamW <ref type="bibr" target="#b38">[37]</ref> as the optimizer and tune the initial learning rate between 1.5e?5 and 2.5e?5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Datasets</head><p>We evaluate our method on three open-domain QA benchmark datasets: HotpotQA <ref type="bibr" target="#b42">[41]</ref>, Natural Questions Open <ref type="bibr" target="#b17">[17]</ref> and SQuAD Open <ref type="bibr" target="#b2">[3]</ref>. On all the three datasets, we focus on the full wiki opendomain QA setting, which requires the system to retrieve evidence paragraphs from the entire Wikipedia and extract the answer span from the retrieved paragraphs.</p><p>Following the train / dev / test splits of Natural Questions Open and SQuAD Open in previous works <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b17">17]</ref>, we use the original validation set as our test set and keep 10% training set as our dev set. Natural Questions Open and SQuAD open consist of single-hop questions, while HotpotQA consists of 113K crowd-sourced multihop questions that require Wikipedia introduction paragraphs to answer. In the train and dev splits of HotpotQA, each question for training comes with two gold supporting paragraphs annotated by the crowd workers. Thus we can evaluate the retrieval performance on the dev set of HotpotQA dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Data Preprocessing</head><p>Here we describe the details of data preprocessing methods that we develop for the HotpotQA dataset.</p><p>Training data construction for the graph-based reranking model. Graph-based reranking model aims to precisely score the retrieved documents by considering multiple documents as a whole instead of independent instances. In order to make our model reusable and robust to new test cases, we carefully design the training data construction method. To keep the distribution of training and test data consistent, we add negative samples to the training data for our graph-based reranking model. Formally, We pair each question with a set of documents D train to form a training sample. We design each training sample with the following strategies: 1) For each training sample which contains all supporting documents, we pair the question with D train where D train includes all supporting documents necessary for multi-hop QA and |D train | ? noisy documents. D train is a set of documents in training.</p><p>, are the number of noisy documents and the number of supporting documents; 2) For each training sample which contains partial supporting documents, we paired question with D train where D train contains supporting documents and |D train |? noisy documents.</p><p>supporting documents are randomly sampled from all supporting documents; 3) For noisy documents, we sample them according to their score given by TF-IDF; 4) For multi-step reranking, we also randomly sample 30% questions and use Question Updater to generate the clue span and update questions. These new questions and their original paired documents are also used as training samples; 5) We concatenate all documents in D train in random order, rather than the reranked order. We use |D train | = 6 and = 2 in our experiments.</p><p>Training data construction for the reader module. We designed the training data for the Reader Module carefully since the Reader module is not only used to predict the final answer but also to tell that no answer found in in current context. The training sample is a triple of &lt; , D, &gt; where is question, D = { 1 , 2 , 3 , 4 } is 4 documents feed into QA model and is the final answer. For each question, we construct 5 types of training sample: 1) We concatenate two supporting passages (ordered as originally in the dataset) and two highest TF-IDF scored negative passages (ordered from higher to lower reranking score) as training samples; 2) We construct a random shuffled version of the 1st type in passage level; 3) We randomly replace one of the supporting passages of the 1st type by a negative passage; 4) One passage which has the final answer and is not one of the supporting passage and three negative passages; 5) We construct four negative passages with high TF-IDF score which are not supporting passages and do not contain the final answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation Metrics</head><p>We evaluate both the paragraph reranking performance and the overall QA performance. Following the existing studies <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b24">24]</ref>, we evaluate the paragraph-level retrieval accuracy using the Paragraph Exact Match (EM) metric, which compares the top 2 paragraphs with the gold supporting paragraphs. For the QA performance, we report standard answer Exact Match (EM) and F 1 scores to measure the overlap between the gold answer and the extracted answer span.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Overall Results</head><p>We evaluate our method on both single-hop and multi-hop opendomain QA datasets. Note that our method is hop-agnostic, i.e., we consistently use the same setting of H = 4 as the maximum number of retrieval hops for all the three datasets. For the multi-hop QA task, we report performance on both the dev and test sets of the HotpotQA dataset. As reported in <ref type="table" target="#tab_2">Table 1</ref>, we compare the performance of our system IDRQA with various existing methods on the HotpotQA full wiki dev set. Since the golden supporting paragraphs are only labeled on the train / dev splits of the HotpotQA dataset, we can only report the paragraph EM metric on the dev set. In <ref type="table" target="#tab_3">Table 2</ref>, we compare our system with various existing methods on HotpotQA full wiki test set. IDRQA outperforms all published and previous unpublished methods on the HotpotQA dev set and the hidden test set on the official leaderboard (on May 21, 2020). Note that we focus on the QA task in this paper, and for the supporting fact prediction task we simply concatenate each pair of question and supporting fact to train a binary classification model. The joint EM and F 1 scores combine the evaluation of answer spans and supporting facts as detailed in <ref type="bibr" target="#b42">[41]</ref>. Thus we are behind state-of-the-art performance on supporting fact and joint scores.</p><p>For the single-hop QA task, we evaluate our method on Natural Questions (NQ) Open and SQuAD Open datasets. We summarize the performance in <ref type="table" target="#tab_4">Table 3</ref>. For NQ Open, we follow the previous work DPR <ref type="bibr" target="#b14">[14]</ref> to use dense retriever instead of TF-IDF for document retrieval. Our method also achieves QA performance comparable to or better than the state-of-the-art methods on both datasets, which   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Detailed Analysis</head><p>Ablation study. To investigate the effectiveness of each module in IDRQA, we compare the performance of several variants of our system on HotpotQA full wiki dev set. As shown in <ref type="table" target="#tab_6">Table 4</ref>, once we disable the Iterative Reranking, Graph-based Reranking and Question Updater module, both the paragraph reranking and QA performance drop significantly. Notably, there is a 11 points drop in Paragraph EM decrease and a 12 points drop in Answer F 1 when Graph-based Reranking is removed from IDRQA. This shows the importance of the graph-based reranking model in our system. To further study the impact of these modules, we decompose the QA performance into question categories Bridge and Comparison. We find that the QA performance on the bridge questions drops much more significantly than that on the comparison questions. This is because the comparison questions require to compare two entities mentioned in the question <ref type="bibr" target="#b42">[41]</ref>, thus iterative retrieval and multihop reasoning may not be necessary. In contrast, to answer the bridge questions which often have missing entities, our iterative graph-based document reranking method is of crucial importance.   Impact of retrieval steps. IDRQA aggregates the document scores to check whether the collected evidence is enough to answer the question, and adaptively determines when to stop the retrieval process. We investigate the number of retrieval steps selected by IDRQA, and report its distribution with breakdown performance in <ref type="table" target="#tab_7">Table 5</ref>. Over 60% questions are answered with 2-step retrieval. About 20% questions are answered with 1-step retrieval, which is close to the ratio of the comparison questions that may not need iterative retrieval. For questions that IDRQA selects to perform over 2-step retrieval, a significant drop on both reranking and QA performance is observed, showing that these questions are the hardest ones in HotpotQA.</p><p>Case study and limitations. We showcase several example questions with answers from IDRQA and the baseline ALBERT-base reranker (ABR) in <ref type="figure" target="#fig_4">Figure 4</ref>. The first case is a hard bridge question where ABR extracts the wrong answer from a relevant but nonsupporting paragraph, showing the advantage of iterative reranking in our system. The second question is correctly answered by both IDRQA and ABR, since it provides sufficient clues to retrieve both paragraphs. The final case is a comparison question that requires numerical reasoning, which is not correctly answered by both IDRQA and ABR. This shows the limitation of our system, and we plan to explore the combination of multi-hop and numerical reasoning in future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">RELATED WORK</head><p>Open-domain QA. For text-based QA, the QA system is provided with semi-structured or unstructured text corpora as the knowledge source to find the answer. Text-based QA dates back to the QA track evaluations of the Text REtrieval Conference (TREC) <ref type="bibr" target="#b33">[32]</ref>. Traditional approaches for text-based QA typically use a pipeline of question parsing, answer type classification, document retrieval, answer candidate generation, and answer reranking, such as the famous IBM Watson system which beat human players on the Jeopardy! quiz show <ref type="bibr" target="#b12">[12]</ref>. However, such pipeline-based QA systems require heavy engineering efforts and only work on specific domains. The open-domain QA task was originally proposed and formalized in Chen et al. <ref type="bibr" target="#b2">[3]</ref>, which builds a simple pipeline with a TF-IDF retriever module and a RNN-based reader module to produce answers from the top 5 retrieved documents. Different from the machine reading comprehension task (MRC) that provides a single paragraph or document as the evidence <ref type="bibr" target="#b28">[27]</ref>, open-domain QA is more challenging since the retrieved documents are inevitably noisy.</p><p>Recent works on open-domain QA largely follow the retrieveand-read approach, and have made prominent improvement on both the retriever module <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b35">34]</ref> and the reader module <ref type="bibr" target="#b22">[22,</ref><ref type="bibr" target="#b34">33,</ref><ref type="bibr" target="#b36">35]</ref>.</p><p>These approaches simply perform one-shot document retrieval to handle single-hop questions. However, for complicated questions that require multi-hop reasoning, these approaches are not applicable since they fail to collect necessary evidence scattered among multiple documents.  <ref type="bibr" target="#b7">[8]</ref> and Transformer-XH <ref type="bibr" target="#b44">[43]</ref> employ the entities in the question and the retrieved documents to link additional documents, which expands the one-shot retrieval results and improves the evidence coverage. GoldEn Retriever <ref type="bibr" target="#b26">[25]</ref> adopts iterative TF-IDF retrieval by generating a new query for each retrieval step. Graph Retriever <ref type="bibr" target="#b20">[20]</ref> employs entity linking to iteratively retrieve and construct a graph of documents. These iterative retrieval methods mitigate the recall problem of one-shot retrieval, however, without iterative reranking and filtering process, the expanded documents inevitably introduce noise to the downstream QA model. Multi-step Reasoner <ref type="bibr" target="#b3">[4]</ref> and MUPPET <ref type="bibr" target="#b11">[11]</ref> read retrieved documents to reformulate the query in latent space for iterative retrieval. However, these embedding-based retrieval methods have difficulties to capture the lexical information in entities due to the compression of information into embedding space. Moreover, these methods perform a fixed number of retrieval steps, which are not able to handle questions that require arbitrary hops of reasoning. Recurrent Retriever [1] supports adaptive retrieval steps, but can only select one document at each step and has no interactions among documents outside of the retrieval chain. In contrast, our method leverages document graph instead of chain to propagate information, reranks and filters documents at each hop of retrieval, and terminates the retrieval process according to the number of positive retrieved documents in the graph.</p><p>Graph Neural Networks for QA. Encouraged by the success of convolutional neural networks (CNNs) and recurrent neural networks (RNNs), graph neural networks (GNNs) are proposed to generalize both of them and organize the connections of neurons according to the structure of the input data <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b39">38]</ref>. The main idea is to generate a node's representation by aggregating its own features and neighbors' features. Similar to CNNs, in GNNs, multiple graph convolutional layers can be stacked to produce high-level node representations. Many popular variants of GNNs are proposed, such as GraphSage <ref type="bibr" target="#b13">[13]</ref>, Graph Convolutional Network (GCN) <ref type="bibr" target="#b15">[15]</ref>, Graph Attention Network (GAT) <ref type="bibr" target="#b32">[31]</ref>, etc. GNNs have achieved great success on graph-related tasks such as node classification, node regression and graph classification. Recently, Graph neural networks (GNNs) have been shown effective on knowledge-based QA tasks by reasoning over graphs <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b29">28,</ref><ref type="bibr" target="#b43">42]</ref>. Recent studies on text-based QA also leverage GNNs for multi-hop reasoning. HDE-Graph <ref type="bibr" target="#b30">[29]</ref> constructs the graph with entity and document nodes to enable rich information interaction. CogQA <ref type="bibr" target="#b8">[9]</ref> extracts candidate answer spans and next-hop entities to build the cognitive graph for reasoning. HGN <ref type="bibr" target="#b18">[18]</ref> employs a hierarchical graph that consists of paragraph, sentence and entity nodes for reasoning on different granularities. DFGN <ref type="bibr" target="#b27">[26]</ref> introduces a fusion layer on top of the entity graph with a mask prediction module. Graph Retriever <ref type="bibr" target="#b20">[20]</ref> uses graph convolution network to fuse information on the entitylinked graph of passages. Multi-grained MRC <ref type="bibr" target="#b45">[44]</ref> utilizes GATs to obtain different levels of representations of documents for machine reading comprehension. These GNN-based methods serve as the reader module to extract answers from a few documents. In contrast, our work employs graph attention network, a popular GNN variant, in the retriever module. To the best of our knowledge, we are the first to propose GNN-based document reranking method for open-domain multi-hop QA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We present a QA framework that can answer any-hop open-domain questions, which iteratively retrieves, reranks and filters documents with a graph-based reranking model, and adaptively decides how many steps of retrieval and reranking are needed for a multi-hop question. Our method consistently achieves promising performance on both single-and multi-hop open-domain QA datasets.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>one of the documents that can answer the question 2 .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>An overview of the IDRQA system, which consists of an Iterative Document Reranking (IDR) phase and a question answering phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Algorithm 1 : 4 ? ? ? + 1 5 D 6 D ? D ? D new 7 D? 8 ?</head><label>145678</label><figDesc>Iterative Document Reranking (inference) input : A textual question ; the maximum number of retrieval hops H ; the number of retrieved documents at each hop ; the number of remaining documents after each reranking process ; the graph-based reranking model M; the reader module R; the question updater model U output : Predicted answer 1 ? ? 0 2 D ? ? 3 while ? &lt;= H do new ? Retrieve top documents according to Rerank and get top documents using M ( , D) Predict the answer using R ( , D) 9 if is not None then /* No more hop needed *</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Case study of example questions with supporting paragraphs from HotpotQA dev set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Performance on the HotpotQA full wiki dev set.</figDesc><table><row><cell>Method</cell><cell>Answer</cell><cell></cell><cell cols="2">Supporting Fact</cell><cell>Paragraph</cell></row><row><cell></cell><cell>EM</cell><cell>F 1</cell><cell>EM</cell><cell>F 1</cell><cell>EM</cell></row><row><cell>Cognitive Graph [9]</cell><cell>37.6</cell><cell>49.4</cell><cell>23.1</cell><cell>58.5</cell><cell>57.8</cell></row><row><cell>DecompRC [21]</cell><cell>-</cell><cell>43.3</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MUPPET [11]</cell><cell>31.1</cell><cell>40.4</cell><cell>17.0</cell><cell>47.7</cell><cell></cell></row><row><cell>GoldEn Retriever [25]</cell><cell>-</cell><cell>49.7</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>DrKIT [8]</cell><cell>35.7</cell><cell>46.6</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Semantic Retrieval MRS [23]</cell><cell>46.5</cell><cell>58.8</cell><cell>39.9</cell><cell>71.5</cell><cell>63.9</cell></row><row><cell>Transformer-XH [43]</cell><cell>50.2</cell><cell>62.4</cell><cell>42.2</cell><cell>71.6</cell><cell>-</cell></row><row><cell>Recurrent Retriever [1]</cell><cell>60.5</cell><cell>73.3</cell><cell>49.3</cell><cell>76.1</cell><cell>75.7</cell></row><row><cell>HopRetriever [19]</cell><cell>62.1</cell><cell>75.2</cell><cell>52.5</cell><cell>78.9</cell><cell>82.5</cell></row><row><cell>IDRQA (ours)</cell><cell>62.9</cell><cell>75.9</cell><cell>51.3</cell><cell>79.1</cell><cell>79.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Performance on the HotpotQA full wiki test set.</figDesc><table><row><cell>Method</cell><cell cols="2">Answer</cell><cell cols="2">Supporting Fact</cell><cell>Joint</cell><cell></cell></row><row><cell></cell><cell>EM</cell><cell>F 1</cell><cell>EM</cell><cell>F 1</cell><cell>EM</cell><cell>F 1</cell></row><row><cell>DecompRC [21]</cell><cell>30.0</cell><cell>40.6</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>QFE [24]</cell><cell>28.6</cell><cell>38.0</cell><cell>14.2</cell><cell>44.3</cell><cell>8.6</cell><cell>23.1</cell></row><row><cell>Cognitive Graph [9]</cell><cell>37.1</cell><cell>48.8</cell><cell>22.8</cell><cell>57.6</cell><cell>12.4</cell><cell>34.9</cell></row><row><cell>MUPPET [11]</cell><cell>30.6</cell><cell>40.2</cell><cell>16.6</cell><cell>47.3</cell><cell>10.8</cell><cell>27.0</cell></row><row><cell>GoldEn Retriever [25]</cell><cell>37.9</cell><cell>48.5</cell><cell>30.6</cell><cell>64.2</cell><cell>18.0</cell><cell>39.1</cell></row><row><cell>DrKIT [8]</cell><cell>42.1</cell><cell>51.7</cell><cell>37.0</cell><cell>59.8</cell><cell>24.6</cell><cell>42.8</cell></row><row><cell>Semantic Retrieval MRS [23]</cell><cell>45.3</cell><cell>57.3</cell><cell>38.6</cell><cell>70.8</cell><cell>25.1</cell><cell>47.6</cell></row><row><cell>Transformer-XH [43]</cell><cell>51.6</cell><cell>64.0</cell><cell>40.9</cell><cell>71.4</cell><cell>26.1</cell><cell>51.2</cell></row><row><cell>Recurrent Retriever [1]</cell><cell>60.0</cell><cell>73.0</cell><cell>49.0</cell><cell>76.4</cell><cell>35.3</cell><cell>61.1</cell></row><row><cell>Hierarchical Graph Network [10]</cell><cell>59.7</cell><cell>71.4</cell><cell>51.0</cell><cell>77.4</cell><cell>37.9</cell><cell>62.2</cell></row><row><cell>HopRetriever [19]</cell><cell>60.8</cell><cell>73.9</cell><cell>53.1</cell><cell>79.3</cell><cell>38.0</cell><cell>63.9</cell></row><row><cell>Multi-hop Dense Retrieval [39]</cell><cell>62.3</cell><cell>75.3</cell><cell>57.5</cell><cell>80.9</cell><cell>41.8</cell><cell>66.6</cell></row><row><cell>IDRQA (ours)</cell><cell>62.5</cell><cell>75.9</cell><cell>51.0</cell><cell>78.9</cell><cell>36.0</cell><cell>63.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Answer EM scores on the test set of Natural Questions Open and SQuAD Open.</figDesc><table><row><cell>Method</cell><cell>NQ</cell><cell>SQuAD</cell></row><row><cell>DrQA [3]</cell><cell>-</cell><cell>29.8</cell></row><row><cell>R 3 [34]</cell><cell>-</cell><cell>29.1</cell></row><row><cell>Multi-step Reasoner [4]</cell><cell>-</cell><cell>31.9</cell></row><row><cell>BERTserini [40]</cell><cell>-</cell><cell>38.6</cell></row><row><cell>MUPPET [11]</cell><cell>-</cell><cell>39.3</cell></row><row><cell>Multi-passage BERT [36]</cell><cell>-</cell><cell>53.0</cell></row><row><cell>ORQA [17]</cell><cell>33.3</cell><cell>20.2</cell></row><row><cell>Recurrent Retriever [1]</cell><cell>31.7</cell><cell>56.5</cell></row><row><cell>Dense Passage Retriever [14]</cell><cell>41.5</cell><cell>36.7</cell></row><row><cell>IDRQA (ours)</cell><cell>45.5</cell><cell>56.6</cell></row><row><cell cols="3">shows the robustness of our method across different open-domain</cell></row><row><cell>QA datasets.</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Bridge: In what year was the actress who was starred in "Streak" with Rumer Willis born? Supporting Streak is a 2008 American ? film directed by Demi Moore, ? and starring Brittany Snow and Rumer Willis? Yes Sorority Row is a 2009 American slasher film ? starring Briana Evigan, Leah Pipes, Rumer Willis, ? No Brittany Anne Snow (born March 9, 1986) is an American actress, producer, and singer. Yes</figDesc><table><row><cell>IDRQA answer: 1986 ?</cell><cell>ABR answer: 2009 ?</cell></row><row><cell cols="3">Bridge: What screenwriter with credits for "Evolution" co-wrote a film starring Nicolas Cage and T?a Leoni? Supporting</cell></row><row><cell cols="2">David Weissman is a screenwriter and director. His film credits include "The Family Man" (2000), "Evolution" (2001), and "When in Rome" (2010).</cell><cell>Yes</cell></row><row><cell cols="2">The Family Man is a 2000 American romantic comedy-drama film directed by Brett Ratner, written by David Diamond and David Weissman, and starring Nicolas Cage and T?a Leoni.</cell><cell>Yes</cell></row><row><cell>IDRQA answer: David Weissman ?</cell><cell>ABR answer: David Weissman ?</cell></row><row><cell>Comparison: Who is older, Annie Morton or Terry Richardson?</cell><cell></cell><cell>Supporting</cell></row><row><cell cols="2">Annie Morton (born October 8, 1970) is an American model born in Pennsylvania?</cell><cell>Yes</cell></row><row><cell cols="2">Terrence "Uncle Terry" Richardson (born August 14, 1965) is an American fashion and portrait photographer?</cell><cell>Yes</cell></row><row><cell>IDRQA answer: Annie Morton ?</cell><cell>ABR answer: Annie Morton ?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Ablation study of our system in different settings on HotpotQA full wiki dev set.</figDesc><table><row><cell></cell><cell cols="2">Bridge (79.9%)</cell><cell cols="2">Comparison (20.1%)</cell><cell></cell><cell cols="2">Full Dev (100%)</cell></row><row><cell>Ablation Setting</cell><cell cols="2">Answer</cell><cell></cell><cell>Answer</cell><cell cols="2">Answer</cell><cell>Paragraph</cell></row><row><cell></cell><cell>EM</cell><cell>F 1</cell><cell>EM</cell><cell>F 1</cell><cell>EM</cell><cell>F 1</cell><cell>EM</cell></row><row><cell>IDRQA</cell><cell>58.1</cell><cell>73.2</cell><cell>71.4</cell><cell>77.9</cell><cell>60.7</cell><cell>74.2</cell><cell>73.8</cell></row><row><cell>w/o Graph-based Reranking</cell><cell>47.4</cell><cell>59.5</cell><cell>70.1</cell><cell>76.4</cell><cell>52.1</cell><cell>62.9</cell><cell>62.6</cell></row><row><cell>w/o Iterative Reranking</cell><cell>49.8</cell><cell>61.7</cell><cell>70.5</cell><cell>77.3</cell><cell>54.3</cell><cell>64.5</cell><cell>65.2</cell></row><row><cell>w/o Question Updater</cell><cell>56.6</cell><cell>71.4</cell><cell>71.3</cell><cell>77.8</cell><cell>59.8</cell><cell>72.9</cell><cell>70.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>Distribution of the selected retrieval steps on Hot-potQA dev set, which is adaptively determined by IDRQA.</figDesc><table><row><cell>Retrieval</cell><cell>% of Questions</cell><cell>Paragraph</cell><cell cols="2">Answer</cell></row><row><cell></cell><cell></cell><cell>EM</cell><cell>EM</cell><cell>F 1</cell></row><row><cell>1-step</cell><cell>21.8</cell><cell>88.4</cell><cell cols="2">70.3 81.9</cell></row><row><cell>2-step</cell><cell>63.2</cell><cell>76.9</cell><cell cols="2">62.0 75.9</cell></row><row><cell>3-step</cell><cell>5.3</cell><cell>39.6</cell><cell cols="2">45.2 59.8</cell></row><row><cell>4-step (max)</cell><cell>9.7</cell><cell>22.0</cell><cell cols="2">37.7 50.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Open-domain multi-hop QA. HotpotQA<ref type="bibr" target="#b42">[41]</ref> is crowd-sourced over Wikipedia as the largest free-form dataset for open-domain multi-hop QA to date. Recently, a variety of approaches have been proposed to address the multi-hop challenge. DecompRC<ref type="bibr" target="#b21">[21]</ref> decomposes a multi-hop question into simpler sub-questions and leverages single-hop QA models to answer it, which still uses one-shot TF-IDF retrieval to collect relevant documents. BERT Reranker<ref type="bibr" target="#b4">[5]</ref>, DrKIT</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We use the natural paragraphs as the basic retrieval units.<ref type="bibr" target="#b1">2</ref> In this work, we focus on the extractive or span-based QA setting, but the problem definition and our proposed method can be generalized to other QA settings as well.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning to Retrieve Reasoning Paths over Wikipedia Graph for Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><forename type="middle">B</forename><surname>Battaglia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Hamrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alvaro</forename><surname>Bapst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinicius</forename><surname>Sanchez-Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Zambaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Malinowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Tacchetti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Raposo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryan</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Faulkner</surname></persName>
		</author>
		<title level="m">Relational inductive biases, deep learning, and graph networks. arXiv</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Reading Wikipedia to Answer Open-Domain Questions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1870" to="1879" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multi-step Retriever-Reader Interaction for Scalable Open-domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shehzaad</forename><surname>Dhuliawala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Multi-step Entity-centric Information Retrieval for Multi-Hop Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajarshi</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameya</forename><surname>Godbole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Kavarthapu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyu</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2nd Workshop on Machine Reading for Question Answering. Hong Kong</title>
		<meeting>the 2nd Workshop on Machine Reading for Question Answering. Hong Kong<address><addrLine>China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="118" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Question Answering by Reasoning Across Documents with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilker</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2306" to="2317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Differentiable Reasoning over a Virtual Knowledge Base</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bhuwan</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manzil</forename><surname>Zaheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vidhisha</forename><surname>Balachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Cognitive Graph for Multi-Hop Reading Comprehension at Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th</title>
		<meeting>the 57th</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="2694" to="2703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Hierarchical Graph Network for Multi-hop Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8823" to="8838" />
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Multi-Hop Paragraph Retrieval for Open-Domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2296" to="2309" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Building Watson: An overview of the DeepQA project</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Ferrucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gondek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">A</forename><surname>Kalyanpur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lally</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Murdock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nyberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Prager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AI magazine</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="59" to="79" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Will</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhitao</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1024" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>O?uz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04906</idno>
		<title level="m">Dense Passage Retrieval for Open-Domain Question Answering</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Semi-Supervised Classification with Graph Convolutional Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=SJU4ayYgl" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 5th International Conference on Learning Representations (Palais des Congr?s Neptune</title>
		<meeting>the 5th International Conference on Learning Representations (Palais des Congr?s Neptune<address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Latent Retrieval for Weakly Supervised Open Domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6086" to="6096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hierarchical Representation Learning for Bipartite Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunyang</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</title>
		<meeting>the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. International Joint Conferences on Artificial Intelligence Organization</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaobo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lifeng</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengjie</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhou</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingquan</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15534</idno>
		<title level="m">HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Knowledge guided text retrieval and reading for open domain QA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03868</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Multi-hop Reading Comprehension through Question Decomposition and Rescoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6097" to="6109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning to Attend On Essential Terms: An Enhanced Retriever-Reader Model for Open-domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmo</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Mcauley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="335" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Revealing the Importance of Semantic Retrieval for Machine Reading at Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2553" to="2566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kosuke</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyosuke</forename><surname>Nishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masaaki</forename><surname>Nagata</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Atsushi</forename><surname>Otsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Itsumi</forename><surname>Saito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hisako</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junji</forename><surname>Tomita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th</title>
		<meeting>the 57th</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<meeting><address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<biblScope unit="page" from="2335" to="2345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Answering Complex Open-domain Questions Through Iterative Query Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Mehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2590" to="2602" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dynamically Fused Graph Network for Multi-hop Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunxuan</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanru</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weinan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6140" to="6150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">SQuAD: 100,000+ Questions for Machine Comprehension of Text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Modeling Semantics with Gated Graph Neural Networks for Knowledge Base Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniil</forename><surname>Sorokin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3306" to="3317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangtao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2704" to="2713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention is All you Need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Graph Attention Networks. International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Building a question answering test collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tice</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="200" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Document Gated Reader for Open-Domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhixing</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Paris, France; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="85" to="94" />
		</imprint>
	</monogr>
	<note>SIGIR&apos;19)</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">R 3 : Reinforced Ranker-Reader for Open-Domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerry</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Evidence Aggregation for Answer Re-Ranking in Open-Domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Klinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multi-passage BERT: A Globally Normalized BERT Model for Open-domain Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaofei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5878" to="5882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">HuggingFace&apos;s Transformers: State-of-the-art Natural Language Processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lysandre</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clement</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anthony</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierric</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R&amp;apos;emi</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Brew</surname></persName>
		</author>
		<idno>ArXiv abs/1910.03771</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zonghan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengqi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S Yu</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Answering Complex Open-Domain Questions with Multi-Hop Dense Retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srini</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yashar</forename><surname>Mehdad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Yih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=EMHoBG0avc1" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">End-to-End Open-Domain Question Answering with BERTserini</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aileen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luchen</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="72" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2369" to="2380" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Variational reasoning for question answering with knowledge graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanjun</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zornitsa</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Transformer-XH: Multi-Evidence Reasoning with eXtra Hop Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corby</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xia</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Tiwary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Document Modeling with Graph Attention Networks for Multi-grained Machine Reading Comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyang</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaobo</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daxin</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.599</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.acl-main.599" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6708" to="6718" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
