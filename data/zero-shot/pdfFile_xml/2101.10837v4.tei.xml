<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Ikshana Hypothesis of Human Scene Understanding</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkata</forename><forename type="middle">Satya</forename><surname>Sai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Blekinge Insitute of Technology Karlskrona</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ajay</forename><surname>Daliparthi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Blekinge Insitute of Technology Karlskrona</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Ikshana Hypothesis of Human Scene Understanding</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:41+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In recent years, deep neural networks (DNNs) achieved state-of-the-art performance on several computer vision tasks. However, the one typical drawback of these DNNs is the requirement of massive labeled data. Even though few-shot learning methods address this problem, they often use techniques such as meta-learning and metric-learning on top of the existing methods. In this work, we address this problem from a neuroscience perspective by proposing a hypothesis named Ikshana, which is supported by several findings in neuroscience. Our hypothesis approximates the refining process of conceptual gist in the human brain while understanding a natural scene/image. While our hypothesis holds no particular novelty in neuroscience, it provides a novel perspective for designing DNNs for vision tasks. By following the Ikshana hypothesis, we design a novel neuralinspired CNN architecture named IkshanaNet. The empirical results demonstrate the effectiveness of our method by outperforming several baselines on the entire and subsets of the Cityscapes and the CamVid semantic segmentation benchmarks.</p><p>Preprint. Under review.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The human brain can seamlessly perceive diverse perceptual and semantic information regarding the natural scene/image during a glance <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. The visual scene information perceived during/after a glance refers to the gist (a summary) of the scene/image. The gist includes all the visual information from the low-level (e.g., colors and contours) to the high-level (e.g., shapes and activation). Due to this reason, <ref type="bibr" target="#b4">[5]</ref> suggested that the gist can be investigated at both the perceptual and conceptual levels. The structural representation of the image refers to the perceptual gist, and the semantic information of the image refers to the conceptual gist. However, the conceptual gist is more refined and modified than the perceptual gist <ref type="bibr" target="#b4">[5]</ref>. Several works <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">[8]</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref> in neuroscience have addressed the fundamental question, i.e.,"how does the human brain performs several visual tasks?" by investigating through conceptual and perceptual gist. They conducted several experiments and proposed various theories to explain how modeling of the scene occurs in the human brain. However, there was no general principle that explains the functioning of the human brain. Even though there is a general principle, we expect that to be different from human-to-human. Depending on the situation and the environment, the human brain can seamlessly grasp the information by recognizing the objects and observing their structure. On the other hand, for a computer to do the same is the fundamental goal of the computer vision field. In recent years, deep learning methods have shown a significant improvement over traditional handcrafted techniques on several computer vision tasks. Though these deep neural networks (DNNs) achieved state-of-the-art performance in many cases, the one major drawback is the requirement of massive labeled data. The collection of a huge amount of labeled data is an expensive and time taking process. Even though these DNNs are said to be inspired by the functioning of the human brain, is this how the human brain learns to perform any visual task? NO. Because the human brain does not require massive labeled data to perform any visual task, and it can perform with few data samples. However, we cannot observe a similar phenomenon in the case of many DNNs. Semantic segmentation is the task of assigning a class label to every pixel in the given image, which has applications in various fields such as medical, autonomous driving, robotic navigation, localization, and scene understanding. The prominent work FCN <ref type="bibr" target="#b11">[12]</ref> adopted the image-classification networks <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref> for semantic segmentation. Later on, several works <ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref><ref type="bibr" target="#b20">[21]</ref><ref type="bibr" target="#b21">[22]</ref><ref type="bibr" target="#b22">[23]</ref> improved the FCN <ref type="bibr" target="#b11">[12]</ref> architecture, and proven to be successful in diverse semantic segmentation benchmarks <ref type="bibr" target="#b24">[24]</ref><ref type="bibr" target="#b25">[25]</ref><ref type="bibr" target="#b26">[26]</ref>. However, these methods mainly focus on achieving state-of-the-art performance by using the entire and additional datasets <ref type="bibr" target="#b27">[27]</ref> (for pre-training). Due to this reason, even though various methods <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b19">20]</ref> outperformed U-Net <ref type="bibr" target="#b15">[16]</ref> in terms of accuracy and computational complexity, the U-Net <ref type="bibr" target="#b15">[16]</ref> architecture is still exploited in several medical image segmentation methods due to its ability to perform with few data samples <ref type="bibr" target="#b28">[28]</ref>. Although several few-shot semantic segmentation (FSS) methods are introduced to address this problem, they often use techniques such as meta-learning <ref type="bibr" target="#b29">[29]</ref><ref type="bibr" target="#b30">[30]</ref><ref type="bibr" target="#b31">[31]</ref><ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref> and metric learning <ref type="bibr" target="#b34">[34]</ref><ref type="bibr" target="#b35">[35]</ref><ref type="bibr" target="#b36">[36]</ref><ref type="bibr" target="#b37">[37]</ref><ref type="bibr" target="#b38">[38]</ref><ref type="bibr" target="#b38">[38]</ref><ref type="bibr" target="#b39">[39]</ref><ref type="bibr" target="#b40">[40]</ref> on top of the existing architectures. Unlike FSS methods, we tackle the formerly mentioned drawback of the DNNs, i.e., the requirement of massive labeled data, from a neuroscience perspective. In this work, we propose a hypothesis of human scene understanding mechanism named Ikshana. The idea is that, "to understand the conceptual gist of a given image; humans look at the image multiple times recurrently at different scales". Following the Ikshana hypothesis, we propose a novel neural-inspired CNN architecture named IkshanaNet, a multi-scale architecture that learns representations at full image resolution. In contrast to the existing CNN architectures that pass the input image only to the initial layer (stem module), our method feeds the input image to every module in the network and to the best of our knowledge, this is the first work to propose the same. To evaluate the performance of IkshanaNet, we conduct extensive experiments on the entire and subsets of the Cityscapes and Camvid benchmarks. Moreover, we conduct multiple ablation studies to verify the effect of image scales in IkshanaNet. The empirical results illustrate that our method outperforms several baselines on the entire and few data samples. Furthermore, the ablation studies shows the importance of multi-scale information to achieve considerable performance. We hope that our hypothesis sparks future research in neural network architectures for vision tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>In Neurological terms, all the low-level and high-level computer vision tasks come under a single term called human scene understanding. A scene is a view of a real-world environment that contains multiple surfaces and objects organized in a meaningful way. In neuroscience, the perceptual gist is more investigated compared to the conceptual gist. The early works on the conceptual gist <ref type="bibr" target="#b41">[41,</ref><ref type="bibr" target="#b2">3]</ref> explained that a typical scene fixation of 275 to 300 ms is often sufficient to understand the gist of the image. Several works on the perceptual gist <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b43">43,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref> provided insight into how the modelling of the scene occurs in the human brain through perceiving boundaries, blobs, scales, texture, contours, openness, depth, and so on. The information perceived through the perpetual gist is refined and extracted into the conceptual gist (the semantic meaning) during the cognitive process. Thus, the conceptual gist is highly dependent upon the perceptual gist. In many cases <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b25">25,</ref><ref type="bibr" target="#b26">26]</ref>, we do not explicitly encode the perceptual process in DNNs, and the CNN learns various representations regarding the image during the training process. Thus, our hypothesis focuses on the conceptual gist rather than the perceptual gist. Neural networks exist from a long time <ref type="bibr" target="#b44">[44]</ref><ref type="bibr" target="#b45">[45]</ref><ref type="bibr" target="#b46">[46]</ref> and some prominent works <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b48">[48]</ref><ref type="bibr" target="#b49">[49]</ref><ref type="bibr" target="#b50">[50]</ref> made them popular during recent years. In our work, we use the convolutional neural network (CNN) architecture <ref type="bibr" target="#b51">[51,</ref><ref type="bibr" target="#b52">52]</ref> to learn representations from the images, which itself is inspired by <ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b54">54]</ref>. The architecture of IkshanaNet is inspired by <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b55">55]</ref> and related to <ref type="bibr" target="#b56">[56,</ref><ref type="bibr" target="#b57">57]</ref>. The first seminal work on Semantic segmentation (SS) using deep learning is the fully convolutional networks (FCN) <ref type="bibr" target="#b11">[12]</ref>. Later on, many semantic segmentation networks followed the FCN <ref type="bibr" target="#b11">[12]</ref> architecture. The total prominent works on deep learning-based semantic segmentation methods can be roughly classified into five categories. They are (i) Encoder-decoder based methods (DeconvNet <ref type="bibr" target="#b58">[58]</ref>, SegNet <ref type="bibr" target="#b16">[17]</ref>, U-Net <ref type="bibr" target="#b15">[16]</ref>, RefineNet <ref type="bibr" target="#b59">[59,</ref><ref type="bibr" target="#b60">60]</ref>, FC-DenseNet <ref type="bibr" target="#b61">[61]</ref>, and GFR-Net <ref type="bibr" target="#b62">[62]</ref>), (ii) Regional proposal methods (MaskRCNN <ref type="bibr" target="#b63">[63]</ref>, FPN <ref type="bibr" target="#b64">[64]</ref>, and PANet <ref type="bibr" target="#b65">[65]</ref>), (iii) Increased resolution of feature map methods (DeepLab series <ref type="bibr" target="#b66">[66]</ref><ref type="bibr" target="#b67">[67]</ref><ref type="bibr" target="#b68">[68]</ref><ref type="bibr" target="#b18">19]</ref>, PSPNet <ref type="bibr" target="#b17">[18]</ref>, DenseASPP <ref type="bibr" target="#b69">[69]</ref>, and HRNet <ref type="bibr" target="#b19">[20]</ref>), (iv) Context information methods (ParseNet <ref type="bibr" target="#b70">[70]</ref>, ATS <ref type="bibr" target="#b71">[71]</ref>, DANet <ref type="bibr" target="#b72">[72]</ref>, OCNet <ref type="bibr" target="#b73">[73]</ref>, OCR <ref type="bibr" target="#b20">[21]</ref>, EncNet <ref type="bibr" target="#b74">[74]</ref>, Non-local <ref type="bibr" target="#b75">[75]</ref>, ZigZagNet <ref type="bibr" target="#b76">[76]</ref>, ACFNet <ref type="bibr" target="#b77">[77]</ref>, CoCurNet <ref type="bibr" target="#b79">[78]</ref>, GLAD <ref type="bibr" target="#b80">[79]</ref>, and HANet <ref type="bibr" target="#b81">[80]</ref>) (v) Boundary refinement methods ( <ref type="bibr" target="#b82">[81]</ref><ref type="bibr" target="#b83">[82]</ref><ref type="bibr" target="#b84">[83]</ref><ref type="bibr" target="#b85">[84]</ref>, Gated-SCNN <ref type="bibr" target="#b21">[22]</ref>, and SegFix <ref type="bibr" target="#b22">[23]</ref>). The IkshanaNet uses the dilated convolutions, interpolation of feature maps, and skip connections from different layers in the network. Therefore, our work is related to the formerly mentioned encoder-decoder and increased resolution of feature map methods. Few-shot segmentation (FSS) methods <ref type="bibr" target="#b29">[29]</ref><ref type="bibr" target="#b30">[30]</ref><ref type="bibr" target="#b31">[31]</ref><ref type="bibr" target="#b32">[32]</ref><ref type="bibr" target="#b33">[33]</ref><ref type="bibr" target="#b34">[34]</ref><ref type="bibr" target="#b35">[35]</ref><ref type="bibr" target="#b36">[36]</ref><ref type="bibr" target="#b37">[37]</ref><ref type="bibr" target="#b38">[38]</ref><ref type="bibr" target="#b39">[39]</ref><ref type="bibr" target="#b40">[40]</ref><ref type="bibr" target="#b87">[85]</ref><ref type="bibr" target="#b88">[86]</ref><ref type="bibr" target="#b89">[87]</ref> are introduced to handle limited training data. They use meta-learning (knowledge distillation), metric-learning (similarity learning), and a combination of both the techniques on top of FCN <ref type="bibr" target="#b11">[12]</ref> based architectures, which often involve multistage training. The metric-learning techniques can be further classified into the prototypical feature learning <ref type="bibr" target="#b30">[30,</ref><ref type="bibr" target="#b90">88,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b35">35,</ref><ref type="bibr" target="#b91">89]</ref> and the affinity learning <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b92">90]</ref> techniques. Unlike general SS methods, FSS methods are evaluated on different benchmarks and handle novel class categories during testing. Since the IkshanaNet does not use any of the formerly mentioned FSS techniques and only handles the classes seen in the training data, our method is more closely related to the general SS methods than the FSS methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ikshana (the eye) hypothesis</head><p>In her prominent work <ref type="bibr" target="#b41">[41]</ref>, professor Mary C. Potter found that an average human can understand the gist of the image between the time interval of 125 to 300 ms. Furthermore, through several works <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b8">[9]</ref><ref type="bibr" target="#b9">[10]</ref><ref type="bibr" target="#b10">[11]</ref> in neuroscience, it is evident that humans understand the gist of the image in a certain time interval. During that time interval, the Ikshana hypothesis approximates the functioning of the human brain. The Ikshana hypothesis states that "To understand the conceptual gist of a given image, humans look at the image multiple times recurrently, at different scales." The word Ikshana is derived from the Sanskrit language, which has many synonyms such as the eye, sight, look, and so on. We present an example to explain the Ikshana hypothesis in <ref type="figure" target="#fig_1">Figure 1</ref>, where there is an image (x) on the left side and the human brain mechanism on the right side. According to the Ikshana hypothesis, for a human to understand the conceptual gist of the given image, the following process occurs in the human brain: At a time step (t), during the first glance (? 1 ), the brain learns the first representation (f (x)) from the image (x) and stores that representation in the memory (M ), as shown in the equation 1.</p><formula xml:id="formula_0">f (x) = ? 1 (x); M = f (x) (1)</formula><p>At a time step (t + 1), during the second glance (? 2 ), the brain holds the first representation (f (x)) in the memory and learns the second representation (g(x)) from the image and the first representation (x, f (x)). Then the brain stores the representation (g(x)) along with (f (x)) in the memory (M ), as shown in the equation 2.</p><formula xml:id="formula_1">g(x) = ? 2 (x, f (x)); M = f (x), g(x)<label>(2)</label></formula><p>At a time step (t + 2), during the third glance (? 3 ), the brain holds the first and the second representations (f (x), g(x)) in the memory and learns the third representation (h(x)) from the image and the previous representations (x, f (x), g(x)). Then the brain stores the representation (h(x)) along with (f (x), g(x)) in the memory (M ), as shown in the equation 3.</p><formula xml:id="formula_2">h(x) = ? 3 (x, f (x), g(x)); M = f (x), g(x), h(x)<label>(3)</label></formula><p>From 1, 2, and 3, this kind of recurrent process occurs at (t + n) times at a single image scale. Depending upon the given task (T ), by combing all the information stored in the memory until the (t + n)th time step, the brain understands the conceptual gist (Y 1 ) of the image at a single scale, as shown in the equation 4.</p><formula xml:id="formula_3">Y 1 = T (f (x), g(x), h(x)...........n(x))<label>(4)</label></formula><p>This process occurs at N different scales and generates N different outputs (Y 1 , Y 2 , Y 3 , ...., Y n ). By considering all the outputs, the brain selects some of those representations and forgets the remaining representations. In this way, the brain learns (?) the final output (Y ) of the given visual task (T ), as shown in the equation <ref type="bibr" target="#b4">5</ref>.  The existing CNN architectures such as VGG <ref type="bibr" target="#b13">[14]</ref>, Resnet <ref type="bibr" target="#b48">[48]</ref>, DenseNet <ref type="bibr" target="#b55">[55]</ref>, and so on learns a representation (say f (x)) with 32/64 filters from the input image and learns further representations on top of the f (x) until the network achieves adequate performance. In contrast, the network designed by following the Ikshana hypothesis learns representations from the input image and previous outputs at each glance/layer.</p><formula xml:id="formula_4">Y = ?(Y 1 , Y 2 , Y 3 , ....Y N )<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">IkshanaNet-main</head><p>In this section, we introduce a novel neural-inspired encoder-decoder CNN architecture named IkshanaNet, designed by following the Ikshana hypothesis. Humans can look at the image and seamlessly learn various useful representations regarding it <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref>. On the other hand, for a computer to do the same, we use the convolutional neural network <ref type="bibr" target="#b53">[53,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b51">51]</ref> architecture to learn representations. The IkshanaNet architecture uses three image scales and consists of 4M parameters. The entire architecture is made of three building blocks, and they are: (1) the glance module, (2) the projection module, and (3) a 1x1 convolutional layer, as illustrated in <ref type="figure" target="#fig_2">Figure 2</ref>. The glance module consists of three 3x3 convolutional layers (with the same dilation rates), and we use it to learn representations from the given image (or a feature map). The number of input filters passed into the glance module varies several times in the architecture; however, it always returns a feature map with 32 filters. The projection module consists of three 3x3 convolutional layers, and we use it to refine the representations learned from the glance modules. The input and output filters are always the same for the projection module. We use the 1x1 convolution layers to reduce the number of filters in a given future map. Except for the last 1x1 convolutional layer that returns the final output, every convolutional layer in the architecture is followed by a batch normalization <ref type="bibr" target="#b93">[91]</ref> and a ReLU <ref type="bibr" target="#b94">[92]</ref> activation layer. In the encoder part, the IkshanaNet learns representations at three image scales. At scale 1, we pass the input image through a glance module with a dilation rate (d= 1), which returns a feature map with 32 filters. Then we concatenate the input image with the previously learned feature map <ref type="bibr">(32 + 3 = 35)</ref>. The concatenation of the input image with the feature map is essential to ensure that we are learning representations from the input image. Then we pass the feature map through another glance module with a dilation rate (d= 2) and concatenate the resulting feature map with the feature maps from the preceding layers (32 + 32 + 3 = 67). We pass the resulting feature map through another glance module with a dilation rate (d= 3), which takes in 67 filters and returns 32 filters. Again, we concatenate the resulting feature map with feature maps from the preceding layers (32 + 32 + 32 + 3 = 99). At this point, we remove the input image from the feature map through tensor slicing (99 ? 3 = 96), and the resulting feature map consists of (32 + 32 + 32 = 96) filters learned from three glances modules. In this way, the network followed the Ikshana hypothesis had three glances recurrently at the full resolution. Then we pass the feature map through a projection  <ref type="bibr">(96 = 96)</ref>. Here, we pass the refined feature map through a 1x1 convolutional layer that reduces 96 filters into 20 filters and name it the side one output (Y 1 ). Simultaneously, we pass the feature map through an average pooling layer, which reduces the size of the feature map by a factor of two. At scale 2, we down-sample the input image by a factor of two and concatenate with the pooled feature map from the scale 1 (96 + 3 = 99). We pass the resulting feature map with 99 filters through three glance modules with different dilation rates (d=1, 2, 3) and concatenate all the outputs as follows (99 + 32 + 32 + 32 = 195). Then we remove the image from the feature map (195 ? 3 = 192) and pass it through a projection module to refine the representations <ref type="bibr">(192 = 192)</ref>. Then we pass the refined feature map through a 1x1 convolutional layer that reduces 192 filters into 20 filters and name it the side two output (Y 2 ). Then, we pass the refined feature map through an average pooling layer that reduces the size by a factor of two. At scale 3, we down-sample the input image by a factor of four and concatenate with the pooled feature map from the scale 2 (192 + 3 = 195). Here, we follow the same process (195 + 32 + 32 + 32 = 291); (291 ? 3 = 288); (288 == 288) as the scale 2 part, which returns a feature map with 20 filters, and name it the side three output (Y 3 ). In the decoder part, we bi-linearly interpolate the outputs from two scales (Y 2 and Y 3 ) to match with the output of scale 1 Y 1 , i.e., the input image size. Then we concatenate all the three outputs (20 + 20 + 20 = 60) and pass it through a 1x1 convolutional layer, which returns a feature map with 20 filters, that is the final output of the network.</p><formula xml:id="formula_5">[Y = ?(Y 1 , Y 2 , Y 3 )]</formula><p>Depth architectures : Here, we introduce three variants of the IkshanaNet named IkshanaNet-3G, IkshanaNet-6G, and IkshanaNet-12G. If we remove the projection layers in IkshanaNet-main, then it will remain with three scales and three glances at each scale; it is IkshanaNet-3G (which consists of 514K parameters). If we increase the number of glances per scale, from three to six, then it is IkshanaNet-6G (which consists of 1.8M parameters), and from three to twelve, then it is IkshanaNet-12G (which consists of 6.5M parameters). Multi-scale architectures : Here, we introduce three variants of IkshanaNet named IkshanaNet 1S-6G, 2S-3G, and 3S-2G. In IkshanaNet 1S-6G, there are no pooling layers and contain six glances at full-scale resolution (which consists of 257K parameters). In IkshaNet 2S-3G, there are two scales and three glances at each scale (which consists of 259K parameters). In IkshanaNet 3S-2G, there are three scales and two glances at each scale (which consists of 260K parameters).  <ref type="bibr" target="#b48">[48]</ref>, MobileNet-V2 <ref type="bibr" target="#b98">[96]</ref>, ResNext <ref type="bibr" target="#b102">[103]</ref>, EfficientNet <ref type="bibr" target="#b99">[97]</ref>, and RegNet <ref type="bibr" target="#b100">[98]</ref> from the segmentation models library <ref type="bibr" target="#b103">[104]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Experiments on Cityscapes</head><p>The Cityscapes <ref type="bibr" target="#b25">[25]</ref> semantic segmentation dataset consists of 5, 000 finely annotated high-quality images, which are further divided into 2, 975/500/1, 525 images for training, validation, and testing. During the evaluation, only 19 classes are considered out of the 35 classes. Therefore, by using the cityscapes-scripts, we convert the 35 classes into 20 classes (including background). We resize all the images from the resolution of 1024x2048 to 512x1024.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Baseline experiments :</head><p>Here, we use the networks DeeplabV3+ (ResNet-101 <ref type="bibr" target="#b48">[48]</ref>), DeeplabV3 (DenseNet-161 <ref type="bibr" target="#b55">[55]</ref>), HRNet-V2 <ref type="bibr" target="#b104">[105]</ref>, and U-Net <ref type="bibr" target="#b15">[16]</ref> as the baselines 2 to compare with IkshanaNet-main. We train all the networks on the entire dataset T 2975 and provide the mean class IoU results evaluated on the validation-set in <ref type="table" target="#tab_1">Table 1</ref>, where we observe the following: (iv) Even though U-Net <ref type="bibr" target="#b15">[16]</ref> and IkshanaNet learn representations at full-scale resolution before reducing the spatial resolution, the IkshanaNet still outperforms U-Net <ref type="bibr" target="#b15">[16]</ref> in the formerly mentioned classes.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Multi-scale ablation study :</head><p>In Section 3.1, the Ikshana hypothesis stated that "humans often require multi-scale information to understand the gist of an image". Therefore, to verify the requirement of multi-scale information, we  <ref type="table" target="#tab_2">Table 2</ref> and Table3, we observe that IkshanaNet 3S-2G network (with only 260K parameters) outperforms all the baselines in the data ablation study by occupying approximately 10x few GFLOPs and 15x few parameters than IkshanaNet-main.</p><p>The above observations suggest that, the multi-scale architectures can achieve superior performance than an isometric architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiments on Camvid</head><p>The Cambridge-driving labeled video dataset <ref type="bibr" target="#b24">[24]</ref> for semantic segmentation consists of 700 images, which are further divided into 367 training, 101 validation, and 233 testing sets. We convert the 32 classes to 12 classes (including background) by following <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b106">107]</ref> and resize the images from the resolution of 720x960 to 368x480. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1">Baseline experiments :</head><p>Here, according to the size of the networks, we classify the total networks into three different sets. Set-1 consists of DeeplabV3+ <ref type="bibr" target="#b18">[19]</ref> with the encoder networks such as Resnet-18 <ref type="bibr" target="#b48">[48]</ref>, EfficientNet-b1 <ref type="bibr" target="#b99">[97]</ref>, RegNetY-08 <ref type="bibr" target="#b100">[98]</ref>, MobileNet-V2 <ref type="bibr" target="#b98">[96]</ref>, and IkshanaNet-3G (see Section 3.2). Set-2 consists of DeeplabV3+ <ref type="bibr" target="#b18">[19]</ref> with the encoder networks such as Resnet-50 <ref type="bibr" target="#b48">[48]</ref>, EfficientNet-b4 <ref type="bibr" target="#b99">[97]</ref>, RegNetY-40 <ref type="bibr" target="#b100">[98]</ref>, and ResNext-50 <ref type="bibr" target="#b102">[103]</ref>, and IkshanaNet-6G (see Section 3.2). Set-3 consists of DeeplabV3+ <ref type="bibr" target="#b18">[19]</ref> with the encoder networks such as Resnet-101 <ref type="bibr" target="#b48">[48]</ref>, EfficientNet-b6 <ref type="bibr" target="#b99">[97]</ref>, RegNetY-80 <ref type="bibr" target="#b100">[98]</ref>, DeepLabV3 ( DenseNet-161 <ref type="bibr" target="#b55">[55]</ref>), HRNet-V2 <ref type="bibr" target="#b104">[105]</ref>, U-Net <ref type="bibr" target="#b15">[16]</ref>, and IkshanaNet-12G (see section 3.2) 3 . Additionally, we include IkshanaNet-main and did not compare it with other networks. By using the same validation, we train each network on three different subsets of the training data, T 367 , T 183 , and T 91 .</p><p>In <ref type="table" target="#tab_4">table 4</ref>, we provide the mean IoU results evaluated on the validation set, the test set, the average M.IoU score of all the variants, the number of parameters (in Million), and the GFLOPs <ref type="bibr" target="#b105">[106]</ref> (calculated the GFLOPs with an input resolution of 1x368x480x3). From table 4, we observe the following:</p><p>In Set-1: (i) IkshanaNet-3G outperforms all other networks in the subsets T 91 , T avg , and requires fewer parameters.</p><p>(ii) EfficientNet-b1 <ref type="bibr" target="#b99">[97]</ref> outperforms other networks in the T 367 and requires fewer GFLOPs.</p><p>In Set-2: (i) IkshanaNet-6G outperforms all other networks in the subsets T 367 , T 183 , T avg , and requires fewer parameters.</p><p>(ii) EfficientNet-b4 <ref type="bibr" target="#b99">[97]</ref> outperforms all other networks in the subset T 91 and requires fewer GFLOPs. In Set-3: (i) IkshanaNet-12G outperforms all other networks in the subsets T 367 , T 183 , T avg , and requires fewer parameters.</p><p>(ii) U-Net <ref type="bibr" target="#b15">[16]</ref> outperformed other networks in the subset T 91 and EfficientNet-b6 <ref type="bibr" target="#b99">[97]</ref> requires fewer GFLOPs than other networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">Multi-scale ablation study :</head><p>Same as Section 4.2.3, by using the same validation set, we train three different variants of IkshanaNet such as 1S-6G, 2S-3G, and 3S-2G (explained in section 3.2) on three subsets of the training data (T 367 , T 183 , and T 91 ).</p><p>In <ref type="table" target="#tab_5">table 5</ref>, we provide the mean IoU results evaluated on the validation set, the test set, the average score of all variants, the parameters, and the GFLOPs. We calculate the GFLOPs with an input resolution of 1x368x480x3. From table 5, we observe that, the IkshanaNet-3S-2G network outperforms all other networks in all the subsets (T 367 , T 183 , T 91 , T avg ), and requires fewer GFLOPs. The results are similar to the section 4.2.3 <ref type="table" target="#tab_3">(Table 3)</ref>, demonstrating the importance of multi-scale information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Validity threats</head><p>(i) Most of the existing works <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21]</ref> used a mini-batch size of 8 and SyncBN <ref type="bibr" target="#b107">[108,</ref><ref type="bibr" target="#b74">74]</ref> for training. However, due to the limited availability of the computing resources, we train all the networks with a mini-batch size of 2. Due to this reason, we cannot directly compare the performance of our method with the state-of-the-art methods.</p><p>(ii) In this work, even though the training data splits are reproducible, the performance of the networks trained on subsets of the training data might depend upon the fact that "how well the subset represents the whole dataset?". If we use a different random seed to generate the splits, then the exact behavior may or may not be expected.</p><p>(iii) In this work, through multi-scale ablation experiments, we observe that multi-scale information is often necessary to improve the performance of the networks. By observing the images in Cityscapes, and CamVid datasets, it is evident that the images consist of multi-scale objects. However, this phenomenon might not be valid to other datasets, where there exist no multi-scale objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this work, we attempt to bridge the gap between the current vision DNNs and the human visual system by proposing a novel hypothesis of human scene understanding and a neural-inspired CNN architecture that learns representations at full-scale resolution. The empirical results illustrate the effectiveness of our method on entire and few data samples compared to the baselines. Also, through multi-scale ablation studies, we observe that using multi-scale information improves the performance of IkshanaNet by reducing the computational complexity. Moreover, we observe that our method is just an improvement over the baselines, and it is still dependent on the data. Hence, it is nowhere close to the human visual system. Therefore, a betterperforming and computationally efficient architectures based on the Ikshana hypothesis will be studied in the future work. Furthermore, we hope that our hypothesis inspires future generation of neural inspired vision architectures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Cityscapes experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1.1 Baseline experiments</head><p>For ease of visualization, we separate the training plots of ResNet-101, DenseNet-161, HRNet-V2, and U-Net from the data ablation study and combine them with baseline experiments. In <ref type="figure" target="#fig_4">Figure 3</ref>, we present the training plots of the networks trained on six subsets of training data (T 2975 , T 1487 , T 743 , T 371 , T 185 , and T 92 ).  In <ref type="figure" target="#fig_6">Figure 5</ref>, we present the training plots of the networks IkshanaNet-1S-6G, IkshanaNet-2S-3G, and IkshanaNet-3S-2G trained on five subsets of training data (T 1487 , T 743 , T 371 , T 185 , and T 92 ). In table 7, we present the class-wise IoU results of these networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 CamVid experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.1 Baseline experiments</head><p>In <ref type="figure">Figure 6</ref>, we present the training plots of the networks ResNet-18, EfficientNet-b1, RegNetY-08, MobileNet-V2, and IkshanaNet-3G, trained on three subsets of training data (T 367 , T 183 , and T 91 ). In <ref type="figure">Figure 7</ref>, we present the training plots of the networks ResNet-50, EfficientNet-b4, RegNetY-40, ResNext-50, and IkshanaNet-6G, trained on three subsets of training data (T 367 , T 183 , and T 91 ).</p><p>In <ref type="figure">Figure 8</ref>, we present the training plots of the networks ResNet-101, EfficientNet-b6, RegNetY-80, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2.2 Muti-scale ablation study</head><p>In <ref type="figure">Figure 9</ref>, we present the training plots of the networks IkshanaNet-1S-6G, IkshanaNet-2S-3G, and IkshanaNet-3S-2G, trained on three subsets of training data (T 367 , T 183 , and S 91 ).        <ref type="table">Table 7</ref>: Class-wise IoU results of the Cityscapes multi-scale ablation study evaluated on val set</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>From the equations 1, 2, 3, 4, and 5, this is how Ikshana hypothesis approximates the functioning of the human brain, while human understands the conceptual gist of the image. The time required</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 :</head><label>1</label><figDesc>The Ikshana hypothesis at single scale (or the number of glances required) by an average human to understand the gist of the image may depend upon several factors such as the given task, age, intelligence, memory, and so on.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>IkshanaNet-main architecture module to refine the representations</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(i) U-Net<ref type="bibr" target="#b15">[16]</ref> (49.3)  shown top performance within the baseline networks followed by HRNet-V2[105] (48.0). (ii) IkshanaNet outperformed U-Net by 5.2 % and HRNet-V2 [105] by 6.5 %. (iii) IkshanaNet outperformed baselines by a huge margin in classes such as fence, pole, traffic light, traffic sign, rider, bus, motorcycle, and bicycle.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Cityscapes Baseline experiments training plotsA.1.2 Data ablation studyInFigure 4, we present the training plots of the networks Resnet-18, MobileNet-V2, EfficientNet-b1 , RegNetY-08 , and IkshanaNet-main, trained on five subsets of training data (T 1487 , T 743 , T 371 , T 185 , and T 92 ). In table 6, we present the class-wise IoU results of these networks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Cityscapes data ablation study training plots A.1.3 Muti-scale ablation study</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 :</head><label>5</label><figDesc>Cityscapes multi-scale ablation study training plots DenseNet-161, HRNet-V2, U-Net, and IkshanaNet-12G, trained on three subsets of training data (T 367 , T 183 , and T 91 ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 :Figure 7 :Figure 8 :Figure 9 :</head><label>6789</label><figDesc>CamVid Set-1 Baseline experiments training plots CamVid Set-2 Baseline experiments training plots CamVid Set-3 Baseline experiments training plots CamVid multi-scale ablation study training plots</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>14.1 83.4 36.6 85.8 28.5 0.0 75.8 3.3 0.0 1.9 0.0 1.4 30.2 IkshanaNet 90.5 51.6 78.1 4.5 1.7 28.0 0.7 24.0 84.0 33.4 83.9 35.2 0.0 65.5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Criterion : Pixel-wise cross-entropy loss Learning rate scheduler : ReduceLROnPlateau (decrease factor = 0.5 and patience = 20 epochs) with an initial learning rate of 1e ? 06. Optimizer : Stochastic gradient descent<ref type="bibr" target="#b96">[94]</ref> with Nesterov momentum [95] 1 Random seed : To ensure that data splits are reproducible, we set the random seed 42 in the function torch.utils.data.random-split. Pre-processing We normalize all the images with mean and standard deviation values of ImageNet<ref type="bibr" target="#b27">[27]</ref> dataset. We did not use any data augmentation techniques.Baselines: We use the open-source implementations for networks DeepLabV3+ (ResNet-101) [99], DeepLabV3 (DenseNet-161) [100], HRNet-V2 [101], and U-Net [102]. We import DeeplabV3+ with encoder networks such as ResNet</figDesc><table><row><cell>4 Experiments</cell></row><row><cell>4.1 Experimental setup</cell></row></table><note>GPU: 1 X NVIDIA Tesla T-4 (16 GB VRAM) Framework : PyTorch 1.8 [93] Epochs : 180 ; Batch size : 2</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Class-wise IoU results of the Cityscapes baseline experiments</figDesc><table><row><cell>Method</cell><cell>road</cell><cell>sidewalk</cell><cell>building</cell><cell>wall</cell><cell>fence</cell><cell>pole</cell><cell>traffic light</cell><cell>traffic sign</cell><cell>vegetation</cell><cell>terrain</cell><cell>sky</cell><cell>person</cell><cell>rider</cell><cell>car</cell><cell>truck</cell><cell>bus</cell><cell>train</cell><cell>motorcycle</cell><cell>bicycle</cell><cell>Average</cell></row><row><cell>ResNet101 [48]</cell><cell>95.0</cell><cell>66.1</cell><cell>81.9</cell><cell>15.0</cell><cell>13.5</cell><cell>26.7</cell><cell>20.7</cell><cell>29.5</cell><cell>86.7</cell><cell>55.4</cell><cell>89.3</cell><cell>48.5</cell><cell>6.3</cell><cell>85.5</cell><cell>6.8</cell><cell>26.1</cell><cell>19.0</cell><cell>9.8</cell><cell>32.0</cell><cell>42.8</cell></row><row><cell cols="2">DenseNet161 [55] 94.8</cell><cell>64.5</cell><cell>81.3</cell><cell>20.1</cell><cell>13.0</cell><cell>15.8</cell><cell>15.6</cell><cell>28.7</cell><cell>84.6</cell><cell>58.7</cell><cell>86.1</cell><cell>44.1</cell><cell>0.6</cell><cell>84.7</cell><cell>17.0</cell><cell>19.7</cell><cell>23.1</cell><cell>4.3</cell><cell>31.4</cell><cell>41.5</cell></row><row><cell>HRNet-V2 [105]</cell><cell>94.9</cell><cell>68.6</cell><cell>84.2</cell><cell>24.0</cell><cell>24.5</cell><cell>39.0</cell><cell>23.2</cell><cell>42.3</cell><cell>86.9</cell><cell>51.5</cell><cell>90.2</cell><cell>55.6</cell><cell>15.3</cell><cell>86.1</cell><cell>19.9</cell><cell>36.1</cell><cell>21.2</cell><cell>2.2</cell><cell>46.1</cell><cell>48.0</cell></row><row><cell>U-Net [16]</cell><cell>94.9</cell><cell>69.4</cell><cell>85.3</cell><cell>27.3</cell><cell>28.7</cell><cell>41.0</cell><cell>32.2</cell><cell>49.0</cell><cell>88.6</cell><cell>46.3</cell><cell>90.4</cell><cell>59.1</cell><cell>14.5</cell><cell>86.5</cell><cell>12.4</cell><cell>28.4</cell><cell>15.5</cell><cell>10.9</cell><cell>55.6</cell><cell>49.3</cell></row><row><cell>IkshanaNet-Main</cell><cell>95.6</cell><cell>72.8</cell><cell>85.9</cell><cell>22.6</cell><cell>35.3</cell><cell>49.6</cell><cell>47.0</cell><cell>60.7</cell><cell>89.2</cell><cell>48.9</cell><cell>91.6</cell><cell>63.3</cell><cell>28.8</cell><cell>87.1</cell><cell>18.4</cell><cell>40.3</cell><cell>21.8</cell><cell>16.5</cell><cell>60.8</cell><cell>54.5</cell></row><row><cell cols="6">4.2.2 Data ablation study :</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>While trained on few data samples, the network size might strongly influence the performance. The networks ResNet-101 [48] (59.3 M), DenseNet-161 [55]) (43.2 M), HRNet-V2 [105] (65.9), and U-Net [16] (31.0) consists more number of parameters compared to IkshanaNet-main (4 M). To make it a fair comparison, we include DeeplabV3+ [19] with several light-weight encoder networks (such as ResNet-18 [48], MobileNet-V2 [96], EfficientNet-b1 [97], and RegNetY-08 [98]) along with the networks from the baseline experiments. Here, we conduct a data ablation study on five different subsets of the training data, T 1487 , T 743 , T 371 , T 185 , and T 92 (suffix number represents the number of training samples in the subset) by using the same validation set (500 images). In table 2, we provide the mean class IoU results evaluated on the validation set, the average M.IoU score, the number of parameters (in million)), and the GFLOPs [106] (calculated with an input resolution of 1x512x1024x3 ). From table 2, we observe the following: (i) U-Net [16] (T avg -32.2) achieves top average performance within the baselines (ii) Even though U-Net [16] consists of 31M parameters, it still managed to outperform its lightweight counterparts. (iii) IkshanaNet outperformed all other baselines in the M.IoU score and the average M.IoU score in all five subsets. (iv) IkshanaNet consists of fewer parameters, and EfficientNet-b1 [97] consists of fewer GFLOPs than other networks.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Cityscapes data ablation experiments evaluated on the validation set</figDesc><table><row><cell>Backbone</cell><cell>T 1487</cell><cell>T 743</cell><cell>T 371</cell><cell>T 185</cell><cell>T 92</cell><cell>T avg</cell><cell cols="2">Param(M) GFLOPs</cell></row><row><cell>ResNet-18 [48]</cell><cell>42.6</cell><cell>35.6</cell><cell>27.9</cell><cell>22.4</cell><cell>21.0</cell><cell>29.9</cell><cell>12.3</cell><cell>36.8</cell></row><row><cell>MobileNet-V2 [96]</cell><cell>38.5</cell><cell>32.2</cell><cell>30.6</cell><cell>22.5</cell><cell>19.2</cell><cell>28.6</cell><cell>4.4</cell><cell>12.3</cell></row><row><cell cols="2">EfficientNet-b1 [97] 37.8</cell><cell>32.5</cell><cell>26.9</cell><cell>24.6</cell><cell>19.8</cell><cell>28.3</cell><cell>7.4</cell><cell>4.6</cell></row><row><cell>RegNetY-08 [98]</cell><cell>28.5</cell><cell>31.9</cell><cell>29.4</cell><cell>27.4</cell><cell>22.1</cell><cell>27.9</cell><cell>7.0</cell><cell>17.2</cell></row><row><cell>ResNet-101 [48]</cell><cell>29.3</cell><cell>28.8</cell><cell>28.6</cell><cell>21.6</cell><cell>19.4</cell><cell>25.5</cell><cell>59.3</cell><cell>177.8</cell></row><row><cell>DenseNet-161 [55]</cell><cell>33.3</cell><cell>30.1</cell><cell>26.0</cell><cell>24.9</cell><cell>20.8</cell><cell>27.0</cell><cell>43.2</cell><cell>129.4</cell></row><row><cell>HRNet-V2 [105]</cell><cell>27.8</cell><cell>18.8</cell><cell>23.3</cell><cell>18.3</cell><cell>15.4</cell><cell>20.7</cell><cell>65.9</cell><cell>187.8</cell></row><row><cell>U-Net[16]</cell><cell>42.8</cell><cell>34.2</cell><cell>30.2</cell><cell>27.8</cell><cell>25.0</cell><cell>32.0</cell><cell>31.0</cell><cell>387.1</cell></row><row><cell>IkshanaNet-Main</cell><cell>43.4</cell><cell>40.2</cell><cell>31.7</cell><cell>29.9</cell><cell>25.8</cell><cell>34.2</cell><cell>4.0</cell><cell>413.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Cityscapes multi-scale ablation experiments evaluated on the validation set</figDesc><table><row><cell>Backbone</cell><cell>T 1487</cell><cell>T 743</cell><cell>T 371</cell><cell>T 185</cell><cell>T 92</cell><cell>T avg</cell><cell cols="2">Param(M) GFLOPs</cell></row><row><cell cols="2">1S-6Glances 29.2</cell><cell>24.9</cell><cell>23.3</cell><cell>20.2</cell><cell>18.1</cell><cell>23.1</cell><cell>0.26</cell><cell>136.0</cell></row><row><cell cols="2">2S-3Glances 37.3</cell><cell>34.9</cell><cell>33.2</cell><cell>25.7</cell><cell>24.0</cell><cell>31.0</cell><cell>0.26</cell><cell>70.0</cell></row><row><cell cols="2">3S-2Glances 43.5</cell><cell>36.9</cell><cell>34.4</cell><cell>27.5</cell><cell>26.5</cell><cell>33.8</cell><cell>0.26</cell><cell>42.4</cell></row><row><cell cols="3">conduct a multi-scale ablation study.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="9">Here, we train three different variants of IkshanaNet, such as the 1S-6G, 2S-3G, and 3S-2G (explained</cell></row><row><cell cols="9">in Section 3.2) on the five different subsets of the training data (same as Section 4.2.2). In table 3, we</cell></row><row><cell cols="8">provide the results of the multi-scale ablation study evaluated on the validation set.</cell></row><row><cell cols="3">From table 3, we observe that:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="9">(i) IkshanaNet-3S-2G network outperforms other networks in the M.IoU score, the average M.IoU</cell></row><row><cell cols="8">score, and requires fewer GFLOPs, while requiring the same number of parameters.</cell></row><row><cell cols="9">(ii) The multi-scale information improved the performance and decreased the computational com-</cell></row><row><cell cols="5">plexity (GFLOPs) of the network and vice-versa.</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(iii) From</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Camvid baseline experiments evaluated on the validation and the test set</figDesc><table><row><cell>Backbone</cell><cell></cell><cell>T 367</cell><cell></cell><cell>T 183</cell><cell></cell><cell>T 91</cell><cell></cell><cell>T avg</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Val</cell><cell>Test</cell><cell>Val</cell><cell>Test</cell><cell>Val</cell><cell>Test</cell><cell>Val</cell><cell>Test</cell><cell cols="2">Param(M) GFLOPs</cell></row><row><cell>ResNet-18[48]</cell><cell>83.3</cell><cell>64.9</cell><cell>79.7</cell><cell>63.7</cell><cell>70.0</cell><cell>56.6</cell><cell>77.7</cell><cell>61.7</cell><cell>12.3</cell><cell>12.4</cell></row><row><cell cols="2">EfficientNet-b1[97] 84.4</cell><cell>68.4</cell><cell>75.0</cell><cell>61.3</cell><cell>77.0</cell><cell>58.8</cell><cell>78.8</cell><cell>62.8</cell><cell>7.4</cell><cell>1.5</cell></row><row><cell>RegNetY-08[98]</cell><cell>80.4</cell><cell>64.3</cell><cell>77.7</cell><cell>61.4</cell><cell>70.9</cell><cell>57.8</cell><cell>76.3</cell><cell>61.2</cell><cell>7.0</cell><cell>5.8</cell></row><row><cell>MobileNet-V2[96]</cell><cell>80.8</cell><cell>63.9</cell><cell>77.3</cell><cell>56.1</cell><cell>66.1</cell><cell>54.6</cell><cell>74.7</cell><cell>58.2</cell><cell>4.4</cell><cell>4.1</cell></row><row><cell>IkshanaNet-3G</cell><cell>81.6</cell><cell>65.7</cell><cell>80.0</cell><cell>62.5</cell><cell>78.0</cell><cell>61.2</cell><cell>79.9</cell><cell>63.1</cell><cell>0.5</cell><cell>26.0</cell></row><row><cell>ResNet-50[48]</cell><cell>78.6</cell><cell>61.6</cell><cell>80.0</cell><cell>60.3</cell><cell>78.3</cell><cell>55.9</cell><cell>80.0</cell><cell>59.3</cell><cell>26.7</cell><cell>25.0</cell></row><row><cell cols="2">EfficientNet-b4[97] 82.7</cell><cell>64.1</cell><cell>77.7</cell><cell>62.2</cell><cell>75.6</cell><cell>60.5</cell><cell>78.7</cell><cell>62.3</cell><cell>18.6</cell><cell>1.7</cell></row><row><cell>RegNetY-40[98]</cell><cell>80.8</cell><cell>62.0</cell><cell>76.4</cell><cell>61.0</cell><cell>74.9</cell><cell>59.2</cell><cell>77.4</cell><cell>60.7</cell><cell>21.5</cell><cell>18.8</cell></row><row><cell>ResNext-50 [103]</cell><cell>80.1</cell><cell>62.6</cell><cell>77.3</cell><cell>56.1</cell><cell>66.1</cell><cell>54.6</cell><cell>74.5</cell><cell>57.8</cell><cell>26.2</cell><cell>25.0</cell></row><row><cell>IkshanaNet-6G</cell><cell>83.3</cell><cell>67.8</cell><cell>81.4</cell><cell>65.9</cell><cell>76.0</cell><cell>60.0</cell><cell>80.2</cell><cell>64.6</cell><cell>1.8</cell><cell>82.0</cell></row><row><cell>ResNet-101[48]</cell><cell>81.6</cell><cell>63.8</cell><cell>75.6</cell><cell>56.4</cell><cell>70.1</cell><cell>55.7</cell><cell>75.8</cell><cell>58.6</cell><cell>59.3</cell><cell>59.9</cell></row><row><cell cols="2">EfficientNet-b6[97] 80.6</cell><cell>65.0</cell><cell>80.3</cell><cell>57.8</cell><cell>77.4</cell><cell>60.4</cell><cell>79.4</cell><cell>61.0</cell><cell>42.0</cell><cell>1.9</cell></row><row><cell>RegNetY-80[98]</cell><cell>78.5</cell><cell>62.0</cell><cell>78.2</cell><cell>63.8</cell><cell>66.2</cell><cell>53.8</cell><cell>74.3</cell><cell>59.9</cell><cell>40.3</cell><cell>34.4</cell></row><row><cell>DenseNet-161[55]</cell><cell>77.8</cell><cell>58.6</cell><cell>75.7</cell><cell>57.8</cell><cell>73.0</cell><cell>53.8</cell><cell>75.5</cell><cell>56.7</cell><cell>43.2</cell><cell>43.6</cell></row><row><cell>HRNet-V2[105]</cell><cell>81.1</cell><cell>63.6</cell><cell>79.1</cell><cell>62.9</cell><cell>72.9</cell><cell>55.0</cell><cell>77.7</cell><cell>60.5</cell><cell>65.9</cell><cell>63.5</cell></row><row><cell>U-Net[16]</cell><cell>83.0</cell><cell>69.5</cell><cell>78.0</cell><cell>62.8</cell><cell>76.8</cell><cell>61.6</cell><cell>79.3</cell><cell>64.6</cell><cell>31.0</cell><cell>130.0</cell></row><row><cell>IkshanaNet-12G</cell><cell>83.9</cell><cell>70.0</cell><cell>83.3</cell><cell>67.1</cell><cell>76.5</cell><cell>60.6</cell><cell>81.2</cell><cell>65.9</cell><cell>6.5</cell><cell>285.0</cell></row><row><cell>IkshanaNet-M</cell><cell>83.2</cell><cell>68.5</cell><cell>79.9</cell><cell>62.9</cell><cell>72.2</cell><cell>58.8</cell><cell>78.4</cell><cell>63.4</cell><cell>4.0</cell><cell>139.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Camvid multi-scale ablation experiments evaluated on the validation and the test set</figDesc><table><row><cell>Backbone</cell><cell>T 367</cell><cell></cell><cell>T 183</cell><cell></cell><cell>T 91</cell><cell></cell><cell>T avg</cell><cell></cell><cell></cell></row><row><cell>Val</cell><cell>Test</cell><cell>Val</cell><cell>Test</cell><cell>Val</cell><cell>Test</cell><cell>Val</cell><cell>Test</cell><cell cols="2">Param(M) GFLOPs</cell></row><row><cell>1S-6Glances 79.2</cell><cell>60.0</cell><cell>77.8</cell><cell>58.8</cell><cell>66.7</cell><cell>50.9</cell><cell>74.6</cell><cell>56.6</cell><cell>0.26</cell><cell>45.6</cell></row><row><cell>2S-3Glances 80.1</cell><cell>65.6</cell><cell>79.5</cell><cell>60.1</cell><cell>77.2</cell><cell>59.5</cell><cell>78.9</cell><cell>61.7</cell><cell>0.26</cell><cell>23.1</cell></row><row><cell>3S-2Glances 82.9</cell><cell>66.5</cell><cell>80.9</cell><cell>62.8</cell><cell>77.5</cell><cell>60.8</cell><cell>80.4</cell><cell>63.4</cell><cell>0.26</cell><cell>14.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>64.4 81.5 14.5 13.8 27.8 17.8 26.3 85.0 46.2 88.8 46.7 7.4 81.3 23.8 34.5 10.1 5.0 39.8 42.6 MobileNetV2 93.9 64.6 81.8 15.8 16.2 24.0 1.0 17.6 84.4 39.9 88.</figDesc><table><row><cell>Subset</cell><cell>Method</cell><cell>road</cell><cell>sidewalk</cell><cell>building</cell><cell>wall</cell><cell>fence</cell><cell>pole</cell><cell>traffic light</cell><cell>traffic sign</cell><cell>vegetation</cell><cell>terrain</cell><cell>sky</cell><cell>person</cell><cell>rider</cell><cell>car</cell><cell>truck</cell><cell>bus</cell><cell>train</cell><cell>motorcycle</cell><cell>bicycle</cell><cell>Average</cell></row><row><cell></cell><cell>ResNet18</cell><cell>93.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>65.6 83.2 13.9 20.5 34.3 21.7 43.9 87.4 43.1 89.5 49.9 0.0 84.2 12.1 9.9 12.9 0.0 47.9 42.8 IkshanaNet 93.5 64.7 82.9 17.0 22.6 35.2 27.0 44.1 86.8 41.4 87.2 52.8 2.5 81.5 0.3 25.6 3.9 7.1 48.9 43.4</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>6 27.8</cell></row><row><cell></cell><cell cols="7">U-Net 94.0 ResNet18 92.8 56.3 78.0 15.3 8.0 15.4 4.9 18.9 82.3 42.8 85.6 35.4 0.1 75.2 13.1 13.9 1.9 0.0 36.6 35.6</cell></row><row><cell></cell><cell>MobileNetV2</cell><cell>92.7 57.3 77.8 6.1</cell><cell>7.8</cell><cell>0.7</cell><cell cols="3">0.1 11.3 81.5 39.2 85.2 30.8 0.1 75.9 3.5 22.9 2.9 0.0 15.4 32.2</cell></row><row><cell></cell><cell cols="2">EfficientNetb1 93.5 60.5 77.1 4.1</cell><cell>3.9</cell><cell>9.1</cell><cell cols="3">0.0 14.0 81.8 39.6 84.6 22.8 1.6 75.1 9.8 18.6 0.0 0.0 20.8 32.5</cell></row><row><cell></cell><cell>RegNetY08</cell><cell>93.9 58.7 78.8 3.4</cell><cell>9.1</cell><cell>0.0</cell><cell>0.0 17.5 83.1 45.2 87.1 32.0 0.0 76.8 2.3</cell><cell>0.3</cell><cell>0.0 0.0 17.1 31.9</cell></row><row><cell>T743</cell><cell>ResNet101</cell><cell>90.5 44.6 72.2 9.2</cell><cell>3.3</cell><cell>5.2</cell><cell>0.0 12.5 79.8 36.2 79.8 25.6 0.0 65.3 0.0</cell><cell>0.0</cell><cell>0.0 0.0 0.0 28.8</cell></row><row><cell></cell><cell>DenseNet161</cell><cell cols="2">91.1 50.8 74.7 13.9 3.3</cell><cell>4.4</cell><cell>1.1 12.1 78.4 32.1 80.8 28.6 0.0 69.6 2.2</cell><cell>1.4</cell><cell>0.2 2.3 25.7 30.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 :</head><label>6</label><figDesc>Class-wise results of the Cityscapes data ablation study evaluated on val set</figDesc><table><row><cell cols="2">Subset Method</cell><cell>road</cell><cell>sidewalk</cell><cell>building</cell><cell>wall</cell><cell>fence</cell><cell>pole</cell><cell>traffic light</cell><cell>traffic sign</cell><cell>vegetation</cell><cell>terrain</cell><cell>sky</cell><cell>person</cell><cell>rider</cell><cell>car</cell><cell>truck</cell><cell>bus</cell><cell>train</cell><cell>motorcycle</cell><cell>bicycle</cell><cell>Average</cell></row><row><cell></cell><cell cols="2">1S-6Glances 86.0</cell><cell>44.5</cell><cell>72.2</cell><cell>4.0</cell><cell>3.3</cell><cell>21.9</cell><cell>2.0</cell><cell>28.0</cell><cell>83.1</cell><cell>35.4</cell><cell>77.5</cell><cell>29.7</cell><cell cols="2">0.0 52.8</cell><cell>0.0</cell><cell>0.9</cell><cell cols="3">0.0 0.0 12.7</cell><cell>29.2</cell></row><row><cell>S1487</cell><cell cols="2">2S-3Glances 90.9</cell><cell>57.5</cell><cell>78.6</cell><cell>9.0</cell><cell>13.8</cell><cell>34.6</cell><cell>16.8</cell><cell>42.8</cell><cell>85.3</cell><cell>39.9</cell><cell>83.7</cell><cell>42.2</cell><cell cols="2">0.0 73.1</cell><cell>0.0</cell><cell>5.4</cell><cell cols="3">0.2 0.0 35.0</cell><cell>37.3</cell></row><row><cell></cell><cell cols="2">3S-2Glances 94.0</cell><cell>67.6</cell><cell>83.0</cell><cell>16.4</cell><cell>24.7</cell><cell>39.1</cell><cell>23.7</cell><cell>47.1</cell><cell>87.0</cell><cell>41.7</cell><cell>87.9</cell><cell>50.7</cell><cell cols="2">2.2 81.1</cell><cell cols="2">3.6 18.7</cell><cell cols="3">5.4 2.8 49.6</cell><cell>43.5</cell></row><row><cell></cell><cell cols="2">1S-6Glances 85.0</cell><cell>34.0</cell><cell>67.6</cell><cell>0.2</cell><cell>0.3</cell><cell>17.1</cell><cell>0.6</cell><cell>15.4</cell><cell>80.4</cell><cell>30.0</cell><cell>74.8</cell><cell>20.9</cell><cell cols="2">0.0 45.2</cell><cell>0.0</cell><cell>0.0</cell><cell cols="2">0.0 0.0</cell><cell>1.4</cell><cell>24.9</cell></row><row><cell>S743</cell><cell cols="2">2S-3Glances 90.8</cell><cell>56.8</cell><cell>77.4</cell><cell>8.6</cell><cell>13.3</cell><cell>31.6</cell><cell>12.6</cell><cell>33.6</cell><cell>85.8</cell><cell>38.1</cell><cell>84.1</cell><cell>38.3</cell><cell cols="2">0.0 66.9</cell><cell>0.1</cell><cell>0.0</cell><cell cols="3">0.0 0.1 24.3</cell><cell>34.9</cell></row><row><cell></cell><cell cols="2">3S-2Glances 92.3</cell><cell>60.5</cell><cell>80.0</cell><cell>11.2</cell><cell>14.7</cell><cell>31.6</cell><cell>6.2</cell><cell>33.6</cell><cell>85.5</cell><cell>39.7</cell><cell>86.8</cell><cell>41.4</cell><cell cols="2">0.0 73.9</cell><cell>4.6</cell><cell>2.3</cell><cell cols="3">6.8 2.1 28.8</cell><cell>36.9</cell></row><row><cell></cell><cell cols="2">1S-6Glances 80.6</cell><cell>29.4</cell><cell>65.1</cell><cell>1.0</cell><cell>0.3</cell><cell>8.8</cell><cell>1.5</cell><cell>8.8</cell><cell>79.0</cell><cell>27.7</cell><cell>73.8</cell><cell>22.3</cell><cell cols="2">0.0 43.9</cell><cell>0.0</cell><cell>0.0</cell><cell cols="2">0.0 0.0</cell><cell>1.1</cell><cell>23.0</cell></row><row><cell>S371</cell><cell cols="2">2S-3Glances 88.6</cell><cell>51.4</cell><cell>74.3</cell><cell>5.9</cell><cell>10.4</cell><cell>26.1</cell><cell>0.9</cell><cell>28.3</cell><cell>83.8</cell><cell>36.5</cell><cell>82.7</cell><cell>37.3</cell><cell cols="2">0.0 66.7</cell><cell>0.6</cell><cell>6.3</cell><cell cols="3">2.4 0.0 28.8</cell><cell>33.2</cell></row><row><cell></cell><cell cols="2">3S-2Glances 90.7</cell><cell>56.0</cell><cell>78.1</cell><cell>12.0</cell><cell>12.0</cell><cell>26.8</cell><cell>4.5</cell><cell>26.1</cell><cell>83.6</cell><cell>33.6</cell><cell>85.4</cell><cell>38.5</cell><cell cols="2">0.0 70.7</cell><cell>3.8</cell><cell>3.5</cell><cell cols="3">0.0 0.2 27.6</cell><cell>34.4</cell></row><row><cell></cell><cell cols="2">1S-6Glances 80.0</cell><cell>18.2</cell><cell>59.1</cell><cell>0.0</cell><cell>0.0</cell><cell>6.0</cell><cell>0.2</cell><cell>2.9</cell><cell>73.3</cell><cell>26.0</cell><cell>72.0</cell><cell>8.6</cell><cell cols="2">0.0 35.7</cell><cell>0.8</cell><cell>0.0</cell><cell cols="2">0.0 0.0</cell><cell>0.0</cell><cell>20.2</cell></row><row><cell>S185</cell><cell cols="2">2S-3Glances 84.8</cell><cell>39.5</cell><cell>69.3</cell><cell>3.6</cell><cell>0.4</cell><cell>7.8</cell><cell>0.0</cell><cell>12.8</cell><cell>78.8</cell><cell>32.7</cell><cell>79.9</cell><cell>19.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">For all the baselines, we use the Nesterov momentum of 0.9 for the SGD<ref type="bibr" target="#b96">[94]</ref> optimizer by following<ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b55">55,</ref><ref type="bibr" target="#b48">48,</ref><ref type="bibr" target="#b98">[96]</ref><ref type="bibr" target="#b99">[97]</ref><ref type="bibr" target="#b100">[98]</ref>. For the IkshanaNet and its variants, we use the Nesterov momentum of 0.7 for the SGD<ref type="bibr" target="#b96">[94]</ref> optimizer by tuning with several values such as 0.5, 0.6, 0.7, 0.8, and 0.9, i.e., the only hyper-parameter tuning step in this work. In our preliminary experiments, we observe that the training of IkshanaNet is unstable with 0.9 momentum. We hypothesize that this phenomenon is due to the small size of IkshanaNet compared to baseline networks<ref type="bibr" target="#b1">2</ref> For the baselines, ResNet-101<ref type="bibr" target="#b48">[48]</ref>, DenseNet-161<ref type="bibr" target="#b55">[55]</ref>, and HRNet-V2<ref type="bibr" target="#b104">[105]</ref>, we use the ImageNet<ref type="bibr" target="#b27">[27]</ref> pre-trained weights. Because in the existing literature, the architectures<ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b104">105]</ref> used an ImageNet pertained network as a feature extractor and reported the results by using pre-trained weights only. However, in the case of IkshanaNet and U-Net<ref type="bibr" target="#b15">[16]</ref> no pre-training is done. Since this work addresses the requirement of massive data, this provides strong motivation against pre-training.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Same as section 4.2.1, except for U-Net<ref type="bibr" target="#b15">[16]</ref> and IkshanaNet-12G, we use the ImageNet<ref type="bibr" target="#b27">[27]</ref> pre-trained weights for all the networks in the Set-3.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Framing pictures: The role of knowledge in automatized encoding and memory for gist</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alinda</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of experimental psychology: General</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">316</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Journal of experimental psychology: human learning and memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1976" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">509</biblScope>
		</imprint>
	</monogr>
	<note>Short-term conceptual memory for pictures</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rapid conceptual identification of sequentially presented pictures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helene</forename><surname>Intraub</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">604</biblScope>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modeling the shape of the scene: A holistic representation of the spatial envelope</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="145" to="175" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Gist of the scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurobiology of attention</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="251" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Eye movements in reading and information processing: 20 years of research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keith</forename><surname>Rayner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological bulletin</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">372</biblScope>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recognition-by-components: a theory of human image understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irving</forename><surname>Biederman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">115</biblScope>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Diagnostic colors mediate scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><forename type="middle">G</forename><surname>Schyns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="176" to="210" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Human gaze control during real-world scene perception</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Henderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="498" to="504" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Perception of objects in natural scenes: is it really attention free</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Karla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Treisman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1476</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">What do we perceive in a glance of a real-world scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asha</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christof</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="10" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">E</forename><surname>Ilya Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hinton</surname></persName>
		</author>
		<idno>25(10.1145</idno>
	</analytic>
	<monogr>
		<title level="j">Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="page">3065386</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Segnet: A deep convolutional encoder-decoder architecture for image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Badrinarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Kendall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="2481" to="2495" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojuan</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2881" to="2890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Object-contextual representations for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020</title>
		<editor>Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="173" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Gated-scnn: Gated shape cnns for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Towaki</forename><surname>Takikawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Acuna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>ICCV</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Segfix: Model-agnostic boundary refinement for segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="489" to="506" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Segmentation and recognition using structure from motion point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Brostow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Fauqueur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cipolla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV (1)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="44" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The cityscapes dataset for semantic urban scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Cordts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Rehfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Enzweiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Benenson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uwe</forename><surname>Franke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3213" to="3223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Scene parsing through ade20k dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adela</forename><surname>Barriuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5122" to="5130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Imagenet: A largescale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">U-net and its variants for medical image segmentation: theory and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nahian</forename><surname>Siddique</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paheding</forename><surname>Sidike</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Elkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Devabhaktuni</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.01118</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep interactive object selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="373" to="381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with prototype learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nanqing</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Conditional networks for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Rakelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alyosha</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations, ICLR</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Workshop Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">SML: semantic meta-learning for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayyappa</forename><surname>Kumar Pambala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Titir</forename><surname>Dutta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soma</forename><surname>Biswas</surname></persName>
		</author>
		<idno>abs/2009.06680</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Differentiable meta-learning model for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pinzhuo</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangkai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="12087" to="12094" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">One-shot learning for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amirreza</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shray</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="167" to="168" />
		</imprint>
	</monogr>
	<note>Irfan Essa, and Byron Boots</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Sg-one: Similarity guidance network for one-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunchao</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="3855" to="3865" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Panet: Few-shot image semantic segmentation with prototype alignment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaixin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Hao Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingtian</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daquan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Canet: Class-agnostic segmentation networks with iterative refinement and attentive few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Few-shot semantic segmentation with democratic attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haochen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutao</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yandan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianbin</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiantong</forename><surname>Zhen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 -16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">12358</biblScope>
			<biblScope unit="page" from="730" to="746" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XIII</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Pyramid graph networks with connection attentions for region-based one-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiushuang</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyao</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Prototype mixture models for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbin</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixiang</forename><surname>Ye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 -16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">12353</biblScope>
			<biblScope unit="page" from="763" to="778" />
		</imprint>
	</monogr>
	<note>Proceedings, Part VIII</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Meaning in visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Potter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">187</biblScope>
			<biblScope unit="issue">4180</biblScope>
			<biblScope unit="page" from="965" to="966" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">From blobs to boundary edges: Evidence for time-and spatial-scale-dependent scene recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Philippe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Schyns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological science</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="195" to="200" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Coarse blobs or fine edges? evidence that information diagnosticity changes the perception of complex visual stimuli</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aude</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><forename type="middle">G</forename><surname>Schyns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive psychology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="72" to="107" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A logical calculus of the ideas immanent in nervous activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Warren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walter</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pitts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The bulletin of mathematical biophysics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="115" to="133" />
			<date type="published" when="1943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning representations by back-propagating errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>David E Rumelhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald J</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">nature</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">6088</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The perceptron: a probabilistic model for information storage and organization in the brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Rosenblatt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">386</biblScope>
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Network in network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations</title>
		<meeting><address><addrLine>Banff, AB, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-04-14" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1800" to="1807" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Phoneme recognition using time-delay neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Waibel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shikano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Acoustics, Speech, and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="339" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Receptive fields, binocular interaction and functional architecture in the cat&apos;s visual cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hubel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Torsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wiesel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of physiology</title>
		<imprint>
			<biblScope unit="volume">160</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">106</biblScope>
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Neocognitron: A neural network model for a mechanism of visual pattern recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunihiko</forename><surname>Fukushima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takayuki</forename><surname>Sei Miyake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on systems, man, and cybernetics</title>
		<imprint>
			<date type="published" when="1983" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="826" to="834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Laurens van der Maaten, and Kilian Weinberger. Multi-scale dense networks for resource efficient image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danlu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianhong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Bridging the gaps between residual learning, recurrent neural networks and visual cortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qianli</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomaso</forename><surname>Poggio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1604.03640</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyeonwoo</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bohyung</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1520" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">RefineNet: Multi-path refinement networks for high-resolution semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Refinenet: Multi-path refinement networks for dense prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guosheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fayao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><surname>Reid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">The one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Drozdzal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1175" to="1183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Gated feedback refinement network for dense image labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mrigank</forename><surname>Md Amirul Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rochan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Bruce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2117" to="2125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Path aggregation network for instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifang</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8759" to="8768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with deep convolutional nets and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-05-07" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iasonas</forename><surname>Kokkinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="834" to="848" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Rethinking atrous convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<idno>abs/1706.05587</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Denseaspp for semantic segmentation in street scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maoke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3684" to="3692" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Parsenet: Looking wider to see better</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<idno>abs/1506.04579</idno>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Attention to scale: Scale-aware semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3640" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Ocnet: Object context network for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1809.00916</idno>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Context encoding for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Zigzagnet: Fusing top-down and bottom-up context for object segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Di</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingguo</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siting</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanfeng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7482" to="7491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title level="m" type="main">Acfnet: Attentional class feature network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibin</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingtuo</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feifei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Errui</forename><surname>Ding</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
				<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6797" to="6806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Co-occurrent features in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenguang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="548" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Global aggregation then local distribution in fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangtai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ansheng</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maoke</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuiyuan</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhai</forename><surname>Tong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Cars can&apos;t fly up in the sky: Improving urbanscene segmentation via height-driven attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungha</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joanne</forename><forename type="middle">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaegul</forename><surname>Choo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9373" to="9383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">High-for-low and low-for-high: Efficient boundary detection from deep object features and its applications to high-level vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gedas</forename><surname>Bertasius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2015-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Semantic image segmentation with task-specific edge detection using cnns and a discriminatively trained domain transform</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Boundary-aware feature propagation for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henghui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xudong</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ai</forename><forename type="middle">Qun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><surname>Magnenat Thalmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Efficient segmentation: Learning downsampling near semantic boundaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitrii</forename><surname>Marin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zijian</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Vajda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priyam</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><forename type="middle">S</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuri</forename><surname>Boykov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
				<title level="m">IEEE/CVF International Conference on Computer Vision, ICCV 2019</title>
		<meeting><address><addrLine>Seoul, Korea (South)</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-11-02" />
			<biblScope unit="page" from="2131" to="2141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Generalized few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
		<idno>abs/2010.05210</idno>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Meta-seg: A generalized meta-learning framework for multi-class few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiying</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tengfei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhui</forename><surname>Diao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaode</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="166109" to="166121" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Dynamic extension nets for few-shot semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyi</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minqian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th ACM International Conference on Multimedia, MM &apos;20</title>
		<meeting>the 28th ACM International Conference on Multimedia, MM &apos;20<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1441" to="1449" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Prior guided feature enrichment network for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuotao</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiyu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaya</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Adaptive prototype learning and allocation for few-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Sevilla-Lara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonghyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joongkyu</forename><surname>Kim</surname></persName>
		</author>
		<idno>abs/2104.01893</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Brinet: Towards bridging the intra-class and inter-class gaps in one-shot segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianghui</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bairun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinchi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaige</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luping</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">31st British Machine Vision Conference 2020</title>
		<meeting><address><addrLine>UK</addrLine></address></meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Rectified linear units improve restricted boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinod</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Icml</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Pytorch: An imperative style, highperformance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">A stochastic approximation method. The annals of mathematical statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herbert</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sutton</forename><surname>Monro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1951" />
			<biblScope unit="page" from="400" to="407" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">A method for solving the convex programming problem with convergence rate o (1/k?2)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yurii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nesterov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Dokl. akad. nauk Sssr</title>
		<imprint>
			<biblScope unit="volume">269</biblScope>
			<biblScope unit="page" from="543" to="547" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
	<note>Mobilenetv2: Inverted residuals and linear bottlenecks</note>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019<address><addrLine>Long Beach, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019-06-15" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Designing network design spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><forename type="middle">Prateek</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10428" to="10436" />
		</imprint>
	</monogr>
	<note>Kaiming He, and Piotr Doll?r</note>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Hrnet-semantic-segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<ptr target="https://github.com/HRNet/HRNet-Semantic-Segmentation" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5987" to="5995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Segmentation models pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavel</forename><surname>Yakubovskiy</surname></persName>
		</author>
		<ptr target="https://github.com/qubvel/segmentation_models.pytorch" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<monogr>
		<title level="m" type="main">High-resolution representations for labeling pixels and regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<idno>abs/1904.04514</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title/>
		<ptr target="https://github.com/sovrasov/flops-counter.pytorch" />
	</analytic>
	<monogr>
		<title level="j">Vladislav Sovrasov. flops-counter</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title/>
		<ptr target="https://github.com/alexgkendall/SegNet-Tutorial" />
	</analytic>
	<monogr>
		<title level="j">Alex Kendall. Segnet-tutorial</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">In-place activated batchnorm for memory-optimized training of dnns</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Samuel Rota</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Bul?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
