<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BoT-SORT: Robust Associations Multi-Pedestrian Tracking</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nir</forename><surname>Aharon</surname></persName>
							<email>niraharon1@mai1.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering</orgName>
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Orfaig</surname></persName>
							<email>royorfaig@tauex.tau.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering</orgName>
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben-Zion</forename><surname>Bobrovsky</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical Engineering</orgName>
								<orgName type="institution">Tel-Aviv University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">BoT-SORT: Robust Associations Multi-Pedestrian Tracking</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Mutli-object tracking</term>
					<term>Tracking-by-detection</term>
					<term>Camera-motion-compensation</term>
					<term>Re-identification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="figure">Figure 1</ref><p>: IDF1-MOTA-HOTA comparisons of state-of-the-art trackers with our proposed BoT-SORT and BoT-SORT-ReID on the MOT17 and MOT20 test sets. The x-axis is IDF1, the y-axis is MOTA, and the radius of the circle is HOTA. Ours BoT-SORT-ReID and our simpler version BoT-SORT achieve the best IDF1, MOTA, and HOTA performance from all other trackers on the leadboards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Abstract</head><p>The goal of multi-object tracking (MOT) is detecting and tracking all the objects in a scene, while keeping a unique identifier for each object. In this paper, we present a new robust state-of-the-art tracker, which can combine the advantages of motion and appearance information, along with camera-motion compensation, and a more accurate Kalman filter state vector. Our new trackers BoT-SORT, and BoT-SORT-ReID rank first in the datasets of MOTChallenge <ref type="bibr" target="#b28">[29,</ref><ref type="bibr" target="#b10">11]</ref> on both MOT17 and MOT20 test sets, in terms of all the main MOT metrics: MOTA, IDF1, and HOTA. For MOT17: 80.5 MOTA, 80.2 IDF1, and 65.0 HOTA are achieved. The source code and the pre-trained models are available at https://github.com/NirAharon/BOT-SORT</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Multi-object tracking (MOT) aims to detect and estimate the spatial-temporal trajectories of multiple objects in a video stream. MOT is a fundamental problem for numerous applications, such as autonomous driving, video surveillance, and more.</p><p>Currently, tracking-by-detection has become the most effective paradigm for the MOT task <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b57">58]</ref>. Tracking-by-detection contains an object detection step, followed by a tracking step. The tracking step is usually built from two main parts: (1) Motion model and state estimation for predicting the bounding boxes of the tracklets in the following frames. A Kalman filter (KF) <ref type="bibr" target="#b7">[8]</ref>, is the popular choice for this task. <ref type="bibr" target="#b1">(2)</ref> Associating the new frame detections with the current set of tracks. Two leading approaches are used for tackling the association task: (a) Localization of the object, mainly intersection-over-union (IoU) between the predicted tracklet bounding box and the detection bounding box. (b) Appearance model of the ob-ject and solving a re-identification (Re-ID) task. Both approaches are quantified into distances and used for solving the association task as a global assignment problem.</p><p>Many of the recent tracking-by-detection works based their study on the SORT <ref type="bibr" target="#b2">[3]</ref>, DeepSORT <ref type="bibr" target="#b47">[48]</ref> and JDE <ref type="bibr" target="#b45">[46]</ref> approaches. We have recognized some limitations in these "SORT-like" algorithms, which we will describe next.</p><p>Most SORT-like algorithms adopt the Kalman filter with the constant-velocity model assumption as the motion model. The KF is used for predicting the tracklet bounding box in the next frame for associating with the detection bounding box, and for predicting the tracklet state in case of occlusions or missed detections.</p><p>The use of the KF state estimation as the output for the tracker leads to a sub-optimal bounding box shape, compared to the detections driven by the object-detector. Most of the recent methods used the KF's state characterization proposed in the classic tracker DeepSORT <ref type="bibr" target="#b47">[48]</ref>, which tries to estimate the aspect ratio of the box instead of the width, which leads to inaccurate width size estimations.</p><p>SORT-like IoU-based approaches mainly depend on the quality of the predicted bounding box of the tracklet. Hence, in many complex scenarios, predicting the correct location of the bounding box may fail due to camera motion, which leads to low overlap between the two related bounding boxes and finally to low tracker performance. We overcome this by adopting conventional image registration to estimate the camera motion, and properly correcting the Kalman filter. We denote this as Camera Motion Compensation (CMC).</p><p>Localization and appearance information (i.e. reidentification) within the SORT-like algorithms, in many cases lead to a trade-off between the tracker's ability to detect (MOTA) and the tracker's ability to maintain the correct identities over time (IDF1). Using IoU usually achieves better MOTA while Re-ID achieves higher IDF1.</p><p>In this work, we propose new trackers which outperform all leading trackers in all the main MOT metrics <ref type="figure">(Figure 1</ref>) for the MOT17 and MOT20 challenges, by addressing the above SORT-like tracker's limitations and integrating them into the novel ByteTrack <ref type="bibr" target="#b57">[58]</ref>. In particular, the main contributions of our work can be summarized as follows:</p><p>? We show that by adding improvements, such as a camera motion compensation-based features tracker and a suitable Kalman filter state vector for better box localization, tracking-by-detection trackers can be significantly improved. ? We present a new simple yet effective method for IoU and ReID's cosine-distance fusion for more robust associations between detections and tracklets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>With the rapid improvements in object detection <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b62">63]</ref> over the past few years, multi-object trackers have gained momentum. More powerful detectors lead to the higher tracking performance and reduce the need for complex trackers. Thus, tracking-by-detection trackers mainly focus on improving data association, while exploiting deep learning trends <ref type="bibr" target="#b57">[58,</ref><ref type="bibr" target="#b11">12]</ref>.</p><p>Motion Models. Most of the recent tracking-by-detection algorithms are based on motion models. Recently, the famous Kalman filter <ref type="bibr" target="#b7">[8]</ref> with constant-velocity model assumption, tends to be the popular choice for modeling the object motion <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b17">18]</ref>. Many studies use more advanced variants of the KF, for example, the NSA-Kalman filter <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b11">12]</ref>, which merges the detection score into the KF. Many complex scenarios include camera motion, which may lead to non-linear motion of the objects and cause incorrect KF's predictions. Therefore, many researchers adopted camera motion compensation (CMC) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b12">13]</ref> by aligning frames via image registration using the Enhanced Correlation Coefficient (ECC) maximization <ref type="bibr" target="#b14">[15]</ref> or matching features such as ORB <ref type="bibr" target="#b35">[36]</ref>.</p><p>Appearance models and re-identification. Discriminating and re-identifying (ReID) objects by deep-appearance cues <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b27">28]</ref> has also become popular, but falls short in many cases, especially when scenes are crowded, due to partial occlusions of persons. Separate appearance-based trackers crop the frame detection boxes and extract deep appearance features using an additional deep neural network <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b11">12]</ref>. They enjoy advanced training techniques but demand high inference computational costs. Recently, several joint trackers <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b43">44]</ref> have been proposed to train detection and some other components jointly, e.g., motion, embedding, and association models. The main benefit of these trackers is their low computational cost and comparable performance.</p><p>Lately, several recent studies <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b57">58]</ref> have abandoned appearance information and relied only on highperformance detectors and motion information which achieve high running speed and state-of-the-art performance. In particular ByteTrack <ref type="bibr" target="#b57">[58]</ref>, which exploits the low score detection boxes by matching the high confidence detections followed by another association with the low confident detections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>In this section, we present our three main modifications and improvements for the multi-object tracking-based tracking-by-detection methods. By integrating these into the celebrated ByteTrack <ref type="bibr" target="#b57">[58]</ref>, we present two new stateof-the-art trackers, BoT-SORT and BoT-SORT-ReID. BoT-SORT-ReID is a BoT-SORT extension including a reidentification module. Refer to Appendix A for pseudocode of ours BoT-SORT-ReID. The pipeline of our algorithm is presented in <ref type="figure" target="#fig_0">Fig 2.</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Kalman Filter</head><p>To model the object's motion in the image plane, it is widely common to use the discrete Kalman filter with a constant-velocity model <ref type="bibr" target="#b47">[48]</ref>, see Appendix B for details.</p><p>In SORT <ref type="bibr" target="#b2">[3]</ref> the state vector was chosen to be a seven-tuple, x = [x c , y c , s, a,? c ,? c ,?] , where (x c , y c ) are the 2D coordinates of the object center in the image plane. s is the bounding box scale (area) and a is the bounding box aspect ratio. In more recent trackers <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b11">12]</ref> the state vector has changed to an eight-tuple, x = [x c , y c , a, h,? c ,? c ,?,?] . However, we found through experiments, that estimating the width and height of the bounding box directly, results in better performance. Hence, we choose to define the KF's state vector as in Eq. (1), and the measurement vector as in Eq. (2). The matrices Q, R were chosen in SORT <ref type="bibr" target="#b2">[3]</ref> to be time indepent, however in DeepSORT <ref type="bibr" target="#b47">[48]</ref> it was suggested to choose Q, R as functions of some estimated elements and some measure-ment elements, as can be seen in their Github source code 1 . Thus, using this choice of Q and R results in time-dependent Q k and R k . Following our changes in the KF's state vector, the process noise covariance Q k and measurement noise covariance R k matrices were modified, see Eq. (3), (4). Thus we have:</p><formula xml:id="formula_0">x k = [x c (k), y c (k), w(k), h(k), x c (k),? c (k),?(k),?(k)]</formula><p>(1)</p><formula xml:id="formula_1">z k = [z xc (k), z yc (k), z w (k), z h (k)]<label>(2)</label></formula><formula xml:id="formula_2">Q k = diag (? p?k?1|k?1 ) 2 , (? p?k?1|k?1 ) 2 , (? p?k?1|k?1 ) 2 , (? p?k?1|k?1 ) 2 , (? v?k?1|k?1 ) 2 , (? v?k?1|k?1 ) 2 , (? v?k?1|k?1 ) 2 , (? v?k?1|k?1 ) 2 (3) R k = diag (? m?k|k?1 ) 2 , (? m?k|k?1 ) 2 , (? m?k|k?1 ) 2 , (? m?k|k?1 ) 2<label>(4)</label></formula><p>We choose the noise factors as in <ref type="bibr" target="#b47">[48]</ref> to be ? p = 0.05, ? v = 0.00625, and ? m = 0.05, since our frame rate is also 30 FPS. Note, that we modified Q and R according to our slightly different state vector x. In the case of track-loss, long predictions may result in box shape deformation, so proper logic is implemented, similar to <ref type="bibr" target="#b57">[58]</ref>. In the ablation study section, we show experimentally that those changes leads to higher HOTA. Strictly speaking, the reasons for the overall HOTA improvement is not clear to us. We assume that our modification of the KF contributes to improving the fit of the bounding box width to the object, as can be seen in <ref type="figure" target="#fig_1">Figure 3</ref>.  <ref type="bibr" target="#b47">[48]</ref> (dashed blue) and the proposed Kalman filter (green). It seems that the bounding box width produced by the proposed KF fits more accurately to object. The dashed blue bounding box intersects the objects legs (in red), as the green bounding box reach to the desire width.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Camera Motion Compensation (CMC)</head><p>Tracking-by-detection trackers rely heavily on the overlap between the predicted tracklets bounding boxes and the detected ones. In a dynamic camera situation, the bounding box location in the image plane can shift dramatically, which might result in increasing ID switches or falsenegatives, <ref type="figure" target="#fig_3">Figure 4</ref>. Trackers in static camera scenarios can also be affected due to motion by vibrations or drifts caused by the wind, as in MOT20, and in very crowded scenes IDswitches can be a real concern. The motion patterns in the video can be summarized as rigid motion, from the changing of the camera pose, and the non-rigid motion of the objects, e.g. pedestrians. With the lack of additional data on camera motion, (e.g. navigation, IMU, etc.) or the camera intrinsic matrix, image registration between two adjacent frames is a good approximation to the projection of the rigid motion of the camera onto the image plane. We follow the global motion compensation (GMC) technique used in the OpenCV <ref type="bibr" target="#b6">[7]</ref> implementation of the Video Stabilization module with affine transformation. This image registration method is suitable for revealing the background motion. First, extraction of image keypoints <ref type="bibr" target="#b38">[39]</ref> takes place, followed by sparse optical flow <ref type="bibr" target="#b5">[6]</ref> for feature tracking with translation-based local outlier rejection. The affine matrix A k k?1 ? R 2?3 was solved using RANSAC <ref type="bibr" target="#b15">[16]</ref>. The use of sparse registration techniques allows ignoring the dynamic objects in the scene based on the detections and thus having the potential of estimating the background motion more accurately.</p><p>For transforming the prediction bounding box from the coordinate system of frame k ? 1 to the coordinates of the next frame k, the calculated affine matrix A k k?1 was used, as will be described next.</p><p>The translation part of the transformation matrix only affects the center location of the bounding box, while the other part affects all the state vector and the noise matrix <ref type="bibr" target="#b46">[47]</ref>. The camera motion correction step can be performed by the following equations:</p><formula xml:id="formula_3">A k k?1 = M 2x2 |T 2x1 = a 11 a 12 a 13 a 21 a 22 a 23 (5) M k k?1 = ? ? ? ? M 0 0 0 0 M 0 0 0 0 M 0 0 0 0 M ? ? ? ? ,T k k?1 = ? ? ? ? ? ? ? ? ? a 13 a 23 0 0 . . . 0 ? ? ? ? ? ? ? ? ? (6) x k|k?1 =M k k?1xk|k?1 +T k k?1 (7) P k|k?1 =M k k?1 P k|k?1M k k?1<label>(8)</label></formula><p>When M ? R 2?2 is a matrix containing the scale and rotations part of the affine matrix A, and T contains the translation part. We use a mathematical trick by defin-ingM</p><formula xml:id="formula_4">k k?1 ? R 8?8 andT k k?1 ? R 8 .</formula><p>Moreover,x k|k?1 , x k|k?1 is the KF's predicted state vector at time k before and after compensation of the camera motion respectively. P k|k?1 , P k|k?1 is the KF's predicated covariance matrix before and after correction respectively. Afterwards, we us? x k|k?1 ,P k|k?1 in the Kalman filter update step as follow:</p><formula xml:id="formula_5">K k = P k|k?1 H k (H k P k|k?1 H k + R k ) ?1 x k|k =x k|k?1 + K k (z k ? H kx k|k?1 ) P k|k = (I ? K k H k )P k|k?1<label>(9)</label></formula><p>In high velocities scenarios, full correction of the state vector, including the velocities term, is essential. When the camera is changing slowly compared to the frame rate, the correction of Eq. 8 can be omitted. By applying this method our tracker becomes robust to camera motion.</p><p>After compensating for the rigid camera motion, and under the assumption that the position of an object only slightly change from one frame to the next. In online high frame rate applications when missing detections occur, track extrapolations can be perform using the KF's prediction step, which may cause more continuous viewing of tracks with slightly higher MOTA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">IoU -Re-ID Fusion</head><p>To exploit the recent developments in deep visual representation, we integrated appearance features into our tracker. To extract these Re-ID features, we adopted the stronger baseline on top of BoT (SBS) <ref type="bibr" target="#b27">[28]</ref> from the Fas-tReID library, <ref type="bibr" target="#b18">[19]</ref> with the ResNeSt50 <ref type="bibr" target="#b55">[56]</ref> as a backbone. We adopt the exponential moving average (EMA) mechanism for updating the matched tracklets appearance state e k i for the i-th tracklet at frame k, as in <ref type="bibr" target="#b45">[46]</ref>, Eq. 10.</p><formula xml:id="formula_6">e k i = ?e k?1 i + (1 ? ?)f k i<label>(10)</label></formula><p>Where f k i is the appearance embedding of the current matched detection and ? = 0.9 is a momentum term. Because appearance features may be vulnerable to crowds, occluded and blurred objects, for maintaining correct feature vectors, we take into account only high confidence detections. For matching between the averaged tracklet appearance state e k i and the new detection embedding vector f k j , cosine similarity is measured. We decided to abandon the common weighted sum between the appearance cost A a and motion cost A m for calculating the cost matrix C, Eq. 11.</p><formula xml:id="formula_7">C = ?A a + (1 ? ?)A m ,<label>(11)</label></formula><p>Where the weight factor ? is usually set to 0.98. We developed a new method for combining the motion and the appearance information, i.e. the IoU distance matrix and the cosine distance matrix. First, low cosine similarity or far away candidates, in terms of IoU's score, are rejected. Then, we use the minimum in each element of the matrices as the final value of our cost matrix C. Our IoU-ReID fusion pipeline can be formulated as follows:</p><formula xml:id="formula_8">d cos i,j = 0.5 ? d cos i,j , (d cos i,j &lt; ? emb ) ? (d iou i,j &lt; ? iou ) 1, otherwise (12) C i,j = min{d iou i,j ,d cos i,j }<label>(13)</label></formula><p>Where C i,j is the (i, j) element of cost matrix C. d iou i,j is the IoU distance between tracklet i-th predicted bounding box and the j-th detection bounding box, representing the motion cost. d cos i,j is the cosine distance between the average tracklet appearance descriptor i and the new detection descriptor j.d cos i,j is our new appearance cost. ? iou is a proximity threshold, set to 0.5, used to reject unlikely pairs of tracklets and detections. ? emb is the appearance threshold, which is used to separate positive association of tracklet appearance states and detections embedding vectors from the negatives ones. We set ? emb to 0.25 following <ref type="figure" target="#fig_2">Figure 5</ref>. The linear assignment problem of the high confidence detections i.e. first association step, was solved using the Hungarian algorithm <ref type="bibr" target="#b21">[22]</ref> and based on our cost matrix C, constructed with Eq. 13. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Settings</head><p>Datasets. Experiments were conducted on two of the most popular benchmarks in the field of multi-object tracking for pedestrian detection and tracking in unconstrained environments: MOT17 <ref type="bibr" target="#b28">[29]</ref> and MOT20 <ref type="bibr" target="#b10">[11]</ref> datasets under the "private detection" protocol. MOT17 contains video sequences filmed with both static and moving cameras. While MOT20 contains crowded scenes. Both datasets contain training sets and test sets, without validation sets. For ablation studies, we follow <ref type="bibr" target="#b61">[62,</ref><ref type="bibr" target="#b57">58]</ref>, by using the first half of each video in the training set of MOT17 for training and the last half for validation.</p><p>Metrics. Evaluations were performed according to the widely accepted CLEAR metrics <ref type="bibr" target="#b1">[2]</ref>. Including Multiple-Object Tracking Accuracy (MOTA), False Positive (FP), False Negative (FN), ID Switch (IDSW), etc., IDF1 <ref type="bibr" target="#b34">[35]</ref> and Higher-Order Tracking Accuracy (HOTA) <ref type="bibr" target="#b26">[27]</ref> to evaluate different aspects of the detection and tracking performance. Tracker speed (FPS) in Hz was also evaluated, although run time may vary significantly for different  <ref type="figure">Figure (b.1)</ref> presents a scenario in which neglecting the camera motion will be expressed in IDSWs or FN. In contrast, in the opposite <ref type="figure" target="#fig_0">figure (b.2)</ref>, the predictions fit their desirable location, and the association will succeed. The images are from the MOT17-13 sequence, which contains camera motion due to the vehicle turning right.  <ref type="bibr" target="#b19">[20]</ref> with tracking threshold of 0.6, new track threshold of 0.7 and, first association matching threshold of 0.8. <ref type="table">Table 1</ref>: Ablation study on the MOT17 validation set for basic strategies, i.e., Updated Kalman filter (KF), camera motion compensation (CMC), output tracks prediction (Pred), with ReID module (w/ReID). All results obtained with the same parameters set. (best in bold).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>hardware. MOTA is computed based on FP, FN, and IDSW. MOTA focuses more on detection performance because the amount of FP and FN are more significant than IDs. IDF1 evaluates the identity association performance. HOTA explicitly balances the effect of performing accurate detection, association, and localization into a single unified metric.</p><p>Implementation details. All the experiments were implemented using PyTorch and ran on a desktop with 11th Gen Intel(R) Core(TM) i9-11900F @ 2.50GHz and NVIDIA GeForce RTX 3060 GPU. For fair comparisons, we directly apply the publicly available detector of YOLOX <ref type="bibr" target="#b16">[17]</ref>, trained by <ref type="bibr" target="#b57">[58]</ref> for MOT17, MOT20, and ablation study on MOT17. For the feature extractor, we trained Fas-tReID's <ref type="bibr" target="#b18">[19]</ref> SBS-50 model for MOT17 and MOT20 with their default training strategy, for 60 epochs. While we trained on the first half of each sequence and tested on the rest. The same tracker parameters were used throughout the experiments. The default detection score threshold ? was 0.6, unless otherwise specified. In the linear assignment step, if the detection and the tracklet similarity were smaller than 0.2, the matching was rejected. For the lost tracklets, we kept them for 30 frames in case it appeared again. Linear tracklet interpolation, with a max interval of 20, was performed to compensate for in-perfections in the ground truth, as in <ref type="bibr" target="#b57">[58]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Ablation Study</head><p>Components Analysis. Our ablation study mainly aims to verify the performance of our bag-of-tricks for MOT and quantify how much each component contributed. MOTChallenge official organization limits the number of attempts researchers can submit results to the test server. Thus, we used the MOT17 validation set, i.e. the second half of the train set of each sequence. To avoid the possible influence caused by the detector, we used Byte-Track's YOLOX-X MOT17 ablation study weights which were trained on CrowdHuman <ref type="bibr" target="#b37">[38]</ref> and MOT17 first half of the train sequences. The same tracking parameters were used for all the experiments, as described in the Implementation details section. <ref type="table">Table 1</ref> summarize the path from the outstanding ByteTrack to BoT-SORT and BoT-SORT-ReID. The Baseline represents our re-implemented Byte-Track, without any guidance from addition modules.</p><p>Re-ID module. Appearance descriptors are an intuitive way of associating the same person over time. It has the potential to overcome the large displacement and long occlusions. Most recent attempts using Re-ID with cosine similarity, outperform simply using IoU for high frame rate videos case. In this section, we compare different strategies for combining the motion and the visual embedding in the first matching association step of our tracker, on the MOT17 validation set, <ref type="table">Table 2</ref>. IoU alone outperforms the Re-ID-based methods, excluding our proposed method. Hence, for low resources applications, IoU is a good design choice. Ours IoU-ReID combination with IoU masking achieves the highest results in terms of MOTA, IDF1, and HOTA, and benefits from the motion and the appearance information.</p><p>Online vs Offline. Many applications are required to analyze events retrospectively. In these cases, the use of offline methods, such as global-link <ref type="bibr" target="#b11">[12]</ref>, can significantly improve the results. In this study, we only focus on improving the online part of the tracker. For fair comparisons in the MOTChallenge benchmarks, we use simple linear tracklet interpolation, as in <ref type="bibr" target="#b57">[58]</ref>.</p><p>Current MOTA. One of the challenges of developing a multi-object tracker is to identify tracker failures using the standard MOT metrics. In many cases, finding the specific reasons or even the time range for the tracker failure can be time-consuming. Hence, for analyzing the fall-backs and difficulties of multi-object trackers we evolve the MOTA metric to time or frame-dependent MOTA, which we call Current-MOTA (cMOTA). cMOTA(t k ) is simply the MOTA from t = t 0 to t = t k . e.g. cMOTA(T ) is equal to the classic MOTA, calculated over all the sequences, where T is the  <ref type="table">Table 2</ref>: Ablation study on the MOT17 validation set for different similarities strategies for exploit the ReID module (w/ReID). Masking indicates strategy for rejecting distant associations. Ours proposed minimum between the IoU and the cosine achieve the highest scores (best in bold). <ref type="figure">Figure 6</ref>: Example of the advantage of current-MOTA (cMOTA) graph in rotating camera scene from MOT17-13 validation set. By examine the cMOTA graph, one can see (in red), that the MOTA drops rapidly from frame 400 to 470 and afterward the cMOTA reach plateau. In this case, by looking at the suspected frames which the cMOTA reveals, we can detect that the reason for the tracker failure is the rotation of the camera. By adding ours CMC (in green), the MOTA preserved high using the same detections and tracking parameters.</p><p>sequence length, Eq. 14.</p><formula xml:id="formula_9">cMOTA(t = T ) = MOTA<label>(14)</label></formula><p>This allows us to easily find cases where the tracker fails. The same procedure can be replay with any of the CLEAR matrices, e.g. IDF1, etc.. An example of the advantage of cMOTA can be found in <ref type="figure">Figure 6</ref>. Potentially, cMOTA can help to identify and explore many other tracker failure scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Benchmarks Evaluation</head><p>We compare our BoT-SORT and BoT-SORT-ReID state-of-the-art trackers on the test set of MOT17 and MOT20 under the private detection protocol in <ref type="table">Table 3</ref>, <ref type="table">Table 4</ref>, respectively. All the results are directly obtained from the official MOTChallenge evaluation server. Comparing FPS is difficult because the speed claimed by each method depends on the devices they are implemented on, and the time spent on detections is generally excluded for tracking-by-detection trackers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MOT17.</head><p>BoT-SORT-ReID and the simpler version, BoT-SORT, both outperform all other state-of-the-art trackers in all main metrics, i.e. MOTA, IDF1, and HOTA. BoT-SORT-ReID is the first tracker to achieve IDF1 above 80, <ref type="table">Table 3</ref>. The high IDF1 along with the high MOTA in diverse scenarios indicates that our tracker is robust and effective.  <ref type="table">Table 3</ref>: Comparison of the state-of-the-art methods under the "private detector" protocol on MOT17 test set. The best results are shown in bold. BoT-SORT and BoT-SORT-ReID ranks 2st and 1st respectively among all the MOT20 leadboard trackers.</p><p>MOT20. MOT20 is considered to be a difficult benchmark due to crowded scenarios and many occlusion cases. Even so, BoT-SORT-ReID ranks 1st in terms of MOTA, IDF1 and HOTA, <ref type="table">Table 4</ref>. Some other trackers were able to achieve the same results in one metric (e.g. the same MOTA or IDF1) but their other results were compromised. Our methods were able to significantly improve the IDF1 and the HOTA while preserving the MOTA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Limitations</head><p>BoT-SORT and BoT-SORT-ReID still have several limitations. In scenes with a high density of dynamic objects, the estimation of the camera motion may fail due to lack of background keypoints. Wrong camera motion may lead to unexpected tracker behavior. Another real-life application concern is the run time. Calculating the global motion of the camera can be time-consuming when large images need to be processed. But GMC run time is negligible compared to the detector inference time. Thus, multi-threading can be applied to calculating GMC, without any additional delays. Separated appearance trackers have relatively low running speed compared with joint trackers and several appearancefree trackers. We apply deep feature extraction only for high confidence detections to reduce the computational cost. If necessary, the feature extractor network can be merged into the detector head, in a joint-detection-embedding manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we propose an enhanced multi-object tracker with MOT bag-of-tricks for a robust association, named BoT-SORT, which ranks 1st in terms of MOTA, IDF1, and HOTA on MOT17 and MOT20 datasets among all other trackers on the leadboards. This method and its components can easily be integrated into other tracking-bydetection trackers. In addition, a new MOT investigation tool -cMOTA is introduced. We hope that this work will help to push forward the multiple-object tracking field.  <ref type="table">Table 4</ref>: Comparison of the state-of-the-art methods under the "private detector" protocol on MOT20 test set. The best results are shown in bold. BoT-SORT and BoT-SORT-ReID ranks 2st and 1st respectively among all the MOT17 leadboard trackers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgement</head><p>We thank Shlomo Shmeltzer Institute for Smart Transportation in Tel-Aviv University for their generous support of our Autonomous Mobile Laboratory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Kalman Filter Model</head><p>The Kalman filter <ref type="bibr" target="#b7">[8]</ref> goal is to try to estimate the state x ? R n given the measurements z ? R m and given a known x 0 , as k ? N + . In the task of object tracking, where no active control exists, the discrete-time Kalman filter is governed by the following linear stochastic difference equations:</p><p>x k = F k x k?1 + n k?1 <ref type="bibr" target="#b14">(15)</ref> </p><formula xml:id="formula_10">z k = H k x k + v k<label>(16)</label></formula><p>Where F k is the transition matrix from discrete-time k ? 1 to k. The observation matrix is H k . The random variables n k and v k represent the process and measurement noise respectively. They are assumed to be independent and identically distributed (i.i.d) with normal distribution.</p><formula xml:id="formula_11">n k ? N (0, Q k ), v k ? N (0, R k )<label>(17)</label></formula><p>The process noise covariance Q k and measurement noise covariance R k matrices might change with each time step. Kalman filter consists of a prediction step and update step. The entire Kalman filter can be summarized in the following recursive equations: </p><formula xml:id="formula_12">x k|k?1 = F kxk?1|k?1 P k|k?1 = F k P k?1|k?1 F k + Q k<label>(</label></formula><p>For proper choice of initial conditionx 0 and P 0 , see literature, e.g. <ref type="bibr" target="#b7">[8]</ref>, and more specifically refer to <ref type="bibr" target="#b57">[58]</ref>.</p><p>At each step k, KF predicts the prior estimate of stat? x k|k?1 and the covariance matrix P k|k?1 . KF updates the posterior state estimationx k|k given the observation z k and the estimated covariance P k|k , calculated based on the optimal Kalman gain K k .</p><p>The constant-velocity model matrices corresponding to the state vector and measurement vector defined in Eq. 1 and Eq. 2, present in Eq. 20. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Overview of ours BoT-SORT-ReID tracker pipeline. The online tracking region is the main part of ours tracker, and the post-processing region is optional addition, as in<ref type="bibr" target="#b57">[58]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Visualization of the bounding box shape compare with the widely-used Kalman filter</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Study for the value of the appearance threshold ? emb on the MOT17 validation set. FastReID's SBS-S50 model was trained on the first half of MOT17. Positive indicated the same ID from different time and negative indicates different ID. It can be seen from the histogram that 0.25 is appropriate choice for ? emb .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Visualization of the predicted tracklets bounding boxes, those predictions later used for association with the new detections BB based on maximum IoU criteria. (a.1), (b.1) show the KF's predictions. (a.2), (b.2) show the KF's prediction after our camera motion compensation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>18 )</head><label>18</label><figDesc>K k = P k|k?1 H k (H k P k|k?1 H k + R k ) ?1 x k|k =x k|k?1 + K k (z k ? H kxk|k?1 ) P k|k = (I ? K k H k )P k|k?1</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/nwojke/deep_sort</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="33">Return: TRemark: tracks rebirth<ref type="bibr" target="#b57">[58]</ref> is not shown in the algorithm for simplicity.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Appendix A. Pseudo-code of BoT-SORT-ReID Algorithm 1: Pseudo-code of BoT-SORT-ReID.</p><p>Input: A video sequence V; object detector Det; appearance (features) extractor Enc; high detection score threshold ? ; new track score threshold ? Output: Tracks T of the video 1 Initialization: </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tracking without bells and whistles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Meinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taixe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="941" to="951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Evaluating multiple object tracking performance: the clear mot metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bernardin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Stiefelhagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EURASIP Journal on Image and Video Processing</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Simple online and realtime tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Upcroft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICIP</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">High-speed tracking-by-detection without using image information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bochinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Eiselein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Yolov4: Optimal speed and accuracy of object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bochkovskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y.</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-Y</forename><forename type="middle">M</forename><surname>Liao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.10934</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Pyramidal implementation of the lucas kanade feature tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Bouguet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">The OpenCV Library. Dr. Dobb&apos;s Journal of Software Tools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Introduction to random signals and applied kalman filtering: with MATLAB exercises and solutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">Y C</forename><surname>Hwang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Wiley</publisher>
			<biblScope unit="page">13</biblScope>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>3rd ed</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Observation-centric sort: Rethinking sort for robust multiobject tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Khirodkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.14360</idno>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.00194</idno>
		<title level="m">Transmot: Spatial-temporal graph transformer for multiple object tracking</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rezatofighi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.09003</idno>
		<title level="m">Mot20: A benchmark for multi object tracking in crowded scenes</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.13514</idno>
		<title level="m">Strongsort: Make deepsort great again</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Giaotracker: A comprehensive framework for mcmot with global information and optimizing strategies in visdrone 2021</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2809" to="2819" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Centernet: Keypoint triplets for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Duan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6569" to="6578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Parametric image alignment using enhanced correlation coefficient maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Evangelidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Z</forename><surname>Psarakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1858" to="1865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="381" to="395" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Yolox: Exceeding yolo series in 2021</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.08430</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mat: Motion-aware multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Fastreid: A pytorch toolbox for general instance reidentification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.02631</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">H</forename><surname>Jonathon Luiten</surname></persName>
		</author>
		<idno>2020. 7</idno>
		<ptr target="https://github.com/JonathonLuiten/TrackEval" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Detecting invisible people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Khurana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.08419</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The hungarian method for the assignment problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">W</forename><surname>Kuhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Naval research logistics quarterly</title>
		<imprint>
			<date type="published" when="1955" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.02396</idno>
		<title level="m">Semi-tcl: Semi-supervised track contrastive representation learning</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Rethinking the competition between detection and reid in multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.12138</idno>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.09441</idno>
		<title level="m">One more check: Making&quot; fake background&quot; be tracked again</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Retinatrack: Online single stage joint detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rathod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Votel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14668" to="14678" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Hota: A higher order metric for evaluating multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luiten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dendorfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="548" to="578" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Bag of tricks and a strong baseline for deep person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Schindler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.00831</idno>
		<title level="m">Mot16: A benchmark for multi-object tracking</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Tubetk: Adopting tubes to track multi-object in a one-step training model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6308" to="6318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Quasi-dense similarity learning for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="164" to="173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Chained-tracker: Chaining paired attentive regression results for end-to-end joint multipleobject detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.02767</idno>
		<title level="m">Yolov3: An incremental improvement</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Performance measures and a data set for multi-target, multicamera tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ristani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Solera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cucchiara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="17" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Orb: An efficient alternative to sift or surf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rublee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rabaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bradski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2011 International conference on computer vision</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="2564" to="2571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.09015</idno>
		<title level="m">Tracklets predicting based adaptive graph tracking</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Crowdhuman: A benchmark for detecting human in a crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.00123</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Good features to track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of IEEE conference on computer vision and pattern recognition</title>
		<meeting>IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1994" />
			<biblScope unit="page" from="593" to="600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Modelling ambiguous assignments for multi-person tracking in crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Stadler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beyerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.15460</idno>
		<title level="m">Transtrack: Multiple-object tracking with transformer</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Learning to track with object permanence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tokmakov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14258</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning discriminative features with multiple granularities for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM international conference on Multimedia</title>
		<meeting>the 26th ACM international conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="274" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Multiple object tracking with correlation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Joint object detection and multi-object tracking with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Weng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.13164</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Towards real-time multi-object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision-ECCV 2020: 16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="107" to="122" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XI 16</note>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">The homography as a state transformation between frames in visual multi-target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename><surname>Beard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Simple online and realtime tracking with a deep association metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wojke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Paulus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE international conference on image processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="3645" to="3649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Track to detect and segment: An online multi-object tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yuan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12352" to="12361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Delorme</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Alameda-Pineda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.15145</idno>
		<title level="m">Transcenter: Transformers with dense queries for multiple-object tracking</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">How to train your deep multi-object tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Osep</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Horaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Leal-Taix?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Alameda-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6787" to="6796" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Remot: A model-agnostic refinement for multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">106</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Relationtrack: Relationaware multiple object tracking with decoupled representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.04322</idno>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Poi: Multiple object tracking with high performance detection and appearance feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="36" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.03247</idno>
		<title level="m">Motr: End-to-end multiple-object tracking with transformer</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08955</idno>
		<title level="m">Splitattention networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Multiplex labeling graph for near-online tracking in crowded scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Internet of Things Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="7892" to="7902" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.06864</idno>
		<title level="m">Bytetrack: Multi-object tracking by associating every detection box</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Fairmot: On the fairness of detection and re-identification in multiple object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Improving multiple object tracking with single object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Omni-scale feature learning for person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cavallaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3702" to="3712" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Tracking objects as points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kr?henb?hl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Deformable detr: Deformable transformers for end-to-end object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.04159</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
