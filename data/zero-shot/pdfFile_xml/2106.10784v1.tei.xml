<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Zhang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Su</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shirui</forename><surname>Pan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojun</forename><surname>Chang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Abbasnejad</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reza</forename><surname>Haffari</surname></persName>
						</author>
						<title level="a" type="main">iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Differentiable ARchiTecture Search (DARTS) has recently become the mainstream of neural architecture search (NAS) due to its efficiency and simplicity. With a gradient-based bi-level optimization, DARTS alternately optimizes the inner model weights and the outer architecture parameter in a weight-sharing supernet. A key challenge to the scalability and quality of the learned architectures is the need for differentiating through the inner-loop optimisation. While much has been discussed about several potentially fatal factors in DARTS, the architecture gradient, a.k.a. hypergradient, has received less attention. In this paper, we tackle the hypergradient computation in DARTS based on the implicit function theorem, making it only depends on the obtained solution to the innerloop optimization and agnostic to the optimization path. To further reduce the computational requirements, we formulate a stochastic hypergradient approximation for differentiable NAS, and theoretically show that the architecture optimization with the proposed method, named iDARTS, is expected to converge to a stationary point. Comprehensive experiments on two NAS benchmark search spaces and the common NAS search space verify the effectiveness of our proposed method. It leads to architectures outperforming, with large margins, those learned by the baseline methods.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Neural Architecture Search (NAS) is an efficient and effective method on automating the process of neural network design, with achieving remarkable success on image recognition <ref type="bibr" target="#b45">(Tan &amp; Le, 2019;</ref><ref type="bibr" target="#b27">Li et al., 2021b;</ref>, language modeling <ref type="bibr" target="#b23">(Jiang et al., 2019)</ref>, and other deep learning ap-1 Faculty of Information Technology, Monash University, Australia 2 Faculty of Engineering and Information Technology, University of Technology Sydney, Australia 3 Australian Institute for Machine Learning, University of Adelaide, Australia. Correspondence to: Shirui Pan &lt;Shirui.Pan@monash.edu&gt;.</p><p>Proceedings of the 38 th International Conference on Machine Learning, PMLR 139, 2021. Copyright 2021 by the author(s).</p><p>plications <ref type="bibr" target="#b41">(Ren et al., 2020;</ref><ref type="bibr" target="#b8">Cheng et al., 2020;</ref><ref type="bibr" target="#b7">Chen et al., 2019b;</ref><ref type="bibr" target="#b22">Hu et al., 2021;</ref><ref type="bibr" target="#b58">Zhu et al., 2021;</ref><ref type="bibr" target="#b42">Ren et al., 2021)</ref>. The early NAS frameworks are devised via reinforcement learning (RL) <ref type="bibr" target="#b38">(Pham et al., 2018)</ref> or evolutionary algorithm (EA)  to directly search on the discrete space. To further improve the efficiency, a recently proposed Differentiable ARchiTecture Search (DARTS)  adopts the continuous relaxation to convert the operation selection problem into the continuous magnitude optimization for a set of candidate operations. By enabling the gradient descent for the architecture optimization, DARTS significantly reduces the search cost to several GPU hours <ref type="bibr" target="#b49">Xu et al., 2020;</ref><ref type="bibr" target="#b11">Dong &amp; Yang, 2019a)</ref>.</p><p>Despite its efficiency, more current works observe that DARTS is somewhat unreliable <ref type="bibr" target="#b51">(Zela et al., 2020a;</ref><ref type="bibr" target="#b28">Li &amp; Talwalkar, 2019;</ref><ref type="bibr" target="#b43">Sciuto et al., 2019;</ref><ref type="bibr" target="#b55">Zhang et al., 2020c;</ref><ref type="bibr" target="#b26">Li et al., 2021a;</ref><ref type="bibr" target="#b54">Zhang et al., 2020b)</ref> since it does not consistently yield excellent solutions, performing even worse than random search in some cases. <ref type="bibr" target="#b51">Zela et al. (2020a)</ref> attribute the failure of DARTS to its supernet training, with empirically observing that the instability of DARTS is highly correlated to the dominant eigenvalue of the Hessian matrix of the validation loss with respect to architecture parameters. On the other hand, <ref type="bibr" target="#b46">Wang et al. (2021a)</ref> turn to the magnitude-based architecture selection process, who empirically and theoretically show the magnitude of architecture parameters does not necessarily indicate how much the operation contributes to the supernet's performance.  observe a precipitous validation loss landscape with respect to architecture parameters, which leads to a dramatic performance drop when discretizing the final architecture for the operation selection. Accordingly, they propose a perturbation based regularization to smooth the loss landscape and improve the stability.</p><p>While there are many variants on improving the DARTS from various aspects, limited research attention has been paid to the approximation of the architecture parameter gradient, which is also called the outer-loop gradient or hypergradient. To fill the gap, this paper focuses on the hypergradient calculation in the differentiable NAS. The main contribution of this work is the development of the differentiable architecture search with stochastic implicit gradients (iDARTS). Specifically, we first revisit the DARTS from the bi-level optimization perspective and utilize the implicit function theorem (IFT) <ref type="bibr" target="#b1">(Bengio, 2000;</ref><ref type="bibr" target="#b30">Lorraine et al., 2020)</ref>, instead of the one-step unroll learning paradigm adopted by DARTS, to calculate the architecture parameter gradient. This IFT based hypergradient depends only on the obtained solution to the inner-loop optimization weights rather than the path taken, thus making the proposed method memory efficient and practical with numerous inner optimization steps. Then, to avoid calculating the inverse of the Hessian matrix with respect to the model weights, we utilize the Neumann series <ref type="bibr" target="#b30">(Lorraine et al., 2020)</ref> to approximate this inverse and propose an approximated hypergradient for DARTS accordingly. After that, we devise a stochastic approximated hypergradient to relieve the computational burden further, making the proposed method applicable to the differentiable NAS. We theoretically demonstrate that, under some mild assumptions <ref type="bibr" target="#b17">(Ghadimi &amp; Wang, 2018;</ref><ref type="bibr" target="#b10">Couellan &amp; Wang, 2016;</ref><ref type="bibr" target="#b19">Grazzi et al., 2020b)</ref> on the inner and outer loss functions, the proposed method is expected to converge to a stationary point with small enough learning rates. Finally, we verify the effectiveness of the proposed approach on two NAS benchmark datasets and the common DARTS search space.</p><p>We make the following contributions:</p><p>? This paper deepens our understanding of the hypergradient calculation in the differentiable NAS. We reformulated the hypergradient in the differentiable NAS with the implicit function theorem (IFT), which can thus gracefully handle many inner optimization steps without increasing the memory requirement.</p><p>? To relieve the heavy computational burdens, we consider a Neumann-approximation for the IFT based differentiable NAS. Further, to make the implicit hypergradient practical for differentiable NAS, we formulate a stochastic hypergradient with the Neumannapproximation.</p><p>? We provide a theoretical analysis of the proposed method and demonstrate that the proposed method is expected to converge to a stationary point when applied to differentiable NAS. Extensive experiments verify the effectiveness of the proposed method which significantly improves the performance of the differentiable NAS baseline on the NAS-Bench-1Shot1 and the NAS-Bench-201 benchmark datasets and the common DARTS search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Preliminaries: DARTS and Bi-level Optimization</head><p>Existing differentiable NAS methods mostly leverage the weight sharing and continuous relaxation to enable the gradient descent for the discrete architecture search, significantly improving the search efficiency. DARTS  is one of the most representative differentiable NAS methods, which utilizes the continuous relaxation to convert the discrete operation selection into the magnitude optimization for a set of candidate operations. Typically, NAS searches for cells to stack the full architecture, where a cell structure is represented as a directed acyclic graph (DAG) with N nodes. NAS aims to determine the operations and corresponding connections for each node, while DARTS applies a softmax function to calculate the magnitude of each operation, transforming the operation selection into a continuous magnitude optimization problem:</p><formula xml:id="formula_0">X n = 0?s&lt;n |O| o=1? (s,n) o o(X s ),? (s,n) o = exp(? s,n o ) o ?O exp(? s,n o )</formula><p>, where X n is the output of node n, O contains all candidate operations, and the output of each node is the weighted sum of its previous nodes' outputs affiliated with all possible operations. In this way, DARTS transforms the discrete architecture search into optimizing the continuous magnitude? s,n o , enabling gradient descent for the architecture optimization. A discrete architecture is obtained by applying an argmax function to the magnitude matrix after the differentiable architecture optimization.</p><p>The optimization in DARTS is based on the bi-level optimization formulation <ref type="bibr" target="#b9">(Colson et al., 2007;</ref><ref type="bibr" target="#b29">Liu et al., 2019)</ref>:</p><formula xml:id="formula_1">min ? L val (w * (?), ?) s.t. w * (?) = argmin w L train (w, ?),<label>(1)</label></formula><p>where ? is the continuous architecture representation and w is the supernet weights. We indicate the L val as L 2 and the L train as L 1 in the remaining text for convenience. The nested formulation in DARTS is the same as the gradientbased hyperparameter optimization with bi-level optimization <ref type="bibr" target="#b16">(Franceschi et al., 2018;</ref><ref type="bibr" target="#b33">Maclaurin et al., 2015;</ref><ref type="bibr" target="#b37">Pedregosa, 2016)</ref>, where the inner-loop is to train the network parameter w and the outer-loop is to optimize the architecture parameter ?. The gradient of the outer-loop for DARTS is then calculated as:</p><formula xml:id="formula_2">? ? L 2 = ( ?L 2 ?? + ?L 2 ?w ?w * (?) ?? ).<label>(2)</label></formula><p>DARTS considers the one-step unroll learning paradigm <ref type="bibr" target="#b39">Rajeswaran et al., 2019)</ref> for the hypergradient calculation. This is done by taking a single step in optimising w instead of the optimal w * .</p><p>Different from the majority of existing works that attributes the failure of DARTS to its supernet optimization <ref type="bibr" target="#b51">(Zela et al., 2020a;</ref><ref type="bibr" target="#b2">Benyahia et al., 2019)</ref>, or the final discretization with argmax <ref type="bibr" target="#b47">Wang et al., 2021b)</ref>, this paper revisits DARTS from the perspective of the hypergradient calculation ? ? L 2 . Rather than considering the one-step unroll learning paradigm <ref type="bibr" target="#b14">Finn et al., 2017)</ref>, this paper utilizes the implicit function theorem (IFT) <ref type="bibr" target="#b1">(Bengio, 2000;</ref><ref type="bibr" target="#b30">Lorraine et al., 2020)</ref> to reformulate the hypergradient calculation in DARTS. In the following subsection, we first recap the hypergradient calculation with different paradigms for DARTS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Hypergradient: From Unrolling to iDARTS</head><p>One-step unrolled differentiation. The one-step unroll learning paradigm, as adopted by DARTS, is commonly used in the bi-level optimization based applications, including meta-learning <ref type="bibr" target="#b14">(Finn et al., 2017)</ref>, hyperparameter optimization <ref type="bibr" target="#b31">(Luketina et al., 2016)</ref>, generative adversarial networks <ref type="bibr" target="#b34">(Metz et al., 2017)</ref>, and neural architecture search , as it simplifies the hypergradient calculation and makes the bi-level optimization formulation practical for large-scale network learning. As described in the Section 2, the one-step unroll learning paradigm restricts the inner-loop optimization with only one step training. Differentiating through the inner learning procedure with one step w * (?) = w ? ?? w L 1 , and obtaining ?w * (?) ?? = ?? ? 2 L1 ???w , DARTS calculates the hypergradient as:</p><formula xml:id="formula_3">? ? L DART S 2 = ?L 2 ?? ? ? ?L 2 ?w ? 2 L 1 ???w ,<label>(3)</label></formula><p>where ? is the inner-loop learning rate for w.</p><p>Reverse-mode back-propagation. Another direction of computing hypergradient is the reverse-mode <ref type="bibr" target="#b15">(Franceschi et al., 2017;</ref><ref type="bibr" target="#b44">Shaban et al., 2019)</ref>, which trains the innerloop with enough steps to reach the optimal points for the inner optimization. This paradigm assumes T -step is large enough to adapt w(?) to w * (?) in the inner-loop. Defining ? as a step of inner optimization that w t (?) = ?(w t?1 , ?), and defining Z t = ? ? w t (?), we have:</p><formula xml:id="formula_4">Z t = A t Z t?1 + B t , where A t = ??(wt?1,?) ?wt?1 , and B t = ??(wt?1,?) ?? .</formula><p>Then the hypergradient of DARTS with the reverse model could be formulated as:</p><formula xml:id="formula_5">? ? L Reverse 2 = ?L 2 ?? + ?L 2 ?w T ( T t=0 B t A t+1 ...A T ). (4)</formula><p>Although the reverse-mode bi-level optimization is easy to implement, the memory requirement linearly increases with the number of steps T <ref type="bibr" target="#b15">(Franceschi et al., 2017)</ref> as it needs to store all intermediate gradients, making it impractical for deep networks. Rather than storing the gradients for all steps, a recent work <ref type="bibr" target="#b44">(Shaban et al., 2019)</ref> only uses the last K-step (K &lt;&lt; T ) gradients to approximate the exact hypergradient, which is called the truncated back-propagation.</p><p>Based on the K-step truncated back-propagation, the hypergradient for DARTS could be described as:</p><formula xml:id="formula_6">h T ?K = ?L 2 ?? + ?L 2 ?w T Z T = ?L 2 ?? + ?L 2 ?w T ( T t=T ?K+1 B t A t+1 ...A T ).<label>(5)</label></formula><p>The lemmas in <ref type="bibr" target="#b44">(Shaban et al., 2019)</ref> show that h T ?K is a sufficient descent direction for the outer-loop optimization.</p><p>Lemma 1 <ref type="bibr" target="#b44">(Shaban et al., 2019)</ref>. For all K ? 1, with T large enough and ? small enough,</p><formula xml:id="formula_7">h T ?K is a sufficient descent direction that, i.e. h T ?K ? ? L 2 ? ?( ? ? L 2 2 ).</formula><p>iDARTS: Implicit gradients differentiation. Although h T ?K significantly decreases memory requirements, it still needs to store K-step gradients, making it impractical for differentiable NAS. In contrast, by utilizing the implicit function theorem (IFT), the hypergradient can be calculate without storing the intermediate gradients <ref type="bibr" target="#b1">(Bengio, 2000;</ref><ref type="bibr" target="#b30">Lorraine et al., 2020)</ref>. The IFT based hypergradient for DARTS could be formulated as the following lemma.</p><p>Lemma 2 Implicit Function Theorem: Consider L 1 , L 2 , and w * (?) as defined in Eq.(1), and with ?L1(w * ,?) ?w = 0, we have</p><formula xml:id="formula_8">? ? L 2 = ?L 2 ?? ? ?L 2 ?w ? 2 L 1 ?w?w ?1 ? 2 L 1 ???w .<label>(6)</label></formula><p>This is also called as implicit differentiation theorem <ref type="bibr" target="#b30">(Lorraine et al., 2020)</ref>. However, for a large neural network, it is hard to calculate the inverse of Hessian matrix in Eq.(6), and one common direction is to approximate this inverse. Compared with Eq.(6), the hypergradient of DARTS  in Eq. <ref type="formula" target="#formula_3">(3)</ref>, which adopts the one-step unrolled differentiation, simply uses an identity to approximate the inverse</p><formula xml:id="formula_9">? 2 L1 ?w?w ?1 = ?I.</formula><p>This naive approximation is also adopted by <ref type="bibr" target="#b31">(Luketina et al., 2016;</ref><ref type="bibr" target="#b0">Balaji et al., 2018;</ref><ref type="bibr" target="#b36">Nichol et al., 2018)</ref>. In contrast, <ref type="bibr" target="#b39">(Rajeswaran et al., 2019;</ref><ref type="bibr" target="#b37">Pedregosa, 2016)</ref> utilize the conjugate gradient (CG) to convert the approximation of the inverse to solving a linear system with ?-optimal solution, with applications to the hyperparameter optimization and meta-learning.</p><p>Recently, the Neumann series is introduced to approximate the inverse in the hyperparameter optimization <ref type="bibr" target="#b30">(Lorraine et al., 2020)</ref> for modern and deep neural networks since it is a more stable alternative to CG and useful in stochastic settings. This paper thus adopts the Neumann series for the inverse approximation and proposes an approximated hypergradient for DARTS accordingly. A stochastic approximated hypergradient is further devised to fit with differentiable NAS and relieve the computational burden, which is called Differentiable Architecture Search with Stochastic Implicit Gradients (iDARTS). We theoretically show the proposed method converges in expectation to a stationary point for the differentiable architecture search with small enough learning rates. A detailed description and analysis of iDARTS follow in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Stochastic Approximations in iDARTS</head><p>As described, our iDARTS utilizes the Neumann series to approximate the inverse of the Hessian matrix for the hypergradient calculation in the IFT-based bi-level optimization of NAS. We further consider a stochastic setting where the Neumann approximation is computed based on minibatch samples, instead of the full dataset, enabling scalability to large datasets, similar to standard-practice in deep learning.</p><p>This section starts by analyzing the bound of the proposed hypergradient approximation, and then shows the convergence property of the proposed stochastic approximated hypergradient for differentiable NAS.</p><p>Before our analysis, we give the following common assumptions in the bi-level optimization. 1</p><p>Assumption 1 For the outer-loop function L 2 :</p><p>1. For any w and ?, L 2 (w, ?) and L 2 (?, ?) are bounded below.</p><p>2. For any w and ?, L 2 (w, ?) and L 2 (?, ?) are Lipschitz continuous with constants L w 2 &gt; 0 and L ? 2 &gt; 0.</p><p>3. For any w and ?, ? w L 2 (w, ?) and ? ? L 2 (?, ?) are Lipschitz continuous with constants L ?w 2 &gt; 0 and L ?? 2 &gt; 0 with respect to w and ?.</p><p>Assumption 2 For the inner-loop function L 1</p><formula xml:id="formula_10">1. ? w L 1 is Lipschitz continuous with respect to w with constant L ?w 1 &gt; 0. 2. The function w : ? ? w(?) is Lipschitz continuous with constant L w &gt; 0, and has Lipschitz gradient with constant L ??w &gt; 0. 3. ? 2 w? L 1 is bounded that ? 2 w? L 1 ? C L w? 1 for some constant C L w? 1 &gt; 0.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Hypergradient based on Neumann Approximation</head><p>In this subsection, we describe how to use the Neumann series to reformulate the hypergradient in DARTS.</p><p>Lemma 3 Neumann series <ref type="bibr" target="#b30">(Lorraine et al., 2020)</ref></p><formula xml:id="formula_11">: With a matrix A that I ? A &lt; 1, A ?1 = ? k=0 (I ? A) k .</formula><p>1 Similar assumptions are also considered in <ref type="bibr" target="#b10">(Couellan &amp; Wang, 2016;</ref><ref type="bibr" target="#b17">Ghadimi &amp; Wang, 2018;</ref><ref type="bibr" target="#b19">Grazzi et al., 2020b;</ref><ref type="bibr">a)</ref>. Based on Lemma 3, the Eq. (6) for the IFT based DARTS is formulated by Eq. (7) as described in Corollary 1.</p><p>Corollary 1 With small enough learning rate ? &lt; 1 L ?w 1 , the hypergradient in DARTS can be formulated as:</p><formula xml:id="formula_12">? ? L 2 = ?L 2 ?? ? ?L 2 ?w ? 2 L 1 ?w?w ?1 ? 2 L 1 ???w = ?L 2 ?? ? ? ?L 2 ?w ? j=0 I ? ? ? 2 L 1 ?w?w j ? 2 L 1 ???w .<label>(7)</label></formula><p>As shown in the Corollary 1, the approximated hypergradient for DARTS, denoted by ? ?L2 could be obtained by only considering the first K terms of Neumann approximation without calculating the inverse of Hessian <ref type="bibr" target="#b44">(Shaban et al., 2019;</ref><ref type="bibr" target="#b30">Lorraine et al., 2020)</ref> as,</p><formula xml:id="formula_13">? ?L2 = ?L 2 ?? ? ? ?L 2 ?w K k=0 I ? ? ? 2 L 1 ?w?w k ? 2 L 1 ???w . (8)</formula><p>As shown, we could observe the relationship between the proposed ? ?L2 and the hypergradient of DARTS in Eq <ref type="formula" target="#formula_3">(3)</ref>, which is the same as ? ?L2 when K = 0. In the following theorem, we give the error bound between our approximated hypergradient ? ?L2 and the exact hypergradient ? ? L 2 .</p><p>Theorem 1 Suppose the inner optimization function L 1 is twice differentiable and is ?-strongly convex with w around w * (?). The error between the approximated gradient ? ?L2</p><formula xml:id="formula_14">and ? ? L 2 in DARTS is bounded with ? ? L 2 ? ? ?L2 C L w? 1 C L w 2 1 ? (1 ? ??) K+1 .</formula><p>Theorem 1 states that the approximated hypergradient approaches to the exact hypergradient as K increases. As described, the form of ? ?L2 is similar to the K-step truncated back-propagation in Eq. (5), while the memory consumption of our ? ?L2 is only 1 K of the memory needed to compute h T ?K , as we only store the gradients of the final solution w * . In the following corollary, we describe the connection between the proposed approximated hypergradient ? ?L2 and the approximation based on the truncated back-propagation h T ?K <ref type="bibr" target="#b44">(Shaban et al., 2019)</ref>.</p><p>Corollary 2 When we assume w t has converged to a stationary point w * in the last K steps, the proposed ? ?L2 is the same as the truncated back-propagation h T ?K .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Stochastic Approximation of Hypergradient</head><p>The Lemma 1 and Corollary 2 show that the approximated hypergradient ? ?L2 has the potential to be a sufficient descent direction. However, it is not easy to calculate the implicit gradients for DARTS based on Eq. (8) as it needs to deal with large-scale datasets in which the loss functions are large sums of error terms:</p><formula xml:id="formula_15">L 2 = 1 R R i=1 L i 2 ; L 1 = 1 J J j=1 L j 1 ,</formula><p>where J is the number of minibatches of the training dataset D train for the inner supernet training L 1 , and R is the number of minibatches of the validation dataset D val for the outer architecture optimization L 2 . It is apparently challenging to calculate the gradient based on the full dataset in each step. We therefore utilize the stochastic gradient based on individual minibatches in practice. That is, we consider the following stochastic approximated hypergradient,</p><formula xml:id="formula_16">? ?L i 2 (w j (?), ?) = ?L i 2 ?? ? ? ?L i 2 ?w K k=0 I ? ? ? 2 L j 1 ?w?w k ? 2 L j 1 ???w .<label>(9)</label></formula><p>where L i 2 and L j 1 correspond to loss functions calculated by randomly sampled minibatches i and j from D val and D train , respectively. This expression can be computed using the Hessian-vector product technique without explicitly computing the Hessian matrix (see Appendix B). Before analyzing the convergence of the proposed ? ?L2 (w j (?), ?), we give the following lemma to show function L 2 : ? ? L 2 (w, ?) is differentiable with a Lipschitz continuous gradient <ref type="bibr" target="#b10">(Couellan &amp; Wang, 2016)</ref>.</p><p>Lemma 4 Based on the Assumption 1 and 2, we have the function L 2 : ? ? L 2 (w, ?) is differentiable with Lipschitz continuous gradient and Lipschitz constant L ??L2 = L ?? 2 + L ?w</p><formula xml:id="formula_17">2 L 2 w + L w 2 L ??w .</formula><p>Then we state and prove the main convergence theorem for the proposed stochastic approximated hypergradient ? ?L i 2 (w j (?), ?) for the differentiable NAS.</p><p>Theorem 2 Based on several assumptions, we could prove the convergence of the proposed stochastic approximated hypergradient for differentiable NAS. Suppose that:</p><p>1. All assumptions in Assumption 1 and 2 and Corollary 1 are satisfied;</p><formula xml:id="formula_18">2. ?D &gt; 0 such that E ? 2 ? D ? ? L 2 2 ; 3. ?i &gt; 0, ? ?i satisfies ? i=1 ? ?i = ? and ? i=1 ? 2 ?i &lt; ?.</formula><p>4. The inner function L 1 has the special structure:</p><formula xml:id="formula_19">L j 1 (w, ?) = h(w, ?) + h j (w, ?), ?j ? 1, .</formula><p>.., J, that h j is a linear function with respect to w and ?.</p><p>With small enough learning rate ? ? for the architecture optimization, the proposed stochastic hypergradient based Algorithm 1 iDARTS Input: D train and D val . Initialized supernet weights w and operations magnitude ? ? .</p><p>while not converged do 2:</p><p>Sample batches from D train . Update supernet weights w based on cross-entropy loss with T steps.</p><p>Get the Hessian matrix ? 2 L1 ?w?w .</p><p>4:</p><formula xml:id="formula_20">Sample batch from D val . Calculate hypergradient ? ?L i 2 (w j (?), ?) based on Eq.(9), and update ? with ? ? ? ? ? ? ? ?L i 2 (w j (?), ?). end while 6: Obtain ? * through argmax.</formula><p>algorithm converges in expectation to a stationary point, i.e. lim</p><formula xml:id="formula_21">m?? E ? ?L i 2 (w j (? m ), ? m ) = 0.</formula><p>The ? is defined as the noise term between the stochastic gradient ? ? L i 2 (w j (?), ?) and the true gradient ? ? L 2 as:</p><formula xml:id="formula_22">? i,j = ? ? L 2 ? ? ? L i 2 (w j (?), ?). where ? ? L i 2 (w j (?), ?) is the non-approximate version of Eq. (9) when K ? ?.</formula><p>Theorem 2 shows that the proposed stochastic approximated hypergradient is also a sufficient descent direction, which leads the differentiable NAS converges to a stationary point. The conditions 2-4 in Theorem 2 are common assumptions in analyzing the stochastic bi-level gradient methods <ref type="bibr" target="#b10">(Couellan &amp; Wang, 2016;</ref><ref type="bibr" target="#b17">Ghadimi &amp; Wang, 2018;</ref><ref type="bibr" target="#b19">Grazzi et al., 2020b;</ref><ref type="bibr">a)</ref>. We assume that L 1 in Eq. <ref type="formula" target="#formula_12">(7)</ref> is ?-strongly convex with w around w * , which can be made possible by appropriate choice of learning rates <ref type="bibr" target="#b39">(Rajeswaran et al., 2019;</ref><ref type="bibr" target="#b44">Shaban et al., 2019)</ref>. Another key assumption in our convergence analysis is the Lipshitz differentiable assumptions for L 1 and L 2 in Assumption 1 and 2, which also received considerable attention in recent optimization and deep learning literature <ref type="bibr" target="#b24">(Jin et al., 2017;</ref><ref type="bibr" target="#b39">Rajeswaran et al., 2019;</ref><ref type="bibr" target="#b30">Lorraine et al., 2020;</ref><ref type="bibr" target="#b32">Mackay et al., 2018;</ref><ref type="bibr" target="#b18">Grazzi et al., 2020a)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Differentiable Architecture Search with Stochastic Implicit Gradients</head><p>Different from DARTS that alternatively optimizes both ? and w with only one step in each round, iDARTS is supposed to train the supernet with enough steps to make sure the w(?) is near w * (?) before optimizing ?. The framework of our iDARTS is sketched in Algorithm 1. Generally, it is impossible to consider a very large T for each round of supernet weights w optimization, as the computational cost increase linear with T . Fortunately, empirical experiments show that, with the weight sharing, the differentiable NAS can adapt w(?) to w * (?) with a small T in the later phase of architecture search.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>In Section 4, we have theoretically shown that our iDARTS can asymptotically compute the exact hypergradient and lead to a convergence in expectation to a stationary point for the architecture optimization. In this section, we conduct a series of experiments to verify whether the iDARTS leads to better results in the differentiable NAS with realistic settings. We consider three different cases to analyze iDARTS, including two NAS benchmark datasets, NAS-Bench-1Shot1 <ref type="bibr" target="#b52">(Zela et al., 2020b)</ref> and NAS-Bench-201 <ref type="bibr" target="#b13">(Dong &amp; Yang, 2020)</ref>, and the common DARTS search space . We first analyze the iDARTS on the two NAS benchmark datasets, along with discussions of hyperparameter settings. Then we compare iDARTS with state-of-the-art NAS methods on the common DARTS search space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Reproducible Comparison on NAS-Bench-1Shot1</head><p>To study the empirical performance of iDARTS, we run the iDARTS on the NAS-Bench-1Shot1 dataset with different random seeds to report its statistical results, and compare with the most closely related baseline DARTS . The NAS-Bench-1Shot1 is built from the NAS-Bench-101 benchmark dataset <ref type="bibr" target="#b50">(Ying et al., 2019)</ref>, through dividing all architectures in NAS-Bench-101 into 3 different unified cell-based search spaces. The architectures in each search space have the same number of nodes and connections, making the differentiable NAS could be directly applied to each search space. The three search spaces contain 6240, 29160, and 363648 architectures with the CIFAR-10 performance, respectively. We choose the third search space in NAS-Bench-1Shot1 to analyse iDARTS, since it is much more complicated than the remaining two search spaces and is a better case to identify the advantages of iDARTS. <ref type="figure" target="#fig_0">Figure 1</ref> plots the mean and standard deviation of the validation and test errors for iDARTS and DARTS, with tracking the performance during the architecture search on the NAS-Bench-1Shot1 dataset. As shown, our iDARTS with different T generally outperforms DARTS during the architecture search in terms of both validation and test error.</p><p>More specifically, our iDARTS significantly outperforms the baseline in the early stage, demonstrating that our iDARTS could quickly find superior architectures and is more stable.</p><p>As described, one significant difference from DARTS is that iDARTS can conduct more than one training step in the inner-loop optimization. <ref type="figure" target="#fig_0">Figure 1</ref> also analyzes the effects of the inner optimization steps T , plotting the performance of iDARTS with different T on the NAS-Bench-1Shot1. As shown, the inner optimization steps positively affect the performance of iDARTS, where increasing T helps iDARTS converge to excellent solutions faster. One underlying reason is that increasing T could adapt w to a local optimal w * , thus helping iDRTS approximate the exact hypergradient more accurately. We should notice that the computational cost of iDARTS also increases with T , and our empirical findings suggest a T = 5 achieves an excellent compute and performance trade-off for iDARTS on NAS-Bench-1shot1.</p><p>More interesting, iDARTS with T = 1 is similar as DARTS which both conduct the inner optimization with only one step, with the difference that iDARTS adopts the Neumann approximation while DARTS considers the unrolled differentiation. We could observe that iDARTS still outperforms DARTS by large margins in this case, showing the superiority of the proposed approximation over DARTS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Reproducible Comparison on NAS-Bench-201</head><p>The NAS-Bench-201 dataset <ref type="bibr" target="#b13">(Dong &amp; Yang, 2020)</ref> is another popular NAS benchmark dataset to analyze differentiable NAS methods. The search space in NAS-Bench-201 contains four nodes with five associated operations, resulting in 15,625 cell candidates. The search space of NAS-Bench-201 is much simpler than NAS-Bench-1Shot1, while it contains the performance of CIFAR-100, CIFAR-100, and ImageNet for all architectures in this search space. Similar to the experiments in the NAS-Bench-1Shot1, we also analyze the importance of hyperparameter T in the NAS-Bench-201 dataset. <ref type="figure" target="#fig_1">Figure 2 (a)</ref> summaries the performance of iDARTS with different number of inner optimization steps T on the NAS-Bench-201. As demonstrated, the performance of iDARTS is sensitive to the hyperparameter iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients  T , and a larger T helps iDARTS to achieve better results while also increases the computational time, which is also in line with the finding in the NAS-Bench-1Shot1. We empirically find that T = 4 is enough to achieve competitive results on NAS-Bench-201.</p><p>The hypergradient calculation of iDARTS is based on the Neumann approximation in Eq. <ref type="formula" target="#formula_12">(7)</ref>, and one underlying condition is that the learning rates ? for the inner optimization should be small enough to make I ? ? ? 2 L1 ?w?w &lt; 1. We also conduct an ablation study to analyze how this hyperpa-rameter affects our iDARTS, where <ref type="figure" target="#fig_1">Figure 2</ref> (b) plots the performance of iDARTS with different learning rates ? for the inner optimization on the NAS-Bench-201. As shown, the performance of iDARTS is sensitive to ?, and a smaller ? is preferred, which also offers support for the Corollary 1 and Theorem 1.</p><p>During the analysis of the convergence of iDARTS, the learning rate ? ? plays a key role in the hypergradient approximation for the architecture optimization. <ref type="figure" target="#fig_1">Figure 2</ref> (c) also summaries the performance of iDARTS with different initial learning rate ? ? on the NAS-Bench-201. As shown in <ref type="figure" target="#fig_1">Figure 2 (c)</ref>, the performance of iDARTS is sensitive to ? ? , where a smaller ? ? is recommended, and a large ? ? is hardly able to converge to a stationary point. An underlying reason may lay in the proof of Theorem 2, that choosing a small enough ? ? guarantees that the iDARTS converges to a stationary point.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Experiments on DARTS Search Space</head><p>We also apply iDARTS to a convolutional architecture search in the common DARTS search space  to compare with the state-of-the-art NAS methods, where all experiment settings are following DARTS for fair comparisons. The search procedure needs to look for two different types of cells on CIFAR-10: normal cell ? normal and reduction cell ? reduce , to stack more cells to form the final structure for the architecture evaluation. The best-found cell on CIFAR-10 is then transferred to CIFAR-100 and ImageNet datasets to evaluate its transferability.</p><p>The comparison results with the state-of-the-art NAS methods are presented in <ref type="table" target="#tab_3">Table 2</ref>, and <ref type="figure" target="#fig_3">Figure 3</ref> demonstrates the best-found architectures by iDARTS. As shown in <ref type="table" target="#tab_3">Table 2</ref>, iDARTS achieves a 2.37?0.03 % test error on CIFAR-10 (where the best single run is 2.35%), which is on par with the state-of-the-art NAS methods and outperforms the DARTS baseline by a large margin, again verifying the effectiveness of the proposed method.</p><p>Following DARTS experimental setting, the best-searched architectures on CIFAR-10 are then transferred to CIFAR-iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients "*" indicates the results reproduced based on the best-reported cell structures with a common experimental setting . "Param" is the model size when applied on CIFAR-10, while "+?" is calculated based on the ImageNet dataset.</p><p>100 and ImageNet to evaluate the transferability. The evaluation setting for CIFAR-100 is the same as CIFAR-10. In the ImageNet dataset, the experiment setting is slightly different from CIFAR-10 in that only 14 cells are stacked, and the number of initial channels is changed to 48. We also follow the mobile setting in  to restrict the number of multiply-add operations ("+?") to be less than 600M on the ImageNet. The comparison results with state-of-the-art differentiable NAS approaches on CIFAR-100 and ImageNet are demonstrated in </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper opens up a promising research direction for NAS by focusing on the hypergradient approximation in the differentiable NAS. We introduced the implicit function theorem (IFT) to reformulate the hypergradient calculation in the differentiable NAS, making it practical with numerous  inner optimization steps. To avoid calculating the inverse of the Hessian matrix, we utilized the Neumann series to approximate the inverse, and further devised a stochastic approximated hypergradient to relieve the computational cost. We theoretically analyzed the convergence and proved that the proposed method, called iDARTS, is expected to converge to a stationary point when applied to a differentiable NAS. We based our framework on DARTS and performed extensive experimental results that verified the proposed framework's effectiveness. While we only considered the proposed stochastic approximated hypergradient for differentiable NAS, iDARTS can in principle be used with a variety of bi-level optimization applications, including in meta-learning and hyperparameter optimization, opening up several interesting avenues for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proof</head><p>Proof of Lemma 2: Based on the implicit function theorem <ref type="bibr" target="#b30">(Lorraine et al., 2020)</ref>, or we simply set L1(w * ,?) ?w = 0 since the model weights w achieved the local optimal in the training set with ?, we have:</p><formula xml:id="formula_23">?L 1 (w * (?), ?) ?w = 0,<label>(10)</label></formula><p>and we have ? ?? ?L 1 (w * (?), ?) ?w = 0,</p><formula xml:id="formula_24">? 2 L 1 ???w + ? 2 L 1 ?w?w ?(w * (?)) ?? = 0, ?(w * (?)) ?? = ? ? 2 L 1 ?w?w ?1 ? 2 L 1 ???w .<label>(11)</label></formula><p>In this way, the hypergradient could be formulated as</p><formula xml:id="formula_25">? ? L 2 = ?L 2 ?? ? ?L 2 ?w ? 2 L 1 ?w?w ?1 ? 2 L 1 ???w .<label>(12)</label></formula><p>Proof of Corollary 1: The key in this proposition is to use the Neumann series to approximate the ? 2 L1 ?w?w ?1 .</p><p>Based on the Neumann series approximation, for I ? A &lt; 1, we have: in the optimal point, we have:</p><formula xml:id="formula_26">A ?1 = ? k=0 (I ? A) k .<label>(13)</label></formula><formula xml:id="formula_27">? 2 L 1 ?w?w ?1 = ?(I ? I + ? ? 2 L 1 ?w?w ) ?1 = ? ? j=0 I ? ? ? 2 L 1 ?w?w j .<label>(14)</label></formula><p>So that:</p><formula xml:id="formula_28">? ? L 2 = ?L 2 ?? ? ? ?L 2 ?w ? j=0 I ? ? ? 2 L 1 ?w?w j ? 2 L 1 ???w .<label>(15)</label></formula><p>Proof of Theorem 1 Based on the Eq. (8) and <ref type="formula" target="#formula_12">(7)</ref>, we have</p><formula xml:id="formula_29">? ? L 2 ? ? ?L2 = ? ?L 2 ?w ? j=K+1 I ? ? ? 2 L 1 ?w?w j ? 2 L 1 ???w .<label>(16)</label></formula><p>Since the L 1 is ?-strongly convex, and ??I ? ? 2 L1 ?w?w I, we have</p><formula xml:id="formula_30">? j=K+1 I ? ? ? 2 L 1 ?w?w j ? ? j=K+1 [I ? ??] j .<label>(17)</label></formula><p>iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients</p><p>Based on the sum of geometric sequence, we have</p><formula xml:id="formula_31">? j=K+1 I ? ? ? 2 L 1 ?w?w j ? 1 ?? (1 ? ??) K+1 .<label>(18)</label></formula><p>Since ?L2 ?w and ? 2 L1 ???w are bounded, we have</p><formula xml:id="formula_32">? ? L 2 ? ? ?L2 C L w? 1 C L w 2 1 ? (1 ? ??) K+1 .<label>(19)</label></formula><p>Proof: Corollary 2 Based on the definitions, the hypergradient of truncated back-propagation and the proposed Neumann approximation based hypergradient are defined in Eq.(4) and Eq.(8). When we assume that w t has converged to a stationary point w * in the last K steps, we have</p><formula xml:id="formula_33">w i (?) = w j (?) = w * (?), f or all i, j ? [T ? K + 1, T ]; ??(w i , ?) ?w i = ??(w j , ?) ?w j = ??(w * (?), ?) ?w * (?) = A T , f or all i, j ? [T ? K + 1, T ]; ??(w i , ?) ?? = ??(w j , ?) ?? = ??(w * (?), ?) ?? = B T , f or all i, j ? [T ? K + 1, T ].<label>(20)</label></formula><p>Now the truncated back-propagation could be formulated as:</p><formula xml:id="formula_34">h T ?K = ?L 2 ?? + ?L 2 ?w T ( T t=T ?K+1 B t A t+1 ...A T ) = ?L 2 ?? + ?L 2 ?w T ( K t=0 B T A t T ).<label>(21)</label></formula><p>We have</p><formula xml:id="formula_35">A T = ??(w * (?), ?) ?w * (?) = ?(w * ? ? ?L1 ?w ) ?w * = I ? ? ? 2 L 1 (w * ) ?w?w , B T = ??(w * (?), ?) ?? = ?(w * ? ? ?L1 ?w ) ?? = ?? ? 2 L 1 (w * ) ???w .<label>(22)</label></formula><p>From the above, we have</p><formula xml:id="formula_36">h T ?K = ?L 2 ?? + ?L 2 ?w T ( K t=0 B T A t T ) = ?L 2 ?? ? ? ?L 2 ?w K j=0 I ? ? ? 2 L 1 ?w?w j ? 2 L 1 ???w = ? ?L2 .<label>(23)</label></formula><p>Proof of Lemma 4: First, for ?(?, ? ), we have</p><formula xml:id="formula_37">? ? L 2 (w, ?) ? ? ? L 2 (w, ? ) = ? ? L 2 (?, ?) ? ? ? L 2 (?, ? ) + ? ? L 2 (w(?), ?) ? ? ? L 2 (w(? ), ?) = ? ? L 2 (?, ?) ? ? ? L 2 (?, ? ) + ? w L 2 (w(?), ?)? ? w(?) ? ? w L 2 (w(? ), ?)? ? w(? ) ? ? ? L 2 (?, ?) ? ? ? L 2 (?, ? ) + ? w L 2 (w(?), ?)? ? w(?) ? ? w L 2 (w(? ), ?)? ? w(? ) .<label>(24)</label></formula><p>iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients Then we divide Eq.(24) to two parts. For the first part, based on the Assumption 1.2, we have:</p><formula xml:id="formula_38">? ? L 2 (?, ?) ? ? ? L 2 (?, ? ) ? L ?? 2 (? ? ? ).<label>(25)</label></formula><p>And for the second part of Eq.(24), we have</p><formula xml:id="formula_39">? w L 2 (w(?), ?)? ? w(?) ? ? w L 2 (w(? ), ?)? ? w(? ) = ? w L 2 (w(?), ?)? ? w(?) ? ? w L 2 (w(? ), ?)? ? w(?) ? ? w L 2 (w(? ), ?)? ? w(? ) + ? w L 2 (w(? ), ?)? ? w(?) ? ? w L 2 (w(? ), ?) ? ? w L 2 (w(? ), ?) ? ? w(?) + ? w L 2 (w(? ), ?) ? ? w(?) ? ? ? w(? ) .<label>(26)</label></formula><p>Based Assumption 1.3, we have</p><formula xml:id="formula_40">? w L 2 (w(? ), ?) ? ? w L 2 (w(? ), ?) ? L ?w 2 w(?) ? w(? ) ,<label>(27)</label></formula><p>and based Assumption 2.2 that we have</p><formula xml:id="formula_41">w(?) ? w(? ) ? L w ? ? ? , and ? ? w(?) ? ? ? w(? ) ? L ??w ? ? ? .<label>(28)</label></formula><p>Based on Assumption 1.3, we know ? w L 2 (w(? ), ?) is bounded that ? w L 2 (w(? ), ?) ? L w 2 . ? ? w(?) is also bounded by ? ? w(?) ? L w . In this way, Eq.(26) could be rephrased as:</p><formula xml:id="formula_42">? w L 2 (w(?), ?)? ? w(?) ? ? w L 2 (w(? ), ?)? ? w(? ) ? L ?w 2 L 2 w ? ? ? + L w 2 L ??w ? ? ? .<label>(29)</label></formula><p>Based on Eq. (24), Eq. <ref type="formula" target="#formula_2">(25)</ref> and <ref type="formula" target="#formula_2">(29)</ref> we have</p><formula xml:id="formula_43">? ? L 2 (w, ?) ? ? ? L 2 (w, ? ) ? (L ?? 2 + L ?w 2 L 2 w + L w 2 L ??w ) ? ? ? .<label>(30)</label></formula><p>Therefore, Lemma 4 is proved.</p><p>Proof of Theorem 2: We first define the noise term between the stochastic estimate ? ? L i 2 and the true gradient ? ? L 2 as:</p><formula xml:id="formula_44">? i = ? ? L 2 ? ? ? L i 2 ,<label>(31)</label></formula><p>and the error between the approximated hypergradient ? ?L2 and the exact hypergradient ? ? L 2 as:</p><formula xml:id="formula_45">e m = ? ? L 2 (w * (? m ), ? m ) ? ? ?L2 (w * (? m ), ? m ).<label>(32)</label></formula><p>We then prove that</p><formula xml:id="formula_46">? ? L i 2 (w * (? m ), ? m ) is an unbiased estimate of ? ? L 2 (w * (? m ), ? m ) that: E[? ? L i 2 (w * (? m ), ? m ) | ? m ] = ? ? L 2 (w * (? m ), ? m ).<label>(33)</label></formula><p>Based on IFT in Eq. <ref type="formula" target="#formula_12">(7)</ref>, we have</p><formula xml:id="formula_47">? ? L i 2 (w * (? m ), ? m ) = ?L i 2 (w * (? m ), ? m ) ?? ? ?L i 2 (w * (? m ), ? m ) ?w ? 2 L j 1 (w * (? m ), ? m ) ?w?w ?1 ? 2 L j 1 (w * (? m ), ? m ) ???w .<label>(34)</label></formula><p>So that</p><formula xml:id="formula_48">E ? ? L i 2 (w * (? m ), ? m ) | ? m =E ? ? ?L i 2 (w * (? m ), ? m ) ?? ? ?L i 2 (w * (? m ), ? m ) ?w ? 2 L j 1 (w * (? m ), ? m ) ?w?w ?1 ? 2 L j 1 (w * (? m ), ? m ) ???w | ? m ? ? .<label>(35)</label></formula><p>iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients Based on the linear assumption for L j 1 in the condition 4 of the Theorem 2, we have</p><formula xml:id="formula_49">? 2 L j 1 (w * (?m),?m) ?w?w = ? 2 L1(w * (?m),?m) ?w?w , and E ? ? L i 2 (w * (? m ), ? m ) | ? m = 1 R R i=1 ?L i 2 (w * (? m ), ? m ) ?? ? 1 R R i=1 ?L i 2 (w * (? m ), ? m ) ?w ? 2 L 1 (w * (? m ), ? m ) ?w?w ?1 1 J J j=1 ? 2 L j 1 (w * (? m ), ? m ) ???w = ?L 2 (w * (? m ), ? m ) ?? ? ?L 2 (w * (? m ), ? m ) ?w ? 2 L 1 (w * (? m ), ? m ) ?w?w ?1 ? 2 L 1 (w * (? m ), ? m ) ???w = ? ? L 2 (w * (? m ), ? m ).<label>(36)</label></formula><p>Based on the Lemma 4, we know that</p><formula xml:id="formula_50">? ? L 2 (w * (? m ), ? m ) is Lipschitz continuous with L ??L2 = L ?? 2 + L ?w 2 L 2 w + L w 2 L ??w . Based on Lipschitz condition, we have E [L 2 (w * (? m+1 ), ? m+1 ) | ? m ] ? E [L 2 (w * (? m ), ? m ) | ? m ] + E [ ? ? L 2 (w * (? m ), ? m ), ? m+1 ? ? m | ? m ] + L ??L2 2 E ? m+1 ? ? m 2 = L 2 (w * (? m ), ? m ) + E [? ? L 2 (w * (? m ), ? m )] , ?? ?m E ? ? L i 2 (w * (? m ), ? m ) | ? m + L ??L2 2 ? 2 ?m E ? ? L i 2 (w * (? m ), ? m ) 2 .<label>(37)</label></formula><p>From our definitions, we have</p><formula xml:id="formula_51">E [? ? L 2 (w * (? m ), ? m )] = E ? ?L2 (w * (? m ), ? m ) + e m = E ? ?L2 (w * (? m ), ? m ) + E [e m ] , E ? ?L i 2 (w * (? m ), ? m ) | ? m = E ? ?L2 (w * (? m ), ? m ) ? ? m | ? m = E ? ?L2 (w * (? m ), ? m ) , E ? ?L i 2 (w j (? m ), ? m ) 2 | ? m = E ? ?L2 (w * (? m ), ? m ) ? ? m 2 = E ? ?L2 (w * (? m ), ? m ) 2 + E ? m 2 ,<label>(38)</label></formula><p>since E(? m ) = 0. In this way, we have</p><formula xml:id="formula_52">E [L 2 (w * (? m+1 ), ? m+1 ) | ? m ] ? E [L 2 (w * (? m ), ? m ) | ? m ] ? ? ?m E ? ?L2 (w * (? m ), ? m ) 2 ? ? ?m E e m , ? ?L2 (w * (? m ), ? m ) + L ??L2 2 ? 2 ?m E ? ?L2 (w * (? m ), ? m ) 2 + L ??L2 2 ? 2 ?m E ? m 2 .<label>(39)</label></formula><p>Based on Theorem 1, we have e m C L w?</p><formula xml:id="formula_53">1 C L w 2 1 ? (1 ? ??) K+1 . In this way, for all ? ?L2 (w * (? m ), ? m ), we have e m , ? ?L2 (w * (? m ), ? m ) ? ?C L w? 1 C L w 2 1 ? (1 ? ??) K+1 ? ?L2 = ? C L w? 1 C L w 2 (1 ? ??) K+1 ? ? ?L2 ? ?L2 2 = ?P ? ?L2 2 ,<label>(40)</label></formula><p>iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients</p><formula xml:id="formula_54">where P = C L w? 1 C L w 2 (1???) K+1 ? ??L2</formula><p>. In this way, we have:</p><formula xml:id="formula_55">E [L 2 (w * (? m+1 ), ? m+1 )] ? E [L 2 (w * (? m ), ? m )] ? ? ?m (1 ? P )E ? ?L2 2 + L ??L2 2 ? 2 ?m (1 + D)E ? ?L2 2 ? E [L 2 (w * (? m ), ? m )] ? ? ?m [(1 ? P ) ? L ??L2 2 ? ?m (1 + D)]E ? ?L2 2 .<label>(41)</label></formula><p>If we choose ? ?m to make (1 ? P ) ?</p><formula xml:id="formula_56">L ?? L 2 2 ? ?m (1 + D) &gt; 0, we have ? ?m &lt; (1?P ) L ?? L 2 2 (1+D)</formula><p>. In addition, since the learning rate should be positive, we should make that 1 ? P &gt; 0, which could be reached by choose appropriate ? and K that</p><formula xml:id="formula_57">C L w? 1 C L w 2 (1???) K+1 ? ??L2 &lt; 1, where 0 &lt; 1 ? ?? ? 1.</formula><p>In this way, we could find that L 2 is decreasing with ? m , and we know that with sufficiently large m, L 2 will decrease and converge since L 2 is bounded.</p><p>Furthermore, we have:</p><formula xml:id="formula_58">E [L 2 (w * (? m ), ? m )] ? E [L 2 (w * (? m+1 ), ? m+1 )] ?? ?m [(1 ? P ) ? L ??L2 2 ? ?m (1 + D)]E ? ?L2 (w * (? m ), ? m ) 2 .<label>(42)</label></formula><p>By telescoping sum, we can show that</p><formula xml:id="formula_59">E [L 2 (w * (? 0 ), ? 0 )] ? E [L 2 (w * (? m ), ? m )] ? K k=0 q t E ? ?L2 (w * (? m ), ? m ) 2 ,<label>(43)</label></formula><formula xml:id="formula_60">where q t = ? ?m [(1?P )? L ?? L 2 2 ? ?m (1+D)] &gt; 0. Since L 2 is bounded, we have K k=0 K?? q t E ? ?L2 (w * (? m ), ? m ) 2 &lt; ?.</formula><p>In addition, based on condition 3, we have </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Practical implementation of hypergradient</head><p>As described, our iDARTS is built based on the DARTS framework with reformulation the hypergradient calculation as:</p><formula xml:id="formula_61">? ?L2 = ?L 2 ?? ? ? ?L 2 ?w K k=0 I ? ? ? 2 L 1 ?w?w k ? 2 L 1 ???w .<label>(44)</label></formula><p>where the different part is the I ? ? ? 2 L1 ?w?w k . As known, it is costly to calculate the Hessian matrix ? 2 L1 ?w?w and ? 2 L1 ???w for a large neural network, and we propose two approximations to reduce the computational cost for pracyical implementation, as described below.   where we define</p><formula xml:id="formula_62">?L 2 ?w K k=0 I ? ? ? 2 L 1 ?w?w k = K k=0 ?L 2 ?w I ? ? ? 2 L 1 ?w?w k = K k=0 V 0 [I ? ?H] k = V 0 + V 1 + V 2 + ... + V k .<label>(45)</label></formula><formula xml:id="formula_63">V 0 = ?L2 ?w , H = ? ? 2 L1 ?w?w , and V 1 = V 0 (I ? H), V 2 = V 1 (I ? H), ..., V K = V K?1 (I ? H). We can find that, ?L2 ?w K k=0 I ? ? ? 2 L1</formula><p>?w?w k could be calculated with K steps of Hessian-vector product. </p><formula xml:id="formula_64">?L 1 (w + A, ?) ?? = ?L 1 (w, ?) ?? + ? 2 L 1 (, ?) ???w A + ..., ?L 1 (w ? A, ?) ?? = ?L 1 (w, ?) ?? ? ? 2 L 1 (w, ?) ???w A + ...,<label>(46)</label></formula><p>where is a very small scalar. When we replace A with ?L2</p><formula xml:id="formula_65">?w K k=0 I ? ? ? 2 L1 ?w?w k , we have ?L 2 ?w K k=0 I ? ? ? 2 L 1 ?w?w k ? 2 L 1 ???w = ?L1(w+ A,?) ?? ? ?L1(w? A,?) ?? 2 .<label>(47)</label></formula><p>As described, the proposed approximated hypergradient ? ?L2 is easy to implement based on the DARTS framework with</p><formula xml:id="formula_66">only replacing ?L2 ?w to ?L2 ?w K k=0 I ? ? ? 2 L1</formula><p>?w?w k , which could be computed using the the Hessian-vector product technique.</p><p>Therefor, we can practically implement our approximated hypergradient ? ?L2 , so as the stochastic approximated hypergradient ? ?L i 2 (w j (?), ?) with minibatches based on the DARTS framework 2 .</p><p>C. Ablation study on the number of approximation terms K As we described before, there are two additional hyperparameters in our practical iDARTS, the inner optimization steps T and the number of terms for the approximation in Eq.(8). We have analyzed T in previous experiments. In this section, we analyze another hyperparameter K on the NAS-Bench-1Shot1 benchmark dataset. In the first experiment, we set a default hyperparameter T = 1 the same as DARTS for the inner supernet training to remove the bias from T . From Eq.(8) and</p><p>(3), we could further find that the hypergradient calculation in our iDARTS with T = 1 and K = 0 is the same as DARTS. <ref type="figure" target="#fig_5">Figure 4</ref> (a) (b) plots the performance of iDARTS with different K on the NAS-Bench-1Shot1. As shown, our iDARTS is very robust to K with limited training steps T = 1, where iDARTS with different K all outperform the DARTS baseline with the same inner training steps T = 1, showing the superiority of the proposed approximation over DARTS. Another interesting finding is that, our iDARTS with K = 1 and T = 1 even achieve slightly more competitive results than K &gt; 1.</p><p>An underlying reason is that, when the inner training step is too small, it is hard to achieve the local optimal w * and the corresponding hypergradient is not accurate. To further investigate the effectiveness of the proposed approximation, we consider setting enough inner training steps with T = 5, and Figure 4 (c) (d) plots the performance of iDARTS with different K on the NAS-Bench-1Shot1 under T = 5. The first impression from <ref type="figure" target="#fig_5">Figure 4</ref> is that increasing inner training steps could significantly improve the performance, where all cases with T = 5 generally outperform T = 1. Another interesting finding is that, with enough inner training steps, the number of approximation terms K has a positive impact on the performance of iDARTS. As shown in <ref type="figure" target="#fig_5">Figure 4</ref> (c) (d), increasing K also helps iDARTS converge to excellent solutions faster, verifying that the proposed ? ?L i 2 could asymptotically approach to the exact hypergradient ? ? L i 2 with the increase of approximation term K. Besides, we can find that, K = 2 is large enough to result in competitive performance for our iDARTS on NAS-Bench-1shot1, which results in similar performance as K ? 3.</p><p>We also conduct an ablation study on NAS-Bench-201 dataset to analyse the hyperparameter K, and <ref type="table" target="#tab_9">Table 3</ref> summarizes the performance of iDARTS on NAS-Bench-201 with a different number of approximation term K. The results in <ref type="table" target="#tab_9">Table  3</ref> are similar to those on the NAS-Bench-1Shot1 dataset, also showing that K has a positive impact on the performance of iDARTS. Firstly, we can find that, with the same inner training steps T = 1 as DARTS baseline, our iDARTS (T = 1, K = 1) with one approximation term outperform DARTS by large margins in this case, verifying the superiority of the proposed approximation over DARTS. Secondly, the results in <ref type="table" target="#tab_9">Table 3</ref> also demonstrate that considering more approximation terms does indeed help improve our iDARTS to a certain degree. With enough inner training steps, the performance of iDARTS increases with K from 0 to 2. Another interesting finding is that the performance of iDARTS does not always increase with the K, and there is a decrease for K ? 3. One underlying reason may be that, the iDARTS with smaller K brings more noises into the hypergradient, which in turn enhances the exploration. Several recent works <ref type="bibr" target="#b53">Zhang et al., 2020a)</ref> show the importance of the exploration in the differentiable NAS, where adding more noises into the hypergradient could improve the performance. Our experimental results suggest that a K = 2 achieves an excellent trade-off between the accuracy of hypergradient and the exploration, thus achieving the competitive performance on the NAS-Bench-201 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Experimental settings in all experiments</head><p>In the first experimental set, we choose the third search space of NAS-Bench-1Shot1 <ref type="bibr" target="#b52">(Zela et al., 2020b)</ref> to analyze iDARTS, since it is much more complicated than the remaining two search spaces and is a better case to identify the advantages of iDARTS. In Section 5.1, we analyzed the hyperparameter T for our iDARTS and compared it with baseline on the NAS-Bench-1Shot1, and we set another hyperparameter K = 3 in all cases. In Appendix C, we further conduct the ablation study to investigate another important hyperparameter K, where we consider two cases with T = 1 and T = 5, and the remaining experimental settings are the same as the default settings.</p><p>In the second experimental set, we choose the NAS-Bench-201 dataset <ref type="bibr" target="#b13">(Dong &amp; Yang, 2020)</ref> to analyze differentiable NAS methods. In Section 5.2, we first conduct a comparison experiment with several NAS baselines, and the hyperparameters for our iDARTS in this experiments are T = 4, K = 2, and ?=0.01. Then we conduct a series ablation studies to investigate three important hyperparameters, inner supernet training steps T , supernet learning rate ?, and architecture learning rate ? ? . In the experiment for the investigation of T , see <ref type="figure" target="#fig_1">Figure 2</ref> (a), we set K = 1 and other hyperparameters are default settings. In the <ref type="figure" target="#fig_1">Figure 2 (b)</ref> and (c), we set T = 4 and K = 1 to investigate both the supernet learning rate ? and architecture learning rate ? ? . In Appendix C, we also analyze the impact of K in iDARTS on NAS-Bench-201 dataset, where we set T = 4 and ?=0.01, and the remaining settings are the default.</p><p>In the common DARTS search space, we follow the experimental settings in  to compare with the state-ofthe-art NAS methods. We search for micro-cell structures on CIFAR-10 to stack more cells to form the final structure for</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Validation and test errors of iDARTS with different T and DARTS on the search space 3 of NAS-Bench-1Shot1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Hyperparameter analysis of iDARTS on the NAS-Bench-201 benchmark dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>The best cells discovered by iDARTS on the DARTS search space.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>t = ?, which imply that lim k?? E ? ?L2 (w * (? m ), ? m ) = 0, so as lim m?? E ? ?L i 2 (w j (? m ), ? m ) = 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Ablation study on K for iDARTS with T = 1 and T = 5 on NAS-Bench-1Shot1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>summarizes the performance of iDARTS on NAS-Bench-201 compared with differentiable NAS baselines, where the statistical results are obtained from independent search experiments with different random seeds. As shown, our iDARTS achieved excellent results on the NAS-Bench-201 benchmark and significantly outperformed the DARTS baseline, with a 93.76%, 71.11%, and 41.44% test accuracy on CIFAR-10, CIFAR-100, and ImageNet, respectively. As described in Section 4, iDARTS is built based on the DARTS framework, with only reformulating the hypergradient calculation. These results inTable 1verified the effectiveness of our iDARTS, which outperforms DARTS by large margins.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Comparison results with NAS baselines on NAS-Bench-201. Pham et al., 2018) 37.51?3.19 53.89?0.58 13.37?2.35 13.96?2.33 15.06?1.95 14.84?2.10 RandomNAS (Li &amp; Talwalkar, 2019) 80.42?3.58 84.07?3.61 52.12?5.55 52.31?5.77 27.22?3.24 26.28?3.09 SETN<ref type="bibr" target="#b12">(Dong &amp; Yang, 2019b)</ref> 84.04?0.28 87.64?0.00 58.86?0.06 59.single run achieves 93.76%, 71.11%, and 41.44% test accuracy on CIFAR-10, CIFAR-100, and ImageNet, respectively.</figDesc><table><row><cell></cell><cell cols="2">Method</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">CIFAR-10 Valid(%) Test(%)</cell><cell>CIFAR-100 Valid(%) Test(%)</cell><cell>ImageNet-16-120 Valid(%) Test(%)</cell></row><row><cell cols="10">ENAS (05?0.24</cell><cell>33.06?0.02</cell><cell>32.52?0.21</cell></row><row><cell cols="4">GDAS (Dong &amp; Yang, 2019a)</cell><cell></cell><cell></cell><cell cols="4">89.88?0.33 93.40?0.49 70.95?0.78 70.33?0.87</cell><cell>41.28?0.46</cell><cell>41.47?0.21</cell></row><row><cell cols="3">DARTS (Liu et al., 2019)</cell><cell></cell><cell></cell><cell></cell><cell cols="4">39.77?0.00 54.30?0.00 15.03?0.00 15.61?0.00</cell><cell>16.43?0.00</cell><cell>16.32?0.00</cell></row><row><cell cols="2">iDARTS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">89.86?0.60 93.58?0.32 70.57?0.24 70.83?0.48 40.38?0.593 40.89?0.68</cell></row><row><cell cols="2">optimal</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>91.61</cell><cell></cell><cell>94.37</cell><cell>74.49</cell><cell>73.51</cell><cell>46.77</cell><cell>47.31</cell></row><row><cell cols="2">T=2 iDARTS's best T=1 86 92 88 90 Valid accuracy</cell><cell>T=3</cell><cell>T=4</cell><cell>Test accuracy</cell><cell>90 95 91 92 93 94</cell><cell>T=1</cell><cell>T=2</cell><cell>T=3</cell><cell>T=4</cell></row><row><cell></cell><cell cols="8">(a) Validation and test performance with different T</cell></row><row><cell></cell><cell>92</cell><cell></cell><cell></cell><cell></cell><cell>96</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Valid accuracy</cell><cell>86 88 90</cell><cell></cell><cell></cell><cell>Test accuracy</cell><cell>88 90 92 94</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">=0.001 0.005 0.01 0.025 0.05</cell><cell></cell><cell>86</cell><cell cols="4">=0.001 0.005 0.01 0.025 0.05</cell></row><row><cell></cell><cell cols="8">(b) Validation and test performance with different ?</cell></row><row><cell></cell><cell>90</cell><cell></cell><cell></cell><cell></cell><cell>95</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Valid accuracy</cell><cell>80 85</cell><cell></cell><cell></cell><cell>Test accuracy</cell><cell>85 90</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>75</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>= 1e -4 3e -4 1e -3</cell><cell cols="2">5e -3 1e -2</cell><cell></cell><cell></cell><cell cols="2">= 1e -4 3e -4 1e -3</cell><cell cols="2">5e -3 1e -2</cell></row><row><cell></cell><cell cols="8">(c) Validation and test performance with different ??</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Comparison results with state-of-the-art weight-sharing NAS approaches.</figDesc><table><row><cell>Method</cell><cell cols="3">Test Error (%) CIFAR-10 CIFAR-100 ImageNet</cell><cell cols="3">Param +? Architecture (M) (M) Optimization</cell></row><row><cell>NASNet-A (Zoph &amp; Le, 2017)</cell><cell>2.65</cell><cell>17.81</cell><cell>26.0 / 8.4</cell><cell>3.3</cell><cell>564</cell><cell>RL</cell></row><row><cell>PNAS (Liu et al., 2018)</cell><cell>3.41?0.09</cell><cell>17.63</cell><cell>25.8 / 8.1</cell><cell>3.2</cell><cell>588</cell><cell>SMBO</cell></row><row><cell>AmoebaNet-A (Real et al., 2019)</cell><cell>3.34?0.06</cell><cell>-</cell><cell>25.5 / 8.0</cell><cell>3.2</cell><cell>555</cell><cell>EA</cell></row><row><cell>ENAS (Pham et al., 2018)</cell><cell>2.89</cell><cell>18.91</cell><cell>-</cell><cell>4.6</cell><cell>-</cell><cell>RL</cell></row><row><cell>EN 2 AS (Zhang et al., 2020d)</cell><cell>2.61?0.06</cell><cell>16.45</cell><cell>26.7 / 8.9</cell><cell>3.1</cell><cell>506</cell><cell>EA</cell></row><row><cell cols="2">RandomNAS (Li &amp; Talwalkar, 2019) 2.85?0.08</cell><cell>17.63</cell><cell>27.1</cell><cell>4.3</cell><cell>613</cell><cell>random</cell></row><row><cell>NSAS (Zhang et al., 2020a)</cell><cell>2.59?0.06</cell><cell>17.56</cell><cell>25.5 / 8.2</cell><cell>3.1</cell><cell>506</cell><cell>random</cell></row><row><cell>PARSEC (Casale et al., 2019)</cell><cell>2.86?0.06</cell><cell>-</cell><cell>26.3</cell><cell>3.6</cell><cell>509</cell><cell>gradient</cell></row><row><cell>SNAS (Xie et al., 2019)</cell><cell>2.85?0.02</cell><cell>20.09</cell><cell>27.3 / 9.2</cell><cell>2.8</cell><cell>474</cell><cell>gradient</cell></row><row><cell>SETN (Dong &amp; Yang, 2019b)</cell><cell>2.69</cell><cell>17.25</cell><cell>25.7 / 8.0</cell><cell>4.6</cell><cell>610</cell><cell>gradient</cell></row><row><cell>MdeNAS (Zheng et al., 2019)</cell><cell>2.55</cell><cell>17.61</cell><cell>25.5 / 7.9</cell><cell>3.6</cell><cell>506</cell><cell>gradient</cell></row><row><cell>GDAS (Dong &amp; Yang, 2019a)</cell><cell>2.93</cell><cell>18.38</cell><cell>26.0 / 8.5</cell><cell>3.4</cell><cell>545</cell><cell>gradient</cell></row><row><cell>XNAS* (Nayman et al., 2019)</cell><cell>2.57?0.09</cell><cell>16.34</cell><cell>24.7 / 7.5</cell><cell>3.7</cell><cell>600</cell><cell>gradient</cell></row><row><cell>PDARTS (Chen et al., 2019a)</cell><cell>2.50</cell><cell>16.63</cell><cell>24.4 / 7.4</cell><cell>3.4</cell><cell>557</cell><cell>gradient</cell></row><row><cell>PC-DARTS (Xu et al., 2020)</cell><cell>2.57?0.07</cell><cell>17.11</cell><cell>25.1 / 7.8</cell><cell>3.6</cell><cell>586</cell><cell>gradient</cell></row><row><cell>DrNAS (Chen et al., 2020)</cell><cell>2.54?0.03</cell><cell>16.30</cell><cell>24.2 / 7.3</cell><cell>4.0</cell><cell>644</cell><cell>gradient</cell></row><row><cell>DARTS (Liu et al., 2019)</cell><cell>2.76?0.09</cell><cell>17.54</cell><cell>26.9 / 8.7</cell><cell>3.4</cell><cell>574</cell><cell>gradient</cell></row><row><cell>iDARTS</cell><cell>2.37?0.03</cell><cell>16.02</cell><cell>24.3 / 7.3</cell><cell>3.8</cell><cell>595</cell><cell>gradient</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>. As shown,</cell></row><row><cell>iDARTS delivers a competitive result with 16.02% test er-</cell></row><row><cell>ror on the CIFAR-100 dataset, which is a state-of-the-art</cell></row><row><cell>performance and outperforms peer algorithms by a large</cell></row><row><cell>margin. On the ImageNet dataset, the best-discovered archi-</cell></row><row><cell>tecture by our iDARTS also achieves a competitive result</cell></row><row><cell>with 24.4 / 7.3 % top1 / top5 test error, outperforming or</cell></row><row><cell>on par with all peer algorithms. Please note that, although</cell></row><row><cell>DrNAS achieved outstanding performance on ImageNet, the</cell></row><row><cell>number of multiply-add operations of its searched model is</cell></row><row><cell>much over 600 M, violating the mobile-setting.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Approximation 1 :</head><label>1</label><figDesc>Although it is hard to directly calculate the Hessian matrix ? 2 L1 ?w?w , we could consider Hessian-vector product technique with autograd to calculate ?L2 ?w ? ? 2 L1 ?w?w . In this way, we can calculate ?L2</figDesc><table><row><cell>?w</cell><cell>K k=0 I ? ? ? 2 L1 ?w?w</cell><cell>k</cell><cell>step by</cell></row><row><cell>step:</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Approximation 2 :</head><label>2</label><figDesc>Apart from the Hessian matrix ? 2 L1 ?w?w , it is also costly to calculate ? 2 L1 ???w for large neural networks, and we follow DARTS to use the Taylor expansion to approximate ? 2 L1 ???w</figDesc><table><row><cell></cell><cell>. After calculating ?L2 ?w</cell><cell>K k=0 I ? ? ? 2 L1 ?w?w</cell><cell>k</cell><cell>,</cell></row><row><cell>considering the function ?L1(w,?) ??</cell><cell>with Taylor expansion, we have</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 3 .</head><label>3</label><figDesc>Ablation study on K for iDARTS with on NAS-Bench-201. = 1, K = 0) 39.77?0.00 54.30?0.00 15.03?0.00 15.61?0.00 16.43?0.00 16.32?0.00 iDARTS(T = 1, K = 1) 86.85?0.93 89.67?1.31 64.09?2.92 64.17?3.26 36.26?5.71 36.11? 5.77 iDARTS(T = 4, K = 0) 87.31?1.33 90.36?1.79 64.76?2.54 64.43?2.47 32.53?1.31 32.42?1.54 iDARTS(T = 4, K = 1) 89.30?1.47 92.44?1.14 67.88?1.86 68.17?2.81 37.11?7.79 36.61?7.47 iDARTS(T = 4, K = 2) 89.86?0.60 93.58?0.32 70.57?0.24 70.83?0.48 40.38?0.59 40.89?0.68 iDARTS(T = 4, K = 3) 89.35?0.03 92.29?0.26 68.51?0.77 68.58?1.18 42.37?0.48 42.26?0.41</figDesc><table><row><cell>Method</cell><cell>CIFAR-10 Valid(%) Test(%)</cell><cell>CIFAR-100 Valid(%) Test(%)</cell><cell>ImageNet-16-120 Valid(%) Test(%)</cell></row><row><cell>DARTS(T</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The codes and training log files could be found in the supplementary material. The best trained models on CIFAR-10, CIFR-100, and ImageNet could be found https://github.com/MiaoZhang0525/iDARTS.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>This study was supported in part by the Australian Research Council (ARC) under a Discovery Early Career Researcher Award (DECRA) No. DE190100626 and DARPA's Learning with Less Labeling (LwLL) program under agreement FA8750-19-2-0501.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Steps  <ref type="bibr" target="#b31">(Luketina et al., 2016)</ref> 1</p><p>???w Reverse-mode <ref type="bibr" target="#b15">(Franceschi et al., 2017</ref>) <ref type="bibr" target="#b44">(Shaban et al., 2019)</ref> K</p><p>architecture evaluation. There are two types of cells with the unified search space: a normal cell ? normal and a reduction cell ? reduce . Cell structures are repeatedly stacked to form the final CNN structure. There are only two reduction cells in the final CNN structure, located in the 1/3 and 2/3 depths of the network. The best architecture searched by our iDARTS on the DARTS search space is obtained with T = 4 and K = 2. In CIFAR-10, we stack 20 cells to form the final structure for training. The batch size is set as 96, and the number of initial filters is 36. We then transfer the best-searched cells to CIFAR-100 and ImageNet to evaluate the transferability. The experiment setting for the evaluation in CIFAR-100 is the same as CIFAR-10. In the ImageNet dataset, the experiment setting is slightly different from CIFAR-10 in that only 14 cells are stacked, and the number of initial channels is changed to 48, and the batch size is set as 128. We use a linear learning rate scheduler and also following PDART <ref type="bibr" target="#b5">(Chen et al., 2019a)</ref> and PCDARTS <ref type="bibr" target="#b49">(Xu et al., 2020)</ref> to use a smaller slope in the last five epochs for the architecture evaluation on the ImageNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Comparison of methods to approximate the hypergradient</head><p>We compare different hypergradient approximations in <ref type="table">Table 4</ref>, which summarizes the computational complexity and memory cost for each method. Under the assumption that Hessian vector products are computed with the autograd, we know that the compute time and memory cost for computing a Hessian vector product are with a constant factor of the compute time and memory used for computing a single derivative ?L2 ?w <ref type="bibr" target="#b39">(Rajeswaran et al., 2019;</ref><ref type="bibr" target="#b20">Griewank, 1993;</ref><ref type="bibr" target="#b21">Griewank &amp; Walther, 2008)</ref>. We denote that the memory cost for computing the gradient of supernet weight w and architecture parameters ? are P and H, respectively. We consider each step in the Steps means the computational time of computing a Hessian vector product. The Conjugate Gradient considers iterative solver (e.g., CG) to calculate the inverse of Hessian, where S is the CG solver optimization steps, and each step contains the computation of Hessian vector product.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards domain generalization using meta-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Balaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sankaranarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Metareg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="998" to="1008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Gradient-based optimization of hyperparameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1889" to="1900" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Overcoming multi-model forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Benyahia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Smires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Musat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="594" to="603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Probabilistic neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">P</forename><surname>Casale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fusi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.05116</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Stabilizing differentiable architecture search via perturbation-based regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Progressive differentiable architecture search: Bridging the depth gap between search and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1294" to="1303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Drnas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10355</idno>
		<title level="m">Dirichlet neural architecture search</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Backbone search for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Detnas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6642" to="6652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Hierarchical neural architecture search for deep stereo matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Drummond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">An overview of bilevel optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Colson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Marcotte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Savard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of operations research</title>
		<imprint>
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="235" to="256" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">On the convergence of stochastic bi-level gradient methods. Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Couellan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Searching for a robust neural architecture in four gpu hours</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">One-shot neural architecture search via self-evaluated template network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3681" to="3690" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Nas-bench-201: Extending the scope of reproducible neural architecture search. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Forward and reverse gradient-based hyperparameter optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Donini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1165" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bilevel programming for hyperparameter optimization and meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frasconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1568" to="1577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghadimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.02246</idno>
		<title level="m">Approximation methods for bilevel programming</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">On the iteration complexity of hypergradient computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Franceschi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3748" to="3758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grazzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Salzo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.07122</idno>
		<title level="m">Convergence properties of stochastic hypergradients</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Some bounds on the complexity of gradients, jacobians, and hessians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Griewank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Complexity in numerical optimization</title>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="1993" />
			<biblScope unit="page" from="128" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Evaluating derivatives: principles and techniques of algorithmic differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Griewank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Walther</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>SIAM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Updet: Universal multi-agent reinforcement learning via policy decoupling with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<idno>abs/2101.08001</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Improved differentiable architecture search for language modeling and named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3576" to="3581" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">How to escape saddle points efficiently</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Netrapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jordan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1724" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Block-wisely supervised neural architecture search with knowledge distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Seattle, WA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Bossnas: Exploring hybrid cnn-transformers with block-wisely self-supervised neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
		<idno>abs/2103.12424</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Dynamic slimmable network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Random search and reproducibility for neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talwalkar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.07638</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Progressive neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">; H</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">iDARTS: Differentiable Architecture Search with Stochastic Implicit Gradients Liu</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>ECCV. Darts: Differentiable architecture search. ICLR</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Optimizing millions of hyperparameters by implicit differentiation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lorraine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vicol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1540" to="1552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Scalable gradient-based tuning of continuous regularization hyperparameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luketina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2952" to="2960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Self-tuning networks: Bilevel optimization of hyperparameters using structured best-response functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mackay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vicol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lorraine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Grosse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Gradient-based hyperparameter optimization through reversible learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maclaurin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duvenaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adams</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2113" to="2122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Xnas: Neural architecture search with expert advice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nayman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Noy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ridnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">On first-order metalearning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Achiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hyperparameter optimization with approximate gradient</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd International Conference on International Conference on Machine Learning</title>
		<meeting>the 33rd International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="737" to="746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Efficient neural architecture search via parameter sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4092" to="4101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Metalearning with implicit gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rajeswaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kakade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="113" to="124" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Regularized evolution for image classifier architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
		<idno type="arXiv">arXiv:2006.02903</idno>
		<title level="m">A comprehensive survey of neural architecture search: Challenges and solutions</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nas-Tc</surname></persName>
		</author>
		<idno>abs/2104.01110</idno>
		<title level="m">neural architecture search on temporal convolutions for complex action recognition. CoRR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Evaluating the search phase of neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sciuto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Musat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.08142</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Truncated back-propagation for bilevel optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shaban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-A</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hatch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boots</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 22nd International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1723" to="1732" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Efficientnet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Rethinking architecture selection in differentiable nas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Rethinking architecture selection in differentiable nas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<title level="m">Snas: stochastic neural architecture search. ICLR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Pc-darts: Partial channel connections for memory-efficient architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G.-J</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Nas-bench-101: Towards reproducible neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7105" to="7114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Understanding and robustifying differentiable architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Elsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Saikia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Marrakchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Nas-bench-1shot1: Benchmarking and dissecting one-shot neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Siems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Differentiable neural architecture search in equivalent space with exploration enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Su</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Overcoming multi-model forgetting in one-shot nas with diversity maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7809" to="7818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">One-shot neural architecture search: Maximising diversity to overcome catastrophic forgetting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">One-shot neural architecture search via novelty driven sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Su</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20. International Joint Conferences on Artificial Intelligence Organization</title>
		<meeting>the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20. International Joint Conferences on Artificial Intelligence Organization</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Multinomial distribution learning for effective neural architecture search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">SOON: scenario oriented object navigation with graph-based exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<idno>abs/2103.17138</idno>
		<imprint>
			<date type="published" when="2021" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Neural architecture search with reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
