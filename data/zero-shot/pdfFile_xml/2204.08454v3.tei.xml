<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wele</forename><surname>Gedara</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaminda</forename><surname>Bandara</surname></persName>
							<email>wbandar1@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
							<email>vpatel36@jhu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Johns Hopkins University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Code available at https://github.com/wgcban/SemiCD.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Remote-sensing (RS) Change Detection (CD) aims to detect "changes of interest" from co-registered bi-temporal images. The performance of existing deep supervised CD methods is attributed to the large amounts of annotated data used to train the networks. However, annotating large amounts of remote sensing images is labor intensive and expensive, particularly with bi-temporal images, as it requires pixelwise comparisons by a human expert. On the other hand, we often have access to unlimited unlabeled multi-temporal RS imagery thanks to everincreasing earth observation programs. In this paper, we propose a simple yet effective way to leverage the information from unlabeled bi-temporal images to improve the performance of CD approaches. More specifically, we propose a semi-supervised CD model in which we formulate an unsupervised CD loss in addition to the supervised Cross-Entropy (CE) loss by constraining the output change probability map of a given unlabeled bi-temporal image pair to be consistent under the small random perturbations applied on the deep feature difference map that is obtained by subtracting their latent feature representations. Experiments conducted on two publicly available CD datasets show that the proposed semisupervised CD method can reach closer to the performance of supervised CD even with access to as little as 10% of the annotated training data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Change Detection (CD) is an important problem in remote sensing in which our goal is to identify relevant changes in bi-temporal remote sensing images that can help in various applications such as damage assessment, urban expansion monitoring, resource management, and military surveillance <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b16">16]</ref>. Depending on the application, the changes we look for in bi-temporal images also vary. For example, in the context of military surveillance and disaster management, changes in buildings may indicate a developing threat or areas to focus on for disaster relief, respectively. Therefore, an ideal CD model should be able to detect all of these application-specific changes of interest while avoiding complex irrelevant changes typically seen in remote sensing images such as changes caused by cloud cover, building shadows, different sensing angles, etc. <ref type="bibr" target="#b51">[50]</ref>.  <ref type="figure" target="#fig_7">Fig. 1</ref>. The efficiency of the proposed semi-supervised CD approach. By utilizing only 10% of the training-set of LEVIR <ref type="bibr" target="#b10">[10]</ref> in a supervised manner and remaining 90% as unsupervised data, our semi-supervised CD method is only 3.1% below the result of the supervised CD method that utilizes 100% of the LEVIR training-set.</p><p>Various CD methods have been proposed to identify these relevant changes efficiently and accurately. Of these methods, most are based on supervised learning in which a model is trained in a supervised manner using a supervised loss function such as Cross-Entropy (CE) by utilizing annotated training samples. Even though supervised CD models can avoid complex irrelevant changes to a great extent, they usually require an extensive collection of annotated training examples, which is expensive and often time-consuming -especially with bi-temporal remotesensing images as it requires comparison of two images semantically as part of the annotation process <ref type="bibr" target="#b39">[38]</ref>. Furthermore, these supervised CD models usually over-fit to the training dataset resulting in a drastic drop in performance under the domain shift <ref type="bibr" target="#b47">[46]</ref> -which is very common in remote sensing images due to the fact that different imaging sensors, different terrain conditions, seasonal variations, and different illumination conditions are possible when capturing images. On the contrary, unsupervised CD models either utilize unsupervised loss functions such as contrastive loss <ref type="bibr" target="#b15">[15]</ref> and similarity-dissimilarity loss <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b52">51,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b28">27,</ref><ref type="bibr" target="#b2">3]</ref> to identify the change regions or generative models (like GANs or any other synthetic change generation pipeline) <ref type="bibr" target="#b38">[37]</ref> to synthetically create a training dataset with known change labels to train a CD model in a supervised manner. However, the main drawback of the aforementioned unsupervised CD methods is that they are very weak in distinguishing changes of interest from irrelevant changes as no such information is given to the CD model during training <ref type="bibr" target="#b1">[2]</ref>.</p><p>To overcome the drawbacks of supervised and unsupervised CD methods mentioned above, we propose a semi-supervised CD framework. We begin our study by examining the cluster assumption for consistency-based semi-supervised learning <ref type="bibr" target="#b7">[8]</ref>, which states that the boundary between change and no-change classes should be aligned with the boundary of low-density regions. If such cluster assumption remains for CD, we can utilize consistency training to leverage the information from unlabeled bi-temporal remote sensing images by enforcing the model's predictions to be invariant over small random perturbations applied to the inputs. We demonstrate that, for CD, such cluster assumption does not hold in multi-temporal image-domain, but rather it holds in the deep feature difference-domain. Hence, we subsequently apply small random perturbations to the deep feature difference map and make the resulting change map from the deep network consistent with the one without any perturbation. Combining this unsupervised consistency loss with the supervised CE loss, we can effectively leverage the information from labeled and unlabeled multi-temporal remote sensing images to improve the CD performance compared to training the network only in a supervised way, as shown in <ref type="figure" target="#fig_7">Fig. 1</ref>. We can see that the proposed semisupervised method can almost reach the Intersection over Union (IoU) of the supervised method by only utilizing 10% of the training data that the supervised model uses for training and the remaining 90% of data in an unsupervised way via the proposed consistency regularization approach. Furthermore, since the proposed semi-supervised model is robust under the small perturbations on the feature-difference map, it can also perform relatively better on out-of-distribution (i.e., different dataset) samples as we demonstrate later in this paper.</p><p>In summary, we make the following contributions:</p><p>-We propose a semi-supervised CD paradigm based on consistency regularization. The proposed approach can effectively leverage the information from freely-available, unlabeled, multi-temporal, remote-sensing images to enhance the CD performance. To the best of our knowledge, this is the first work which proposes a deep semi-supervised approach for CD. -We reformulate the fundamental assumption of consistency-based regularization -the cluster assumption for CD. We empirically show that the cluster assumption does not hold in the bi-temporal image domain but rather it holds in the deep feature difference-domain. -Our method of leveraging information from the unlabeled, multi-temporal remote-sensing images is simple. Since, the cluster assumption holds in the deep feature difference domain, we apply small random perturbations to the deep feature difference map of a given bi-temporal image pair and make the deep network's prediction consistent with the one without any perturbation. Furthermore, this approach makes our CD model produce better change maps even under small perturbations that appear in the feature difference maps when testing on the out-of-distribution data. -Finally, we conduct extensive experiments including cross-dataset to demonstrate the effectiveness of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related works</head><p>Supervised CD. Given a set of bi-temporal image pairs and their corresponding ground-truth change labels, supervised CD methods train a model by minimizing the Cross-Entropy (CE) loss over the training dataset <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">9]</ref>. These supervised CD networks are mainly based on convolutional neural networks <ref type="bibr" target="#b16">[16,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b54">53,</ref><ref type="bibr" target="#b50">49,</ref><ref type="bibr" target="#b37">36,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b44">43,</ref><ref type="bibr" target="#b43">42]</ref>, attention/transformer architectures <ref type="bibr" target="#b0">[1]</ref>, or the combination of both <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b13">13,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b53">52,</ref><ref type="bibr" target="#b18">18]</ref>. Since it is required to perform some form of comparison between the pre-change and post-change image to obtain the change map, the existing methods either adopt: (1) Early fusion <ref type="bibr" target="#b49">[48,</ref><ref type="bibr" target="#b56">55,</ref><ref type="bibr" target="#b42">41,</ref><ref type="bibr" target="#b17">17,</ref><ref type="bibr" target="#b16">16]</ref>, which processes fused pre-change and post-change images along the spectral dimension through the CD network, (2) Siamese-concatenation <ref type="bibr" target="#b55">[54,</ref><ref type="bibr" target="#b16">16]</ref>, in which hidden features of pre-change and post-change images from a shared encoder are concatenated and then processed through the decoder to obtain the change map, or (3) Siamese-difference <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b9">9,</ref><ref type="bibr" target="#b16">16]</ref>, in which the absolute difference of the hidden features of a pre-change and a post-change are processed through the decoder to obtain the change map. Among these three methods, the Siamese difference has been shown to produce better results in many cases, making it the basic architecture for the CD problem. However, due to the limited annotated training-data, most of these architectures rely on transfer learning <ref type="bibr" target="#b9">[9,</ref><ref type="bibr" target="#b12">12]</ref> as the starting point of the CD network (or part of the network like encoder) that have been trained on a larger dataset for a different problem like ImageNet classification <ref type="bibr" target="#b25">[24]</ref>. However, this approach is limited in the sense that it assumes similarities between the natural images and remote sensing data <ref type="bibr" target="#b27">[26]</ref>, and is unable to utilize freely-available, unlabeled remote sensing data particularly in to the CD problem. In order to fully utilize the available unlabeled remote sensing data into the CD problem and to reduce the dependency on a large number of annotated training samples, there is a growing interest among researchers to explore semi-supervised methods for CD. Semi-supervised CD methods on individual image pairs. Semi-supervised learning introduces regularization on unlabeled data to improve supervised learning, making it possible to train a CD model with limited annotated data without outfitting it on the labeled-training set. How to effectively harness the information from unlabeled bi-temporal images to improve the CD performance is a longstanding question, and researchers have attempted various methods to answer this question in the past. Among these, Bovolo et al. <ref type="bibr" target="#b2">[3]</ref> proposed a semi-supervised CD on multispectral images using a properly defined S 3 VM technique and an unsupervised model selection strategy based on a similarity measure. Later, Chen et al. <ref type="bibr" target="#b14">[14]</ref> introduced the Gaussian process for semi-supervised CD in which difference images are first generated, and then both the labeled and unlabeled data was exploited by a probabilistic GP classifier. In order to overcome the shortcomings of the GP classifier and include the spatial contextual information, MRF regularization was employed by introducing edge information and high-order potentials. Furthermore, Ghosh et al. <ref type="bibr" target="#b20">[20]</ref> proposed a semi-supervised CD method based on a Self-Organizing Feature Map (SOFM), where only a few labeled patterns were utilized to initialize the SOFM network, and fuzzy set theory was then employed determine the membership values of the unlabeled data. Apart from these methods, Yuan et al. <ref type="bibr" target="#b52">[51]</ref> introduced the metric learning to semi-supervised CD. In this method, first, a proper distance metric was learned so that the no-change class pixels are mapped closely to each other, while pixels from the change class are mapped further apart as much as possible. Next, the unlabeled data were incorporated into the CD problem via a Laplacian regularized framework. However, all of these semi-supervised CD methods mentioned above only investigate the individual image pairs and cannot leverage the information from a large amount of unlabeled images, which is essential for large-scale real-world applications.</p><p>Semi-supervised CD with a large amount of unlabeled images. Only a very few works have focused on CD with a large amount of unlabeled RS images.</p><p>In a more recent work, Peng et al. <ref type="bibr" target="#b36">[35]</ref> proposed a solution to the above problem through a Generative Adversarial Network (GAN). The proposed method is based on two assumptions: the segmentation and entropy maps between the labeled and unlabeled data must follow the same distribution. Subsequently, two discriminators are adopted to reinforce these two assumptions. However, we argue that these two assumptions do not hold when the labeled and unlabeled change maps have different distributions and thus preventing us from utilizing images from another dataset to the CD problem. In contrast, our method enforces consistency between the network's predictions under small random perturbations applied in the hidden feature difference domain, allowing us to combine unlabeled RS images to the training process even from another domain, resulting in better generalization performance over multiple datasets.</p><p>Consistency regularization. Among the many approaches available for semisupervised learning, consistency training has shown state-of-the-art performance in different applications such as classification <ref type="bibr" target="#b34">[33,</ref><ref type="bibr" target="#b41">40,</ref><ref type="bibr" target="#b45">44]</ref>, semantic segmentation <ref type="bibr" target="#b35">[34,</ref><ref type="bibr" target="#b29">28,</ref><ref type="bibr" target="#b26">25]</ref>, object detection <ref type="bibr" target="#b22">[22]</ref>, and image-to-image translation <ref type="bibr" target="#b48">[47,</ref><ref type="bibr" target="#b33">32]</ref>. The consistency regularization is inspired by two interconnected assumptions: the cluster assumption and the low-density separation assumption. The cluster assumption states that if two samples belong to the same cluster in the input distribution, they are likely to belong to the same class, which indirectly infers the low-density assumption which states that the decision boundary separating the two classes should lie in the low-density regions <ref type="bibr" target="#b7">[8]</ref>. Thus, consistency regularization methods enforce the low-density separation assumption by encouraging the deep network f to produce invariant prediction f (u) = f (u + ?) for random perturbation ? applied on unlabeled data point u. However, applying this formulation directly to the semi-supervised CD problem is challenging because adding perturbations to the input bi-temporal images could introduce new changes that may confuse the CD network during training and can result in poor CD performance. We suspect this is why consistency regularization has not been explored in the context of CD. In this paper, we show that the semi-supervised CD can also benefit from consistency regularization with impressive results by reformulating it appropriately to the CD problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The cluster assumption in CD</head><p>The cluster assumption is the key to successfully applying consistency regularization in semi-supervised learning. The cluster assumption states that when low-density regions separate classes, we can efficiently utilize unlabeled data to refine the decision boundaries by consistency regularization. Following this notion, we can redefine the cluster assumption for the CD problem, where we can think of low-density regions as the regions with no-changes and high-density regions as change regions. Therefore, for CD, the cluster assumption holds if the boundary between low-density and high-density regions align with the boundary between change and no-change classes of the ground-truth change map. If the</p><formula xml:id="formula_0">(a) (b) (c) (d) (e)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Low-density regions</head><p>High-density regions cluster assumption holds for CD, we can apply small random perturbations to each data point and make the predicted change map from the deep network to be consistent. As one can realize, we cannot guarantee such consistency when change and no-change class clusters overlap with each other, as applying a small perturbation could lead to altered class labels. Having formulated the cluster assumption for CD, let us now try to visualize it in both the input bi-temporal image domain and the hidden feature difference domain. To visualize the cluster assumption in the input bi-temporal image domain, we compute the average L 2 distance between a patch of size 15 ? 15 with its immediately neighboring eight patches. In this case, we consider input bi-temporal image I as the concatenation of pre-change I A and post-change image I B along their spectral dimension. In order to visualize the cluster assumption in the hidden feature difference domain, we compute the average square distance between the 512?dimensional hidden feature difference vector and its eight immediately neighboring vectors. In <ref type="figure" target="#fig_0">Fig.  2</ref>, we visualize the average L 2 distance in the input bi-temporal image domain and hidden feature difference domain for two example images from the LEVIR dataset <ref type="bibr" target="#b10">[10]</ref>. From <ref type="figure" target="#fig_0">fig. 2 -(d)</ref> and (e), one can notice that the cluster assumption for CD does not hold in the input bi-temporal image domain since the low-density regions (in blue color) do not align with the boundaries of the change-class. In contrast, the cluster assumption holds for the hidden feature difference domain where the change-class has a high average distance, corresponding to high-density regions.</p><p>Since, the cluster assumption for CD holds in hidden feature difference domain, we can now utilize consistency regulation to leverage the information from freely-available, unlabeled, bi-temporal remote-sensing images to enhance the performance of supervised CD. The Encoder. For the encoder, we use a pre-trained ResNet50 <ref type="bibr" target="#b21">[21]</ref>. The output of the encoder is a 2048-dimensional feature cube with a spatial resolution of H/4 ? W/4, where H and W are the height and width of the input bi-temporal image {I A , I B }, respectively. In particular, we utilize the encoder in a Siamese network architecture <ref type="bibr" target="#b3">[4]</ref>, where we share the weights of the encoder with prechange I A and post-change I B image to obtain their hidden feature representations F A and F B . We can mathematically formulate the above process as:</p><formula xml:id="formula_1">F A = f e (I A ),<label>(1)</label></formula><formula xml:id="formula_2">F B = f e (I B ).<label>(2)</label></formula><p>The feature difference module. Once we have the hidden feature representations F A and F B from the encoder for a given bi-temporal image {I A , I B }, we compute the absolute difference between F A and F B to obtain the difference in the hidden features, and subsequently process it through a Pyramid Pooling Module (PPM) <ref type="bibr" target="#b57">[56]</ref> f PPM to effectively harvest changes in different scales. We denote the output from the above process as hidden feature difference F d of bi-temporal image {I A , I B }. We can mathematically express the process inside the feature difference module as:</p><formula xml:id="formula_3">F d = f PPM (|F A ? F B | 1 ) .<label>(3)</label></formula><p>The decoder f d . The purpose of the decoder is to estimate the output change probability map? from the hidden feature difference F d . We use series of subpixel convolutional upsampling modules <ref type="bibr" target="#b40">[39]</ref>, until we reach the spatial resolution of the input bi-temporal images H ? W . The process inside the decoder can mathematically express as:? = f d (F d ).</p><p>(4) We optimize the parameters of our CD model f CD (?) = f d (f PPM (f e (?))) using the proposed semi-supervised technique which utilizes labeled as well as unlabeled bi-temporal images available for training.</p><p>Learning from labeled data (supervised phase). In this phase, we optimize the parameters of our CD network f CD (?) to predict only the changes of interest implied by the labeled training data:</p><formula xml:id="formula_4">D l = {I l A,i , I l B,i }, y l i N l i=1 , where {I l A,i , I l B,i } denotes the i-th bi-temporal image, y l i</formula><p>is the corresponding ground-truth change mask, and N l is the size of the labeled dataset. To this end, we utilize the Cross Entropy (CE) loss <ref type="bibr" target="#b32">[31]</ref> as the supervised loss L sup which measures the performance of the predicted change probability map? l i = f CD (I l A,i , I l B,i ) compared to the actual change map y l i as:</p><formula xml:id="formula_5">L sup = CE(? l i , y l i ).<label>(5)</label></formula><p>The above process is graphically depicted in <ref type="figure" target="#fig_0">Fig. 2 -(a)</ref>.</p><p>Learning from unlabeled data (unsupervised phase). In this phase, we make use of unlabeled bi-temporal images D ul = I ul A,i , I ul</p><formula xml:id="formula_6">B,i N ul i=1</formula><p>in addition to the labeled data D l , where {I ul A,i , I ul B,i } is the i-th unlabeled bi-temporal image and N ul is the size of the unlabeled dataset which is generally assumed to be higher than the size of the labeled dataset (i.e., N ul &gt;&gt; N l ). Now, our goal is to effectively utilize this readily-available unlabeled bi-temporal images to improve the performance of our change detection model f CD (?) over the case where we have only labeled data. To archive this goal, we formulate an unsupervised loss L unsup based on unlabeled data which provides an additional training signal to optimize the parameters of f CD (?). Our unsupervised loss is based on the cluster assumption in CD that we presented in Sec. 3.1, where we enforce the predictions of our f CD (?) to be consistent under small random perturbations applied on the deep feature difference map F d as shown in <ref type="figure" target="#fig_0">Fig. 2-(</ref></p><formula xml:id="formula_7">b). Let's define ( F ul d,i ) 1 , ? ? ? , ( F ul d,i ) p , ? ? ? , ( F ul d,i</formula><p>) p=Np as the set of randomly perturbed versions of the hidden feature difference F ul d,i of the i-th unlabeled bi-temporal image pair {I ul A,i , I ul B,i }. Next, we process F ul d,i through our main decoder f d (?) and obtain the predicted change probability map as:</p><formula xml:id="formula_8">y ul i = f d F ul d,i .<label>(6)</label></formula><p>Similarly, we process each perturbed version of the hidden feature difference map through a set of N p auxiliary decoders which are similar in design as f d (?) and obtain their corresponding predictions ( y ul i ) p as:</p><formula xml:id="formula_9">y ul i p = f p d ( F ul d,i ) p , where p = 1, . . . , N p .<label>(7)</label></formula><p>Next, we enforce y ul i p Np p=1 to be consistent with? ul i by defining the unsupervised loss L unsup as follows:</p><formula xml:id="formula_10">L unsup = Np p=1 d y ul i p ,? ul i ,<label>(8)</label></formula><p>where d(?) is a distance metric that measures the dissimilarity between the predictions y ul i p and? ul i . For our experiments we use d(?) as the mean squares error (MSE).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Types of perturbations.</head><p>In our experiments, we use following perturbations: : To make our feature difference map isotropically smooth around each data vector, we apply adversarial perturbation to it in the direction where it will alter most as: F ul d,i = p adv + F ul d,i .</p><p>Final loss function. We define our final loss function L as follows,</p><formula xml:id="formula_11">L = L sup + ?(t)L unsup ,<label>(9)</label></formula><p>where ?(t) is a regularization constant which is a function of the training iteration number t. In particular, we vary ?(t) from 0 to 1 like the Gaussian function for the first T number of iterations and keep it constant at 1 for the remaining iterations t &gt; T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental setup</head><p>Datasets. We use two publicly available, widely-used CD datasets for our experiments, namely LEVIR <ref type="bibr" target="#b10">[10]</ref> and WHU <ref type="bibr" target="#b23">[23]</ref>. The LEVIR and WHU are building CD datasets. Following previous works on supervised CD [9,1], we create non-overlapping patches of size 256 ? 256 for the training, for both the datasets while utilizing their default train, val, and test sets. In the semi-supervised setting, we randomly select the required number of labeled training data for each case from the original train-set and consider the rest of the images in the train-set as unlabeled data by discarding the corresponding change labels. We optimize CD models on val-set and report the results on the test-set. Performance metrics. Following [9,1], we use Intersection over Union (IoU ) as the primary performance metric to quantify the CD model's performance.</p><p>Since a better CD model should predict both change and no-change regions correctly, we report IoU metric w.r.t. change-class (IoU c ) along with the overall pixel accuracy (OA) which measures the proportion of correctly predicted pixels. Implementation details. We implemented our model in PyTorch and trained using an NVIDIA Quadro RTX 8000 GPU. During training, we applied data augmentation through random flip, random re-scale (0.8 ? 1.2), random crop, Gaussian blur, and random color jittering. The learning rate is initially set equal to 0.01. We trained the model for 80 epochs, and used a batch size of 8 for both labeled and unlabeled datasets. The code and pre-trained models will be publicly made available after the review process. Please refer supplementary material for more details on the experimental setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and discussion</head><p>In order to demonstrate the superiority of our semi-supervised CD method, we perform both quantitative and qualitative comparisons with SOTA methods. As we discussed in Sec. 2, SemiCDNet <ref type="bibr" target="#b36">[35]</ref> is the current and the only SOTA method available for semi-supervised CD. However, to make the analysis more comprehensive, we also compare our proposed method with SOTA semi-supervised segmentation methods, namely AdvNet <ref type="bibr" target="#b46">[45]</ref> and s4GAN <ref type="bibr" target="#b30">[29]</ref> by properly reimplementing them for the CD task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experiments within the same dataset</head><p>In this experiment, we compare the CD performance of our method with SOTA methods where training and testing were performed on the same dataset (denoted by LEVIR?LEVIR and WHU?WHU 1 ). <ref type="table" target="#tab_1">Table 1</ref> summarizes the IoU c and OA showing that "one can achieve better results when there is access to more labeled data." (2) However, for the same amount of labeled data, all semi-supervised CD methods (i.e., AdvNet <ref type="bibr" target="#b46">[45]</ref>, s4GAN <ref type="bibr" target="#b30">[29]</ref>, and SemiCDNet <ref type="bibr" target="#b36">[35]</ref>) give better results than supervised CD, empirically validating that "CD can benefit from the freely available, unlabeled, remote-sensing data". (3) Notably, our semi-supervised CD method outperforms the SOTA SemiCDNet method <ref type="bibr" target="#b36">[35]</ref> by a significant margin, empirically demonstrating that our method can leverage information from unlabeled data more efficiently than its counterparts. More importantly, when the amount of labeled data is very less (5% and 10% of cases), our method significantly outperforms the SOTA method by at least a 5% increase in the IoU metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Model generalizability/transferability</head><p>In this experiment, our goal is to test how well our model generalizes to other datasets compared to the SOTA methods. To analyze this, we take the models trained in the previous Section 5.1 and test them on another dataset for the same task. In particular, models trained on LEVIR are tested on WHU and vice versa. Note that both LEVIR and WHU are building CD datasets; therefore, if the model is well generalized, then it should give better CD results not only for the one we trained but also on the other datasets. <ref type="table" target="#tab_2">Table 2</ref> summarizes the results from LEVIR ? WHU and WHU ? LEVIR with different % of labeled data used in training. The key takeaways from Tab. 2 can be summarized as follows: (1) Semi-supervised CD models produce better CD results than the supervised model, confirming the generally accepted belief that "supervised methods are generally less generalized." (2) In particular, the proposed method archives outstanding CD results in both datasets, confirming that our method is much more generalized than the SOTA methods. Especially in the case where the labeled data is less (i.e., 5% and 10%), the improvement of the proposed method over the SOTA is more than 22%, which demonstrates a strong capability of generalization. This could be because the proposed approach is trained to produce consistent results even under small perturbations that appear on hidden feature difference maps -making it more robust and generalized to slight variations appearing on the hidden feature differences when testing on another dataset.    SOTA methods are less generalized compared to our method can be explained as follows. As we explained in Section 2, the SOTA method uses adversarial loss to exploit information from unlabeled data where it assumes that the change maps for both labeled and unlabeled data follow the same distribution. This forces the CD network to predict change maps similar to the ones seen during training, leading to poor generalization when the target data follows a different distribution. In contrast, we do not assume such an assumption and utilize the consistency training to leverage the information from unlabeled data, making it a more generalized CD method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Cross-dataset experiments</head><p>"Is it possible to improve CD results on one dataset by incorporating unlabeled remote sensing data from a different dataset?". To answer this question, in this experiment, we incorporate two datasets into the semi-supervised training process in which LEVIR is utilized as the labeled dataset and WHU is considered as the unlabeled dataset. We denote this scenario as: {LEVIR(sup.%), WHU(unsup.)} ? LEVIR. The quantitative results of this experiments are summarized in Tab. 3. From Tab. 3, it is clear that by incorporating unlabeled data even from another dataset can generally improve the CD results. More importantly, we can see that the proposed method outperforms the SOTA method SemiCDNet <ref type="bibr" target="#b36">[35]</ref> by a significant margin in all cases, further demonstrating the higher capability of our method in leveraging the information from unlabeled data. Furthermore, we also present a qualitative comparison of our method with the SOTA methods in <ref type="figure">Fig</ref>   the figure by different colors of arrow heads, our method is able to predict more difficult changes accurately than all the methods under consideration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Ablation study</head><p>In this ablation study, we demonstrate how different perturbations that we discussed in Sec. 3.2 contribute to the semi-supervised learning process. To demonstrate this, we conduct an experiment on LEVIR with 10% labeled samples (i.e., LEVIR (10%) ? LEVIR). Starting from no-perturbations (i.e., supervised case) we progressively incorporate random Feature Noise (FN), random Feature Drop (FD), Guided Feature Cutout (GFC), Context &amp; Object masking (C&amp;T), and Feature-VAT (F-VAT) into the semi-supervised learning process, and the corresponding quantitative and qualitative results are summarized in Tab. 4 and <ref type="figure" target="#fig_6">Fig. 6</ref>, respectively. As we can see both qualitatively and quantitatively, adding different types of random perturbations into the hidden feature difference map and then making the resulting change prediction map from the deep-network to be consistent results in significant improvement in the CD, while utilizing the same amount of annotated training images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we proposed a novel semi-supervised CD method that can leverage information from unlabeled RS data to improve the performance of CD by enforcing the predicted change probability map from the CD network to be consistent under different random perturbations applied on the hidden feature difference map. The proposed method can almost reach the supervised results with limited access to the annotated samples while outperforming the existing SOTA semi-supervised CD method (i.e., SemiCDNet) by a significant margin. Furthermore, experiments show that the proposed method has better generalizability and transferability compared to the SOTA semi-supervised CD methods. Since the proposed method does not assume any assumptions about the distribution for unlabeled change mask during the unsupervised training unlike GAN-based methods, it can also produce relatively better CD results when it is testing on another dataset that haven't been seen during training or when combining unlabeled data from completely different dataset to the semi-supervised learning process.   <ref type="figure" target="#fig_7">Figure 1</ref> shows additional examples to demonstrate the cluster assumption in CD. From these images, we can also see that the cluster assumption does not hold in the bi-temporal image domain but rather holds in the deep feature difference domain. Therefore, we can leverage the information from freely-available, unlabeled, multi-temporal remote sensing images through consistency regularization by making the network's predicted change probability map consistent even under the small random perturbations applied on the hidden feature difference map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Additional qualitative results for LEVIR?LEVIR</head><p>In this section, we provide additional qualitative results on LEVIR-CD dataset.  From these examples also we can see that proposed semi-supervised approach generates much better change maps than the SOTA methods, further demonstrating its effectiveness of leveraging information from freely-available, unlabeled, remotesensing data to improve the CD performance.  these examples as well, we can see that the proposed semisupervised approach generates much better change maps than SOTA methods, further demonstrating its effectiveness in leveraging freely-available, unlabeled remote-sensing images to improve CD performance.   <ref type="figure" target="#fig_0">Fig. 2 and 3</ref>, from these examples as well, we can see that the proposed semi-supervised approach generates much better change maps than SOTA methods, further demonstrating its effectiveness in leveraging freelyavailable, unlabeled remote-sensing images to improve CD performance.   <ref type="figure" target="#fig_0">Fig. 2, 3</ref>, and 8, from these examples as well, we can see that the proposed semi-supervised approach generates much better change maps than SOTA methods, further demonstrating its effectiveness in leveraging freelyavailable, unlabeled remote-sensing images to improve CD performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Additional qualitative examples for LEVIR(5%)?LEVIR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Additional qualitative examples for LEVIR(10%)?LEVIR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Additional qualitative examples for LEVIR(20%)?LEVIR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Additional qualitative examples for LEVIR(40%)?LEVIR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Additional qualitative results for WHU?WHU</head><p>In this section, we provide additional qualitative results on WHU-CD dataset.  <ref type="figure" target="#fig_6">Figure 6</ref> shows additional qualitative examples for WHU(5%)?WHU. From these examples also we can see that proposed semi-supervised approach generates much better change maps than the SOTA methods, further demonstrating its effectiveness of leveraging information from freely-available, unlabeled, remotesensing data to improve the CD performance.   <ref type="figure" target="#fig_6">Fig. 6</ref>, from these examples as well, we can see that the proposed semisupervised approach generates much better change maps than SOTA methods, further demonstrating its effectiveness in leveraging freely-available, unlabeled remote-sensing images to improve CD performance.   <ref type="figure" target="#fig_0">Fig. 2 and 3</ref>, from these examples as well, we can see that the proposed semisupervised approach generates much better change maps than SOTA methods, further demonstrating its effectiveness in leveraging freely-available, unlabeled remote-sensing images to improve CD performance. <ref type="figure" target="#fig_15">Fig. 9</ref>. Additional qualitative results for WHU(40%)?WHU. <ref type="figure" target="#fig_15">Figure 9</ref> shows additional qualitative examples for WHU(40%)?WHU. Similar to <ref type="figure" target="#fig_0">Fig. 2, 3</ref>, and 8, from these examples as well, we can see that the proposed semi-supervised approach generates much better change maps than SOTA methods, further demonstrating its effectiveness in leveraging freely-available, unlabeled remote-sensing images to improve CD performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Additional qualitative examples for WHU(5%)?WHU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Additional qualitative examples for WHU(10%)?WHU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Additional qualitative examples for WHU(20%)?WHU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Additional qualitative examples for WHU(40%)?WHU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Additional qualitative examples for model transferability: LEVIR?WHU</head><p>In this section, we provide additional qualitative results related to model transferability experiments. More specifically, we show the qualitative results when model is trained on LEVIR and test on WHU for different percentages of labeled data used in the training.  <ref type="figure" target="#fig_1">Fig. 13</ref>. Additional qualitative results for model transferability: LEVIR(40%)?WHU.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Examples for LEVIR(5%)?WHU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Examples for LEVIR(40%)?WHU</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Additional qualitative results for cross-domain experiments</head><p>In this section, we present the additional qualitative results for cross-domain experiments. We combine labeled and unlabeled data from two different datasets and evaluate the performance. More specifically, we use different percentage of labeled data from LEVIR and consider unlabeled data from WHU into the semi-supervised learning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Additional qualitative examples for</head><p>{LEVIR(5%),WHU(unsup.)?LEVIR} </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>The cluster assumption in CD. (a) Pre-change images. (b) Post-change images. (c) Ground-truth change maps, where white-pixels corresponds to change regions and black-pixels corresponds to no-change regions. (d) The cluster assumption in the input bi-temporal image domain. (e) The cluster assumption in the hidden feature difference domain. Note that the regions closer to red color correspond to high-density regions while those with blue color correspond to low-density regions. The black lines indicate the segmentation boundaries of change and no-change classes. These example images are from the LEVIR building CD dataset [10].</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>The proposed semi-supervised approach for CD. (a) Supervised phase. (b) Unsupervised phase.3.2 Proposed semi-supervised CD approach CD network architecture. As shown in Fig. 3.2, our CD network consists of three main components: 1. An Encoder f e to extract hidden feature representations F A and F B of pre-change image I A and post-change image I B , 2. A feature difference module to obtain the difference of hidden feature representations F d of pre-change and post-change images, and 3. A decoder f d to predict the change map from hidden feature difference F d .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>-</head><label></label><figDesc>Random feature noise: We generate a 3D noise tensor N ? U(?0.3, 0.3), then scale it according to the magnitude of values in F ul d,i , and add it to the hidden feature difference map to get the perturbed version: F ul d,i = F ul d,i + N ? F ul d,i . -Random feature drop: We mask out 10% to 40% of the most needed regions in the feature difference map by first sampling a threshold ? ? U(0.6, 0.9), then generating the mask M = {F ul d,i &lt; ?} 1 where F ul d,i is the normalized feature difference map F ul d,i along the channel-dimension, and finally element-wise multiplying it with the obtained mask to get the perturbed feature difference map F ul d,i = M ? F ul d,i . -Guided Feature Cutout: To reduce the CD network's dependency on a specific part of the feature difference map, we randomly zero-out a random-crop from the feature difference map based on the predicted change map? ul i to get perturbed feature difference map F ul d,i . -Content and object masking: Based on the assumption that the CD network's output should be invariant to the change or no-change classes, we create two perturb versions of the hidden feature difference map by masking out change region in the hidden feature difference map by change-mask M c or no-change region in the hidden feature difference map by a nochange-mask M nc = 1 ? M c . -Feature-VAT [30]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 3 )</head><label>3</label><figDesc>The</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Qualitative results of different CD methods with % of labeled data for (a) testing on the same dataset: LEVIR ? LEVIR and (b) testing on a different dataset: LEVIR ? WHU. See supplementary material for additional qualitative results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>The qualitative results for {LEVIR(100%), WHU (unsup.)} ?LEVIR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>The qualitative improvements of predicted change maps with different types of perturbations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 1 .</head><label>1</label><figDesc>Additional examples to demonstrate the cluster assumption in CD. (a) Prechange image. (b) Post-change image. (c) Ground-truth change mask. (d) Cluster assumption in bi-temporal image domain. (e) Cluster assumption in hidden feature difference domain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 2 .</head><label>2</label><figDesc>Additional qualitative results for LEVIR(5%)?LEVIR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 2</head><label>2</label><figDesc>shows additional qualitative examples for LEVIR(5%)?LEVIR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 3 .</head><label>3</label><figDesc>Additional qualitative results for LEVIR(10%)?LEVIR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 3</head><label>3</label><figDesc>shows additional qualitative examples for LEVIR(10%)?LEVIR. Similar to Fig. 2, from</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 4 .</head><label>4</label><figDesc>Additional qualitative results for LEVIR(20%)?LEVIR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head>Figure 8</head><label>8</label><figDesc>shows additional qualitative examples for LEVIR(20%)?LEVIR. Similar to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 5 .</head><label>5</label><figDesc>Additional qualitative results for LEVIR(40%)?LEVIR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head>Figure 9</head><label>9</label><figDesc>shows additional qualitative examples for LEVIR(40%)?LEVIR. Similar to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 6 .</head><label>6</label><figDesc>Additional qualitative results for WHU(5%)?WHU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Fig. 7 .</head><label>7</label><figDesc>Additional qualitative results for WHU(10%)?WHU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head>Figure 7</head><label>7</label><figDesc>shows additional qualitative examples for WHU(5%)?WHU. Similar to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 8 .</head><label>8</label><figDesc>Additional qualitative results for WHU(20%)?WHU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 8</head><label>8</label><figDesc>shows additional qualitative examples for WHU(20%)?WHU. Similar to</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Fig. 10 .Fig. 11 .Fig. 12 .</head><label>101112</label><figDesc>Additional qualitative results for model transferability: LEVIR(5%)?WHU.4.2 Examples for LEVIR(10%)?WHUAdditional qualitative results for model transferability: LEVIR(10%)?WHU.4.3 Examples for LEVIR(20%)?WHUAdditional qualitative results for model transferability: LEVIR(20%)?WHU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 14 .Fig. 15 .Fig. 16 .Fig. 17 .</head><label>14151617</label><figDesc>Additional qualitative results for model transferability: LEVIR(5%)?WHU.5.2 Additional qualitative examples for{LEVIR(10%),WHU(unsup.)?LEVIR} Additional qualitative results for model transferability: LEVIR(10%)?WHU.5.3 Additional qualitative examples for{LEVIR(20%),WHU(unsup.)?LEVIR} Additional qualitative results for model transferability: LEVIR(20%)?WHU.5.4 Additional qualitative examples for{LEVIR(40%),WHU(unsup.)?LEVIR} Additional qualitative results for model transferability: LEVIR(40%)?WHU.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Supervised Ours Pre-change RGB Post-change RGB</head><label></label><figDesc></figDesc><table><row><cell></cell><cell>79%</cell><cell></cell><cell>Supervised</cell><cell cols="2">Semi-supervised (ours)</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>77.91%</cell><cell></cell><cell></cell></row><row><cell></cell><cell>77%</cell><cell></cell><cell></cell><cell></cell><cell>77.16%</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>76.22%</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>change class IoU</cell><cell>69% 71% 73% 75%</cell><cell>+ 8.6%</cell><cell>75.46%</cell><cell>72.34% + 3.9%</cell><cell>74.94% + 3.9%</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>67%</cell><cell>66.82%</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>65%</cell><cell cols="2">10%</cell><cell>20%</cell><cell>40%</cell><cell>100%</cell><cell>10%</cell><cell>20%</cell><cell>40%</cell><cell>100%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">% of labeled data</cell><cell></cell><cell></cell><cell cols="2">% of labeled data</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(a)</cell><cell></cell><cell></cell><cell></cell><cell>(b)</cell></row></table><note>GT oracle</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>The average quantitative metrics of different CD methods on LEVIR?LEVIR and WHU?WHU with the percentage of labeled data.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">LEVIR(% labeled)?LEVIR</cell><cell></cell><cell cols="2">WHU(% labeled)?WHU</cell><cell></cell></row><row><cell>Method</cell><cell>5%</cell><cell>10%</cell><cell>20%</cell><cell>40%</cell><cell>5%</cell><cell>10%</cell><cell>20%</cell><cell>40%</cell></row><row><cell></cell><cell>IoU c OA</cell><cell>IoU c OA</cell><cell>IoU c OA</cell><cell>IoU c OA</cell><cell>IoU c OA</cell><cell>IoU c OA</cell><cell>IoU c OA</cell><cell>IoU c OA</cell></row><row><cell>Sup. only</cell><cell cols="8">61.0 97.60 66.8 98.13 72.3 98.44 74.9 98.60 50.0 97.48 55.7 97.53 65.4 98.20 76.1 98.94</cell></row><row><cell>AdvNet[45]</cell><cell cols="8">66.1 98.08 72.3 98.45 74.6 98.58 75.0 98.60 55.1 97.90 61.6 98.11 73.8 98.80 76.6 98.94</cell></row><row><cell>s4GAN[29]</cell><cell cols="8">64.0 97.89 67.0 98.11 73.4 98.51 75.4 98.62 18.3 96.69 62.6 98.15 70.8 98.60 76.4 98.96</cell></row><row><cell>SemiCDNet[35]</cell><cell cols="8">67.6 98.17 71.5 98.42 74.3 98.58 75.5 98.63 51.7 97.71 62.0 98.16 66.7 98.28 75.9 98.93</cell></row><row><cell>Ours Oracle</cell><cell cols="8">72.5 98.47 75.5 98.63 76.2 98.68 77.2 98.72 65.8 98.37 68.1 98.47 74.8 98.84 77.2 98.96 IoU c =77.9 and OA=98.77 IoU c =85.5 and OA=99.38</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>The average quantitative metrics of different CD methods for LEVIR ? WHU and WHU ? LEVIR with the percentage of labeled data.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">LEVIR (% labeled) ? WHU</cell><cell></cell><cell></cell><cell cols="3">WHU (% labeled) ? LEVIR</cell></row><row><cell>Method</cell><cell>5%</cell><cell>10%</cell><cell>20%</cell><cell>40%</cell><cell></cell><cell>5%</cell><cell></cell><cell>10%</cell><cell>20%</cell><cell>40%</cell></row><row><cell></cell><cell>IoU c OA</cell><cell>IoU c OA</cell><cell>IoU c OA</cell><cell>IoU c OA</cell><cell cols="2">IoU c OA</cell><cell cols="2">IoU c OA</cell><cell>IoU c OA</cell><cell>IoU c OA</cell></row><row><cell>Sup. only</cell><cell cols="5">24.5 95.90 32.2 96.70 38.7 96.59 47.2 97.12 3.7</cell><cell cols="4">94.68 10.9 93.60 9.2</cell><cell>92.81 6.6</cell><cell>93.95</cell></row><row><cell>AdvNet[45]</cell><cell cols="5">27.2 96.37 33.2 96.56 32.8 96.97 43.1 97.33 4.3</cell><cell cols="4">94.44 11.0 93.56 11.6 92.57 7.3</cell><cell>93.85</cell></row><row><cell>s4GAN[29]</cell><cell cols="5">31.2 96.33 31.7 95.65 41.9 96.95 47.9 97.63 1.6</cell><cell cols="2">94.94 7.8</cell><cell cols="2">94.30 8.7</cell><cell>93.22 2.2</cell><cell>94.29</cell></row><row><cell>SemiCDNet[35]</cell><cell cols="5">28.4 96.41 32.5 96.93 39.5 97.20 48.3 97.53 3.4</cell><cell cols="2">94.68 8.9</cell><cell cols="2">94.03 9.7</cell><cell>92.16 5.3</cell><cell>94.60</cell></row><row><cell>Ours</cell><cell cols="5">35.4 96.40 39.3 96.76 42.1 96.99 51.5 97.72 7.8</cell><cell cols="4">94.72 11.7 94.48 10.6 93.82 12.3 94.92</cell></row><row><cell cols="10">for LEVIR?LEVIR and WHU?WHU for different % of labeled data. The key</cell></row><row><cell cols="10">takeaways from Tab. 1 can be summarized as follows: (1) Increasing the % of</cell></row><row><cell cols="10">labeled data in training results in increased CD performance for all methods,</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>The average quantitative metrics of different CD methods for {LEVIR(sup.%), WHU (unsup.)} ? LEVIR with the percentage of labeled data.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="5">{LEVIR(sup.%),WHU(unsup.)}?LEVIR</cell></row><row><cell cols="2">Method</cell><cell>5% IoU c OA</cell><cell>10% IoU c OA</cell><cell cols="2">20% IoU c OA</cell><cell>40% IoU c OA</cell><cell cols="2">100% IoU c OA</cell></row><row><cell cols="2">Sup. only</cell><cell cols="7">61.0 97.60 66.8 98.13 72.3 98.44 74.9 98.60 77.9 98.77</cell></row><row><cell cols="2">AdvNet[45]</cell><cell cols="7">65.2 98.10 71.6 98.42 75.0 98.63 76.5 98.71 77.4 98.78</cell></row><row><cell cols="2">s4GAN[29]</cell><cell cols="7">66.7 98.12 68.4 98.26 73.4 98.54 75.3 98.65 75.8 98.63</cell></row><row><cell cols="2">SemiCDNet[35]</cell><cell cols="7">67.6 98.19 71.9 98.46 74.9 98.62 76.4 98.70 77.9 98.80</cell></row><row><cell>Ours</cell><cell></cell><cell cols="7">71.4 98.40 74.6 98.58 76.4 98.69 77.9 98.77 78.6 98.82</cell></row><row><cell>Pre-change</cell><cell>Post-change</cell><cell>Supervised</cell><cell>AdvNet</cell><cell>s4GAN</cell><cell cols="2">SemiCDNet</cell><cell>Ours</cell><cell>Ground-truth</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>. 5 for the scenario: {LEVIR(100%), WHU(unsup.) }?LEVIR. As highlighted in</figDesc><table><row><cell cols="2">Case Configuration</cell><cell>IoU c OA</cell></row><row><cell cols="2">I Baseline (i.e., Sup.)</cell><cell>66.8 98.13</cell></row><row><cell cols="2">II Sup.+FN</cell><cell>74.7 98.55</cell></row><row><cell cols="2">III Sup.+FN+FD</cell><cell>74.8 98.60</cell></row><row><cell cols="2">IV Sup.+FN+FD+GFC</cell><cell>74.9 98.60</cell></row><row><cell cols="3">V Sup.+FN+FD+GFC+C&amp;O 75.1 98.61</cell></row><row><cell>VI</cell><cell cols="2">Sup.+FN+FD+GFC+C&amp;O 75.5 98.63 +F-VAT (final model)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>How</figDesc><table><row><cell>different types of per-</cell></row><row><cell>turbations contributes to proposed semi-</cell></row><row><cell>supervised CD.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Supplementary Materials for Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing ImagesWele Gedara Chaminda Bandara and Vishal M. Patel</figDesc><table><row><cell>Johns Hopkins University, USA</cell></row><row><cell>{wbandar1, vpatel36}@jhu.edu</cell></row><row><cell>1 "Cluster assumption" in CD</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Specifically, X?Y denotes training a model on the train-set of dataset X and testing it on the test-set of dataset Y .</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">A transformer-based siamese network for change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">G C</forename><surname>Bandara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.01293</idno>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A theoretical framework for unsupervised change detection based on change vector analysis in the polar domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bovolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="218" to="236" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A novel approach to unsupervised change detection based on a semisupervised svm and a similarity measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bovolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marconcini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Signature verification using a&quot; siamese&quot; time delay neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>S?ckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Automatic analysis of the difference image for unsupervised change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Prieto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote sensing</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1171" to="1182" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Guided anisotropic diffusion and iterative learning for weakly supervised change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caye</forename><surname>Daudt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Le Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gousseau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised change detection in satellite images using principal component analysis and k-means clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Celik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE geoscience and remote sensing letters</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="772" to="776" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Semi-supervised learning (chapelle, o</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
		<editor>. et al.</editor>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>book reviews</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Remote sensing image change detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">10</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A spatial-temporal attention-based method and a new dataset for remote sensing image change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shi</surname></persName>
		</author>
		<idno type="DOI">10.3390/rs12101662</idno>
		<ptr target="https://www.mdpi.com/2072-4292/12/10/16622" />
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Change detection in multi-temporal vhr images based on deep siamese multi-scale convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.11479</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Change detection in multisource vhr images via deep siamese convolutional multiple-layers recurrent neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TGRS.2019.29567564</idno>
		<ptr target="https://doi.org/10.1109/TGRS.2019.29567564" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2848" to="2864" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dasnet: Dual attentive fully convolutional siamese networks for change detection in highresolution satellite images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A semisupervised context-sensitive change detection technique via gaussian process</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Self-supervised change detection in multiview remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<idno type="DOI">10.1109/tgrs.2021.3089453</idno>
		<ptr target="http://dx.doi.org/10.1109/TGRS.2021.30894532" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Fully convolutional siamese networks for change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Daudt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Le Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boulch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Urban change detection for multispectral earth observation using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Daudt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Le Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gousseau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IGARSS 2018-2018 IEEE International Geoscience and Remote Sensing Symposium</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Looking for change? roll the dice and demand attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">I</forename><surname>Diakogiannis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Waldner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Caccetta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Snunet-cd: A densely connected siamese network for change detection of vhr images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Semi-supervised change detection using modified self-organizing feature map neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Consistency-based semi-supervised learning for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for multisource building extraction from an open aerial and satellite imagery data set</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="574" to="586" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title/>
		<idno type="DOI">10.1109/TGRS.2018.28588179</idno>
		<ptr target="https://doi.org/10.1109/TGRS.2018.28588179" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with directional context-aware consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Seasonal contrast: Unsupervised pre-training from uncurated remote sensing data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ma?as</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacoste</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Giro-I Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unsupervised change-detection methods for remote-sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Melgani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Moser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Serpico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3288" to="3297" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Semi-supervised semantic segmentation with high-and low-level consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tatarchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Semi-supervised semantic segmentation with high-and low-level consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tatarchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">I</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Machine learning: a probabilistic perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Murphy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>MIT press</publisher>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Transformation consistency regularization-a semisupervised paradigm for image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mustafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Mantiuk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Realistic evaluation of deep semi-supervised learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Semi-supervised semantic segmentation with crossconsistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ouali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hudelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semicdnet: A semisupervised convolutional neural network for change detection in high resolution remote-sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<idno type="DOI">10.1109/TGRS.2020.30119135</idno>
		<ptr target="https://doi.org/10.1109/TGRS.2020.30119135" />
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Change detection in synthetic aperture radar images using a dual-domain network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Unsupervised change detection in satellite images with generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="10047" to="10061" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">S2looking: A satellite side-looking dataset for building change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">24</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rueckert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">An efficient lightweight neural network for remote sensing image change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">24</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Dynamicearthnet: Daily multi-spectral satellite dataset for semantic change segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Toker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kondmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eisenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Camero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Hoderlein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>?enaras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2203.12560</idno>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Changenet: A deep learning architecture for visual change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Varghese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gubbi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Balamuralidhar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV) Workshops</title>
		<meeting>the European Conference on Computer Vision (ECCV) Workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Interpolation consistency training for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kawaguchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kannala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03825</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Advent: Adversarial entropy minimization for domain adaptation in semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bucher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?rez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Loveda: A remote sensing land-cover dataset for domain adaptive semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.08733</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Semi-supervised learning for few-shot image-to-image translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gonzalez-Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weijer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fusion network for change detection of high-resolution panchromatic imagery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wiratama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Pseudo-siamese capsule network for aerial remote sensing images change detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A survey of change detection methods based on remote sensing images for multi-source and multi-objective scenarios</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Semi-supervised change detection method for multitemporal hyperspectral images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">148</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A deeply supervised image fusion network for change detection in high resolution bi-temporal remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tapete</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Shangguan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">166</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Escnet: An end-to-end superpixel-enhanced change detection network for very-high-resolution remote sensing images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Hdfnet: Hierarchical dynamic fusion network for change detection in optical aerial images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Coarse-to-fine satellite images change detection framework via boundary-aware attentive network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Pyramid scene parsing network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
