<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Two Wrongs Don&apos;t Make a Right: Combating Confirmation Bias in Learning with Label Noise</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingcai</forename><surname>Chen</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuntao</forename><surname>Du</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Xu</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyu</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongjun</forename><surname>Wang</surname></persName>
							<email>chjwang@nju.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">State Key Laboratory for Novel Software Technology</orgName>
								<orgName type="institution">Nanjing University Nanjing University</orgName>
								<address>
									<postCode>210023</postCode>
									<settlement>Nanjing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Two Wrongs Don&apos;t Make a Right: Combating Confirmation Bias in Learning with Label Noise</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Learning with noisy labels</term>
					<term>Label Refurbishment</term>
					<term>Confir- mation bias</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Noisy labels damage the performance of deep networks. For robust learning, a prominent two-stage pipeline alternates between eliminating possible incorrect labels and semi-supervised training. However, discarding part of noisy labels could result in a loss of information, especially when the corruption is not completely random, e.g., classdependent or instance-dependent. Moreover, from the training dynamics of a representative two-stage method DivideMix, we identify the domination of confirmation bias: pseudo-labels fail to correct a considerable amount of noisy labels, and consequently, the errors accumulate. To sufficiently exploit information from noisy labels and mitigate wrong corrections, we propose Robust Label Refurbishment (Robust LR)-a new hybrid method that integrates pseudo-labeling and confidence estimation techniques to refurbish noisy labels. We show that our method successfully alleviates the damage of both label noise and confirmation bias. As a result, it achieves state-of-the-art results across datasets and noise types. For example, Robust LR achieves up to 4.5% absolute top-1 accuracy improvement over the previous best on the real-world noisy dataset WebVision.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Given certain capacity, deep networks have the capability of fitting arbitrary complex functions <ref type="bibr" target="#b13">[14]</ref>. However, the randomization tests on common architectures <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b3">4]</ref> show that they also easily fit training data with random labels. This phenomenon naturally raises the question of how deep learning continues to succeed in the presence of label noise.</p><p>Recently, the state-of-the-art two-stage methods significantly improve noise robustness by incorporating Semi-Supervised Learning (SSL) <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b50">51]</ref>. The  <ref type="figure">Fig. 1</ref>. The motivation of our method. Underlying ground-truth label, noisy label, and predicted label are denoted as y,?,? respectively. In every epoch, the examples are divided into four groups as shown in (b): I. The predicted labels agree with the clean labels. II. The predicted labels correct the noisy labels. III. The predicted labels agree with the noisy labels. IV. The predicted labels fail to correct the labels. In (c) and (d), the x-axes denote the epochs, and y-axes denote the proportions of different groups. Best viewed in color pipeline of a representative algorithm DivideMix <ref type="bibr" target="#b26">[27]</ref> is shown in <ref type="figure">Figure 1</ref>(a).</p><p>In the first stage, problematic labels are identified and removed according to the per-example loss, i.e., the so-called "small-loss trick". Therefore, the noisy dataset is divided into a labeled subset and an unlabeled subset. In the second stage, DivideMix calls an SSL algorithm named MixMatch <ref type="bibr" target="#b4">[5]</ref>, which minimizes the entropy of predictions on unlabeled examples through pseudo-labels. Such a pipeline leverages mislabeled data, improving the robustness to heavy and complex label noise. However, we conclude that the two-stage pipeline suffers from two drawbacks. On the one hand, according to Vapnik's principle <ref type="bibr" target="#b43">[44,</ref><ref type="bibr" target="#b7">8]</ref>, 1 discarding possible noisy labels to construct an SSL setting is inefficient. Specifically, some correct labels are wrongly filtered. What's more, incorrect labels may also contain knowledge about the targets <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b5">6]</ref>. For example, when an airplane image is mislabeled as a bird, the noisy label encodes the similarity information between the target and bird. On the other hand, when introducing pseudo-labels during the SSL stage, confirmation bias <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b2">3]</ref> appears: Those confident but wrong predictions would be used to guide subsequent training, leading to a loop of self-reinforcing errors. Label noise, together with confirmation bias, damage the performance.</p><p>To observe the erroneous pseudo-labeling, we draw the training dynamics of a recent two-stage method DivideMix <ref type="bibr" target="#b26">[27]</ref> on the corrupted training set of CIFAR-10 <ref type="bibr" target="#b24">[25]</ref> (under 90% synthetic symmetric noise). In every epoch, examples are grouped according to the relationship between their predicted labels, corrupted labels, and underlying ground-truth labels as in <ref type="figure">Figure 1</ref>(b). The yellow color indicates the examples whose predicted labels agree with given noisy labels, i.e., III. predicted label = noisy label ? = ground-truth. The small region I and III at the bottom of <ref type="figure">Figure 1</ref>(c) suggests that the model only agrees with a small fraction of noisy labels. It's because DivideMix would ignore possible wrong labels and fit them less. On the other side, the red color indicates those predictions which fail to correct the noisy labels, i.e., IV. predicted label ? = noisy label and predicted label ? = ground-truth. From the region IV at the top of <ref type="figure">Figure 1</ref>(c), those wrong predictions comprise a large part throughout the training process, indicating consecutive damage of wrong pseudo-labels. This phenomenon bears out the existence of confirmation bias, which could affect performance adversely.</p><p>Our work begins by suggesting that better robustness can be achieved by sufficiently exploiting the information in the noisy labels and mitigating the sideeffect of SSL. We observe one of the recent two-stage methods as <ref type="figure">Figure 1</ref>(c): The pseudo-labels dominate the given noisy labels during training. Thus, we propose a hybrid method named Robust LR to address the problem. It estimates the label confidence by modeling the per-example loss and then accordingly refurbishes noisy labels through a dynamic convex combination with pseudo-labels. Thus, Robust LR improves upon the two-stage pipeline by leveraging all noisy labels and constructing target labels in a more fine-grained manner. To further alleviate confirmation bias: 1). Two models are trained simultaneously, where each model interacts with its peer through pseudo-labeling and confidence estimation. 2). Different augmentation strategies are deployed for loss modeling and learning following recent findings <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b32">33]</ref>. For comparison, we draw <ref type="figure">Figure 1</ref>(d) using our method under the same setting. Compared with <ref type="figure">Figure 1</ref>(c), the part of predictions disagreeing with the noisy labels becomes more accurate. It indicates that our approach alleviates the damage of wrong pseudo-labels while combating label noise. To sum up, we highlight the contributions of this paper as follows:</p><p>-We analyze the inefficiency of the two-stage pipeline and suggest that there is a loss of information when transforming the label noise problem into SSL. Moreover, the visualization of the training dynamics helps us identify the domination of confirmation bias (see <ref type="figure">Figure 1</ref>(c)). -To address, we propose a hybrid method named Robust LR. By integrating pseudo-labeling and confidence estimation techniques into label refurbishment, it successfully leverages all noisy labels and alleviates the damage of both label noise and confirmation bias (see <ref type="figure">Figure 1(d)</ref>). -We experimentally show that our method significantly advances state-of-theart results on CIFAR-10, CIFAR-100 with synthetic label noise, as well as the real-world noisy dataset WebVision. Besides, we systematically study the components of Robust LR to examine their impacts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>The label noise is ubiquitous in real-world data. When the noise rate is insignificant, it can be implicitly dealt with. For example, the noise labels in MNIST, CIFAR, and ImageNet (some of them are reported in https://labelerrors. com/), are usually neglected. Regularization techniques, including Dropout <ref type="bibr" target="#b39">[40]</ref>, weight decay <ref type="bibr" target="#b25">[26]</ref>, and the inherent robustness in deep networks <ref type="bibr" target="#b49">[50]</ref> combat label noise. The damage of noisy labels gradually appears as noise becomes non-negligible. Some methods assume a class-dependent (or instance-independent) label noise, i.e., the distribution of noisy labels only dependent on the ground-truth label:</p><formula xml:id="formula_0">p(? = j | y = i, X = x) = p(? = j | y = i)<label>(1)</label></formula><p>The corruption process thus can be modeled by a label transition matrix T ? [0, 1] C?C where T ij := p(? = j | y = i) and C is the number of classes. Webly learning <ref type="bibr" target="#b11">[12]</ref> adds an extra noise adaptation layer on top of the base model to mimic the transition behavior. The base model is first trained on easy examples, and then the entire model is trained on the noisy dataset. Backward correction <ref type="bibr" target="#b33">[34]</ref> estimates the label transition through the outputs of a network trained on the noisy dataset. Then it trains another network with weighted loss, where the weights are from the estimated label transition matrix. Forward correction <ref type="bibr" target="#b33">[34]</ref> does the same to obtain the matrix. But it instead corrects the outputs during forward pass when trains a new network. To better estimate the transition matrix, Dual T <ref type="bibr" target="#b45">[46]</ref> factorizes it into two easy-to-estimate matrices.</p><p>The effectiveness of these approaches depends on whether the transition matrix is accurate. Besides, the noise type could be more complex in real-world, e.g., instance-dependent:</p><formula xml:id="formula_1">p(? = j | y = i, X = x) = T i,j (x)p(y = j | y = i)<label>(2)</label></formula><p>where T i,j (x) is the instance-dependent noise model. The aforementioned methods have difficulty in modeling such complex noise. A large part of the methods achieves robustness by relying on the internal noise tolerance of deep networks. They mainly differ in the example selection, loss weighting, or label refurbishment strategies <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b38">39]</ref>. Bootstrapping <ref type="bibr" target="#b35">[36]</ref> uses the interpolation of labels and model predictions for training. Decouple <ref type="bibr" target="#b30">[31]</ref> updates two predictors with only disagreed examples. Activate bias <ref type="bibr" target="#b6">[7]</ref> emphasizes high variance examples. MentorNet <ref type="bibr" target="#b22">[23]</ref> weights examples using a pre-trained teacher network. Co-teaching <ref type="bibr" target="#b18">[19]</ref> maintains two models where one selects examples with small losses to update another. Based on Co-teaching, Co-teaching+ <ref type="bibr" target="#b47">[48]</ref> prevents two models from converging to a consensus by only considering disagreed examples. D2L <ref type="bibr" target="#b29">[30]</ref> adopts a measure called local intrinsic dimensionality. Labels are refurbished to prevent the increase of intrinsic dimension. SELFIE <ref type="bibr" target="#b37">[38]</ref> only considers examples with consistent predictions for refurbishment. TopoFilter <ref type="bibr" target="#b44">[45]</ref> adopts a different selection criteria by exploring the latent representational space. Self-adaptive training <ref type="bibr" target="#b20">[21]</ref> uses the exponential moving average of predictions as pseudo-labels. SEAL <ref type="bibr" target="#b9">[10]</ref> retrains a model with the average predictions of a teacher model. However, these methods may suffer from big performance drops under heavy noise due to inaccurate correction, weighting, or refurbishment.</p><p>Recently, the two-stage pipeline has gained much attention. SELF <ref type="bibr" target="#b31">[32]</ref> first uses the ensemble of predictions to filter problematic labels. In the second stage, it performs an SSL method named Mean Teacher <ref type="bibr" target="#b42">[43]</ref>. DivideMix <ref type="bibr" target="#b26">[27]</ref> uses the Gaussian Mixture Model (GMM) to separate examples with small and big losses, and they are treated as clean and noisy examples, respectively. Then the SSL method MixMatch <ref type="bibr" target="#b4">[5]</ref> is used to leverage the feature information. RoCL <ref type="bibr" target="#b50">[51]</ref> selects clean examples according to the consistency of the loss and output, followed by a self-training method. This type of method utilizes SSL to leverage mislabeled examples. However, we suggest that they fail to exploit all noisy labels and suffer from wrong corrections. The proposed method Robust LR leverages possible noisy labels. It preserves label information in a soft manner by adopting successful ideas from the two-stage pipeline and SSL into the classic label refurbishment process as shown in <ref type="table" target="#tab_0">Table 1</ref>. Furthermore, Robust LR is dedicated to alleviating confirmation bias. Different augmentation strategies and co-training are combined to form a hybrid method. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of Robust LR</head><p>Robust LR refurbishes the noisy labels before training. To reduce the marginalized effect of wrong labels, the refurbished label y * ? ? C?1 comes from a dynamic convex combination of the noisy label? (one-hot label over C classes) and the soft pseudo-label? (predicted probability distribution over C classes).</p><formula xml:id="formula_2">y * = w? + (1 ? w)?<label>(3)</label></formula><p>The pseudo-label? is obtained from models' prediction. The weight w, i.e., the clean probability, is estimated using a two-component GMM fitted on the per-example loss. To further alleviate confirmation bias, two models are simultaneously trained, where one model contributes to another's confidence estimation and pseudo-labeling process. They have the same structure but different parameters ? (0) , ? <ref type="bibr" target="#b0">(1)</ref> . The overall pipeline of Robust LR is shown in <ref type="figure" target="#fig_1">Figure 2</ref> and Algorithm 1. In every training round, the confidence estimation and pseudo-labeling are performed first. Then the model is trained with the refurbished labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Warm-up</head><formula xml:id="formula_3">+(1? ) ?</formula><p>Noisy dataset ? , model parameters ? (0) , ? <ref type="bibr" target="#b0">(1)</ref> .  As shown in <ref type="bibr" target="#b3">[4]</ref>, deep models tend to fit clean examples first. Therefore, Robust LR warms two models up by shortly training them on the noisy dataset. The commonly used mini-batch gradient descent algorithm is performed to update the parameters. For illustration, we denote this process as Train(dateset, parameters, number of iterations). Thus, the warm-up process is as:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GMM Average Sharpen</head><formula xml:id="formula_4">Train(D, ? (m) , I warm ) for m = 0, 1<label>(4)</label></formula><p>where I warm is a small number of iterations so that the training ends before models fitting too many noisy labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Main training round</head><p>Confidence estimation It has been shown that models are prone to present smaller losses on clean examples <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b26">27]</ref>. Therefore, Robust LR estimates the label confidence based on the loss value. Specifically, the per-example cross-entropy loss H between the noisy label and the prediction is first calculated,</p><formula xml:id="formula_5">? i = H(? i , p(y | x i ; ? (1?m) ))<label>(5)</label></formula><p>Then a two-component one-dimensional GMM is used to model the distribution of per-example loss,</p><formula xml:id="formula_6">W = GMM({(? i )} N i=1 )<label>(6)</label></formula><p>where W = {w i } N i=1 is the label confidence which equals to the probability of each loss value belonging to the GMM component with smaller mean. The parameters of GMM are determined using the expectation-maximization algorithm. The procedure follows the standard practice, so we don't elaborate on the details here. Note that, to alleviate confirmation bias, the label confidence for the current model m comes from the predictions of another model 1 ? m.</p><p>Pseudo-labeling To correct the noisy labels with accurate pseudo-labels, two models' predictions are averaged and then sharpened,</p><formula xml:id="formula_7">y i = Sharpen( p(y | x i ; ? (m) ) + p(y | x i ; ? (1?m) ) 2 )<label>(7)</label></formula><p>where the sharpening function scales the categorical distribution with a hyperparameter T , for m = 0 to 1 do ? train two models separately 5:</p><formula xml:id="formula_8">Sharpen(p) i = p 1 T i C j=1</formula><p>for i = 0 to N do 6:</p><p>?i = H(yi, p(y | xi; ? (1?m) )) 7:</p><p>? obtain per-example loss 8:</p><p>end for 9:</p><formula xml:id="formula_9">W = GMM({(?i)} N i=1 )</formula><p>? fit GMM 10:</p><p>for i = 0 to N do 11:?i = Sharpen( p(y|x i ;? (m) )+p(y|x i ;? (1?m) ) 2 )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12:</head><p>? pseudo-label 13:</p><formula xml:id="formula_10">y * i = wi?i + (1 ? wi)?i ? refurbish 14:</formula><p>end for 15:</p><formula xml:id="formula_11">Train({(Aug(xi), y * i )} N i=1 , ? (m) , I) 16:</formula><p>end for 17: end for where C is the number of classes. p i is the probability of i-th class of input distribution p.</p><p>Model training After label refurbishment using the estimated confidence and pseudo-labels according to <ref type="bibr">Equation 3</ref>, current model m is trained with the refurbished labels for I iterations,</p><formula xml:id="formula_12">Train({(Aug(x i ), y * i )} N i=1 , ? (m) , I)<label>(9)</label></formula><p>where Aug(?) is the data augmentation function introduced in the next section. The cross-entropy between the soft labels and predictions is used as loss here.</p><p>After the training of model m, another model 1 ? m is trained similarly. This process proceeds until reaching a fixed number of training rounds. During implementation, a regularization loss term is used as in <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b26">27]</ref>. It encourages the network to output uniform distribution across examples in the mini-batch.</p><formula xml:id="formula_13">L reg = c ? c log( ? c p c ) p c = 1 B B i=1 p(y = c | x i ; ?)<label>(10)</label></formula><p>where ? is the uniform prior distribution, we set ? c = 1 C .</p><p>For asymmetric noise, we add a negative entropy loss term during warm-up following <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b26">27]</ref>.</p><formula xml:id="formula_14">c p(y | x; ?)log(p(y | x; ?))<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The different augmentation strategies</head><p>Due to the lack of accurate supervised information, improving the generalization ability is the core task of learning with label noise. Data augmentation is a common technique that approaches such a problem via applying stochastic transformation on images.</p><p>In Robust LR, forward pass serves three purposes: loss modeling, pseudolabeling, and learning. We use basic image augmentation for loss modeling and pseudo-labeling but stronger augmentations for learning. This design is based on two recent findings: 1). In learning with label noise, using different augmentations for loss modeling and learning is more effective <ref type="bibr" target="#b32">[33]</ref>. 2). Unsupervised learning benefits from stronger data augmentation <ref type="bibr" target="#b10">[11]</ref>, and we find the same preference can also be extended to this problem.</p><p>In particular, the basic image augmentation for loss modeling and pseudolabeling consists of random crop and random horizontal flip. The strong transformation Aug(?) consists of RandAugment <ref type="bibr" target="#b12">[13]</ref> and Cutout <ref type="bibr" target="#b14">[15]</ref>. RandAugment first randomly selects a given number of operations from a pre-defined set of transformations. The set consists of geometric and photometric transformations, such as affine transformation and color adjustment. In the next, these operations are applied with given magnitudes. Cutout randomly masks out square regions of images. These augmentations are sequentially applied to the input images. The settings of RandAugment are reported in the supplementary material.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Limitations</head><p>Our paper and experiments are limited to the image classification task. While there isn't any reason to believe that these ideas won't carry over to other domains and modalities, this was considered beyond the scope of this work. The augmentation strategies may stand in the way when one tries to put our method in other applications: The studied transformations are only for vision tasks (some transformations also need to be adjusted to suit different image data). As a general framework, modality-agnostic data augmentation could be designed so that our method can be widely used. We leave it for further exploration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Comparison with state-of-the-art methods</head><p>We benchmark the proposed method on experimental settings using CIFAR-10, CIFAR-100 <ref type="bibr" target="#b24">[25]</ref> with different levels of synthetic noises, as well as the real-world noisy dataset WebVision <ref type="bibr" target="#b28">[29]</ref>. CIFAR-10, CIFAR-100 Following previous methods <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b26">27]</ref>, two types of synthetic noises are experimented: symmetric and asymmetric noise. Symmetric noise is generated by assigning examples to random classes with the same probability. The noise rate ranges from 20% to 90% (note that the noise labels are randomly distributed throughout C classes, and the true labels may be maintained after corruption). Asymmetric noise is generated by randomly corrupting labels according to a pre-defined transition matrix. Examples would only be corrupted to similar classes, such as deer to horse. 40% asymmetric noise is experimented (50% being indistinguishable). For comparison, results of F-correction <ref type="bibr" target="#b33">[34]</ref>, Co-teaching+ <ref type="bibr" target="#b47">[48]</ref>, P-correction <ref type="bibr" target="#b46">[47]</ref>, Mete-learning <ref type="bibr" target="#b27">[28]</ref>, M-correction <ref type="bibr" target="#b1">[2]</ref>, DivideMix <ref type="bibr" target="#b26">[27]</ref>, AugDesc <ref type="bibr" target="#b32">[33]</ref> are reported. For a fair comparison, the results of other methods are cited from <ref type="bibr" target="#b26">[27]</ref>, and they use the same network architecture. Note that The method AugDesc adds strong augmentation techniques on top of DivideMix. Here we include the version with the same augmentation technique (RandAugment). We report the average performance of Robust LR over 3 trials with different random seeds for generating noise and parameters initialization. The backbone <ref type="figure">Fig. 3</ref>. Confusion matrices on CIFAR-10 under asymmetry noise. The airp. and auto. are airplane and automobile for short structure is PreAct Resnet <ref type="bibr" target="#b19">[20]</ref>. The training details are reported in the supplementary material. Following previous work, the best test accuracy across all epochs and the averaged test accuracy over the last 10 epochs are both reported. A validation set with 5,000 examples is drawn from the noisy training set for hyper-parameters tuning. We find that two main hyper-parameters in Robust LR, namely temperature value and the weight for regularization term <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b1">2]</ref>, don't need to be heavily tuned. Specifically, there are only two sets of hyper-parameters for light and heavy noise, respectively. For light noise, namely CIFAR-10 under 20% to 80% symmetric noise, 40% asymmetric noise, and CIFAR-100 under 20% symmetric noise, the temperature is 1, and the coefficient for regularization term is 2. For heavy noise, namely CIFAR-10 under 90% symmetric noise and CIFAR-100 under 50% to 90% symmetric noise, the temperature is 1/3, and the coefficient for regularization term is 10.</p><formula xml:id="formula_15">D L U S D X W R E L U G F D W G H H U G R J I U R J K R U V H V K L S W U X Q N D&amp;RUUXSWHGODEHOV DLUS DXWR ELUG FDW GHHU GRJ IURJ KRUVH VKLS WUXQN 7UXHODEHOV D L U S D X W R E L U G F D W G H H U G R J I U R J K R U V H V K L S W U X Q N E3UHGLFLWLRQVRQWKHWUDLQLQJVHW DLUS DXWR ELUG FDW GHHU GRJ IURJ KRUVH VKLS WUXQN 7UXHODEHOV</formula><p>As shown in <ref type="table" target="#tab_2">Table 2</ref>, our method consistently outperforms previous best results on all the settings. The improvement is substantial, especially when the noise is heavy. For example, Robust LR obtains 92.8% accuracy on CIFAR-10 under 90% noise, surpassing the previous best by more than 3%. We remark that previous methods underperform under heavy noise because they fail to avoid confirmation bias. It's worth noting that Robust LR outperforms AugDesc even with the same augmentation. It shows that our improvement also comes other components.</p><p>The distribution of asymmetric noise in the corrupted training set is shown in <ref type="figure">Figure 3(a)</ref>. The comparison between Robust LR and other methods is shown in <ref type="table" target="#tab_2">Table 2</ref>. Our method outperforms the previous best method over 1%. As we can see in the confusion matrix in <ref type="figure">Figure 3(b)</ref>, Robust LR resists the mimicked class-dependent noise and correctly predicts most of them.</p><p>WebVision To verify the effectiveness of our approach on the real-world largescale noisy dataset, we then conduct experiments on WebVision <ref type="bibr" target="#b28">[29]</ref>. The dataset was crawled from Flickr and Google using the same 1,000 classes as the ImageNet ILSVRC12 dataset for querying. Following the setting of previous work <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b26">27]</ref>: The first 50 classes of the ImageNet ILSVRC12 dataset are compared, and its validation set is used. The model is the inception-resnet v2 <ref type="bibr" target="#b40">[41]</ref>. In terms of the hyper-parameters, the temperature is 3 and the coefficient for the regularization term is 1. As shown in <ref type="table" target="#tab_3">Table 3</ref>, Robust LR improves the performance by a considerable margin, e.g., 4.5% top-1 accuracy against the previous best on the test set of WebVision. This result suggests that our method successfully copes with complex real-world noise. We remark that the improvement can be attributed to the full utilization of label information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ablation study</head><p>We further study the components of Robust LR. Specifically, we analyze the results of:</p><p>1. To study the effect of label refurbishment, we remove label refurbishment and directly use either given noisy labels or pseudo-labels. When the probability of being clean is larger than 0.5, the noisy label is used. Otherwise, the pseudolabel is used. 2. To study the effect of strong augmentation, we replace it with basic transformation. 3. To study the effect of GMM for dynamic confidence estimation, we replace it with 0.5 fixed confidence. 4. To study the effect of co-training, we only use one model. 5. To study the effect of using another models' predictions to obtain label confidence, we use (a). the training model itself or (b). the ensemble of two models. 6. To study the effect of using two models' predictions to generate pseudo-labels, we only use the training model.</p><p>The results on CIFAR-10 with four levels of symmetry noise are reported. From <ref type="table">Table 4</ref>, other training schemes suffer from different degrees of performance drops. This verifies that the incorporating of the components in Robust LR is effective. In the next, we analyze each component.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Label refurbishment</head><p>The label refurbishment alleviates the marginalized effect of wrong labels and thus, contributes to the final performance. Under light noise, i.e., when the noise is insignificant or can be corrected easily, the gain is limited. Under heavy noise, e.g., 90% noise rate, the model is much sensitive to its absence.</p><p>We also notice the large gap between the best and last performance (73.8% vs. 23.9%) under heavy noise. To understand, we further observe models' behaviors. We find that the training is unstable under heavy noise, e.g., the GMM may not converge in some rounds and assigns more than 95% of examples with bigger clean probabilities. The bad confidence estimation would affect later training in return. The training can be stabilized after further tuning the hyper-parameters, such as the learning rate. For consistency, we only report the performance under the same hyper-parameters.</p><p>Data augmentation Replacing the strong augmentation is detrimental to performance. We find that the model unconverges without it. We remark that it's because Robust LR is a holistic method. Strong data augmentation not only serves the common purpose of regularization <ref type="bibr" target="#b36">[37]</ref>, but also is part of the different augmentation strategies <ref type="bibr" target="#b32">[33]</ref>.</p><p>One may still argue that the augmentation is more important than other components. We show that our components all improves upon the Robust LR with strong augmentation in <ref type="table">Table 4</ref>. Besides, as shown in <ref type="table" target="#tab_2">Table 2</ref>, our method outperforms AugDesc, a method with the same augmentation Robust LR uses.</p><p>GMM The GMM is also essential, and removing the dynamic confidence estimation damages the performance. We also notice that, for four levels of corruption, GMM assigns 18%, 44%, 70%, 78% examples bigger noisy probability (w &lt; 0.5) at the end of training, respectively. It is an accurate estimation of the real noise rate (for 20%, 50%, 80%, 90% noise rate, there is actually 18%, 45%, 72%, 81% noisy labels). For WebVision, the GMM assigns 18% examples bigger noisy probability in the end, which is also approximate to the widely accepted estimation 20% <ref type="bibr" target="#b28">[29]</ref>. We envision this could be used to estimate the noise rate in real-world datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Co-training</head><p>We first remove co-training directly, and, undoubtedly, the performance drops. It is noteworthy that one model's performance already surpasses previous co-training methods, such as DivideMix or Co-teaching. We then conduct experiments to further tease apart the usages of two models for different purposes. When training one model, using both models to obtain pseudo-labels is helpful. It is because the ensemble of two models is more accurate, directly contributing to better pseudo-labeling. Ensembling also brings better confidence estimation. When using the ensemble of two models for GMM fitting, the performance is slightly better under light noise. However, the accuracy drops under heavy noise. We reckon it is because using the model to estimate the confidence for itself leads to the fitting of its own error. The choice of using one model or both models for confidence estimation and pseudo-labeling is a balance between being more accurate (for the current epoch) and avoiding confirmation bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Finding the noisy labels in CIFAR-10</head><p>Apart from combating label noise, Robust LR can be directly used to find the noisy labels in the training set. Standard empirical risk minimization would easily fit the training set with only a small amount of noisy labels. Instead, Robust LR could avoid the fitting on the possible noisy labels. We use CIFAR-10 to illustrate how we can use Robust LR to find noisy labels in a mostly correctly labeled dataset.</p><p>We first train Robust LR on the CIFAR-10 training set (without corruption) for 100 epochs without modifying the algorithm. <ref type="table">In the next, examples with  VKLSDXWR  ,'  GHHUGRJ  ,'  ELUGDLUS  ,'  FDWGRJ  ,'  GRJELUG  ,'</ref> GRJFDW ,' FDWGHHU ,' DLUSDXWR ,' ELUGGHHU ,' GRJKRUVH ,'  <ref type="figure" target="#fig_3">Figure 4</ref> (note that there is no ground-truth or high-resolution originals, we can only subjectively tell whether the noisy labels are right or wrong). Some of them are mislabeled probably because of the similarity between two classes, such as 25095 (bird vs. airplane), 38775 (dog vs. cat). Some classes don't usually consider similar, but images in these classes can still be ambiguous, e.g., image 36782 (dog vs. bird) and 33079 (dog vs. horse). These verify that the noise we are facing in the real world could be complex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we study the problem of learning with label noise. We analyze the drawbacks of the two-stage pipeline and identify its confirmation bias problem by visualizing the training dynamics. The observation motivates us to propose Robust LR, a new training algorithm that dynamically refurbishes labels using confidence estimation and pseudo-labeling techniques. We demonstrate that our approach combats both confirmation bias and label noise. As a result, it significantly advances the state-of-the-art. We then conduct ablation experiments to study the effects of the components. Finally, we attempt to find the mislabeled examples in CIFAR-10 with Robust LR. In future work, we are interested in further incorporating ideas from weakly supervised learning into hybrid methods and continuing to combat complex label noise.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Pipeline of Robust LR</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Algorithm 1 1 :</head><label>11</label><figDesc>Robust LR Input: Noisy datasetD = {(xi,?i)} N i=1 , # iterations for warm up Iwarm, # iterations in main training round I, # training rounds R, training strategy Train(dateset, parameters, # iterations).Output: model's parameters ? (0) , ?<ref type="bibr" target="#b0">(1)</ref> Randomly initialize ? (0) , ?<ref type="bibr" target="#b0">(1)</ref> 2: Train(D, ? (m) , Iwarm) for m = 0, 1 ? warm up 3: for r = 1 to R do 4:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>Some mislabeled or indistinguishable examples in the training set of CIFAR-10 found by Robust LR. The wrong annotations, the predicted classes (in the parentheses), and the IDs of images are shown. The airp. and auto. are airplane and automobile for short top-50 big losses are selected and hand-picked. We successfully find some mislabeled or indistinguishable examples in the training set as in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Comparison of other training methods with Robust LR</figDesc><table><row><cell>Method</cell><cell>Label Refurbishment Two-stage Robust LR</cell></row><row><cell>inputs</cell><cell></cell></row><row><cell>Fully explore</cell><cell></cell></row><row><cell>labels</cell><cell></cell></row><row><cell>Complex &amp; Heavy Noise</cell><cell></cell></row><row><cell>3 Method</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Comparison with state-of-the-art methods on CIFAR10 and CIFAR-100 with synthetic noise. Sym. and Asym. are symmetric and asymmetric for short, respectively. The best results are indicated in bold. *AugDesc uses the same augmentation technique</figDesc><table><row><cell cols="2">(RandAugment) as our method</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Dataset</cell><cell></cell><cell>CIFAR-10</cell><cell></cell><cell cols="2">CIFAR-100</cell></row><row><cell>Noise type</cell><cell cols="2">Sym.</cell><cell>Asym.</cell><cell cols="2">Sym.</cell></row><row><cell cols="6">Method/Noise ratio 20% 50% 80% 90% 40% 20% 50% 80% 90%</cell></row><row><cell>F-correction</cell><cell cols="5">Best 86.8 79.8 63.3 42.9 87.2 61.5 46.6 19.9 10.2 Last 83.1 59.4 26.2 18.8 83.1 61.4 37.3 9.0 3.4</cell></row><row><cell>Co-teaching+</cell><cell cols="2">Best 89.5 85.7 67.4 47.9 Last 88.2 84.1 45.5 30.1</cell><cell>--</cell><cell cols="2">65.6 51.8 27.9 13.7 64.1 45.3 15.5 8.8</cell></row><row><cell>P-correction</cell><cell cols="5">Best 92.4 89.1 77.5 58.9 88.5 69.4 57.5 31.1 15.3 Last 92.0 88.7 76.5 58.2 88.1 68.1 56.4 20.7 8.8</cell></row><row><cell>Meta-Learning</cell><cell cols="5">Best 92.9 89.3 77.4 58.7 89.2 68.5 59.2 42.4 19.5 Last 92.0 88.8 76.1 58.3 88.6 67.7 58.0 40.1 14.3</cell></row><row><cell>M-correction</cell><cell cols="5">Best 94.0 92.0 86.8 69.1 87.4 73.9 66.1 48.2 24.3 Last 93.8 91.9 86.6 68.7 86.3 73.4 65.4 47.6 20.5</cell></row><row><cell>DivideMix</cell><cell cols="5">Best 96.1 94.6 93.2 76.0 93.4 77.3 74.6 60.2 31.5 Last 95.7 94.4 92.9 75.4 92.1 76.9 74.2 59.6 31.0</cell></row><row><cell>AugDesc  *</cell><cell>Best 96.1 -Last 96.0 -</cell><cell>-89.6 -89.4</cell><cell>--</cell><cell>78.1 -77.8 -</cell><cell>-36.8 -36.7</cell></row><row><cell>Ours</cell><cell cols="5">Best 96.5 95.8 94.3 92.8 94.4 79.1 75.3 66.7 37.5 Last 96.4 95.7 94.2 92.8 93.7 78.6 74.6 66.2 37.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Comparison with other methods on WebVision</figDesc><table><row><cell>Method</cell><cell>WebVision ILSVRC12</cell></row><row><cell></cell><cell>top-1 top-5 top-1 top-5</cell></row><row><cell cols="2">F-correction 61.12 82.68 57.36 82.36</cell></row><row><cell cols="2">Decoupling 62.54 84.74 58.26 82.26</cell></row><row><cell>D2L</cell><cell>62.68 84.00 57.80 81.36</cell></row><row><cell cols="2">MentorNet 63.00 81.40 57.80 79.92</cell></row><row><cell cols="2">Co-teaching 63.58 85.20 61.48 84.70</cell></row><row><cell cols="2">Iterative-CV 65.24 85.34 61.60 84.98</cell></row><row><cell cols="2">DivideMix 77.32 91.64 75.20 90.84</cell></row><row><cell cols="2">Robust LR 81.84 94.12 75.48 93.76</cell></row><row><cell cols="2">Table 4. Ablation study. Results on CIFAR-10 with different levels of symmetry noise</cell></row><row><cell>are reported</cell><cell></cell></row><row><cell>Method/Noise ratio</cell><cell>20% 50% 80% 90%</cell></row><row><cell>Robust LR</cell><cell>Best 96.5 95.8 94.5 92.8 Last 96.4 95.7 94.2 92.8</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">When solving a problem of interest, do not solve a more general problem as an intermediate step.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Image classification with deep learning in the presence of noisy labels: A survey. Knowledge-Based Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Algan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ulusoy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">215</biblScope>
			<biblScope unit="page">106771</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pseudolabeling and confirmation bias in deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrz?bski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.02249</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Confidence scores make instance-dependent label-noise learning possible</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Berthon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="825" to="836" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Active bias: Training more accurate neural networks by emphasizing high variance samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.07433</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<idno type="DOI">10.7551/mitpress/9780262033589.001.0001</idno>
		<ptr target="https://direct.mit.edu/books/book/3824" />
		<title level="m">Semi-Supervised Learning</title>
		<editor>Zien, A.</editor>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="2006-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Understanding and utilizing deep neural networks trained with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1062" to="1070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Heng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.05458</idno>
		<title level="m">Beyond class-conditional assumption: A primary attempt to combat instance-dependent label noise</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Webly supervised learning of convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1431" to="1439" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="702" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Approximation by superpositions of a sigmoidal function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cybenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of control, signals and systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="303" to="314" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<title level="m">Improved regularization of convolutional neural networks with cutout</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A semi-supervised two-stage approach to learning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1215" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Randomization tests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Edgington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Onghena</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fr?nay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="845" to="869" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.06872</idno>
		<title level="m">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Self-adaptive training: beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07541</idno>
		<title level="m">Learning from complementary labels</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Nlnl: Negative learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Learning multiple layers of features from tiny images</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A simple weight decay can improve generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krogh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hertz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="page" from="950" to="957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07394</idno>
		<title level="m">Dividemix: Learning with noisy labels as semisupervised learning</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Learning to learn from noisy labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5051" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<title level="m">Webvision database: Visual learning and understanding from web data</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dimensionality-driven learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Houle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wijewickrema</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3355" to="3364" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Decoupling&quot; when to update&quot; from&quot; how to update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02613</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Mummadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P N</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H P</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beggel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.01842</idno>
		<title level="m">Self: Learning to filter noisy labels with self-ensembling</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Augmentation strategies for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hollerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8022" to="8031" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krishna Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1701.06548</idno>
		<title level="m">Regularizing neural networks by penalizing confident output distributions</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A survey on image data augmentation for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shorten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="48" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Selfie: Refurbishing unclean samples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5907" to="5915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.08199</idno>
		<title level="m">Learning from noisy labels with deep neural networks: A survey</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5552" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.01780</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
		<imprint>
			<publisher>Wiley-Interscience</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.04835</idno>
		<title level="m">A topological filter for learning with label noise</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Dual t: Reducing estimation error for transition matrix in label-noise learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.07805</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Probabilistic end-to-end noise correction for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7017" to="7025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">How does disagreement help generalization against label corruption</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7164" to="7173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning with biased complementary labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="68" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
		<title level="m">Understanding deep learning requires rethinking generalization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Robust curriculum learning: From clean label detection to noisy label self-correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Learning Representations</title>
		<meeting>the International Conference on Learning Representations<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="28" to="29" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
