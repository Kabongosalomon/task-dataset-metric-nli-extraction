<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Journal Of L A T E X Class</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Files</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vol</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xx</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="middle">X</forename><surname>No</surname></persName>
						</author>
						<title level="a" type="main">Spatial-Temporal Interactive Dynamic Graph Convolution Network for Traffic Forecasting</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Interactive learning</term>
					<term>dynamic graph generation</term>
					<term>graph convolution</term>
					<term>traffic forecasting</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Accurate traffic forecasting is essential for urban traffic control, route planning, and flow detection. Although many spatial-temporal methods are currently proposed, they are still deficient in synchronously capturing the spatial-temporal dependence of traffic data. In addition, most methods ignore the hidden dynamic associations that arise between the road network nodes as it evolves over time. We propose a neural network-based Spatial-Temporal Interactive Dynamic Graph Convolutional Network (STIDGCN) to address the above challenges for traffic forecasting. Specifically, we propose an interactive dynamic graph convolution structure which divides the traffic data by intervals and synchronously captures the divided traffic data's spatial-temporal dependence through an interactive learning strategy. The interactive learning strategy motivates STIDGCN effective for long-range forecasting. We also propose a dynamic graph convolution module through a novel dynamic graph generation method to capture the dynamically changing spatial correlations in the traffic network. Based on a priori knowledge and input data, the dynamic graph generation method can generate a dynamic graph structure, which allows exploring the unseen node connections in the road network and simulating the dynamic associations between nodes over time. Extensive experiments on four real-world traffic flow datasets demonstrate that STIDGCN outperforms the state-of-the-art baselines.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>W Ith the help of available massive urban traffic data collected from sensors on the road, cabs, private car trajectories, and transaction records of public transportation, big traffic data analysis has become an indispensable part of smart city development <ref type="bibr" target="#b0">[1]</ref> for traffic planning, control, and condition assessment. Traffic forecasting, aiming to predict the urban dynamics with the observed historical traffic data, is critical for traffic services like flow control, route planning, and flow detection. Accurate traffic forecasting can contribute to reducing road congestion, facilitating city management of the traffic road network, and even enhancing transportation efficiency <ref type="bibr" target="#b1">[2]</ref>.</p><p>Although traffic forecasting has been continuously an active research hot-spot in the past several decades and extensive research efforts have been made in this field to improve predictive performance, it still faces some challenges. The traffic data is spatial-temporal data with complex temporal correlations and dynamic spatial correlations. As a type of time series data, urban traffic data shows specific periodicity and trends, such as morning and evening peaks. Effective capture of periodicity and trend requires models that can accurately capture the long-term dependence between output and input. These complex temporal correlations hence make long-range forecasting of traffic data difficult. For example, when using the past 12-time steps' observed traffic data to predict the future 12-time steps' data, it is generally more difficult to accurately predict the 9th-12th time steps' data than to predict 1st-3rd time steps' data. As shown in <ref type="figure" target="#fig_0">Figure  1</ref>, traffic data's dynamic spatial correlations are also diverse ? A. <ref type="bibr">Liu</ref>  due to the intricate traffic flow on the road network. <ref type="figure" target="#fig_0">Figure  1a</ref> shows that traffic conditions can spatially affect each other and change dynamically. For example, an accident on one road segment can affect the traffic conditions of its nearby road segments. Besides, traffic flow in different directions on the same segment may also behave differently. There are also some hidden spatial correlations in the traffic dynamics, which stem from spatial heterogeneity, dynamic associations, and uncertainty. This implicit spatial correlation also poses a challenge for traffic forecasting. As in <ref type="figure" target="#fig_0">Figure 1b</ref>, spatial heterogeneity means that different areas(e.g., residential areas and business districts) have different traffic patterns because they have different characteristics, such as road types, road width, POIs, etc. Dynamic associations are time-varying associations between nodes generated by traffic flows. This association could be learned arXiv:2205.08689v5 <ref type="bibr">[cs.</ref>LG] <ref type="bibr" target="#b25">26</ref> Sep 2022 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Modeling Construction Spatial Correlation Temporal Correlation STGCN <ref type="bibr" target="#b2">[3]</ref> In Series GCN (Pre-Defined Graph) GLU ST-MetaNet <ref type="bibr" target="#b3">[4]</ref> In Series GAT (Pre-Defined Graph) GRU ASTGCN <ref type="bibr" target="#b4">[5]</ref> In Series Attention+GCN (Pre-Defined Graph) 1D CNN+Attention Graph WaveNet <ref type="bibr" target="#b5">[6]</ref> In Series GCN (Adaptive Graph) TCN MGDCN <ref type="bibr" target="#b6">[7]</ref> In Series GCN (Multiple Graph) GRU+Attention SLCNN <ref type="bibr" target="#b7">[8]</ref> In Series GCN (Dynamic Graph) 1D CNN MTGNN <ref type="bibr" target="#b8">[9]</ref> In Series GCN (Adaptive Graph) 1D CNN STGODE <ref type="bibr" target="#b9">[10]</ref> In Series ODE+GCN (Dynamic Graph) TCN DMSTGCN <ref type="bibr" target="#b10">[11]</ref> In Series GCN (Adaptive Graph) 1D CNN ASTGNN <ref type="bibr" target="#b11">[12]</ref> In Series GCN (Dynamic Graph) Attention STG-NCDE <ref type="bibr" target="#b12">[13]</ref> In Series NCDE+GCN (Adaptive Graph) NCDE GMAN <ref type="bibr" target="#b13">[14]</ref> In Parallel Attention (Pre-Defined Graph) Attention STFGNN <ref type="bibr" target="#b14">[15]</ref> In Parallel GCN (Multiple Graph) 1D CNN DCRNN <ref type="bibr" target="#b15">[16]</ref> In Embedded GCN (Pre-Defined Graph) LSTM AGCRN <ref type="bibr" target="#b16">[17]</ref> In Embedded GCN (Adaptive Graph) GRU MRA-BGCN <ref type="bibr" target="#b17">[18]</ref> In Embedded Attention+GCN (Multiple Graph) GRU STSGCN <ref type="bibr" target="#b18">[19]</ref> In Embedded GCN (Multiple Graph) GCN(Sliding Window) from historical traffic data and road network structure. Uncertainties refer to the impact of events on traffic conditions, such as weather changes, holidays, and emergencies.</p><p>To effectively capture the spatial-temporal dependence, some deep learning-based methods are applied. The spatial dependence and temporal dependence are widely studied in traffic forecasting. As shown in <ref type="table" target="#tab_1">Table 1</ref>, some methods captured the temporal correlation and spatial correlation separately and combined them either in serial or in parallel. These methods might weaken the captured spatial-temporal correlation and even amplify some unimportant features. Some other recent methods try to synchronously capture the spatial and temporal dependencies by embedding the spatial module into the temporal module, which contributes positively to the models. Nevertheless, the spatial-temporal modules used in these methods are limited in interactive learning of the temporal and spatial information between traffic data, which affects the model's awareness of the periodicity and trend of the sequence.</p><p>To capture the hidden spatial correlations, many current studies map out deeper graph structures by defining various adjacency matrices. As shown in <ref type="table" target="#tab_1">Table 1</ref>, these studies capture the hidden spatial correlations by defining adaptive adjacency matrices or combining multiple adjacency matrices. However, these methods do not adequately utilize the historical traffic data. Although the adaptive adjacency matrix could discover the implicit relationship between graph nodes and thus enhance the model's capture of spatial heterogeneity, it would be fixed as the model training stops. It could not simulate the dynamic association between graph nodes over time. Therefore, these methods are still insufficient to capture the hidden spatial correlations effectively. The dynamic association between nodes over time could be further explored with historical traffic data and initial adjacency matrix.</p><p>With the above concerns, we propose a Spatial-Temporal Interactive Dynamic Graph Convolutional Neural Network (STIDGCN) to explore the interactions between input data and the dynamic correlations in the road network. We design an interactive dynamic graph convolution network to capture the traffic data's spatial-temporal dependence. By embedding the graph convolution module into an interactive learning structure, STIDGCN can synchronously capture the temporal and spatial correlation of traffic data. This structure exploits the trendiness of time series to divide the series at intervals. The interaction learning between the divided sub-series explores the potential associations between spatial-temporal data. In order to effectively capture the hidden spatial correlations, we propose a dynamic graph convolution network that can fully use existing a priori knowledge (graph structure, historical data) through a dynamic graph generation method.</p><p>The contribution of this work is summarized as follows:</p><p>? A new spatial-temporal model STIDGCN is proposed, which embeds the graph convolution into an interactive learning structure. It enables the synchronous capture of temporal and spatial correlations. Spatial-temporal dependence can be learned through the interactive learning structure and dynamic graph convolution network, thus enabling effective long-range prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head><p>We propose a dynamic graph convolution network through a dynamic graph generation method. The dynamic graph is generated by fusing the adaptive and learnable adjacency matrix in which the adaptive adjacency discovers the spatial heterogeneity and learnable adjacency matrix simulates the dynamic associations between nodes.</p><p>? Extensive experiments were conducted on four realworld datasets from previous work. The experimental results show that our model has state-of-the-art performance compared to the baseline models.</p><p>The rest of this paper is organized as follows: Problem definition and related works are stated in Section 2. The proposed method is elaborated in Section 3. Experimental results and analysis are presented in Section 4. Finally, the conclusion is made in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">PROBLEM DEFINITION AND RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Problem Definition</head><p>Traffic forecasting is a time series prediction task using a priori knowledge. Here the priori knowledge is the initial adjacency matrix generated from the traffic road network. Given a road network, we can represent it as a graph G = (V, E, A), where V denotes the set of nodes, |V | = N . Each node denotes an observation point (sensor or road segment) in the traffic road network, and E is a set of edges. The edges in graph G represent the connection relationships between the nodes, and the weights of the edges are the distances between the nodes. A ? R N ?N is the adjacency matrix of graph G. The traffic forecasting task is to predict the future traffic sequence X</p><formula xml:id="formula_0">(t+1) G , X (t+2) G , . . . , X (t+T ) G using a seg- ment of historical sequence X (t?T +1) G , X (t?T +2) G , . . . , X (t) G , where X (t)</formula><p>G ? R N ?C denotes the observation of graph G at time step t, C denotes the number of feature channels, T denotes the length of a given historical time series, T denotes the length of the time series to be predicted.The final traffic flow forecasting problem can be defined as:</p><formula xml:id="formula_1">X (t?T +1) G , . . . , X (t) G f ? X (t+1) G , . . . , X (t+T ) G<label>(1)</label></formula><p>where f denotes the learning function from the historical sequence to the predicted sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Spatial-Temporal Traffic Forecasting</head><p>Traffic forecasting has been extensively studied and traffic forecasting methods can be divided into two groups: traditional methods and deep learning methods. The traditional methods include classical statistical methods and traditional machine learning methods. Early statistical methods used for traffic forecasting are represented by models such as Historical Averages (HA), Auto-Regressive Integrated Moving Average (ARIMA) <ref type="bibr" target="#b19">[20]</ref>, and Vector Auto-Regressive (VAR) <ref type="bibr" target="#b20">[21]</ref>. These models are based on linear time series methods and need to rely on static assumptions. Since traffic data are complex nonlinear data, these models naturally underperform compared to machine learning-based methods.</p><p>To capture complex nonlinear relationships in traffic data, some traditional machine learning methods are applied to traffic forecasting, such as Support Vector Regression (SVR) <ref type="bibr" target="#b21">[22]</ref>, Random Forest Regression (RFR) <ref type="bibr" target="#b22">[23]</ref>, and K-Nearest Neighbor (KNN) <ref type="bibr" target="#b23">[24]</ref>. These methods tend to be more effective but require certain experience to design manual features.</p><p>Deep learning based methods are effective in automatically capturing features for representational learning. Early studies used RNNs <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref> (including LSTM and GRU) to capture the temporal features of traffic data. Ma et al. <ref type="bibr" target="#b24">[25]</ref> first applied LSTM to traffic speed forecasting. LSTM improves the ability to model long-range sequential correlations while overcoming the gradient disappearance and explosion problems. Cui et al. <ref type="bibr" target="#b27">[28]</ref> proposed a Stacked Bidirectional and Unidirectional LSTM for traffic speed forecasting to capture the backward and forward time series correlation. The RNN-based methods have its limitations, such as error accumulation, slow training, and inability to handle long sequences. Convolutional neural network(CNN) can process data in parallel and have a relatively small memory occupation. Some CNN-based methods are widely used for time series, such as WaveNet <ref type="bibr" target="#b28">[29]</ref> and Temporal Convolutional Neural Network (TCN) <ref type="bibr" target="#b29">[30]</ref>. Recently, Liu et al. proposed SCINet <ref type="bibr" target="#b30">[31]</ref> to expand the receptive field of convolutional operations and achieve multi-resolution analysis in a downsample-convolve-interact manner. This novel time series forecasting method also obtains outstanding performance in traffic forecasting. However, the above methods do not consider the spatial correlation of traffic data to fully reflect the Spatial-Temporal dependence.</p><p>Some studies introduce CNN to capture spatial correlation of traffic data. Zhang et al. <ref type="bibr" target="#b31">[32]</ref> proposed ST-ResNet to predict urban pedestrian flow with a CNN structure. Yao et al. <ref type="bibr" target="#b32">[33]</ref> proposed a spatial-temporal dynamic network for New York cab and bicycle data forecasting, which processed spatial-temporal information by CNN and LSTM, respectively. CNN treats traffic data as Euclidean data to capture spatial correlations. Practically the traffic road network has its own topology and traffic data is essentially non-Euclidean data, and the spatial correlation captured by CNN based methods is limited. Graph Neural Network(GNN) can model non-Euclidean data, and it is suitable for capturing spatial correlation in spatial-temporal data.</p><p>Recently, GNN based spatial-temporal modeling methods are widely used to capture the spatial correlation of traffic data. Meanwhile, the RNNs-based, CNNs-based, and attention mechanism-based <ref type="bibr" target="#b33">[34]</ref> modules capture the temporal correlation in spatial-temporal modeling methods. DCRNN <ref type="bibr" target="#b15">[16]</ref> models the spatial correlation of traffic as a diffusion process on directed graphs, and it uses GRU in combination with diffusion GCN for traffic forecasting. STGCN <ref type="bibr" target="#b2">[3]</ref> employs convolution operation fully in the time dimension and uses spectral graph convolution to capture the spatial correlation of traffic data. Since urban traffic is a dynamically changing system, the fixed graph structure with a static adjacency matrix cannot represent such dynamics. For this reason, Wu et al. <ref type="bibr" target="#b5">[6]</ref> proposed Graph WaveNet to capture the dynamic spatial correlation by designing an adaptive adjacency matrix with GCN. Song et al. <ref type="bibr" target="#b18">[19]</ref> proposed STSGCN to capture temporal and spatial correlations synchronously by using sliding windows to process the constructed local spatial-temporal graphs. Nevertheless, these approaches have not effectively capture the hidden dynamic associations between nodes, which inherently exists in traffic dynamics.</p><p>Besides, methods based on the self-attention mechanism are widely used in the long-range forecasting of traffic data. Guo et al. <ref type="bibr" target="#b4">[5]</ref> proposed ASTGCN as a spatial-temporal graph convolutional network based on attention mechanisms. The temporal and spatial attention mechanisms were used to model temporal and spatial correlations, respectively. Zheng et al. <ref type="bibr" target="#b13">[14]</ref> proposed a Graph Multi-Attention Network (GMAN) with an encoder-decoder structure consisting of spatial-temporal attention blocks to model the effects of spatial-temporal factors on traffic conditions. Guo et al. <ref type="bibr" target="#b11">[12]</ref> proposed an Attention-based Spatial-Temporal Graph Neural Network (ASTGNN). Their proposed trendaware self-attention module is used to capture temporal correlation, and the proposed dynamic graph convolution module is used to capture dynamic spatial correlation.  The interactive learning module uses a tree structure and divides the input data at intervals. The dynamic graph convolution module is embedded into the IDGCN to achieve synchronous extraction of spatial-temporal dependencies. DGCN consists of a graph generator and fusion graph convolution. Graph generator generates a learnable adjacency matrix to simulate the dynamic association of changes between nodes. The fusion graph convolution fuses two adjacency matrices and performs graph convolution.</p><formula xml:id="formula_2">x 1-T+1 x t-T+2 x t-1 x t x t+1 x t+2 x t+T ?-1 x t+T ? x 0 x 1 x n-1 x n x 2 x 0 x n x 3 x 1 x n-1 x' 2 x' 0 x' n x' 3 x' 1 x' n-1 ? + ? + Start</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Graph Convolution Network</head><p>GCN methods <ref type="bibr" target="#b34">[35]</ref> extend the traditional convolution method to graph structures and use it to capture the neighbor information of nodes and edges. The two mainstream GCN methods are spectral and spatial methods, respectively. Bruna et al. <ref type="bibr" target="#b35">[36]</ref> first proposed a generalized GCN based on spectral methods in 2014. They mapped the topological graph structure in the spatial domain to the spectral domain by Fourier transform and performed the convolution operation. Finally, the GCN operation is completed by returning to the spatial domain using the inverse transform. Defferrard et al. <ref type="bibr" target="#b36">[37]</ref> improved the traditional GCN and proposed ChebNet to reduce the complexity of Laplacian computation. Kipf and Welling <ref type="bibr" target="#b37">[38]</ref> simplified ChebNet and achieved state-of-the-art performance. GCNs based on spatial methods capture the representations of nodes by aggregating feature information from their neighbors for convolution, such as GraphSAGE <ref type="bibr" target="#b38">[39]</ref>. In addition, Velikovi and Petar <ref type="bibr" target="#b39">[40]</ref> proposed GAT, which uses the attention mechanism to dynamically adjust the correlation weights of neighboring nodes and use these weights to determine the node importance.</p><p>In contrast to previous work, the proposed STIDGCN shares the spatial-temporal features learned between sequences by using a dynamic graph interactive learning strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">SPATIAL-TEMPORAL INTERACTIVE DYNAMIC GRAPH CONVOLUTION NETWORK</head><p>We proposed the spatial-temporal interactive dynamic graph convolutional network(STIDGCN) to synchronously capture of the temporal and spatial correlations. In this approach, dynamic graph structures is presented to capture hidden spatial associations and the dynamic associations between nodes over time are explored. The framework is shown in <ref type="figure" target="#fig_1">Figure 2a</ref>, which consists of two main modules, namely the interactive learning module and the concatenation fusion module.</p><p>First, the original input data is passed through a convolutional layer to get a higher dimensional space to capture deeper dependencies. The features are then fed into the interactive Dynamic Graph Convolution Network (IDGCN) module. Here we deal with interactive learning by divide and conquer. As shown in <ref type="figure" target="#fig_1">Figure 2b</ref>, the input sequence is equally divided into two subsequences using interleaved sampling. Subsequently, the two half-sized subsequences learn interactively in the interactive learning structure, sharing to learn their respective features. While capturing temporal correlations, the Dynamic Graph Convolution Network (DGCN) module is embedded in the interactive learning structure to interactively learn their respective spatial correlations. After IDGCN, two sequences are output. Subsequences (length halved) are recursively generated in the dividing stage. All the result subsequences in the conquer stage are recombined in a time-indexed order and fed into the dynamic graph convolution module for global spatialtemporal feature capture. Finally, the captured features are passed through the Multilayer Perceptron (MLP) to output the forecasting sequence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Interactive Learning</head><p>Inspired by SCINet <ref type="bibr" target="#b30">[31]</ref> and Multilevel Wavelet Decomposition Network <ref type="bibr" target="#b40">[41]</ref>, sequence data can be downsampled to</p><formula xml:id="formula_3">t 1 t 2 t 3 t 4 t 5 t 0 t 0 t 2 t 4 t 1 t 2 t 5</formula><p>Splitting by parity achieve multi-resolution analysis and expand the receptive field. This paper employs CNN and GCN to implement the interactive learning strategy. Compared to CNN-based TCN, the interaction between sequences is tighter, which could better capture the complex temporal correlations and dynamic spatial correlations. As shown in <ref type="figure" target="#fig_1">Figure 2b</ref>, the main component of interactive learning is IDGCN. For most time series data, due to the trending and closeness, the interleaved down-sampling subsequences still maintain most information from the original series. As shown in <ref type="figure" target="#fig_2">Figure 3</ref>, the two subsequences of traffic data for a road segment still preserve the temporal trend and periodicity of the original sequence after downsampling.</p><p>The segmented subsequences learn the spatial-temporal features interactively in the dynamic graph convolution module. As shown in <ref type="figure" target="#fig_1">Figure 2b</ref>, the two subsequences use separate convolution modules to preprocess the features to increase the receptive field. The two subsequences share the parameter weights in the dynamic graph convolution module. More interactive learning processes could be overlayed when necessary.</p><p>Assume that X ? R C?N ?T is the input to the interactive learning structure. The subsequence of X after interval division (according to parity index interval) can be represented as X odd ? R C?N ?T /2 , X even ? R C?N ?T /2 . The 1D convolution operation in the interactive learning structure can be represented as Conv1, Conv2, Conv3, Conv4. The output after the first interactive learning is X even ? R C?N ?T /2 , X odd ? R C?N ?T /2 . X even , X odd are subjected to one more interactive learning and the final subsequence are X odd?out ? R C?N ?T /2 , X even?out ? R C?N ?T /2 output. The operations in the interactive learning structure can be defined as:</p><formula xml:id="formula_4">X even , X odd = Split(X)<label>(2)</label></formula><p>X odd = tanh (DGCN (Conv1 (X even ))) X odd (3)</p><formula xml:id="formula_5">X even = tanh (DGCN (Conv2 (X odd ))) X even<label>(4)</label></formula><p>X odd?out = X odd + tanh (DGCN (Conv3 (X even ))) (5)</p><p>X even?out = X even + tanh (DGCN (Conv4 (X odd ))) <ref type="bibr" target="#b5">(6)</ref> where is denoted Hadamard product, tanh is the activation function, and DGCN denotes the dynamic graph convolution in the DGCN module. This interactive learning strategy allows the spatial-temporal features of each other to be captured between subsequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dynamic Graph Convolution</head><p>The structure of the DGCN module is shown in <ref type="figure" target="#fig_1">Figure 2c</ref>, which consists of two main modules: graph generator and fusion graph convolution. DGCN module utilizes its generated graph structure to explore deeper spatial correlations better and increase the model's performance for capturing spatial heterogeneity. As shown in <ref type="figure" target="#fig_1">Figure 2c</ref>, the graph generator takes the hidden features H ? R C?N ?T as input and the pre-defined initial adjacency matrix A ? R N ?N as the first input. After the input H ? R C?N ?T , A ? R N ?N is processed by diffusion graph convolution <ref type="bibr" target="#b15">[16]</ref>, it is then fed to the MLP to generate the matrix A ? R N ?N with spatial-temporal feature: A = Sof tM ax(M LP <ref type="figure">(GCN (H, A)</ref>))</p><p>where M LP denotes multilayer perceptron, and GCN denotes diffusion graph convolution operation. The generated matrix A ? R N ?N is discrete. Since this variable needs to be sampled during the training process to ensure the sampling process to be derivable, here we use Gumbel reparameterization <ref type="bibr" target="#b41">[42]</ref> :</p><formula xml:id="formula_7">A learn = GumbelSof tmax(A ) = Sof tM ax((log (A ) ? log(? log(g))) /? )<label>(8)</label></formula><p>where g ? Gumbel(0, 1) is a random variable. ? is the softmax temperature and is set to 0.5. A learn ? R N ?N is the adjacency matrix generated by the graph generator, and it can simulate the dynamic correlations generated between graph nodes. In addition to the adjacency matrix A learn generated by the graph generator, we define an adaptive adjacency matrix <ref type="bibr" target="#b5">[6]</ref> A apt ? R N ?N which can be expressed as :</p><formula xml:id="formula_8">A apt = Sof tM ax Relu E 1 E 2<label>(9)</label></formula><p>where E 1 ? R N ?c and E 2 ? R N ?c are learnable parameters. The initial value of A apt is the adjacency matrix A ? R N ?N pre-defined by a priori graph. As shown in <ref type="figure" target="#fig_1">Figure 2c</ref>, we fuse A apt with A learn using the adaptive fusion structure. After fusion, the resulting adjacency matrix A dyn is fed into the diffusion GCN for dynamic correlations simulation between nodes and and exploring the unseen node connections in the road network. This fusion operation can be defined as follows:</p><formula xml:id="formula_9">A dyn = ?A apt + (1 ? ?)A learn<label>(10)</label></formula><p>where A dyn is the dynamic adjacency matrix after fusion and ? is the learnable adaptive parameter factor. In STIDGCN, we use diffusion GCN in three modules: graph generator, fusion graph convolution and concatenation fusion respectively. We define the input of diffusion GCN as X in ? R C?N ?T uniformly.</p><p>In the graph generator, the diffusion GCN used is defined as:</p><formula xml:id="formula_10">GCN (X in , A apt ) = K k=0 A k apt X in W<label>(11)</label></formula><p>where A apt ? R N ?N is the adaptive adjacency matrix, k is the diffusion step, K is the maximum number of diffusion step, and W ? R N ?N denotes the parameter matrix.</p><p>In the fusion graph convolution module, A dyn is the adjacency matrix of the input to the diffusion GCN, where the diffusion GCN can be defined as:</p><formula xml:id="formula_11">GCN (X in , A dyn ) = K k=0 A k dyn X in W<label>(12)</label></formula><p>As shown in <ref type="figure" target="#fig_1">Figure 2a</ref>, the spatial-temporal features obtained from the interactive learning structure are fed to a diffusion GCN module after recombining them in a temporally indexed order. Here the diffusion GCN module is used for feature capture and correction of the whole sequence data. Unlike before, we use two matrices in this diffusion GCN module, a pre-defined initial adjacency matrix A ? R N ?N and a dynamic adjacency matrix A dyn ? R N ?N generated by the interactive learner structure. For the initial adjacency matrix A ? R N ?N , we use directed graphs, and the forward and backward transition matrices of A are denoted as A f = A/rowsum(A) and A b = A T /rowsum A T , respectively. The diffusion GCN module in this context can be defined as:</p><formula xml:id="formula_12">GCN (X in , A, A dyn ) = K k=0 (A k f X in W 1 + A k b X in W 2 + A k dyn X in W 3 )<label>(13)</label></formula><p>The DGCN module can explore the unseen node connections in the road network to capture hidden spatial correlations. DGCN module can also dynamically simulate the dynamic associations generated between nodes over time based on the input traffic data. The DGCN module is embedded in the interactive learning structure to enhance the capture of temporal correlation using the captured spatial information during the training process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENT RESULTS AND ANALYSIS</head><p>To evaluate the performance of STIDGCN, we conducted extensive experiments on four real-world freeway traffic flow datasets and verified the functionality of each STIDGCN module through ablation experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>In our experiments, we used four real-world public available traffic flow datasets <ref type="bibr" target="#b18">[19]</ref>, which are PEMS03, PEMS04, PEMS07, and PEMS08. All four datasets were collected by the Caltrans Performance Measurement System (PeMS) <ref type="bibr" target="#b42">[43]</ref> every 30 seconds in real-time. These data are eventually aggregated into 5-minute time observations, so there are 12 observations for an hour, and our goal is to predict the traffic data for the next hour. The dataset details are shown in <ref type="table" target="#tab_3">Table 2</ref>. The graph's adjacency matrix in the experiments is constructed based on the distance between sensors in these real traffic road networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baseline Methods</head><p>We compared STIDGCN with 15 baseline methods, which are as follows:</p><p>? HA: Historical Average uses the average results of historical data to predict future data.</p><p>? VAR <ref type="bibr" target="#b43">[44]</ref>: Vector Auto-Regression is a time series model that captures the temporal correlation of traffic series.</p><p>? SVR <ref type="bibr" target="#b44">[45]</ref>: Support Vector Regression is a machine learning method that uses support vector machines to do regression on traffic sequences. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DCRNN [16]: Diffusion Convolutional Recurrent</head><p>Neural Network is an encoder-decoder structure that combines diffusion GCN with GRU to capture the spatial-temporal dependencies of traffic data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>?</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STGCN [3]: Spatial-Temporal Graph Convolutional</head><p>Network combines the spectral GCN with 1D convolution to capture spatial-temporal dependencies. ? Graph WaveNet <ref type="bibr" target="#b5">[6]</ref>: Graph WaveNet combines gated TCN with spatial GCN and proposes an adaptive adjacency matrix to learn dynamic spatial correlations.</p><p>? AGCRN <ref type="bibr" target="#b16">[17]</ref>: Adaptive Graph Convolutional Recurrent Network is a model that combines GCN with GRU using an adaptive graph structure.</p><p>?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>STSGCN [19]: Spatial-Temporal Synchronous Graph</head><p>Convolutional Network is a GCN model that constructs multiple local spatial-temporal graphs to capture spatial-temporal dependencies synchronously.</p><p>? STFGNN <ref type="bibr" target="#b14">[15]</ref>: Spatial-Temporal Fusion Graph Neural Networks efficiently learn hidden correlations by performing fusion operations on the generated spatial-temporal graphs.</p><p>? ASTGNN <ref type="bibr" target="#b11">[12]</ref>: Attention based Spatial-Temporal Graph Neural Network is a self-attention traffic forecasting model that combines a time-trending selfattention mechanism with a dynamic GCN.</p><p>? SCINet <ref type="bibr" target="#b30">[31]</ref>: Sample Convolution and Interaction Network uses an interactive convolutional structure, allowing multi-resolution processing of sequence data and expanding the receptive field of the convolution operation.</p><p>? STG-NCDE <ref type="bibr" target="#b12">[13]</ref>: Spatial-Temporal Graph Neural Controlled Differential Equation uses spatialtemporal NCDEs to process traffic data and is a controlled differential equation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Settings</head><p>All datasets used in the experiments are divided into the training set, validation set, and test set according to the ratio of 6:2:2. Z-score normalization is applied to standardize the datasets before feeding them to the network. For the missing traffic data, we mask them, i.e., we do not consider these missing data (value 0). We use data from 12 continuous-time steps in the past one hour to predict data from 12 continuous future time steps of the next hour. Experiments are conducted under a computer environment with one Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz and one NVIDIA Tesla V100 GPU card. We train STIDGCN using the Ranger optimizer <ref type="bibr" target="#b46">[47]</ref> with the initial learning rate set to 0.001. The batch size is set to 64, and the training epoch is 500, where we set the early stop mechanism. The model converges to an end at around epoch 300.</p><p>We selected three standard metrics to evaluate all methods' performance, namely mean absolute error (MAE), mean absolute error (MAPE), and root mean square error (RMSE), which are defined as follows:</p><formula xml:id="formula_13">M AE = 1 N N i=1 Y i ?? i<label>(14)</label></formula><formula xml:id="formula_14">M AP E = 100% N N i=1 Y i ?? i Y i<label>(15)</label></formula><formula xml:id="formula_15">RM SE = 1 N N i=1 Y i ?? i 2<label>(16)</label></formula><p>where N denotes the number of samples, Y i denotes the ground truth, and? i denotes the prediction value. <ref type="table" target="#tab_4">Table 3</ref> shows the forecasting results of STIDGCN and the comparison model for the next hour (12 timesteps) on four test sets of real traffic flow data. Our proposed STIDGCN performs better than all baseline methods on these four traffic datasets, except for the MAPE metric in PEMS03 and PEMS04, which is slightly worse than Graph WaveNet and SCINet, respectively. STIDGCN on PEMS07 and PEMS08, the results have more noticeable improvement. In PEMS07, STIDGCN improves the state-of-the-art method by 6.1%, 4.7%, and 5.0% in MAE, RMSE and MAPE, respectively. In PEMS08, STIDGCN improves the state-of-the-art method by 6.5%, 2.1%, and 3.7% in MAE, RMSE and MAPE, respectively. The results in <ref type="table" target="#tab_4">Table 3</ref> show that statistical methods (HA, VAR), traditional machine learning methods (SVR), LSTM and TCN perform poorly because these models only consider temporal correlation and neglect the complex spatial correlation in traffic data. Spatial-temporal GCN models represented by STGCN and DCRNN perform better because both temporal and spatial correlations are considered. In addition, models based on attention mechanisms (ASTGCN, ASTGNN) also perform well because attention mechanisms can capture the temporal correlation of long sequences. Graph WaveNet performs even better than some recently proposed models (STFGNN, STG-NCDE). Graph WaveNet is the embedding of diffusion GCN into TCN, which has an excellent ability to capture temporal correlation. This compact dependency capture is close to the synchronous capture of spatial-temporal features. Although STSGCN uses a synchronous method to capture spatial-temporal features, it uses a simple sliding window to capture temporal correlations. It indicates that STSGCN downplays the capture of temporal correlation, and its overall performance is not very good even when the spatial correlation is captured effectively. It is worth noting that SCINet achieves good performance even without considering spatial correlation. It also demonstrates the effectiveness of interactive learning and the importance of spatial modeling for traffic data. NCDE as a new deep learning model, even with the good results obtained, its performance is not as good as the proposed STIDGCN due to its capturing spatialtemporal features in series. Our proposed STIDGCN uses an interactive learning strategy for synchronous capturing of correlations. Its DGCN module can explore the unseen node connections in the road network to capture hidden spatial correlations and simulate the generation of dynamic associations between nodes over time. <ref type="figure" target="#fig_5">Figure 4</ref> shows the variation of MAE, RMSE, and MAPE for a portion of the model on four traffic datasets with increasing forecasting time horizons. As the forecast horizon increases, the forecast difficulty will also change; MAE, RMSE, and MAPE will continue to increase. Our proposed STIDGCN uses an interactive learning strategy where sequences learn each other's spatial-temporal features to obtain long-range forecasting capabilities. As shown in <ref type="figure" target="#fig_5">Figure  4</ref>, STIDGCN performs better than ASTGNN based on the attention mechanism, even in long-range forecasting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Comparison and Analysis of Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Study</head><p>To further evaluate which components of STIDGCN are the key components affecting the model results, we conducted ablation experiments on PEMS04 and PEMS08 datasets. We designed six STIDGCN variants, which are as follows: The results of the ablation experiments are shown in <ref type="figure" target="#fig_6">Figure 5</ref>. The effects of these components on the model as a whole have essentially similar distributions on the PEMS04 and PEMS08 datasets. We also compared AST-GNN in ablation experiments. Firstly, GCN is crucial for STIDGCN, and secondly, our proposed IDGCN module is crucial for the overall model performance improvement. The 1D convolution used to expand the receptive field is a crucial component of the interactive learning structure, and ablation experiments show that it can significantly improve model performance. The model performance deteriorated after replacing the interactive learning structure with TCN, and ASTGNN's combined performance outperforms STIDGCN. It verifies that synchronous feature capture in the interactor is more effective than capture in series like TCN or ASTGNN. In addition, we conducted an ablation study of the two adjacency matrices defined inside the DGCN module, and <ref type="figure" target="#fig_6">Figure 5</ref> shows that the adaptive adjacency matrix is vital to the model. The learnable adjacency matrix also plays a significant role and cooperates with the adaptive adjacency matrix to generate the dynamic adjacency matrix. As shown in <ref type="figure" target="#fig_6">Figure 5</ref>, ASTGNN's performance outperforms STIDGCN when STIDGCN removes the dynamic adjacency matrix. It shows the necessity of a dynamic adjacency matrix for graph convolution. This dynamic adjacency matrix al- lows graph convolution better to capture the hidden spatial correlations in the traffic data. Therefore, our proposed two core structures (interactive learning and dynamic graph convolution) are effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Effect of Different Structure Configurations</head><p>To further investigate the effects of hyperparameter settings and model structure settings, we conducted experiments on the PEMS08 dataset. STIDGCN does not take the form of repeatedly stacked modules to capture features, so the only hyperparameters related to the model structure are the num-ber of feature channels. As shown in <ref type="figure" target="#fig_7">Figure 6</ref>, the number of feature channels specifically affects STIDGCN. STIDGCN's performance does not improve consistently as the number of feature channels increases. STIDGCN's performance also tends to level off when the number of feature channels is increased to a specific value. While feature channels range from 64 to 80, STIDGCN performs best. However, increasing the number of feature channels leads to more parameters and a longer inference time for the model. Therefore, the number of feature channels of STIDGCN is finally selected as 64.  In addition, we have made a few changes to the submodules in the interactive learning structure to demonstrate that the current structure is the most reasonable. The interactive learning structure consists of four separate convolutional modules and one weight-sharing DGCN module. The convolution module is designed to extract correlations between different time steps in the current sequence and broadens the model's receptive field in the interactive learning architecture. Meanwhile, the weight-sharing DGCN module can interactively learn spatial correlations in different sequences. We have made the following changes to the IDGCN module:</p><p>? IDGCN Conv?1: Replace the 4 separate convolutional modules with a single weight-sharing convolutional module in the interactive learning structure.</p><p>? IDGCN DGCN?2: The weight-sharing DGCN module in the interaction learning structure is replaced by 2 separate DGCN modules. Two separate DGCN modules are used to capture the spatial correlation of the sequences during the two interactive learning sessions, respectively.</p><p>? IDGCN DGCN?4: The weight-sharing DGCN modules in the interaction learning structure are replaced by 4 separate DGCN modules. The 4 DGCN modules capture the spatial correlation of the sequences during the two interactive learning processes, respectively.</p><p>? IDGCN Interaction?1: The number of interactive learning in the interactive learning structure is changed from 2 to 1, i.e., two convolution operations and one graph convolution operation are removed.</p><p>? IDGCN Interaction?4: The number of interactive learning in the interaction learning structure is changed from 2 to 4, i.e., the interactive learning operation in the IDGCN module is repeated twice.</p><p>As shown in <ref type="table" target="#tab_5">Table 4</ref>, the changed structure affects  <ref type="table" target="#tab_5">Table 4</ref> show that the weightsharing convolution module is not more effective than the separate convolution module. DGCN module has the opposite performance; adding the DGCN module does not lead to better performance. The weight-sharing DGCN module is equivalent to stacking DGCN modules in interactive learning, allowing STIDGCN to have a larger receptive field in spatial terms and nodes to make associations with more distant nodes. A separate DGCN module does not give a shared receptive field and can lead to poorer model performance. STIDGCN uses a synchronous strategy to capture spatial-temporal dependencies in the interactive learning structure. Therefore, reducing the number of interactive learning means reducing the capture of spatial-temporal dependencies, and this operation will undoubtedly lead to poorer performance of STIDGCN. Experiments show that two interactive learning is sufficient to fit the features, and increasing the interactive learning operation in the IDGCN module leads to a poorer ability to fit the features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Computation Time</head><p>In this part, we compare the computation cost of STIDGCN with part of the baseline models on the PEMS08 dataset in <ref type="table" target="#tab_6">Table 5</ref>. STIDGCN does not suffer from severe computation costs while having outstanding performance. Compared with other state-of-the-art baselines like ASTGNN and STG-NCDE, STIDGCN achieves better performance while significantly reducing computation costs. Although ASTGNN has emergent performance, it processes data in an autoregressive manner, leading to high computation costs. Graph Wave has less computation cost due to parallel data processing and lightweight model. Although SCINet has the lowest computation cost, it has its deficiency in capturing spatial correlations. The computation cost of STIDGCN mainly comes from the dynamic graph convolution structure in its interactive learning. STIDGCN parallelizes data processing in a non-autoregressive manner to make the model more efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>In this paper, we propose a dynamic graph generation model STIDGCN using an interactive learning strategy. Specifically, we embed dynamic GCN modules into the interactive learning structure to capture spatial-temporal dependencies synchronously. The application scenario of interactive learning strategy is time series forecasting that exhibits certain periodicity and trend. We propose a DGCN module to simulate dynamic spatial correlations, i.e., to use the input spatial-temporal information to generate a dynamic graph structure and cooperate with a pre-defined initial adjacency matrix. The DGCN module explores the unseen node connections in the road network to capture hidden spatial correlations and simulates the dynamic correlation generated between nodes over time. Experiments on four real datasets show that simultaneous learning and dynamic graph generation are essential for spatial-temporal forecasting. Our proposed model outperforms the state-ofthe-art baseline. In interactive learning, feature learning is performed in uniform distribution among individual sequences. However, the degree of correlations between data is not always uniformly distributed. Therefore, we consider using attention mechanisms in interactive learning as a good improvement solution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Spatial diversity of traffic data. Traffic flow in (a) shows that traffic flow in different directions on the same road may behave differently, and accidents on the road can affect nearby roads. (b) shows the hidden spatial correlation(spatial heterogeneity, dynamic associations, and uncertainty).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>STIDGCN architecture. STIDGCN consists of an interactive learning module and concatenation fusion module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Impact of splitting operations on traffic data. (a) is the initial sequence, (c) is the subsequence generated by dividing by odd index, and (d) is the subsequence generated by dividing by even index. The subseries obtained after the interval division operation still retain the original series's time trend information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>?</head><label></label><figDesc>LSTM<ref type="bibr" target="#b45">[46]</ref>: Long-Short Term Memory is a neural network-based model that can effectively capture time series correlation.? TCN [30]: Temporal Convolutional Neural Network is implemented by stacked causal dilation convolution to capture time series correlation efficiently.?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>?</head><label></label><figDesc>w/o GCN: On the base of STIDGCN, the diffusion GCN module is removed.? w/o DGCN: On the base of STIDGCN, the DGCN module is replaced with a normal diffusion GCN. The adjacency matrix input to the GCN is the predefined initial adjacency matrix.? w/o Conv: On the base of STIDGCN, remove the 1D convolution module from the interactive learning structure. ? w/o Interaction: On the base of STIDGCN, the interactive learning structure is replaced by a TCN and connected in series with the dynamic convolution module. The TCN is set to 6 layers of convolution, and the number of feature channels is 64. ? w/o Apt Adj: On the base of STIDGCN, the adaptive adjacency matrix of the DGCN module is removed. The adjacency matrix of the input graph generator is replaced with the pre-defined initial adjacency matrix. ? w/o Learned Adj: On the base of STIDGCN, remove the graph generator structure, keep the adaptive adjacency matrix, and change the fusion GCN to diffusion GCN in the DGCN module.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 4 .</head><label>4</label><figDesc>Forecasting performance comparison at each horizon on four datasets. STIDGCN performs best in PEMS07, PEMS08, and PEMS04. STIDGCN outperforms ASTGNN at time steps 10, 11, and 12. STIDGCN has a better long-range forecast ability.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 5 .</head><label>5</label><figDesc>Component analysis of STIDGCN. Each of the components in STIDGCN contributes a positive effect. Among them, DGCN and the interactive learning structure are the components that influence the model most.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 6 .</head><label>6</label><figDesc>Effect of the number of feature channels on model performance. Increasing the number of feature channels from 16 to 128 shows that STIDGCN has the best performance in the 64-80 interval.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 1</head><label>1</label><figDesc>Classification of spatial-temporal modeling methods.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 2</head><label>2</label><figDesc>Dataset Description.</figDesc><table><row><cell></cell><cell cols="4">Datasets Nodes Edges TimeSteps</cell><cell>Time Range</cell><cell>Missing Rate</cell></row><row><cell></cell><cell>PEMS03</cell><cell>358</cell><cell>547</cell><cell>26208</cell><cell>09/01/2018 -11/30/2018</cell><cell>0.672%</cell></row><row><cell></cell><cell>PEMS04</cell><cell>307</cell><cell>340</cell><cell>16992</cell><cell>01/01/2018 -02/28/2018</cell><cell>3.182%</cell></row><row><cell></cell><cell>PEMS07</cell><cell>883</cell><cell>866</cell><cell>28224</cell><cell>05/01/2017 -08/31/2017</cell><cell>0.452%</cell></row><row><cell></cell><cell>PEMS08</cell><cell>170</cell><cell>295</cell><cell>17856</cell><cell>07/01/2016 -08/31/2016</cell><cell>0.696%</cell></row><row><cell>?</cell><cell cols="4">ASTGCN [5]: Attention based spatial-temporal</cell><cell></cell></row><row><cell></cell><cell cols="4">graph convolutional network captures spatial-</cell><cell></cell></row><row><cell></cell><cell cols="4">temporal dependencies by designing spatial and</cell><cell></cell></row><row><cell></cell><cell cols="4">temporal attention mechanisms, respectively.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 3</head><label>3</label><figDesc>Comparison of STIDGCN and baselines on four traffic datasets.</figDesc><table><row><cell>Methods</cell><cell cols="2">PEMS03 MAE RMSE</cell><cell>MAPE</cell><cell cols="2">PEMS04 MAE RMSE</cell><cell>MAPE</cell><cell cols="2">PEMS07 MAE RMSE</cell><cell>MAPE</cell><cell cols="2">PEMS08 MAE RMSE</cell><cell>MAPE</cell></row><row><cell>HA</cell><cell>31.58</cell><cell>52.39</cell><cell>33.78%</cell><cell>38.03</cell><cell>59.24</cell><cell>27.88%</cell><cell>45.12</cell><cell>65.64</cell><cell>24.51%</cell><cell>34.86</cell><cell>59.24</cell><cell>27.88%</cell></row><row><cell>VAR</cell><cell>23.65</cell><cell>38.26</cell><cell>24.51%</cell><cell>24.54</cell><cell>38.61</cell><cell>17.24%</cell><cell>50.22</cell><cell>75.63</cell><cell>32.22%</cell><cell>19.19</cell><cell>29.81</cell><cell>13.10%</cell></row><row><cell>SVR</cell><cell>21.97</cell><cell>35.29</cell><cell>21.51%</cell><cell>28.70</cell><cell>44.56</cell><cell>19.20%</cell><cell>32.49</cell><cell>50.22</cell><cell>14.26%</cell><cell>23.25</cell><cell>36.16</cell><cell>14.64%</cell></row><row><cell>LSTM</cell><cell>21.33</cell><cell>35.11</cell><cell>23.33%</cell><cell>26.77</cell><cell>40.65</cell><cell>18.23%</cell><cell>29.98</cell><cell>45.94</cell><cell>13.20%</cell><cell>23.09</cell><cell>35.17</cell><cell>14.99%</cell></row><row><cell>TCN</cell><cell>19.32</cell><cell>33.55</cell><cell>19.93%</cell><cell>23.22</cell><cell>37.26</cell><cell>15.59%</cell><cell>32.72</cell><cell>42.23</cell><cell>14.26%</cell><cell>22.72</cell><cell>35.79</cell><cell>14.03%</cell></row><row><cell>DCRNN</cell><cell>17.99</cell><cell>30.31</cell><cell>18.34%</cell><cell>21.22</cell><cell>33.44</cell><cell>14.17%</cell><cell>25.22</cell><cell>38.61</cell><cell>11.82%</cell><cell>16.82</cell><cell>26.36</cell><cell>10.92%</cell></row><row><cell>STGCN</cell><cell>17.55</cell><cell>30.42</cell><cell>17.34%</cell><cell>21.16</cell><cell>34.89</cell><cell>13.83%</cell><cell>25.33</cell><cell>39.34</cell><cell>11.21%</cell><cell>17.50</cell><cell>27.09</cell><cell>11.29%</cell></row><row><cell>ASTGCN</cell><cell>17.34</cell><cell>29.56</cell><cell>17.21%</cell><cell>22.93</cell><cell>35.22</cell><cell>16.56%</cell><cell>24.01</cell><cell>37.87</cell><cell>10.73%</cell><cell>18.25</cell><cell>28.06</cell><cell>11.64%</cell></row><row><cell>GWN</cell><cell>14.79</cell><cell>25.51</cell><cell>14.32%</cell><cell>19.36</cell><cell>31.72</cell><cell>13.31%</cell><cell>21.22</cell><cell>34.12</cell><cell>9.07%</cell><cell>15.07</cell><cell>23.85</cell><cell>9.51%</cell></row><row><cell>STSGCN</cell><cell>17.48</cell><cell>29.21</cell><cell>16.78%</cell><cell>21.19</cell><cell>33.65</cell><cell>13.90%</cell><cell>24.26</cell><cell>39.03</cell><cell>10.21%</cell><cell>17.13</cell><cell>26.80</cell><cell>10.96%</cell></row><row><cell>AGCRN</cell><cell>15.98</cell><cell>28.25</cell><cell>15.23%</cell><cell>19.83</cell><cell>32.26</cell><cell>12.97%</cell><cell>22.37</cell><cell>36.55</cell><cell>9.12%</cell><cell>15.95</cell><cell>25.22</cell><cell>10.09%</cell></row><row><cell>STFGNN</cell><cell>16.77</cell><cell>28.34</cell><cell>16.30%</cell><cell>19.83</cell><cell>31.88</cell><cell>13.02%</cell><cell>22.07</cell><cell>35.80</cell><cell>9.21%</cell><cell>16.64</cell><cell>26.22</cell><cell>10.60%</cell></row><row><cell>ASTGNN</cell><cell>14.78</cell><cell>25.00</cell><cell>14.79%</cell><cell>18.60</cell><cell>30.91</cell><cell>12.36%</cell><cell>20.62</cell><cell>34.00</cell><cell>8.86%</cell><cell>15.00</cell><cell>24.70</cell><cell>9.50%</cell></row><row><cell>SCINet</cell><cell>15.25</cell><cell>24.58</cell><cell>14.54%</cell><cell>19.30</cell><cell>31.28</cell><cell>12.05%</cell><cell>21.56</cell><cell>34.37</cell><cell>9.03%</cell><cell>15.76</cell><cell>24.65</cell><cell>10.01%</cell></row><row><cell>STG-NCDE</cell><cell>15.57</cell><cell>27.09</cell><cell>15.06%</cell><cell>19.21</cell><cell>31.09</cell><cell>12.76%</cell><cell>20.53</cell><cell>33.84</cell><cell>8.80%</cell><cell>15.45</cell><cell>24.81</cell><cell>9.92%</cell></row><row><cell>STIDGCN</cell><cell>14.55</cell><cell>24.42</cell><cell>14.68%</cell><cell>18.42</cell><cell>29.81</cell><cell>12.27%</cell><cell>19.28</cell><cell>32.26</cell><cell>8.36%</cell><cell>14.03</cell><cell>23.35</cell><cell>9.15%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4</head><label>4</label><figDesc>IDGCN module configuration analysis.</figDesc><table><row><cell>Structure</cell><cell cols="3">MAE RMSE MAPE</cell></row><row><cell>IDGCN Conv?1</cell><cell>14.33</cell><cell>23.57</cell><cell>9.22%</cell></row><row><cell>IDGCN DGCN?2</cell><cell>14.60</cell><cell>23.87</cell><cell>9.69%</cell></row><row><cell>IDGCN DGCN?4</cell><cell>14.64</cell><cell>24.06</cell><cell>9.91%</cell></row><row><cell>IDGCN Interaction?1</cell><cell>14.32</cell><cell>23.74</cell><cell>9.32%</cell></row><row><cell>IDGCN Interaction?2</cell><cell>14.81</cell><cell>23.87</cell><cell>9.81%</cell></row><row><cell>STIDGCN</cell><cell>14.03</cell><cell>23.35</cell><cell>9.15%</cell></row></table><note>STIDGCN. The results in</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 5</head><label>5</label><figDesc>The computation cost on the PEMS08 dataset.</figDesc><table><row><cell>Model</cell><cell cols="2">Computation Time Training (s/epoch) Inference (s)</cell></row><row><cell>GWN</cell><cell>10.64</cell><cell>1.20</cell></row><row><cell>STSGCN</cell><cell>61.28</cell><cell>12.40</cell></row><row><cell>STFGNN</cell><cell>21.93</cell><cell>4.45</cell></row><row><cell>SCINet</cell><cell>5.09</cell><cell>2.86</cell></row><row><cell>ASTGNN</cell><cell>44.48</cell><cell>23.70</cell></row><row><cell>STG-NCDE</cell><cell>84.47</cell><cell>9.17</cell></row><row><cell>STIDGCN</cell><cell>22.16</cell><cell>2.43</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Dl-traff: Survey and benchmark of deep learning models for urban traffic prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shibasaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th ACM International Conference on Information &amp; Knowledge Management</title>
		<meeting>the 30th ACM International Conference on Information &amp; Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="4515" to="4525" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A comprehensive survey on graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Y</forename><surname>Philip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="4" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Spatio-temporal graph convolutional networks: A deep learning framework for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in IJCAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Urban traffic prediction from spatio-temporal data using deep meta learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 25th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1720" to="1730" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Attention based spatial-temporal graph convolutional networks for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="922" to="929" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Graph wavenet for deep spatial-temporal graph modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploiting spatiotemporal correlations of arrive-stay-leave behaviors for private car flow prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Network Science and Engineering</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Spatiotemporal graph structure learning for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1177" to="1185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Connecting the dots: Multivariate time series forecasting with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="753" to="763" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Spatial-temporal graph ode networks for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="364" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Dynamic and multi-faceted spatio-temporal deep learning for traffic speed forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="547" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning dynamics and heterogeneity of spatial-temporal graph data for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Graph neural controlled differential equations for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Park</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.03558</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Gman: A graph multiattention network for traffic prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="1234" to="1241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Spatial-temporal fusion graph neural networks for traffic flow forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="4189" to="4196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Diffusion convolutional recurrent neural network: Data-driven traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adaptive graph convolutional recurrent network for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="17" to="804" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multirange attentive bicomponent graph convolutional network for traffic forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="3529" to="3536" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Spatial-temporal synchronous graph convolutional networks: A new framework for spatial-temporal network data forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="914" to="921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Modeling and forecasting vehicular traffic flow as a seasonal arima process: Theoretical basis and empirical results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Hoel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of transportation engineering</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="664" to="672" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Integrating granger causality and vector auto-regression for traffic prediction of largescale wlans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">KSII Transactions on Internet and Information Systems (TIIS)</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="136" to="151" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Supervised weighting-online learning algorithm for short-term traffic flow prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-S</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-J</forename><surname>Byon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Castro-Neto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Easa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Intelligent Transportation Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1700" to="1707" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Regression conformal prediction with random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bostr?m</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>L?fstr?m</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Linusson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine learning</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="155" to="176" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Short-term traffic and travel time prediction models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Lint</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Hinsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Applications to Critical Transportation Issues</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="41" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Long short-term memory neural network for traffic speed prediction using remote microwave sensor data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="187" to="197" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Using lstm and gru neural network methods for traffic flow prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 31st Youth Academic Annual Conference of Chinese Association of Automation (YAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="324" to="328" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Learning phrase representations using rnn encoder-decoder for statistical machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bougares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.1078</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Stacked bidirectional and unidirectional lstm recurrent neural network for forecasting networkwide traffic state with missing values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Part C: Emerging Technologies</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="page">102674</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Wavenet: A generative model for raw audio</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Senior</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>SSW</publisher>
			<biblScope unit="volume">125</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Temporal convolutional networks for action segmentation and detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Flynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Hager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="156" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Time series is a special sequence: Forecasting with sample convolution and interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.09305</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Deep spatio-temporal residual networks for citywide crowd flows prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-first AAAI conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Revisiting spatialtemporal similarity: A deep learning framework for traffic prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI conference on artificial intelligence</title>
		<meeting>the AAAI conference on artificial intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="5668" to="5675" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A new model for learning in graph domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Monfardini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scarselli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings. 2005 IEEE international joint conference on neural networks</title>
		<meeting>2005 IEEE international joint conference on neural networks</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="729" to="734" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Spectral networks and deep locally connected networks on graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Estrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd international conference on learning representations, ICLR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Convolutional neural networks on graphs with fast localized spectral filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bresson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vandergheynst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Semi-supervised classification with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Kipf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.02907</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Inductive representation learning on large graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Leskovec</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Multilevel wavelet decomposition network for interpretable time series analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2437" to="2446" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Categorical reparameterization with gumbel-softmax</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01144</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Freeway performance measurement system: mining loop detector data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Petty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Skabardonis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Varaiya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Research Record</title>
		<imprint>
			<biblScope unit="volume">1748</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="96" to="102" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Vector autoregressive models for multivariate time series</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zivot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="385" to="429" />
		</imprint>
	</monogr>
	<note>Modeling financial time series with S-PLUS?</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Support vector regression machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Ranger21: a synergistic deep learning optimizer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Demeure</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.13731</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
