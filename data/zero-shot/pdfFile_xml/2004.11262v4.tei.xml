<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Supervised Domain Adaptation: A Graph Embedding Perspective and a Rectified Experimental Protocol</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Hedegaard</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Aarhus University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omar</forename><forename type="middle">Ali</forename><surname>Sheikh-Omar</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Aarhus University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandros</forename><surname>Iosifidis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Electrical and Computer Engineering</orgName>
								<orgName type="institution">Aarhus University</orgName>
								<address>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Supervised Domain Adaptation: A Graph Embedding Perspective and a Rectified Experimental Protocol</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T12:58+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Supervised Domain Adaptation</term>
					<term>Graph Embed- ding</term>
					<term>Transfer Learning</term>
					<term>Few-shot</term>
					<term>Domain Shift</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Domain Adaptation is the process of alleviating distribution gaps between data from different domains. In this paper, we show that Domain Adaptation methods using pairwise relationships between source and target domain data can be formulated as a Graph Embedding in which the domain labels are incorporated into the structure of the intrinsic and penalty graphs. Specifically, we analyse the loss functions of three existing state-of-the-art Supervised Domain Adaptation methods and demonstrate that they perform Graph Embedding. Moreover, we highlight some generalisation and reproducibility issues related to the experimental setup commonly used to demonstrate the few-shot learning capabilities of these methods. To assess and compare Supervised Domain Adaptation methods accurately, we propose a rectified evaluation protocol, and report updated benchmarks on the standard datasets Office31 (Amazon, DSLR, and Webcam), Digits (MNIST, USPS, SVHN, and MNIST-M) and VisDA (Synthetic, Real).</p><p>1 Rectified Office31 splits: www.github.com/lukashedegaard/office31 2 Rectified M?U splits</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>Deep neural networks have been applied successfully to a variety of applications. However, their performance tends to suffer when a trained model is applied to a data domain different from the one used in training. This is of no surprise, as statistical learning theory makes the simplifying assumption that both training and test data are generated by the same underlying process; the use of real-world datasets makes the i.i.d. assumption impractical as it requires collecting data and training a model for each domain. The collection and labelling of datasets that are sufficiently large to train a well-performing model from random initialisation may be prohibitively costly. Therefore, we often have little data for the task at hand. Training a deep network with scarce training data, in turn, can lead to overfitting <ref type="bibr" target="#b0">[1]</ref>.</p><p>The process aiming to alleviate this challenge is commonly referred to as Transfer Learning. The main idea in Transfer Learning is to leverage knowledge extracted from one or more source domains to improve the performance on problems defined in a related target domain <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4]</ref>. In the image classification task, we may want to utilise the large number of labelled training samples in the ImageNet database to improve the performance on another image classification task on a very different domain, e.g. that of fine-grained classification of aquatic macroinvertebrates <ref type="bibr" target="#b4">[5]</ref>. This is frequently done by  <ref type="figure">Fig. 1</ref>: The two-stream network architecture used in DAGE, CCSA <ref type="bibr" target="#b5">[6]</ref>, d-SNE <ref type="bibr" target="#b6">[7]</ref> and NEM <ref type="bibr" target="#b7">[8]</ref>. It allows source domain samples X S and target domain samples X T to be introduced to a deep convolutional neural network simultaneously. The network is split into a feature extractor network ? n (?) and a classifier network h(?). A domain adaptation loss L domain is defined on the output of the feature extractors to encourage the generation of domain-invariant features.</p><p>reusing the parameters of a deep learning model trained on a large source domain dataset under the assumption that the two datasets are similar. To clearly define Transfer Learning, the literature distinguishes between a domain and a task. A domain D consists of an input space X and a marginal probability distribution p(X), where X = {x 1 , . . . , x N } ? X are N samples from that space. Given a domain, a task T is composed of an output space Y and a posterior probability p(y i | x i ) for a label y i ? Y given some input x i . Suppose we have a source domain D S with an associated task T S and a target domain D T with a corresponding task T T . Transfer Learning is defined as the process of improving the target predictive function f T (x i ) ? p T (y i | x i ) using the knowledge in D S and T S when there is a difference between the domains (D S = D T ) or the tasks (T S = T T ) <ref type="bibr" target="#b1">[2]</ref>.</p><p>Two domains or two tasks are said to be different if their constituent parts are not the same. In some cases, the feature and label space of the source and target domains are equal. Then, the performance degradation associated with reusing a model in an unseen domain, is caused by a domain shift. The process of aligning the distributions between the domains is called Domain Adaptation. A special case of domain shift called covariate shift occurs when the difference between domains is caused by differences in their marginal input distributions <ref type="bibr" target="#b8">[9]</ref>, i.e. p(X S ) = p(X T ). An efficient approach to Domain Adaptation in this case, is to use a deep neural network feature-extractor ? n to transform the inputs of the respective domains into a common, domain-invariant space by means of a Siamese network architecture as seen in <ref type="figure">Fig. 1</ref>. A common classifier h can then be trained on the latent features to make predictions on target domain data.</p><p>To align the domains with this approach, it is not strictly necessary to have labels available in the target dataset, and many Unsupervised Domain Adaptation methods can achieve good performance given enough (unlabelled) target data. In cases where the data is difficult to acquire, such as for medical images of a rare disease, Supervised Domain Adaptation methods are superior, and can utilise the few available target samples to efficiently align the domains. However, as we will show, having very few target data samples complicates the experiment design if best practices for train, validation, and test split independence are to be upheld. This few-shot supervised case is the focus of this work.</p><p>A typical optimisation goal in Supervised Domain Adaptation methods is to explicitly map samples belonging to the same class close together in a common latent subspace, while separating samples with different labels irrespective of the originating domain. In <ref type="bibr" target="#b9">[10]</ref> it was shown that Graph Embedding <ref type="bibr" target="#b10">[11]</ref>, which aims at increasing the within-class compactness and between-class separability by appropriately connecting samples in intrinsic and penalty graph structures, provides a natural framework for Supervised Domain Adaptation, and produces results on par with the state-of-the-art. In this extension of <ref type="bibr" target="#b9">[10]</ref>, the following contributions are presented:</p><p>1) We show that many existing Supervised Domain Adaptation methods aiming to produce a domain-invariant space by means of pairwise similarities can be expressed as Graph Embedding methods. Specifically, we analyse the loss functions of three recent state-of-the-art Supervised Domain Adaptation methods: Classification and Contrastive Semantic Alignment (CCSA) <ref type="bibr" target="#b5">[6]</ref>, Domain Adaptation using Stochastic Neighborhood Embedding (d-SNE) <ref type="bibr" target="#b6">[7]</ref>, and Domain Adaptation with Neural Embedding Matching (NEM) <ref type="bibr" target="#b7">[8]</ref>. 2) We argue that Graph Embedding and the specification of edges in the intrinsic and penalty graphs provides an expressive framework for encoding and exploiting assumptions about the datasets at hand. 3) We identify flaws in the traditionally employed experiment protocol for Few-shot Supervised Domain Adaptation that violate machine learning best practices with regards to independence of train, validation and test splits. 4) We propose a rectified experimental protocol, which clearly defines a validation set and ensures that the test set remains independent throughout experiments. 5) We publish ready-to-use Python packages for the two most commonly used Few-shot Supervised Domain  <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16]</ref>, and VisDA-C <ref type="bibr" target="#b16">[17]</ref> dataset collections using the rectified experimental protocol. The source code of our experiments is available online <ref type="bibr" target="#b3">4</ref> . The remainder of the paper is structured as follows: In Section II, we provide a brief overview of Domain Adaptation methods that aim to find a domain-invariant latent space. We introduce Graph Embedding, how to optimise the graph preserving criterion, and multi-view extensions in Section III. Section IV delineates the Domain Adaptation via Graph Embedding (DAGE) framework and the DAGE-LDA method as proposed in <ref type="bibr" target="#b9">[10]</ref>. In Section V, we analyse three recent stateof-the-art methods and show that they can also be viewed as Graph Embedding methods. In Section VI, we explain the issues with the existing experimental setup used in prior Domain Adaptation work and propose a rectified experimental protocol. Finally, in Section VII we present updated benchmark results on the canonical datasets Office-31, Digits and VisDA-C using the rectified protocol, and Section VIII draws the conclusions of the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head><p>In Domain Adaptation (DA), it is usually assumed that all source data is labelled. Depending on the label availability for the target data, DA methods are categorised as Supervised, Semi-supervised, and Unsupervised. It is important to distinguish between these cases, as experiment protocols and the volume of data used for training varies widely between the three cases, even using the same datasets.</p><p>Supervised Domain Adaptation methods focus on few-shot learning scenarios, where the labelled target data is scarce with very few samples per class. Classification and Contrastive Semantic Alignment (CCSA) <ref type="bibr" target="#b5">[6]</ref> is one such method, which embeds the contrastive loss introduced by Hadsell et al. <ref type="bibr" target="#b17">[18]</ref> as a loss term in a two-stream deep neural network. Effectively, it places a penalty on the distance between samples with the the same class across source and target domains, as well as the proximity of samples that belong to different classes and fall within a distance margin. Domain Adaptation using Stochastic Neighborhood Embedding (d-SNE) <ref type="bibr" target="#b6">[7]</ref> uses the same deep two-stream architecture, and finds its inspiration in the dimensionality reduction method of Stochastic Neighbor Embedding (SNE). From it, a modified-Hausdorffian distance is derived, which minimises the Euclidean distance in the embedding space between the furthest same-class data pairs, and maximises the distance of the closest different-label pairs. Domain Adaptation With Neural Embedding Matching (NEM) <ref type="bibr" target="#b7">[8]</ref> extends the contrastive loss of CCSA with an additional loss term to match the local neighbourhood relations of the target data prior to and after feature embedding. It does so with a graph embedding loss which connects the nearest neighbours of the target data in their original feature space and adds the weighted sum of distances between corresponding embedded features to the constrastive loss. In <ref type="bibr" target="#b18">[19]</ref>, an addon domain classification layer is tasked with classifying the domain of training samples to produce a domain confusion loss that is used in feature extraction layers. Moreover, they take inspiration in distillation works, and use a soft label loss that matches a target sample to the average output distribution for the corresponding label in the source domain. Few-shot Adversarial Domain Adaptation (FADA) <ref type="bibr" target="#b19">[20]</ref> uses a similar approach by training a domain-class discriminator with a four-way classification procedure for combinations of sameor different domain or class. In <ref type="bibr" target="#b20">[21]</ref>, an alignment loss for Second-or Higher-Order Scatter Tensors (So-HoT) is used to bring each within-class scatter closer in terms of their means and covariances. They do this by taking the squared norm of the difference between scatter tensors for each class.</p><p>Semi-supervised Domain Adaptation methods also have very few labelled target samples, but use unlabelled data in addition. Examples of this are d-SNE and NEM, both of which provide extensions to include unlabelled data. In d-SNE <ref type="bibr" target="#b6">[7]</ref>, the semi-supervised extension is achieved by a mechanism similar to the Mean-Teacher network technique <ref type="bibr" target="#b21">[22]</ref>, which entails the training of a parallel network on the unsupervised data and the use of an L2 consistency loss between the embeddings for the two networks. In NEM <ref type="bibr" target="#b7">[8]</ref>, a progressive learning strategy is employed, which gradually assigns pseudo labels to the most confident predictions on unlabelled data in each epoch. The pseudo-labelled data is then used for training in the next epoch. In graph-embedding based methods, such as DAGE-LDA <ref type="bibr" target="#b9">[10]</ref>, it is straight forward to incorporate unlabelled data into the loss by means of Label Propagation <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24]</ref>. Moreover, some unsupervised methods (e.g. <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b25">26]</ref>) include semi-supervised extensions as well.</p><p>Unsupervised Domain Adaptation methods do not assume that any labels are available in the target domain, and use only the label information from the source domain. In Transfer Component Analysis (TCA) <ref type="bibr" target="#b26">[27]</ref>, domain are aligned by projecting data onto a set of learned transfer components. To learn the components, they minimise the Maximum Mean Discrepancy (MMD) in a Reproducing Kernel Hilbert Space (RKHS). In practice, the kernel trick is used to define a kernel matrix, and a projection matrix is learned from the corresponding empirical kernel map. Scatter Component Analysis (SCA) <ref type="bibr" target="#b27">[28]</ref> also operates in a RKHS, but uses the notion of scatter (which recovers MMD) to align the domains. A projection matrix is then found by maximisation of the totaland between-class scatters, and minimisation of the domainand within-class scatters. Here, between-and within-class scatters are defined only from source domain data. A recent addition to this space is the Graph Embedding Framework for Maximum Mean Discrepancy-Based Domain Adaptation Algorithm (GEF) <ref type="bibr" target="#b28">[29]</ref>, which assigns pseudo-labels to target data and solves the generalised eigenvalue problem for a MMD-based graph to compute a linear projection of the source data. The reconstructed source data is then used to train a classifier which in turn updates the psuedo-labels of the target data. In Locality Preserving Joint Transfer for Domain Adaptation (LPJT) <ref type="bibr" target="#b24">[25]</ref>, they use a multi-faceted approach of distribution matching to minimise the marginal-and conditional MMD: Landmark selection to learn importance weights for each source and target sample; label propagation, assigning pseudo labels to unlabelled samples; and locality preservation by use of Graph Embedding, solved as the generalised eigenvalue problem. Joint Distribution Invariant Projections (JDIP) <ref type="bibr" target="#b25">[26]</ref> use a least-squares estimation of the L2 distance for the joint distribution of source and target domains to produce mappings to a domain-invariant subspace with either linear or kernelized projections. Another branch of Unsupervised DA techniques use Adversarial methods to confuse the domains: In Domain-Adversarial Neural Networks (DANN) <ref type="bibr" target="#b15">[16]</ref>, a deep neural network is extended with an additional Discriminator head, that is trained to distinguish the source and target domains. This is similar to what was done in <ref type="bibr" target="#b18">[19]</ref> for Supervised Domain Adaptation. Conditional Domain Adversarial Networks (CDAN) <ref type="bibr" target="#b29">[30]</ref> take inspiration in the recent advances of Conditional Generative Adversarial Networks, and use multilinear-and entropy conditioning to improve discriminability and transferability between domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. GRAPH EMBEDDING AND ITS OPTIMIZATION PROBLEM</head><p>Graph Embedding <ref type="bibr" target="#b10">[11]</ref> is a general dimensionality reduction framework based on the exploitation of graph structures. Suppose we have a data matrix X = [x 1 , ? ? ? , x N ] ? R D?N and want to obtain its one-dimensional representation z = [z 1 , ? ? ? , z N ] ? R d?N where d = 1. To encode the data relationships, which should be preserved in the subspace, we can construct a so-called intrinsic graph G = (X, W), where columns of the matrix X represent vertices and elements in W express the pair-wise relationships between these vertices. The element W (i,j) describes a non-negative edge weight between vertices x i and x j . When we want to suppress relationships between some graph vertices in the embedding space, we can create a corresponding penalty graph G p = (X, W p ). The optimal one-dimensional embeddings z * are found by optimising the graph preserving criterion <ref type="bibr" target="#b10">[11]</ref>:</p><formula xml:id="formula_0">z * = argmin z Bz=c i =j z i ? z j 2 2 W (i,j) = argmin z Bz=c z Lz (1)</formula><p>where c is a constant, L = D?W and B = D p ?W p are N ? N graph Laplacian matrices of G and G p , respectively, and D = j W (i,j) and D p = j W (i,j) p are the corresponding (diagonal) Degree matrices. Using a linear embedding, z i = v x i , the above criterion takes the form:</p><formula xml:id="formula_1">z * = argmin v XBX v=c v XLX v.<label>(2)</label></formula><p>which is equivalent to maximizing the trace ratio problem <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b31">32]</ref>:</p><formula xml:id="formula_2">J (v) = v XBX v v XLX v .<label>(3)</label></formula><p>Following Lagrange-based optimisation, the optimal projection v ? R D is found by solving the generalized eigenanalysis problem XBX v = ?XLX v and is given by the eigenvector corresponding to the maximal eigenvalue. When 1 &lt; d ? D, the trace ratio problem in Eq. (3) becomes:</p><formula xml:id="formula_3">J (V) = Tr V XBX V Tr V XLX V .<label>(4)</label></formula><p>where Tr(?) is the trace operator and V ? R D?d is a projection matrix. The trace ratio problem in Eq. (4) does not have a closed-form solution. Therefore, it is conventionally approximated by solving the ratio trace problem,</p><formula xml:id="formula_4">J (V) = Tr[(V XLX V) ?1 (V XBX V)].</formula><p>The ratio trace problem can be reformulated as the generalised eigenvalue problem via a Lagrangian formulation, so the problem is reduced to finding the vector v that satisfies XBX v = ?XLX v for ? = 0. The columns of V are given by the eigenvectors of the matrix (XLX ) ?1 (XBX ) corresponding to the d maximal eigenvalues. The trace ratio problem in Eq.</p><p>(3) can also be converted to an equivalent trace difference problem <ref type="bibr" target="#b30">[31]</ref>:</p><formula xml:id="formula_5">J (V, ?) = Tr V (XBX ? ?XLX )V ,<label>(5)</label></formula><p>where ? is the trace ratio calculated by applying an iterative process as described in <ref type="bibr" target="#b30">[31]</ref> and <ref type="bibr" target="#b32">[33]</ref>. After obtaining the trace ratio value ? * , the optimal projection matrix V * is obtained by substitution of ? * into the trace difference problem in Eq. (5) and maximisation of its value. Non-linear mappings from x i ? R D to z i ? R d can be obtained by exploiting the Representer Theorem, i.e. by use of an implicit nonlinear mapping ? :</p><formula xml:id="formula_6">R D ? F, with F a reproducing kernel space, leading to x i ? R D ? ?(x i ) ? F.</formula><p>We can express the mapping in the form of</p><formula xml:id="formula_7">z i = ? ? ?(x i ) where ? = [?(x 1 ), . . . , ?(x N )]</formula><p>are the training data representations in F and the projection matrix is given by V = ?A. In that case, the problems in Eqs. (4) and (5) are transformed by substituting X with K = ? ?, which is the kernel matrix calculated using the kernel function ?(x i , x j ) = K (i,j) .</p><p>Extensions which use intrinsic and penalty graphs to jointly determine transformations for data from multiple input spaces (views) have also been proposed. As was shown in <ref type="bibr" target="#b33">[34]</ref>, several such methods (called multi-view methods), including Multi-View Fisher Discriminant Analysis <ref type="bibr" target="#b34">[35]</ref>, Partial Least Squares <ref type="bibr" target="#b35">[36]</ref>, (deep) Canonical Correlation Analysis <ref type="bibr" target="#b36">[37]</ref>, and Multi-view Discriminant Analysis <ref type="bibr" target="#b37">[38]</ref> can be expressed as specific instantiations of the problem in Eq. (4), which exploit the view label information to define corresponding intrinsic and penalty graphs. Moreover, the Multi-view Nonparametric Discriminant Analysis <ref type="bibr" target="#b38">[39]</ref> and Deep Multi-view Learning to Rank <ref type="bibr" target="#b39">[40]</ref> methods have been formulated based on the problem in Eq. (4) for retrieval and ranking problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. DOMAIN ADAPTATION VIA GRAPH EMBEDDING</head><p>Given the versatility of graph embedding, we derive the framework for Domain Adaptation via Graph Embedding (DAGE) in this section, and detail a simple yet effective instantiation inspired by Linear Discriminant Analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. DAGE Framework</head><p>The aim of transformation-based Domain Adaptation methods is to learn a common subspace where the distribution gap between source domain data and target domain data is as small as possible. In the supervised setting, we want a transformation ?(?), which places samples of the same class close together without regard to the originating domain to achieve within-class compactness. On the other hand, we want ?(?) to clearly separate samples with different labels irrespective of the domain to gain between-class separability.</p><p>Let X S ? R D?N S and X T ? R D?N T be two data matrices from the source and target domains, respectively, and let N = N S +N T . Suppose we have a transformation ?(?) which can produce d-dimensional vectors from D-dimensional data. Then we can construct a matrix ? = [?(X S ), ?(X T )] ? R d?N containing the transformed data from both domains. By encoding the desired pair-wise data relationships in an intrinsic graph G = (X, W) and computing its graph Laplacian matrix L, we can formulate a measure of within-class spread as</p><formula xml:id="formula_8">N i=1 N j=1 ? (i) ? ? (j) 2 2 W (i,j) = Tr ?L? .<label>(6)</label></formula><p>Similarly, we can create a penalty graph G p = (X, W p ) and express the between-class separability using</p><formula xml:id="formula_9">N i=1 N j=1 ? (i) ? ? (j) 2 2 W (i,j) p = Tr ?B? .<label>(7)</label></formula><p>Since the goal is to minimise the within-class spread (Eq. (6)) and maximise the between-class separability (Eq. <ref type="formula" target="#formula_9">(7)</ref>), we can utilise the trace ratio objective function to perform Domain Adaptation via Graph Embedding:</p><formula xml:id="formula_10">? * = argmin ? Tr ?L? Tr ?B? (8)</formula><p>Note that the graph Laplacian matrices of the intrinsic and the penalty graphs are placed respectively in the numerator and denominator of the trace ratio problem, since Eq. (8) corresponds to a minimization problem. Note also that the criterion in Eq. (8) can be seen as the multidimensional generalisation of Eq. (1) in which an arbitrary function ?(?) is used in place of a linear projection v.</p><p>When the transformation is a linear projection V, i.e. ?(X) = V X, the DAGE criterion becomes:</p><formula xml:id="formula_11">V * = argmin V Tr V XLX V Tr V XBX V (9) where X = [X S , X T ].</formula><p>The optimal transformation matrix V * is obtained by solving the ratio trace problem. Its solution is formed by the eigenvectors corresponding to the d largest eigenvalues of the generalised eigenvalue problem XBX v * = ?XLX v * , or by minimising the trace difference problem as described in Section III:</p><formula xml:id="formula_12">J (V, ?) = Tr V (XLX ? ?XBX )V<label>(10)</label></formula><p>The linear DAGE criterion in Eq. (9) can also be formulated using the kernel trick for non-linear mappings. Suppose ? : R D ? F is a nonlinear function mapping the input data into a reproducing kernel Hilbert space F. Let the matrix ? = [?(x 1 ), ? ? ? , ?(x N )] be composed of data in F. Based on the Representer Theorem, we let V = ?A and get</p><formula xml:id="formula_13">A * = argmin A Tr A KLKA Tr A KBKA ,<label>(11)</label></formula><p>where K = ? ? has elements equal to</p><formula xml:id="formula_14">K (i,j) = ?(x i ) ?(x j ).</formula><p>The solution of Eq. (11) can be found via generalised eigenvalue decomposition or by applying an iterative process similar to the linear case. Eigenvalue decomposition for nonlinear DAGE is intractable for large datasets as the computational complexity is in the order of O(N 3 ) <ref type="bibr" target="#b40">[41]</ref>. An alternative solution is to express the DAGE criterion as part of the loss function in a deep neural network. For Supervised Domain Adaptation problems in the visual domain, the first layers of a neural network architecture can be seen as a non-linear parametric function ? n (?) taking as input the raw image data and giving vector representations as output. This allows the DAGE objective to be optimised with gradient descent-based approaches. Moreover, the DAGE loss can be optimised together with a classification loss (e.g. cross-entropy) in an end-to-end manner. Given a mini-batch b of data, the DAGE loss can be computed:</p><formula xml:id="formula_15">L DAGE = Tr ? b L b ? b Tr ? b B b ? b ,<label>(12)</label></formula><p>where</p><formula xml:id="formula_16">? b = ? n X (b) S , ? n X (b) T</formula><p>is a matrix formed by the transformed features in the mini-batch b and the graph Laplacian matrices L b and B b are computed on the data forming the mini-batch. Optimisation using batches is also applied commonly in dimensionality reduction methods when the full data does not fit in memory <ref type="bibr" target="#b41">[42,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44]</ref>. The gradient for a mini-batch is:</p><formula xml:id="formula_17">? ? b L DAGE = Tr ? b L b + ? b L b Tr ? b B b ? b ? Tr ? b L b ? b ? b B b + ? b B b Tr ? b B b ? b 2<label>(13)</label></formula><p>The resulting loss to be optimised is the sum of the DAGE loss and classification losses for source and target domain data:</p><formula xml:id="formula_18">argmin ??,? h ? L DAGE + (1 ? ?) ? L S CE + (1 ? ?)L T CE<label>(14)</label></formula><p>where ? ? and ? h denote the parameters of the parametric functions ? n (?) for feature extraction and h(?) for classification, respectively. ?, ? ? [0, 1] are mixing coefficients for the ratio of domain adaptation to cross entropy losses and ratio of source and target cross entropy losses. for each mini-batch b in training set do 5:  <ref type="formula">8)</ref> is a generic criterion which can lead to a multitude of Domain Adaptation solutions. Constructing the two graphs G and G p in different ways gives rise to different properties to be optimised in the subspace R d . A simple instantiation of DAGE inspired by Linear Discriminant Analysis is obtained by using an intrinsic graph structure that connects samples of the same class:</p><formula xml:id="formula_19">? b ? [? n (X (b) S ), ? n (X (b) T )] 6: Create L b ,</formula><formula xml:id="formula_20">W (i,j) = 1, if i = j 0, otherwise<label>(15)</label></formula><p>where i and j are the labels associated with the i-th and j-th samples, respectively. The corresponding penalty graph structure connects samples of different classes:</p><formula xml:id="formula_21">W (i,j) p = 1, if i = j 0, otherwise<label>(16)</label></formula><p>Despite the simplicity of the above-described DAGE instantiation, the method produces state-of-the-art results as will be shown in Section VII.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. STATE OF THE ART SUPERVISED DOMAIN ADAPTATION METHODS PERFORM GRAPH EMBEDDING</head><p>In Section IV, we analysed the domain-invariant space approach to Supervised Domain Adaptation, and showed that it can be naturally described as multi-view Graph Embedding. In fact, any domain adaptation method, which uses pairs of samples to produce a domain-invariant latent space, can be cast as a multi-view Graph Embedding method. To illustrate this point, we analyse three recent state-of-the-art methods and show that they are instances of Domain Adaptation via Graph Embedding with different choices of W and W p . A similar relationship can be shown for several other Domain Adaptation methods such as <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b44">45]</ref>. In the subsequent subsections, we focus on the Domain Adaptation terms included in the optimisation function of each method, while we omit the corresponding cross-entropy terms of each method for simplicity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Classification and Contrastive Semantic Alignment</head><p>The contrastive semantic alignment loss of CCSA <ref type="bibr" target="#b5">[6]</ref> is constructed from two terms: A similarity loss L S , which penalises the distance between within-class samples of different domains, and a dissimilarity loss L D , which penalises the proximity of between-class samples if they come within a distance margin , i.e.:</p><formula xml:id="formula_22">L CSA = L S + L D .<label>(17)</label></formula><p>Using as notational shorthand d ij = ? n (x i ) ? ? n (x j ) 2 , the partial losses are defined as follows:</p><formula xml:id="formula_23">L S = xi?D S xj ?D T i= j 1 2 d 2 ij<label>(18)</label></formula><formula xml:id="formula_24">L D = xi?D S xj ?D T i = j 1 2 max {0, ? d ij } 2 .<label>(19)</label></formula><p>The similarity loss can be expressed equivalently in terms of the weighted summation over graph edges:</p><formula xml:id="formula_25">L S = xi?D S xj ?D T ? n (x i ) ? ? n (x j ) 2 2 W (i,j) = Tr(?L? )<label>(20)</label></formula><p>where the graph weight matrix W has an edge for samplepairs with the same label but different originating domains</p><formula xml:id="formula_26">W (i,j) = 1 2 , if i = j and D i = D j 0, otherwise,<label>(21)</label></formula><p>and L is the graph Laplacian matrix associated with W. Using the fact that max{f (x)} = ? min{?f (x)}, the dissimilarity loss can likewise be expressed in terms of a summation over graph edges:</p><formula xml:id="formula_27">L D = ? xi?D S xj ?D T i = j dij &lt; 1 2 (d ij ? ) 2 = ? xi?D S xj ?D T i = j dij &lt; d 2 ij 1 2 1 + 2 d 2 ij ? 2 d ij = ? xi?D S xj ?D T ? n (x i ) ? ? n (x j ) 2 2 W (i,j) p = ?Tr(?B? )<label>(22)</label></formula><p>where</p><formula xml:id="formula_28">W (i,j) p = ? ? ? ? ? 1 2 + 2 2d 2 ij ? dij , if d ij &lt; and i = j and D i = D j 0, otherwise<label>(23)</label></formula><p>and B is the graph Laplacian matrix associated with the corresponding weight matrix W p . Note that the weight matrix of Eq. (23) constitutes an -distance margin rule for graph embedding. The partial similarity and dissimilarity losses can thus be expressed with graph Laplacian matrices which encode the within-class and between-class relations. Combining Eqs. <ref type="bibr" target="#b19">(20)</ref> and <ref type="formula" target="#formula_1">(22)</ref>, we see that the contrastive semantic alignment loss of CCSA is equivalent to:</p><formula xml:id="formula_29">L CSA = Tr ?L? ? ??B?<label>(24)</label></formula><p>which constitutes the trace difference problem in Eq. (10) from Graph Embedding. While CCSA employs a value of ? = 1, one can also determine an optimised value for ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Domain Adaptation using Stochastic Neighborhood Embedding</head><p>Following the procedure outlined above, it is straightforward to show that d-SNE <ref type="bibr" target="#b6">[7]</ref> can also be viewed as a graph embedding. For each target sample, the domain adaptation loss term of d-SNE penalises the furthest distance to a within-class source sample, and encourages the distance for the closest between-class to source sample to be maximised:</p><formula xml:id="formula_30">L d-SNE = xj ?D T max xi?D S i= j a|a ? d 2 ij ? min xi?D S i = j b|b ? d 2 ij<label>(25)</label></formula><p>We can readily express this using the trace difference formulation:</p><formula xml:id="formula_31">L d-SNE = Tr ?L? ? ??B?<label>(26)</label></formula><p>with ? = 1 and Graph Laplacian matrices L and B corresponding to the weight matrices:</p><formula xml:id="formula_32">W (i,j) = ? ? ? ? ? 1, if d ij = max x k ?D S {a | a ? d kj } and j = i = k and D i = D j 0, otherwise,<label>(27)</label></formula><formula xml:id="formula_33">W (i,j) p = ? ? ? ? ? 1, if d ij = min x k ?D S {b | b ? d kj }</formula><p>and j = i = k and D i = D j 0, otherwise.</p><p>Because only a single edge is specified for each source sample per graph Laplacian, it is worth noting that the resulting graph connectivity for d-SNE is highly dependent on the batch size used during optimisation. Small batch sizes will result in more densely connected graphs than large batch sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Neural Embedding Matching</head><p>NEM <ref type="bibr" target="#b7">[8]</ref> extends the contrastive loss of CCSA with an additional term designed to maintain the neighbour relationship of target data throughout the feature embedding:</p><formula xml:id="formula_35">L NEM = L CSA + ?L neighbour<label>(29)</label></formula><p>Here, the hyperparameter ? weights the importance of the neighbour matching loss, which is specified as the loss over a neighbourhood graph with edges between each target sample i and its k nearest neighbours N (i) in the original feature space:</p><formula xml:id="formula_36">L neighbour = xi?D T xj ?N (i) ? n (x i ) ? ? n (x j ) 2 ? RBF (x i , x j ),<label>(30)</label></formula><formula xml:id="formula_37">where ? RBF (x, x ) = exp (? x ? x 2 2 /2? 2 )</formula><p>is the Radial Basis Function kernel used to assign a weight to the edge between any pair of vertices. To express the NEM loss in terms of a graph embedding, the neighbour term can be incorporated into the similarity weight matrix by extending the encoding rule from Eq. <ref type="formula" target="#formula_1">(21)</ref>:</p><formula xml:id="formula_38">W (i,j) = ? ? ? ? ? ? ?RBF(xi,xj ) dij , if j ? N (i) and D i = D j = D T 1 2 , if i = j and D i = D l 0, otherwise,<label>(31)</label></formula><p>The penalty weight matrix for NEM is the same as for CCSA in Eq. (23) and the final graph embedding problem is a trace difference problem as in Eqs. <ref type="bibr" target="#b23">(24)</ref> and <ref type="bibr" target="#b25">(26)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Discussion</head><p>While some methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref> explicitly formulate the process of Domain Adaptation as Graph Embedding, we have shown that many others <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, which employ pairwise (dis)similarities between data, can also be formulated as such. It would be trivial to perform the same analysis on other methods (e.g <ref type="bibr" target="#b20">[21]</ref>).</p><p>Of course, not all Domain Adaptation methods fit nicely into the structure of Graph Embedding. The use of an adversarial network branch <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b29">30]</ref> is not straight-forward to integrate into the intrinsic and penalty matrices of a Graph Embedding. Moreover, progressive learning strategies and the use of pseudo-labels in semi-and unsupervised methods <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b28">29]</ref> relates more to the training loop than the loss-formulation. Nonetheless, Graph Embedding captures many existing powerful Domain Adaptation methods, and gives us a common lens through which to see them: In CCSA, all same-class sample pairs are given a similar attraction, while different-class pairs are only repelled if they come within a distance margin; in NEM, target domain samples are additionally encouraged to remain close if they were similar in their input-space; in d-SNE, for each sample only the furthest same-class sample is attracted, while the closest sample of different label is repelled; in DAGE-LDA, we simply attract same-class pairs and repel different-class pairs without further assumptions.</p><p>An ongoing challenge in Machine Learning and Domain Adaptation is how to clearly encode our prior knowledge and assumptions into the learning problem for a specific application <ref type="bibr" target="#b8">[9]</ref>. We would argue that the construction rules for the graph Laplacian matrices of Graph Embedding may be an ideal way to specify this in a simple if-then-else manner. Say, we want to encode an assumption that some classes (e.g. bike and bookcase) have large within-class differences, while others to not. In the intrinsic matrix, we might then state a rule, that the bike and bookcase classes should only attract the most similar same-class sample and ignore the others, while all samples should be attracted equally for the other classes. The is a plethora of options for constructing the graphs using margins, nearest-neighbour rules, etc. We leave thier exploration to future work. be split. In this section, we describe the experimental setup that is normally used to evaluate and compare supervised Domain Adaptation methods. We showcase issues related to non-exclusive use of data in model selection and testing phases and we describe how the evaluation process can be improved by proposing a new experimental setup.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. RECTIFIED EXPERIMENTAL PROTOCOL</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Traditional Experiment Setup</head><p>The experiment setup used to evaluate the performance of Domain Adaptation methods, e.g. <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>, is as follows: A number of samples of each class are drawn from the source domain, and a few samples per class are drawn from the target domain to be used for training. For instance, in experiments on the Office31 dataset <ref type="bibr" target="#b11">[12]</ref> with the Amazon data as source domain and the Webcam data as target domain, the number of samples per class forming the training set is equal to twenty and three, respectively. The remaining target data is used for testing. The sampled data from both source and target domains are paired up as the Cartesian product of the two sets, producing as the resulting dataset all combinations of two samples from either domain. To limit the size and redundancy, the dataset is filtered to have a predefined ratio of same-class samples (where both samples in a pair have the same label) to different-class samples. This ratio is commonly set equal to 1:3. An illustration of this is found in <ref type="figure">Fig. 2</ref>.</p><p>This combined dataset is then used to train a model with a Domain Adaptation technique, e.g. using the two stream architecture as illustrated in <ref type="figure">Fig. 1</ref>    conducted on the test set from the target domain. Because very few unique samples from the target domain are used for training in each experiment, the results will usually vary significantly between runs and will depend on the random seed used for creating the training and test splits. Therefore, each experiment is repeated multiple times, each time with a new seed value, and the mean accuracy alongside the standard deviation over the runs are reported. The absence of validation data on each experiment has the risk of performing model selection (including hyper-parameter search) based on the performance on the test data. One could try to avoid the problem by performing model selection and hyper-parameter search using training/test splits from seed values which are not used for the final training/test splits. This, however, is not enough to guarantee that the test performance generalises to unseen data, since it is probable that test data is used for model selection and hyper-parameter search, as illustrated in <ref type="figure">Fig. 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Rectified Experiment Setup</head><p>To avoid the above described issues of the experiment setup used in evaluating the performance of Domain Adaptation methods, we need to conduct our sampling in two steps: First, we need to define the data in the target domain that will be used for evaluating the performance of the Domain Adaptation method in all the runs. The remaining data in the target domain will be used to form the training and validation sets in the target domain in different runs. This can be done exactly as described in Section VI-A: We draw few samples from the source domain and the training set of the target domain, and combine them using the Cartesian Product with an optional ratio for filtering. In this way, we ensure that independent test data is used for method evaluation, and a validation set is available for model selection and hyper-parameter search. This data splitting procedure is illustrated in <ref type="figure" target="#fig_4">Fig. 4a</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VII. EXPERIMENTS AND RESULTS</head><p>In this section, we conduct experiments on the Office31, Digits (MNIST, USPS, SVHN, MNIST-M), and VisDA datasets using the rectified experimental setup and compare the results to those from the traditional experimental setup. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Datasets</head><p>The Office31 dataset <ref type="bibr" target="#b11">[12]</ref> contains images of 31 object classes found in the modern office. It has three visual domains: Amazon (A) consists of 2.817 images found on the e-commerce site www.amazon.com. These images are generally characterised by their white background and studiolighting conditions. DSLR (D) contains 498 high resolution images taken using a digital single-lens reflex camera. Webcam (W) has 795 images captured using a web-camera. The objects photographed are the same as for DSLR, but the images in this case are low-resolution and suffer from visual artefacts such as colour imbalances and optical distortion. A TABLE I: Macro average classification accuracy (%) on the supervised adaptation setting of Office-31. Top rows: Results using the traditional experiment setup. Bottom rows: Results when using the rectified experiment setup. Unless stated otherwise, the convolutional layers of a VGG-16 pretrained on imagenet network were used for feature-extraction. The results are reported as the mean and standard deviation across five runs.  sample of the Office31 images is shown in <ref type="figure" target="#fig_5">Fig. 5</ref>.</p><formula xml:id="formula_39">A ? D A ? W D ? A D ? W W ? A W ? D Avg.</formula><p>The digits datasets contain handwritten digits from 0 to 9 and comprise MNIST <ref type="bibr" target="#b12">[13]</ref>, USPS <ref type="bibr" target="#b13">[14]</ref>, SVHN <ref type="bibr" target="#b14">[15]</ref>, and MNIST-M <ref type="bibr" target="#b15">[16]</ref>. MNIST consists of 70,000 grayscale images with a 28 ? 28 resolution, USPS has 11,000 16 ? 16 grayscale images, SVHN has 99,280 RGB images of house numbers, and MNIST-M is a dataset generated by superimposing RGB backgrounds on MNIST.</p><p>VisDA-2017 <ref type="bibr" target="#b16">[17]</ref> is a large-scale Domain Adaptation dataset comprising three domains with 12 common object cateogies. The domains comprise a training (source) domain of synthetic 3D object renderings, as well as validation and test domains (targets) with real images from the MS COCO <ref type="bibr" target="#b45">[46]</ref> and YouTube-BoundingBoxes <ref type="bibr" target="#b46">[47]</ref> datasets respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Office31</head><p>In our experiments on the Office31 dataset, we used a model consisting of the convolutional layers of a VGG-16 <ref type="bibr" target="#b47">[48]</ref> network pretrained on ImageNet <ref type="bibr" target="#b48">[49]</ref> with randomly initialised dense layers of 1024 and 128 neurons, respectively, as done in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. This network is subsequently fine-tuned on all source data (FT-Source). We found a gradual-unfreeze procedure <ref type="bibr" target="#b50">[50]</ref>, where four pretrained layers are unfrozen each time the model converges, to work well. To produce a baseline method (FT-Target), the FT-Source model is further fine-tuned on the target data.</p><p>We follow the experimental procedure described in Section VI-B. After first splitting off 30% of the target data to form the test set, we create the training set using twenty source samples per class for the Amazon domain, and eight source samples per class for DSLR and Webcam. From the target domain, three samples per class are drawn in each case. The remaining target data is used as a validation set. Thus, we employ the same number of samples for training as in the traditional split <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b18">19]</ref>, but ensure an independent test split as well as a well-defined validation split. The model is duplicated across two streams with shared weights as depicted in <ref type="figure">Fig. 1</ref> and trained on the combined training data, with one domain entering each stream. This experiment is performed for all six combinations of source and target domain in {A, D, W}, and each combination is run five times using different seeds. We re-implemented CCSA and d-SNE using their publicly available source code and included them in our experiments. Prior to executing the five runs, an independent hyper-parameter search on the space summarised in <ref type="table" target="#tab_4">Table III</ref> was conducted for each method using Bayesian Optimisation with the Expected Improvement acquisition function <ref type="bibr" target="#b51">[51]</ref> given 100 trials. For the final tests, we used data augmentation with random modifications of colour hue and saturation, image brightness and contrast, as well as rotation and zoom. For a fair comparison, all hyper-parameter tuning and tests are performed with the exact same computational budget and data available for all methods tested.</p><p>The best performing hyper-parameter values are used to  train the model following a standard procedure. The training procedure for DAGE-LDA is described in Algorithm 1. Once a model is trained, we use the test data to generate predictions and report the macro average classification accuracy.</p><p>The results for Office31 are shown in <ref type="table" target="#tab_4">Table I and Table II</ref>. Comparing the CCSA and d-SNE results of the traditional experimental setup with the rectified one, we see that the achieved macro accuracy is generally lower: ?1.2% on average for CCSA, d-SNE and DAGE-LDA. This is in-line with our expectations, and confirms that the traditional setup may have suffered from generalisation issues as described in Section VI-A. Comparing CCSA, d-SNE, and DAGE-LDA in the rectified experimental setup, we see that DAGE-LDA has the highest average score across all six adaptations, though it only outperforms the other methods on a single adaptation (W ? A). CCSA performs next best, and d-SNE comes last of the three. This suggests, that the higher accuracy reported in <ref type="bibr" target="#b6">[7]</ref> as compared to <ref type="bibr" target="#b5">[6]</ref> may be due to better hyper-parameter optimisation rather than a better Domain Adaptation loss.</p><p>As an additional experiment, we repeat the adaptation task for DAGE-LDA using the ResNet-50 <ref type="bibr" target="#b52">[52]</ref> to gauge the effect of using an improved feature-extractor. Comparing the VGG-16 results with those for ResNet-50, we observe an average improvement of 4.0%. This matches the relative difference in top-1 accuracy on ImageNet (75.6% for VGG16 and 79.3% for ResNet-50 <ref type="bibr" target="#b52">[52]</ref>), and highlights the importance of disclosing which feature-extractor is used in derived methods <ref type="bibr" target="#b53">[53]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Digits</head><p>For our experiments on the digits datasets MNIST, USPS, SVHN, and MNIST-M, we use a network architecture which has two streams with shared weights, with two convolutional layers containing 6 and 16 5 ? 5 filters respectively, maxpooling, and two dense layers of size 120 and 84 prior to the classification layer. This architecture is the same as the one used in <ref type="bibr" target="#b5">[6]</ref>. The test-train splits were predifined from TorchVision Datasets <ref type="bibr" target="#b54">[54]</ref> and TensorFlow Datasets <ref type="bibr" target="#b55">[55]</ref>, and validation data was sampled from the train split of the target dataset. Though our implementation uses Tensorflow, the datasets were made compatible using the Dataset Ops library. Aside from following the rectified sampling, the experiments use the procedures from <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b56">56]</ref>. For augmentations, zoom, brightness and contrast perturbations, as well as colour saturation and hue augmentations were applied when relevant.</p><p>The first set of experiments on the digits datasets are the transfers between MNIST and USPS, MNIST and SVHN, and from MNIST to MNIST-M. Here, we sample 10 samples per class from the target train split, and use 5,000 randomly sampled images per class for MNIST and 700 per class for USPS and SVHN. The experiments are repeated 5 times. Prior to this, a hyper-parameter search using Bayesian Optimisation and the search space described in <ref type="table" target="#tab_4">Table III</ref> was conducted for the MNIST?USPS task. These hyper-parameters were used for the remaining transfers, except for the MNIST?SVHN transfer, which had its own hyper-parameter search using an equivalent computational budget for each method. The results are presented in <ref type="table" target="#tab_6">Table IV</ref>. Here, DAGE-LDA has the highest accuracy on most tasks, with CCSA and d-SNE achieving slightly higher accuracy on one transfer each. A 2D UMAP <ref type="bibr" target="#b57">[57]</ref> visualisation of the latent space features produced using the DAGE-LDA loss in the USPS?MNIST adaptation is shown in <ref type="figure" target="#fig_6">Fig. 6</ref>.</p><p>The second set of experiments consider a few-shot transfer, were the network is trained from random initialisation using 2,000 randomly sampled images per class from MNIST (source) and a varying number of USPS (target) samples per class. Experiments with 1, 3, 5 and 7 target samples per class were conducted and each experiment was repeated 10 times. The results obtained by running the experiments are shown in <ref type="table" target="#tab_7">Table V</ref>. Comparing CCSA, d-SNE and DAGE-LDA, we T ) and ? n (X train S ) on the USPS ? MNIST adaptation for a network trained using the DAGE-LDA loss. In the latent space, the target data is mapped close to the source training data (dark contours), but with some deviations, which improve class separability. This illustrates the trade-off made in the DAGE-LDA loss between within-class compactness and between-class separability. find that DAGE-LDA has the highest average accuracy, closely followed by CCSA and then d-SNE. While the originally reported results for d-SNE <ref type="bibr" target="#b6">[7]</ref> show better performance than the other methods, it should be noted they used a LeNet++ <ref type="bibr" target="#b58">[58]</ref> architecture for feature extraction. Based on our own results for d-SNE, which used a CNN-architecture similar to the other methods, we attribute their higher accuracy to the choice of feature-extractor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. VisDA Classification</head><p>Following the setup in <ref type="bibr" target="#b6">[7]</ref>, the VisDA-C experiments use a ResNet-152V2 model as classification backbone. First, it is loaded with ImageNet-pretrained weights and finetuned on the synthetic source data. These model weights subsequently initialise the SDA methods, which employ 10 samples per class from the target domain (real) in addition to 100 samples per class from the source data (synthetic) for training and 30% for validation. The evaluation results on the remaining target data is shown in <ref type="table" target="#tab_7">Table VI</ref>.  <ref type="table" target="#tab_4">Table III</ref>). The faint lines represent a single transfer S ? T , where S, T ? {A, D, W}, while the bold lines are the average over all transfers. The horizontal axis shows the hyper-parameter value and the vertical axis is the average accuracy relative to the maximum average accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Sensitivity Analysis</head><p>within the search space. To gauge the sensitivity of the domain adaptation loss weightings, we use the Bayesian model to compute the partial dependence of each hyper-parameter. The partial dependence "averages out" the influence of other hyperparameters, and yields the best estimate given the 100 trials performed during hyper-parameter optimisation of Office31 transfers. Because the Bayesian optimisation chooses trials sequentially in a trade-off between exploration and exploitation, it should be noted that the estimate for high performing hyper-parameter values have tighter confidence bounds than low performers. In <ref type="figure" target="#fig_7">Fig. 7</ref>, we see plots of the average estimates of normalised accuracy for the ratio of domain adaptation loss to cross entropy loss, ?, as defined in Eq. <ref type="bibr" target="#b13">(14)</ref>. We observe that CCSA and d-SNE are highly sensitive to the chosen value of ?. For these methods, the domain adaptation loss works best when used as a regularisation term of small magnitude, and high values may lead to divergence during training. Meanwhile, DAGE-LDA works well over a range of chosen values. This makes sense, considering that the DAGE-LDA criterion explicitly minimises within-class distances and maximises between-class distances, which is akin to the operation performed by cross entropy for categorical data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VIII. CONCLUSION</head><p>In this paper, we have shown that Domain Adaptation can be viewed as Graph Embedding (DAGE) and that many existing methods for Supervised Domain Adaptation (SDA) can be formulated in this common framework. Within the DAGE framework, a very simple LDA-inspired instantiation matches or surpasses the current state-of-the-art methods on few-shot supervised adaptation task using the standard benchmarks in SDA. Moreover, we argued that the intrinsic and penalty graph Laplacian matrices in Graph Embedding give us a straight-forward way of encoding application-specific assumptions about the domain and tasks at hand. Finally, we highlighted some generalisation and reproducibility issues related to the experimental setup commonly used to evaluate the performance of Domain Adaptation methods and proposed a rectified experimental setup for more accurately assessing and comparing the generalisation capability of SDA methods. Alongside our source code, we made the revised trainingvalidation-test splits available to facilitate fair comparisons of SDA methods in future research. Omar Ali Sheikh-Omar is an industrial PhD fellow at Stibo Systems and Aarhus University (Denmark). He obtained his B.Sc. degree in Software Engineering from Aalborg University (Denmark) in 2017 and his M.Sc. degree in Computer Engineering from Aarhus University in 2019. He is interested in deep learning, recommender systems, coresets and differential privacy.</p><p>Alexandros Iosifidis (SM'16) is an Associate Professor at Aarhus University, Denmark. He serves as Associate Editor in Chief (Neural Networks) for Neurocomputing journal, he was an Area Chair for IEEE ICIP 2018-2021 and EUSIPCO 2019,2021, and a Publicity co-Chair of IEEE ICME 2021. He was the recipient of the EURASIP Early Career Award 2021 for contributions to statistical machine learning and artificial neural networks. His research interests focus on neural networks and statistical machine learning finding applications in computer vision, financial modelling and graph analysis problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 :Fig. 3 :</head><label>23</label><figDesc>FOR FEW-SHOT SUPERVISED DOMAIN ADAPTATION An important aspect of conducting experiments on domain adaptation in few-shot settings relates to how the data should T Cartesian product of two sets, each with three samples. Sample labels are indicated by their shape, while the colour indicates their origin. The Cartesian product produces all pairwise combinations of samples with one sample from each set. A ratio filter (here with a 1:1 ratio) can be used to limit the ratio of same-class samples to different-class samples. (a) The current domain adaptation setup in [6, 7] leads to dependent splits. (b) Drawing a validation set does not ensure test set independence. (c) To produce an independent test split, an initial fixed train-rest split should be made followed by train-val splits for each experimental run.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Data preparation procedure. Test data is a constant subset of target data, whereas training and validation data are sampled with different seeds for each experiment. Training data is the Cartesian product of training samples from target and source domain, filtered to have a predefined ratio of same-class to different class pairs. Here, ovals represent operations and rectangles represent data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Automated hyper-parameter search is performed using a single trainvalidation split, producing the tuned hyper-parameters to be used for evaluation with other splits.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 :</head><label>4</label><figDesc>Rectified experimental setup</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 :</head><label>5</label><figDesc>Samples from the Office31 (Amazon, DSLR, Webcam), digits (MNIST, USPS, SVHN, MNIST-M), and VisDA (Synthetic, Real) datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 :</head><label>6</label><figDesc>UMAP visualisations of latent network features ? n (X test</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>AFig. 7 :</head><label>7</label><figDesc>result of Bayesian Optimisation is a statistical model, which gives an expected optimisation value (accuracy) and confidence bounds for any hyper-parameter combination Average partial dependence of optimisation result on the weighting ratio of domain adaptation loss to cross entropy loss, ?, in Office 31. Each line represents the estimated partial dependence for the DA-CE Loss ratio in high-dimensional optimisation space (see</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Lukas</head><label></label><figDesc>Hedegaard is a PhD student at Aarhus University, Denmark. He received his M.Sc. degree in Computer Engineering in 2019 and B.Eng. degree in Electronics in 2017 at Aarhus University, specialising in signal processing and machine learning. His current research interests include deep learning, transfer learning and human activity recognition focused on efficient utilisation of training data and computational resources.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Adaptation datasets, Office31 1 and MNIST?USPS 2 , which follow the rectified experimental protocol and are compatible with both Tensorflow and PyTorch through the use of a new open source library called Dataset Ops 3 . 6) We supply an updated benchmark for DAGE-LDA [10], CCSA, and d-SNE on the Office31 [12], Digits</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Algorithm 1 Procedure for training a DAGE-LDA model Input: Source data X S , target data X T , number of training epochs T , hyper-parameters (?, ?, ) Output: Trained neural network model ? 1: ? ? Load pre-trained network weights (FT-Source) 2: for t in 1, ..., T epochs do 3:Split dataset into training, validation and test sets according to the rectified experiment protocol.</figDesc><table /><note>4:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>e.g. from Eq. (15) using mini-batch b.</figDesc><table><row><cell>:</cell><cell>Update ? by optimising Eq. (14) via gradient descent</cell></row><row><cell></cell><cell>on mini-batch b.</cell></row><row><cell>10:</cell><cell>end for</cell></row><row><cell cols="2">11: end for</cell></row><row><cell cols="2">B. DAGE-LDA</cell></row></table><note>7: Create B b , e.g. from Eq. (16) using mini-batch b.8: Compute L DAGE according to Eq. (12).9The DAGE criterion in Eq. (</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE II</head><label>II</label><figDesc></figDesc><table><row><cell cols="4">: Office-31 average classification accuracy (%) for</cell></row><row><cell cols="4">the traditional and rectified experimental methodology. As</cell></row><row><cell cols="4">feature-extractor, the convolutional layers of a VGG-16 pre-</cell></row><row><cell cols="3">trained on ImageNet network were used.</cell><cell></cell></row><row><cell cols="2">Experiment setup Traditional [10]</cell><cell cols="2">Rectified Difference</cell></row><row><cell>CCSA</cell><cell>83.1</cell><cell>82.2</cell><cell>-0.9</cell></row><row><cell>d-SNE</cell><cell>83.6</cell><cell>81.6</cell><cell>-2.0</cell></row><row><cell>DAGE-LDA</cell><cell>83.6</cell><cell>82.8</cell><cell>-0.8</cell></row><row><cell>Average</cell><cell></cell><cell></cell><cell>-1.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III :</head><label>III</label><figDesc>Employed hyper-parameter search space.</figDesc><table><row><cell>Hyper-Parameter</cell><cell cols="2">Lower Upper</cell><cell>Prior</cell></row><row><cell>Learning Rate</cell><cell>10 ?6</cell><cell>0.1</cell><cell>Log-Uniform</cell></row><row><cell>Learning Rate Decay</cell><cell>10 ?7</cell><cell>0.01</cell><cell>Log-Uniform</cell></row><row><cell>Momentum</cell><cell>0.5</cell><cell cols="2">0.99 Inv Log-Uniform</cell></row><row><cell>Dropout</cell><cell>0.1</cell><cell>0.8</cell><cell>Uniform</cell></row><row><cell>L2 Regularisation</cell><cell>10 ?7</cell><cell>10 ?3</cell><cell>Log-Uniform</cell></row><row><cell>Batch Norm</cell><cell>False</cell><cell>True</cell><cell>Uniform</cell></row><row><cell>Margin,  ?</cell><cell>10 ?3</cell><cell>10</cell><cell>Log-Uniform</cell></row><row><cell>No. Unfrozen Base-Layers  ?</cell><cell>0</cell><cell>16</cell><cell>Uniform</cell></row><row><cell>DA-CE Loss Ratio, ?</cell><cell>0.01</cell><cell>0.99</cell><cell>Uniform</cell></row><row><cell>S-T CE Loss Ratio, ?</cell><cell>0.0</cell><cell>1.0</cell><cell>Uniform</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>? Only relevant for CCSA and d-SNE.? Only relevant for the experiments in Office31 dataset.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV :</head><label>IV</label><figDesc>Macro average classification accuracy (%) for supervised domain adaptation on the digits datasets. 10 samples per class were used from the target domain. The results are reported as the mean and standard deviation across five runs.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">MNIST ? MNIST-M MNIST ? USPS</cell><cell>USPS ? MNIST</cell><cell cols="2">MNIST ? SVHN SVHN ? MNIST</cell><cell>Avg.</cell></row><row><cell>Trad.</cell><cell>CCSA (LeNet++) [7] d-SNE (LeNet++) [7]</cell><cell>78.3 ? 2.0 87.8 ? 0.2</cell><cell>97.3 ? 0.2 99.0 ? 0.1</cell><cell>95.7 ? 0.4 98.9 ? 0.4</cell><cell>37.6 ? 3.6 61.7 ? 0.4</cell><cell>94.6 ? 0.4 96.5 ? 0.2</cell><cell>80.7 88.7</cell></row><row><cell>Rect.</cell><cell>CCSA d-SNE DAGE-LDA</cell><cell>72.9 ? 1.2 67.2 ? 1.2 72.5 ? 1.5</cell><cell>96.3 ? 0.5 96.6 ? 0.3 96.5 ? 0.3</cell><cell>93.2 ? 0.5 93.7 ? 0.5 93.7 ? 0.7</cell><cell>52.3 ? 3.2 55.8 ? 1.1 57.4 ? 0.9</cell><cell>87.1 ? 1.3 88.4 ? 0.9 89.5 ? 0.4</cell><cell>80.4 80.3 81.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE V :</head><label>V</label><figDesc>MNIST ? USPS classification accuracy (%) using the rectified experimental protocol. The number of available target samples per class is varied and 200 source samples per class are used. The mean and standard deviation is reported across ten runs.</figDesc><table><row><cell></cell><cell>Samples/class</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>7</cell><cell>Avg.</cell></row><row><cell></cell><cell>CCSA [6]</cell><cell>85.0</cell><cell>90.1</cell><cell>92.4</cell><cell>92.9</cell><cell>90.1</cell></row><row><cell>Trad.</cell><cell>FADA [20] d-SNE (LeNet++) [7]</cell><cell>89.1 92.9</cell><cell>91.9 93.6</cell><cell>93.4 95.1</cell><cell>94.4 96.1</cell><cell>92.2 94.4</cell></row><row><cell></cell><cell>NEM [8]</cell><cell>72.2</cell><cell>86.6</cell><cell>91.4</cell><cell>91.8</cell><cell>85.5</cell></row><row><cell>Rect.</cell><cell>CCSA d-SNE DAGE-LDA</cell><cell>89.1 ? 1.1 88.3 ? 1.7 88.8 ? 1.8</cell><cell>91.2 ? 0.9 91.4 ? 1.2 92.4 ? 0.5</cell><cell>93.8 ? 0.4 93.1 ? 0.5 93.4 ? 0.4</cell><cell>94.3 ? 0.4 93.6 ? 0.6 94.1 ? 0.3</cell><cell>92.1 91.6 92.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>TABLE VI :</head><label>VI</label><figDesc>VisDA-C Accuracy (%) for traditional<ref type="bibr" target="#b6">[7]</ref> and rectified splits, where the mean and standard deviation is reported across five runs.</figDesc><table><row><cell>Method</cell><cell cols="2">Traditional [7] Rectified (ours)</cell></row><row><cell>FT-Source</cell><cell>52.8</cell><cell>54.5</cell></row><row><cell>CCSA</cell><cell>76.9</cell><cell>77.0 ? 0.8</cell></row><row><cell>d-SNE</cell><cell>80.7</cell><cell>78.0 ? 1.1</cell></row><row><cell cols="2">DAGE-LDA -</cell><cell>78.4 ? 1.2</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Traditional FT-Source <ref type="bibr" target="#b9">[10]</ref> 66.6 ? 3.0 59. <ref type="bibr" target="#b7">8</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrzebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey on transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1345" to="1359" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A survey of transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torrey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shavlik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="242" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Data enrichment in finegrained classification of aquatic macroinvertebrates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Raitoharju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Riabchenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Meissner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ahmad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kiranyaz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR 2nd Workshop on Computer Vision for Analysis of Underwater Imagery</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="43" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unified deep supervised domain adaptation and generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Piccirilli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5715" to="5725" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">d-sne: Domain adaptation using stochastic neighborhood embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Majumder</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="43" to="56" />
		</imprint>
	</monogr>
	<note>Domain Adaptation in Computer Vision with Deep Learning</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Domain adaptation with neural embedding matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">An introduction to domain adaptation and transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Kouw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loog</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.11806</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Supervised domain adaptation using graph embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hedegaard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">A</forename><surname>Sheikh-Omar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Pattern Recognition</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Graph embedding and extensions: A general framework for dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="51" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Adapting visual category models to new domains</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="213" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Handwritten digit recognition with a back-propagation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Denker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Hubbard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="1990" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="396" to="404" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reading digits in natural images with unsupervised feature learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Coates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bissacco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Workshop on Deep Learning and Unsupervised Feature Learning</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>March</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">59</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Visda: A synthetic-to-real benchmark for visual domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Usman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kaushik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition Workshops</title>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Simultaneous deep transfer across domains and tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tzeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Saenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4068" to="4076" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Fewshot adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Motiian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Iranmanesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6670" to="6680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Domain adaptation by mixture of alignments of second-or higher-order scatter tensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7139" to="7148" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semisupervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1195" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Semi-supervised learning using gaussian fields and harmonic functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="912" to="919" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deep learning via semi-supervised embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ratle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1168" to="1175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Locality preserving joint transfer for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="6103" to="6115" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Domain adaptation by joint distribution invariant projections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="8264" to="8277" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Domain adaptation via transfer component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="199" to="210" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Scatter component analysis: A unified framework for domain adaptation and domain generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghifary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Balduzzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">B</forename><surname>Kleijn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1414" to="1430" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A graph embedding framework for maximum mean discrepancy-based domain adaptation algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="199" to="213" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Conditional adversarial domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1640" to="1650" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Trace ratio problem revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="729" to="735" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On the optimal class representation in linear discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tefas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Pitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1491" to="1497" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A generalized foley-sammon transform based on generalized fisher discriminant criterion and its application to face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-F</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-T</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-D</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="147" to="158" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generalized multi-view embedding for visual recognition and cross-modal retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Cybernetics</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2542" to="2555" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multiview fsher discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Diethe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hardoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The collinearity problem in linear regression: The partial least squares (pls) approach to generalized inverses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ruhe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dunn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Scientific and Statistical Computing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="735" to="743" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Deep canonical correlation analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Arona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bilmes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Livescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1247" to="1255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Multi-view discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="188" to="194" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Multi-view nonparametric discriminant analysis for image retrieval and recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabbouj</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1537" to="1541" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Deep multi-view learning to rank</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Iosifidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gabbouj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gottumukkala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1426" to="1438" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The complexity of the matrix eigenproblem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">Y</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirty-first annual ACM symposium on Theory of computing</title>
		<meeting>the thirty-first annual ACM symposium on Theory of computing</meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="507" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning a parametric embedding by preserving local structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Intelligence and Statistics</title>
		<imprint>
			<date type="published" when="2009-04" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="384" to="391" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Dimensionality reduction using similarity-induced embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Passalis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tefas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3429" to="3441" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Stochastic gradient descent for spectral embedding with implicit orthogonality constraint</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">El</forename><surname>Gheche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chierchia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Frossard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3567" to="3571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Graph matching and pseudo-label guided deep unsupervised domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Artificial Neural Networks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="342" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2014</title>
		<editor>D. Fleet, T. Pajdla, B. Schiele, and T. Tuytelaars</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">YouTube-BoundingBoxes: A large high-precision humanannotated data set for object detection in video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Real</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mazzocchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<idno>abs/1702.00824</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno>abs/1409.1556</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A tutorial on bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Brochu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Cora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>De Freitas</surname></persName>
		</author>
		<idno>abs/1012.2599</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">A metric learning reality check</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Musgrave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-N</forename><surname>Lim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Torchvision the machine-vision package of torch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Marcel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM International Conference on Multimedia</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="1485" to="1488" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">TensorFlow Datasets, a collection of ready-to-use datasets</title>
		<ptr target="https://www.tensorflow.org/datasets" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Joint crossdomain classification and subspace learning for unsupervised adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="60" to="66" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Umap: Uniform manifold approximation and projection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mcinnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Grossberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Open Source Software</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">29</biblScope>
			<biblScope unit="page">861</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">A discriminative feature learning approach for deep face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="499" to="515" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
