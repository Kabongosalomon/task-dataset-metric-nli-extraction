<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">FarsTail: A Persian Natural Language Inference Dataset</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-07-08">8 Jul 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hossein</forename><surname>Amirkhani</surname></persName>
							<email>amirkhani@qom.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Azarijafari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zohreh</forename><surname>Pourjafari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soroush</forename><surname>Faridan-Jahromi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeinab</forename><surname>Kouhkan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Azadeh</forename><surname>Amirak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Engineering and IT Department</orgName>
								<orgName type="institution">University of Qom</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">FarsTail: A Persian Natural Language Inference Dataset</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-07-08">8 Jul 2021</date>
						</imprint>
					</monogr>
					<note type="submission">Preprint submitted to Elsevier July 12, 2021</note>
					<note>(Hossein Amirkhani) Persian language, Farsi dataset, Deep learning, Benchmark</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T15:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Natural language processing, Natural language inference,</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Natural language inference (NLI) is known as one of the central tasks in natural language processing (NLP) which encapsulates many fundamental aspects of language understanding. With the considerable achievements of data-hungry deep learning methods in NLP tasks, a great amount of effort has been devoted to develop more diverse datasets for different languages. In this paper, we present a new dataset for the NLI task in the Persian language, also known as Farsi, which is one of the dominant languages in the Middle East. This dataset, named FarsTail, includes 10,367 samples which are provided in both the Persian language as well as the indexed format to be useful for non-Persian researchers. The samples are generated from 3,539 multiple-choice questions with the least amount of annotator interventions in a way similar to the SciTail dataset. A carefully designed multi-step process is adopted to ensure the quality of the dataset. We also present the results of traditional and state-of-the-art methods on FarsTail including different embedding methods such as word2vec, fastText, ELMo, BERT, and LASER, as well as different modeling approaches such as DecompAtt, ESIM, HBMP, and ULMFiT to provide a solid baseline for the future research. The best obtained test accuracy is 83.38% which shows that there is a big room for improving the current methods to be useful for real-world NLP applications in different languages. We also investigate the extent to which the models exploit superficial clues, also known as dataset biases, in FarsTail, and partition the test set into easy and hard subsets according to the success of biased models. The dataset is available at https://github.com/dml-qom/FarsTail.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Persian language, Farsi dataset, Deep learning, Benchmark</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Natural Language Processing (NLP) deals with the development of automatic methods for processing, analyzing, and generating human languages. It consists of a vast number of problems, ranging from low-level to high-level tasks such as named entity recognition <ref type="bibr" target="#b0">[1]</ref>, sentiment analysis <ref type="bibr" target="#b1">[2]</ref>, machine translation <ref type="bibr" target="#b2">[3]</ref>, and machine reading comprehension <ref type="bibr" target="#b3">[4]</ref>. One important task in NLP is Natural Language Inference (NLI) which is believed to be a stringent test for language understanding, since a system with the ability to identify the implications of natural language sentences should have a good level of language understanding <ref type="bibr" target="#b4">[5]</ref>.</p><p>The goal of NLI is to determine the inference relationship between a premise p and a hypothesis h. It is a three-class problem, where each pair (p, h) is assigned to one of these classes: entailment if the hypothesis can be inferred from the premise, contradiction if the hypothesis contradicts with the premise, and neutral if none of the other conditions hold. To determine the hypothesis status, some prior knowledge is considered besides the premise. This includes the knowledge that typical speakers of that language know, such as the commonsense facts and general semantic knowledge. For example, the typical English speakers know that "USA" refers to "the United States of America".</p><p>After substantial success of deep learning (DL) based methods in different artificial intelligence tasks, the NLP researchers also started to develop DL-based models to learn the patterns in available natural language data generated by humans <ref type="bibr" target="#b5">[6]</ref>. The percentage of deep learning papers nearly doubled in a six-year period from 2012 in the major NLP conferences <ref type="bibr" target="#b6">[7]</ref>. Since these methods need a large amount of training data to let the model learn the general pattern for the particular task without overfitting to the available data, different research groups started to gather and publish large datasets. For the NLI task, the development of Stanford NLI dataset (SNLI) caused a considerable progress in developing DL-based models for NLI task <ref type="bibr" target="#b7">[8]</ref>.</p><p>In DL-based NLI literature, there has been a considerable amount of researches on languages with a large amount of training data, such as English, but relatively little attention has been paid to data-poor languages. Despite some efforts in developing NLI datasets for other languages by translation or transferring knowledge obtained from learning on one language to other languages <ref type="bibr" target="#b8">[9]</ref>, presenting native datasets for other languages help develop models with more comprehensive language understanding capabilities. In addition, these datasets can be used to evaluate the proposed learning architectures and methods for a broader range of languages.</p><p>The focus of this paper is on Persian (Farsi) language which is a pluricentric language spoken and used by around 110 million people in countries such as Iran, Afghanistan, and Tajikistan. It has had a considerable influence on its neighboring languages such as Turkic, Armenian, Georgian, and Indo-Aryan languages. Its alphabet includes 32 characters written right to left. <ref type="table">Table 1</ref> shows some features of Persian language which make its processing different from other languages.</p><p>In this paper, we present, to the best of our knowledge, the first relatively large-scale Persian corpus for NLI task, called FarsTail. We tried to reduce the amount of annotation interventions to provide realistic samples which are naturally occurring in real-world applications instead of task-specific synthesized examples. A protocol similar to the SciTail dataset <ref type="bibr" target="#b9">[10]</ref> is followed where the sentences are either generated, with the least amount of interventions, from multiple-choice questions or selected from natural sentences that already exist independently "in the wild". However, in contrast to Sci-Tail which only includes the neutral and entailment classes, we also include contradiction examples in the dataset.</p><p>Each person generates three data examples from a multiple-choice question, one for each class, with the same premises but different hypotheses. The entailment hypothesis is formed by substituting the correct answer in the question. Then, a text snippet is extracted from web that the generated hypothesis can be inferred from. The contradiction hypothesis is formed by substituting one wrong answer in the question. Finally, the neutral hypothesis is extracted from web such that it is similar to the question but with an unknown status based on the premise. In the next phase, each sample is relabeled by four other persons and the samples with at least 4 out of 5 agreements are preserved. The rejected samples undergo a new modification and relabeling phase.</p><p>A total of 10,367 samples are generated from a collection of 3,539 multiplechoice questions. The train, validation, and test portions include 7,266, 1,537, and 1,564 instances, respectively. We ensure that the instances with the same premises are in the same set. The developed dataset can also be used in other tasks such as question answering, summarization, semantic search, <ref type="table">Table 1</ref>: Some features of Persian language which make its processing different from other languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Feature Example</head><p>Different forms for some words "Caesar" is written as either ?"????????"? or ?"????????"? Different words used for some foreign concepts "computer" is written as either ?"????????"? or ?"??????"? Adding a space may change the meaning ?"????"? means "mother", while ???"? ?"??? means "we are in" Words with the same spelling but different pronunciation and meaning ?"???"? can be pronounced as "molk" or "malek" which mean "territory" and "king", respectively Words arbitrarily disjointed to two words separated with a space "nobody" is written as either ?"?????"? or ???"? ?"???? Words with different plural forms "teachers" can be written as ?,"??????"? " ?????? ???? ", or ?"??????"? Words with different formal and conversational forms "listening" is formally written as ?,"?????"? while it is sometimes written in conversational form as ?"?????"? The critical role of punctuation in the meaning of some sentences ?????"? ???????? ?????? ????? ?:"?????? Forgive him, it is not necessary to execute him. ?????"? ???????? ??????? ????? ?:"????? It is not necessary to forgive him, execute him.</p><p>Prior knowledge that typical Persian language speakers know "Before revolution" means "Before 1979 revolution" to Iranians and machine translation. The developed dataset (as raw texts for Persian researchers and indexed data for non-Persian researchers) has been released for non-commercial usages.</p><p>We evaluate different traditional and state-of-the-art methods on FarsTail, including different embedding methods such as word2vec <ref type="bibr" target="#b10">[11]</ref>, fastText <ref type="bibr" target="#b11">[12]</ref>, ELMo <ref type="bibr" target="#b12">[13]</ref>, BERT <ref type="bibr" target="#b13">[14]</ref>, and LASER <ref type="bibr" target="#b14">[15]</ref>, as well as different modeling methods such as DecompAtt <ref type="bibr" target="#b15">[16]</ref>, ESIM <ref type="bibr" target="#b16">[17]</ref>, HBMP <ref type="bibr" target="#b17">[18]</ref>, and ULMFiT <ref type="bibr" target="#b18">[19]</ref>. The best obtained accuracy on test set is 83.38% which shows that there are many rooms to improve the models trained on this dataset. We also investigate the superficial clues, also known as dataset biases, available in FarsTail to obtain a more realistic view of the performance of the models.</p><p>Concurrent to this work, ParsiNLU <ref type="bibr" target="#b19">[20]</ref> is developed which is a suite of Persian datasets for different tasks, including an NLI set with 2,700 instances. Around half of the instances are written by native speakers and the remaining instances are translated from the MNLI dataset <ref type="bibr" target="#b20">[21]</ref>. FarsTail is superior to this dataset in three aspects: It has around 4 times more instances; it just includes first-hand native sentences without translation clues; and task-specific human-generated texts are kept as low as possible to provide instances which are naturally occurring in real-world applications.</p><p>The rest of this paper is organized as follows. In Section 2, the available English and non-English NLI datasets are reviewed. Section 3 presents the FarsTail development process as well as its statistics. The experimental results are presented in Section 4, and the paper concludes in the last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>In this section, we review some available English and non-English NLI datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">English NLI datasets</head><p>? SICK <ref type="bibr" target="#b21">[22]</ref>: As one of the first attempts to introduce relatively largescale datasets for NLI task, this dataset was introduced as a task in SemEval-2014. It consists of about 10k English sentence pairs annotated for two different tasks, relatedness in meaning and entailment. The original sentence pairs are randomly selected from 8k ImageFlickr dataset and the SemEval 2012 STS MSR-Video Description dataset. Some rule-based syntactic and lexical transformations are applied to each sentence to obtain sentences with similar, contradictory, and different meanings. Its partly automated construction introduced some spurious patterns into the data <ref type="bibr" target="#b7">[8]</ref>.</p><p>? SNLI <ref type="bibr" target="#b7">[8]</ref>: The Stanford NLI dataset has been developed to alleviate the lack of large-scale annotated data for the NLI problem. It includes 570k labeled instances (550k training, 10k validation, and 10k test examples) gathered using the Amazon Mechanical Turk. An image caption was presented to each turker as the premise and they were asked to generate three sentences as hypothesis, one for each class (entailment, contradiction, and neutral). In the relabeling phase, if at least three out of four new labelers agreed with the main label, this instance was kept in the dataset. This dataset played a considerable role in developing and enhancing deep learning-based NLI systems.</p><p>? MultiNLI <ref type="bibr" target="#b20">[21]</ref>: Compared to SNLI, MultiNLI covers 10 different genres of spoken and written text. With 433k instances, its scale is comparable to SNLI. The test set consists of two parts: matched set which includes the same genres in the training set and mismatched set which includes genres not available in the training set. This allows for cross-genre generalization evaluation.</p><p>? MedNLI <ref type="bibr" target="#b22">[23]</ref>: This dataset was generated by the same approach as SNLI, adjusted for the clinical domain. The MIMIC-III v1.3 <ref type="bibr" target="#b23">[24]</ref>, with de-identified records of 38,597 patients, was used as the premise source. The hypothesis sentences were generated by clinicians. Four clinicians worked on a total of 4,683 premises over a period of six weeks, which resulted in 14,049 unique sentence pairs.</p><p>? SciTail <ref type="bibr" target="#b9">[10]</ref>: This is the first NLI dataset which is collected using the available texts without authoring the sentences. This makes the dataset more realistic, since it consists of natural texts instead of task-specific synthesized sentences. SciTail is the most similar dataset to the dataset presented in this paper. The hypotheses were created from science questions and their corresponding answers, and premises were gathered from the relevant web sentences. It contains 1,834 questions with 10,101 entailment instances and 16,925 neutral ones. This dataset does not contain the contradiction label.</p><p>? QA-NLI <ref type="bibr" target="#b24">[25]</ref>: This dataset is similar to SciTail, except that it was fully automatically constructed. The authors proposed a method to derive NLI datasets from the question answering datasets. This was done by introducing the QA2D task to derive a declarative sentence from a question-answer pair. The generated sentence (D) along with the corresponding passage (P ) forms an NLI example as (P, D). For the correct, incorrect, and unknown answers, the pairs were labeled as entailment, contradiction, and neutral, respectively. Note that incorrect answers are available in QA datasets with multiple answers, and unknowns are also available in some datasets such as SQuAD 2.0 <ref type="bibr" target="#b25">[26]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Non-English NLI datasets</head><p>? Evalita <ref type="bibr" target="#b26">[27]</ref>: Constructed on the basis of Wikipedia revision histories, this dataset includes 800 short Italian sentence pairs.</p><p>? ArbTEDS <ref type="bibr" target="#b27">[28]</ref>: This is a small Arabic dataset with 600 pairs annotated as either inferable or non-inferable. A semi-automatic tool was used to extract the candidate pairs from web, using the Arabic news headlines as the hypothesis and one paragraph returned by the Google-API for this headline as the premise. The pairs were then labeled by eight annotators.</p><p>? German emails <ref type="bibr" target="#b28">[29]</ref>: Constructed from the customer emails to the support center of a multimedia software company as premises and the category descriptions as the hypotheses, this dataset includes 638 entailment and 24,143 non-entailment pairs. The matching and nonmatching categories were considered as entailment and non-entailment hypotheses, respectively.</p><p>? ASSIN <ref type="bibr" target="#b29">[30]</ref>: This is a two-class dataset with the entailment and notentailment classes including a collection of 10,000 pairs, half in Brazilian Portuguese and half in European Portuguese.</p><p>? XNLI [9]: This dataset was developed for evaluating the cross-lingual understanding capabilities of models. The same crowdsourcing-based procedure used for MultiNLI dataset <ref type="bibr" target="#b20">[21]</ref>   of the instances are written by native speakers and the remaining instances are translated from the MultiNLI dataset <ref type="bibr" target="#b20">[21]</ref>. The superiority of the FarsTail dataset over the ParsiNLU NLI set is that it includes around 4 times more instances which are first-hand native sentences without translation clues. Also, to provide texts that are naturally occurring in real-world applications, FarsTail includes the least amount of task-specific human-generated texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">FarsTail dataset</head><p>In this section, we present the process of developing FarsTail dataset as well as its statistics. FarsTail has been developed with a process similar to the SciTail dataset <ref type="bibr" target="#b9">[10]</ref> with some modifications. A group of five persons (called annotators herein) with a background in NLI worked under the supervision of an NLP expert to develop FarsTail. The taken steps are depicted in <ref type="figure" target="#fig_0">Fig. 1</ref> which include generating NLI instances from multiple-choice questions, relabeling, and data cleaning. The details of these steps are given in Sections 3.1 and 3.2, and the dataset statistics are presented in Section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Generating NLI instances from questions</head><p>A collection of 3,539 multiple-choice questions was gathered from Iranian university exams in different topics including religion, history, constitution of Iran, history of literature, and Islamic revolution. For each multiple-choice question, an annotator followed the following steps to generate three different pairs, one for each class (entailment, contradiction, and neutral):</p><p>Multiple-choice question:  1. The correct answer is inserted into the question to generate a sentence called h 1 . 2. The web is searched to find a text portion p where (p, h 1 ) has entailment relation. We use the available texts on the web instead of generating the premises to provide real-world, naturally occurring texts instead of task-specific synthesized examples. <ref type="bibr" target="#b2">3</ref>. An incorrect answer is inserted into the question to generate a sentence called h 2 such that (p, h 2 ) has contradiction relation. The annotator is asked to generate h 2 similar to h 1 in length, but different in structure and words. 4. From the web, a related sentence h 3 is found with a similar length to h 1 and h 2 such that its entailment or contradiction relation cannot be inferred from p. The pair (p, h 3 ) is considered as a neutral instance. <ref type="figure" target="#fig_2">Fig. 2</ref> shows an example of the sample generation process in FarsTail.</p><formula xml:id="formula_0">?????? ????? ???? ??????? ????????? ???? ????? ?????? ????? ???????? ???? ?????? o ??????? ??????? o ?????(? ?)????? ????? ???? ????? o ?????? ?????? o ???????? ??????</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Relabeling and data cleaning</head><p>After the sample generation phase, each sample was relabeled by the other four annotators retaining the samples with an agreement of at least 80% among five labelers. The samples were presented to the annotators in a random order to reduce annotation bias caused by presenting the samples with the same premise in succession. To give the rejected samples one more chance, they were revised by their original annotator and relabeled again. The samples which could not obtain a 80% label agreement in any of these two relabeling phases were removed. Among all 10,617 samples <ref type="bibr" target="#b2">(3,</ref><ref type="bibr">5393)</ref>, 190 samples were removed in this phase resulting in 10,427 instances.</p><p>The retained samples were investigated one more time for spelling and writing mistakes emphasizing on avoiding probable label change caused by cleaning. Finally, to reduce the unwanted repetition in the data, 60 more samples were removed including the instances generated from different questions which both their premises and hypotheses had a cosine similarity higher than 0.8. The total number of samples in the dataset is therefore 10,367.</p><p>The instances were randomly divided into training, validation, and test sets such that the samples generated from the same question were in the same subset. In addition, to avoid information leak, the samples generated from different questions which either their premises or hypotheses had a cosine similarity higher than 0.9 were included in the same subset. The training, validation, and test sets percentages are nearly 70/15/15 with 7,266, 1,537, and 1,564 samples, respectively.</p><p>The dataset is presented in two formats, raw and indexed. The raw data includes the Persian sentences, while the indexed data is a tokenized version of sentences where each sentence is encoded as a list of word indexes (integers) 1 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">FarsTail statistics</head><p>The statistics of FarsTail dataset is presented in <ref type="table" target="#tab_1">Table 2</ref>. To provide the possibility for comparing different subsets, there is one section for each of train, validation, and test sets. For each of these sets, beside the total statistics, the statistics for different classes are also shown separately where E, C, and N stand for entailment, contradiction, and neutral classes, respectively. The column "samples" of <ref type="table" target="#tab_1">Table 2</ref> shows the number of samples in each subset. As mentioned in Section 3.2, 70/15/15% of data go to the train, validation, and test sets, respectively. It can be seen that this is a balanced dataset without any meaningful differences between the number of samples in different classes.</p><p>The next column (premise tokens) presents the average number of tokens in the premises obtained by the Hazm python library's tokenizer. The next column (hypothesis tokens) shows the same values for hypothesis sentences. To provide a more meaningful length statistic, the next two columns (premise processed tokens and hypothesis processed tokens) report the number of unique tokens ignoring stopwords 2 as well as one-character tokens including punctuations. It is worth mentioning that there are a total of 20,973 tokens in FarsTail dataset where 467 tokens are stopwords or one-character tokens.</p><p>According to these four "tokens" columns, there is not any significant difference between the average number of tokens in train, validation, and test sets. More importantly, the average number of tokens in different classes are almost the same which shows that the length of premises and hypotheses cannot be exploited as a feature to find clues about the class of the given inputs.</p><p>One more point to consider about the "tokens" columns is that the premises in FarsTail are longer than the premises in SciTail dataset <ref type="bibr" target="#b9">[10]</ref>. The reported average premise length for entail and neutral samples in Sci-Tail training set are 10.79 and 10.28, respectively, while these numbers are <ref type="bibr">19.35 and 19.31</ref> in FarsTail. Regarding hypotheses, the average length for entail and neutral samples are respectively 6.69 and 7.01 which are almost the same as FarsTail <ref type="bibr">(8.42 and 8.26)</ref>. These longer premises are due to the FarsTail's sample generation process where we insisted on finding exact web text portions which the hypothesis could be inferred from. Anyway, this makes FarsTail a more challenging dataset since it seeks more reasoning to connect the facts presented in longer premises.</p><p>Finally, the last two columns show the average proportion of the hypothesis tokens that overlap with the premise. Both columns treat the sentences as a set of tokens ignoring the word repetition, but the second column also ignore the stopwords and one-character tokens. As expected, the most and the least overlap between premise and hypothesis are in the entailment and neutral samples, respectively. This shows that there are some superficial clues in the samples which can be exploited to estimate the relationship between two sentences without truly understanding them. In Section 4.3, we show that the mere similarity between premise and hypothesis can be used in a simple baseline model which obtains an accuracy higher than random; however, this accuracy is far from what that is obtained by more advanced deep models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>In this section, we present the results of different methods on the FarsTail dataset to provide a baseline for future researches. The evaluated models are introduced in Sections 4.1 and the results are presented in Section 4.2. Finally, in Section 4.3, we investigate the biases available in FarsTail to provide a more realistic view of the performance of the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Models</head><p>We used different methods for representing the input sentences ranging from traditional TF-IDF to more recent word embedding methods such as word2vec 3 <ref type="bibr" target="#b10">[11]</ref>, fastText 4 <ref type="bibr" target="#b11">[12]</ref>, ELMo 5 <ref type="bibr" target="#b12">[13]</ref>, and BERT <ref type="bibr" target="#b13">[14]</ref>. For the BERT method, we fine-tuned two pre-trained models from the Hugging Face Transformers library <ref type="bibr" target="#b31">[32]</ref>, ParsBERT <ref type="bibr" target="#b32">[33]</ref> and BERT-base-multilingual-cased (mBERT).</p><p>As the classifier, we exploited different methods including Support Vector Machine (SVM), Long Short-Term Memory (LSTM), and Gated Recurrent Unit (GRU) along with three models developed specially for the NLI task including DecompAtt <ref type="bibr" target="#b15">[16]</ref>, ESIM <ref type="bibr" target="#b16">[17]</ref>, and HBMP <ref type="bibr" target="#b17">[18]</ref>.</p><p>One popular approach in learning with small labeled training datasets is to train a language model (LM) on a large unlabeled corpus and fine-tune it on the downstream task. Besides the BERT-based models which lie in this category, we tested ULMFiT <ref type="bibr" target="#b18">[19]</ref> with three steps: LM pre-training, LM fine-tuning, and classifier fine-tuning. In the first step, a language model was trained on a general-domain corpus. We used the Persian Wikipedia for this purpose. Then, the trained LM was fine-tuned on the target task texts without considering their labels. Finally, the pre-trained language model was augmented with additional layers which were trained on the labeled dataset of the target task.</p><p>We also tested LASER 6 <ref type="bibr" target="#b14">[15]</ref> as an embedding space which is shared between multiple languages. Since LASER provides sentence embeddings rather than word embeddings, a simple deep model was trained on the computed representations.</p><p>The hyper-parameters were chosen based on the models' accuracy on the validation set. Most importantly, we selected the following values for the BERT models: 3 epochs of training with a learning rate of 2e-5, a batch size of 32, and a weight decay of 0.5. <ref type="table" target="#tab_2">Table 3</ref> shows the results obtained from training different models on the FarsTail training set. Note that the LASER and tf-idf representations were just used with the SVM classifier because they deliver sentence-level representations which cannot be used with the word-level methods like LSTM and BiGRU. On the other hand, to feed the SVM classifier with the word-level representations including word2vec, fastText, and ELMo, we computed a tfidf-weighted average of these word representations for each sentence. Note that the reported test accuracies are for models trained on both training and validation sets using the hyper-parameters tuned based on the validation set. For brevity, we just report the result of one representation for DecompAtt, ESIM, and HBMP. In the ESIM and HBMP methods, all representations obtained almost similar accuracies; while in the DecompAtt method, word2vec considerably outperformed other embeddings. According to <ref type="table" target="#tab_2">Table 3</ref>, the BERT models obtained the best accuracies with a large margin compared to other models. Between ParsBERT and mBERT, the latter shows a slightly better performance. Anyway, this 83.38% test accuracy shows that there is a big room for improving the current methods to be useful for real-world NLP applications in different languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>To provide a more detailed view of the performance of different models, <ref type="figure" target="#fig_3">Fig. 3</ref> shows the confusion matrices of six best performing ones. According to this figure, the most difficult class for all methods is contradiction that is confused more with entailment than neutral. This is because distinguishing a contradiction situation, especially from an entailment one, needs higher levels of natural language understanding than superficial pattern recognition.</p><p>On the other hand, the neutral class is the simplest one because many neutral samples can be easily identified by simple patterns like the overlap between their premise and hypothesis. This is compatible with the statistics presented in <ref type="table" target="#tab_1">Table 2</ref> where the overlap between premises and hypotheses in the neutral class is clearly different from that in the other two classes. Obviously, the performance of the models that rely on such superficial clues can degrade in out-of-distribution situations. The next section is a step towards investigating these biases in the FarsTail dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Dataset bias</head><p>Dataset bias includes correlations between input data and target values which are not generalizable to real-world instances. For example, negation words like nobody, no, never, and nothing in some NLI datasets like SNLI and MultiNLI are strongly correlated with the contradiction class <ref type="bibr" target="#b33">[34]</ref>. Deep models tend to exploit these clues to solve the dataset instead of the intended task. Therefore, even though they obtain high in-distribution accuracies, their performance drops significantly for out-of-distribution data <ref type="bibr" target="#b34">[35]</ref>. In this section, we investigate the available biases in the FarsTail dataset.</p><p>To identify the words associated with different inference classes, the pointwise mutual information (PMI) is computed between each word and class in the training set hypotheses: PMI(word, class) = log p(word, class) p(word, .)p(., class) .</p><p>As in <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b35">36]</ref>, we apply add-100 smoothing to the raw statistics. <ref type="table" target="#tab_4">Table 4</ref> shows the top ten words by PMI(word, class) in FarsTail as well as MultiNLI and SciTail for comparison. The table also reports the ratio of instances of each word belonging to the specified class. FarsTail shows lower PMI values and lower occurrence number of these superficial clues compared to the other two datasets. In addition, the top words by PMI in FarsTail belong to a wider range of classes. Even though we tried to keep the annotation clues low by reducing the amount of task-specific human-generated texts, some of these biases emerged in FarsTail hypotheses. For example, the words " " and " " (only) have   As another approach for investigating dataset biases, we evaluated two biased models which classified instances based on incomplete input data. The classification accuracy of these models gives an estimate of the degree to which the superficial clues can be exploited by the learning algorithms. Inspired from <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b36">37]</ref>, we first investigated a hypothesis-only model by finetuning the mBERT model on the hypotheses to predict the entailment labels without seeing the premises. The model obtained an accuracy of 55.31% on the test set. The corresponding confusion matrix presented in <ref type="figure" target="#fig_4">Fig. 4</ref> shows that the main success of the hypothesis-only model has been in the neutral class, with the entailment and contradiction classes in the next places.</p><p>In the second biased model, we used the cosine similarity between the bagof-word count vectors of the premise and hypothesis as the input feature to investigate the ability of a model in deciding about the inference relationship just exploiting the similarity between the premise and hypothesis. An SVM classifier trained on this input feature obtained an accuracy of 56.46% on the test set. <ref type="figure" target="#fig_4">Fig. 4</ref> shows that this model has obtained a good performance in distinguishing the neutral class from the other two classes. This is compatible with the overlap statistics presented in <ref type="table" target="#tab_1">Table 2</ref> where the overlap between premises and hypotheses in the neutral class is clearly different from that in the other two classes. On the other hand, the worst performance of this biased model has been in the contradiction class where the model has performed near random. This is because contradiction needs a higher level of inference to be determined.</p><p>According to whether or not the test samples were correctly classified by each of the biased models, we partitioned the FarsTail test set into two subsets (for each biased model): easy and hard. Two binary columns added to the test set, denoted as hard(hypothesis) and hard(overlap), indicate whether or not each sample belongs to the hard subset based on the hypothesis-only and overlap-based biased models, respectively. Comparing these subsets, 497 (32%) test samples are easy for both biased models, while 313 (20%) samples are hard for both. On the other hand, 386 (25%) and 368 (23%) test samples are hard just for the hypothesis-only and overlap-based biased models, respectively. Obviously, these two models capture different biased patterns in the dataset since nearly half of the samples are easy for one model and hard for the other. The introduction of these subsets of the test set allows for a more precise evaluation of the developed models. As an example, <ref type="table" target="#tab_5">Table 5</ref> shows the detailed performance of some models on different FarsTail test subsets. As expected, all models were more successful in classifying easy samples. This shows the previously known fact that a part of the models' success in recognizing textual entailment is due to their exploitation of available biases in the dataset <ref type="bibr" target="#b33">[34]</ref>. Also, comparing the results obtained for the subsets respective to the two biased models shows that the models' accuracy on the hard subset obtained by the overlap-based biased model is usually lower than that of the hypothesis-only biased model. This reveals that the models exploit more of the overlap information between premises and hypotheses than the biased patterns in the hypotheses. Obviously, these models will have difficulty in classifying samples that come from a different distribution. We consider the construction of out-of-distribution challenge sets for the FarsTail dataset as a future work. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we introduced, to the best of our knowledge, the first relatively large-scale NLI dataset for Persian language. We presented the details of the FarsTail development process, which is carefully designed to ensure the data quality. We also presented the dataset statistics as well as the results of some traditional and state-of-the-art methods on it. We also investigated the dataset biases in FarsTail.</p><p>Due to the usage of multiple-choice questions in developing the FarsTail dataset, these questions along with their corresponding premises can also be exploited in the machine reading comprehension (MRC) task. In the future, we plan to present this MRC dataset as a byproduct of FarsTail. We also consider developing Persian NLI challenge sets as a future work to establish a benchmark for evaluating the models' out-of-distribution performance.</p><p>Since the best obtained result on the FarsTail test set, using the powerful BERT method, is 83.38%, we hope it invokes more research on developing methods which are applicable to real-world NLP tasks in different languages, specially data-poor ones.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The FarsTail dataset development steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Who was the Secretary-General of the United Nations before Ant?nio Guterres? o Javier Solana o Ban Ki-moon (correct answer) o Kofi Annan o Yoshir? Mori : Entailment hypothesis (question + correct answer) ????.? ????? ???? ????? ???????? ????????? ???? ????? ?????? ????? ???????? ???? ?????? Ban Ki-moon was the Secretary-General of the United Nations before Ant?nio Guterres. : Premise (from web) ????.? ???????? ????? ???? ????? ???????? ??? ?????? ????? ???????? ?????? ???????? ???????? ???? ??????? ????????? ? ?????? ?????? ????? ???????? ??????? ?????? The United Nations General Assembly formally elected Ant?nio Guterres as the next UN Secretary-General and Ban Kimoon's successor.Contradiction hypothesis (question + incorrect answer):????.? ????? ???????? ?????? ????? ???????? ???? ?????? ???????? ??????? ????????? ???? ????? ?????? ?????? Before Ant?nio Guterres, Kofi Annan had been selected as the United Nations Secretary-General.Neutral hypothesis (from web):??????.? ??????? ?????? ????? ???????? ????? ?????? ??????? ???????? ???? ??????? ????????? ????? ??????? ???? ?????? ????? ???????? ??????? The United Nations members unanimously nominated Ant?nio Guterres as UN Secretary-General.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>An example of generating NLI instances from questions in FarsTail.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Confusion matrices of different models on the FarsTail test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 :</head><label>4</label><figDesc>Confusion matrices of the biased models on the FarsTail test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>was followed to collect and validate 750 examples from each of ten text sources resulted in a total of 7,500 examples. These examples were then translated into 14 different languages by professional translators. The total 112,500 annotated pairs are in English, French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi, Swahili, and Urdu languages. Unfortunately, it does not include the Persian language.? OCNLI<ref type="bibr" target="#b30">[31]</ref>: This is the first large-scale Chinese NLI dataset which includes around 56k annotated sentence pairs. The annotations are elicited from native speakers specializing in linguistics.? ParsiNLU<ref type="bibr" target="#b19">[20]</ref>: This concurrent work is a suite of Persian datasets for different tasks, including an NLI set with 2,700 instances. Around half</figDesc><table><row><cell>Build entailment hypothesis</cell><cell></cell><cell></cell></row><row><cell>(question + correct answer)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Revise and relabel again</cell><cell></cell></row><row><cell>Find premise from web for</cell><cell>the removed samples</cell><cell></cell></row><row><cell>entailment hypothesis</cell><cell></cell><cell></cell></row><row><cell>Multiple-choice</cell><cell></cell><cell></cell></row><row><cell>questions</cell><cell>Data cleaning</cell><cell>FarsTail dataset</cell></row><row><cell>Build contradict hypothesis</cell><cell>Retain samples with at</cell><cell></cell></row><row><cell>(question + incorrect answer)</cell><cell>least 80% agreement</cell><cell></cell></row><row><cell>Find neutral hypothesis from</cell><cell>Relabel each sample by</cell><cell></cell></row><row><cell>web</cell><cell>4 other annotators</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the FarsTail dataset.</figDesc><table><row><cell cols="3">subset class samples</cell><cell>prem. tokens</cell><cell>hyp. tokens</cell><cell>prem. proc. tokens</cell><cell>hyp. proc. tokens</cell><cell>overlap</cell><cell>proc. overlap</cell></row><row><cell></cell><cell>E</cell><cell>2,429</cell><cell>40.50</cell><cell>15.53</cell><cell>19.35</cell><cell>8.42</cell><cell>0.67</cell><cell>0.68</cell></row><row><cell>Train</cell><cell>N C</cell><cell>2,448 2,389</cell><cell>40.52 40.23</cell><cell>15.62 15.61</cell><cell>19.31 19.20</cell><cell>8.26 8.30</cell><cell>0.40 0.57</cell><cell>0.30 0.54</cell></row><row><cell></cell><cell cols="2">Total 7,266</cell><cell>40.42</cell><cell>15.59</cell><cell>19.29</cell><cell>8.33</cell><cell>0.55</cell><cell>0.51</cell></row><row><cell></cell><cell>E</cell><cell>515</cell><cell>39.70</cell><cell>14.85</cell><cell>19.13</cell><cell>8.27</cell><cell>0.67</cell><cell>0.66</cell></row><row><cell>Val</cell><cell>N C</cell><cell>523 499</cell><cell>39.71 39.58</cell><cell>14.95 15.09</cell><cell>19.16 19.17</cell><cell>8.06 8.11</cell><cell>0.39 0.58</cell><cell>0.29 0.54</cell></row><row><cell></cell><cell cols="2">Total 1,537</cell><cell>39.67</cell><cell>14.96</cell><cell>19.15</cell><cell>8.14</cell><cell>0.54</cell><cell>0.50</cell></row><row><cell></cell><cell>E</cell><cell>519</cell><cell>39.57</cell><cell>15.48</cell><cell>18.84</cell><cell>8.39</cell><cell>0.68</cell><cell>0.68</cell></row><row><cell>Test</cell><cell>N C</cell><cell>535 510</cell><cell>39.23 39.44</cell><cell>16.02 15.81</cell><cell>18.73 18.86</cell><cell>8.36 8.38</cell><cell>0.38 0.57</cell><cell>0.27 0.52</cell></row><row><cell></cell><cell cols="2">Total 1,564</cell><cell>39.41</cell><cell>15.78</cell><cell>18.81</cell><cell>8.38</cell><cell>0.54</cell><cell>0.49</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Validation and test set accuracy of different models trained on the FarsTail training set.</figDesc><table><row><cell>Model</cell><cell cols="3">Representation Val Accuracy Test Accuracy</cell></row><row><cell></cell><cell>tf-idf</cell><cell>0.5303</cell><cell>0.5301</cell></row><row><cell></cell><cell>LASER</cell><cell>0.5459</cell><cell>0.5198</cell></row><row><cell>SVM</cell><cell>word2vec</cell><cell>0.5120</cell><cell>0.5448</cell></row><row><cell></cell><cell>fastText</cell><cell>0.5296</cell><cell>0.5371</cell></row><row><cell></cell><cell>ELMo</cell><cell>0.5621</cell><cell>0.5710</cell></row><row><cell></cell><cell>word2vec</cell><cell>0.5172</cell><cell>0.5243</cell></row><row><cell>LSTM</cell><cell>fastText</cell><cell>0.5205</cell><cell>0.5192</cell></row><row><cell></cell><cell>ELMo</cell><cell>0.5478</cell><cell>0.5505</cell></row><row><cell></cell><cell>word2vec</cell><cell>0.5192</cell><cell>0.5224</cell></row><row><cell>BiGRU</cell><cell>fastText</cell><cell>0.5211</cell><cell>0.5243</cell></row><row><cell></cell><cell>ELMo</cell><cell>0.5582</cell><cell>0.5428</cell></row><row><cell>DecompAtt</cell><cell>word2vec</cell><cell>0.6597</cell><cell>0.6662</cell></row><row><cell>ESIM</cell><cell>fastText</cell><cell>0.7033</cell><cell>0.7116</cell></row><row><cell>HBMP</cell><cell>word2vec</cell><cell>0.6617</cell><cell>0.6604</cell></row><row><cell>ULMFiT</cell><cell>Learned</cell><cell>0.7281</cell><cell>0.7244</cell></row><row><cell>BERT</cell><cell>ParsBERT mBERT</cell><cell>0.8081 0.8263</cell><cell>0.8299 0.8338</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>The top ten words by PMI(word,class) in three datasets. The Counts column shows how many of the instances of each word occur in hypotheses belong to the specified class. confine the general point presented in the premise to make a contradicting hypothesis as in the following instance: ?????? ????? ????? ???? ?????? ??? ????? ???? ???:? ????? ????? ????? ????? ??????? ?????????? ????? ?????? ???? ???? ???????? ???? ????? : ??? ?????.? Premise: One of the things that is repeated in the message of all the prophets is: I do not ask you for a reward.</figDesc><table><row><cell></cell><cell>Word</cell><cell>Class</cell><cell>PMI</cell><cell>Counts</cell></row><row><cell></cell><cell>never</cell><cell cols="2">Contradiction 0.852</cell><cell>6599/8363</cell></row><row><cell></cell><cell>no</cell><cell cols="3">Contradiction 0.820 12499/16515</cell></row><row><cell></cell><cell>nothing</cell><cell cols="2">Contradiction 0.775</cell><cell>2090/2758</cell></row><row><cell></cell><cell>any</cell><cell cols="2">Contradiction 0.735</cell><cell>5430/7739</cell></row><row><cell>MultiNLI</cell><cell>none anything</cell><cell cols="2">Contradiction 0.681 Contradiction 0.668</cell><cell>553/702 2239/3336</cell></row><row><cell></cell><cell>completely</cell><cell cols="2">Contradiction 0.664</cell><cell>855/1190</cell></row><row><cell></cell><cell>also</cell><cell>Neutral</cell><cell>0.644</cell><cell>1845/2726</cell></row><row><cell></cell><cell>refused</cell><cell cols="2">Contradiction 0.644</cell><cell>401/498</cell></row><row><cell></cell><cell>nobody</cell><cell cols="2">Contradiction 0.603</cell><cell>612/881</cell></row><row><cell></cell><cell>to</cell><cell>Neutral</cell><cell>0.488</cell><cell>3541/5266</cell></row><row><cell></cell><cell>have</cell><cell>Neutral</cell><cell>0.481</cell><cell>845/1155</cell></row><row><cell></cell><cell>the</cell><cell>Neutral</cell><cell cols="2">0.479 14194/21758</cell></row><row><cell></cell><cell>definite</cell><cell>Entailment</cell><cell>0.478</cell><cell>144/146</cell></row><row><cell>SciTail</cell><cell>because system</cell><cell>Neutral Neutral</cell><cell>0.466 0.461</cell><cell>571/749 654/885</cell></row><row><cell></cell><cell>.</cell><cell>Neutral</cell><cell cols="2">0.454 14790/23261</cell></row><row><cell></cell><cell>a</cell><cell>Neutral</cell><cell>0.451</cell><cell>6086/9514</cell></row><row><cell></cell><cell>off</cell><cell>Neutral</cell><cell cols="2">0.437 7644/12162</cell></row><row><cell></cell><cell>and</cell><cell>Neutral</cell><cell>0.430</cell><cell>2771/4352</cell></row><row><cell></cell><cell>:</cell><cell>Neutral</cell><cell>0.244</cell><cell>95/158</cell></row><row><cell></cell><cell>"</cell><cell>Entailment</cell><cell>0.227</cell><cell>466/1053</cell></row><row><cell></cell><cell>"</cell><cell cols="2">Contradiction 0.222</cell><cell>463/1053</cell></row><row><cell></cell><cell>(only)</cell><cell cols="2">Contradiction 0.221</cell><cell>61/87</cell></row><row><cell>FarsTail</cell><cell>(be) ??? (also)</cell><cell cols="2">Contradiction 0.202 Neutral 0.179</cell><cell>202/440 50/76</cell></row><row><cell></cell><cell>(only)</cell><cell cols="2">Contradiction 0.168</cell><cell>38/50</cell></row><row><cell></cell><cell>(self)</cell><cell>Neutral</cell><cell>0.163</cell><cell>143/319</cell></row><row><cell></cell><cell>(after)</cell><cell cols="2">Contradiction 0.162</cell><cell>74/144</cell></row><row><cell></cell><cell>(work,effect)</cell><cell>Entailment</cell><cell>0.159</cell><cell>70/135</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Accuracy of different models on different subsets of the FarsTail test set.</figDesc><table><row><cell></cell><cell></cell><cell cols="4">Hypothesis-only Overlap-based</cell></row><row><cell>Model</cell><cell>Full</cell><cell>Easy</cell><cell>Hard</cell><cell>Easy</cell><cell>Hard</cell></row><row><cell cols="3">DecompAtt (word2vec) 0.6662 0.7341</cell><cell>0.5823</cell><cell cols="2">0.7633 0.5404</cell></row><row><cell>HBMP (word2vec)</cell><cell cols="2">0.6604 0.7618</cell><cell>0.5350</cell><cell cols="2">0.7565 0.5360</cell></row><row><cell>ESIM (fastText)</cell><cell cols="2">0.7116 0.7931</cell><cell>0.6109</cell><cell cols="2">0.8120 0.5815</cell></row><row><cell>mBERT</cell><cell cols="2">0.8338 0.8763</cell><cell>0.7811</cell><cell cols="2">0.8981 0.7504</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Hazm python library was used for tokenization (https://github.com/sobhe/hazm)</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">A stoplist with 389 words was used from Hazm library.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://vectors.nlpl.eu/repository 4 https://fasttext.cc/docs/en/crawl-vectors.html 5 https://github.com/HIT-SCIR/ELMoForManyLangs 6 https://github.com/facebookresearch/LASER</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A survey on recent advances in named entity recognition from deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Yadav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2145" to="2158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bibliometrics of sentiment analysis literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Keramatfar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Amirkhani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Information Science</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="15" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A survey of deep learning techniques for neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07526</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A survey on machine reading comprehension systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Baradaran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ghiasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Amirkhani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.01582</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Maccartney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A survey of the usages of deep learning for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Otter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Neural Networks and Learning Systems</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Recent trends in deep learning based natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hazarika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Poria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computational Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="55" to="75" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">XNLI: Evaluating cross-lingual sentence representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2475" to="2485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">SciTail: A textual entailment dataset from science question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Khot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sabharwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5189" to="5197" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<title level="m">Distributed representations of words and phrases and their compositionality</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
	<note>Advances in neural information processing systems</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
	<note>Deep contextualized word representations</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Massively multilingual sentence embeddings for zero-shot cross-lingual transfer and beyond, Transactions of the Association for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Artetxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="597" to="610" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A decomposable attention model for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>T?ckstr?m</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2249" to="2255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Enhanced LSTM for natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1657" to="1668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Sentence embeddings in NLI with iterative refinement encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Talman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Yli-Jyr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="482" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Universal language model fine-tuning for text classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Khashabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shakeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hosseini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pezeshkpour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alikhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aminnaseri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bitaab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Brahman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghazarian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.06154</idno>
		<title level="m">ParsiNLU: A suite of language understanding challenges for persian</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A broad-coverage challenge corpus for sentence understanding through inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nangia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1112" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">SemEval-2014 Task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Menini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zamparelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 8th International Workshop on Semantic Evaluation</title>
		<meeting>the 8th International Workshop on Semantic Evaluation<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Lessons from natural language inference in the clinical domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Romanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shivade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1586" to="1596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">H</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">Anthony</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Transforming question answering datasets into natural language inference datasets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Demszky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Guu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.02922</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Know what you don&apos;t know: Unanswerable questions for SQuAD</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="784" to="789" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Zanzotto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pennacchiotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
	<note>Proceedings of EVALITA 2009 2 (6.4</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A dataset for Arabic textual entailment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alabbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Student Research Workshop associated with RANLP 2013</title>
		<meeting>the Student Research Workshop associated with RANLP 2013</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="7" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">An analysis of textual inference in German customer emails</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Eichler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gabryszak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014</title>
		<meeting>the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="69" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Overview of the evaluation of semantic similarity and textual inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">R</forename><surname>Fonseca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Borges Dos Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Criscuolo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Alu?sio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Linguam?tica</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">OCNLI: Original chinese natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>K?bler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Moss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing: Findings</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3512" to="3526" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<title level="m">HuggingFace&apos;s Transformers: State-of-the-art natural language processing</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gharachorloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farahani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Manthouri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.12515</idno>
		<title level="m">ParsBERT: Transformer-based model for persian language understanding</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Annotation artifacts in natural language inference data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gururangan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Swayamdipta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="107" to="112" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Right for the wrong reasons: Diagnosing syntactic heuristics in natural language inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pavlick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Linzen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">57th Annual Meeting of the Association for Computational Linguistics, ACL 2019</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3428" to="3448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">New protocols and negative results for textual entailment data collection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Palomaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">B</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pitler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">EMNLP</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="8203" to="8214" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Poliak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Naradowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Haldar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rudinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Durme</surname></persName>
		</author>
		<title level="m">Proceedings of the Seventh Joint Conference on Lexical and Computational Semantics</title>
		<meeting>the Seventh Joint Conference on Lexical and Computational Semantics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="180" to="191" />
		</imprint>
	</monogr>
	<note>Hypothesis only baselines in natural language inference</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
