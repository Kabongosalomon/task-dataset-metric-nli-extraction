<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SpectralNET: Exploring Spatial-Spectral WaveletCNN for Hyperspectral Image Classification MALIS -Machine Learning and Intelligent Systems</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanmay</forename><surname>Chakraborty</surname></persName>
							<email>s:tanmay.chakraborty@eurecom.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Data Science and Engineering</orgName>
								<orgName type="institution">EURECOM</orgName>
								<address>
									<settlement>Biot</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utkarsh</forename><surname>Trehan</surname></persName>
							<email>utkarsh.trehan@eurecom.fr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Data Science and Engineering</orgName>
								<orgName type="institution">EURECOM</orgName>
								<address>
									<settlement>Biot</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Dr</roleName><forename type="first">Maria</forename><forename type="middle">A</forename><surname>Zuluaga</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Data Science and Engineering</orgName>
								<orgName type="institution">EURECOM</orgName>
								<address>
									<settlement>Biot</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">SpectralNET: Exploring Spatial-Spectral WaveletCNN for Hyperspectral Image Classification MALIS -Machine Learning and Intelligent Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Wavelet CNN</term>
					<term>2-D Convolutional Neural Net (CNN)</term>
					<term>3-D Convolutional Neural Net</term>
					<term>SpectralNET</term>
					<term>hyperspectral image (HSI)</term>
					<term>spectral-spatial features</term>
					<term>HSI classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Hyperspectral Image (HSI) classification using Convolutional Neural Networks (CNN) is widely found in the current literature. Approaches vary from using SVMs to 2D CNNs, 3D CNNs, 3D-2D CNNs. Besides 3D-2D CNNs and FuSENet, the other approaches do not consider both the spectral and spatial features together for HSI classification task, thereby resulting in poor performances. 3D CNNs are computationally heavy and are not widely used, while 2D CNNs do not consider multiresolution processing of images, and only limits itself to the spatial features. Even though 3D-2D CNNs try to model the spectral and spatial features their performance seems limited when applied over multiple dataset. In this article, we propose SpectralNET, a wavelet CNN, which is a variation of 2D CNN for multi-resolution HSI classification. A wavelet CNN uses layers of wavelet transform to bring out spectral features. Computing a wavelet transform is lighter than computing 3D CNN. The spectral features extracted are then connected to the 2D CNN which bring out the spatial features, thereby creating a spatialspectral feature vector for classification. Overall a better model is achieved that can classify multi-resolution HSI data with high accuracy. Experiments performed with SpectralNET on benchmark dataset, i.e. Indian Pines, University of Pavia, and Salinas Scenes confirm the superiority of proposed SpectralNET with respect to the state-of-the-art methods. The code is publicly available in https://github.com/tanmay-ty/SpectralNET.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>A Hyperspectral Image (HSI) is a high dimension image cube, where each band stores the intensity values of the pixels in a particular spectrum <ref type="bibr" target="#b0">[1]</ref>. HSI classification is the task of correctly predicting the different pixel values associated with the different classes present in a remotely sensed HSI. Applications include urban development, detection of land changes, military applications, land cover analysis, crop detection etc. A key feature of HSI is they contain both spectral and spatial information.</p><p>Deep-learning based methods specially CNNs perform extremely well on image data. In recent works, HSI classification using different CNN models is also seen besides traditional hand-extracted feature based models <ref type="bibr" target="#b1">[2]</ref>. Most models are based on 2D CNN, and 3D CNN <ref type="bibr" target="#b2">[3]</ref>. Due to satisfactory performances of the two independent models <ref type="bibr" target="#b3">[4]</ref>, hybrid 3D-2D CNNs have also been proposed in the literature <ref type="bibr" target="#b4">[5]</ref>. FuSENet is another model proposed in literature for HSI classification <ref type="bibr" target="#b5">[6]</ref>.</p><p>In <ref type="bibr" target="#b6">[7]</ref>, a band weighing strategy has been proposed that utilizes multiple binary support vector machines (SVM) in order to maximize the spectral distances between each class of a remotely sensed HSI. Their method was able to weight the spectral bands and improve classification results. A similar approach using SVMs has been proposed in <ref type="bibr" target="#b7">[8]</ref>, where the authors explored discrete space model (DSM) to transform continuous spectral features into discrete feature space, they utilized a composite kernel to take into account the spectral and spatial features. This pre-processing step improved the performance of SVMs for HSI classification. Kernel based approaches has also been found in the literature. In <ref type="bibr" target="#b8">[9]</ref>, spectral similarity based kernels has been developed and utilized along with the RBF kernel in a SVM. For the problem in hand they concluded spectral similarity based kernels outperform traditional SVM kernels.</p><p>The work in <ref type="bibr" target="#b9">[10]</ref>, adapts and improves the traditional lowrank representation (LRR) to the HSI classification problem. Locality-and structure-regularized LRR combines both the spectral and spatial features to explore the local similarity of pixels. The authors of <ref type="bibr" target="#b10">[11]</ref>, applied the concept of spectral gradient for HSI classification. They extracted the spatial features through a random forest algorithm and spectral features through spectral gradients. Then they perform a multi-scale fusion to integrate spatial-spectral features for the SVM to perform classification. The work in <ref type="bibr" target="#b11">[12]</ref>, introduced deep support vector machines (DSVM) for HSI classification. The model was able to outperform most of the state-of-the-art algorithms including all the variants of traditional SVMs.</p><p>In <ref type="bibr" target="#b12">[13]</ref>, a 3D octave CNN has been proposed which factorizes the mixed frequency feature map to reduce the spatial redundancy obtained when using a traditional 3D CNN with HSI. The authors of <ref type="bibr" target="#b13">[14]</ref>, utilized pseudo 3D blocks with a densely connected network. Their pseudo 3D blocks can capture both spectral and spatial features simultaneously compared to a traditional 3D CNN. The article <ref type="bibr" target="#b14">[15]</ref>, utilized small 3D patches extracted from the original HSI cube to train a 3D CNN with 3D kernel. In the following works <ref type="bibr" target="#b15">[16]</ref>, residual connections were added to a 3D CNN in order to assimilate both high and low level features present in a HSI and improve classification results. The work of <ref type="bibr" target="#b16">[17]</ref>, studied the effect of dimensionality reduction of HSI on 3D CNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>arXiv:2104.00341v1 [eess.IV] 1 Apr 2021</head><p>They concluded reducing the dimension of the training image reduced training time by 60%.</p><p>In <ref type="bibr" target="#b18">[18]</ref>, a 3D-2D CNN has been proposed for HSI classification. As a pre-processing the authors utilized channel wise shift and channel wise weighting to highlight the different spectral bands. In <ref type="bibr" target="#b3">[4]</ref>, 2D-3D CNN has been utilized with multi band feature fusion mechanism. This mechanism allows them to fuse both shallow and deep features in spectral band, which improves the feature vector sent into the dense layer.The work proposed in <ref type="bibr" target="#b19">[19]</ref>, introduces adaptive spectral unmixing into a 3D-2D CNN along with a early exit strategy. The early exit strategy reduces computational cost for easy samples. In <ref type="bibr" target="#b20">[20]</ref>, a residual hybrid 3D-2D CNN has been proposed, which has further been improved in <ref type="bibr" target="#b21">[21]</ref> and is currently the stateof-the-art.</p><p>Efforts have also been made with Recurrent Neural Networks (RNN), Generative Adversarial Networks (GAN), Graph CNNs <ref type="bibr" target="#b22">[22]</ref>, and Squeeze and Excitation Residual Network <ref type="bibr" target="#b23">[23]</ref>. RNNs consider the spectral signature of the HSI as a sequence in order to learn discriminative features <ref type="bibr" target="#b24">[24]</ref>.</p><p>Even though the 3D-2D CNNs model both the spatial and spectral features from a HSI cube, their model performance when applied over multiple dataset seems limited. 3D CNNs are also computationally expensive over 2D CNNs. So a method involving only 2D CNN as well as the power of extracting both spatial and spectral features is desirable.</p><p>In this article, a 2D wavelet CNN has been proposed for HSI classification. The work in <ref type="bibr" target="#b25">[25]</ref>, established wavelet transform as a good feature extractor for HSI classification task. Thus fusing the wavelet transform into a 2D CNN model brings out both the spectral and spatial features from a HSI. These features are then concatenated channel wise and sent as an input to the dense classification layers of the 2D CNN. The developed model uses Factor Analysis (FA) as a pre-processing step to reduce the huge dimensionality of HSI. Then patches are extracted and sent into the CNN. This reduces the training time as well. The spectral features coming from wavelet transform are computationally lighter as well compared to a 3D CNN. The model outperforms all previous models and paves the way for wavelet CNN in multi-resolution image classification. This model has been named SpectralNET in this paper.</p><p>The rest of the paper is arranged in the following way Section II, describes the SpectralNET model in details, Section III contains our experiments and discussions, and the paper is concluded in Section IV.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. SPECTRALNET</head><p>The conventional 2D CNN can be considered a limited version of a multi-resolution CNN that can consider both spectral and spatial information <ref type="bibr" target="#b26">[26]</ref>. Previous works have been successful in establishing the convolution and pooling function in a 2D CNN as filtering and downsampling <ref type="bibr" target="#b27">[27]</ref>. A basic CNN can be mathematically represented as the weighed sum of nearest neighbours with an added constant bias.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Background for SpectralNET</head><p>Given an input vector X n with corresponding labels Y n from the R n space. In equation 1, Y i is a label from Y n labels and X i is the corresponding sample from X n . W j is the weight defined by a filtering kernel. N i are neighbouring i data.</p><formula xml:id="formula_0">y i = j?Ni W j X j (1)</formula><p>The equation 1 can be simply considered as the convolution of X i and kernel W j and can be rewritten as Y = X * W. This is called the convolution layer of a CNN, where W is in R o . The output of the convolution layers are typically big and needs to be pooled down before feeding it to the next layer. The pooling layers are placed in between convolution layers to perform a filtering operation and reducing the number of outputs.</p><p>This paves the way towards the multi-resolution CNN where the convolution is performed by a pair of kernels k low and k high which generate X low and X high . The multi-resolution CNN performs the hierarchical decomposition of the X low,t into X low,t+1 and X high,t+1 with different kernels at each step t.</p><p>For SpectralNET, the wavelet kernel K high,t is Haar wavelets and K low,t is a scaling function <ref type="bibr" target="#b28">[28]</ref>. The 2D haar wavelets utilize the following four kernels <ref type="bibr" target="#b29">[29]</ref>.</p><formula xml:id="formula_1">(f L,L f L,H f H,L f H,H ) for wavelet transform</formula><formula xml:id="formula_2">f L,L = 1 1 1 1 f L,H = ?1 ?1 1 1 f H,L = ?1 1 ?1 1 f H,H = 1 ?1 ?1 1<label>(2)</label></formula><p>A HSI patch x with SxS dimensions when passed through a Haar transform the (i,j)-th spectrum position value can be written as</p><formula xml:id="formula_3">Haar(i , j ) = x(2i ? 1, 2j ? 1) + x(2i ? 1, 2j) + x(2i, 2j ? 1) + x(2i, 2j).</formula><p>The HSI patch taken as an input is decomposed by the wavelet transform into sub-bands, these sub-bands are then sent through a convolution layer to learn the spectral and location features. Note that the sub-bands indicated as high and low pass filers do not necessarily filter the spectral band in with high pass and low pass filter. The part of the sub-band is again decomposed in the next layer by the wavelet transform and sent into the convolution layer. This process is continued in each layer and the CNN continues to learn the spectral and spatial features from the HSI patch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. SpectralNET Model Description</head><p>The input HSI cube having dimension MxNxR is first sent into a layer of Factor Analysis (FA) to reduce the dimension into MxNxB. Reducing the dimension reduces training time by 60% <ref type="bibr" target="#b16">[17]</ref>. The output vector Y having a dimension 1xMN take up a class from the available land cover categories denoted by C. The spectral dimensions are preserved in FA, i.e. MxN, just the bands are reduced from R to B. Using FA in HSI as a pre-processing step is extremely beneficial, as FA is able to describe the variability among the different correlated and <ref type="figure">Fig. 1</ref>. Input HSI cube is pre-processed using Factor Analysis (FA) to reduce the dimention to 3. Patches are extracted from the pre-processed image and sent as an input to the SpectralNET model. SpectralNET model architecture with 4-level wavelet decomposition of the input HSI patch. The input kernel size is 3x3 with 1x1 padding. The output batch channel size is denoted by the numbers written after conv. To reduce feature map 3x3 kernels with stride 2 and 1x1 padding are used. The wavelet transformed features are added channelwise. To prevent the gradient from vanishing projection shortcuts are utilized with 1x1 convolutions. An average pooling layer is used globally after which the output is sent to the fully connected layers with dropout neurons. overlapping spectrum bands, which helps making the model classify similar examples better. On the other hand, commonly used Principal Component Analysis (PCA) based reduction does not directly address this objective in HSI. PCA provides an approximation to the required factors which do not help to differentiate similar examples that well. After the FA step is complete, overlapping 3D patches of size SxSxB are extracted from the pre-processed HSI and sent into the SpectralNET. SxS is the window size for patch extraction, for the Indian Pines dataset the patch size has been set at 64x64 and for the University of Pavia and Salinas Scene dataset the window size has been set at 24x24. The truth values for these patches are determined by the center pixel's class category. The values were chosen based on experimentation to maximize the overall accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Implementation</head><p>The proposed SpectralNET model architecture is given in <ref type="figure">figure 1</ref>. The model is initialized with 3x3 convolution kernels and 1x1 padding. To replace pooling layers in between convolution a stride of 2 has been utilized. A global mean pooling has been employed at the end of all the convolution layers before sending into the dense layer, this prevents overfitting in the model. Dense connections has been utilized along with projection shortcuts for utilizing the wavelet transformed data more efficiently <ref type="bibr" target="#b30">[30]</ref>  <ref type="bibr" target="#b31">[31]</ref>. Dense connections with channel wise concatenation of the decomposed data makes sure that all the features flow till the end of the model. The model explored two dropout layers as well along with batch normalization to prevent overfitting. Since the number of samples are very less in HSI the chances of overfitting are high. All steps to prevent the model from overfitting needs to be taken. Rectified Linear Unit (ReLU) has been utilized as the activation function. We explored the Stochastic gradient descent (SGD) over 150 epochs with a learning rate of 0.01 and momentum of 0.9 to optimize the objective function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. EXPERIMENTS, RESULTS, AND DISCUSSION</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Dataset and Training</head><p>The experiments were conducted on multiple publicly available benchmark datasets, Indian Pines (IP), University of Pavia (UP), and Salinas Scene (SA) <ref type="bibr" target="#b0">1</ref> . The detailed descriptions of the three datasets are given in table I.The classification spectral layout for IP dataset is given in <ref type="figure" target="#fig_0">figure 2</ref>.</p><p>To perform the experiments, Google colab cloud platform with GPU has been utilized 2 . Based on our experimental analysis an optimum learning rate of 0.01 with a momentum of 0.9 was chosen for the SGD optimizer. For preserving the validity of the results for all datasets, the bands of the extracted patches have all been set to 3. So, the patch dimension for IP dataset is 64x64x3 and for UP and SA it is 24x24x3 respectively. The model has been trained for 150 epochs and convergence was achieved at around 60 epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Classification Results</head><p>The classification results are given in table II. Three benchmark metrics are utilized to judge the performance of the proposed model. Overall Accuracy (OA) gives the total number of correctly classified labels out of the total number of labels. Average Accuracy (AA) gives the mean of class wise classification accuracies, and Kappa Accuracy is a measure that correlates the ground truth and classified values. The results are compared with the state-of-the-art methods like HybridSN <ref type="bibr" target="#b21">[21]</ref> and FuSENET <ref type="bibr" target="#b5">[6]</ref>, besides SVM, 2D CNN, 3D CNN, M3D CNN [32] 3 . The results are compared for two sets 10% -90% random train test split and 30% -70% random train test split respectively. It can be observed from the results that the proposed model outperforms all state-of-the-art models in both the sets. Even though in the 10% train set the HybridSN model appears to perform better in SA dataset, that might be because of the fact it takes a lot more spectral bands as input compared to the proposed model. It can also be seen from the results that 2D CNN standalone performs better than 3D CNN in SA dataset. It might be due to the increased spectral redundancy in the SA dataset compared to the rest. The performance of FuSENET, HybridSN and SpectralNET is consistently high throughout the three dataset over M3D CNN. SpectralNET is able to outperform all even with a lot less spectral bands, i.e. 3, utilized than the state-of-the-art models which utilize 15, 30 bands. This highlights the merit of using wavelets based spectral features with a CNN. The time for training the SpectralNET is around 30 minutes which is also comparable to the currently established models.</p><p>For more detailed class wise classification results are in the appendix. From the results it can be established that the performance of SpectralNET is superior to all the methods currently available for HSI classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. CONCLUSION</head><p>In a nutshell, a wavelet CNN has been proposed in this work for HSI classification task. The developed SpectralNET takes into consideration both spectral and spatial features present in a high dimensional HSI cube using layers of wavelet decomposition of the input and adding that to the CNN. Experiments conducted with the three benchmark datasets IP, UP and SA along with a comparison with the state-of-the-art methods establish the superiority of the proposed model. This work has been done in the context of the Machine Learning and Intelligent System (MALIS) course and it represents the final project report.    </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 2 .</head><label>2</label><figDesc>Image cube, spectral ground truth, and spectral prediction for Indian Pines Dataset along with legend.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 .</head><label>3</label><figDesc>Confusion matrix for IP, UP, and SA using SpectralNET.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I</head><label>I</label><figDesc></figDesc><table><row><cell>.</cell><cell cols="4">DETAILED DESCRIPTION OF EACH DATASET USED DURING</cell></row><row><cell></cell><cell></cell><cell>EXPERIMENT.</cell><cell></cell><cell></cell></row><row><cell>Name</cell><cell>Spatial Dimension</cell><cell>Spectral Bands</cell><cell>Wavelength Range</cell><cell>Classes</cell></row><row><cell>IP</cell><cell>145x145</cell><cell>224</cell><cell>400nm -2500nm</cell><cell>16</cell></row><row><cell>UP</cell><cell>610x340</cell><cell>103</cell><cell>430nm -860nm</cell><cell>9</cell></row><row><cell>SA</cell><cell>512x217</cell><cell>224</cell><cell>360nm -2500nm</cell><cell>16</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II .</head><label>II</label><figDesc>CLASSIFICATION ACCURACIES (%) OF PROPOSED SPECTRALNET IN TERMS OF OA, KAPPA, AND AA WITH VARYING TRAINING DATA 10% AND 30%, RESPECTIVELY APPENDIX CLASSWISE CLASSIFICATION RESULTS Class wise classification results for IP, SA and UP datasets are summarised in table III, IV, and V respectively. Confusion matrix are available in figure 3. TABLE III. DETAILED CLASSIFICATION RESULTS FOR INDIAN PINES DATASET IN TERMS OF PRECISION, RECALL, F1-SCORE, TEST LOSS, OVERALL ACCURACY, AVERAGE ACCURACY AND KAPPA ACCURACY.</figDesc><table><row><cell>Class Labels</cell><cell>Precision</cell><cell>Recall</cell><cell>f1-score</cell><cell>Support</cell></row><row><cell>Alfalfa</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>32</cell></row><row><cell>Corn-notill</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1000</cell></row><row><cell>Corn-mintill</cell><cell>1.00</cell><cell>0.99</cell><cell>1.00</cell><cell>581</cell></row><row><cell>Corn</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>166</cell></row><row><cell>Grass-pasture</cell><cell>0.99</cell><cell>1.00</cell><cell>1.00</cell><cell>338</cell></row><row><cell>Grass-trees</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>511</cell></row><row><cell>Grass-pasture-mowed</cell><cell>1.00</cell><cell>0.85</cell><cell>0.92</cell><cell>20</cell></row><row><cell>Hay-windrowed</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>335</cell></row><row><cell>Oats</cell><cell>0.78</cell><cell>1.00</cell><cell>0.88</cell><cell>14</cell></row><row><cell>Soyabean-notill</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>680</cell></row><row><cell>Soyabean-mintill</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1719</cell></row><row><cell>Soyabean-clean</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>415</cell></row><row><cell>Wheat</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>143</cell></row><row><cell>Woods</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>886</cell></row><row><cell>Buildings-Grass-Trees-Drives</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>270</cell></row><row><cell>Stone-Steel-Towers</cell><cell>0.98</cell><cell>1.00</cell><cell>0.99</cell><cell>65</cell></row><row><cell>accuracy</cell><cell></cell><cell></cell><cell>1.00</cell><cell>7175</cell></row><row><cell>macro avg</cell><cell>0.98</cell><cell>0.99</cell><cell>0.99</cell><cell>7175</cell></row><row><cell>weighted avg</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>7175</cell></row><row><cell>Test loss</cell><cell></cell><cell></cell><cell></cell><cell>0.7%</cell></row><row><cell>Average accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell>99.98%</cell></row><row><cell>Kappa accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell>99.84%</cell></row><row><cell>Overall accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell>99.86%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE IV .</head><label>IV</label><figDesc>DETAILED CLASSIFICATION RESULTS FOR SALINAS SCENE DATASET IN TERMS OF PRECISION, RECALL, F1-SCORE, TEST LOSS, OVERALL ACCURACY, AVERAGE ACCURACY AND KAPPA ACCURACY.</figDesc><table><row><cell>Class Labels</cell><cell>Precision</cell><cell>Recall</cell><cell>f1-score</cell><cell>Support</cell></row><row><cell>Brocoli-green-weeds-1</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1406</cell></row><row><cell>Brocoli-green-weeds-2</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>2608</cell></row><row><cell>Fallow</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1383</cell></row><row><cell>Fallow-rough-plow</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>976</cell></row><row><cell>Fallow-smooth</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1875</cell></row><row><cell>Stubble</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>2771</cell></row><row><cell>Celery</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>2505</cell></row><row><cell>Grapes-untrained</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>7890</cell></row><row><cell>Soil-vinyard-develop</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>4342</cell></row><row><cell>Corn-senesced-green-weeds</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>2295</cell></row><row><cell>Lettuce-romaine-4wk</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>748</cell></row><row><cell>Lettuce-romaine-5wk</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1349</cell></row><row><cell>Lettuce-romaine-6wk</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>641</cell></row><row><cell>Lettuce-romaine-7wk</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>749</cell></row><row><cell>Vinyard-untrained</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>5088</cell></row><row><cell>Vinyard-vertical-trellis</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1265</cell></row><row><cell>accuracy</cell><cell></cell><cell></cell><cell>1.00</cell><cell>37891</cell></row><row><cell>macro avg</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>37891</cell></row><row><cell>weighted avg</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>37891</cell></row><row><cell>Test loss</cell><cell></cell><cell></cell><cell></cell><cell>0.001%</cell></row><row><cell>Average accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell>100%</cell></row><row><cell>Kappa accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell>100%</cell></row><row><cell>Overall accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell>100%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE V .</head><label>V</label><figDesc>DETAILED CLASSIFICATION RESULTS FOR UNIVERSITY OF PAVIA DATASET IN TERMS OF PRECISION, RECALL, F1-SCORE, TEST LOSS, OVERALL ACCURACY, AVERAGE ACCURACY AND KAPPA ACCURACY.</figDesc><table><row><cell>Class Labels</cell><cell>Precision</cell><cell>Recall</cell><cell>f1-score</cell><cell>Support</cell></row><row><cell>Asphalt</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>4642</cell></row><row><cell>Meadows</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>13055</cell></row><row><cell>Gravel</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>1496</cell></row><row><cell>Trees</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>2145</cell></row><row><cell>Painted metal sheet</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>942</cell></row><row><cell>Bare soil</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>3520</cell></row><row><cell>Bitumen</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>931</cell></row><row><cell>Self-Blocking Bricks</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>2577</cell></row><row><cell>Shadows</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>663</cell></row><row><cell>accuracy</cell><cell></cell><cell></cell><cell>1.00</cell><cell>29944</cell></row><row><cell>macro avg</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>29944</cell></row><row><cell>weighted avg</cell><cell>1.00</cell><cell>1.00</cell><cell>1.00</cell><cell>29944</cell></row><row><cell>Test loss</cell><cell></cell><cell></cell><cell></cell><cell>0.07%</cell></row><row><cell>Average accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell>99.98%</cell></row><row><cell>Kappa accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell>99.98%</cell></row><row><cell>Overall accuracy (%)</cell><cell></cell><cell></cell><cell></cell><cell>99.99%</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">http://lesun.weebly.com/hyperspectral-data-set.html 2 https://colab.research.google.com/</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">https://github.com/eecn/Hyperspectral-Classification</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Chapter 1.1 -hyperspectral and multispectral imaging: setting the scene</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Amigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Hyperspectral Imaging (J. M. Amigo</title>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="3" to="16" />
		</imprint>
	</monogr>
	<note>of Data Handling in Science and Technology</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep learning for hyperspectral image classification: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Benediktsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="6690" to="6709" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification with deep learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y K</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="5408" to="5423" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification method based on 2d-3d cnn and multibranch feature fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="5776" to="5788" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Joint spatial-spectral hyperspectral image classification based on convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020. Image/Video Understanding and Analysis (IUVA)</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fusenet: fused squeeze-and-excitation network for spectral-spatial hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IET Image Processing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1653" to="1661" />
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Band weighting via maximizing interclass distance for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="922" to="925" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification using discrete space model and support vector machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="374" to="378" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Spectral-similaritybased kernel of svm for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">2154</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Locality and structure regularized low rank representation for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="911" to="923" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Classification of hyperspectral imagery based on spectral gradient, svm and spatial random forest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chunhui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lejun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiaoqing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Infrared Physics and Technology</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="61" to="69" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Deep support vector machine for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Okwuashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">E</forename><surname>Ndehedehe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page">107298</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Csa-mso3dcnn: Multiscale octave 3d cnn with channel and spatial attention for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">188</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A new spectral-spatial pseudo-3d dense network for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A fast 3d cnn for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ahmad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Spectral-spatial residual network for hyperspectral image classification: A 3-d deep learning framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chapman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="847" to="858" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reduced 3-d deep learning framework for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Laban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Abdellatif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Ebeid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Shedeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Tolba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The International Conference on Advanced Machine Learning Technologies and Applications</title>
		<imprint/>
	</monogr>
	<note>AMLTA2019) (A. E. Hassanien, A. T</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gaber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Bhatnagar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tolba</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="13" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Hyperspectral image classification using mixed convolutions and covariance pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Combining spectral unmixing and 3d/2d dense networks with early-exiting strategy for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">779</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning deep hierarchical spatial-spectral features for hyperspectral image classification based on residual 3d-2d cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page">5276</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Hybridsn: Exploring 3-d-2-d cnn feature hierarchy for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Dubey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Geoscience and Remote Sensing Letters</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="277" to="281" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nonlocal graph convolutional networks for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Spatial-spectral squeezeand-excitation residual network for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">884</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Cascaded recurrent neural networks for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ghamisi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Geoscience and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="5384" to="5394" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Two-dimensional empirical wavelet transform based supervised hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">N</forename><surname>Prabhakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Geetha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ISPRS Journal of Photogrammetry and Remote Sensing</title>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="37" to="45" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fujieda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Takayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hachisuka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.08620</idno>
		<title level="m">Wavelet convolutional neural networks</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Wavelet convolutional neural networks for texture classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Fujieda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Takayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hachisuka</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.07394</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Moving window-based double haar wavelet transform for image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2771" to="2779" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multilevel wavelet-cnn for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition workshops</title>
		<meeting>the IEEE conference on computer vision and pattern recognition workshops</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="773" to="782" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multi-scale 3d deep convolutional neural network for hyperspectral image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Image Processing (ICIP)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3904" to="3908" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
