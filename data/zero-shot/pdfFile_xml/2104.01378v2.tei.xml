<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">speechocean762: An Open-Source Non-native English Speech Corpus For Pronunciation Assessment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junbo</forename><surname>Zhang</surname></persName>
							<email>zhangjunbo1@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xiaomi Corporation</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwen</forename><surname>Zhang</surname></persName>
							<email>zhangzhiwen01@speechocean.com</email>
							<affiliation key="aff1">
								<orgName type="institution">SpeechOcean Ltd</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongqing</forename><surname>Wang</surname></persName>
							<email>wangyongqing3@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xiaomi Corporation</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Yan</surname></persName>
							<email>yanzhiyong@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xiaomi Corporation</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Song</surname></persName>
							<email>songqiong@speechocean.com</email>
							<affiliation key="aff1">
								<orgName type="institution">SpeechOcean Ltd</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukai</forename><surname>Huang</surname></persName>
							<email>huangyukai@speechocean.com</email>
							<affiliation key="aff1">
								<orgName type="institution">SpeechOcean Ltd</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Li</surname></persName>
							<email>like@speechocean.com</email>
							<affiliation key="aff1">
								<orgName type="institution">SpeechOcean Ltd</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Povey</surname></persName>
							<email>dpovey@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xiaomi Corporation</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Wang</surname></persName>
							<email>wangyujun@xiaomi.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Xiaomi Corporation</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">speechocean762: An Open-Source Non-native English Speech Corpus For Pronunciation Assessment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T12:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms: corpus</term>
					<term>computer-assisted language learning (CALL)</term>
					<term>second language (L2)</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces a new open-source speech corpus named "speechocean762" designed for pronunciation assessment use, consisting of 5000 English utterances from 250 non-native speakers, where half of the speakers are children. Five experts annotated each of the utterances at sentence-level, wordlevel and phoneme-level. A baseline system is released in open source to illustrate the phoneme-level pronunciation assessment workflow on this corpus. This corpus is allowed to be used freely for commercial and non-commercial purposes. It is available for free download from OpenSLR, and the corresponding baseline system is published in the Kaldi speech recognition toolkit.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>As an indispensable part of Computer-aided language learning (CALL), computer-aided pronunciation training (CAPT) applications with pronunciation assessment technology are widely used in foreign language learning <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> and proficiency tests <ref type="bibr" target="#b2">[3]</ref>. CAPT has been proved very useful to improve the pronunciation of the foreign language learners <ref type="bibr" target="#b3">[4]</ref>. Due to the acute shortage of qualified teachers <ref type="bibr" target="#b4">[5]</ref> and the increasing popularity of online learning, the research of pronunciation assessment is being paid more attention <ref type="bibr" target="#b5">[6]</ref>.</p><p>According to the real-world CAPT applications' features, we divide the practical pronunciation assessment tasks into three categories by the assessment granularity: sentence-level, word-level, and phoneme-level. The sentence-level assessment evaluates the whole sentence. Specifically, three types of sentence-level scores frequently appear in practical CAPT systems: accuracy, completeness, and fluency. The accuracy indicates the level of the learner pronounce each word in the utterance correctly; the completeness indicates the percentage of the words that are actually pronounced, and the fluency here is in the narrow sense <ref type="bibr" target="#b6">[7]</ref>, which focuses on whether the speaker pronounces smoothly and without unnecessary pauses. The word-level assessment has a finer scale than the sentence-level assessment. Typical word-level scores are accuracy and stress. Furthermore, as the finest granularity assessment, the phonemelevel assessment evaluates each phone's pronunciation quality in the utterance. Note that the word-level accuracy score should not be regarded as the simple average of the phone-level accuracy scores, although they have strong correlations. Take the word "above" (/@"b2v/) as an example. A foreign language learner may mispronounce it as /@"bAv/ (mispronounce /2/ to /A/ ) or as /@"k2v/ (mispronounce /b/ to /k/). For the two incorrect pronunciations, the numbers of the mispronounced phones are both one, but most people may realize that the latter mispronunciation is worse than the former.</p><p>There are some public corpora for pronunciation assessment. The ISLE Speech Corpus <ref type="bibr" target="#b7">[8]</ref> is an early and widely accepted <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b10">11]</ref> data set. It contains mispronunciation tags at the word and phoneme level, and the speakers are all from German and Italian. It is free for academic use, but it is charged for commercial use. ERJ <ref type="bibr" target="#b11">[12]</ref> is another famous non-native English corpus for pronunciation assessment, collected from 202 Japanese students annotated with phonemic and prosodic symbols. ATR-Gruhn <ref type="bibr" target="#b12">[13]</ref> is a non-native English corpus with multiple accents. The annotations of ATR-Gruhn are speaker-level proficiency ratings. TL-school <ref type="bibr" target="#b13">[14]</ref> is a corpus of speech utterances collected in northern Italy schools for assessing the performance of students learning both English and German. The data set of a spoken CALL shared task <ref type="bibr" target="#b14">[15]</ref> is available to download, where Swiss students answer prompts in English, and the students' responses are manually labeled as "accept" or "reject". L2-ARCTIC <ref type="bibr" target="#b15">[16]</ref> is a non-native English speech corpus with manual annotations, which has been used in some recent studies <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b17">18]</ref>, and it uses substitution, deletion, and insertion to annotate for the phoneme-level scoring. Sell-corpus <ref type="bibr" target="#b18">[19]</ref> is another multiple accented Chinese-English speech corpus with phoneme substitution annotations. Some corpora, such as CU-CHLOE <ref type="bibr" target="#b19">[20]</ref>, Supra-CHLOE <ref type="bibr" target="#b20">[21]</ref> and COLSEC <ref type="bibr" target="#b21">[22]</ref>, have been used in many studies <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26]</ref> but are not publicly available. Corpora for languages other than English also exist. The Tokyo-Kikuko <ref type="bibr" target="#b26">[27]</ref> is a non-native Japanese corpus with phonemic and prosodic annotations. The iCALL corpus <ref type="bibr" target="#b27">[28]</ref> is a Mandarin corpus spoken by non-native speakers of European descent with annotated pronunciation errors. The SingaKids-Mandarin <ref type="bibr" target="#b28">[29]</ref> corpus focuses on mispronunciation patterns in Singapore children's Mandarin speech.</p><p>To our knowledge, none of the existing non-native English corpora for pronunciation assessment contains all the following features:</p><p>? It is available for free download for both commercial and non-commercial purposes.</p><p>? The speaker variety encompasses young children and adults.</p><p>? The manual annotations are in many aspects at sentencelevel, word-level and phoneme-level.</p><p>To meet these features, we created this corpus to support researchers in their pronunciation assessment studies. The corpus arXiv:2104.01378v2 [cs.CL] 2 Jun 2021  is available on the OpenSLR 1 website, and the corresponding baseline system has been a part of the Kaldi speech recognition toolkit 2 .</p><p>The rest of this paper is organized as follows: Section 2 describes the audio acquisition. Section 3 details how we annotated the data for the pronunciation assessment tasks. In Section 4, a Kaldi recipe for this corpus is introduced, which illustrates how to do phoneme-level pronunciation assessment, and the experiment results are provided as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Audio Acquisition</head><p>This corpus's text script is selected from daily life text, containing about 2,600 common English words. As shown in <ref type="figure" target="#fig_0">Figure  1</ref>, speakers were asked to hold their mobile phones 20cm from their mouths and read the text as accurately as possible in a quiet 3?3 meters room. The mobile phones include the popular models of Apple, Samsung, Xiaomi, and Huawei. The number of sentences read aloud by each speaker is 20, and the total duration of the audio is about 6 hours.</p><p>The speakers are 250 English learners whose mother tongue is Mandarin. The training set and test set are divided randomly, with 125 speakers for each.</p><p>We carefully selected the speakers considering gender, age and proficiency of English. The experts roughly rated the speaker's English pronunciation proficiency into three levels: good, average, and poor. <ref type="figure" target="#fig_1">Figure 2</ref> shows the distributions of the speaker's English pronunciation proficiency. <ref type="figure" target="#fig_2">Figure 3</ref> shows the distributions of the speaker's age. The gender ratio is 1:1 for both adults and children.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Manual Annotation</head><p>Manual annotations are the essential part of this corpus. The annotations are the scores that indicate the pronunciation quality. Each utterance in this corpus is scored manually by five experts independently under the same metrics.  The "SpeechOcean uTrans" Application. Before this dialog is displayed, the experts have reached an agreement on the canonical phone sequences by voting. For the phonemelevel scoring, the expert selects the phone symbol and then makes a score of 0 or 1. If a phone symbol is not be selected, the score would be 2 as the default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Manual Scoring Metrics</head><p>The experts discussed and formulated the manual scoring metrics. <ref type="table" target="#tab_0">Table 1</ref> shows the detailed metrics. The phoneme-level score is the pronunciation accuracy of each phone. The wordlevel scores include accuracy and stress, and the sentence-level scores include accuracy, completeness, fluency and prosody. The sentence-level completeness score, which is not depicted in <ref type="table" target="#tab_0">Table 1</ref>, is the percentage of the words in the target text that are actually pronounced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Multiple Canonical Phone Sequences Problem</head><p>The phoneme-level scoring requires determining the canonical phone sequence. A problem in practice is that the canonical phone sequence may not be unique. Take the word "fast" as an example. In middle school, most Chinese students were taught that this word should be pronounced as /fA:st/, so a proper canonical phone sequence is "F AA S T" with the phone set defined by the CMU Dictionary <ref type="bibr" target="#b29">[30]</ref>. However, some speakers may pronounce this word as /faest/ following the American pronunciation. If that is the case, the phone "AA" in the canonical phone sequence "F AA S T" would be misjudged as low score. The phone is pronounced correctly 1</p><p>The phone is pronounced with a heavy accent 0</p><p>The pronunciation is incorrect or missed Word-level Accuracy 10</p><p>The pronunciation of the whole word is correct 7-9</p><p>Most phones in the word are pronounced correctly, but the word's pronunciation has heavy accents <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref> No more than 30% phones in the word are wrongly pronounced 2-3</p><p>More than 30% phones in the word are wrongly pronounced, or be mispronounced into some other word 0-1</p><p>The whole pronunciation is hard to distinguish or the word is missed Word-level Stress 10</p><p>The stress position is correct, or the word is a mono-syllable word 5</p><p>The stress position is incorrect Sentence-level Accuracy 9-10</p><p>The overall pronunciation of the sentence is excellent without obvious mispronunciation 7-8</p><p>The overall pronunciation of the sentence is good, with a few mispronunciations 5-6</p><p>The pronunciation of the sentence has many mispronunciations but it is still understandable 3-4</p><p>Awkward pronunciation with many serious mispronunciations 0-2</p><p>The pronunciation of the whole sentence is unable to understand or there is no voice Sentence-level Fluency 8-10</p><p>Coherent speech, without noticeable pauses, repetition or stammering 6-7</p><p>Coherent speech in general, with a few pauses, repetition and stammering 4-5</p><p>The speech is incoherent, with many pauses, repetition and stammering 0-3</p><p>The speaker is not able to read the sentence as a whole or there is no voice Sentence-level Prosodic 9-10</p><p>Correct intonation, stable speaking speed and rhythm <ref type="bibr" target="#b6">[7]</ref><ref type="bibr" target="#b7">[8]</ref> Nearly correct intonation at a stable speaking speed 3-6</p><p>Unstable speech speed, or the intonation is inappropriate 0-2</p><p>The reading of the sentence is too stammering to do prosodic scoring or there is no voice <ref type="figure">Figure 5</ref>: Building LG directly for the word "fast" with the canonical phone sequence voted by the experts, with skippable silence. The proper canonical phone sequence, in this case, should be "F AE S T". Our solution is as follows. For each word, experts will be shown several possible canonical phone sequences before scoring. The expert must first select the sequence that is closest to the pronunciation in her or his belief. Since there are five experts, the sequence chosen by each expert may be different, so the five experts vote to determine the final canonical sequence. Then all the experts use the same canonical phone sequence to score. The canonical phone sequences are carried as a part of the corpus's meta-information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Scoring Workflow</head><p>We developed an application named "SpeechOcean uTrans" for the experts to convieniently score the audio. The interface of the application is shown in <ref type="figure" target="#fig_3">Figure 4</ref>.</p><p>Before the scoring, the experts read the transcript and listen to the audio to get familiar with the utterance. Then the experts are required to listen to the audio repeatedly at least three times. As we mentioned, some words have more than one canonical phone sequence. For those words, experts need to choose and vote to reach an agreement on the canonical phone sequence. Then the experts score the audio following the scoring metrics expressed in <ref type="table" target="#tab_0">Table 1</ref>. If the scores seem unreasonable, for example, the word-level score is high but all the phone-level scores are low, the "SpeechOcean uTrans" application would raise a warning message to remind the expert to recheck the scores.  early to the range 0 to 10 for comparison. The sentence-level scores variety encompasses 3 to 10, while most of the wordlevel and phoneme-level scores are from 8 to 10. This behaviour stems from the fact that high sentence-level scores rely on a consistently "good" word and phoneme pronouncation. Even a single word mispronunciation can lead to a low overall score. Due to limited space, we suggest readers to refer to the available online corpus to obtain the detailed statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Score Distribution</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">The Kaldi Recipe</head><p>For demonstrating how to use this corpus to score at phonemelevel, we uploaded a recipe named "gop speechocean762" to the Kaldi toolkit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Pipeline</head><p>We believe that the classical method is more suitable for building the baseline system than the latest methods. So the pipeline is built following the neural network (NN) based goodness of pronunciation (GOP) method, which is widely used and detailed in <ref type="bibr" target="#b30">[31]</ref>. Here we only represent some specifics of implementing it on Kaldi. The GOP method requires a pre-trained acoustic model trained by native spoken data, which is trained by the "egs/librispeech/s5/local/nnet3/run tdnn.sh" script in Kaldi. The frame-level posterior matrix is generated through forward propagation on the native acoustic model, and the matrix is used for the forced alignment and the computing to obtain the GOP values and the GOP-based features, whose definitions could be found in <ref type="bibr" target="#b30">[31]</ref> as well. Then we train a regressor for each phone using the GOP-based features to predict the phonemelevel scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Alignment Graph Building without Lexicon</head><p>Kaldi's default alignment setup does not guarantee the alignment output to be identical to the canonical phone sequence voted by the experts. We continue to use the word "fast" as the example. The two possible phone sequences of this word, which are "F AA S T" and "F AE S T" specifically, are both contained in the lexicon finite state transducer (FST), shown in <ref type="figure" target="#fig_4">Figure 6</ref>.</p><p>In that case, the phone sequence produced by the alignment is uncertain. If the experts' canonical phone sequence differs from the alignment result, the scores will not be comparable with the manual scores. Therefore, we build the lexicon-to-grammar (LG) FST directly using the canonical phone sequence voted by the experts without composing the lexicon FST and the grammar FST. The process of directly constructing LG is simple: first, construct a linear FST structure, whose input labels are the canonical phone sequences voted by the experts, whereas the output labels are the corresponding words and epsilons <ref type="bibr" target="#b31">[32]</ref>. Then, add skippable silence between the words, and use the disambiguation symbol to construct the tail at the end of LG, as shown in <ref type="figure">Figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Supervised Training and Data Balancing</head><p>With the GOP-based features and the corresponding manual scores, we train a regressor for each mono phone. The model structure is a support vector regressor (SVR) <ref type="bibr" target="#b32">[33]</ref>. Besides, we train polynomial regression models with the GOP values directly for each phone as an alternative lightweight method.</p><p>A problem is that the data's phoneme-level scores are quite unbalanced, as discussed in Section 3.4. We use the high-score samples of other phones as the current phone's low-score samples to supplement the training set to address this issue. For example, a good pronunciation sample of the phone AE can be considered as a poor pronunciation sample of the phone AA. For the model training of a particular phone, we randomly select the samples of other phones with high manual scores, setting their scores as zero and add them to the training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results</head><p>For evaluating the recipe's performance, we compare the predicted scores with the manual scores to calculate the mean squared error (MSE) and Pearson correlation coefficient (PCC). The result is shown in <ref type="table" target="#tab_1">Table 2</ref>. As a baseline system, this recipe is based on the classical NN-based GOP method without using latest techniques. So the result is not quite strong, which is in line with our expectations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>We released an open-source corpus for pronunciation assessment tasks. The corpus includes both child and adult speech and is manually annotated by five experts. The annotations are at sentence-level, word-level and phoneme-level. A Kaldi recipe is released to illustrate to use of the classic GOP method for phoneme-level scoring. In the future, we will expand the recipe to word-level and sentence-level scoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgements</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Recording setup. Speakers read the text holding their mobile phones in a quiet room.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Speaker's English pronunciation proficiency distributions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Speaker's age distributions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: The "SpeechOcean uTrans" Application. Before this dialog is displayed, the experts have reached an agreement on the canonical phone sequences by voting. For the phonemelevel scoring, the expert selects the phone symbol and then makes a score of 0 or 1. If a phone symbol is not be selected, the score would be 2 as the default.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>The part related of the word "fast" in L.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 7 Figure 7 :</head><label>77</label><figDesc>shows the distribution of the sentence-level scores. The phoneme-level and word-level score distributions are shown in the Figure 8, where the phoneme-level scores are mapped lin-Sentence-level score distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 8 :</head><label>8</label><figDesc>Score distribution in different levels.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Manual Scoring Metrics</figDesc><table><row><cell>Score</cell><cell>Description</cell></row><row><cell></cell><cell>Phoneme-level Accuracy</cell></row><row><cell>2</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Performance of the recipe</figDesc><table><row><cell></cell><cell cols="2">MSE PCC</cell></row><row><cell>GOP value</cell><cell>0.69</cell><cell>0.25</cell></row><row><cell>GOP-based feature</cell><cell>0.16</cell><cell>0.45</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://www.openslr.org/101 2 https://github.com/kaldi-asr/kaldi/tree/ master/egs/gop_speechocean762</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The authors would like to thank Jan Trmal for uploading this corpus to OpenSLR. The authors would also like to thank Heinrich Dinkel and Qinghua Wu for their helpful suggestions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">References</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Eduspeak?: A speech recognition and pronunciation scoring toolkit for computer-aided language learning applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Franco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rossier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rao Gadde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shriberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Abrash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Precoda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Language Testing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="401" to="418" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The training skills of college students&apos; oral English based on the computer-aided language learning environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Journal of Physics: Conference Series</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1578</biblScope>
			<biblScope unit="page">12040</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Using spoken language technology for generating feedback to prepare for the TOEFL iBT? test: a user perception study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zechner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Assessment in Education: Principles, Policy &amp; Practice</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On optimization of non-intelligence factors in college English teaching in computer-aided language learning environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in Applied Mechanics and Materials</title>
		<imprint>
			<biblScope unit="volume">644</biblScope>
			<biblScope unit="page" from="6124" to="6127" />
			<date type="published" when="2014" />
			<publisher>Trans Tech Publ</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Nuance in the noise: The complex reality of teacher shortages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">P</forename><surname>Mcvey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Trinidad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bellwether Education Partners</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Improving English phoneme pronunciation with automatic speech recognition using voice chatbot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">K</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-T</forename><surname>Lau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">W</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-K</forename><surname>Lam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-J</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-K</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Technology in Education</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="88" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The lexical element in spoken second language fluency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lennon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Perspectives on fluency</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="25" to="42" />
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The ISLE corpus of non-native spoken English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Menzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Atwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bonaventura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Herron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Howarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Souter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of LREC 2000: Language Resources and Evaluation Conference</title>
		<meeting>LREC 2000: Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="957" to="964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Using the HTK speech recogniser to anlayse prosody in a corpus of german spoken learner&apos;s English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Atwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">UCREL Technical Paper number 16. Special issue. Proceedings of the Corpus Linguistics</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page" from="591" to="598" />
		</imprint>
		<respStmt>
			<orgName>Lancaster University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The automatic assessment of non-native prosody: Combining classical prosodic analysis with acoustic modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>H?nig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Bocklet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Riedhammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Batliner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>N?th</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Thirteenth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mixtures of deep neural experts for automated speech scoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Papi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Trentin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gretter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matassoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Falavigna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech 2020</title>
		<meeting>Interspeech 2020</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3845" to="3849" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Development of English speech database read by Japanese to support call research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Minematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tomiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yoshimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dantsuji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Makino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ICA</title>
		<meeting>ICA</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="557" to="560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A multi-accent nonnative English database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gruhn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cincarek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ASJ</title>
		<imprint>
			<biblScope unit="page" from="195" to="196" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">TLT-school: a corpus of non native children speech</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gretter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matassoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bann?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Daniele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 12th Language Resources and Evaluation Conference</title>
		<meeting>The 12th Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="378" to="385" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Overview of the 2017 spoken call shared task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gerlach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rayner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Russel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Strik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Speech and Language Technology in Education (SLaTE)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">L2-ARCTIC: A non-native English speech corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sonsaat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Silpachai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Lucic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chukharev-Hudilainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Levis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gutierrez-Osuna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc</title>
		<imprint>
			<biblScope unit="page" from="2783" to="2787" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">An end-to-end mispronunciation detection system for L2 English speech leveraging novel anti-phone modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-C</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><surname>Hung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Interspeech</title>
		<meeting>Interspeech</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3032" to="3036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">SED-MDD: Towards sentence dependent end-to-end mispronunciation detection and diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3492" to="3496" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Sell-corpus: an open source multiple accented chinese-english speech corpus for l2 english learning assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7425" to="7429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Mispronunciation detection and diagnosis in L2 English speech using multidistribution deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on Audio, Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="207" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Design and collection of an L2 English corpus with a suprasegmental focus for chinese learners of English</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICPhS</title>
		<imprint>
			<biblScope unit="page" from="1210" to="1213" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Construction and data analysis of a Chinese learner spoken English corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Wei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Shanhai Foreign Languse Eduacation Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Improvement of segmental mispronunciation detection with prior knowledge extracted from large L2 speech corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Twelfth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Lexical stress detection for L2 English speech using deep belief networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Interspeech</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1811" to="1815" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Intonation classification for L2 English speech using multi-distribution deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="18" to="33" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Automatic lexical stress and pitch accent detection for L2 English speech using multi-distribution deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="page" from="28" to="36" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Development of Japanese speech database read by non-native speakers for constructing call system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nishina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yoshimura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Saita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Takai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Maekawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Minematsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakagawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Makino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dantsuji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICA</title>
		<meeting>ICA</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="561" to="564" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">iCALL corpus: Mandarin chinese spoken by non-native speakers of european descent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixteenth Annual Conference of the International Speech Communication Association</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Singapore mandarin: Its positioning, internal structure and corpus planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Paper presented atthe 22nd Annual Conference of the Southeast Asian Linguistics Society</title>
		<meeting><address><addrLine>Agay, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The CMU pronunciation dictionary</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Weide</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Improved mispronunciation detection with deep neural network trained acoustic models and transfer learning based logistic regression classifiers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">K</forename><surname>Soong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Speech Communication</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="154" to="166" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Speech recognition with weighted finite-state transducers,&quot; in Springer handbook of speech processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Riley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="559" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Support vector regression machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Drucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="155" to="161" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
