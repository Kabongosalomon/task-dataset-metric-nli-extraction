<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">First Order Generative Adversarial Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Calvin</forename><surname>Seward</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Urs</forename><surname>Bergmann</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolay</forename><surname>Jetchev</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
						</author>
						<title level="a" type="main">First Order Generative Adversarial Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:48+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>GANs excel at learning high dimensional distributions, but they can update generator parameters in directions that do not correspond to the steepest descent direction of the objective. Prominent examples of problematic update directions include those used in both Goodfellow's original GAN and the WGAN-GP. To formally describe an optimal update direction, we introduce a theoretical framework which allows the derivation of requirements on both the divergence and corresponding method for determining an update direction, with these requirements guaranteeing unbiased minibatch updates in the direction of steepest descent. We propose a novel divergence which approximates the Wasserstein distance while regularizing the critic's first order information. Together with an accompanying update direction, this divergence fulfills the requirements for unbiased steepest descent updates. We verify our method, the First Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a new state of the art on the One Billion Word language generation task. Code to reproduce experiments is available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Generative adversarial networks (GANs) <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref> excel at learning generative models of complex distributions, such as images <ref type="bibr" target="#b16">Ledig et al., 2017)</ref>, textures <ref type="bibr" target="#b12">(Jetchev et al., 2016;</ref><ref type="bibr" target="#b3">Bergmann et al., 2017;</ref><ref type="bibr" target="#b13">Jetchev et al., 2017)</ref>, and even texts <ref type="bibr" target="#b10">(Gulrajani et al., 2017;</ref><ref type="bibr" target="#b11">Heusel et al., 2017)</ref>.</p><p>GANs learn a generative model G that maps samples from multivariate random noise into a high dimensional space. The goal of GAN training is to update G such that the generative model approximates a target probability distri- bution. In order to determine how close the generated and target distributions are, a class of divergences, the so-called adversarial divergences was defined and explored by <ref type="bibr" target="#b18">(Liu et al., 2017)</ref>. This class is broad enough to encompass most popular GAN methods such as the original GAN <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref>, f -GANs <ref type="bibr" target="#b26">(Nowozin et al., 2016)</ref>, moment matching networks <ref type="bibr" target="#b17">(Li et al., 2015)</ref>, Wasserstein GANs  and the tractable version thereof, the WGAN-GP <ref type="bibr" target="#b10">(Gulrajani et al., 2017)</ref>.</p><p>GANs learn a generative model with distribution Q by minimizing an objective function ? (P Q) measuring the similarity between target and generated distributions P and Q. In most GAN settings, the objective function to be minimized is an adversarial divergence <ref type="bibr" target="#b18">(Liu et al., 2017)</ref>, where a critic function is learned that distinguishes between target and generated data. For example, in the classic GAN <ref type="bibr" target="#b9">(Goodfellow et al., 2014</ref>) the critic f classifies data as real or generated, and the generator G is encouraged to generate samples that f will classify as real.</p><p>Unfortunately in GAN training, the generated distribution often fails to converge to the target distribution. Many popular GAN methods are unsuccessful with toy examples, for example failing to generate all modes of a mixture of Gaussians <ref type="bibr" target="#b32">(Srivastava et al., 2017;</ref><ref type="bibr" target="#b22">Metz et al., 2017)</ref> or failing to learn the distribution of data on a one-dimensional line in a high dimensional space <ref type="bibr" target="#b8">(Fedus et al., 2017)</ref>. In these situations, updates to the generator don't significantly reduce the divergence between generated and target distributions; if there always was a significant reduction in the divergence then the generated distribution would converge to the target.</p><p>The key to successful neural network training lies in the ability to efficiently obtain unbiased estimates of the gradients of a network's parameters with respect to some loss. With GANs, this idea can be applied to the generative setting. There, the generator G is parameterized by some values ? ? R m . If an unbiased estimate of the gradient of the divergence between target and generated distributions with respect to ? can be obtained during mini-batch learning, then SGD can be applied to learn G.</p><p>In GAN learning, intuition would dictate updating the generated distribution by moving ? in the direction of steepest descent ?? ? ? (P Q ? ). Unfortunately, ?? ? ? (P Q ? ) is generally intractable, therefore ? is updated according to arXiv:1802.04591v2 <ref type="bibr">[cs.</ref>LG] 7 Jun 2018 First Order Generative Adversarial Networks a tractable method; in most cases a critic f is learned and the gradient of the expected critic value ? ? E Q ? [f ] is used as the update direction for ?. Usually, this update direction and the direction of steepest descent ?? ? ? (P Q ? ), don't coincide and therefore learning isn't optimal. As we see later, popular methods such as WGAN-GP <ref type="bibr" target="#b10">(Gulrajani et al., 2017)</ref> are affected by this issue.</p><p>Therefore we set out to answer a simple but fundamental question: Is there an adversarial divergence and corresponding method that produces unbiased estimates of the direction of steepest descent in a mini-batch setting?</p><p>In this paper, under reasonable assumptions, we identify a path to such an adversarial divergence and accompanying update method. Similar to the WGAN-GP, this divergence also penalizes a critic's gradients, and thereby ensures that the critic's first order information can be used directly to obtain an update direction in the direction of steepest descent.</p><p>This program places four requirements on the adversarial divergence and the accompanying update rule for calculating the update direction that haven't to the best of our knowledge been formulated together. This paper will give rigorous definitions of these requirements, but for now we suffice with intuitive and informal definitions:</p><p>A. the divergence used must decrease as the target and generated distributions approach each other. For example, if we define the trivial distance between two probability distribution to be 0 if the distributions are equal, and 1 otherwise, i.e. ? trivial (P Q) := 0 P = Q 1 otherwise then even as Q gets close to P, ? trivial (P Q) doesn't change. Without this requirement, ? ? ? (P Q ? ) = 0 and every direction is a "direction of steepest descent,"</p><p>B. critic learning must be tractable, C. the gradient ? ? ? (P Q ? ) and the result of an update rule must be well defined, D. the optimal critic enables an update which is an estimate of ?? ? ? (P Q ? ).</p><p>In order to formalize these requirements, we define in Section 2 the notions of adversarial divergences and optimal critics. In Section 3 we will apply the adversarial divergence paradigm and begin to formalize the requirements above and better understand existing GAN methods. The last requirement is defined precisely in Section 4 where we explore criteria for an update rule guaranteeing a low variance unbiased estimate of the true gradient ?? ? ? (P Q ? ).</p><p>After stating these conditions, we devote Section 5 to defining a divergence, the Penalized Wasserstein Divergence that fulfills the first two basic requirements. In this setting, a critic is learned, that similarly to the WGAN-GP critic, pushes real and generated data as far apart as possible while being penalized if the critic violates a Lipschitz condition.</p><p>As we will discover, an optimal critic for the Penalized Wasserstein Divergence between two distributions need not be unique. In fact, this divergence only specifies the values that the optimal critic assumes on the supports of generated and target distributions. Therefore, for many distributions, multiple critics with different gradients on the support of the generated distribution can all be optimal.</p><p>We apply this insight in Section 6 and add a gradient penalty to define the First Order Penalized Wasserstein Divergence. This divergence enforces not just correct values for the critic, but also ensures that the critic's gradient, its first order information, assumes values that allow for an easy formulation of an update rule. Together, this divergence and update rule fulfill all four requirements.</p><p>We hope that this gradient penalty trick will be applied to other popular GAN methods and ensure that they too return better generator updates. Indeed, <ref type="bibr" target="#b8">(Fedus et al., 2017)</ref> improves existing GAN methods by adding a gradient penalty.</p><p>Finally in Section 7, the effectiveness of our method is demonstrated by generating images and texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Notation, Definitions and Assumptions</head><p>In <ref type="bibr" target="#b18">(Liu et al., 2017)</ref> an adversarial divergence is defined: Definition 1 (Adversarial Divergence). Let X be a topological space, C(X 2 ) the set of all continuous real valued functions over the Cartesian product of X with itself and set G ? C(X 2 ), G = ?. An adversarial divergence ? (? ?) over X is a function</p><formula xml:id="formula_0">P(X) ? P(X) ? R ? {+?} (P, Q) ? ? (P Q) = sup g?G E P?Q [g].</formula><p>The function class G ? C(X 2 ) must be carefully selected if ? (? ?) is to be reasonable. For example, if G = C(X 2 ) then the divergence between two Dirac distributions ? (? 0 ? 1 ) = ?, and if G = {0}, i.e. G contains only the constant function which assumes zero everywhere, then ? (? ?) = 0.</p><p>Many existing GAN procedures can be formulated as an adversarial divergence. For example, setting</p><formula xml:id="formula_1">G = {x, y ? log(u(x)) + log(1 ? u(y)) | u ? V} V = (0, 1) X ? C(X) 1 results in ? G (P Q) = sup g?G E P?Q [g]</formula><p>, the divergence in Goodfellow's original GAN <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref>. See <ref type="bibr" target="#b18">(Liu et al., 2017)</ref> for further examples.</p><p>For convenience, we'll restrict ourselves to analyzing a special case of the adversarial divergence (similar to Theorem 4 of <ref type="bibr" target="#b18">(Liu et al., 2017)</ref>), and use the notation:</p><formula xml:id="formula_2">Definition 2 (Critic Based Adversarial Divergence). Let X be a topological space, F ? C(X), F = ?. Further let f ? F, m f : X ? X ? R, m f : (x, y) ? m 1 (f (x)) ? m 2 (f (y)) and r f ? C(X 2 ). Then define ? : P(X) ? P(X) ? F ? R ? {+?} (P, Q, f ) ? ? (P Q; f ) = E P?Q [m f ? r f ]<label>(1)</label></formula><p>and set ? (P Q) = sup f ?F ? (P Q; f ).</p><p>For example, the ? G from above can be equivalently defined by setting F = (0, 1) X ? C(X), m 1 (x) = log(x), m 2 (x) = log(1 ? x) and r f = 0. Then</p><formula xml:id="formula_3">? G (P Q) = sup f ?F E P [m f ? r f ]<label>(2)</label></formula><p>is a critic based adversarial divergence.</p><p>An example with a non-zero r f is the WGAN-GP <ref type="bibr" target="#b10">(Gulrajani et al., 2017)</ref>, which is a critic based adversarial divergence when F = C 1 (X), the set of all differentiable real functions on X, m 1 (x) = m 2 (x) = x, ? &gt; 0 and</p><formula xml:id="formula_4">r f (x, y) = ?E ??U ([0,1]) [( ? z f (z)| ?x+(1??)y ? 1) 2 ].</formula><p>Then the WGAN-GP divergence ? I (P Q) is:</p><formula xml:id="formula_5">? I (P Q) = sup f ?F ? I (P Q; f ) = sup f ?F E P?Q [m f ? r f ]. (3)</formula><p>While Definition 1 is more general, Definition 2 is more in line with most GAN models. In most GAN settings, a critic in the simpler C(X) space is learned that separates real and generated data while reducing some penalty term r f which depends on both real and generated data. For this reason, we use exclusively the notation from Definition 2.</p><p>One desirable property of an adversarial divergence is that ? (P * P) obtains its infimum if and only if P * = P, leading to the following definition adapted from <ref type="bibr" target="#b18">(Liu et al., 2017)</ref>: Definition 3 (Strict adversarial divergence). Let ? be an adversarial divergence over a topological space X. ? is called a strict adversarial divergence if for any P, P * ? P(X), ? (P * P) = inf P ?P(X) ? (P * P ) ? P * = P</p><p>In order to analyze GANs that minimize a critic based adversarial divergence, we introduce the set of optimal critics.</p><p>Definition 4 (Optimal Critic, OC ? (P, Q)). Let ? be a critic based adversarial divergence over a topological space X and P, Q ? P(X), F ? C(X), F = ?. Define OC ? (P, Q) to be the set of critics in F that maximize ? (P Q; ?). That is</p><formula xml:id="formula_6">OC ? (P, Q) := {f ? F | ? (P Q; f ) = ? (P Q)}.</formula><p>Note that OC ? (P, Q) = ? is possible, . In this paper, we will always assume that if OC ? (P, Q) = ?, then an optimal critic f * ? OC ? (P, Q) is known. Although is an unrealistic assumption, see <ref type="bibr" target="#b5">(Bi?kowski et al., 2018)</ref>, it is a good starting point for a rigorous GAN analysis. We hope further works can extend our insights to more realistic cases of approximate critics.</p><p>Finally, we assume that generated data is distributed according to a probability distribution Q ? parameterized by ? ? ? ? R m satisfying the mild regularity Assumption 1. Furthermore, we assume that P and Q both have compact and disjoint support in Assumption 2. Although we conjecture that weaker assumptions can be made, we decide for the stronger assumptions to simplify the proofs. Assumption 1 (Adapted from ). Let ? ? R m . We say Q ? ? P(X), ? ? ? satisfies assumption 1 if there is a locally Lipschitz function g : ??R d ? X which is differentiable in the first argument and a distribution Z with bounded support in R d such that for all ? ? ? it holds</p><formula xml:id="formula_7">Q ? ? g(?, z) where z ? Z.</formula><p>Assumption 2 (Compact and Disjoint Distributions). Using ? ? R m from Assumption 1, we say that P and (Q ? ) ??? satisfies Assumption 2 if for all ? ? ? it holds that the supports of P and Q ? are compact and disjoint.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Requirements Derived From Related Work</head><p>With the concept of an Adversarial Divergence now formally defined, we can investigate existing GAN methods from an Adversarial Divergence minimization standpoint. During the last few years, weaknesses in existing GAN frameworks have been highlighted and new frameworks have been proposed to mitigate or eliminate these weaknesses. In this section we'll trace this history and formalize requirements for adversarial divergences and optimal updates.</p><p>Although using two competing neural networks for unsupervised learning isn't a new concept <ref type="bibr" target="#b30">(Schmidhuber, 1992)</ref>, recent interest in the field started when <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref> generated images with the divergence ? G defined in Eq. 2. However,  shows if P, Q ? have compact disjoint support then ? ? ? G (P Q ? ) = 0, preventing the use of gradient based learning methods.</p><p>In response to this impediment, the Wasserstein GAN was proposed in  with the divergence:</p><formula xml:id="formula_8">? W (P Q) = sup f L ?1 E x?P [f (x)] ? E x ?Q [f (x )]</formula><p>where f L is the Lipschitz constant of f . The following example shows the advantage of ? W . Consider a series of Dirac measures (? 1 n ) n&gt;0 . Then ? W (? 0 ? 1 n ) = 1 n while ? G (? 0 ? 1 n ) = 1. As ? 1 n approaches ? 0 , the Wasserstein divergence decreases while ? G (? 0 ? 1 n ) remains constant. This issue is explored in <ref type="bibr" target="#b18">(Liu et al., 2017)</ref> by creating a weak ordering, the so-called strength, of divergences. A divergence ? 1 is said to be stronger than ? 2 if for any sequence of probability measures (P n ) n?N and any target probability measure P * the convergence ? 1 (P * P n )</p><formula xml:id="formula_9">n?? ?? inf P?P(X) ? 1 (P * P) implies ? 2 (P * P n ) n?? ?? inf P?P(X) ? 2 (P * P).</formula><p>The divergences ? 1 and ? 2 are equivalent if ? 1 is stronger than ? 2 and ? 2 is stronger than ? 1 . The Wasserstein distance ? W is the weakest divergence in the class of strict adversarial divergences <ref type="bibr" target="#b18">(Liu et al., 2017)</ref>, leading to the following requirement:</p><formula xml:id="formula_10">Requirement 1 (Equivalence to ? W ). An adversarial di- vergence ? is said to fulfill Requirement 1 if ? is a strict adversarial divergence which is weaker than ? W .</formula><p>The issue of the zero gradients was side stepped in (Goodfellow et al., 2014) (and the option more rigorously explored in <ref type="bibr" target="#b8">(Fedus et al., 2017)</ref></p><formula xml:id="formula_11">) by not updating with ?? ? E x ?Q ? [log(1 ? f (x ))] but instead using the gradi- ent ? ? E x ?Q ? [f (x )].</formula><p>As will be shown in Section 4, this update direction doesn't generally move ? in the direction of steepest descent.</p><p>Although using the Wasserstein distance as a divergence between probability measures solves many theoretical problems, it requires that critics are Lipschitz continuous with Lipschitz constant 1. Unfortunately, no tractable algorithm has yet been found that is able to learn the optimal Lipschitz continuous critic (or a close approximation thereof). This is due in part to the fact that if the critic is parameterized by a neural network f ? , ? ? ? C ? R c , then the set of admissible parameters {? ? ? C | f ? L ? 1} is highly non-convex. Thus critic learning is a non-convex optimization problem (as is generally the case in neural network learning) with non-convex constraints on the parameters. Since neural network learning is generally an unconstrained optimization problem, adding complex nonconvex constraints makes learning intractable with current methods. Thus, finding an optimal Lipschitz continuous critic is a problem that can not yet be solved, leading to the second requirement:</p><p>Requirement 2 (Convex Admissible Critic Parameter Set). Assume ? is a critic based adversarial divergence where critics are chosen from a set F. Assume further that in training, a parameterization ? ? R c of the critic function f ? is learned. The critic based adversarial divergence ? is said to fulfill requirement 2 if the set of admissible parameters {? ? R c | f ? ? F} is convex.  <ref type="bibr" target="#b9">(Goodfellow et al., 2014)</ref>, WGAN , WGAN-GP <ref type="bibr" target="#b10">(Gulrajani et al., 2017)</ref>, WGAN-LP <ref type="bibr" target="#b27">(Petzka et al., 2018)</ref>, DRAGAN <ref type="bibr" target="#b14">(Kodali et al., 2017)</ref>  <ref type="bibr" target="#b10">(Gulrajani et al., 2017)</ref> that since a Wasserstein critic must have gradients of norm at most 1 everywhere, a reasonable strategy would be to transform the constrained optimization into an unconstrained optimization problem by penalizing the divergence when a critic has nonunit gradients. With this strategy, the so-called Improved Wasserstein GAN or WGAN-GP divergence defined in Eq. 3 is obtained.</p><p>The generator parameters are updated by training an optimal critic f * and updating with ? ? E Q ? [f * ]. Although this method has impressive experimental results, it is not yet ideal. <ref type="bibr" target="#b27">(Petzka et al., 2018)</ref> showed that an optimal critic for ? I has undefined gradients on the support of the generated distribution Q ? . Thus, the update direction ? ? E Q ? [f * ] is undefined; even if a direction was chosen from the subgradient field (meaning the update direction is defined but random) the update direction won't generally point in the direction of steepest gradient descent. This naturally leads to the next requirement:</p><p>Requirement 3 (Well Defined Update Rule). An update rule is said to fulfill Requirement 3 on a target distribution P and a family of generated distributions (Q ? ) ??? if for every ? ? ? the update rule at P and Q ? is well defined.</p><p>Note that kernel methods such as <ref type="bibr" target="#b7">(Dziugaite et al., 2015)</ref> and <ref type="bibr" target="#b17">(Li et al., 2015)</ref> provide exciting theoretical guarantees and may well fulfill all four requirements. Since these guarantees come at a cost in scalability, we won't analyze them further.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Correct Update Rule Requirement</head><p>In the previous section, we stated a bare minimum requirement for an update rule (namely that it is well defined). In this section, we'll go further and explore criteria for a "good" update rule. For example in Lemma 8 in Section A of Appendix, it is shown that there exists a target P and a family of generated distributions (Q ? ) ??? fulfilling Assumptions 1 and 2 such that for the optimal critic f *</p><formula xml:id="formula_12">?0 ? OC ? I (P, Q ?0 ) there is no ? ? R so that ? ? ? I (P Q ? )| ?0 = ?? ? E Q ? [f * ?0 ]| ?0</formula><p>for all ? 0 ? ? if all terms are well defined. Thus, the update rule used in the WGAN-GP setting, although well defined for this specific P and Q ?0 , isn't guaranteed to move ? in the direction of steepest descent. In fact, <ref type="bibr" target="#b21">(Mescheder et al., 2018)</ref> shows that the WGAN-GP does not converge for specific classes of distributions. Therefore, the question arises what well defined update rule also moves ? in the direction of steepest descent?</p><p>The most obvious candidate for an update rule is simply use the direction ?? ? ? (P Q ? ), but since in the adversarial divergence setting ? (P Q ? ) is the supremum over a set of infinitely many possible critics, calculating ?? ? ? (P Q ? ) directly is generally intractable.</p><p>One strategy to address this issue is to use an envelope theorem <ref type="bibr" target="#b23">(Milgrom &amp; Segal, 2002)</ref>. Assuming all terms are well defined, then for every optimal critic f *</p><formula xml:id="formula_13">? OC ? (P, Q ?0 ) it holds ? ? ? (P Q ? )| ?0 = ? ? ? (P Q ? ; f * )| ?0 .</formula><p>This strategy is outlined in detail in  when proving the Wasserstein GAN update rule, and explored in the context of the classic GAN divergence ? G in ).</p><p>Yet in many GAN settings, <ref type="bibr" target="#b9">(Goodfellow et al., 2014;</ref><ref type="bibr" target="#b29">Salimans et al., 2016;</ref><ref type="bibr" target="#b27">Petzka et al., 2018)</ref>, the update rule is to train an optimal critic f * and then take a step in the direction of ? ? E Q ? [f * ]. In the critic based adversarial divergence setting (Definition 2), a direct result of Eq. 1 together with Theorem 1 from <ref type="bibr" target="#b23">(Milgrom &amp; Segal, 2002)</ref> is that for every f * ? OC ? (P, Q ?0 )</p><formula xml:id="formula_14">? ? ? (P Q ? )| ?0 = ? ? ? (P Q; f * ) = ?? ? (E Q ? [m 2 (f * )] + E P?Q ? [r f * ])| ?0<label>(4)</label></formula><p>when all terms are well defined. Thus, the update direction ? ? E Q ? [f * ] only points in the direction of steepest descent for special choices of m 2 and r f . One such example is the Wasserstein GAN where m 2 (x) = x and r f = 0.</p><p>Most popular GAN methods don't employ functions m 2 and r f such that the update direction ? ? E Q ? [f * ] points in the direction of steepest descent. For example, with the classic GAN, m 2 (x) = log(1 ? x) and r f = 0, so the update</p><formula xml:id="formula_15">direction ? ? E Q ? [f * ] clearly is not oriented in the direction of steepest descent ? ? E Q ? [log(1 ? f * )].</formula><p>The WGAN-GP is similar, since as we see in Lemma 8 in Appendix, Section A,</p><formula xml:id="formula_16">? ? E P?Q ? [r f * ] is not generally a multiple of ? ? E Q ? [f * ].</formula><p>The question arises why this direction is used instead of directly calculating the direction of steepest descent? Using the correct update rule in Eq. 4 above involves estimating ? ? E P?Q ? [r f * ], which requires sampling from both P and Q ? . GAN learning happens in mini-batches, therefore ? ? E P?Q ? [r f * ] isn't calculated directly, but estimated based on samples which can lead to variance in the estimate.</p><p>To analyze this issue, we use the notation from <ref type="bibr" target="#b2">(Bellemare et al., 2017)</ref> where X m := X 1 , X 2 , . . . , X m are samples from P and the empirical distributionP m is defined b?</p><formula xml:id="formula_17">P m :=P m (X m ) := 1 m m i=1 ? Xi . Further let V Xm?P be the element-wise variance. Now with mini-batch learning we get 2 V Xm?P [? ? EP m ?Q ? [m f * ? r f * ]| ?0 ] = V Xm?P [? ? (EP m [m 1 (f * )] ? E Q ? [m 2 (f * )] ? EP m?Q? [r f * ])| ?0 ] = V Xm?P [? ? EP m ?Q ? [r f * ]| ?0 ]. Therefore, estimation of ? ? E P?Q ? [r f * ] is an extra source of variance.</formula><p>Our solution to both these problems chooses the critic based adversarial divergence ? in such a way that there exists a ? ? R so that for all optimal critics f * ? OC ? (P, Q ?0 ) it holds</p><formula xml:id="formula_18">? ? E P?Q ? [r f * ]| ?0 ? ?? ? E Q ? [m 2 (f * )]| ?0 .<label>(5)</label></formula><p>In Theorem 2 we see conditions on P, Q ? such that equality holds. Now using Eq. 5 we see that</p><formula xml:id="formula_19">? ? ? (P Q ? )| ?0 = ?? ? (E Q ? [m 2 (f * )] + E P?Q ? [r f * ])| ?0 ? ?? ? (E Q ? [m 2 (f * )] + ?E Q ? [m 2 (f * )])| ?0 = ?(1 + ?)? ? E Q ? [m 2 (f * )]| ?0 making (1 + ?)? ? E Q ? [m 2 (f * )</formula><p>] a low variance update approximation of the direction of steepest descent.</p><p>We're then able to have the best of both worlds. On the one hand, when r f serves as a penalty term, training of a critic neural network can happen in an unconstrained optimization fashion like with the WGAN-GP. At the same time, the direction of steepest descent can be approximated by calculating ? ? E Q ? [m 2 (f * )], and as in the Wasserstein GAN we get reliable gradient update steps.</p><p>With this motivation, Eq. 5 forms the basis of our final requirement:</p><p>Requirement 4 (Low Variance Update Rule). An adversarial divergence ? is said to fulfill requirement 4 if ? is a critic based adversarial divergence and for every optimal critic f * ? OC ? (P, Q ?0 ) fulfills Eq. 5.</p><p>2 Because the first expectation doesn't depend on ?, ? ? EP m [m1(f * )] = 0. In the same way, because the second expectation doesn't depend on the mini-batch Xm sampled,</p><formula xml:id="formula_20">V Xm?P [E Q ? [m2(f * )]] = 0.</formula><p>It should be noted that the WGAN-GP achieves impressive experimental results; we conjecture that in many cases ? ? E Q ? [f * ] close enough to the true direction of steepest descent. Nevertheless, as the experiments in Section 7 show, our gradient estimates lead to better convergence in a challenging language modeling task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Penalized Wasserstein Divergence</head><p>We now attempt to find an adversarial divergence that fulfills all four requirements. We start by formulating an adversarial divergence ? P and a corresponding update rule than can be shown to comply with Requirements 1 and 2. Subsequently in Section 6, ? P will be refined to make its update rule practical and conform to all four requirements.</p><p>The divergence ? P is inspired by the Wasserstein distance, there for an optimal critic between two Dirac distributions</p><formula xml:id="formula_21">f * ? OC ? (? a , ? b ) it holds f (a) ? f (b) = |a ? b|. Now if we look at ? simple (? a ? b ) := sup f ?F f (a) ? f (b) ? (f (a) ? f (b)) 2 |a ? b|<label>(6)</label></formula><p>it's easy to calculate that ? simple (? a ? b ) = 1 4 |a ? b|, which is the same up to a constant (in this simple setting) as the Wasserstein distance, without being a constrained optimization problem. See <ref type="figure" target="#fig_1">Figure 1</ref> for an example.</p><p>This has another intuitive explanation. Because Eq. 6 can be reformulated as</p><formula xml:id="formula_22">? simple (? a ? b ) = sup f ?F f (a)?f (b)?|a?b| f (a) ? f (b) |a ? b| 2</formula><p>which is a tug of war between the objective f (a) ? f (b) and the squared Lipschitz penalty |f (a)?f (b)| |a?b| weighted by |a?b|. This |a ? b| term is important (and missing from <ref type="bibr" target="#b10">(Gulrajani et al., 2017)</ref>, <ref type="bibr" target="#b27">(Petzka et al., 2018)</ref>) because otherwise the slope of the optimal critic between a and b will depend on |a ? b|.</p><p>The penalized Wasserstein divergence ? P is a straightforward adaptation of ? simple to the multi dimensional case.</p><p>Definition 5 (Penalized Wasserstein Divergence). Assume X ? R n and P, Q ? P(X) are probability measures over X, ? &gt; 0 and F = C 1 (X). Set</p><formula xml:id="formula_23">? P (P Q; f ) := E x?P [f (x)] ? E x ?Q [f (x )] ?? E x?P,x ?Q (f (x) ? f (x )) 2 x ? x .</formula><p>Define the penalized Wasserstein divergence as</p><formula xml:id="formula_24">? P (P Q) = sup f ?F ? P (P Q; f ).</formula><p>This divergence is updated by picking an optimal critic f * ? OC ? P (P, Q ?0 ) and taking a step in the direction of</p><formula xml:id="formula_25">? ? E Q ? [f * ]| ?0 .</formula><p>This formulation is similar to the WGAN-GP <ref type="bibr" target="#b10">(Gulrajani et al., 2017)</ref>, restated here in Eq. 3.</p><p>Theorem 1. Assume X ? R n , and P, Q ? ? P(X) are probability measures over X fulfilling Assumptions 1 and 2. Then for every ? 0 ? ? the Penalized Wasserstein Divergence with it's corresponding update direction fulfills Requirements 1 and 2.</p><p>Further, there exists an optimal critic f * ? OC ? P (P, Q ?0 ) that fulfills Eq. 5 and thus Requirement 4.</p><p>Proof. See Appendix, Section A.</p><p>Note that this theorem isn't unique to ? P . For example, for the penalty in Eq. 8 of <ref type="bibr" target="#b27">(Petzka et al., 2018)</ref> we conjecture that a similar result can be shown. The divergence ? P is still very useful because, as will be shown in the next section, ? P can be modified slightly to obtain a new critic ? F , where every optimal critic fulfills Requirements 1 to 4.</p><p>Since ? P only constrains the value of a critic on the supports of P and Q ? , many different critics are optimal, and in general ? ? E Q ? [f * ] depends on the optimal critic choice and is thus is not well defined. With this, Requirements 3 and 4 are not fulfilled. See <ref type="figure" target="#fig_1">Figure 1</ref> for a simple example.</p><p>In theory, ? P 's critic could be trained with a modified sampling procedure so that ? ? E Q ? [f * ] is well defined and Eq. 5 holds, as is done in both <ref type="bibr" target="#b14">(Kodali et al., 2017)</ref> and <ref type="bibr" target="#b33">(Unterthiner et al., 2018)</ref>. By using a method similar to <ref type="bibr" target="#b4">(Bishop et al., 1998)</ref>, one can minimize the divergence ? P (P,Q ? ) whereQ ? is data equal to x + where x is sampled from Q ? and is some zero-mean uniform distributed noise. In this way the support ofQ ? lives in the full space X and not the submanifold supp(Q ? ). Unfortunately, while this method works in theory, the number of samples required for accurate gradient estimates scales with the dimensionality of the underlying space X, not with the dimensionality of data or generated submanifolds supp(P) or supp(Q ? ). In response, we propose the First Order Penalized Wasserstein Divergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">First Order Penalized Wasserstein Divergence</head><p>As was seen in the last section, since ? P only constrains the value of optimal critics on the supports of P and Q ? , the gradient ? ? E Q ? [f * ] is not well defined. A natural method to refine ? P to achieve a well defined gradient is to enforce two things:  , and that so d d? ?P (?0 ? ? ) = 1 2 . Let ?0 = 0.5; our goal is to calculate d d? ?P (?0 ? ? )| ?=? 0 via our update rule. Since multiple critics are optimal for ?P (?0 ? ? ), we will explore how the choice of optimal critic affects the update. In Subfigure 1a, we chose the first order optimal critic f * ? 0 (</p><formula xml:id="formula_26">x) = x(?4x 2 +4x?2), and d d? ?P (?0 ? ? )| ?=? 0 = ? 1 2 d d? E ? ? [f * ? 0</formula><p>] ?=? 0 and the update rule is correct (see how the red, black and green lines all intersect in one point). In Subfigure 1b, the optimal critic is set to f * ? 0 (x) = ?2x 2 which is not a first order critic resulting in the update rule calculating an incorrect update.</p><p>? f * should be optimal on a larger manifold, namely the manifold Q ? that is created by "stretching" Q ? bit in the direction of P (the formal definition is below).</p><p>? The norm of the gradient of the optimal critic, ? x f * (x) on supp(Q ? ) should be equal to the norm of the maximal directional derivative in the support of Q ? (see Eq. 15 in Appendix).</p><p>By enforcing these two points, we assure that ? x f * (x) is well defined and points towards the real data P. Thus, the following definition emerges (see proof of Lemma 7 in Appendix, Section A for details). Definition 6 (First Order Penalized Wasserstein Divergence <ref type="figure">(FOGAN)</ref>). Assume X ? R n and P, Q ? P(X) are probability measures over X. Set F = C 1 (X), ?, ? &gt; 0 and</p><formula xml:id="formula_27">?F (P Q; f ) := E x?P [f (x)] ? E x ?Q [f (x )] ? ? E x?P,x ?Q (f (x) ? f (x )) 2 x ? x ? ? E x?P,x ?Q ? ? ?xf (x) x ? Ex ?P [(x ? x ) f (x)?f (x ) x ?x 3 ] Ex ?P [ 1 x ?x ] ? ? 2</formula><p>Define the First Order Penalized Wasserstein Divergence as</p><formula xml:id="formula_28">? F (P Q) = sup f ?F ? F (P Q; f ).</formula><p>This divergence is updated by picking an optimal critic f * ? OC ? P (P, Q ?0 ) and taking a step in the direction of</p><formula xml:id="formula_29">? ? E Q ? [f * ]| ?0 .</formula><p>In order to define a GAN from the First Order Penalized Wasserstein Divergence, we must define a slight modification of the generated distribution Q ? to obtain Q ? . Similar to the WGAN-GP setting, samples from Q ? are obtained by</p><formula xml:id="formula_30">x ? ?(x ? x) where x ? P and x ? Q ? . The difference is that ? ? U([0, ?])</formula><p>, with ? chosen small, making Q ? and Q ? quite similar. Therefore updates to ? that reduce ? F (P Q ? ) also reduce ? F (P Q ? ).</p><p>Conveniently, as is shown in Lemma 5 in Appendix, Section A, any optimal critic for the First Order Penalized Wasserstein divergence is also an optimal critic for the Penalized Wasserstein Divergence. The key advantage to the First Order Penalized Wasserstein Divergence is that for any P, Q ? fulfilling Assumptions 1 and 2, ? F (P Q ? ) with its corresponding update rule ? ? E Q ? [f * ] on the slightly modified probability distribution Q ? fulfills requirements 3 and 4.</p><p>Theorem 2. Assume X ? R n , and P, Q ? ? P(X) are probability measures over X fulfilling Assumptions 1 and 2 and Q ? is Q ? modified using the method above. Then for every ? 0 ? ? there exists at least one optimal critic f * ? OC ? F (P, Q ?0 ) and ? F combined with update direction ? ? E Q ? [f * ]| ?0 fulfills Requirements 1 to 4. If P, Q ? are such that ?x, x ? supp(P), supp(Q ? ) it holds f * (x) ? f * (x ) = c x ? x for some constant c, then equality holds for Eq. 5.</p><p>Proof. See Appendix, Section A Note that adding a gradient penalty, other than being a necessary step for the WGAN-GP <ref type="bibr" target="#b10">(Gulrajani et al., 2017)</ref>, DRAGAN <ref type="bibr" target="#b14">(Kodali et al., 2017)</ref> and Consensus Optimization GAN <ref type="bibr" target="#b20">(Mescheder et al., 2017)</ref>, has also been shown empirically to improve the performance the original GAN method (Eq. 2), see <ref type="bibr" target="#b8">(Fedus et al., 2017)</ref>. In addition, using stricter assumptions on the critic, <ref type="bibr" target="#b25">(Nagarajan &amp; Kolter, 2017)</ref> provides a theoretical justification for use of a gradient penalty in GAN learning. The analysis of Theorem 2 in Appendix, Section A provides a theoretical understanding why in the Penalized Wasserstein GAN setting adding a gradient penalty causes ? ? E Q ? [f * ] to be an update rule that points in the direction of steepest descent, and may provide a path for other GAN methods to make similar assurances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Experimental Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Image Generation</head><p>We begin by testing the FOGAN on the CelebA image generation task <ref type="bibr" target="#b19">(Liu et al., 2015)</ref>, training a generative model with the DCGAN architecture  and <ref type="table">Table 2</ref>. Comparison of different GAN methods for image and text generation. We measure performance with respect to the FID on the image datasets and JSD between n-grams for text generation. obtaining Fr?chet Inception Distance (FID) scores <ref type="bibr" target="#b11">(Heusel et al., 2017)</ref> competitive with state of the art methods without doing a tuning parameter search. Similarly, we show competitive results on LSUN <ref type="bibr" target="#b34">(Yu et al., 2015)</ref> and CIFAR-10 <ref type="bibr" target="#b15">(Krizhevsky &amp; Hinton, 2009</ref>). See <ref type="table">Table 2</ref>, Appendix B.1 and released code 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">One Billion Word</head><p>Finally, we use the First Order Penalized Wasserstein Divergence to train a character level generative language model on the One Billion Word Benchmark <ref type="bibr" target="#b6">(Chelba et al., 2013)</ref>.</p><p>In this setting, a 1D CNN deterministically transforms a latent vector into a 32 ? C matrix, where C is the number of possible characters. A softmax nonlinearity is applied to this output, and given to the critic. Real data is one-hot encoding of 32 character texts sampled from the true data.</p><p>We conjecture this is an especially difficult task for GANs, since data in the target distribution lies in just a few corners of the 32 ? C dimensional unit hypercube. As the generator is updated, it must push mass from one corner to another, passing through the interior of the hypercube far from any real data. Methods other than Coulomb GAN <ref type="bibr" target="#b33">(Unterthiner et al., 2018)</ref> WGAN-GP <ref type="bibr" target="#b10">(Gulrajani et al., 2017;</ref><ref type="bibr" target="#b11">Heusel et al., 2017)</ref> and the Sobolev GAN <ref type="bibr" target="#b24">(Mroueh et al., 2018)</ref> have not been shown to be successful at this task.</p><p>We use the same setup as in both <ref type="bibr" target="#b10">(Gulrajani et al., 2017;</ref><ref type="bibr" target="#b11">Heusel et al., 2017)</ref> with two differences. First, we train to minimize our divergence from Definition 6 with parameters ? = 0.1 and ? = 1.0 instead of the WGAN-GP divergence. Second, we use batch normalization in the generator, both for training our FOGAN method and the benchmark WGAN-GP; we do this because batch normalization improved performance and stability of both models.</p><p>As with <ref type="bibr" target="#b10">(Gulrajani et al., 2017;</ref><ref type="bibr" target="#b11">Heusel et al., 2017)</ref> we use the Jensen-Shannon-divergence (JSD) between n-grams from the model and the real world distribution as an evaluation metric. The JSD is estimated by sampling a finite number of 32 character vectors, and comparing the distributions of the n-grams from said samples and true data. This estimation is biased; smaller samples result in larger JSD estimations. A Bayes limit results from this bias; even when samples are drawn from real world data and compared with real world data, small sample sizes results in large JSD estimations. In order to detect performance difference when training with the FOGAN and WGAN-GP, a low Bayes limit is necessary. Thus, to compare the methods, we sampled 6400 32 character vectors in contrast with the 640 vectors sampled in past works. Therefore, the JSD values in those papers are higher than the results here.</p><p>For our experiments we trained both models for 500, 000 iterations in 5 independent runs, estimating the JSD between 6-grams of generated and real world data every 2000 training steps, see <ref type="figure" target="#fig_2">Figure 2</ref>. The results are even more impressive when aligned with wall-clock time. Since in WGAN-GP training an extra point between real and generated distributions must be sampled, it is slower than the FOGAN training; see <ref type="figure" target="#fig_2">Figure 2</ref> and observe the significant (2?) drop in estimated JSD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Proof of Things</head><p>Proof of Theorem 1. The proof of this theorem is split into smaller lemmas that are proven individually.</p><p>? That ? P is a strict adversarial divergence which is equivalent to ? W is proven in Lemma 4, thus showing that ? P fulfills Requirement 1.</p><p>? ? P fulfills Requirement 2 by design.</p><p>? The existence of an optimal critic in OC ? P (P, Q) follows directly from Lemma 3.</p><p>? That there exists a critic f * ? OC ? P (P, Q) that fulfills Eq. 5 is because Lemma 3 ensures that a continuous differentiable f * exists in OC ? P (P, Q) which fulfills Eq. 9. Because Eq. 9 holds for f * ? C(X), the same reasoning as the end of the proof of Lemma 7 can be used to show Requirement 4</p><p>We prepare by showing a few basic lemmas used in the remaining proofs Lemma 1 (concavity of ? P (P Q; ?)). The mapping</p><formula xml:id="formula_31">C 1 (X) ? R, f ? ? P (P Q; f ) is concave. Proof. The concavity of f ? E x?P [f (x)] ? E x ?Q [f (x )] is trivial. Now consider ? ? (0, 1), then E x?P,x ?Q (?(f (x) ? f (x )) + (1 ? ?)(f (x) ?f (x ))) 2 x ? x ?E x?P,x ?Q ?(f (x) ? f (x )) 2 + (1 ? ?)(f (x) ?f (x )) 2 x ? x =?E x?P,x ?Q (f (x) ? f (x )) 2 x ? x + (1 ? ?)E x?P,x ?Q (f (x) ?f (x )) 2 x ? x ,</formula><p>thus showing concavity of ? P (P Q; ?).</p><p>Lemma 2 (necessary and sufficient condition for maximum). Assume P, Q ? P(X) fulfill assumptions 1 and 2. Then for any f ? OC ? P (P, Q) it must hold that</p><formula xml:id="formula_32">P x ?Q E x?P f (x) ? f (x ) x ? x = 1 2? = 1<label>(7)</label></formula><p>and</p><formula xml:id="formula_33">P x?P E x ?Q f (x) ? f (x ) x ? x = 1 2? = 1.<label>(8)</label></formula><p>Further, if f ? C 1 (X) and fulfills Eq. 7 and 8, then f ? OC ? P (P, Q)</p><p>Proof. Since in Lemma 1 it was shown that the the mapping f ? ? P (P Q, f ) is concave, f ? OC ? (P, Q) if and only if f ? C 1 (X) and f is a local maximum of ? P (P Q; ?). This is equivalent to saying that all u 1 , u 2 ? C 1 (X) with supp(u 1 ) ? supp(Q) = ? and supp(u 2 ) ? supp(P) = ? it holds</p><formula xml:id="formula_34">? (?,?) E P [f + ?u 1 ] ? E Q [f + ?u 2 ] ? ?E x?P,x ?Q ((f + ?u 1 )(x) ? (f + ?u 2 )(x )) 2 x ? x ?=0,?=0 = 0 which holds if and only if E x?P u 1 (x) 1 ? 2?E x ?Q (f (x) ? f (x )) x ? x = 0 and E x ?Q u 2 (x ) 1 ? 2?E x?P (f (x) ? f (x )) x ? x = 0</formula><p>proving that Eq. 7 and 8 are necessary and sufficient.</p><p>First Order Generative Adversarial Networks Lemma 3. Let P, Q ? P(X) be probability measures fulfilling Assumptions 1 and 2. Define an open subset of X, ? ? X, such that supp(Q) ? ? and inf x?supp(P),x ?? x ? x &gt; 0. Then there exists a f ? F = C 1 (X) such that</p><formula xml:id="formula_35">?x ? ? : E x?P f (x) ? f (x ) x ? x = 1 2? (9) and ?x ? supp(P) : E x ?Q f (x) ? f (x ) x ? x = 1 2?<label>(10)</label></formula><p>and ? P (P Q; f ) = ? P (P Q).</p><p>Proof. Since ? (P Q; f ) = ? (P Q; f + c) for any c ? R and is only affected by values of f on supp(P) ? ? we first start by considering</p><formula xml:id="formula_36">F = f ? C 1 (supp(P) ? ?) | E x?P,x ?Q f (x ) x ? x = 0</formula><p>Observe that Eq. 9 holds if</p><formula xml:id="formula_37">x ? ? : f (x ) = E x?P [ f (x) x?x ] ? 1 2? E x?P [ 1 x?x ]</formula><p>and similarly for Eq. 10</p><formula xml:id="formula_38">?x ? supp(P) : f (x) = E x ?Q [ f (x ) x?x ] + 1 2? E x ?Q [ 1 x?x ]</formula><p>. Now it's clear that if the mapping T : F ? F defined by</p><formula xml:id="formula_39">T (f )(x) := ? ? ? ? ? ? ? E x ?Q [ f (x ) x?x ]+ 1 2? E x ?Q [ 1 x?x ] x ? supp(P) E x ?P [ f (x ) x?x ]? 1 2? E x ?P [ 1 x?x ] x ? ?<label>(11)</label></formula><p>admit a fix point f * ? F, i.e. T (f * ) = f * , then f * is a solution to Eq. 9 and 10, and with that a solution to Eq. 7 and 8 and ? P (P Q; f * ) = ? P (P Q).</p><p>Define the mapping S : F ? F by</p><formula xml:id="formula_40">S(f )(x) = f (x) 2?Ex ?P,x ?Q f (x)?f (x ) x?x . Then Ex ?P,x ?Q S(f )(x) ? S(f )(x ) x ? x = 1 2?<label>(12)</label></formula><p>and</p><formula xml:id="formula_41">S(S(f ))(x) = S(f )(x) 2?Ex ?P,x ?Q S(f )(x)?S(f )(x ) x?x = S(f )(x) 2? 1 2? = S(f )(x)</formula><p>making S a projection. By the same reasoning, if Ex ?P,x ?Q</p><formula xml:id="formula_42">f (x)?f (x ) x?x = 1 2? then f is a fix-point of S, i.e. S(f ) = f . Assume f is such a function, then by definition of T in Eq. 11 Ex ?P,x ?Q T (f )(x) ? T (f )(x ) x ? x = Ex ?P E x ?Q T (f )(x) x ? x ? E x ?Q Ex ?P T (f )(x ) x ? x = Ex ?P E x ?Q f (x ) x ? x + 1 2? ? E x ?Q Ex ?P f (x) x ? x ? 1 2? = ?Ex ?P,x ?Q f (x) ? f (x ) x ? x + 2 1 2? = 1 2? .</formula><p>Therefore, S(T (S(f ))) = T (S(f )). We can define S(F) = {S(f ) | f ? F} and see that T : S(F) ? S(F). Further, since S(?) only multiplies with a scalar, S(F ) ? F.</p><p>Let f 1 , f 2 ? S(F). From Eq. 12 we get</p><formula xml:id="formula_43">E x?P,x ?Q f 1 (x ) ? f 2 (x ) x ? x = E x?P,x ?Q f 1 (x) ? f 2 (x) x ? x .</formula><p>Now since for every f ? F it holds by design that E x?P,x ?Q</p><formula xml:id="formula_44">f (x ) x?x = 0 and since S(F) ? F we see that f 1 , f 2 ? S(F) that E x?P,x ?Q f 1 (x ) ? f 2 (x ) x ? x = E x?P,x ?Q f 1 (x) ? f 2 (x) x ? x = 0</formula><p>Using this with the continuity of f 1 , f 2 , there must exist x 1 ? supp(P) with</p><formula xml:id="formula_45">E x ?Q f 1 (x ) ? f 2 (x ) x 1 ? x = 0</formula><p>With this (and compactness of our domain), Q must have mass in both positive and negative regions of f 1 ? f 2 and exists a constant p &lt; 1 such that for all f 1 , f 2 ? S(F) it holds sup x?supp(P)</p><formula xml:id="formula_46">E x ?Q f 1 (x ) ? f 2 (x ) x ? x ? p sup x?supp(P) E x ?Q 1 x ? x sup x ?? |f 1 (x ) ? f 2 (x )|.<label>(13)</label></formula><p>To show the existence of a fix-point for T in the Banach Space (F, ? ? ) we use the Banach fixed-point theorem to show that T has a fixed point in the metric space (S(F), ? ? ) (remember that T :</p><formula xml:id="formula_47">S(F) ? S(F) and S(F) ? F). If f 1 , f 2 ? S(F) then sup x?supp(P) |T (f 1 )(x) ? T (f 2 )(x)| = sup x?supp(P) E x ?Q f1(x )?f2(x ) x?x E x ?Q 1 x?x ? p sup x ?supp(Q) |f 1 (x ) ? f 2 (x )| using Eq. 13</formula><p>The same trick can be used to find some some q &lt; 1 and show</p><formula xml:id="formula_48">sup x ?? |T (f 1 )(x ) ? T (f 2 )(x )| ? q sup x?supp(P) |f 1 (x) ? f 2 (x)| thereby showing T (f 1 ) ? T (f 2 ) ? &lt; max(p, q) f 1 ? f 2 ?</formula><p>The Banach fix-point theorem then delivers the existence of a fix-point f * ? S(F) for T .</p><p>Finally, we can use the Tietze extension theorem to extend f * to all of X, thus finding a fix point for T in C 1 (X) and proving the lemma.</p><p>Lemma 4. ? P is a strict adversarial divergence and ? P and ? W are equivalent.</p><p>Proof. Let P, Q ? P(X) be two probability measures fulfilling Assumptions 1 and 2 with P = Q. It's shown in <ref type="bibr" target="#b31">(Sriperumbudur et al., 2010)</ref> that ? = ? W (P, Q) &gt; 0, meaning there exists a function f ? C(X), f L ? 1 such that and so for a sufficiently small ? &gt; 0 we'll get ? P (P Q; ?f ) &gt; 0 meaning ? P (P Q) &gt; 0 and ? P is a strict adversarial divergence.</p><formula xml:id="formula_49">E P [f ] ? E Q [f ] = ? &gt; 0.</formula><p>To show equivalence, we note that ? P (P Q) ? sup m?C(X 2 ) E x?P,x ?Q m(x, x ) 1 ? ? m(x, x )</p><p>x ? x therefore for any optimum it must hold m(x, x ) ? x?x 2? , and thus (similar to Lemma 2) any optimal solution will be Lipschitz continuous with a the Lipschitz constant independent of P, Q. Thus ? W (P Q) ? ?? P (P Q) for ? &gt; 0, from which we directly get equivalence.</p><p>Proof of Theorem 2. We start by applying Lemma 5 giving us ? OC ? F (P, Q ?0 ) = ?.</p><p>? For any P, Q ? P(X) fulfilling Assumptions 1 and 2, it holds that ? F (P Q) = ? P (P Q), meaning ? F is like ? P a strict adversarial divergence which is equivalent to ? W , showing Requirement 1.</p><p>? ? F fulfills Requirement 2 by design.</p><p>? Every f * ? OC ? F (P, Q ?0 ) is in OC ? P (P, Q ?0 ) ? C 1 (X), therefore f * the gradient ? ? E Q ? [f * ]| ?0 exists. Further Lemma 7 shows that the update rule ? ? E Q ? [f * ]| ?0 is unique, thus showing Requirement 3.</p><p>? Lemma 7 gives us every f * ? OC ? F (P, Q ?0 ) with the corresponding update rule fulfills Requirement 4, thus proving Theorem 2.</p><p>Before we can show this theorem, we must prove a few interesting lemmas about ? F . The following lemma is quite powerful; since ? P (P Q) = ? F (P Q) and OC ? F (P, Q) ? OC ? P (P, Q) any property that's proven for ? P automatically holds for ? F .</p><p>Lemma 5. If let X ? R n and P, Q ? P(X) be probability measures fulfilling Assumptions 1 and 2. Then 1. there exists f * ? OC ? P (P, Q) so that ? F (P Q; f * ) = ? P (P Q; f * ), 2. ? P (P Q) = ? F (P Q),</p><p>3. ? = OC ? F (P, Q), 4. OC ? F (P, Q) ? OC ? P (P, Q).</p><p>Clain <ref type="formula" target="#formula_14">(4)</ref> is especially helpful, now anything that has been proven for all f * ? OC ? P (P, Q) automatically holds for all f * ? OC ? F (P, Q)</p><p>Proof. For convenience define</p><formula xml:id="formula_50">G(P, Q; f ) := E x ?Q ? ? ? ? ? ? x f (x) x ? Ex ?P [(x ? x ) f (x)?f (x ) x ?x 3 ] Ex ?P [ 1 x ?x ] ? ? 2 ? ? ?</formula><p>(G is for gradient penalty) and note that   </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>First</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Comparison of ?P update rule given different optimal critics. Consider the simple example of divergence ?P from Definition 5 between Dirac measures with update rule 1 2 d d? E ? ? [f ] (the update rule is from Lemma 7 in Appendix, Section A). Recall that ?P (?0 ? ? ; f ) = ?f (?) ? (f (?)) 2 2?</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3Figure 2 .</head><label>2</label><figDesc>https://github.com/zalandoresearch/first_order_gan Five training runs of both WGAN-GP and FOGAN, with the average of all runs plotted in bold and the 2? error margins denoted by shaded regions. For easy visualization, we plot the moving average of the last three n-gram JSD estimations. The first two plots both show training w.r.t. number of training iterations; the second plot starts at iteration 50. The last plot show training with respect to wall-clock time, starting after 6 hours of training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>The 2 )</head><label>2</label><figDesc>Stone-Weierstrass theorem tells us that there existsa f ? C ? (X) such that f ?f ? ? ? 4 and thus E P [f ]?E Q [f ] ? ? 2. Now consider the function ?f with ? &gt; 0, it's clear that? P (P Q) ? ? P (P Q; ?f ) = ?(E P [f ] ? E Q [f ] ? ? ? ? 2 ?E x?P,x ?Q [ (f (x) ? f (x )) 2 x ? x ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>?Figure 5 .</head><label>5</label><figDesc>F (P Q; f ) = ? P (P Q; f ) ? G(P, Q; f ) ?0 Therefore it's clear that ? F (P Q) ? ? P (P Q)Plugging this into Eq. 14 gives us?x ? supp(Q ) : ? x Ex ?P f * (x) ? f * (x)x ? x Images from a First Order GAN after training on LSUN data set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 6 .</head><label>6</label><figDesc>Samples generated by First Order GAN trained on fhe One Billion Word benchmark with FOGAN (left) the original TTUR method (right).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Zalando Research, M?hlenstra?e 25, 10243 Berlin, Germany 2 LIT AI Lab &amp; Institute of Bioinformatics, Johannes Kepler University Linz, Austria. Correspondence to: Calvin Seward &lt;calvin.seward@zalando.de&gt;.</figDesc><table /><note>1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc>Comparing existing GAN methods with regard to the four Requirements formulated in this paper. The methods compared are the classic GAN</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>First Order Generative Adversarial NetworksChange spent kands that the righ Qust of orlists are mave hor int Is that the spens has lought ant If a took and their osiy south M Willing contrased vackering in S The Ireas's last to vising 5t .. WalaMurka in the moroe Dry Hall Sitning tven the concer There are court phinchs hasffort He scores a supponied foutver il Bartfol reportings ane the depor Seu hid , it 's watter 's remold Later fasted the store the inste</figDesc><table><row><cell>The FNF sicker , Nalnelber once She 's wast to miblue as ganemat threw pirnatures for hut only a Umialasters are not oversup on t Beacker it this that that that W Though 's lunge plans wignsper c He says : Indiwezal deducated belenseous K Starfers on Rbama 's all is lead Inverdick oper , caldawho 's non She said , five by theically rec RichI , Learly said remain ."" Reforded live for they were like The plane was git finally fuels</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">(0, 1) X denotes all functions mapping X to (0, 1).</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This work was supported by Zalando SE with Research Agreement 01/2016.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>First Order Generative Adversarial Networks Claim (1). Let ? ? X be an open set such that supp(Q) ? ? and ? ? supp(P) = ?. Then Lemma 3 tells us there is a f ? OC ? P (P, Q) (and thus f ? C 1 (X)) such that</p><p>and thus, because supp <ref type="bibr">(Q)</ref> ? ? open and f ? C 1 (X),</p><p>Now taking the gradients with respect to x gives us</p><p>meaning</p><p>Claims <ref type="formula">(2)</ref> and <ref type="formula">(3)</ref>. The claims are a direct result of Claim (1); for every P, Q ? P(X) there exists a</p><p>thus showing both ? P (P Q) = ? F (P Q) and f * ? OC ? F (P Q).</p><p>Claim (4). This claim is a direct result of claim (2); since ? P (P Q) = ? F (P Q), that means that if f * ? OC ? F (P Q), then</p><p>thus ? P (P Q; f * ) = ? P (P Q) and f * ? OC ? P (P Q).</p><p>and note that due to construction of Q and v, v is such that for almost all x ? supp(Q ) there exists an a = 0 where for all ? ? [0, |a|] it holds x + ?sign(a)v ? supp(Q ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>First Order Generative Adversarial Networks</head><p>Using Eq. 7 we see,</p><p>Therefore,</p><p>Now from the proof of Lemma 5 claim (4), we know that since G(P, Q; f * ) = 0 we get</p><p>and since for x = 0 and w = 1 it holds w,</p><p>and with</p><p>Therefore there exists no ? ? R such that Eq. 5 holds for every distribution in the WGAN-GP context. The learned networks (both generator and critic) are then fine-tuned with learning rates divided by 10. Samples from the trained model can be viewed in <ref type="figure">figure 4</ref>.</p><p>First Order Generative Adversarial Networks  The learned networks (both generator and critic) are then fine-tuned with learning rates divided by 10. Samples from the trained model can be viewed in <ref type="figure">figure 5</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Billion Word</head><p>The parameters used for the Billion Word training were one run with the following settings, followed by a second run using initialized with the best saved model from the first run and learning rates divided by 10. Samples from our method and the WGAN-GP baseline can be found in <ref type="figure">figure 6</ref> 'activation_d': 'relu', 'batch_norm_d': False, 'batch_norm_g': True, 'batch_size': 64, 'checkpoint_dir': 'logs/checkpoints/0201_181559_0.000300_0.000100', 'critic_iters': 1, 'data_path': '1-billion-word-language-modeling-benchmark-r13output', 'dim': 512, 'gan_divergence': 'FOGAN', 'gradient_penalty': 1.0, 'is_train': True, 'iterations': 500000, 'jsd_test_interval': 2000, 'learning_rate_d': 0.0003, 'learning_rate_g': 0.0001, 'lipschitz_penalty': 0.1, 'load_checkpoint_dir': 'False', 'log_dir': 'logs/tboard/0201_181559_0.000300_0.000100', 'max_n_examples': 10000000, 'n_ngrams': 6, 'num_sample_batches': 100, 'print_interval': 100, 'sample_dir': 'logs/samples/0201_181559_0.000300_0.000100', 'seq_len': 32, 'squared_divergence': False, 'use_fast_lang_model': True</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Towards principled methods for training generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Wasserstein Generative Adversarial Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning (ICML)</title>
		<meeting>the 34th International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The cramer distance as a solution to biased wasserstein gradients</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Bellemare</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dabney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10743</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Learning texture manifolds with the periodic spatial GAN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jetchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Svens?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gtm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The generative topographic mapping</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="215" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bi?kowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Sutherland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Demystifying</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gans</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">One billion word benchmark for measuring progress in statistical language modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chelba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brants</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robinson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1312.3005</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Training generative neural networks via maximum mean discrepancy optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Dziugaite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st Conference on Uncertainty in Artificial Intelligence (UAI)</title>
		<meeting>the 31st Conference on Uncertainty in Artificial Intelligence (UAI)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Many paths to equilibrium: GANs do not need to decrease a divergence at every step</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rosca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.08446</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 27 (NIPS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Improved Training of Wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GANs trained by a two time-scale update rule converge to a local nash equilibrium</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Texture synthesis with spatial generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jetchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.08207</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Jetchev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ganosaic</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.00269</idno>
		<title level="m">Mosaic creation with generative texture manifolds</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">How to train your DRAGAN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kodali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Abernethy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kira</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1705.07215</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Photo-realistic single image superresolution using a generative adversarial network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ledig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Theis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Husz?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Caballero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandro</forename><surname>Acosta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aitken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Totz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<idno>doi: 10. 1109/CVPR.2017.19</idno>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="105" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Generative moment matching networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML)</title>
		<meeting>the 32nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Approximation and convergence properties of generative adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Bousquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chaudhuri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30 (NIPS)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5545" to="5553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep learning face attributes in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3730" to="3738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The numerics of GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Which training methods for gans do actually converge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mescheder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1801.04406v2</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Unrolled generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pfau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of Learning Representations (ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Envelope theorems for arbitrary choice sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milgrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Segal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="583" to="601" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Mroueh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sercu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sobolev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gan</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Gradient descent GAN optimization is locally stable</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Nagarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Kolter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Training generative neural samplers using variational divergence minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nowozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Cseke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tomioka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>F-Gan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29 (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the regularization of wasserstein GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Petzka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lukovnicov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference of Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Improved techniques for training GANs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zaremba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 29 (NIPS)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2234" to="2242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning factorial codes by predictability minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="863" to="879" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Hilbert space embeddings and metrics on probability measures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">K</forename><surname>Sriperumbudur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fukumizu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Lanckriet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1517" to="1561" />
			<date type="published" when="2010-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">VEEGAN: Reducing mode collapse in GANs using implicit variational learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Valkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sutton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nessler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Seward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Heusel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ramsauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">Coulomb</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gans</surname></persName>
		</author>
		<title level="m">Provably optimal nash equilibria via potential fields. International Conference of Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Seff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lsun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1506.03365</idno>
		<title level="m">Construction of a large-scale image dataset using deep learning with humans in the loop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
