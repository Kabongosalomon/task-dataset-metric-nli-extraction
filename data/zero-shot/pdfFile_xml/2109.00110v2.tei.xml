<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MINIF2F: A CROSS-SYSTEM BENCHMARK FOR FORMAL OLYMPIAD-LEVEL MATHEMATICS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunhao</forename><surname>Zhen?</surname></persName>
							<email>kunhao.zheng@polytechnique.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">OpenAI University of Pittsburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ecole</forename><surname>Polytechnique</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">OpenAI University of Pittsburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">OpenAI University of Pittsburgh</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><forename type="middle">Polu</forename><surname>Openai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">OpenAI University of Pittsburgh</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">MINIF2F: A CROSS-SYSTEM BENCHMARK FOR FORMAL OLYMPIAD-LEVEL MATHEMATICS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>Published as a conference paper at ICLR 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T05:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present miniF2F, a dataset of formal Olympiad-level mathematics problems statements intended to provide a unified cross-system benchmark for neural theorem proving. The miniF2F benchmark currently targets Metamath, Lean, Isabelle (partially) and HOL Light (partially) and consists of 488 problem statements drawn from the AIME, AMC, and the International Mathematical Olympiad (IMO), as well as material from high-school and undergraduate mathematics courses. We report baseline results using GPT-f (Polu &amp; Sutskever, 2020), a neural theorem prover based on GPT-3 (Brown et al., 2020)  and provide an analysis of its performance. We intend for miniF2F to be a community-driven effort and hope that our benchmark will help spur advances in neural theorem proving.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Shared benchmarks and datasets have historically played a crucial role in driving advances in largescale applications of deep learning, e.g. in computer vision <ref type="bibr" target="#b4">(Deng et al., 2009)</ref> and natural language processing <ref type="bibr" target="#b18">(Wang et al., 2019;</ref><ref type="bibr" target="#b12">Rajpurkar et al., 2016;</ref><ref type="bibr" target="#b10">Paperno et al., 2016)</ref>. Neural theorem proving is a rapidly developing area which aims to apply techniques from deep learning to interactive theorem proving. To date, most contributions in this area have focused on individual theorem proving systems, each with a separately-implemented mathematics library and with results reported on a dataset-specific test split; examples include the HOList <ref type="bibr" target="#b0">(Bansal et al., 2019a)</ref>, CoqGym <ref type="bibr" target="#b23">(Yang &amp; Deng, 2019)</ref> and LeanStep <ref type="bibr" target="#b5">(Han et al., 2021)</ref> theorem proving environments and benchmarks. However, benchmarks from this paradigm are not ideal for measuring the mathematical reasoning ability of neural theorem provers for several reasons. Library-specific train/test splits are siloed by construction, dependent on how theorems and lemmas are split in these libraries, and as such are not directly comparable across systems. Moreover, formal mathematics libraries are closer to software repositories than informal mathematical exposition, and many lemmas are implementation-specific artifacts without precise informal mathematical or cross-system translations.</p><p>To date, the neural theorem proving community has not organized its efforts around a cross-system benchmark. To address this need and to provide a common resource to research groups working on formal theorem proving, we present miniF2F, a unified cross-system benchmark of formal mathematics of progressively increasing difficulty, centering around Olympiad-level problem statements (AMC, AIME, IMO) as well as high-school and undergraduate maths classes. Both the content and name of miniF2F are inspired by the IMO Grand Challenge <ref type="bibr" target="#b15">(Selsam et al., 2019)</ref>: to build an AI that can win a gold medal in the International Mathematical Olympiad in a formal-to-formal (F2F) format. More precisely, the agent must receive IMO problems written in a formal mathematical format, and must produce a formal (i.e. machine-checkable) proof for that problem.</p><p>We intend for miniF2F to serve as a stepping stone for different formal systems towards the IMO Grand Challenge <ref type="bibr" target="#b15">(Selsam et al., 2019)</ref>, as it is end-to-end verifiable, cross-platform and spans a wide range of difficulty. While we report baseline results on miniF2F using GPT-f , a language model Published as a conference paper at ICLR 2022 based on GPT-3 which has been finetuned for theorem proving, language models are not a mandatory approach for Olympiad problems and this assumption is not reflected in miniF2F, preserving the generality and widespread applicability of the benchmark to systems similar to DeepHOL <ref type="bibr" target="#b0">(Bansal et al., 2019a)</ref> or Holophrasm <ref type="bibr" target="#b20">(Whalen, 2016)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">BACKGROUND AND RELATED WORK</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BENCHMARKS</head><p>In the closely related field of (first-order) automated theorem proving (ATP), the TPTP <ref type="bibr" target="#b17">(Sutcliffe, 2017)</ref> benchmark is a library of test problems in a unified format for ATP systems. In interactive theorem proving, the "Freek 100" <ref type="bibr" target="#b21">(Wiedijk, 2008)</ref> tracks progress across various interactive theorem provers on a list of 100 mathematical theorems.  built a simplified formal proof environment INT with an associated synthetic inequality benchmark. Competitions and communal challenges have also spurred development in formal theorem proving. The CADE ATP System Competition (CASC) <ref type="bibr" target="#b16">(Sutcliffe, 2016)</ref> is a competition that evaluates the performance of first-order automated theorem proving systems. Proof <ref type="bibr">Ground (Haslbeck et al., 2019)</ref>, part of the ITP conference, is an interactive proving contest (for humans) that supports Coq, Isabelle, and Lean, which focuses on evaluating the formalization effort of proof to given problems within limited time. Finally, the IMO Grand Challenge <ref type="bibr" target="#b15">(Selsam et al., 2019)</ref>, a proposal from researchers working on the interactive proof assistant Lean, aims to build a system capable of solving IMO problems in the formal-to-formal format.</p><p>Due to its convenient framing as a natural language processing task, the domain of informal mathematical reasoning has received more attention than the formal one. MATH <ref type="bibr" target="#b7">(Hendrycks et al., 2021)</ref> is a mathematics benchmark comprising 12,500 statements in natural language where exercises are classified into 5 levels of difficulty across various domains. Each exercise is combined with a detailed step-by-step proof in natural language. Scaling state-of-the-art models shows little amelioration on MATH, which requires advanced mathematical reasoning capabilities. miniF2F includes a number of formalized statements from MATH. NaturalProofs <ref type="bibr" target="#b19">(Welleck et al., 2021)</ref> is another benchmark of natural proof in mathematics , containing 32k theorem statements and proofs. It essentially contains the proofs in ProofWiki and other resources. While MATH is more oriented towards mathematics exercises, NaturalProofs is focused on proofs of general mathematics theorems. <ref type="bibr" target="#b13">Saxton et al. (2019)</ref> built a mathematics dataset with 2 ? 10 6 training data and 10 4 test data, presented in a question-answering format where each statement is paired with a question written in natural language and a direct answer without proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NEURAL THEOREM PROVING</head><p>HOList <ref type="bibr" target="#b0">(Bansal et al., 2019a;</ref><ref type="bibr">b;</ref><ref type="bibr" target="#b9">Paliwal et al., 2020)</ref> provides an environment as well as a benchmark for HOL Light. They also proposes various deep reinforcement learning approaches for theorem proving and report a pass rate of 59.91% on their benchmark. <ref type="bibr" target="#b23">Yang &amp; Deng (2019)</ref> built CoqGym, a large-scale dataset, which comes also with a learning environment, of 71k human-written proofs in Coq proof assistant. They report a 30.0% pass rate on the held-out test theorems in CoqGym. <ref type="bibr" target="#b11">Polu &amp; Sutskever (2020)</ref> applied a decoder-only transformer similar to GPT-3 <ref type="bibr" target="#b2">(Brown et al., 2020)</ref> to proof steps prediction in Metamath combined with a log-probability based proof search. They also proposed a methodology to train a value function to further guide proof search, achieving a 56.22% pass rate on the held-out test set. Large language models were applied to Lean by <ref type="bibr" target="#b5">Han et al. (2021)</ref>. They created an environment around the Lean prover targeted to machine learning and propose a dataset extracted from low level proof artifacts that is shown to boost performance when used as a self-supervised co-training objective. They report a 48.4% pass rate on held-out test statements from mathlib, Lean's mathematical library (mathlib Community, 2020).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">MINIF2F BENCHMARK</head><p>miniF2F is a dataset of manually formalized statements of Olympiad type problems, aligned in Lean, Metamath, and Isabelle (partial at the time of writing), providing a cross-platform benchmark for formal mathematical reasoning. Olympiad type problems are of particular interest to compare automated provers across different formal systems as the theories required to solve them are well identified and they generally do not require the definition of new mathematical concepts (a capability that remains beyond the current neural theorem proving state of the art).</p><p>The formalized statements in miniF2F are drawn from multiple sources, ranging from high school and undergraduate level exercises to Olympiad problems. miniF2F also covers different subsubjects in mathematics as well as proof strategies, focusing on the types of exercises whose statements are expressible in most formal systems. This leads to a systemic focus on algebra, number theory and inequalities because, for example, geometry and combinatorial problems are generally challenging to formalize due to only nascent efforts in these areas in most formal systems. The statements in miniF2F are all manually formalized and selected to cover a variety of difficulty levels for both humans and machines. Formal proofs for these statements are optionally attached.</p><p>miniF2F draws from AIME, AMC, IMO problems as well as problems from the MATH <ref type="bibr" target="#b7">(Hendrycks et al., 2021)</ref> informal dataset. Formalizing problems from the MATH dataset serves two purposes. First, problems in MATH are segmented by difficulty level (from 1 to 5), randomly selecting a subset from each of these difficulty levels allows miniF2F to cover a wider range of difficulty. Second, it provides the community an opportunity to compare capabilities of formal automated prover to their informal counter-parts as discussed in later sections.</p><p>miniF2F comprises a test set and a validation set, which are a stratified random split from the statements we formalized such that each set equally covers each problem type and difficulty (when available). <ref type="table" target="#tab_0">Table 1</ref> shows a detailed distribution of these statements.</p><p>Versioning miniF2F is an evolving effort and new statements will continuously be added. Periodically, we will freeze versions of the benchmark. The current version of the benchmark is v1 1 and results in this paper are reported using this version. v1 comprises 244 test and 244 valid statements. The set of statements of each version is guaranteed to remain stable, only allowing fixes in case errors are later discovered.</p><p>Rules of engagement and License miniF2F is meant to serve as a shared resource for research groups working on applying deep learning to formal theorem proving. There is no formal process to submit evaluation results and researchers are simply invited to cite miniF2F indicating the version used in their evaluations. We also encourage them to contribute proofs found by their approaches back to the benchmark. The parts of the benchmark associated with each theorem prover (Metamath, Lean, Isabelle) are meant to be licensed in a way that is aligned with the licensing usage associated with the theorem prover's main library. As a result, the Metamath version of the benchmark is released under the MIT License, while the Lean and Isabelle versions are released under the Apache License.</p><p>Formalization effort and challenges We found that, for trained practitioners (but not necessarily experts, including students recently introduced to formal systems), formalizing a statement takes about 15 minutes on average, and reviewing a formalized statement, about half of that on average. Note that not all exercises are directly or naturally formalizable. In particular, multi-choice questions, word problems, and exercises that require to explicit a witness or a set as part of the answer present interesting challenges:</p><p>multi-choice questions 2 these problems are generally straightforwardly formalizable by reformulating the statement using the right answer only, and could be made "fair" in a competitive setup by formalizing all possible choices and running automated provers on all of them, attributing points only if a proof of the correct answer is provided.</p><p>word problems 3 where significant information is presented in natural language generally require non-trivial efforts to be formalized. We generally formalized them by explicitly modeling the mathematics concepts and expression presented in natural language while attempting as best as possible to preserve the mathematical difficulty of the original problem. Sometime the formalization work is most of the difficulty associated with the original question; in such cases we would discard the problem entirely.</p><p>problems that require to explicit a set or witness 4 (e.g. find all ... such that ...) are not directly formalizable. The best approximation we relied on for these was to formalize the statement with the witness or answer provided, turning such exercises into the generation of a proof that the answer is correct, and if needed, that it is the unique one-which is, at times, a much easier exercise. A non negligible portion of IMO problems are as such, which we foresee could become a challenge in the future, to fairly compare humans to automated proving systems in a competitive setup.</p><p>Porting effort In addition to Metamath, Lean, Isabelle (work in progress) and HOL Light (work in progress), we are eager to extend the coverage of miniF2F to Coq, and will welcome any effort in that direction or to extend miniF2F to further systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">EXPERIMENTS</head><p>In this section, in order to study baseline performances associated with existing systems, we report pass rates achieved by GPT-f <ref type="bibr" target="#b11">(Polu &amp; Sutskever, 2020)</ref> applied to Metamath, GPT-f /PACT <ref type="bibr" target="#b11">(Polu &amp; Sutskever, 2020;</ref><ref type="bibr" target="#b5">Han et al., 2021)</ref> applied to Lean as well as a baseline prover implemented in Lean denoted as the tidy baseline. Pass rates are reported as Pass@N where N is the number of proof search attempts per statement. Pass@N is computed by running more attempts per statement, averaged to get an unbiased, low-variance estimate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">METAMATH</head><p>Metamath is powered by a meta logic system based on a single substitution rule. It's characterized by its simplicity which makes it convenient to study machine learning. Proofs in Metamath are, as a consequence of the low-level proofsteps, much longer than in other systems as there is no assistance from high-level tactics. Proofs which are trivial in other systems (e.g. n-digit addition or simple ring arithmetic transformations) can be quite tedious in Metamath. The absence of tactics is both a benefit, as the models sees and learns on everything, and a challenge, as proofs of even simple exercises require hundreds of proofsteps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">GPT-F</head><p>We report the pass rate of GPT-f applied to Metamath as described in <ref type="bibr" target="#b11">Polu &amp; Sutskever (2020)</ref>. We use a model with 700m learnable parameters. The model is trained on an updated dump of the set.mm library (but similar synthetic datasets), using the log-probability based search as reported in <ref type="table">Table 8</ref> of the GPT-f paper <ref type="bibr" target="#b11">(Polu &amp; Sutskever, 2020)</ref>.</p><p>The model achieves a Pass@1 of 1.3% and a Pass@8 of 1.6% on miniF2F-test. As expected, these numbers are quite low due to the length of typical proofs for even simple math exercises. The average proof length is also reported in <ref type="table" target="#tab_2">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">LEAN</head><p>In comparison to Metamath, Lean benefits from a large number of powerful tactics to assist formalization efforts. Typical Lean proofs are much shorter than Metamath's. This is also a formal system of interest as it has received a lot of attention from the mathematical community as recent theories have successfully been formalized in Lean (Perfectoid Spaces , Liquid Tensor experiment <ref type="bibr" target="#b14">(Scholze, 2020)</ref>).</p><p>Lean is also associated with the IMO Grand Challenge <ref type="bibr" target="#b15">(Selsam et al., 2019)</ref> which aims to organize a formal-to-formal challenge during the upcoming IMO competitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">T I D Y BASELINE</head><p>We use the generic best-first search algorithm presented in PACT <ref type="bibr" target="#b5">(Han et al., 2021)</ref>. The algorithm works as follows: Given a list of tactics L with priority, we maintain a priority queue Q of tactic states whose priority is given by the priority of the last applied tactic in L that led to it. While Q is not empty, we pop the top tactic state t from Q. We iterate through L and apply each tactic to t. If no error is raised, we capture the returned tactic states from Lean and insert them back into Q.</p><p>We use the same terminology as in PACT <ref type="bibr" target="#b5">(Han et al., 2021)</ref>: maximum queue size ? max , depth limit d max . We also enforce a budget of i max iterations of the outer loop. When Q's size reach q max , all the tactic states to be inserted are discarded. We do not expand the next tactic state when the depth is beyond d max . This loop is run until a proof is found or the iterations budget is exhausted.</p><p>For consistency checking, we run the tidy baseline under the same settings and on the same test set as in PACT <ref type="bibr" target="#b5">(Han et al., 2021)</ref> except that we don't set a global timeout. Our implementation achieved a 10.5% pass rate on mathlib's test split. This result is comparable to the reported 9.9% in PACT given the waived global timeout.</p><p>In addition to the curated list of tactics L used in PACT <ref type="bibr" target="#b5">(Han et al., 2021)</ref>, we added 4 high-level tactics HL =[nlinarith, linarith, ring nf, norm num] to L with higher priorities than the others. We report our pass rate on miniF2F in <ref type="table" target="#tab_1">Table 2</ref>. We report the pass rate of GPT-f /PACT as described in <ref type="bibr" target="#b5">Han et al. (2021)</ref>. We use a model with 700M learnable parameters. The model is trained on an updated dump 56 of the mathlib library using the PACT methodology denoted in the paper as mix2 &gt; mix1 + tactic in <ref type="figure">Figure 6</ref>.</p><p>The model achieves a Pass@1 of 24.6% and a Pass@8 of 29.2% on miniF2F-test. The average proof length is also reported in <ref type="table" target="#tab_2">Table 3</ref>. One goal of miniF2F is to study the comparison of performance across formal systems. In this section we reported the performance of the same methodology (GPT-f <ref type="bibr" target="#b11">(Polu &amp; Sutskever, 2020)</ref>) applied to both Lean and Metamath. Both models are pre-trained on WebMath <ref type="bibr" target="#b11">(Polu &amp; Sutskever, 2020)</ref> and respectively trained on datasets extracted from Lean <ref type="bibr" target="#b5">(Han et al., 2021)</ref> and Metamath <ref type="bibr" target="#b11">(Polu &amp; Sutskever, 2020)</ref>. The overall compute deployed at training is comparable in both setup and exactly equivalent at test-time, yet the achieved performance appears drastically superior when applied to Lean. We hypothesize that this is mainly explained by the model's access to highlevel tactics when applied to Lean, enabling the model to learn how to guide Lean's automation in an effective way.</p><p>An example of this high-level guidance behavior is well exemplified by the following proof of the statement algebra_sqineq_2unitcircatblt1 where the model heavily relies on Lean's nlinarith solver but provides it with essential premises to successfully guide the search. </p><formula xml:id="formula_0">, b ? R, a 2 + b 2 = 2 ? a ? b ? 1).</formula><p>In Metamath, GPT-f fails to find a proof as it requires a very large number of steps to appropriately rewrite the goal in a way that is amenable to the use of set.mm's existing theorems. The tidy baseline also fails to find a proof of that statement as nlinarith is not capable of solving the goal without being passed extraneous premises.</p><p>These results motivate the use of neural theorem proving with formal systems that expose powerful high level tactics and also suggest the potential of a closer collaboration between formal systems and machine learning practitioners. It also motivates the use of generative models in that setup as the arguments required by high-level tactics to succeed on non trivial problems generally do not exist in the context of the statement and therefore have to be generated ex-nihilo.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.2">COMPARISON OF INFORMAL AND FORMAL SETUPS</head><p>The use of formal systems for neural theorem proving is often motivated by the role of the formal system as a verifier, enabling more advanced neural search strategies than possible in a fully informal setup where the generation of a model can't be verified automatically, as well as the access to powerful tactics. Our formalization of a subset of the MATH <ref type="bibr" target="#b7">(Hendrycks et al., 2021)</ref> informal dataset provides an interesting approximate quantification of the benefit of having access to a formal system in the context of neural theorem proving. Approximate, because we only formalized a small subset of the MATH statements, but nonetheless useful since we drew uniformly from the 5 difficulty levels.</p><p>In <ref type="bibr" target="#b7">Hendrycks et al. (2021)</ref>, the performance of GPT-3 (which is a larger model than the GPT-f model studied here) is reported to be 6.0% in the algebra category and 3.9% in the number theory category. GPT-f applied to Lean by comparison achieves 51.4% in the algebra category and 41.7% in the number theory category. It is also worthwhile to note that the tidy baseline also highly outperforms (31.4% in algebra and 30.0% in number theory) GPT-3 in an informal setup demonstrating the benefit of proof automation alone.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.3">LIMITATION</head><p>With miniF2F being cross-system as the goal, types of problems that are less expressible in certain systems such as geometry and combinatorial problems are less covered. The shift of distribution of problem types may result in skewing the research direction of models when benchmarking on miniF2F. Directionally we aim to fix it and extend the coverage of miniF2F as we grow the benchmark. However, works and efforts on the corresponding library of other systems are required as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We presented miniF2F, a dataset of formal Olympiad-level mathematics problem statements, meant to serve as an initial effort towards cross-system benchmarking of neural mathematical reasoning capabilities in formal environments. We reported the performance of the neural theorem prover GPT-f <ref type="bibr" target="#b11">(Polu &amp; Sutskever, 2020)</ref> on both the Lean and Metamath parts of miniF2F as well as the performance of our non-neural tidy baseline applied to Lean. Then, we discussed these baselines and put them in perspective with previously reported comparable results in informal environments <ref type="bibr" target="#b7">(Hendrycks et al., 2021)</ref>.</p><p>Finally, we hope that miniF2F will prove to be useful to the scientific community working on neural theorem proving and spur advances in this domain. <ref type="table">Table 4</ref>: Problem 11 of 2000 AMC 12 is formalized with proof in different languages in miniF2F. The proof is optionally attached thus not part of the benchmark. The proof in Metamath is too long to be fully displayed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A EXAMPLE OF STATEMENT IN MINIF2F</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Natural Language</head><p>Two non-zero real numbers, a and b, satisfy ab = a ? b. Which of the following is a possible value of a fixes a b::real assumes "a \&lt;noteq&gt; 0" "b \&lt;noteq&gt; 0" and "a * b = a -b" shows "a / b + b / a -a * b = 2" using assms by <ref type="bibr">(smt (verit, ccfv threshold)</ref> diff divide distrib div self divide divide times eq eq divide imp nonzero mult div cancel left) end</p><formula xml:id="formula_1">b + b a ? ab? (A) -2 (B) ?1 2 (C) 1 3 (D) 1 2 (E) 2 Metamath ${ amc12-2000-</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B PERFORMANCE BY DIFFICULTY ON STATEMENTS FORMALIZED FROM MATH DATASET</head><p>The MATH dataset assigns a difficulty ranging from 1 to 5 to each of its problem. <ref type="table" target="#tab_3">Tables 5 and  6</ref> report the number of proved statement split by difficulty level on the algebra and number theory categories. <ref type="table">Table 5</ref>: Counts of successfully proved statements formalized from MATH-Algebra in miniF2F v1 split by difficulty. This table corresponds to "MATH Algebra" in <ref type="figure" target="#fig_0">Figure 1</ref>.</p><p>miniF2F-valid miniF2F-test Difficulty Level 1 2 3 4 5 1 2 3 4 5 Metamath/GPT-f 1 0 0 0 0 2 0 1 0 1 Lean/tidy 6 4 2 2 1 6 4 7 3 1 Lean/GPT-f 9 7 8 6 2 8 7 10 7 3 miniF2F-valid miniF2F-test Difficulty Level 1 2 3 4 5 1 2 3 4 5 Metamath/GPT-f 0 0 0 0 0 0 0 0 0 0 Lean/tidy 8 3 2 2 2 7 4 3 2 2 Lean/GPT-f 9 5 5 4 2 10 5 5 3 2</p><p>More broadly, Lean GPT-f is capable of solving any problem that the tidy baseline or Metamath GPT-f can solve in MiniF2F. Qualitatively, the problems on which it fail either require multiple nontrivial reasoning steps (outside a few exceptions, problems requiring more than 2 non-trivial steps of mathematical reasoning are generally out of reach of these baselines) or require a cut introduction that is hard to generate, such as generating a non trivial witness.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Counts of successfully proved statements in miniF2F. Green bar: results from Lean GPT-f. Red bar: best result from the tidy baseline. Blue bar: results from Metamath GPT-f.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>a,sq_nonneg b,sq_nonneg (a -b)] end (The statement above (algebra_sqineq_2unitcircatblt1) requires to prove the assertion ?a</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>p11.0 $e |-( ph -&gt; A e. RR ) $. amc12-2000-p11.1 $e |-( ph -&gt; B e. RR ) $. amc12-2000-p11.2 $e |-( ph -&gt; A =/= 0 ) $. amc12-2000-p11.3 $e |-( ph -&gt; B =/= 0 ) $. amc12-2000-p11.4 $e |-( ph -&gt; ( A x. B ) = ( A -B ) ) $. amc12-2000-p11 $p |-( ph -&gt; ( ( ( A / B ) + ( B / A ) ) -( A x. B ) ) = 2 ) $= ( cdiv co caddc cmul cmin c2 cexp eqcomd ... $. $} Lean theorem amc12 2000 p11 (a b : R) (h 0 : a = 0 ? b = 0) (h 1 : a * b = a -b) : a / b + b / a -a * b = 2 := begin field simp [h 0 .1, h 0 .2], simp only [h 1 , mul comm, mul sub], ring, end Isabelle theorem amc12 2000 p11:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Number of statements and their provenance in miniF2F v1</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Test Set Validation Set</cell></row><row><cell></cell><cell>TOTAL</cell><cell></cell><cell>244</cell><cell>244</cell></row><row><cell></cell><cell>IMO</cell><cell></cell><cell>20</cell><cell>20</cell></row><row><cell></cell><cell>AIME</cell><cell></cell><cell>15</cell><cell>15</cell></row><row><cell></cell><cell>AMC</cell><cell></cell><cell>45</cell><cell>45</cell></row><row><cell></cell><cell></cell><cell>Level 5</cell><cell>14</cell><cell>14</cell></row><row><cell></cell><cell></cell><cell>Level 4</cell><cell>14</cell><cell>14</cell></row><row><cell></cell><cell>Algebra</cell><cell>Level 3</cell><cell>14</cell><cell>14</cell></row><row><cell></cell><cell></cell><cell>Level 2</cell><cell>14</cell><cell>14</cell></row><row><cell>MATH</cell><cell></cell><cell>Level 1 Level 5</cell><cell>14 16</cell><cell>14 16</cell></row><row><cell></cell><cell></cell><cell>Level 4</cell><cell>11</cell><cell>11</cell></row><row><cell></cell><cell>Number Theory</cell><cell>Level 3</cell><cell>11</cell><cell>11</cell></row><row><cell></cell><cell></cell><cell>Level 2</cell><cell>11</cell><cell>11</cell></row><row><cell></cell><cell></cell><cell>Level 1</cell><cell>11</cell><cell>11</cell></row><row><cell></cell><cell>Algebra</cell><cell></cell><cell>18</cell><cell>18</cell></row><row><cell>CUSTOM</cell><cell cols="2">Number Theory</cell><cell>8</cell><cell>8</cell></row><row><cell></cell><cell>Induction</cell><cell></cell><cell>8</cell><cell>8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>The table shows the number of solved statement in miniF2F when running the tidy baseline with different values of i max as well Lean's built-in tidy tactic. All tidy baseline experiments are run with ? max = 128, d max = 8 using L + HL. Despite the tidy baseline being deterministic, it is still subject to per-tactic application timeouts, explaining the number 43 reported on miniF2F-test for i max = 32.</figDesc><table><row><cell>parameters</cell><cell cols="2">miniF2F-valid miniF2F-test</cell></row><row><cell>Lean's tidy tactic</cell><cell>12 / 244</cell><cell>13 / 244</cell></row><row><cell>i max = 1</cell><cell>21 / 244</cell><cell>23 / 244</cell></row><row><cell>i max = 2</cell><cell>31 / 244</cell><cell>29 / 244</cell></row><row><cell>i max = 4</cell><cell>38 / 244</cell><cell>41 / 244</cell></row><row><cell>i max = 8</cell><cell>41 / 244</cell><cell>44 / 244</cell></row><row><cell>i max = 16</cell><cell>41 / 244</cell><cell>44 / 244</cell></row><row><cell>i max = 32</cell><cell>41 / 244</cell><cell>43 / 244</cell></row><row><cell>i max = 64</cell><cell>41 / 244</cell><cell>44 / 244</cell></row><row><cell>i max = 128</cell><cell>41 / 244</cell><cell>44 / 244</cell></row><row><cell>4.2.2 GPT-F/PACT</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Baseline performance on Metamath and Lean. All proof searches are provided with a 128 expansions budget. GPT-f attempts e = 16 tactics per expansion while the tidy baseline attempts e = 17 tactics per expansion (L + HL, see section 4.2.1). Reported proof lengths are averages over all the proofs found in each run. Note that the tidy baseline being deterministic, there is no point attempting a proof search more than once.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>miniF2F-valid</cell><cell></cell><cell></cell><cell>miniF2F-test</cell><cell></cell></row><row><cell>Formal System</cell><cell>Model</cell><cell>Proof Length</cell><cell cols="2">Pass rate Pass@1 Pass@8</cell><cell>Proof Length</cell><cell cols="2">Pass rate Pass@1 Pass@8</cell></row><row><cell cols="2">Metamath GPT-f</cell><cell>16.2</cell><cell>1.0%</cell><cell>2.0%</cell><cell>20.3</cell><cell>1.3%</cell><cell>1.6%</cell></row><row><cell>Lean</cell><cell>tidy</cell><cell>1.7</cell><cell>16.8%</cell><cell>-</cell><cell>1.8</cell><cell>18.0%</cell><cell>-</cell></row><row><cell>Lean</cell><cell>GPT-f</cell><cell>2.6</cell><cell>23.9%</cell><cell>29.3%</cell><cell>2.5</cell><cell>24.6%</cell><cell>29.2%</cell></row><row><cell cols="2">4.3 DISCUSSION</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">4.3.1 ACCESS TO HIGH-LEVEL TACTICS</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 :</head><label>6</label><figDesc>Counts of successfully proved statements formalized from MATH-Number theory in miniF2F v1 split by difficulty. This table corresponds to "MATH Number Theory" in Figure 1.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/openai/miniF2F/tree/v1</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Example: amc12a 2020 p10 in https://github.com/openai/miniF2F/blob/main/ lean/src/test.lean 3 Example: mathd algebra 398 in https://github.com/openai/miniF2F/blob/main/ lean/src/test.lean 4 Example: imo 1997 p5 in https://github.com/openai/miniF2F/blob/main/lean/ src/test.lean</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://github.com/jasonrute/lean_proof_recording/commit/ 8499f10c2e10dd533152070ed933c4f0b21ecdc0 6 https://github.com/jesse-michael-han/lean-step-public/commit/ a2b83c237bfe4d6f1c48bb48bc0769b5940e614a</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>We are grateful to Wenda Li and Xavier Martinet for contributing the Isabelle and HOL Light statements currently available in miniF2F, paving the way towards a full support of Isabelle and HOL Light, as well as their feedback and encouragement in the process. We thank Harri Edwards for his comments that greatly improved the manuscript.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Holist: An environment for machine learning of higher order logic theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitij</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stewart</forename><surname>Wilcox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="454" to="463" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Learning to reason in large theories without imitation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitij</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><forename type="middle">N</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><forename type="middle">M</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viktor</forename><surname>Toman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.10501</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melanie</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arvind</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Girish</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanda</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandhini</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ariel</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Clemens</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mateusz</forename><surname>Litwin</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin</editor>
		<meeting><address><addrLine>Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
	<note>Ilya Sutskever, and Dario Amodei</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Lean perfectoid spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Buzzard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Commelin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Massot</surname></persName>
		</author>
		<ptr target="https://leanprover-community.github.io/lean-perfectoid-spaces/" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Proof artifact co-training for theorem proving with language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><forename type="middle">Michael</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Rute</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Edward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Ayers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Polu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.06203</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Maximilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Haslbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Nipkow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wimmer</surname></persName>
		</author>
		<ptr target="https://www21.in.tum.de/?wimmers/proofground/" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Collin</forename><surname>Burns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurav</forename><surname>Kadavath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akul</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Basart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dawn</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Steinhardt</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.03874</idno>
		<title level="m">Measuring mathematical problem solving with the math dataset</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The mathlib Community. The lean mathematical library</title>
		<idno type="DOI">10.1145/3372885.3373824</idno>
		<ptr target="https://doi.org/10.1145/3372885" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs</title>
		<editor>Jasmin Blanchette and Catalin Hritcu</editor>
		<meeting>the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs<address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Graph representations for higher-order logic and theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Paliwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarah</forename><surname>Loos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Rabe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kshitij</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="2967" to="2974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The LAMBADA dataset: Word prediction requiring a broad discourse context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Paperno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germ?n</forename><surname>Kruszewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angeliki</forename><surname>Lazaridou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ngoc</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raffaella</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandro</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Pezzelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gemma</forename><surname>Baroni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Boleda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fern?ndez</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/p16-1144</idno>
		<ptr target="https://doi.org/10.18653/v1/p16-1144" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics, ACL 2016<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>: Long Papers. The Association for Computer Linguistics</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Generative language modeling for automated theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislas</forename><surname>Polu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03393</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Squad: 100, 000+ questions for machine comprehension of text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pranav</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantin</forename><surname>Lopyrev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d16-1264</idno>
		<ptr target="https://doi.org/10.18653/v1/d16-1264" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<editor>Jian Su, Xavier Carreras, and Kevin Duh</editor>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Austin, Texas, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The Association for Computational Linguistics</publisher>
			<date type="published" when="2016-11-01" />
			<biblScope unit="page" from="2383" to="2392" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Analysing mathematical reasoning abilities of neural models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Saxton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pushmeet</forename><surname>Kohli</surname></persName>
		</author>
		<idno>ICLR 2019</idno>
		<ptr target="https://openreview.net/forum?id=H1gR5iR5FX" />
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Liquid tensor experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Scholze</surname></persName>
		</author>
		<ptr target="https://xenaproject.wordpress.com/2020/12/05/liquid-tensor-experiment/" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Selsam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Buzzard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reid</forename><surname>Barton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percey</forename><surname>Liang</surname></persName>
		</author>
		<ptr target="https://imo-grand-challenge.github.io/" />
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>Sarah Loss, and Freek Wiedijk. Imo</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">The CADE ATP System Competition -CASC. AI Magazine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sutcliffe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="99" to="101" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The TPTP Problem Library and Associated Infrastructure. From CNF to TH0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sutcliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Automated Reasoning</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="483" to="502" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>TPTP v6.4.0</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">GLUE: A multi-task benchmark and analysis platform for natural language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amanpreet</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rJ4km2R5t7" />
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Welleck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiacheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Ronan Le Bras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yejin</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.01112</idno>
		<title level="m">Naturalproofs: Mathematical theorem proving in natural language</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Holophrasm: a neural automated theorem prover for higher-order logic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Whalen</surname></persName>
		</author>
		<idno>abs/1608.02644</idno>
		<ptr target="http://arxiv.org/abs/1608.02644" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Formalizing 100 theorems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Freek</forename><surname>Wiedijk</surname></persName>
		</author>
		<ptr target="https://www.cs.ru.nl/?freek/100/" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">INT: an inequality benchmark for evaluating generalization in theorem proving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhuai</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Baker Grosse</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=O6LPudowNQm" />
	</analytic>
	<monogr>
		<title level="m">9th International Conference on Learning Representations, ICLR 2021, Virtual Event</title>
		<meeting><address><addrLine>Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning to prove theorems via interacting with proof assistants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6984" to="6994" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
