<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Towards Total Recall in Industrial Anomaly Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Roth</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of T?bingen</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Latha</forename><surname>Pemula</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Amazon AWS</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joaquin</forename><surname>Zepeda</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Amazon AWS</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Amazon AWS</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Amazon AWS</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">Amazon AWS</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Towards Total Recall in Industrial Anomaly Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T11:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Being able to spot defective parts is a critical component in large-scale industrial manufacturing. A particular challenge that we address in this work is the cold-start problem: fit a model using nominal (non-defective) example images only. While handcrafted solutions per class are possible, the goal is to build systems that work well simultaneously on many different tasks automatically. The best peforming approaches combine embeddings from ImageNet models with an outlier detection model. In this paper, we extend on this line of work and propose PatchCore, which uses a maximally representative memory bank of nominal patchfeatures. PatchCore offers competitive inference times while achieving state-of-the-art performance for both detection and localization. On the challenging, widely used MVTec AD benchmark PatchCore achieves an image-level anomaly detection AUROC score of up to 99.6%, more than halving the error compared to the next best competitor. We further report competitive results on two additional datasets and also find competitive results in the few samples regime. Code: github.com/amazon-research/patchcore-inspection. * Work done during a research internship at Amazon AWS.</p><p>1 Commonly also dubbed one-class classification (OCC).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The ability to detect unusual patterns in images is a feature deeply ingrained in human cognition. Humans can differentiate between expected variance in the data and outliers after having only seen a small number of normal instances. In this work we address the computational version of this problem, cold-start 1 anomaly detection for visual inspection of industrial image data. It arises in many industrial scenarios where it is easy to acquire imagery of normal examples but costly and complicated to specify the expected defect variations in full. This task is naturally cast as a outof-distribution detection problem where a model needs to distinguish between samples being drawn from the training data distribution and those outside its support. Industrial visual defect classification is especially hard, as errors can <ref type="figure">Figure 1</ref>. Examples from the MVTec benchmark datasets. Superimposed on the images are the segmentation results from Patch-Core. The orange boundary denotes anomaly contours of actual segmentation maps for anomalies such as broken glass, scratches, burns or structural changes in blue-orange color gradients. vary from subtle changes such as thin scratches to larger structural defects like missing components <ref type="bibr" target="#b4">[5]</ref>. Some examples from the MVTec AD benchmark along with results from our proposed method are shown in <ref type="figure">Figure 1</ref>. Existing work on cold-start, industrial visual anomaly detection relies on learning a model of the nominal distribution via autoencoding methods <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b44">44]</ref>, GANs <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b43">43]</ref>, or other unsupervised adaptation methods <ref type="bibr" target="#b42">[42,</ref><ref type="bibr" target="#b57">56]</ref>. Recently, <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b9">10]</ref> proposed to leverag common deep representations from Im-ageNet classification without adaptation to the target distribution. Despite the missing adaptation, these models offer strong anomaly detection performance and even solid spatial localization of the defects. The key principle behind these techniques is a feature matching between the test sample and the nominal samples while exploiting the multiscale nature of deep feature representations. Subtle, finegrained defect segmentation is covered by high-resolution features, whereas structural deviations and full image-level anomaly detection are supposed to be covered by features at much higher abstraction levels. The inherent downside of this approach, since it is non-adaptive, is the limited matching confidence at the higher abstraction levels: high-level abstract features from ImageNet training coincide little with the abstract features required in an industrial environment. In addition, nominal context usable by these methods at test time is effectively limited by the small number of extractable high-level feature representations.</p><p>In this paper, we present PatchCore as an effective remedy by (1) maximizing nominal information available at test time, <ref type="bibr" target="#b1">(2)</ref> reducing biases towards ImageNet classes and (3) retaining high inference speeds. Relying on the fact that an image can be already classified as anomalous as soon as a single patch is anomalous <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b57">56]</ref>, Patch-Core achieves this by utilizing locally aggregated, mid-level features patches. The usage of mid-level network patch features allows PatchCore to operate with minimal bias towards ImageNet classes on a high resolution, while a feature aggregation over a local neighbourhood ensures retention of sufficient spatial context. This results in an extensive memory bank allowing PatchCore to optimally leverage available nominal context at test time. Finally, for practical applicability, PatchCore additionally introduces greedy coreset subsampling <ref type="bibr" target="#b0">[1]</ref> for nominal feature banks as a key element to both reduce redundancy in the extracted, patch-level memory bank as well as significantly bringing down storage memory and inference time, making Patch-Core very attractive for realistic industrial use cases.</p><p>Thorough experiments on the diverse MVTec AD <ref type="bibr" target="#b4">[5]</ref> as well as the specialized Magnetic Tile Defects (MTD) <ref type="bibr" target="#b25">[26]</ref> industrial anomaly detection benchmarks showcase the power of PatchCore for industrial anomaly detection. It achieves state-of-the-art image-level detection scores on MVTec AD and MTD, with nearly perfect scores on MVTec AD (up to AUROC 99.6%), reducing detection error of previous methods by more than half, as well as state-ofthe-art industrial anomaly localization performance. Patch-Core achieves this while retaining fast inference times without requiring training on the dataset at hand. This makes PatchCore very attractive for practical use in industrial anomaly detection. In addition, further experiments showcase the high sample efficiency of PatchCore, matching existing anomaly detection methods in performance while using only a fraction of the nominal training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head><p>Most anomaly detection models rely on the ability to learn representations inherent to the nominal data. This can be achieved for example through the usage of autoencoding models <ref type="bibr" target="#b44">[44]</ref>. To encourage better estimation of the nominal feature distribution, extensions based on Gaussian mixture models <ref type="bibr" target="#b61">[60]</ref>, generative adversarial training objectives <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b43">43]</ref>, invariance towards predefined physical augmentations <ref type="bibr" target="#b24">[25]</ref>, robustness of hidden features to reintroduction of reconstructions <ref type="bibr" target="#b28">[29]</ref>, prototypical memory banks <ref type="bibr" target="#b20">[21]</ref>, attention-guidance <ref type="bibr" target="#b53">[52]</ref>, structural objectives <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b60">59]</ref> or constrained representation spaces <ref type="bibr" target="#b38">[38]</ref> have been pro-posed. Other unsupervised representation learning methods can similarly be utilised, such as via GANs <ref type="bibr" target="#b12">[13]</ref>, learning to predict predefined geometric transformations <ref type="bibr" target="#b19">[20]</ref> or via normalizing flows <ref type="bibr" target="#b42">[42]</ref>. Given respective nominal representations and novel test representations, anomaly detection can then be a simple matter of reconstruction errors <ref type="bibr" target="#b44">[44]</ref>, distances to k nearest neighbours <ref type="bibr" target="#b17">[18]</ref> or finetuning of a one-class classification model such as OC-SVMs <ref type="bibr" target="#b47">[46]</ref> or SVDD <ref type="bibr" target="#b51">[50,</ref><ref type="bibr" target="#b57">56]</ref> on top of these features. For the majority of these approaches, anomaly localization comes naturally based on pixel-wise reconstruction errors, saliency-based approaches such as GradCAM <ref type="bibr" target="#b48">[47]</ref> or XRAI <ref type="bibr" target="#b27">[28]</ref> can be used for anomaly segmentation <ref type="bibr" target="#b42">[42,</ref><ref type="bibr" target="#b45">45,</ref><ref type="bibr" target="#b53">52]</ref> as well.</p><p>Industrial Anomaly Detection. While literature on general anomaly detection through learned nominal representations is vast, industrial image data comes with its own challenges <ref type="bibr" target="#b4">[5]</ref>, for which recent works starting with <ref type="bibr" target="#b3">[4]</ref> have shown state-of-the-art detection performance using models pretrained on large external natural image datasets such as ImageNet <ref type="bibr" target="#b15">[16]</ref> without any adaptation to the data at hand. This has given rise to other industrial anomaly detection methods reliant on better reuse of pretrained features such as SPADE <ref type="bibr" target="#b9">[10]</ref>, which utilizes memory banks comprising various feature hierarchies for finegrained, kNN-based <ref type="bibr" target="#b17">[18]</ref> anomaly segmentation and image-level anomaly detection. Similarly, <ref type="bibr" target="#b13">[14]</ref> recently proposed PaDiM, which utilizes a locally constrained bag-of-features approach <ref type="bibr" target="#b7">[8]</ref>, estimating patch-level feature distribution moments (mean and covariance) for patch-level Mahalanobis distance measures <ref type="bibr" target="#b33">[33]</ref>. This approach is similar to <ref type="bibr" target="#b40">[40]</ref> studied on full images. To better account for the distribution shift between natural pretraining and industrial image data, subsequent adaptation can be done, e.g. via student-teacher knowledge distillation <ref type="bibr" target="#b23">[24]</ref> such as in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b45">45]</ref> or normalizing flows <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b29">30]</ref> trained on top of pretrained network features <ref type="bibr" target="#b42">[42]</ref>.</p><p>The specific components used in PatchCore are most related to SPADE and PaDiM. SPADE makes use of a memory-bank of nominal features extracted from a pretrained backbone network with separate approaches for image-and pixel-level anomaly detection. PatchCore similarly uses a memory bank, however with neighbourhoodaware patch-level features critical to achieve higher performance, as more nominal context is retained and a better fitting inductive bias is incorporated. In addition, the memory bank is coreset-subsampled to ensure low inference cost at higher performance. Coresets have seen longstanding usage in fundamental kNN and kMeans approaches <ref type="bibr" target="#b21">[22]</ref> or mixture models <ref type="bibr" target="#b18">[19]</ref> by finding subsets that best approximate the structure of some available set and allow for approximate solution finding with notably reduced cost <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b8">9]</ref>. More recently, coreset-based methods have also found their way into Deep Learning approaches, e.g for network pruning <ref type="bibr" target="#b34">[34]</ref>, active learning <ref type="bibr" target="#b49">[48]</ref> and increasing effective data coverage of mini-batches for improved GAN training <ref type="bibr" target="#b50">[49]</ref> or representation learning <ref type="bibr" target="#b41">[41]</ref>. The latter three have found success utilizing a greedy coreset selection mechanism. As we aim to approximate memory bank feature space coverage, we similarly adapt a greedy coreset mechanism for PatchCore . Finally, our patch-level approach to both image-level anomaly detection and anomaly segmentation is related to PaDiM with the goal of encouraging higher anomaly detection sensitivity. We make use of an efficient patch-feature memory bank equally accessible to all patches evaluated at test time, whereas PaDiM limits patch-level anomaly detection to Mahalanobis distance measures specific to each patch. In doing so, PatchCore becomes less reliant on image alignment while also estimating anomalies using a much larger nominal context. Furthermore, unlike PaDiM, input images do not require the same shape during training and testing. Finally, PatchCore makes use of locally aware patch-feature scores to account for local spatial variance and to reduce bias towards ImageNet classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head><p>The PatchCore method consists of several parts that we will describe in sequence: local patch features aggregated into a memory bank ( ?3.1), a coreset-reduction method to increase efficiency ( ?3.2) and finally the full algorithm that arrives at detection and localization decisions ( ?3.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Locally aware patch features</head><p>We use X N to denote the set of all nominal images (?x ? X N : y x = 0) available at training time, with y x ? {0, 1} denoting if an image x is nominal (0) or anomalous <ref type="bibr" target="#b0">(1)</ref>. Accordingly, we define X T to be the set of samples provided at test time, with ?x ? X T : y x ? {0, 1}. Following <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b13">[14]</ref>, PatchCore uses a network ? pre-trained on ImageNet. As the features at specific network hierarchies plays an important role, we use ? i,j = ? j (x i ) to denote the features for image x i ? X (with dataset X ) and hierarchylevel j of the pretrained network ?. If not noted otherwise, in concordance with existing literature, j indexes feature maps from ResNet-like <ref type="bibr" target="#b22">[23]</ref> architectures, such as ResNet-50 or WideResnet-50 <ref type="bibr" target="#b58">[57]</ref>, with j ? {1, 2, 3, 4} indicating the final output of respective spatial resolution blocks.</p><p>One choice for a feature representation would be the last level in the feature hierarchy of the network. This is done in <ref type="bibr" target="#b3">[4]</ref> or <ref type="bibr" target="#b9">[10]</ref> but introduces the following two problems. Firstly, it loses more localized nominal information <ref type="bibr" target="#b13">[14]</ref>. As the types of anomalies encountered at test time are not known a priori, this becomes detrimental to the downstream anomaly detection performance. Secondly, very deep and abstract features in ImageNet pretrained networks are biased towards the task of natural image classification, which has only little overlap with the cold-start industrial anomaly detection task and the evaluated data at hand.</p><p>We thus propose to use a memory bank M of patch-level features comprising intermediate or mid-level feature representations to make use of provided training context, avoiding features too generic or too heavily biased towards Im-ageNet classification. In the specific case of ResNet-like architectures, this would refer to e.g. j ? <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>. To formalize the patch representation we extend the previously introduced notation. Assume the feature map ? i,j ? R c * ?h * ?w * to be a three-dimensional tensor of depth c * , height h * and width w * . We then use ? i,j (h, w) = ? j (x i , h, w) ? R c * to denote the c * -dimensional feature slice at positions h ? {1, . . . , h * } and w ? {1, . . . , w * }. Assuming the receptive field size of each ? i,j to be larger than one, this effectively relates to image-patch feature representations. Ideally, each patch-representation operates on a large enough receptive field size to account for meaningful anomalous context robust to local spatial variations. While this could be achieved by strided pooling and going further down the network hierarchy, the thereby created patch-features become more ImageNet-specific and thus less relevant for the anomaly detection task at hand, while training cost increases and effective feature map resolution drops.</p><p>This motivates a local neighbourhood aggregation when composing each patch-level feature representation to increase receptive field size and robustness to small spatial deviations without losing spatial resolution or usability of feature maps. For that, we extend above notation for ? i,j (h, w) to account for an uneven patchsizes p (corresponding to the neighbourhood size considered), incorporating feature vectors from the neighbourhood</p><formula xml:id="formula_0">N (h,w) p = {(a, b)|a ? [h ? p/2 , ..., h + p/2 ], b ? [w ? p/2 , ..., w + p/2 ]},<label>(1)</label></formula><p>and locally aware features at position (h, w) as . For PatchCore, we use adaptive average pooling. This is similar to local smoothing over each individual feature map, and results in one single representation at (h, w) of predefined dimensionality d, which is performed for all pairs (h, w) with h ? {1, ..., h * } and w ? {1, ..., w * } and thus retains feature map resolution. For a feature map tensor ? i,j , its locally aware patch-feature collection P s,p (? i,j ) is</p><formula xml:id="formula_1">? i,j N (h,w) p = f agg {? i,j (a, b)|(a, b) ? N (h,w) p } ,<label>(2)</label></formula><formula xml:id="formula_2">P s,p (? i,j ) = {? i,j (N (h,w) p )| h, w mod s = 0, h &lt; h * , w &lt; w * , h, w ? N},<label>(3)</label></formula><p>with the optional use of a striding parameter s, which we set to 1 except for ablation experiments done in ?4.4.2. Empirically and similar to <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b13">[14]</ref>, we found aggregation of multiple feature hierarchies to offer some benefit. However, to retain the generality of used features as well as the spatial resolution, PatchCore uses only two intermediate feature hierarchies j and j + 1. This is achieved simply by computing P s,p (? i,j+1 ) and aggregating each element with its corresponding patch feature at the lowest hierarchy level used (i.e., at the highest resolution), which we achieve by bi-</p><formula xml:id="formula_3">linearly rescaling P s,p (? i,j+1 ) such that |P s,p (? i,j+1 )| and |P s,p (? i,j )| match.</formula><p>Finally, for all nominal training samples x i ? X N , the PatchCore memory bank M is then simply defined as</p><formula xml:id="formula_4">M = xi?X N P s,p (? j (x i )).<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Coreset-reduced patch-feature memory bank</head><p>For increasing sizes of X N , M becomes exceedingly large and with it both the inference time to evaluate novel test data and required storage. This issue has already been noted in SPADE <ref type="bibr" target="#b9">[10]</ref> for anomaly segmentation, which makes use of both low-and high-level feature maps. Due to computational limitations, SPADE requires a preselec-tion stage of feature maps for pixel-level anomaly detection based on a weaker image-level anomaly detection mechanism reliant on full-image, deep feature representations, i.e., global averaging of the last feature map. This results in low-resolution, ImageNet-biased representations computed from full images which may negatively impact detection and localization performance.</p><p>These issues can be addressed by making M meaningfully searchable for larger image sizes and counts, allowing for patch-based comparison beneficial to both anomaly detection and segmentation. This requires that the nominal feature coverage encoded in M is retained. Unfortunately, random subsampling, especially by several magnitudes, will lose significant information available in M encoded in the coverage of nominal features (see also experiments done in ?4. <ref type="bibr">4.2)</ref>. In this work we use a coreset subsampling mechanism to reduce M, which we find reduces inference time while retaining performance.</p><p>Conceptually, coreset selection aims to find a subset S ? A such that problem solutions over A can be most closely and especially more quickly approximated by those computed over S <ref type="bibr" target="#b0">[1]</ref>. Depending on the specific problem, the coreset of interest varies. Because PatchCore uses nearest neighbour computations (next Section), we use a minimax facility location coreset selection, see e.g., <ref type="bibr" target="#b49">[48]</ref> and <ref type="bibr" target="#b50">[49]</ref>, to ensure approximately similar coverage of the M-coreset M C in patch-level feature space as compared to the original memory bank M</p><formula xml:id="formula_5">M * C = arg min M C ?M max m?M min n?M C m ? n 2 .<label>(5)</label></formula><p>The exact computation of M * C is NP-Hard <ref type="bibr" target="#b55">[54]</ref>, we use the iterative greedy approximation suggested in <ref type="bibr" target="#b49">[48]</ref>. To further reduce coreset selection time, we follow <ref type="bibr" target="#b50">[49]</ref>, making use of the Johnson-Lindenstrauss theorem <ref type="bibr" target="#b10">[11]</ref> to reduce dimensionalities of elements m ? M through random linear projections ? :</p><formula xml:id="formula_6">R d ? R d * with d * &lt; d.</formula><p>The memory bank reduction is summarized in Algorithm 1. For notation, we use PatchCore?n% to denote the percentage n to which the original memory bank has been subsampled to, e.g., Patch-Core?1% a 100x times reduction of M. <ref type="figure">Figure 3</ref> gives a visual impression of the spatial coverage of greedy coreset subsampling compared to random selection.</p><p>Algorithm 1: PatchCore memory bank.</p><p>Input: Pretrained ?, hierarchies j, nominal data X N , stride s, patchsize p, coreset target l, random linear projection ?.</p><formula xml:id="formula_7">Output: Patch-level Memory bank M. Algorithm: M ? {} for x i ? X N do M ? M ? P s,p (? j (x i )) end / * Apply greedy coreset selection. * / M C ? {} for i ? [0, ..., l ? 1] do m i ? arg max m?M?M C min n?M C ?(m) ? ?(n) 2 M C ? M C ? {m i } end M ? M C</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Anomaly Detection with PatchCore</head><p>With the nominal patch-feature memory bank M, we estimate the image-level anomaly score s ? R for a test image x test by the maximum distance score s * between test patchfeatures in its patch collection P(x test ) = P s,p (? j (x test )) to each respective nearest neighbour m * in M:</p><formula xml:id="formula_8">m test, * , m * = arg max m test ?P(x test ) arg min m?M m test ? m 2 s * = m test, * ? m * 2 .<label>(6)</label></formula><p>To obtain s, we use scaling w on s * to account for the behaviour of neighbour patches: If memory bank features closest to anomaly candidate m test, * , m * , are themselves far from neighbouring samples and thereby an already rare nominal occurrence, we increase the anomaly score</p><formula xml:id="formula_9">s = 1 ? exp m test, * ? m * 2 m?N b (m * ) exp m test, * ? m 2 ? s * ,<label>(7)</label></formula><p>with N b (m * ) the b nearest patch-features in M for test patch-feature m * . We found this re-weighting to be more robust than just the maximum patch distance. Given s, segmentations follow directly. The image-level anomaly score in Eq. 7 (first line) requires the computation of the anomaly score for each patch through the arg max-operation. A segmentation map can be computed in the same step, similar to <ref type="bibr" target="#b13">[14]</ref>, by realigning computed patch anomaly scores based on their respective spatial location. To match the original input resolution, (we may want to use intermediate network features), we upscale the result by bi-linear interpolation. Additionally, we smoothed the result with a Gaussian of kernel width ? = 4, but did not optimize this parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experimental Details</head><p>Datasets. To study industrial anomaly detection performance, the majority of our experiments are performed on the MVTec Anomaly Detection benchmark <ref type="bibr" target="#b4">[5]</ref>. MVTec AD contains 15 sub-datasets with a total of 5354 images, 1725 of which are in the test set. Each sub-dataset is divided into nominal-only training data and test sets containing both nominal and anomalous samples for a specific product with various defect types as well as respective anomaly ground truth masks. As in <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b57">56]</ref>, images are resized and center cropped to 256 ? 256 and 224 ? 224, respectively. No data augmentation is applied, as this requires prior knowledge about class-retaining augmentations. We also study industrial anomaly detection on more specialized tasks. For that, we leverage the Magnetic Tile Defects (MTD) <ref type="bibr" target="#b25">[26]</ref> dataset as used in <ref type="bibr" target="#b42">[42]</ref>, which contains 925 defect-free and 392 anomalous magnetic tile images with varied illumination levels and image sizes. Same as in <ref type="bibr" target="#b42">[42]</ref>, 20% of defect-free images are evaluated against at test time, with the rest used for cold-start training. Finally, we also highlight potential applicability of Patch-Core to non-industrial image data, benchmarking coldstart anomaly localization on Mini Shanghai Tech Campus (mSTC) as done in e.g. <ref type="bibr" target="#b53">[52]</ref> and <ref type="bibr" target="#b13">[14]</ref>. mSTC is a subsampled version of the original STC dataset <ref type="bibr" target="#b32">[32]</ref>, only using every fifth training and test video frame. It contains pedestrian videos from 12 different scenes. Training videos include normal pedestrian behaviour while test videos can contain different behaviours such as fighting or cycling. For comparability of our cold-start experiments, we follow established mSTC protocols <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b53">52]</ref>, not making use of any anomaly supervision and images resized to 256 ? 256.</p><p>Evaluation Metrics. Image-level anomaly detection performance is measured via the area under the receiveroperator curve (AUROC) using produced anomaly scores. In accordance with prior work we compute on MVTec the class-average AUROC <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b13">14]</ref>. To measure segmentation performance, we use both pixel-wise AUROC and the PRO metric first, both following <ref type="bibr" target="#b5">[6]</ref>. The PRO score takes into account the overlap and recovery of connected anomaly components to better account for varying anomaly sizes in MVTec AD, see <ref type="bibr" target="#b5">[6]</ref> for details. <ref type="table">Table 1</ref>. Anomaly Detection Performance (AUROC) on MVTec AD <ref type="bibr" target="#b4">[5]</ref>. PaDiM * denotes a result from <ref type="bibr" target="#b13">[14]</ref> with problem-specific backbone selection. The total count of misclassifications was determined as the sum of false-positive and false-negative predictions given a F1-optimal threshold. We did not have individual anomaly scores for competing methods so could compute this number only for PatchCore.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Anomaly Detection on MVTec AD</head><p>The results for image-level anomaly detection on MVTec are shown in <ref type="table">Table 1</ref>. For PatchCore we report on various levels of memory bank subsampling (25%, 10% and 1%). For all cases, PatchCore achieves significantly higher mean image anomaly detection performance with consistently high performance on all sub-datasets (see supplementary B for detailed comparison). Please note, that a reduction from an error of 2.1% (PaDiM) to 0.9% for Patch-Core?25% means a reduction of the error by 57%. In industrial inspection settings this is a relevant and significant reduction. For MVTec at optimal F1 threshold, there are only 42 out of 1725 images classified incorrectly and a third of all classes are solved perfectly. In the supplementary material B we also show that both with F1-optimal working point and at full recall, classification errors are also lower when compared to both SPADE and PaDiM. With Patch-Core, less than 50 images remain misclassified. In addition, PatchCore achieves state-of-the-art anomaly segmentation, both measured by pixelwise AUROC ( <ref type="table" target="#tab_1">Table 2</ref>, 98.1 versus 97.5 for PaDiM) and PRO metric ( <ref type="table" target="#tab_2">Table 3</ref>, 93.5 versus 92.1). Sample segmentations in <ref type="figure">Figure 1</ref> offer qualitative impressions of the accurate anomaly localization.</p><p>In addition, due to the effectiveness of our coreset memory subsampling, we can apply PatchCore?1% on images of higher resolution (e.g. 280/320 instead of 224) and en-semble systems while retaining inferences times less than PatchCore?10% on the default resolution. This allows us to further push image-and pixel-level anomaly detection as highlighted in Tab. 4 (detailed results in supplementary), in parts more than halving the error again (e.g. 1% ? 0.4% for image-level AUROC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Inference Time</head><p>The other dimension we are interested in is inference time. We report results in <ref type="table" target="#tab_3">Table 5</ref> (implementation details in supp. A) comparing to reimplementations of SPADE <ref type="bibr" target="#b9">[10]</ref> and PaDiM <ref type="bibr" target="#b13">[14]</ref> using WideResNet50 and operations on GPU where possible. These inference times include the forward pass through the backbone. As can be seen, inference time for joint image-and pixel-level anomaly detection of PatchCore?100% (without subsampling) are lower than SPADE <ref type="bibr" target="#b9">[10]</ref> but with higher performance. With coreset subsampling, Patchcore can be made even faster, with lower inference times than even PaDiM while retaining state-of-the-art image-level anomaly detection and segmentation performance. Finally, we examine PatchCore?100% with approximate nearest neighbour search (IVFPQ <ref type="bibr" target="#b26">[27]</ref>) as an orthogonal way of reducing inference time (which can also be applied to SPADE, however which already performs notably worse than even PatchCore?1%). We find a performance drop, especially for image-level anomaly detection, while inference times are still higher than Patch-Core?1%. Though even with performance reduction, approximate nearest neighbour search on PatchCore?100% still outperforms other methods. A combination of coreset and approximate nearest neighbour would further reduce inference time, allowing scaling to much larger datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablations Study</head><p>We report on ablations for the locally aware patchfeatures and the coreset reduction method. Supplementary experiments show consistency across different backbones ( ?C.2), scalability with increased image resolution ( ?C.3) and a qualitative analysis of remaining errors ( ?C.4).   <ref type="figure">Figure 5</ref>. Performance retention for different subsamplers, results for PRO score in the supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.1">Locally aware patch-features and hierarchies</head><p>We investigate the importance of locally aware patchfeatures ( ?3.3) by evaluating changes in anomaly detection performance over different neighbourhood sizes in Eq. 1. Results in the top half of <ref type="figure" target="#fig_2">Figure 4</ref> show a clear optimum between locality and global context for patch-based anomaly predictions, thus motivating the neighbourhood size p = 3.</p><p>More global context can also be achieved by moving down the network hierarchy (see e.g. <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b13">14]</ref>), however at the cost of reduced resolution and heavier ImageNet class bias ( ?3.1). Indexing the first three WideResNet50-blocks with 1 -3, <ref type="figure" target="#fig_2">Fig. 4 (bottom)</ref> again highlights an optimum between highly localized predictions, more global context and Ima-geNet bias. As can be seen, features from hierarchy level 2 can already achieve state-of-the-art performance, but benefit from additional feature maps taken from subsequent hierarchy levels (2+3, which is chosen as the default setting). <ref type="figure">Figure 5</ref> compares different memory bank M subsampling methods: Greedy coreset selection, random subsampling and learning of a set of basis proxies corresponding to the subsampling target percentage p target . For the latter, we sample proxies p i ? P ? R d with |P| = p target ? |M|, which are then tasked to minimize a basis reconstruction objective</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.2">Importance of Coreset subsampling</head><formula xml:id="formula_10">L rec (m i ) = m i ? p k ?P e mi?p k 2 pj ?P e mi?pj p k 2 2 ,<label>(8)</label></formula><p>to find N proxies that best describe the memory bank data M. In <ref type="figure">Figure 5</ref> we compare the three settings and find that coreset-based subsampling performs better than the other possible choices. The performance of no subsampling is comparable to a coreset-reduced memory bank that is two orders of magnitudes smaller in size. We also find subsampled memory banks to contain much less redundancy. We recorded the percentage of memory bank samples that are used at test time for non-subsampled and coreset-subsampled memory banks. While initially only less than 30% of memory bank samples are used, coreset subsampling (to 1%) increases this factor to nearly 95%. For certain subsampling intervals (between around 50% and 10%), we even find joint performance over anomaly detection and localization to partly increase as compared to nonsubsampled PatchCore . Finally, reducing the memory bank size M by means of increased striding (see Eq. 3) shows worse performance due to the decrease in resolution context, with stride s = 2 giving an image anomaly detection AUROC of 97.6%, and stride s = 3 an AUROC of 96.8%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Low-shot Anomaly Detection</head><p>Having access to limited nominal data is a relevant setting for real-world inspection. Therefore in addition to reporting results on the full MVTec AD, we also study the performance with fewer training examples. We vary the amount of training samples from 1 (corresponding to 0.4% of the total nominal training data) to 50 (21%), and compare to reimplementations of SPADE <ref type="bibr" target="#b9">[10]</ref> and PaDiM <ref type="bibr" target="#b13">[14]</ref> using the same backbone (WideResNet50). Results are summarized in <ref type="figure">Figure 6</ref>, with detailed results available in Supp. <ref type="figure">Figure 6</ref>. PatchCore shows notably higher sample-efficiency than competitors, matching the previous state-of-the-art with a fraction of nominal training data. Note that PaDiM and SPADE where reimplemented with WideResNet50 for comparability. <ref type="table">Table 6</ref>. Anomaly Segmentation on mSTC <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b53">52]</ref> and anomaly detection on MTD <ref type="bibr" target="#b25">[26]</ref> compared to results reported in <ref type="bibr" target="#b42">[42]</ref>. 76.6 80.0 97.7 97.9 ?C.1. As shown, using only one fifth of nominal training data, PatchCore can still match previous state-of-the-art performance. In addition, comparing to the 16-shot experiments performed in <ref type="bibr" target="#b42">[42]</ref>, we find PatchCore to outperform their approach which adapts a normalizing flows model on top of already pretrained features. Compared to image-level memory approaches in <ref type="bibr" target="#b9">[10]</ref>, we find matching localization and detection performance with only 5/1 nominal shots.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Evaluation on other benchmarks</head><p>We benchmark PatchCore on two additional anomaly detection performance benchmarks: The ShanghaiTech Campus dataset (STC) <ref type="bibr" target="#b32">[32]</ref> and the Magnetic Tile Defects dataset (MTD) <ref type="bibr" target="#b25">[26]</ref>. Evaluation for STC as described in ?4.1 follows <ref type="bibr" target="#b53">[52]</ref>, <ref type="bibr" target="#b13">[14]</ref> and <ref type="bibr" target="#b9">[10]</ref>. We report unsupervised anomaly localization performance on a subsampled version of the STC video data (mSTC), with images resized to 256 ? 256 <ref type="bibr" target="#b13">[14]</ref>. As the detection context is much closer to natural image data available in ImageNet, we make use of deeper network feature maps at hierarchy levels 3 and 4, but otherwise do not perform any hyperparameter tuning for PatchCore. The results in <ref type="table">Table 6</ref> (top) show state-ofthe-art anomaly localization performance which suggests good transferability of PatchCore to such domains. Finally, we examine MTD, containing magnetic tile defect images of varying sizes on which spatially rigid approaches like PaDiM cannot be applied directly. Here, nominal data already exhibits high variability similar to those encountered in anomalous samples <ref type="bibr" target="#b42">[42]</ref>. We follow the protocol proposed in <ref type="bibr" target="#b42">[42]</ref> to measure image-level anomaly detection performance and find performance to match (and even slightly outperform) that of <ref type="bibr" target="#b42">[42]</ref>  <ref type="table">(Table 6</ref>, bottom).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>This paper introduced the PatchCore algorithm for coldstart anomaly detection, in which knowledge of only nominal examples has to be leveraged to detect and segment anomalous data at test-time. PatchCore strikes a balance between retaining a maximum amount of nominal context at test-time through the usage of memory banks comprising locally aware, nominal patch-level feature representations extracted from ImageNet pretrained networks, and minimal runtime through coreset subsampling. The result is a state-of-the-art cold-start image anomaly detection and localization system with low computational cost on industrial anomaly detection benchmarks. On MVTec, we achieve an image anomaly detection AUROC over 99% with highest sample efficiency in relevant small training set regimes.</p><p>Broader Impact. As automated industrial anomaly detection is one of the most successful applications of Computer Vision, the improvements gained through Patch-Core can be of notable interest for practitioners in this domain. As our work focuses specifically on industrial anomaly detection, negative societal impact is limited. And while the fundamental approach can potentially we leveraged for detection systems in more controversial domains, we don't believe that our improvements are significant enough to change societal application of such systems.</p><p>Limitations. While PatchCore shows high effectiveness for industrial anomaly detection without the need to specifically adapt to the problem domain at hand, applicability is generally limited by the transferability of the pretrained features leveraged. This can be addressed by merging the effectiveness of PatchCore with adaptation of the utilized features. We leave this interesting extension to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary: Towards Total Recall in Industrial Anomaly Detection</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation Details</head><p>We implemented our models in Python 3.7 <ref type="bibr" target="#b52">[51]</ref> and PyTorch <ref type="bibr" target="#b37">[37]</ref>. Experiments are run on Nvidia Tesla V4 GPUs. We used torchvision ImageNet-pretrained models from torchvision and the PyTorch Image Models repository <ref type="bibr" target="#b54">[53]</ref>. By default, following <ref type="bibr" target="#b9">[10]</ref> and <ref type="bibr" target="#b13">[14]</ref>, PatchCore uses a WideResNet50-backbone <ref type="bibr" target="#b58">[57]</ref> for direct comparability. Patch-level features are taken from feature map aggregation of the final outputs in blocks 2 and 3. For all nearest neighbour retrieval and distance computations, we use faiss <ref type="bibr" target="#b26">[27]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Full MVTec AD comparison</head><p>This section contains a more detailed comparison on MVTec AD. We include more models and a more finegrained performance comparison on all MVTec AD sub-datasets where available. In the main part of the paper this has been referenced in ?4.2. The corresponding result tables are S1, S2 and S3. We observe that PatchCore?25% solves six of the 15 MVTec datasets and achieves highest AUROC performance on most datasets and in average. <ref type="figure">Figure S3</ref> show Precision-Recall and ROC curves for PatchCore variants as well as reimplemented, comparable methods SPADE <ref type="bibr" target="#b9">[10]</ref> and PaDiM <ref type="bibr" target="#b13">[14]</ref> using a WideResNet50 backbone. We also plot classification error both at 100% recall and under a F1-optimal threshold to give a comparable working point. As can be seen, PatchCore achieves consistently low classification errors with defined working points as well, with near-optimal Precision-Recall and ROC curves across datasets, in contrast to SPADE and PaDiM.</p><p>Finally, <ref type="table">Table S4</ref> showcases the detailed performance on all MVTec AD subdatasets for larger imagesizes (280 ? 280) and a WideResNet-101 backbone for further performance boosts using PatchCore?1%, which allows for efficient anomaly detection at inference time even with larger images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Additional Ablations &amp; Details</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Detailed Low-Shot experiments</head><p>This section offers detailed numerical values to the low-shot method study provided in the main part of this work ( ?4.5). The results are included in <ref type="table" target="#tab_3">Table S5</ref> and we find consistently higher numbers for detection and anomaly localization metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2. Dependency on pretrained networks</head><p>We tested PatchCore with different backbones, the results are shown in S6. We find that results are mostly stable over the choice of different backbones. The choice of WideResNet50 was made to be comparable with SPADE and PaDiM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3. Influence of image resolution</head><p>Next we study the influence of image size on performance. In the main paper we have used 224 ? 224 to be comparable with prior work. In <ref type="figure" target="#fig_2">Figure S4</ref> we vary the image size from 288 ? 288, 360 ? 360 to 448 ? 448 and the neighborhood sizes (P) within 3, 5, 7, and 9. We observe slightly increased detection performance and the performance saturates for PatchCore . For anomaly segmentation we observe a consistent increase, so if good localization is of importance, this is an ingredient to validate over.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.4. Remaining Misclassifications</head><p>The high image-level anomaly detection performance allows us to look into all remaining misclassifications in detail. We compute the working point (threshold above which scores are considered anomalous) using the F1-optimal point. With this threshold a total of 19 false-positive and 23 false-negative errors remain, all of which are visualized in Figures S1 and S2. Each segmentation map was normalized to the threshold value, so in some cases background scores are pronounced disproportionally.</p><p>Looking at <ref type="figure">Figure S1</ref>, we find that the majority of false-positive errors either stem from a) (in blue) ambiguity in labelling , i.e., image changes that could also be potentially labelled as anomalous, and b) (in orange) very high nominal variance, <ref type="figure">Figure S1</ref>. Visualization of remaining false positive classifications (under F1-optimal thresholding). Colors denote different error sources. Orange denotes high degrees of nominal variance mistaken for anomalies, blue denotes misclassifications due to anomalies in the labelling context and olive denotes variance in the background mistaken for anomalous content. resembling potential anomalies . While the former can hardly be addressed by proposed methods, the latter could be addressed by offering some form of adaptation to the nominal data. However, as PatchCore outperforms adaptive methods, such adaptation would show most promise operating alongside pretraining-based methods such as PatchCore .</p><p>To understand false-negative errors made, we include in <ref type="figure">Figure S2</ref> the generated segmentation maps and ground-truth masks. As can be seen, a large part of anomalies are localized well, however with insufficient weight placed on the anomalous regions, and could potentially be addressed by some means of postprocessing. Other misclassifications are caused mostly by either high degrees of nominal variance that gets mistaken for anomalous context, and finegrained anomalies that could be captured when moving to higher image resolutions. The amount of completely missed anomalies is small in comparison, and in one case caused by image preprocessing cropping out the actual anomalous region.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.5. Local Awareness and Subsampling</head><p>For completeness we repeat the <ref type="figure" target="#fig_2">Figures 4 and 5</ref> from the main paper with included PRO score results in S5 and S6. <ref type="figure">Figure S2</ref>. Visualization of remaining false-negative classifications (under F1-optimal thresholding). Colors denote different error sources. Orange denotes high degrees of nominal variance mistaken for anomalies, green denotes actually localized anomalies, but too little weight placed on these anomalies, pink stands for anomalies that were not recovered, purple denotes anomalies missed due to cropping-based image-processing (one anomaly in total), and gray stands for finegrained anomalies that could be recovered when operating on higher image resolutions. <ref type="table">Table S1</ref>. Anomaly Detection Performance (AUROC) on MVTec AD <ref type="bibr" target="#b4">[5]</ref>. PaDiM * denotes a result from <ref type="bibr" target="#b13">[14]</ref> with a backbone specifically selected for the task of image-level anomaly detection, which we could not reproduce.  <ref type="figure">Figure S3</ref>. Precision-Recall curves (left) and ROC curves (right) for PatchCore , variants and comparable methods SPADE <ref type="bibr" target="#b9">[10]</ref> and PaDiM <ref type="bibr" target="#b13">[14]</ref>. Different colors in the lines correspond to difference MVTec classes.  <ref type="figure" target="#fig_2">Figure S4</ref>. Influence of image size (S) and neighbourhood size (P) on PatchCore performance. The PatchCore baseline with default values is included for reference. <ref type="figure">Figure S5</ref>. Influence of local awareness and network feature depths on anomaly detection performance. <ref type="figure">Figure S6</ref>. Performance retention for different subsamplers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>with f agg some aggregation function of feature vectors in the neighbourhood N (h,w) p</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .Figure 3 .</head><label>23</label><figDesc>Overview of PatchCore. Nominal samples are broken down into a memory bank of neighbourhood-aware patch-level features. For reduced redundancy and inference time, this memory bank is downsampled via greedy coreset subsampling. At test time, images are classified as anomalies if at least one patch is anomalous, and pixel-level anomaly segmentation is generated by scoring each patch-feature. Comparison: coreset (top) vs. random subsampling (bottom) (red) for 2D data (iblue) sampled from (a) multimodal and (b) uniform distributions. Visually, coreset subsampling better approximates the spatial support, random subsampling misses clusters in the multi-modal case and is less uniform in (b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Local awareness and network feature depths vs. detection performance. PRO score results in the supplementary.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Anomaly Segmentation Performance (pixelwise AUROC) on MVTec AD<ref type="bibr" target="#b4">[5]</ref>.</figDesc><table><row><cell>Method</cell><cell cols="9">AESSIM [5] ?-VAE + grad. [15] CAVGA-Rw [52] PatchSVDD [56] SPADE [10] PaDiM [14] PatchCore?25% PatchCore?10% PatchCore?1%</cell></row><row><cell>AUROC ?</cell><cell>87</cell><cell>88.8</cell><cell>89</cell><cell>95.7</cell><cell>96.0</cell><cell>97.5</cell><cell>98.1</cell><cell>98.1</cell><cell>98.0</cell></row><row><cell>Error ?</cell><cell>13</cell><cell>11.2</cell><cell>11</cell><cell>4.3</cell><cell>4.0</cell><cell>2.5</cell><cell>1.9</cell><cell>1.9</cell><cell>2.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Anomaly Detection Performance on MVTec AD<ref type="bibr" target="#b4">[5]</ref> as measured in PRO [%]<ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b9">10]</ref>.</figDesc><table><row><cell></cell><cell cols="8">Method AE SSIM [5] Student [6] SPADE [10] PaDiM [14] PatchCore?25% PatchCore?10% PatchCore?1%</cell></row><row><cell></cell><cell>PRO ?</cell><cell>69.4</cell><cell>85.7</cell><cell>91.7</cell><cell>92.1</cell><cell>93.4</cell><cell>93.5</cell><cell>93.1</cell></row><row><cell></cell><cell>Error ?</cell><cell>30.6</cell><cell>14.3</cell><cell>8.3</cell><cell>7.9</cell><cell>6.6</cell><cell>6.5</cell><cell>6.9</cell></row><row><cell cols="5">Table 4. PatchCore-1% with higher resolution/larger back-</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">bones/ensembles. The coreset subsampling allows for computa-</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">tionally expensive setups while still retaining fast inference.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Metric? AUROC pwAUROC</cell><cell>PRO</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">DenseN-201 &amp; RNext-101 &amp; WRN-101 (2+3), Imagesize 320</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Score ?</cell><cell>99.6</cell><cell>98.2</cell><cell>94.9</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Error ?</cell><cell>0.4</cell><cell>1.8</cell><cell>5.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">WRN-101 (2+3), Imagesize 280</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Score ?</cell><cell>99.4</cell><cell>98.2</cell><cell>94.4</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Error ?</cell><cell>0.6</cell><cell>1.8</cell><cell>5.6</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">WRN-101 (1+2+3), Imagesize 280</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Score ?</cell><cell>99.2</cell><cell>98.4</cell><cell>95.0</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Error ?</cell><cell>0.8</cell><cell>1.6</cell><cell>5.0</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc></figDesc><table><row><cell>Method</cell><cell>PatchCore?100%</cell><cell>PatchCore?10%</cell><cell>PatchCore?1%</cell></row><row><cell>Scores</cell><cell>(99.1, 98.0, 93.3)</cell><cell cols="2">(99.0, 98.1, 93.5) (99.0, 98.0, 93.1)</cell></row><row><cell>Time (s)</cell><cell>0.6</cell><cell>0.22</cell><cell>0.17</cell></row><row><cell cols="2">Method PatchCore?100% + IVFPQ</cell><cell>SPADE</cell><cell>PaDiM</cell></row><row><cell>Scores</cell><cell>(98.0, 97.9, 93.0)</cell><cell cols="2">(85.3, 96.6, 91.5) (95.4, 97.3, 91.8)</cell></row><row><cell>Time (s)</cell><cell>0.2</cell><cell>0.66</cell><cell>0.19</cell></row></table><note>Mean inference time per image on MVTec AD. Scores are (image AUROC, pixel AUROC, PRO metric).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>?Table S2 .Table S3 .</head><label>S2S3</label><figDesc>Method \Dataset ? Avg Bottle Cable Capsule Carpet Grid Hazeln. Leather Metal Nut Pill Screw Tile Toothb. Trans. Wood Zipper Anomaly Segmentation Performance on MVTec [5], as measured in pixelwise AUROC. Anomaly Segmentation Performance on MVTec [5], as measured in PRO [%] [5, 10]. Avg Bottle Cable Capsule Carpet Grid Hazeln. Leather Metal Nut Pill Screw Tile Toothb. Trans. Wood Zipper Table S4. Anomaly Detection and Localization Performance (AUROC) on MVTec AD [5] with PatchCore?1 using larger images (280 ? 280) and a WideResNet101 backbone. Avg Bottle Cable Capsule Carpet Grid Hazeln. Leather Metal Nut Pill Screw Tile Toothb. Trans. Wood Zipper</figDesc><table><row><cell>GeoTrans [20]</cell><cell>67.2</cell><cell>74.4</cell><cell>78.3</cell><cell>67.0</cell><cell>43.7</cell><cell>61.9</cell><cell>35.9</cell><cell>84.1</cell><cell>81.3</cell><cell>63.0</cell><cell>50.0</cell><cell>41.7</cell><cell>97.2</cell><cell>86.9</cell><cell>61.1</cell><cell>82.0</cell></row><row><cell>GANomaly [2]</cell><cell>76.2</cell><cell>89.2</cell><cell>75.7</cell><cell>73.2</cell><cell>69.9</cell><cell>70.8</cell><cell>78.5</cell><cell>84.2</cell><cell>70.0</cell><cell>74.3</cell><cell>74.6</cell><cell>79.4</cell><cell>65.3</cell><cell>79.2</cell><cell>83.4</cell><cell>74.5</cell></row><row><cell>DSEBM [58]</cell><cell>70.9</cell><cell>81.8</cell><cell>68.5</cell><cell>59.4</cell><cell>41.3</cell><cell>71.7</cell><cell>76.2</cell><cell>41.6</cell><cell>67.9</cell><cell>80.6</cell><cell>99.9</cell><cell>69.0</cell><cell>78.1</cell><cell>74.1</cell><cell>95.2</cell><cell>58.4</cell></row><row><cell>OCSVM [3]</cell><cell>71.9</cell><cell>99.0</cell><cell>80.3</cell><cell>54.4</cell><cell>62.7</cell><cell>41.0</cell><cell>91.1</cell><cell>88.0</cell><cell>61.1</cell><cell>72.9</cell><cell>74.7</cell><cell>87.6</cell><cell>61.9</cell><cell>56.7</cell><cell>95.3</cell><cell>51.7</cell></row><row><cell>ITAE [25]</cell><cell>83.9</cell><cell>94.1</cell><cell>83.2</cell><cell>68.1</cell><cell>70.6</cell><cell>88.3</cell><cell>85.5</cell><cell>86.2</cell><cell>66.7</cell><cell>78.6</cell><cell>100</cell><cell>73.5</cell><cell>100</cell><cell>84.3</cell><cell>92.3</cell><cell>87.6</cell></row><row><cell>SPADE [10]</cell><cell>85.5</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>CAVGA-R w [52]</cell><cell>90</cell><cell>96</cell><cell>92</cell><cell>93</cell><cell>88</cell><cell>84</cell><cell>97</cell><cell>89</cell><cell>82</cell><cell>86</cell><cell>81</cell><cell>97</cell><cell>89</cell><cell>99</cell><cell>79</cell><cell>96</cell></row><row><cell>PatchSVDD [56]</cell><cell>92.1</cell><cell>98.6</cell><cell>90.3</cell><cell>76.7</cell><cell>92.9</cell><cell>94.6</cell><cell>92.0</cell><cell>90.9</cell><cell>94.0</cell><cell>86.1</cell><cell>81.3</cell><cell>97.8</cell><cell>100</cell><cell>91.5</cell><cell>96.5</cell><cell>97.9</cell></row><row><cell>DifferNet [42]</cell><cell>94.9</cell><cell>99.0</cell><cell>95.9</cell><cell>86.9</cell><cell>92.9</cell><cell>84.0</cell><cell>99.3</cell><cell>97.1</cell><cell>96.1</cell><cell>88.8</cell><cell>96.3</cell><cell>99.4</cell><cell>98.6</cell><cell>91.1</cell><cell>99.8</cell><cell>95.1</cell></row><row><cell>PaDiM [14]</cell><cell>95.3</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>MahalanobisAD [40]</cell><cell>95.8</cell><cell>100</cell><cell>95.0</cell><cell>95.1</cell><cell>100</cell><cell>89.7</cell><cell>99.1</cell><cell>100</cell><cell>94.7</cell><cell>88.7</cell><cell>85.2</cell><cell>99.8</cell><cell>96.9</cell><cell>95.5</cell><cell>99.6</cell><cell>97.9</cell></row><row><cell>PaDiM  *  [14]</cell><cell>97.9</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PatchCore?25</cell><cell>99.1</cell><cell>100</cell><cell>99.5</cell><cell>98.1</cell><cell>98.7</cell><cell>98.2</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>96.6</cell><cell>98.1</cell><cell>98.7</cell><cell>100</cell><cell>100</cell><cell>99.2</cell><cell>99.4</cell></row><row><cell>PatchCore?10</cell><cell>99.0</cell><cell>100</cell><cell>99.4</cell><cell>97.8</cell><cell>98.7</cell><cell>97.9</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>96.0</cell><cell>97.0</cell><cell>98.9</cell><cell>99.7</cell><cell>100</cell><cell>99.0</cell><cell>99.5</cell></row><row><cell>PatchCore?1</cell><cell>99.0</cell><cell>100</cell><cell>99.3</cell><cell>98.0</cell><cell>98.0</cell><cell>98.6</cell><cell>100</cell><cell>100</cell><cell>99.7</cell><cell>97.0</cell><cell>96.4</cell><cell>99.4</cell><cell>100</cell><cell>99.9</cell><cell>99.2</cell><cell>99.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Wood Zipper</cell></row><row><cell>vis. expl. VAE [31]</cell><cell>86</cell><cell>87</cell><cell>90</cell><cell>74</cell><cell>78</cell><cell>73</cell><cell>98</cell><cell>95</cell><cell>94</cell><cell>83</cell><cell>97</cell><cell>80</cell><cell>94</cell><cell>93</cell><cell>77</cell><cell>78</cell></row><row><cell>AE SSIM [5]</cell><cell>87</cell><cell>93</cell><cell>82</cell><cell>94</cell><cell>87</cell><cell>94</cell><cell>97</cell><cell>78</cell><cell>89</cell><cell>91</cell><cell>96</cell><cell>59</cell><cell>92</cell><cell>90</cell><cell>73</cell><cell>88</cell></row><row><cell>?-VAE + grad. [15]</cell><cell>88.8</cell><cell>93.1</cell><cell>88.0</cell><cell>91.7</cell><cell>72.7</cell><cell>97.9</cell><cell>98.8</cell><cell>89.7</cell><cell>91.4</cell><cell>93.5</cell><cell>97.2</cell><cell>58.1</cell><cell>98.3</cell><cell>93.1</cell><cell>80.9</cell><cell>87.1</cell></row><row><cell>CAVGA-R w [52]</cell><cell>89</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>PatchSVDD [56]</cell><cell>95.7</cell><cell>98.1</cell><cell>96.8</cell><cell>95.8</cell><cell>92.6</cell><cell>96.2</cell><cell>97.5</cell><cell>97.4</cell><cell>98.0</cell><cell>95.1</cell><cell>95.7</cell><cell>91.4</cell><cell>98.1</cell><cell>97.0</cell><cell>90.8</cell><cell>95.1</cell></row><row><cell>SPADE [10]</cell><cell>96.0</cell><cell>98.4</cell><cell>97.2</cell><cell>99.0</cell><cell>97.5</cell><cell>93.7</cell><cell>99.1</cell><cell>97.6</cell><cell>98.1</cell><cell>96.5</cell><cell>98.9</cell><cell>87.4</cell><cell>97.9</cell><cell>94.1</cell><cell>88.5</cell><cell>96.5</cell></row><row><cell>PaDiM [14]</cell><cell>97.5</cell><cell>98.3</cell><cell>96.7</cell><cell>98.5</cell><cell>99.1</cell><cell>97.3</cell><cell>98.2</cell><cell>99.2</cell><cell>97.2</cell><cell>95.7</cell><cell>98.5</cell><cell>94.1</cell><cell>98.8</cell><cell>98.5</cell><cell>94.9</cell><cell>98.5</cell></row><row><cell>PatchCore?25</cell><cell>98.1</cell><cell>98.6</cell><cell>98.4</cell><cell>98.8</cell><cell>99.0</cell><cell>98.7</cell><cell>98.7</cell><cell>99.3</cell><cell>98.4</cell><cell>97.4</cell><cell>99.4</cell><cell>95.6</cell><cell>98.7</cell><cell>96.3</cell><cell>95.0</cell><cell>98.8</cell></row><row><cell>PatchCore?10</cell><cell>98.1</cell><cell>98.6</cell><cell>98.5</cell><cell>98.9</cell><cell>99.1</cell><cell>98.7</cell><cell>98.7</cell><cell>99.3</cell><cell>98.4</cell><cell>97.6</cell><cell>99.4</cell><cell>95.9</cell><cell>98.7</cell><cell>96.4</cell><cell>95.1</cell><cell>98.9</cell></row><row><cell>PatchCore?1</cell><cell>98.0</cell><cell>98.5</cell><cell>98.2</cell><cell>98.8</cell><cell>98.9</cell><cell>98.6</cell><cell>98.6</cell><cell>99.3</cell><cell>98.4</cell><cell>97.1</cell><cell>99.2</cell><cell>96.1</cell><cell>98.5</cell><cell>94.9</cell><cell>95.1</cell><cell>98.8</cell></row><row><cell>PatchCore?25</cell><cell>93.4</cell><cell>96.2</cell><cell>92.5</cell><cell>95.5</cell><cell>96.6</cell><cell>96.0</cell><cell>93.8</cell><cell>98.9</cell><cell>91.4</cell><cell>93.2</cell><cell>97.9</cell><cell>87.3</cell><cell>91.5</cell><cell>83.7</cell><cell>89.4</cell><cell>97.1</cell></row><row><cell>PatchCore?10</cell><cell>93.5</cell><cell>96.1</cell><cell>92.6</cell><cell>95.5</cell><cell>96.6</cell><cell>95.9</cell><cell>93.9</cell><cell>98.9</cell><cell>91.3</cell><cell>94.1</cell><cell>97.9</cell><cell>87.4</cell><cell>91.4</cell><cell>83.5</cell><cell>89.6</cell><cell>97.1</cell></row><row><cell>PatchCore?1</cell><cell>93.1</cell><cell>95.9</cell><cell>91.6</cell><cell>95.5</cell><cell>96.5</cell><cell>96.1</cell><cell>93.8</cell><cell>98.9</cell><cell>91.2</cell><cell>92.9</cell><cell>97.1</cell><cell>88.3</cell><cell>90.2</cell><cell>81.2</cell><cell>89.5</cell><cell>97.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">PatchCore?1, Hierarchies (2, 3), Imagesize 280</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>AUROC</cell><cell>99.4</cell><cell>100</cell><cell>99.6</cell><cell>98.2</cell><cell>98.4</cell><cell>99.8</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>97.2</cell><cell>98.9</cell><cell>98.9</cell><cell>100</cell><cell>100</cell><cell>99.5</cell><cell>99.9</cell></row><row><cell>pwAUROC</cell><cell>98.2</cell><cell>98.6</cell><cell>98.4</cell><cell>99.1</cell><cell>98.7</cell><cell>98.7</cell><cell>98.8</cell><cell>99.3</cell><cell>98.8</cell><cell>97.8</cell><cell>99.3</cell><cell>96.1</cell><cell>98.8</cell><cell>96.4</cell><cell>95.1</cell><cell>98.9</cell></row><row><cell>PRO</cell><cell>94.4</cell><cell>96.6</cell><cell>93.8</cell><cell>96.0</cell><cell>97.4</cell><cell>96.8</cell><cell>91.2</cell><cell>99.1</cell><cell>94.8</cell><cell>94.0</cell><cell>97.5</cell><cell>89.5</cell><cell>95.5</cell><cell>84.8</cell><cell>91.7</cell><cell>97.8</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">PatchCore?1, Hierarchies (1, 2, 3), Imagesize 280</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>AUROC</cell><cell>99.2</cell><cell>100</cell><cell>99.7</cell><cell>98.1</cell><cell>98.2</cell><cell>98.3</cell><cell>100</cell><cell>100</cell><cell>100</cell><cell>97.1</cell><cell>99.0</cell><cell>98.9</cell><cell>98.9</cell><cell>99.7</cell><cell>99.9</cell><cell>99.7</cell></row><row><cell>pwAUROC</cell><cell>98.4</cell><cell>98.6</cell><cell>98.7</cell><cell>99.1</cell><cell>98.7</cell><cell>98.8</cell><cell>98.8</cell><cell>99.3</cell><cell>99.0</cell><cell>98.6</cell><cell>99.5</cell><cell>96.3</cell><cell>98.9</cell><cell>97.1</cell><cell>95.2</cell><cell>99.0</cell></row><row><cell>PRO</cell><cell>95.0</cell><cell>96.6</cell><cell>94.6</cell><cell>96.3</cell><cell>97.5</cell><cell>97.0</cell><cell>91.5</cell><cell>99.1</cell><cell>95.4</cell><cell>96.0</cell><cell>98.1</cell><cell>90.0</cell><cell>95.8</cell><cell>85.9</cell><cell>92.0</cell><cell>98.0</cell></row></table><note>? Method \Dataset ? Avg Bottle Cable Capsule Carpet Grid Hazeln. Leather Metal Nut Pill Screw Tile Toothb. Trans.? Method \Dataset ?? Metric \Dataset ?</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table S5 .</head><label>S5</label><figDesc>Low-Shot Anomaly Detection Performance on MVTec<ref type="bibr" target="#b4">[5]</ref>, as measured on AUROC. ? 0.7 73.4 ? 1.3 75.2 ? 1.5 77.5 ? 1.1 78.9 ? 0.9 79.6 ? 0.8 81.1 ? 0.4 PaDiM 76.1 ? 0.4 78.9 ? 0.6 81.0 ? 0.2 83.2 ? 0.7 85.5 ? 0.6 86.5 ? 0.3 90.1 ? 0.? 0.6 86.4 ? 0.9 90.8 ? 0.8 93.6 ? 0.6 95.4 ? 0.7 95.8 ? 0.6 97.5 ? 0.3 PatchCore-25 84.1 ? 0.7 87.2 ? 1.0 91.0 ? 0.9 93.8 ? 0.5 95.5 ? 0.6 95.9 ? 0.6 97.7 ? 0.4 PIXEL-LEVEL AUROC SPADE 91.9 ? 0.3 93.1 ? 0.2 94.5 ? 0.1 95.4 ? 0.1 95.7 ? 0.2 95.7 ? 0.2 96.2 ? 0.0 PaDiM 88.2 ? 0.3 90.5 ? 0.2 92.5 ? 0.1 93.9 ? 0.1 94.8 ? 0.1 95.1 ? 0.1 96.3 ? 0.0 PatchCore-10 92.0 ? 0.2 93.1 ? 0.2 94.8 ? 0.1 96.2 ? 0.1 96.8 ? 0.3 96.9 ? 0.3 97.8 ? 0.0 PatchCore-25 92.4 ? 0.3 93.3 ? 0.2 94.8 ? 0.1 96.1 ? 0.1 96.8 ? 0.3 96.9 ? 0.3 97.7 ? 0.0 PRO METRIC SPADE 83.5 ? 0.4 85.8 ? 0.1 88.3 ? 0.2 89.6 ? 0.1 90.1 ? 0.2 90.1 ? 0.3 90.8 ? 0.1 PaDiM 72.4 ? 1.2 77.8 ? 0.7 82.7 ? 0.2 85.9 ? 0.2 87.5 ? 0.2 88.2 ? 0.2 90.4 ? 0.1 PatchCore-10 82.4 ? 0.3 85.1 ? 0.3 88.7 ? 0.2 90.9 ? 0.1 91.8 ? 0.2 92.0 ? 0.2 93.0 ? 0.1 PatchCore-25 83.7 ? 0.5 86.0 ? 0.3 88.8 ? 0.2 90.9 ? 0.1 91.7 ? 0.1 91.9 ? 0.2 92.8 ? 0.0Table S6. Anomaly Detection Performance on MVTec<ref type="bibr" target="#b4">[5]</ref>, as measured on AUROC.</figDesc><table><row><cell>? Method \Shots ? Retained % SPADE DifferNet PatchCore-10</cell><cell>1 0.4 71.6 3 2 5 10 16 20 50 0.8 2.1 4.1 6.6 8.3 21 IMAGE-LEVEL AUROC ----87.3 --% of M Img. AUROC Pw. AUROC PRO ResNet50 [23] 10 99.0 98.1 93.3 1 98.7 97.8 93.3 WideResNet50 [57] 10 98.9 98.1 93.5 1 99.0 98.0 93.1 ResNet101 [23] 10 98.6 97.9 92.5 1 98.7 97.8 92.2 WideResNet101 [57] 10 99.1 98.2 93.4 1 99.0 98.1 93.0 ResNeXt101 [55] 10 98.9 98.0 92.8 83.4 ? Backbone 1 98.7 97.8 92.6</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We thank Yasser Jadidi and Alex Smola for setup support of our compute infrastructure. K.R. thanks the International Max Planck Research School for Intelligent Systems (IMPRS-IS) and the European Laboratory for Learning and Intelligent Systems (ELLIS) PhD program for support.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Geometric approximation via coresets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pankaj</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sariel</forename><surname>Har</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peled</forename><surname>Kasturi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Varadarajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Combinatorial and Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Ganomaly: Semi-supervised anomaly detection via adversarial training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samet</forename><surname>Akcay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Atapour-Abarghouei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toby</forename><forename type="middle">P</forename><surname>Breckon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Transfer representation-learning for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jerone</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Tanay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewis</forename><surname>Griffin</surname></persName>
		</author>
		<idno>. 07 2016. 4</idno>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Deep nearest neighbor anomaly detection. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liron</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yedid</forename><surname>Hoshen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Mvtec ad -a comprehensive real-world dataset for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Uninformed students: Student-teacher anomaly detection with discriminative latent embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Improving unsupervised defect segmentation by applying structural similarity to autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sindy</forename><surname>L?we</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications</title>
		<meeting>the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Approximating CNNs with bag-of-local-features models works surprisingly well on imagenet</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wieland</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Bethge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Coresets, sparse greedy approximation, and the frank-wolfe algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><forename type="middle">L</forename><surname>Clarkson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Algorithms</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Sub-image anomaly detection with deep pyramid correspondences. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niv</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yedid</forename><surname>Hoshen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An elementary proof of a theorem of johnson and lindenstrauss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjoy</forename><surname>Dasgupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anupam</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Random Structures &amp; Algorithms</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Unsupervised anomaly detection for x-ray images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diana</forename><surname>Davletshina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valentyn</forename><surname>Melnychuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viet</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hitansh</forename><surname>Singla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Berrendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evgeniy</forename><surname>Faerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Fromm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Schubert</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image anomaly detection with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukas</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marius</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning and Knowledge Discovery in Databases</title>
		<editor>Michele Berlingerio, Francesco Bonchi, Thomas G?rtner, Neil Hurley, and Georgiana Ifrim</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Padim: A patch distribution modeling framework for anomaly detection and localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Defard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandr</forename><surname>Setkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelique</forename><surname>Loesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romaric</forename><surname>Audigier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition. ICPR International Workshops and Challenges</title>
		<editor>Alberto Del Bimbo, Rita Cucchiara, Stan Sclaroff, Giovanni Maria Farinella, Tao Mei, Marco Bertini, Hugo Jair Escalante, and Roberto Vezzani</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="475" to="489" />
		</imprint>
	</monogr>
	<note>2, 3, 5, 6, 7, 8, 1, 4</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Iterative energy-based projection on a normal data manifold for anomaly localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dehaene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriel</forename><surname>Frigo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Combrexelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Eline</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Density estimation using real NVP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">A Geometric Framework for Unsupervised Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleazar</forename><surname>Eskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Prerau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Portnoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sal</forename><surname>Stolfo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Springer US</publisher>
			<biblScope unit="page" from="77" to="101" />
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Scalable training of mixture models via coresets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Faulkner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Krause</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Q. Weinberger</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2011" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="2142" to="2150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep anomaly detection using geometric transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Izhak</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ran</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Moussa Reda Mansour, Svetha Venkatesh, and Anton van den Hengel. Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingqiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vuong</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Budhaditya</forename><surname>Saha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Smaller coresets for kmedian and k-means clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sariel</forename><surname>Har</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-Peled</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akash</forename><surname>Kushal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete and Computational Geometry</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="3" to="19" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Inverse-transform autoencoder for anomaly detection. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoqing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinkun</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosen</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cewu</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1911" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Surface defect saliency of magnetic tile. The Visual Computer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yuan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="85" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Billionscale similarity search with gpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Xrai: Better attributions through regions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Kapishnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tolga</forename><surname>Bolukbasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernanda</forename><surname>Viegas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Terry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rapp: Novelty detection with reconstruction along projection pathway</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ki</forename><forename type="middle">Hyun</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangwoo</forename><surname>Shim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongsub</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongseob</forename><surname>Jeon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeongwoo</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Byungchan</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andre</forename><forename type="middle">S</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Glow: Generative flow with invertible 1x1 convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Durk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prafulla</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dhariwal</surname></persName>
		</author>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Garnett</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Towards visually explaining variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenqian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runze</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srikrishna</forename><surname>Karanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bir</forename><surname>Bhanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">J</forename><surname>Radke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Octavia</forename><surname>Camps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Future frame prediction for anomaly detection -a new baseline</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On the generalized distance in statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prasanta</forename><surname>Chandra Mahalanobis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Institute of Sciences (Calcutta)</title>
		<meeting>the National Institute of Sciences (Calcutta)</meeting>
		<imprint>
			<date type="published" when="1936" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="49" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Data-independent neural pruning via coresets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Mussay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Margarita</forename><surname>Osadchy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Braverman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samson</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Are pre-trained cnns good feature extractors for anomaly detection in surveillance videos? CoRR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tiago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rodrigo</forename><surname>Nazar?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moacir</forename><forename type="middle">A</forename><surname>Fernandes De Mello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ponti</surname></persName>
		</author>
		<idno>abs/1811.08495</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Anomaly detection with multiple-hypotheses predictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyu</forename><surname>Duc Tam Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Lou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Klar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brox</surname></persName>
		</author>
		<idno>PMLR, 09-15</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<editor>Kamalika Chaudhuri and Ruslan Salakhutdinov</editor>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="4800" to="4809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>K?pf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zach</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alykhan</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasank</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Ocgan: One-class novelty detection using gans with constrained latent representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pramuditha</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Generative probabilistic novelty detection with adversarial autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Pidhorskyi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ranya</forename><surname>Almohsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">A</forename><surname>Adjeroh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gianfranco</forename><surname>Doretto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Neural Information Processing Systems, NIPS&apos;18</title>
		<meeting>the 32nd International Conference on Neural Information Processing Systems, NIPS&apos;18<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6823" to="6834" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Modeling the distribution of normal data in pre-trained deep features for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oliver</forename><surname>Rippel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Mertens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dorit</forename><surname>Merhof</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 25th International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Revisiting training strategies and generalization performance in deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karsten</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Milbich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prateek</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjorn</forename><surname>Ommer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><forename type="middle">Paul</forename><surname>Cohen</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<editor>Hal Daum? III and Aarti Singh</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="13" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Same same but differnet: Semi-supervised defect detection with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Adversarially learned one-class classifier for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Khalooei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmood</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehsan</forename><surname>Adeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Anomaly detection using autoencoders with nonlinear dimensionality reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mayu</forename><surname>Sakurada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takehisa</forename><surname>Yairi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, MLSDA&apos;14</title>
		<meeting>the MLSDA 2014 2nd Workshop on Machine Learning for Sensory Data Analysis, MLSDA&apos;14<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
	<note>Association for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadreza</forename><surname>Salehi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niousha</forename><surname>Sadjadi</surname></persName>
		</author>
		<editor>Soroosh Baselizadeh, Mohammad Hossein Rohban, and Hamid R</editor>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Multiresolution knowledge distillation for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rabiee</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Support vector method for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2000-06" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="582" to="588" />
		</imprint>
	</monogr>
	<note>Max-Planck-Gesellschaft</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Grad-cam: Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Active learning for convolutional neural networks: A core-set approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Sener</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Small-GAN: Speeding up GAN training using core-sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samarth</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirudh</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augustus</forename><surname>Odena</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th International Conference on Machine Learning</title>
		<editor>Hal Daum? III and Aarti Singh</editor>
		<meeting>the 37th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Support vector data description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="45" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Python 3 Reference Manual. CreateSpace</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><surname>Van Rossum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><forename type="middle">L</forename><surname>Drake</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Scotts Valley, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Attention guided anomaly localization in images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashanka</forename><surname>Venkataramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kuan-Chuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rajat Vikram</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhijit</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mahalanobis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020</title>
		<editor>Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Pytorch image models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Wightman</surname></persName>
		</author>
		<ptr target="https://github.com/rwightman/pytorch-image-models" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Integer and Combinatorial Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Laurence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><forename type="middle">L</forename><surname>Wolsey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nemhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Wiley Series in Discrete Mathematics and Optimization</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Dollar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Patch svdd: Patch-level svdd for anomaly detection and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihun</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungroh</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asian Conference on Computer Vision (ACCV)</title>
		<meeting>the Asian Conference on Computer Vision (ACCV)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<editor>Edwin R. Hancock Richard C. Wilson and William A. P. Smith</editor>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<publisher>BMVA Press</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="87" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Deep structured energy based models for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuangfei</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weining</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongfei</forename><surname>Zhang</surname></persName>
		</author>
		<idno>PMLR. 4</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of The 33rd International Conference on Machine Learning</title>
		<editor>Maria Florina Balcan and Kilian Q. Weinberger</editor>
		<meeting>The 33rd International Conference on Machine Learning<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06" />
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="20" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Image quality assessment: from error visibility to structural similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Zhou Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Bovik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Sheikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="600" to="612" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Deep autoencoding gaussian mixture model for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Martin Renqiang Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daeki</forename><surname>Lumezanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haifeng</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
