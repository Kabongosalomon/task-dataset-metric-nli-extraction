<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ElePose: Unsupervised 3D Human Pose Estimation by Predicting Camera Elevation and Learning Normalizing Flows on 2D Poses</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
							<email>wandt@cs.ubc.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">University of British Columbia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of British Columbia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of British Columbia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ElePose: Unsupervised 3D Human Pose Estimation by Predicting Camera Elevation and Learning Normalizing Flows on 2D Poses</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Human pose estimation from single images is a challenging problem that is typically solved by supervised learning. Unfortunately, labeled training data does not yet exist for many human activities since 3D annotation requires dedicated motion capture systems. Therefore, we propose an unsupervised approach that learns to predict a 3D human pose from a single image while only being trained with 2D pose data, which can be crowd-sourced and is already widely available. To this end, we estimate the 3D pose that is most likely over random projections, with the likelihood estimated using normalizing flows on 2D poses. While previous work requires strong priors on camera rotations in the training data set, we learn the distribution of camera angles which significantly improves the performance. Another part of our contribution is to stabilize training with normalizing flows on high-dimensional 3D pose data by first projecting the 2D poses to a linear subspace. We outperform the stateof-the-art unsupervised human pose estimation methods on the benchmark datasets Human3.6M and MPI-INF-3DHP in many metrics.</p><p>Given observations of 2D human joints in monocular imagery, we train a neural network to recover the depth -the missing third coordinate of the 3D human pose. With the same goals, Chen et al. <ref type="bibr" target="#b3">[4]</ref> and Yu et al.</p><p>[59] train a 3D pose estimator in an adversarial setting <ref type="bibr" target="#b10">[11]</ref>. Their generator predicts a 3D pose that is randomly rotated and projected to a virtual camera which is fed into an adversarial network over 'fake' projected 3D poses and the 'real' 2D pose distribution. The idea is that, for a correct 3D pose prediction, the rotated and projected 2D pose should also come from the distribution of 2D training poses. However, the predicted 3D pose is rotated randomly over a fixed prior distribution defined relative to the camera coordinate system. It is a reasonable assumption when the camera is close to parallel to the ground plane. However, even for small elevation angles and even when modeling variation by sampling from a predefined Gaussian distribution, this leads to</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Human pose estimation from single images is an ongoing research topic with many applications in medicine, sports, and human-computer interaction. Tremendous improvements have been achieved in recent years via machine learning. However, many recent approaches rely on a large amount of data used to train a 3D pose estimator in a supervised fashion. Unfortunately, such training data is hard to record and rarely available for specialized domains. For this reason, recent work focuses on reducing the amount of labeled data by using weak supervision in the form of unpaired 2D-3D examples, sparse supervision with a small amount of labeled 3D data, or multi-view setups during training. In contrast, we propose a method that is trained only from 2D data, which is easy to annotate by clicking <ref type="bibr">Figure 1</ref>. The consecutive steps performed by traditional methods and by our approach are shown from left to right. The commonly used prior distribution of the randomly sampled elevation angle leads to errors if it does not exactly match the distribution in the training dataset. ElePose solves this problem by learning this distribution and compensating for it before applying other transformations which significantly increases the performance of our method. visible keypoints in readily available images and thereby alleviates the 3D labelling and multi-view capture steps required by weakly-and fully-supervised approaches. random projections that cannot be found in the training data as shown in <ref type="figure">Fig. 1</ref>.</p><p>We build upon this concept and improve the handling of varying camera angles. Our core contribution is to train a network that predicts the elevation for every 2D input. After correcting for the predicted elevation, 3D reconstructions are upright such that rotating around the y-coordinate corresponds to rotating around the up-direction and uniformly sampling from all possible azimuth angles is meaningful as human poses are generally symmetric around the direction of gravity and the ground normal. While camera angles have been estimated in supervised and weakly supervised settings <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b52">53]</ref> we do it for the monocular case and without supervision.</p><p>The approach of projecting to random virtual cameras requires to know the distributions of camera poses. Tailored to this, we propose a method for estimating the distribution of elevation angles from multiple point estimates, which further improves the performance of our model.</p><p>Another major change compared to previous work is that we use normalizing flows to learn a prior distribution over 2D poses, which is subsequently used to infer the most likely 3D pose. By contrast to GANs, which at best give a surrogate to the likelihood of an outcome with the discriminator response, our probabilistic formulation via normalizing flows naturally gives a likelihood for a predicted pose during inference time. Besides gaining a significant improvement in accuracy and robustness over existing methods, our approach is also able to provide a measure for its performance, which is very valuable information in practical applications.</p><p>We overcome several technical challenges to make training and inference tractable. First, the bijectivity of normalizing flows is a useful property, which enables them to avoid mode collapse. However, their construction restricts their input and output dimensions to be equal. For highdimensional data, such as human poses, this leads to nonoptimal convergence and an incomplete latent space. Second, the normalizing flow is still an approximation to the true pose distribution and can predict a high likelihood for poses that are outside the original distribution. Optimizing the depth estimation network to produce 3D poses with high likelihoods for their back projections causes convergence to non-optimal solutions. To avoid this, we propose to first project the 2D poses to a lower-dimensional space given by a Principal Components Analysis (PCA) on the training data. Additionally, we introduce a suitable prior for the relative bone lengths in the human body to predict anthropometrically valid 3D poses.</p><p>Ethics and general impact. Building such an unsupervised approach for motion capture promises to be more inclusive to people and activities that are not well represented in current motion capture datasets. We will make the source code available.</p><p>Pose estimators could be abused for unwanted surveillance and our method could be used for motion pattern analysis. However, we believe this risk is low since it does not reconstruct any visual features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>In this section we discuss recent 3D human pose estimation approaches, structured by the different types of supervision, and put our approach in context. Full Supervision. Supervised approaches rely on large datasets that contain millions of images with corresponding 3D pose annotations. Li et al. <ref type="bibr" target="#b21">[22]</ref> were the first to apply CNNs to regress a 3D pose from image input directly. They later improved their work <ref type="bibr" target="#b23">[24]</ref> by a structured learning framework. Others followed this image-to-3D approach <ref type="bibr">[9, 16, 23, 25, 29, 33, 35, 39, 44, 46-49, 58, 61]</ref>. Typically, these end-to-end approaches achieve exceptional performance on similar image data. However, they struggle to generalize to very different scenes. To avoid the dependence on image data other approaches use a pretrained 2D joint detector <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b33">34]</ref>. Martinez et al. <ref type="bibr" target="#b25">[26]</ref> train a neural network on 2D poses and corresponding 3D ground truth. Due to its simplicity, it can be trained quickly for a large number of epochs leading to high accuracy, and serves as a baseline for many following approaches. While effective, the major downside of all supervised methods is that they do not generalize well to images with unseen poses.</p><p>Weak Supervision. Weakly supervised approaches require only a small set of labeled 3D poses or unpaired 2D and 3D poses. Several approaches assume unpaired 2D and 3D poses <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b59">60]</ref> and leverage available motion capture data and combine it with unknown 2D data. To allow for in-the-wild pose estimation of datasets where no training data is available, a transfer learning approach is introduced by Mehta et al. <ref type="bibr" target="#b26">[27]</ref> which was later improved in Mehta et al. <ref type="bibr" target="#b28">[29]</ref> to achieve real-time performance. Other work first learns an embedding of multi-view data which is then used to train a 3D pose estimator with a sparse set of labeled 3D poses. Rhodin et al. <ref type="bibr" target="#b40">[41,</ref><ref type="bibr" target="#b41">42]</ref> use multi-view images and known camera positions to learn a 3D pose embedding. Others <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b44">45]</ref> followed the same idea. Compared to completely supervised approaches, these weakly supervised methods generalize and transfer better to unseen poses. However, they struggle with poses that are very different from the labeled training set.</p><p>Multi-view Supervision without 3D Data. Multi-view approaches only use information from multiple cameras <ref type="figure">Figure 2</ref>. Overview of our approach. Given a normalized 2D input pose a lifting network predicts a depth for each joint coordinate which gives a 3D pose. Additionally it predicts the camera elevation in a parallel path. This 3D pose is randomly rotated and projected to 2D. The pretrained normalizing flow computes the negative log-likelihood which is used as a loss to train the lifting network. without requiring any 3D data. Rochette et al. <ref type="bibr" target="#b42">[43]</ref> achieve similar performance as a comparable fully supervised approach. However, they use a large number of cameras from different viewing angles, which limits the practical applicability. Kocabas et al. <ref type="bibr" target="#b17">[18]</ref> apply epipolar geometry to 2D poses from multiple views to compute a pseudo ground truth which is then used to train the 3D lifting network. Iqbal et al. <ref type="bibr" target="#b14">[15]</ref> train an end-to-end network that refines the pre-trained 2D pose estimator during the self-supervised training. Likewise, Wandt et al. <ref type="bibr" target="#b52">[53]</ref> reconstruct 3D poses in a canonical pose space that is consistent over all views. While these multi-view approaches are a promising direction towards motion capture in the wild, they still require multiple temporally synchronized cameras for training.</p><p>Unsupervised. This section covers work that does not use any 3D data or additional views. Our work also falls into this category. Drover et al. <ref type="bibr" target="#b7">[8]</ref> propose an unsupervised learning approach to monocular human pose estimation. They randomly project an estimated 3D pose back to 2D. This 2D projection is then evaluated by a discriminator following adversarial training approaches. However, they create an artificial 2D dataset from known ground-truth 3D poses. Chen et al. <ref type="bibr" target="#b3">[4]</ref> extend <ref type="bibr" target="#b7">[8]</ref> with a cycle consistency loss that is computed by lifting the randomly projected 2D pose to 3D and inversing the previously defined random projection. In contrast to Drover et al. <ref type="bibr" target="#b7">[8]</ref> they only use 2D data given by the dataset. Yu et al. <ref type="bibr" target="#b58">[59]</ref> build upon <ref type="bibr" target="#b3">[4]</ref> and introduce a learnable scaling factor for the input 2D poses. None of them estimates the camera orientation and its distribution and we are also the first to apply normalizing flows to this setting.</p><p>Normalizing Flow. Informally, a normalizing flow is a tool to efficiently map distributions back and forth between two spaces. It applies to probability density estimation, which we use for the likelihood estimation of poses.</p><p>Let Z ? R N be a known distribution (in our case a normal distribution) and g be an invertible function g(z) = x, with x ? R N as a vector representing the joints of a human pose <ref type="bibr" target="#b0">1</ref> . With the change of variables formula the probability density function of x is computed as</p><formula xml:id="formula_0">p X (x) = p Z (f (x)) det ?f ?x ,<label>(1)</label></formula><p>where f is the inverse of g and ?f ?x is the Jacobian of f . That means given an invertible function f the density of a 2D pose x can be calculated by the product of the density of its projection f (x) with the respective Jacobian determinant.</p><p>In our case f is the trainable neural network proposed in <ref type="bibr" target="#b6">[7]</ref>. Details on the construction and training are given in the supplemental document. Normalizing flows have been used to learn prior distributions of 3D human poses <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b56">57,</ref><ref type="bibr" target="#b59">60]</ref> or to model ambiguities during the lifting step <ref type="bibr" target="#b54">[55]</ref>. However, they aim to build a probabilistic 3D model of a skeleton and therefore require 3D training data. To the best of our knowledge, our approach is the first that uses normalizing flows to learn the prior distribution of 2D input data to infer the probability of a reconstructed 3D pose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Formulation</head><p>Our goal is to train a neural network that given a 2D pose x ? R 2J recovers the 3D pose y ? R 3J with J 3D joint positions. In our unsupervised setting, only a dataset of 2D poses is available for training. The general concept follows the assumptions of previous work in this domain, i.e., we assume that a 3D pose is plausible when viewing its 2D projections from multiple views. The difficulty lies in finding a plausibility measure for these 2D projections without multi-view data. We propose to learn this measure via normalizing flows. As a second major contribution we learn the camera angle distribution instead of predefining a dataset-dependent prior. This not only makes our approach more flexible but also overcomes the problem of wrongly rotated poses resulting in significant improvement in performance. All parts of our pipeline are visualized in <ref type="figure">Fig. 2</ref> and explained in the following sections.</p><p>Lifting and Camera Model. Given 2D joint locations x ? R 2?J , we introduce a lifting network that predicts for every joint j the depth w j = d j + D as the offset d j to a constant depth D. The full 3D pose is reconstructed based on the perspective unprojection</p><formula xml:id="formula_1">y j = [u j w j , v j w j , w j ],<label>(2)</label></formula><p>where u j and v j are the horizontal and vertical joint positions in the image. It inverts the perspective projection operation</p><formula xml:id="formula_2">P (y j ) = P ([y (x) j , y (y) j , y (z) j ]) = [y (x) j /y (z) j , y (y) j /y (z) j ], (3) with [y (x) j , y (y) j , y (z)</formula><p>j ] as the 3D position of joint j. To prevent ambiguous reconstructions with negative depth, w j is clipped to be larger than one. Following previous work <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b58">59]</ref> the depth D is fixed to D = 10, as perspective effects change little with depth, and each 2D pose y is normalized by centering it at the root joint and dividing it by the mean length of the vector from the root joint to the head joint.</p><p>Reprojection to Virtual Cameras. We motivate our approach from multi-view camera setups, where the depth can be supervised by reprojection to the other views. Since no multi-view data is available in an unsupervised setting we assume a virtual second view. It requires rotating 3D poses centered at their root joint with</p><formula xml:id="formula_3">y 2 = R[y 1 ] 3?J , where R ? R 3?3</formula><p>is the rotation matrix from the original camera to a virtual camera and [y 1 ] 3?J the pose vector y 1 in the original camera coordinate system reshaped to a matrix with one of the J 3D joint positions in each column. Typically, the rotation R is randomly sampled from a predefined distribution R <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b58">59]</ref>. However, in general, it is unknown and different for every dataset. One of our core contributions is to learn this distribution instead of predefining it which we discuss in the following. Using the same perspective camera model as for the lifting in Eq. 3 the 2D pose x 2 = P (y 2 ) is computed by moving the predicted 3D pose with the predefined translation D and dividing each joint by its depth.</p><p>Reprojection Likelihood In a multi-view setting the reprojection likelihood is typically a Gaussian with standard deviation ? r , centered at the 2D projection x 2 of the 3D pose y 2 leading to a least squares loss when inferred using maximum likelihood or MAP. Since multi-camera information is not available in an unsupervised setting there exists no corresponding 2D pose that can be matched to x 2 . While previous work <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b58">59]</ref> tries to learn the distribution of plausible 2D poses with an adversarial approach we leverage normalizing flows for learning the probability density function of the 2D poses in the training dataset. We define the reprojection likelihood by computing the likelihood of the latent variable z in the latent space of a normalizing flow using Eq. 1. In contrast to <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b58">59]</ref>, this enables us to compute a likelihood for each reconstructed 3D pose which is very valuable information for downstream tasks.</p><p>In practice, we minimize the negative log-likelihood of Eq. 1 which gives the normalizing flow loss</p><formula xml:id="formula_4">L N F = ? log(p X (x)).<label>(4)</label></formula><p>Stabilized Normalizing Flows. We found that directly training the normalizing flow on 2D poses leads to nonoptimal convergence during training of the lifting network. We hypothesize that it is due to the high dimensionality of the input data which leads to a sparse latent space of the normalizing flow. That means the latent space contains poses that are not in the original distribution of 2D poses, although the normalizing flow assigns a high likelihood to them. To mitigate this, instead of directly estimating the likelihood of a 2D pose we propose to first project the 2D pose to a low dimensional subspace. Our subspace is determined by principal components analysis. The projection to the subspace eliminates redundancies and noise from the data and, therefore, leads to a more stable training of the normalizing flow and subsequently the lifting network.</p><p>Camera Distribution and Elevation. The predicted 3D pose y is rotated to a virtual view by randomly sampling R ? R. To achieve a reasonable 2D projection of the rotated 3D pose the distribution R needs to be defined such that it matches the distribution of rotations present in the training data set. In general, R is unknown in an unsupervised setting. However, there are reasonable priors for camera setups based on natural human behaviour while recording another human: 1) cameras are held horizontally, 2) since gravity defines a clear up-direction, cameras (or observed subjects) are mostly rotated around the azimuth axis, and 3) similar activities are recorded with similar but slightly varying elevation angles. In terms of R these three points mean that 1) there is negligible rotation around the optical axis, 2) a uniform prior over 360 ? rotation around the azimuth axis is plausible, and 3) an unknown but restricted rotation around the elevation axis. While the former two assumptions can be straightforwardly modeled the latter is commonly approximated by sampling the elevation angle from a uniform distribution in the interval [??/9, ?/9] <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b58">59]</ref>. Unfortunately, this can lead to situations where a reconstructed person is strongly tilted towards the camera as visualized in <ref type="figure">Fig. 1</ref>. This in turn results in backprojections that cannot be observed in the training set. As a major contribution in this paper we propose to learn the distribution of the elevation angle R e . Since each 2D pose can have a unique elevation angle the lifting network is extended by a branch that predicts the elevation angle. The resulting rotation matrix R e is used to rotate the predicted 3D pose y to the direction of gravity by R T e [y] 3?J . This step alone already improves the predictions since it compensates for the formerly ignored elevation and therefore the azimuth rotation is correctly applied around the azimuth axis.</p><p>To further improve the results we additionally use the elevation predictions to predict the normal distribution of elevation angles in the dataset by calculating the mean ? e and standard deviation ? e over all elevation angles in a batch such that p(R e ) = N (? e , ? e ).</p><p>The rotation around the azimuth axis R a is randomly sampled from a uniform distribution in the interval [??, ?]. To rotate the pose back in elevation direction a rotationR e for each sample in the batch is randomly sampled from the normal distribution N (? e , ? e ). To allow for backpropagation through the sampling step we use the same reparametrization as for variational autoencoders, i.e. R e ? ? e + ? e N (0, 1).</p><p>The full rotation R can now be written as</p><formula xml:id="formula_7">R = R T e R aRe .<label>(7)</label></formula><p>Our experiments show that our novel elevation angle estimation significantly improves results by approximately 15% in PA-MPJPE and more than 22% in MPJPE.</p><p>Skeleton likelihood. Human poses have several anthropometric properties defined by the kinematic chain of bones. Most of these properties, such as bone lengths and joint angle limits, are unknown in an unsupervised setting. However, relative bone lengths are nearly constant across people <ref type="bibr" target="#b37">[38]</ref>. For this reason, we calculate the relative bone lengths b k for the k-th bone divided by the mean length of all bones of a single pose. We use a Gaussian prior with the mean at the pre-calculated relative bone lengthb k . The density for the bone lengths prior is given by</p><formula xml:id="formula_8">p(b 1 , b 2 , . . . , b K |b 1 ,b 2 , . . . ,b K ) = K k=1 N (b k |b k , ? b ),<label>(8)</label></formula><p>where K is the number of bones. This forms a prior in terms of 3D pose y and a likelihood, p(x 1 , d), of x 1 given a depth d since a 3D pose is formed as a combination of observation and latent variable. Practically, we define the loss L bone as the negative log-likelihood of Eq. 8. Note that our formulation imposes a soft constraint but does not fix bones to a predefined length.</p><p>Additional Losses. We additionally employ 3 losses similar to <ref type="bibr" target="#b58">[59]</ref>, namely the 3D lifting loss L 3D , the deformation loss L def , and the 2D reprojection loss L 2D . <ref type="figure">Figure 2</ref> visualizes these three losses. Since the 3D pose y 2 that produces the 2D pose x 2 is known the lifting network is applied again to x 2 to obtain the lifted pose? 2 . We define the traditional supervised L 2 loss</p><formula xml:id="formula_9">L 3D = ? 2 ? y 2 2 .<label>(9)</label></formula><p>By rotating? 2 back to the original view we get a 3D pos? y 1 = R T? 2 that should match y 1 . Yu et al. <ref type="bibr" target="#b58">[59]</ref> showed that instead of directly applying another L 2 loss on these two poses it is beneficial to consider the deformation between two poses at different time steps. Since we do not assume any temporal data we define the same loss between two samples of a batch that could come from different people and sequences. For the poses y 1 and? 1 at batch position a and b we define the time and pose independent deformation loss</p><formula xml:id="formula_10">L def = (? (a) 1 ?? (b) 1 ) ? (y (a) 1 ? y (b) 1 ) 2 .<label>(10)</label></formula><p>Using the same perspective projection as before? 1 is projected to the 2D posex = P (? 1 ). This gives the 2D back projection loss</p><formula xml:id="formula_11">L 2D = x ? x 1 .<label>(11)</label></formula><p>Since the combination of these three terms has proven to be successful in <ref type="bibr" target="#b58">[59]</ref> we summarize them as our basis loss</p><formula xml:id="formula_12">L base = L 3D + L def + L 2D .<label>(12)</label></formula><p>Neural Network Structure. The lifting network is inspired by the MLP-based lifting network from Martinez et al. <ref type="bibr" target="#b25">[26]</ref> and consists of 3 residual blocks, each of which contains 2 fully connected layers with 1024 neurons followed by a leaky ReLU activation function. The input is upscaled to a dimension of 1024 by a fully connected layer followed by a leaky ReLU activation function. Downscaling to the dimension of the depth is performed by another fully connected layer without activation. The elevation angle is predicted in a path parallel to the 3 residual blocks of the depth estimation network that has identical architecture. The normalizing flow consists of 8 coupling blocks. Each sub-network that predicts the affine transformations s and t contains 2 fully connected layers with 1024 neurons and ReLU activation functions.</p><p>Training Details. The normalizing flow is pretrained separately from the lifting network for 100 epochs with a batch size of 256 samples. We use the Adam optimizer with an initial learning rate of 10 ?4 and a weight decay of 10 ?5 . For the pretraining of the normalizing flow we divided the learning rate by 10 after 10, 20, and 30 epochs. The full loss function is</p><formula xml:id="formula_13">L = L NF + 50L bone + L base .<label>(13)</label></formula><p>When training the lifting network we use an initial learning rate of 2 ? 10 ?4 and an exponential scheduling with a decay of 0.95 every epoch for a total number of 100 epochs. Both, the pretraining of the normalizing flow and the training of the lifting network, take approximately 6 hours on an NVIDIA P100 Pascal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We perform experiments on the well-known benchmark datasets Human3.6M <ref type="bibr" target="#b13">[14]</ref>, MPI-INF-3DHP <ref type="bibr" target="#b26">[27]</ref> and 3DPW <ref type="bibr" target="#b50">[51]</ref>. For the Human3.6M dataset, we follow standard protocols and evaluate on every 64th frame of the test set.</p><p>Metrics For the evaluation on Human3.6M we calculate the mean per joint position error (MPJPE), i.e. the mean Euclidean distance between the reconstructed and the ground truth joint coordinates. Since an unsupervised setting does not contain metric data we scale the reconstructed 3D pose to match ground truth, commonly known as N-MPJPE <ref type="bibr" target="#b41">[42]</ref>. The second common protocol first employs a Procrustes alignment (includes scaling) between the poses before calculating the MPJPE, also known as PA-MPJPE. For 3DHP we report the Percentage of Correct Keypoints (PCK) and the corresponding area under curve, scalenormalized as mentioned above, which we call N-PCK. It is the percentage of predicted joints that are within a distance of 150mm or lower to their corresponding ground truth joint. Additionally, we evaluate the Correct Poses Score (CPS) recently proposed by Wandt et al. <ref type="bibr" target="#b52">[53]</ref>. Unlike the PCK, the CPS classifies a pose as correct if all joints of the pose are correctly estimated. To be independent of a threshold value, the CPS calculates the area under the curve in a range from 0mm to 300mm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results in Controlled Conditions</head><p>To show the performance of our approach in a fair comparison to others, we start with using the 2D poses given by the dataset. This allows for a fair comparison since it does not rely on the performance of pretrained 2D detectors that vary from method to method. <ref type="table" target="#tab_0">Table 1</ref> presents results for the benchmark dataset Human3.6M with different types of supervision. All shown results use the same 2D input data. We outperform state-of-the-art <ref type="bibr" target="#b58">[59]</ref> in unsupervised pose estimation in PA-MPJPE by 12.6%. Notably, we even slightly improve on the PA-MPJPE of the fully supervised method of Martinez et al. <ref type="bibr" target="#b25">[26]</ref>. We achieve comparable performance to weakly supervised methods and approaches using multi-view supervision in the N-MPJPE metric. Note that <ref type="bibr" target="#b58">[59]</ref> uses a prior for the scale during training and therefore directly calculate the MPJPE. However, we outperform them even when they apply the ground truth scale (PA-MPJPE: 39.7) during training. For the Human3.6M dataset we obtain a CPS of 196.1. <ref type="table">Table 2</ref> and <ref type="table" target="#tab_1">Table 3</ref> shows results for the MPI-INF-3DHP and 3DPW (in Train-Test-mode) datasets, respectively. On the 3DHP dataset, we only found two other methods that use the 2D poses provided by the dataset and on the 3DPW we found no comparable method.</p><p>To create training data for the 3DPW dataset we reprojected the 3D skeletons to 2D. This step is necessary because of the difference between the provided 2D and 3D data. Note that for practical applications this step is not required. The 3DPW dataset is particularly challenging since its training set comprises only data captured in-the-wild and additionally it is much smaller compared to the other two datasets.</p><p>The results show that our approach performs well even in challenging conditions. <ref type="figure" target="#fig_0">Figure 3</ref> shows subjective results for both datasets. On the left side are reconstructions with a low PA-MPJPE and visually plausible 3D skeletons. Even poses that rarely occur in the training set are reconstructed correctly, e.g., sit-  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results in Practical Conditions</head><p>In practice, where only images are available, we use an off-the-shelf 2D pose detector. To be directly comparable to our closest competitor we use the same 2D detections produced by Cascaded Pyramid Networks <ref type="bibr" target="#b4">[5]</ref> that are provided by the authors of VideoPose3D <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b36">37]</ref>. <ref type="table">Table 4</ref> shows our results when testing on the predicted 2D poses. We outperform comparable unsupervised methods even though <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b58">59]</ref> both use temporal information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Correlation Between Predicted 3D Poses and Likelihood of Projections</head><p>A benefit of our novel normalizing flow formulation is that it can also be used during testing to evaluate the likeli- <ref type="table">Table 4</ref>. Results for unsupervised methods of the Human3.6M dataset when using 2D pose predictions. The star * indicates using a scale prior from the dataset instead of applying normalization via N-MPJPE at the inference stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PA-MPJPE?</head><p>N-MPJPE? CPS? Kundu <ref type="bibr" target="#b19">[20]</ref> 62.4 --Kundu <ref type="bibr" target="#b20">[21]</ref> 63.8 --Chen <ref type="bibr" target="#b3">[4]</ref> 68.0 --Yu <ref type="bibr">[</ref> hood of the predicted 3D poses. For practical applications, this can be an important value to assess the reliability of the predicted poses for downstream tasks. We apply the normalizing flow to compute the negative log-likelihood of predicted poses. For the reprojection log-likelihood we randomly sample 100 rotations from the distribution learned during the training stage which is then averaged over all rotations. The elevation distribution is estimated over the whole training set. A box plot of the results is shown in <ref type="figure" target="#fig_2">Fig. 5</ref>. We show bins in 5mm steps from 20-120mm while the 120mm bin includes 120mm and above. As expected, in many cases, the likelihood correlates with the 3D reconstruction error.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Ablation Studies</head><p>We perform several experiments with different configurations of our approach on the Human3.6M dataset by training the lifting network with each of them separately. Additionally, we train the normalizing flow directly on the 2D poses (i.e. no PCA). The results in <ref type="table" target="#tab_3">Table 5</ref> show that each of our contributions is important to achieve the best performance. Note that using the bone lengths prior together with either PCA or elevation alone outperforms <ref type="bibr" target="#b3">[4]</ref> and its improved reimplementation by <ref type="bibr" target="#b58">[59]</ref>. Without the PCA we achieve an PA-MPJPE of 45.5mm which shows the importance of projecting to the PCA space before training the normalizing flow. Adding our novel elevation prediction improves the results by almost 15%.</p><p>Since the PCA is an important part of achieving an acceptable performance, we evaluate the impact of the number of PCA bases. <ref type="figure" target="#fig_1">Fig. 4</ref> shows the results. Projecting to a PCA space smaller than 15 bases removes important information from the reprojected 2D poses and results in errors above 100mm. For visualization purposes we only visualize the error for more than 15 bases. The best performance lies between 22 and 30 bases that cover between 99.6% and 99.9% of the variance in the training set. The increase at 31 bases shows that the normalizing flow struggles to learn the probability density when the input dimension is too large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Limitations</head><p>Our proposed method enables 3D human pose estimation with only 2D annotations and paves the way to a monocular motion capture system for all possible human activities. The only requirement is a set of 2D annotations which can be obtained by crowd sourcing 2D joint annotations. This is the main limitation of our approach. More specifically, our method requires similar poses seen from different angles. While we compensate for one of these aspects, the elevation angle, natural assumptions on the shape of the distribution of azimuth angles are hard or even impossible to make. Additionally, poses that appear visually correct from all angles can still be implausible in 3D space which is a general problem in monocular human pose estimation. In future work we plan to mitigate these problems by learning 3D pose priors and conditional distributions over full camera rotations jointly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Human pose estimation from single images is a challenging problem, especially for activities where no 3D annotations exist. To this end, we propose an unsupervised approach that learns a 3D lifting only from 2D annotations. While previous approaches utilize a predefined prior on the camera distribution we find that learning this distribution significantly improves the results. We formulate the 3D human pose estimation problem as a maximum likelihood estimation over random projections of the 3D pose. Normalizing flows appear to be an ideal tool. They not only learn a well-defined prior distribution of 2D poses but also allow us to calculate the likelihood of reconstructed 3D pose at test time which provides valuable information. Since we observed that directly using the normalizing flow as prior leads to unstable training of the lifting network we additionally propose to first project the 2D poses to a low dimensional subspace.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Subjective results of our method for the Human3.6M dataset (top row), the 3DHP dataset (middle two rows), and the 3DPW dataset (last row). The last column shows failure cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 4 .</head><label>4</label><figDesc>PA-MPJPE for different numbers of PCA bases. Between 22 and 30 PCA bases appears to be the ideal range.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Correlation between the PA-MPJPE and the negative log-likelihood assigned to a set of projections of the predicted 3D pose. As desired, poses with a low 3D error have a low negative log-likelihood and vice versa for high 3D errors. Errors are given in millimeters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Evaluation results for the Human3.6M dataset in mm. The bottom section, labeled with unsupervised, shows comparable unsupervised methods. Best results are marked in bold. Numbers are taken from the respective papers. The star * indicates using a scale prior from the dataset. The MPJPE for<ref type="bibr" target="#b25">[26]</ref> is taken from<ref type="bibr" target="#b58">[59]</ref>.</figDesc><table><row><cell>Supervision</cell><cell>Method</cell><cell cols="2">PA-MPJPE?</cell><cell>N-MPJPE?</cell></row><row><cell>full</cell><cell>Martinez [26]</cell><cell></cell><cell>37.1</cell><cell>45.5*</cell></row><row><cell>weak</cell><cell cols="2">3D interpreter [56]</cell><cell>88.6</cell><cell>-</cell></row><row><cell></cell><cell>AIGN [50]</cell><cell></cell><cell>79.0</cell><cell>-</cell></row><row><cell></cell><cell>RepNet [52]</cell><cell></cell><cell>38.2</cell><cell>50.9</cell></row><row><cell></cell><cell>Drover [8]</cell><cell></cell><cell>38.2</cell><cell>-</cell></row><row><cell></cell><cell>Kundu [20]</cell><cell></cell><cell>62.4</cell><cell>-</cell></row><row><cell>multi-view</cell><cell>EpipolarPose [18]</cell><cell></cell><cell>47.9</cell><cell>54.9</cell></row><row><cell></cell><cell>Wandt [53]</cell><cell></cell><cell>51.4</cell><cell>65.9</cell></row><row><cell>unsupervised</cell><cell>Chen [4]</cell><cell></cell><cell>58.0</cell><cell>-</cell></row><row><cell></cell><cell cols="2">[4] reimplemented by [59]</cell><cell>46.0</cell><cell>-</cell></row><row><cell></cell><cell>Yu [59] (temporal)</cell><cell></cell><cell>42.0</cell><cell>85.3  *</cell></row><row><cell></cell><cell>Ours</cell><cell></cell><cell>36.7</cell><cell>64.0</cell></row><row><cell cols="5">Table 2. Evaluation results for the MPI-INF-3DHP dataset. The</cell></row><row><cell cols="5">bottom section, labeled with unsupervised, shows methods that</cell></row><row><cell cols="5">can solve our setting. Numbers are taken from [59]. A star  *</cell></row><row><cell cols="3">indicates an unknown normalization.</cell><cell></cell><cell></cell></row><row><cell>Supervision</cell><cell>Method</cell><cell>PA-MPJPE?</cell><cell cols="2">N-PCK? AUC?</cell></row><row><cell>weak</cell><cell>Kundu [20]</cell><cell>93.9</cell><cell>84.6</cell><cell>60.8</cell></row><row><cell cols="2">unsupervised Yu [59]</cell><cell>-</cell><cell>86.2  *</cell><cell>51.7  *</cell></row><row><cell></cell><cell>Ours</cell><cell>54.0</cell><cell>86.0</cell><cell>50.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 3 .</head><label>3</label><figDesc>Evaluation results for the 3DPW dataset.</figDesc><table><row><cell cols="2">PA-MPJPE?</cell><cell cols="3">N-MPJPE? N-PCK? AUC?</cell><cell>CPS?</cell></row><row><cell>Ours</cell><cell>64.1</cell><cell>93.0</cell><cell>81.5</cell><cell>51.5</cell><cell>120.3</cell></row><row><cell cols="6">ting on the floor with crossed legs. The right column shows</cell></row><row><cell cols="6">occasional failure cases, with a PA-MPJPE over 200mm.</cell></row><row><cell cols="6">Typical failure cases are: limbs are rotated in the wrong di-</cell></row><row><cell cols="6">rection (first and third row) and limb ordering (second and</cell></row><row><cell>fourth row).</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 .</head><label>5</label><figDesc>Ablation study with different loss terms on the Hu-man3.6M dataset.</figDesc><table><row><cell>Configuration</cell><cell cols="2">PA-MPJPE MPJPE</cell></row><row><cell>base (L N F + L 3D + L def + L 2D )</cell><cell>77.9</cell><cell>135.0</cell></row><row><cell>base + L bl</cell><cell>48.1</cell><cell>83.8</cell></row><row><cell>base + L bl + elevation</cell><cell>45.5</cell><cell>73.9</cell></row><row><cell>base + L bl + PCA</cell><cell>43.1</cell><cell>83.8</cell></row><row><cell>Ours (base + L bl + PCA + elevation)</cell><cell>36.7</cell><cell>64.0</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">This could be either the 2D pose vector x or its image in the PCA subspace.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">3D multibodies: Fitting sets of plausible 3D models to ambiguous image data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Biggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S?bastien</forename><surname>Erhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Novotny</surname></persName>
		</author>
		<editor>NeurIPS</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">3d human pose esti-mation= 2d pose estimation+ matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="7035" to="7043" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Unsupervised 3d pose estimation with geometric selfsupervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Drover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rohith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Stojanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised 3d pose estimation with geometric self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Drover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Stojanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="5714" to="5724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Cascaded pyramid network for multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilun</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxiang</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiqiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7103" to="7112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Garnet: Graph attention residual networks based on adversarial learning for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihua</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoli</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Sheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Computer Graphics</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="276" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Density estimation using real NVP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jascha</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samy</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings. OpenReview.net</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Can 3d pose be learned from 2d projections alone</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Drover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong Phuoc</forename><surname>Huynh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision Workshops (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Marker-less 3D human motion capture with monocular image sequence and height-maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongkang</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonghao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feilin</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><surname>Kankanhalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weidong</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="20" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning pose grammar to encode human body configuration for 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoshu</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<editor>Sheila A. McIlraith and Kilian Q. Weinberger</editor>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6821" to="6828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ian</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherjil</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Neural Information Processing Systems (NIPS), NIPS&apos;14</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Learning 3d global human motion estimation from unpaired</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Habekost</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takaaki</forename><surname>Shiratori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuting</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taku</forename><surname>Komura</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>disjoint datasets. 2020. 2</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">In the wild human pose estimation using explicit 2d features and intermediate 3d representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikhsanul</forename><surname>Habibie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Human3.6m: Large scale datasets and predictive methods for 3d human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1325" to="1339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Weaklysupervised 3d human pose learning via multi-view images in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Umar</forename><surname>Iqbal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavlo</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Kautz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Vibe: Video inference for human body pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Athanasiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">SPEC: Seeing people in the wild with an estimated camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chun-Hao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lea</forename><surname>Tesch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Otmar</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Hilliges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. International Conference on Computer Vision (ICCV)</title>
		<meeting>International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="11035" to="11045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Selfsupervised learning of 3d human pose using multi-view geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salih</forename><surname>Karagoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Akbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Probabilistic modeling for human mesh recovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Kolotouros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dinesh</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<biblScope unit="page" from="2021" to="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Self-supervised 3d human pose estimation via part guided novel image synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mugalodi</forename><surname>Rakesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Kinematic-structure-preserved representation for unsupervised 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jogendra</forename><surname>Nath Kundu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siddharth</forename><surname>Seth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rahul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mugalodi</forename><surname>Rakesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkatesh</forename><surname>Babu Radhakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anirban</forename><surname>Chakraborty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="11312" to="11319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">3d human pose estimation from monocular images with deep convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision (ACCV)</title>
		<meeting><address><addrLine>Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">9004</biblScope>
			<biblScope unit="page" from="332" to="347" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cascaded deep monocular 3d human pose estimation with evolutionary training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shichao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Pratama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Wing</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chi-Keung</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwang-Ting</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Maximummargin structured learning with deep networks for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weichen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV), ICCV &apos;15</title>
		<meeting><address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2848" to="2856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Orinet: A fully convolutional network for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">92</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A simple yet effective baseline for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Monocular 3d human pose estimation in the wild using improved cnn supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on 3D Vision (3DV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">XNect: Real-time multi-person 3D motion capture with a single RGB camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Franziska</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<editor>Mohamed Elgharib, Pascal Fua, Hans-Peter Seidel, Helge Rhodin, Gerard Pons-Moll, and Christian Theobalt</editor>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">39</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Vnect: Real-time 3d human pose estimation with a single rgb camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Shafiei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Multiview-consistent semi-supervised learning for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Nitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Gundavarapu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="6907" to="6916" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">3d human pose estimation from a single image via distance matrix regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesc</forename><surname>Moreno-Noguer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Unsupervised 3d human pose representation with viewpoint and pose disentanglement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhui</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">3d human pose estimation using convolutional neural networks with 2d pose information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungheon</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jihye</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nojun</forename><surname>Kwak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="156" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Ordinal depth supervision for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7307" to="7316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Coarse-to-fine volumetric prediction for single-image 3d human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Konstantinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1263" to="1272" />
		</imprint>
	</monogr>
	<note>Derpanis, and Kostas Daniilidis</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">3d human pose estimation in video with temporal convolutions and semi-supervised training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Pavllo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Github, 3d human pose estimation in video with temporal convolutions and semi-supervised training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Pavllo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fundamental ratios and logarithmic periodicity in human limb bones</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Pietak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siyan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caroline</forename><forename type="middle">W</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">D</forename><surname>Stringer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Anatomy</title>
		<imprint>
			<biblScope unit="volume">222</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="526" to="537" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Exploiting temporal information for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Imtiaz</forename><surname>Mir Rayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Neural scene decomposition for multi-person motion capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isinsu</forename><surname>Katircioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7703" to="7713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unsupervised geometry-aware representation learning for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning monocular 3d human pose estimation from multi-view images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Sp?rri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isinsu</forename><surname>Katircioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Weakly-supervised 3d pose estimation from a single image using multi-view consistency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Rochette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Bowden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMVC</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">LCR-Net: Localization-Classification-Regression for Human Pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Rogez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Weinzaepfel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting><address><addrLine>Honolulu, United States</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017-07" />
			<biblScope unit="page" from="1216" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">View-invariant probabilistic embedding for human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaping</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Compositional human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxiang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2602" to="2611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Integral human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="529" to="545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Structured prediction of 3d human pose with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isinsu</forename><surname>Bugra Tekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Katircioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference (BMVC)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Lifting from the deep: Convolutional 3d pose estimation from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Denis</forename><surname>Tome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lourdes</forename><surname>Agapito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Adversarial inverse graphics networks: Learning 2d-to-3d lifting and image-to-image translation from unpaired supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><forename type="middle">F</forename><surname>Hsiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">W</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katerina</forename><surname>Seto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fragkiadaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4364" to="4372" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Recovering accurate 3D human pose in the wild using IMUs and a moving camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Timo Von Marcard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Bodo Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pons-Moll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">11214</biblScope>
			<biblScope unit="page" from="614" to="631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Repnet: Weakly supervised training of an adversarial reprojection network for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019-06" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Canonpose: Self-supervised monocular 3d human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petrissa</forename><surname>Zell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Distill knowledge from nrsfm for weakly supervised 3d pose learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Lucey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Probabilistic monocular 3d human pose estimation with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tom</forename><surname>Wehrbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Single image 3d interpreter network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuandong</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Ghum &amp; ghuml: Generative 3d human shape and articulated pose models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">Gabriel</forename><surname>Bazavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Deep kinematics analysis for monocular 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiancheng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaokang</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Towards alleviating the modeling ambiguity of unsupervised monocular 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenbo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingbing</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenglong</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="8651" to="8660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Weakly supervised 3d human pose and shape reconstruction with normalizing flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Zanfir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><forename type="middle">Gabriel</forename><surname>Bazavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahul</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020</title>
		<editor>Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm, editors</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Hemlets pose: Learning part-centric heatmap triplets for accurate 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianjuan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangbo</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2344" to="2353" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
