<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Reasoning over Hybrid Chain for Table-and-Text Open Domain QA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanjun</forename><surname>Zhong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The School of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit2">Sun Yat-sen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Huang</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Beihang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Liu</surname></persName>
							<email>qian.liu@buaa.edu.cnnanduan@microsoft.com</email>
							<affiliation key="aff2">
								<orgName type="institution">Beihang University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Zhou</surname></persName>
							<email>zhouming@chuangxin.com</email>
							<affiliation key="aff3">
								<orgName type="laboratory">Langboat Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahai</forename><surname>Wang</surname></persName>
							<email>wangjiah@mail</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The School of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit2">Sun Yat-sen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">The School of Computer Science and Engineering</orgName>
								<orgName type="institution" key="instit2">Sun Yat-sen University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Duan</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Microsoft Research</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Reasoning over Hybrid Chain for Table-and-Text Open Domain QA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T18:55+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Tabular and textual question answering requires systems to perform reasoning over heterogeneous information, considering table structure, and the connections among table and text. In this paper, we propose a ChAincentric Reasoning and Pre-training framework (CARP). CARP utilizes hybrid chain to model the explicit intermediate reasoning process across table and text for question answering. We also propose a novel chain-centric pretraining method, to enhance the pre-trained model in identifying the cross-modality reasoning process and alleviating the data sparsity problem. This method constructs the large-scale reasoning corpus by synthesizing pseudo heterogeneous reasoning paths from Wikipedia and generating corresponding questions. We evaluate our system on OTT-QA, a large-scale table-and-text open-domain question answering benchmark, and our system achieves the state-of-the-art performance. Further analyses illustrate that the explicit hybrid chain offers substantial performance improvement and interpretablity of the intermediate reasoning process, and the chain-centric pretraining boosts the performance on the chain extraction.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Open domain question answering <ref type="bibr" target="#b12">(Joshi et al., 2017;</ref><ref type="bibr" target="#b8">Dunn et al., 2017;</ref><ref type="bibr" target="#b16">Lee et al., 2019)</ref> requires systems to retrieve and perform reasoning over supported knowledge, and finally derive an answer. Generally, the real-world knowledge resource is heterogeneous, which involve both semi-structured web tables and unstructured text like Wikipedia passages. Therefore, question answering over hybrid tabular and textual knowledge is essential and attracts wide attentions <ref type="bibr" target="#b3">(Chen et al., 2020a)</ref>, and is more challenging as systems need to aggregate</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieved Passage</head><p>The 2019-20 NBA season is the 74th season of the National Basketball Association. The season was suspended by COVID-19. The 2020 NBA All-Star ? information in both table and text considering their connections and the table structure.</p><p>As the example shown in <ref type="figure">Fig. 1</ref>, the complete reasoning process for answering the question involves hybrid information pieces in both the table ("Year" and "Points" columns in the first row) and the passage ("COVID-19"). Therefore, modeling the structural connections inside heterogeneous knowledge is critical for modeling the reasoning process. Many recent works on table-and-text open domain QA simply take the supported flattened table and passages <ref type="bibr" target="#b3">(Chen et al., 2020a;</ref><ref type="bibr" target="#b18">Li et al., 2021)</ref> as a whole for question answering, which neglects the structural information and connections among table and text, and leads to more noise as full tables always contain redundant information. Secondly, these methods tackle the whole reasoning process as a black box, and lack the interpretability of the intermediate reasoning process. Moreover, the data sparsity problem is also severe, as the high-quality annotated reasoning process is hard to be obtained.</p><p>To tackle these challenges, we propose a ChAin-centric Reasoning and Pre-training framework (CARP), which models the intermediate reasoning process across table and text with a hybrid chain for question answering. CARP first formulates a heterogeneous graph, whose nodes are information pieces in the relevant table and passages, to represent the interaction residing in hybrid knowledge. Then, it identifies the most plausible reasoning path leading to the answer with a Transformer-based extraction model. Moreover, to augment the pretrained model with ability to identify the reasoning process, we propose a novel chain-centric pretraining method, which takes the advantage of the clear table structure and table-passage connections to construct large-scale pseudo reasoning paths, and reversely generate questions. CARP framework has following advantages. Firstly, the hybrid chain models the interaction between table and text, and reduces the redundant information. Secondly, it provides a guidance for QA, and better interpretability of the intermediate reasoning process. Lastly, both the training of the extraction model and the pre-training corpus construction require no human-annotated reasoning process, which alleviates the data sparsity problem and broadens the potential applications of the framework. Experiments show that our system achieves the state-of-the-art result on a large-scale <ref type="table">table-</ref>andtext open-domain question answering benchmark OTT-QA. Notably, the effectiveness of the chaincentric pre-training method is proved by the significant performance boost of the chain extraction model. Results show that incorporating the hybrid chain enhances the QA model, especially for the questions requiring more complicated reasoning process. We summarize following contributions: 1) We propose to model the intermediate reason-</p><p>ing process for question answering over table and text, with a fine-grained hybrid chain.</p><p>2) We propose a novel pre-training method, which captures the reasoning process by pretraining on a synthesized reasoning corpus consisting of large-scale cross-modality reasoning paths and corresponding questions.</p><p>3) Experiments show that our system achieves the state-of-the-art result and further analysis proves the effectiveness of utilizing the hybrid chain and the pre-training method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Definition</head><p>In this paper, we study the task of question answering over table and text in a challenging opendomain setting, because the supported knowledge is not always provided in a realistic application. The task <ref type="bibr" target="#b3">(Chen et al., 2020a</ref>) takes a question as the input, then requires the systems to first retrieve supported tables and passages, and then make inference over the retrieved knowledge to derive a free-formed answer as the output. The answer is a span from either the table cells or the passages. One of the core challenges of this task is that problem solving always requires complex reasoning process across table and text, considering the crossmodality interaction and table structure.</p><p>3 Framework: CARP <ref type="figure">Fig. 2</ref> shows the pipeline of our CARP framework, which has three main parts: (1) a retriever that retrieves tabular and textual knowledge with the given question ( ? 3.5); (2) a chain extractor that extracts hybrid chain from the retrieved knowledge ( ? 3.2).</p><p>(3) a reader that answers questions with retrieved knowledge and the extracted hybrid chains ( ? 3.4). We detailedly illustrate the hybrid chain (i.e., definition, extraction, pre-training, and application in QA), and briefly introduce the retriever.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Hybrid Chain Notation</head><p>Hybrid chain logically reveals the fine-grained reasoning process from question to the answer across table and text. We define the hybrid chain as a sequence of nodes extracted from a fine-grained heterogeneous graph G , whose nodes V contain the question, cells in the table and sentences in the related passages. One example of the hybrid chain is shown in <ref type="figure">Fig. 1</ref>. Two nodes in the graph are connected by edges E defined by two types of connections: structural connections and contextual connections. The former indicates that pairs of cells within a same row (e.g., edge c in <ref type="figure">Fig. 1</ref>), or a cell to the a sentence in its linked passage (e.g., edge b), are structurally connected. The latter indicates that pairs of nodes with relevant context (i.e., entity/ keyword co-occurrence) are contextually connected (e.g., edge a indicates co-occurred keyword "COVID-19"). Specifically, we use offthe-shelf named entity recognition model <ref type="bibr" target="#b21">(Peters et al., 2017)</ref> to extract entities, and extract noun phrase and numerical items as keywords from the node context. Moreover, a table cell and a passage is linked by the entity linker as described in ? 3.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Hybrid Chain Extraction</head><p>Here we introduce how to extract hybrid chains, including the model architecture, training and inference process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Model Architecture</head><p>We tackle the chain extraction as a semantic matching problem, which selects the best chain from several candidate chains. Taking a question and a candidate hybrid chain as the inputs, the model calculates the confidence score of the hybrid chain for answering the question. Each candidate hybrid chain is represented as a flattened sequence of its nodes context. Details and an example are given in the Appendix B.3. We utilize rich contextual representations embodied in pre-trained models like RoBERTa   </p><formula xml:id="formula_0">(s ? c i , s + c i ) = softmax(W h c i + b)<label>(1)</label></formula><p>where W and b are the learnable parameters. The model is trained with the cross-entropy loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Model Training</head><p>As mentioned above, the key challenge is constructing the training instances (i.e., ground-truth chains and negative chains), as there is no gold-annotated reasoning process given as a prior.</p><p>We first introduce how to build ground-truth hybrid chains from the heterogeneous graph G . Partly inspired by <ref type="bibr" target="#b2">Chen et al. (2019a)</ref>, we use a heuristic algorithm to derive pseudo ground-truth hybrid chains. Starting from the question, we do the exhaustive search to find all the shortest paths to the nodes containing the answer as the candidate chains. Then, we select the best chain from all the candidate chains that have maximum textual similarity with the question as the final ground-truth hybrid chain, and take it as the positive instance. To build the hard negative instances, we find the shortest paths from the question node to the nonanswer nodes and select the one with maximum textual similarity with the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Model Inference</head><p>During Inference, we first build a set of candidate hybrid chains from the graph G, and adopt the extraction model to rank all the chains, and finally select the best chain with highest confidence score.</p><p>More specifically, the set of whole candidate hybrid chains contains the shortest paths from the question node to all the other nodes in the graph. Suppose the number of nodes is n in the graph, the number of candidate chains is n?1 i=0 SP (i), where SP is the number of shortest paths to node i.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Chain-centric Pre-training</head><p>Pre-training for reasoning is always challenging because high-quality reasoning data is hard to be obtained. To better help the pre-trained model in capturing the complicated reasoning process across table and text and alleviate the data sparsity problem, we propose a chain-centric pre-training method. The method augments the chain extraction model by pre-training on a synthesized reasoning corpus in larger scale and of higher reasoning complexity. The overall process of adopting pre-training strategy is illustrated in <ref type="figure">Fig. 3:</ref> (1) synthesizing heterogeneous chains from the Wikipedia corpus and reversely generating corresponding questions by a trained generator; (2) pre-training a generic extraction model with the synthesized corpus; (3) fine-tuning a specific extraction model with the downstream data. We introduce the pre-training task and the corpus construction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Task Formulation</head><p>The pre-training task can be viewed as a similar semantic matching task that maps hybrid chains to the corresponding pseudo questions. The pretraining objective is in the same spirit of the chain extraction model as described in ? 3.2. If the model can better distinguish the relevant hybrid chain for answering the given question, then it has deeper understanding of the reasoning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Corpus Construction</head><p>To construct the large-scale reasoning corpus, we adopt a novel way of first synthesizing heterogeneous reasoning paths, and then reversely generating corresponding questions. Tables in Wikipedia often contain hyperlinks to their related passages. The clear table structure and the explicit table-text links provide natural benefits for automatically synthesizing logically reasonable reasoning paths.</p><p>Therefore, we select semi-structured tables on Wikipedia as the table source, and take the passages hyper-linked to the table cells as the source of passages. The parsed Wikipedia corpus consists of over 200K tables and 3 millions of hyperlinked passages. Then, we synthesize pseudo chains with different reasoning depths. For example, to synthesize a 4-hop reasoning path, we randomly select two cells (c 0 , c 1 ) within the same row and their related passages (p 0 , p 1 ) to form a chain (p 0 , c 0 , c 1 , p 1 ). Similarly, (p 0 , c 0 ) or (c 0 , c 1 , p 1 ) can be selected as a 2-hop or a 3-hop chain, respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Specific Chain Extractor ? Corpus Construction</head><p>How many points did Lebron James get in the NBA Season suspended by COVID-19?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hybrid chain</head><p>Text The season was suspended by COVID-19  <ref type="figure">Figure 3</ref>: An overview of our pre-training approach. A generic train extractor is first learned by pre-training on the synthesized reasoning corpus. Then, we fine-tune the specific extractor by the downstream data.</p><p>Finally, taking a synthesized flattened chain as the input, we adopt a generation model built based on BART  to reversely generate a pseudo question to construct a pair of (question, chain) as a positive instance. It is worth noting that the generation model is trained by the ground-truth (question, chain) pairs as described in ? 3.2. To encourage the model to better discriminate relevant chains, we select other chains sampled from the same table with top-n similarity with the question as the hard negative instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Hybrid Chain for QA</head><p>Having extracted the hybrid chains for each table segment and its related passages, we need to build a reader model to extract the answer a with the inputs. We build a reader model based on a sparse-attention based Transformer architecture Longformer (Beltagy et al., 2020) to process long sequence efficiently. With longer limited length up to 4096 tokens, the reader can read top-k retrieved evidences jointly for question answering. The input sequence x is the concatenation of the question and top-k pairs of (table segment, passages, hybrid chain). The Longformer encodes the input x of length T into a sequence of hidden vectors:</p><formula xml:id="formula_1">h(x) = [h(x) 1 , h(x) 2 , ? ? ? , h(x) T ]<label>(2)</label></formula><p>The probabilities p start (i) and p end (i) of the start and ending token of the answer a are calculated by:</p><formula xml:id="formula_2">p start (i) = exp(W s h(x) i + b s ) j exp(W s h(x) j + b s ) p end (i) = exp(W e h(x) i + b e ) j exp(W e h(x) j + b e )<label>(3)</label></formula><p>where W s , W e , b s , b e are learnable weights and bias parameters of the answer extraction layer. Specifically, to alleviate the bias that the model only looks at the extracted chain, we only set the chain as a guidance of the intermediate reasoning process and force the model to select answer from the tokens of the table and passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Knowledge Retrieval</head><p>Unlike retrievers in text-based open-domain QA systems, the retriever for this task is required to search both supported passages and tables. We briefly introduce the retriever in the last part for integrality, as it is not the main focus of our paper. Instead of independently retrieving tables and passages, we follow <ref type="bibr" target="#b3">Chen et al. (2020a)</ref> and use an "early-fusion" mechanism, which groups highlyrelevant table cells in a row and their related passages as a self-contained group (fused block). This strategy integrates richer information from two modalities and benefits following retrieval process. We adopt BLINK  as the entity linker to link a table cell to its related passage. BLINK is a highly effective BERT-based entity linking model and is able to link against all Wikipedia entities. Specifically, taking the cell to be linked and the table metadata as the inputs, BLINK automatically finds the relevant passages for each cell. After the linking procedure, we represent each fused block as a row in the table and linked related passages. Further details are given in the Appendix. We then tackle the fused block as a basic unit to be retrieved.</p><p>Finally, a Transformer-based retriever is employed to retrieve top-k fused blocks as the knowledge. We apply a shared RoBERTa-encoder RoBERT a(?)  to separately encode questions and fused blocks. The relevance of the question and a fused block is measured by the dot-product over their representations of the [CLS] token. We train the retriever model as in <ref type="bibr" target="#b13">Karpukhin et al. (2020)</ref>, where each question is paired with a positive fused block and m negative blocks to approximate the softmax over all blocks. Negative blocks are a combination of in-batch negatives which are fused blocks of the other instances in the mini-batch, and hard negative blocks which are sampled from the other rows in the same table. During inference, we apply the trained encoder to all fused blocks and index them with FAISS (Johnson et al., 2021) offline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>In this section, we conduct experiments to explore the effectiveness of our method from the following aspects: (1) the performance of our overall system on QA; (2) the performance of the hybrid chain extraction model;</p><p>(3) the ablation study about the pretraining strategy; (4) the comprehensive qualitative analysis. The retrieval performance and implementation details of all components are described in Appendix A and B, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dataset and Evaluation</head><p>In the real-world scenario, solving many questions requires retrieving supporting heterogeneous knowledge and making reasoning over it. Therefore, we evaluate the performance of our approach on the OTT-QA <ref type="bibr" target="#b3">(Chen et al., 2020a)</ref>   <ref type="table" target="#tab_5">Table 1</ref>, OTT-QA has over 40K instances and it also provides a corpus collected from Wikipedia with over 400K tables and 6 million passages. Furthermore, the problem solving in OTT-QA requires complex reasoning steps. The reasoning types can be divided into several categories: single hop questions (13%), two hop questions (57%), and multihop questions (30%). We adopt the exact match (EM) and F1 scores <ref type="bibr" target="#b24">(Yu et al., 2018)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>We compare our system to the following methods:</p><p>? HYBRIDER <ref type="bibr" target="#b5">(Chen et al., 2020b)</ref>   passages, and adopts a two stage model to cope with heterogeneous information.</p><p>? Iterative Retriever and Block Reader The model family is proposed by <ref type="bibr" target="#b3">Chen et al. (2020a)</ref>, which couples Iterative Retriever (IR) / Fusion Retriever (FR) with Single Block Reader (SBR) / Cross Block Reader (CBR). IR and FR indicate retrieving supported knowledge by standard iterative retrieval or using "early fusion" strategy to group tables and passages as fused blocks before retrieval, respectively. SBR indicates the standard way of retrieving top-k blocks and then feeding them independently to the reader and selecting the answer with the highest confidence score. CBR means concatenating the top-k blocks together to the reader, with the goal of utilizing the cross-attention mechanism to model their dependency.</p><p>? DUREPA <ref type="bibr" target="#b18">(Li et al., 2021</ref>) is a recently proposed method that jointly reads tables and passages and selectively decides to directly generate an answer or an executable SQL query to derive the output. <ref type="table" target="#tab_7">Table 2</ref> reports the performance of our model and baselines on the development set and blind test set on OTT-QA. In terms of both EM and F1, our model significantly outperforms previous systems with 32.5% EM and 38.5% F1 on the blind test set, and achieves the state-of-the-art performance on the OTT-QA dataset. It is worth noting that, our approach, which exploits explicit hybrid chain, helps the model to capture the reasoning process and boost the performance of the QA model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Comparison</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation of Chain-centric Reasoning</head><p>To verify the effectiveness of our proposed hybrid chain, we firstly eliminate hybrid chain from the QA model inputs, and report the result of "CARP w/o hybrid chain" on the development set in <ref type="table" target="#tab_7">Table  2</ref>. Incorporating hybrid chain into the QA model improves the performance significantly. Then, we explore the performance of various variants in hybrid chain extraction, whose backbone is the pre-trained model RoBERTa . The variants consider three aspects: (1) encoding strategies; (2) ways of heterogeneous graph construction; (3) negative sampling strategies.</p><p>(1) Dual Ranking vs Cross Matching: Dualtower ranking model <ref type="bibr" target="#b13">(Karpukhin et al., 2020)</ref> encodes the question and the hybrid chain separately, and uses the cosine-distance to measure their relevance for ranking. Cross matching means that we use a semantic matching model as described in ? 3.2.</p><p>(2) Simple (S) vs Weighted (W): Simple indicates the edges in the graph are unweighted. Weighted graph means that the edges connecting highly-related (higher ratio of overlapped keywords) nodes have lower weight, and thus the paths with higher overall relatedness (shorter length) are ranked higher in the ground-truth chain construction ( ? 3.2).</p><p>(3) BMNeg vs InnerNeg: BMNeg means that the most similar chain from other positive instances with BM25 are selected as the negative instance. InnerNeg indicates that we select negative instances from other chains constructed from the same fused block, as described in ? 3.2.   <ref type="table" target="#tab_9">Table 3</ref> reports the performance of the hybrid chain extraction model (without pre-training) with different components. We note that a selected chain is correct when it contains an answer node. We take Recall@n as the evaluation metric. Based on the table, we have following findings. Firstly, semantic matching model with cross-attention mechanisms performs better than standard dual-tower ranking model, which verifies that cross-attention mechanism is beneficial for modeling the connections among heterogeneous information. Secondly, finding the shortest path in the weighted graph is better than in the simple graph, which shows that modeling the relatedness of nodes is essential in finding a more reasonable hybrid chain. Finally, negative sampling strategy is extremely essential for hybrid chain selection. The goal of inference is to select the most plausible chain from several candidate chains sampled from the same fused block. Therefore, sampling hard negative instance from the same fused block is much better than sampling from other training instances. We take the setting of "Cross Matching (W + InnerNeg)" as the final setting of the extraction model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rec@1 Rec@2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Evaluation of Chain-centric Pre-training</head><p>In this part, we evaluate the effectiveness of the chain-centric pre-training strategy under different settings. The table cells are aligned to the passages according to their hyperlinks in the Wikipedia website. The main variance of pre-training is the different way of constructing instances for training the BART-based generator. All means that we take all the paths from the question node to the answer node as positive chains to train the generator. Shortest indicates that we only select the shortest paths. As shown in <ref type="table" target="#tab_11">Table 4</ref>, the pre-training strategy improves the performance of the hybrid chain extraction model by a large margin, showing the effectiveness of chain-centric pre-training in helping the model to capture the intermediate reasoning process with given questions. We believe that several reasons for the improvement of chain-centric pretraining are as follows. Automatically synthesizing pre-training data is an effective data augmentation scheme because it can generate data in larger scale and of higher reasoning complexity, which can help the model to better capture the complicated reasoning steps by pre-training.</p><p>Besides, selecting all paths leading to answer as positive chains to train the generator is better than selecting the shortest paths. This observation is intuitively reasonable since the goal of pre-training is to encourage the model to learn a more general reasoning ability with all possible reasoning paths.  Performance on (%) Baseline CARP <ref type="figure">Figure 4</ref>: The performance of baseline and our CARP on the randomly selected 100 instances across different hops. The performance on 1-hop questions is lower mainly because these questions are much less frequent in the dataset <ref type="bibr" target="#b3">(Chen et al., 2020a)</ref>, and always require more complex numerical table understanding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Qualitative Analysis</head><p>We randomly select 100 instances from the development set and manually annotate the plausible hybrid chains and conduct qualitative analyses on several aspects: (1) the performance on the questions requiring different reasoning steps;</p><p>(2) a case study by giving an example; (3) an analysis of common error types to shed a light on future directions.</p><p>Performance on M-hop Questions As shown in <ref type="figure">Fig. 4</ref>, we report the performance of the baseline (CARP without hybrid chain) and CARP on the selected questions with different reasoning steps. It can be observed that as the number of reasoning steps increases, the improvement brought by our method to the baseline becomes more significant. This observation verifies that, the hybrid chain is essential in helping the model to identify the intermediate reasoning steps towards the answer especially when the reasoning is more complicated. Our synthesized pre-training corpus includes higher ratio of 3-hop questions, which enhance the multi-hop reasoning ability of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Case Study</head><p>We conduct a case study by giving an example shown in <ref type="figure">Fig. 5</ref>. From the example, our chain extraction model selects a semanticconsistent hybrid chain from the fused block and the QA model correctly predicts the answer with the help of the hybrid chain. This observation re-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieved Passage</head><p>Villa Maipa is a localidad (district) of the General San Mart? n Partido ? The localidad is home to Chacarita Juniors, a football club that won the 1969 Metropolitano.</p><p>Club Atletico Chacarita Juniors is an Argentine football ? The squad currently plays at Argentine Primera Division.  <ref type="figure">Figure 5</ref>: A case study of our approach. The answer is Argentine Primera Division. We omit some unimportant sentences in the passage for simplification. flects that our model has the ability to extract intermediate reasoning process from the given inputs and utilize these information to facilitate the question answering process. Hybrid chain also makes the predictions become more interpretable.</p><p>Error Analysis We summarize major types of errors to shed a light on future directions. The most common type of errors is caused by the disturbance of wrongly retrieved fused blocks because we feed top-k fused blocks jointly to the model. We observe that although our model finds the correct blocks and identifies correct chains, but the answer is selected from the other blocks. The second type of errors is caused by failing to understand complicated numerical relation when building the chain (e.g., "finding the 9 th team" needs to numerically compare the rank of several teams). Further research can focus on the confidence of the retrieved blocks and the numerical understanding of the table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Related Work</head><p>Semi-structured web table is an essential knowledge source that storing significant amount of realworld knowledge. Furthermore, since the compact structured representation of table allows it to represent relational facts like numerical facts and collections of homogeneous entities, so table is a great complement to textual knowledge. There has been a growing interest in QA with both tabular and textual knowledge. HybridQA <ref type="bibr" target="#b5">(Chen et al., 2020b</ref>) is a close-domain table-and-text question answering dataset with ground-truth knowledge provided. In realistic scenario, the supported knowledge is always required to be retrieved from knowledge corpus. There are also other table-based datasets, like WikiTableQuestions <ref type="bibr" target="#b20">(Pasupat and Liang, 2015)</ref>, WikiSQL <ref type="bibr" target="#b25">(Zhong et al., 2017)</ref>, SPIDER <ref type="bibr" target="#b24">(Yu et al., 2018)</ref>, and TABFACT <ref type="bibr" target="#b4">(Chen et al., 2019b)</ref>, etc. These datasets mainly focus on reasoning on table and may discard some important information stored in textual corpus. We study OTT-QA <ref type="bibr" target="#b3">(Chen et al., 2020a)</ref>, which is a large open-domain table-andtext QA dataset requiring aggregating information from hybrid knowledge.</p><p>There exist text-based question answering datasets designed in open-domain <ref type="bibr" target="#b12">(Joshi et al., 2017;</ref><ref type="bibr" target="#b8">Dunn et al., 2017;</ref><ref type="bibr" target="#b16">Lee et al., 2019)</ref> or multihop <ref type="bibr" target="#b22">Welbl et al., 2018)</ref> settings. Graph-based models <ref type="bibr" target="#b6">(De Cao et al., 2018;</ref><ref type="bibr" target="#b9">Fang et al., 2019;</ref><ref type="bibr" target="#b7">Ding et al., 2019)</ref> utilize graph structure and graph neural network to model the connections among sentences or entities for multi-hop QA. There are works adopting chain-like reasoning to solve multi-hop textual QA <ref type="bibr" target="#b2">(Chen et al., 2019a;</ref><ref type="bibr" target="#b0">Asai et al., 2019;</ref><ref type="bibr" target="#b10">Feng et al., 2020)</ref>.</p><p>Our approach differs from previous methods mainly in two aspects: (1) our method formulate heterogeneous chain to model the complex reasoning process across table and text; (2) the chaincentric pre-training method can enhance reasoning ability of models by pre-training on a synthesized reasoning corpus, containing heterogeneous reasoning paths and pseudo multi-hop questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we present a chain-centric reasoning and pre-training (CARP) framework for table-andtext question answering. When answering the questions given retrieved table and passages, CARP first extracts explicit hybrid chain to reveal the intermediate reasoning process leading to the answer across table and text. The hybrid chain provides a guidance for QA, and explanation of the intermediate reasoning process. To enhance the extraction model with better reasoning ability and alleviate data sparsity problem, we design a novel chaincentric pre-training method. This method synthesizes the reasoning corpus in a larger scale and of higher reasoning complexity, which is achieved by automatically synthesizing heterogeneous reasoning paths from tables and passages in Wikipedia and reversely generating multi-hop questions. We find that the pre-training task boosts performance on the hybrid chain extraction model, especially for questions requiring more complex reasoning, which leads to significant improvement on the performance of the QA model. The hybrid chain also provides better interpretability of the reasoning process. Our system achieves the state-of-the-art result on a table-and-text open-domain QA benchmark.</p><p>In this part, we evaluate the retrieval performance of retrievers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Settings</head><p>Our retriever is evaluated on the OTT-QA dataset <ref type="bibr" target="#b3">(Chen et al., 2020a)</ref>, which is a large-scale opendomain question answering dataset over table and text. We compare our retriever with the following retrieval methods. (1) BM25 <ref type="bibr" target="#b3">(Chen et al., 2020a)</ref> is a sparse method to retrieve tabular evidence with BM25. It represent the table with the flattened sequence of table metadata (i.e., table title and section title) and table content. (2) Bi-Encoder <ref type="bibr" target="#b14">(Kosti'c et al., 2021)</ref> is a dense retriever which uses a BERT-based encoder for questions, and a shared BERT-based encoder to separately en-code tables and text as representations for retrieval. (3) <ref type="bibr">Tri-Encoder (Kosti'c et al., 2021)</ref> is a dense retriever that uses three individual BERT-based en-coder to separately encode questions, tables and text as representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Evaluation Metrics</head><p>In this experiment, we use two metrics to evaluate the retriever: table recall and fused block recall. <ref type="table">Table recall</ref> indicates whether the top-k retrieved blocks come from the ground-truth table, which is also used in other papers. However, in tabletext retrieval, table recall is imperfect as an coarsegrained metric since our basic retrieval unit is a table-text block. Therefore we use a more finegrained and challenging metric: fused block recall at top-k ranks, where a fused block is considered a correct match when it meets two requirements: coming from the ground truth table and containing the correct answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Performance</head><p>The results are shown in <ref type="table" target="#tab_14">Table 5</ref>. We can find that our retriever substantially outperforms sparse BM25 method and achieves comparable performance with Bi-Encoder and Tri-Encoder.  token between cells or passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Retrieval Model</head><p>In this part, we describe the details of the fused block retrieval model. Our retrieval model follows a typical dual-encoder architecture, which uses a dense encoder E(?) to map any fused block to a d-dimensional dense vector and build an index for all the blocks for retrieval. At query time, the input question q is mapped to a d-dimensional dense vector by the same neural encoder E(?), and returns top-k fused blocks that are closest to the question representation. The similarity of q and b is measured by a dot-product of two vectors:</p><formula xml:id="formula_3">sim(q, b) = E(q) ? E(b).<label>(4)</label></formula><p>In practice, we use a pre-trained RoBERTa-base  to initialize our encoder and take the representation at the first token (i.e. [CLS] token) as the the output. At inference time, we apply FAISS <ref type="bibr" target="#b11">(Johnson et al., 2021)</ref> to index the dense representations of all fused blocks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.1 Training</head><p>The training objective aims to maximize the probability of positive pairs. Formally, given a question q i together with its positive block b + i and m negative blocks {b ? i,1 , ..., b ? i,m }, we optimize the loss function as the negative log-likelihood of positive block:</p><formula xml:id="formula_4">L(q i , b + i , {b ? i,1 , ..., b ? i,m }) = ? log e sim(q i ,b + i ) e sim(q i ,b + i ) + m j=1 e sim(q i ,b ? i,j ) .<label>(5)</label></formula><p>Following <ref type="bibr" target="#b13">Karpukhin et al. (2020)</ref>, we use 1 hard negative fused block randomly sampled from the same table, and m ? 1 in-batch negatives during training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Hybrid Chain Extraction Model</head><p>In this part, we describe the example of the flattened hybrid chain and training details of our hybrid chain extraction model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Verbalization of the hybrid chain</head><p>We introduce how to represent hybrid chain with natural language, and enable the powerful pre-trained language model to calculate its contextual representations. Each node is either the question, a table cell or a sentence in the passages. Therefore, we represent the content in different types of nodes as: "[Question] (question)", " <ref type="table" target="#tab_3">[Table]</ref> (column_name) is (cell_content)" or "[Passage] (sentence)", respectively.</p><p>[Question], <ref type="table" target="#tab_3">[Table]</ref>, [Passage] denote special symbols. Then, we concatenate the context in all the nodes corresponding to their types, and separate them with a "[SEP]" special symbol. In our experiment, we omit the question node from the final sequence, to avoid exceeding the maximum sequence length limit of the pre-trained models. For example, the hybrid chain in <ref type="figure">Fig. 1</ref>  Training Details We employ cross-entropy loss as the loss function. We apply AdamW as the optimizer for model training. We employ RoBERTa-Base as the backbone of our approach. We set the learning rate as 1e-5, warmup step as 0, batch size as 16 per GPU, and set max sequence length as 512.</p><p>The training time for one epoch takes 1 hours on 8 V100 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Chain-centric Pre-training</head><p>Corpus Construction When constructing the pre-training corpus, we use 3 millions pairs of (question, hybrid chain) as the positive training instances, and search for the same number of hard negative instances, and the final pre-training corpus contains nearly 6 millions of training instances. It worth noted that, to avoid the bias caused by the length of the hybrid chain, we automatically synthesize hybrid chains with different length various from 1 to 4. The ratio of the synthesized chains with different lengths are: 1-hop (0.1); 2hop (0.25); 3-hop (0.35); 4-hop (0.3). As for the pseudo questions generator, we employ BART-Large as the backbone. It is firstly trained upon pairs of our extracted hybrid chains and questions from the OTT-QA dataset. During training, its learning rate is set as 3e-5, warmup step is as 2000, and batch size is as 8 per GPU. The training time for one epoch takes nearly 2 hours on 8 V100 GPUs.</p><p>Training Details Then we describe the training details of the chain-centric pre-training. Similar to the implementation details of hybrid chain extractor, we employ cross-entropy loss as the loss function. We adopt RoBERTa-Base  as the model backbone and use AdamW as the optimizer for model training the backbone of our approach. We set the learning rate as 3e-5, warmup step as 0, batch size as 32 per GPU, and set max sequence length as 512. The training time for one epoch takes 8 hours on 8 V100 GPUs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 QA Model</head><p>We employ the Longformer-Base <ref type="bibr" target="#b1">(Beltagy et al., 2020)</ref> as the backbone of our QA model. We set batch size as 2 per GPU, set max sequence length as 512, and set document stride as 3072. The learning rate is 1e-5. The training time for one epoch takes 3 hours on 8 V100 GPUs. We concatenate top-15 fused block as the evidence for both training and inference. We adopt AdamW as the optimizer, and use cross entropy as the loss function. During training and inference, we force the model to only select the answer from the tokens of the fused blocks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>An example of the table-and-text QA with intermediate reasoning process. The answer is 25.3.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>a</cell></row><row><cell></cell><cell></cell><cell cols="3">Retrieved Table</cell><cell></cell><cell></cell></row><row><cell>b</cell><cell cols="5">Lebron James Career Statistics</cell><cell></cell></row><row><cell>Team</cell><cell></cell><cell>Year</cell><cell cols="3">Points Per Game</cell><cell></cell><cell>Blocks</cell></row><row><cell>L.A. Lakers</cell><cell></cell><cell>19-20</cell><cell>c</cell><cell cols="2">25.3</cell><cell></cell><cell>0.5</cell></row><row><cell>Cleveland</cell><cell></cell><cell>17-18</cell><cell></cell><cell cols="2">27.8</cell><cell></cell><cell>0.9</cell></row><row><cell></cell><cell></cell><cell cols="4">Reasoning Process</cell><cell></cell></row><row><cell>? COVID-19?</cell><cell>a</cell><cell cols="2">? COVID-19.</cell><cell>b</cell><cell>19-20</cell><cell>c</cell><cell>25.3</cell></row><row><cell>Question</cell><cell></cell><cell cols="2">Sentence</cell><cell cols="4">Table Cell Table Cell</cell></row><row><cell>Figure 1:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Points Per Game 25.3 Sentence Table cell Hybrid Chain 25.3 Answer Question Table Passage Hybrid Chain Extractor Retriever Reader</head><label></label><figDesc></figDesc><table><row><cell cols="4">How many points did Lebron James</cell><cell></cell></row><row><cell cols="4">get in the NBA Season suspended by</cell><cell></cell></row><row><cell cols="2">COVID-19?</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>The season was</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>suspended by</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>COVID-19</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Table cell</cell></row><row><cell>Team</cell><cell>Year</cell><cell>Game Points Per</cell><cell>Blocks</cell><cell>Year</cell></row><row><cell cols="2">L.A. Lakers 19-20</cell><cell>25.3</cell><cell>0.9</cell><cell>19-20</cell></row><row><cell cols="2">Cleveland 17-18</cell><cell>27.8</cell><cell>0.5</cell><cell></cell></row><row><cell cols="4">(19-20) The 2019-20 NBA season ... The</cell><cell></cell></row><row><cell cols="4">season was suspended by COVID-19. The</cell><cell></cell></row><row><cell cols="2">2020 NBA All-Star ?</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">Figure 2: Overview of our system. Retriever ( ? 3.5) first retrieves knowledge from the corpus for the question.</cell></row><row><cell cols="5">Secondly, hybrid chain extractor ( ? 3.2) extracts hybrid chains from the knowledge, which is improved by pre-</cell></row><row><cell cols="5">training ( ? 3.3). Finally, reader ( ? 3.4) answers the questions with retrieved evidence and extracted hybrid chain.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table [</head><label>[</label><figDesc></figDesc><table><row><cell cols="2">Synthetic Pre-training Corpus</cell></row><row><cell cols="2">Question</cell></row><row><cell cols="2">What is the profession of the person in Royal</cell></row><row><cell cols="2">Melbourne Institute of Technology who was born</cell></row><row><cell cols="2">on 12 November 1940?</cell></row><row><cell cols="2">Hybrid chain</cell></row><row><cell>Text</cell><cell>John Raymond Garrett ( born 12 November 1940 )</cell></row><row><cell></cell><cell>Table [Name] is John Garrett</cell></row><row><cell></cell><cell>Table ) [Notability] is journalist</cell></row><row><cell cols="2">Downstream Dataset</cell></row><row><cell>Training</cell><cell></cell></row><row><cell></cell><cell>Year] is 19-20</cell></row><row><cell></cell><cell>Table [Points Per Game] is 25.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>dataset. OTT-QA is a large-scale table-and-text open-domain question answering benchmark for evaluating opendomain question answering over both tabular and textual knowledge. As the data statistics shown in</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1 :</head><label>1</label><figDesc>Data statistics of OTT-QA dataset.</figDesc><table><row><cell>to evaluate</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 :</head><label>2</label><figDesc>Performance of different methods on the dev set and the blind test set on OTT-QA. The performance of CARP without hybrid chain is also reported.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 3 :</head><label>3</label><figDesc>Performance of the hybrid chain extraction model with different variances.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 4 :</head><label>4</label><figDesc>Performance of the chain extraction with chain-centric pre-training under different settings.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>46</cell></row><row><cell></cell><cell></cell><cell>42</cell></row><row><cell>40</cell><cell></cell><cell>35</cell><cell>33</cell></row><row><cell>20</cell><cell>12.5</cell><cell>18.8</cell></row><row><cell>0</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">1-hop (16%) 2-hop (60%) 3-hop (24%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Question</head><label></label><figDesc>What division that the Argentinian Primera Metropolitana club in the city that won the 1969 Metropolitano plays in?</figDesc><table><row><cell></cell><cell cols="2">Retrieved Table</cell></row><row><cell cols="3">List of football clubs in Argentina</cell></row><row><cell>Club</cell><cell>City</cell><cell></cell><cell>Province</cell></row><row><cell>Chacarita Juniours</cell><cell cols="2">Villa Maipa</cell><cell>Buenos Aires</cell></row><row><cell>Colegiales</cell><cell>Munro</cell><cell></cell><cell>Buenos Aires</cell></row><row><cell></cell><cell cols="2">Hybrid Chain</cell></row><row><cell>Question</cell><cell>Table Cell</cell><cell cols="2">Sentence</cell></row><row><cell>? Metropolitano</cell><cell>Villa Maipa</cell><cell cols="2">? Argentine Primera Division</cell></row><row><cell>? Metropolitano</cell><cell></cell><cell cols="2">Chacarita Juniors</cell></row><row><cell>Sentence</cell><cell></cell><cell cols="2">Table Cell</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 5 :</head><label>5</label><figDesc>Overall retrieval results on OTT-QA dev set.Table recalls and fused block recalls are reported. table meta data, the cells in the rows, and related passages: F used Block = ([TAB] [TITLE] title [DATA] row[PASSAGES] passages), where row and passages indicate the flattened row and all the related passages of this row, and there is a [SEP]</figDesc><table><row><cell>B Implementation Details</cell></row><row><cell>B.1 Fused Block Representation</cell></row><row><cell>In this part, we describe how we represent a</cell></row><row><cell>fused block with a table row and its related</cell></row><row><cell>passages. Similar to Chen et al. (2020a), we</cell></row><row><cell>represent each fused block as the concatena-</cell></row><row><cell>tion of the</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>can be represented as: "[Question] How many ... COVID 19? [SEP] [Passage] The season ... COVID-19. [SEP] [Table] Year is 19-20. [SEP] [Table] Points is 25.3."</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Akari</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuma</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10470</idno>
		<title level="m">Learning to retrieve reasoning paths over wikipedia graph for question answering</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Longformer: The long-document transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iz</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arman</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Greg</forename><surname>Shih-Ting Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Durrett</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.02610</idno>
		<title level="m">Multi-hop question answering via reasoning chains</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eva</forename><surname>Schlinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2010.10439</idno>
		<title level="m">Open question answering over tables and text</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianshu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunkai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyou</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><forename type="middle">Yang</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.02164</idno>
		<title level="m">Tabfact: A largescale dataset for table-based fact verification</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanwen</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.07347</idno>
		<title level="m">Hybridqa: A dataset of multi-hop question answering over tabular and textual data</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Question answering by reasoning across documents with graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicola</forename><surname>De Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilker</forename><surname>Aziz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Titov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.09920</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Tang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.05460</idno>
		<title level="m">Cognitive graph for multihop reading comprehension at scale</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Levent</forename><surname>Sagun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volkan</forename><surname>Ugur Guney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cirik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.05179</idno>
		<title level="m">Searchqa: A new q&amp;a dataset augmented with context from a search engine</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Hierarchical graph network for multi-hop question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siqi</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Pillai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuohang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingjing</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03631</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning to recover reasoning chains for multi-hop question answering via cooperative games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yufei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mo</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhan</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Murray</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Dan</forename><surname>Zhu</surname></persName>
		</author>
		<idno>abs/2004.02393</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Billionscale similarity search with gpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Big Data</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="535" to="547" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Triviaqa: A large scale distantly supervised challenge dataset for reading comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunsol</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Weld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03551</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Dense passage retrieval for open-domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Karpukhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barlas</forename><surname>Oguz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sewon</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ledell</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen-Tau</forename><surname>Yih</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.04906</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multi-modal retrieval of tables and texts using triencoder models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bogdan</forename><surname>Kosti&amp;apos;c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Risch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Moller</surname></persName>
		</author>
		<idno>abs/2108.04049</idno>
	</analytic>
	<monogr>
		<title level="j">ArXiv</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Zero-shot entity linking with dense entity retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Ledell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petroni</forename><surname>Fabio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josifoski</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Riedel</forename><surname>Sebastian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zettlemoyer</forename><surname>Luke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">EMNLP</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Latent retrieval for weakly supervised open domain question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.00300</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal ; Abdelrahman Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ves</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.13461</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander Hanbo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henghui</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiguo</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xiang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.02866</idno>
		<title level="m">Dual reader-parser on hybrid textual and tabular evidence for open domain question answering</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinhan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingfei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandar</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Omer</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veselin</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>abs/1907.11692</idno>
	</analytic>
	<monogr>
		<title level="m">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panupong</forename><surname>Pasupat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Percy</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.00305</idno>
		<title level="m">Compositional semantic parsing on semi-structured tables</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Semi-supervised sequence tagging with bidirectional language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Waleed</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chandra</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Constructing datasets for multi-hop reading comprehension across documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johannes</forename><surname>Welbl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pontus</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="287" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhilin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saizheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.09600</idno>
		<title level="m">Hotpotqa: A dataset for diverse, explainable multi-hop question answering</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michihiro</forename><surname>Yasunaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongxu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zifan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irene</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingning</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanelle</forename><surname>Roman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.08887</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1709.00103</idno>
		<title level="m">Seq2sql: Generating structured queries from natural language using reinforcement learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
