<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">SPICE: Semantic Pseudo-Labeling for Image Clustering</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Chuang</forename><surname>Niu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Hongming</forename><surname>Shan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><forename type="first">Ge</forename><surname>Wang</surname></persName>
						</author>
						<title level="a" type="main">SPICE: Semantic Pseudo-Labeling for Image Clustering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>A MANUSCRIPT 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Deep clustering</term>
					<term>self-supervised learning</term>
					<term>semi- supervised learning</term>
					<term>representation learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The similarity among samples and the discrepancy among clusters are two crucial aspects of image clustering. However, current deep clustering methods suffer from inaccurate estimation of either feature similarity or semantic discrepancy. In this paper, we present a Semantic Pseudo-labeling-based Image ClustEring (SPICE) framework, which divides the clustering network into a feature model for measuring the instance-level similarity and a clustering head for identifying the cluster-level discrepancy. We design two semantics-aware pseudo-labeling algorithms, prototype pseudo-labeling and reliable pseudo-labeling, which enable accurate and reliable self-supervision over clustering. Without using any ground-truth label, we optimize the clustering network in three stages: 1) train the feature model through contrastive learning to measure the instance similarity; 2) train the clustering head with the prototype pseudo-labeling algorithm to identify cluster semantics; and 3) jointly train the feature model and clustering head with the reliable pseudo-labeling algorithm to improve the clustering performance. Extensive experimental results demonstrate that SPICE achieves significant improvements (?10%) over existing methods and establishes the new state-of-the-art clustering results on six image benchmark datasets in terms of three popular metrics. Importantly, SPICE significantly reduces the gap between unsupervised and fullysupervised classification; e.g. there is only 2% (91.8% vs 93.8%) accuracy difference on CIFAR-10. Our code is made publically available at https://github.com/niuchuangnn/SPICE.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I MAGE clustering aims to group images into different meaningful clusters without human annotations, and is an essential task in unsupervised learning with the applications in many areas. At the core of image clustering are the measurements of the similarity among samples (images) and the discrepancy among semantic clusters. Recently, deep learning based clustering methods have achieved great progress thanks to the strong representation capability of deep neural networks.</p><p>Initially, by combining autoencoders with clustering algorithms, some deep clustering methods were proposed to learn representation features and perform clustering simultaneously and alternatively <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, achieving better results than the traditional methods. Due to the overestimation of low-level features, these autoencoder-based C. <ref type="bibr">Niu</ref>   methods hardly capture discriminitative features of complex images. Thus, a number of methods were proposed to learn discriminitative label features under various constraints <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>. However, these methods have limited performance when directly using the label features to measure the similarity among samples. This is because the category-level features lose too much instance-level information to accurately measure the instance similarity. Very recently, Van Gansbeke et al. <ref type="bibr" target="#b0">[1]</ref> proposed to leverage the embedding features of unsupervised representation learning model to search for similar samples across the whole dataset, and then encourage a clustering model to output the same labels for similar instances, which further improved the clustering performance. Considering the imperfect embedding features, the local nearest samples in the embedding space do not always have the same semantics especially when the samples lie around the borderlines between different clusters as shown in <ref type="figure" target="#fig_0">Fig. 1(a)</ref>, which may compromise the performance. Essentially, SCAN only utilizes the instance similarity for training the clustering model without explicitly exploring the semantic discrepancy between clusters, as shown in <ref type="figure" target="#fig_0">Fig. 1(b</ref>  The label feature based methods that directly map images to cluster labels, where self-supervision is calculated based on the label features only. (c) A two-stage unsupervised classification method that first trains the feature model and then trains the whole classification work with a label feature based self-supervision and an embedding feature based contrastive loss simultaneously and separately. (d) The SCAN learning framework that constrains the similar samples in the embedding space having the same cluster label. (e) The proposed SPICE framework that synergizes both the similarity among samples and the discrepancy between clusters for training a clustering network through semantics-aware pseudo-labeling.</p><p>Image ClustEring (SPICE) framework that synergizes the similarity among instances and semantic discrepancy between clusters to generate accurate and reliable self-supervision over clustering. In SPICE, the clustering network is divided into two parts: a feature model and a subsequent clustering head, which is exactly a traditional classification network. To effectively measure the instance similarity and the cluster discrepancy, we split the training process into three stages: 1) training the feature model; 2) training the clustering head; and 3) jointly training the feature model and clustering head. We highlight that there is no any annotations throughout the training process. More specifically, in the first stage we adopt the selfsupervised contrastive learning paradigm to train the feature model, which can accurately measure the similarity among instance samples. In the second stage, we propose a prototype pseudo-labeling algorithm to train the clustering head in the expectation-maximization (EM) framework with the feature model fixed, which can take into account both the instance similarity and the semantic discrepancy for clustering. In the final stage, we propose a reliable pseudo-labeling algorithm to jointly optimize the feature model and the clustering head, which can boost both the clustering performance and the representation ability.</p><p>Compared with the instance similarity based method <ref type="bibr" target="#b0">[1]</ref>, the proposed prototype pseudo-labeling algorithm can leverage the predicted cluster labels, obtained from the clustering head, to identify cluster prototypes in the feature space, and then assign each prototype label to its neighbor samples for training the clustering head alternatively. Thus, the inconsistency among borderline samples can be avoided when the prototypes are well captured, as shown in <ref type="figure" target="#fig_0">Fig. 1(b)</ref>. On the other hand, given the predicted labels, the reliable pseudo-labeling algorithm can identify unreliable samples in the embedding space, as the yellow circles in <ref type="figure" target="#fig_0">Fig. 1(c)</ref>, which will be filtered out during joint training. Therefore, the proposed SPICE can generate more accurate and reliable supervision by synergizing the similarity and discrepancy.</p><p>Our main contributions are summarized as follows. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>In this section, we first analyze the deep image clustering methods systematically, and then briefly review the related unsupervised representation learning and semi-supervised classification methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Deep Clustering</head><p>Deep clustering methods have shown significant superiority over traditional clustering algorithms, especially in computer vision. In a data-driven fashion, deep clustering can effectively utilize the representation ability of deep neural networks. Initially, some methods were proposed to combine deep neural networks with traditional clustering algorithms, as shown in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>. Most of these clustering methods combine the stacked auto-encoders (SAE) <ref type="bibr" target="#b16">[17]</ref> with the traditional clustering algorithms, such as k-means <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b2">[3]</ref>, Gaussian mixture model <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>, spectral clustering <ref type="bibr" target="#b19">[20]</ref>, subspace clustering <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b5">[6]</ref>, and relative entropy constraint <ref type="bibr" target="#b6">[7]</ref>. However, since the pixel-wise reconstruction loss of SAE tends to over-emphasize low-level features, these methods have inferior performance in clustering images of complex contents due to the lack of object-level semantics. Instead of using SAE, Yang et al. <ref type="bibr" target="#b20">[21]</ref> alternately perform the agglomerative clustering <ref type="bibr" target="#b21">[22]</ref> and train the representation model by enforcing the samples within a selected cluster and its nearest cluster having similar features while pushing away the selected cluster from its other neighbor clusters. However, the performance of JULE can be compromised by the errors accumulated during the alternation, and their successes in online scenarios are limited as they need to perform clustering on the entire dataset.</p><p>Recently, novel methods emerged that directly learn to map images into label features, which are used as the representation features during training and as the one-hot encoded cluster indices during testing <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b24">[24]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b25">[25]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b26">[26]</ref>, <ref type="bibr" target="#b15">[16]</ref>, as shown in <ref type="figure" target="#fig_1">Fig. 2(b)</ref>. Actually, these methods aim to train the classification model in the unsupervised setting while using multiple indirect loss functions, such as sample relations <ref type="bibr" target="#b10">[11]</ref>, invariant information <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b14">[15]</ref>, mutual information <ref type="bibr" target="#b12">[13]</ref>, partition confidence maximisation <ref type="bibr" target="#b25">[25]</ref>, attention <ref type="bibr" target="#b13">[14]</ref>, and entropy <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b25">[25]</ref>, <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b14">[15]</ref>. Gupta et al. <ref type="bibr" target="#b27">[27]</ref> proposed to train an ensemble of deep networks and select the predicted labels that a large number of models agree on as the high-quality labels, which are then used to train a ladder network <ref type="bibr" target="#b28">[28]</ref> in a semi-supervised learning mode. However, the performance of these methods may be sub-optimal when using such label features to compute the similarity and discrepancy between samples, as the categorylevel label features can hardly reflect the relations of instancelevel samples accurately.</p><p>To improve the representation learning ability, a two-stage unsupervised classification method (TSUC) <ref type="bibr" target="#b29">[29]</ref> was proposed. In the first stage, the unsupervised representation learning model was trained for initialization. In the second stage, a mutual information loss <ref type="bibr" target="#b12">[13]</ref> based on the label features and a contrastive loss based on the embedding features were simultaneously optimized for training the whole model, as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>(c). Although the better initialization and contrastive loss can help learn representation features, the supervision based on the similarity and the discrepancy are computed independently, and the end-to-end training without accurate discriminative supervision will even harm the representation features as analyzed in Section IV-F2. In contrast, Van Gansbeke et al. <ref type="bibr" target="#b0">[1]</ref> proposed a method called SCAN to use embedding features of the representation learning model for computing the instance similarity, based on which the label features are learned by encouraging similar samples to have the same label, as shown in <ref type="figure" target="#fig_1">Fig. 2(d)</ref>. Sharing the same idea with SCAN, NNM <ref type="bibr" target="#b30">[30]</ref> was proposed to enhance SCAN by searching similar samples on both the entire dataset and the sub-dataset. However, since the embedding features are not perfect, similar instances do not always have the same semantics especially when the samples lie near the borderlines of different clusters. Therefore, only using the instance similarity and ignoring the semantic discrepancy between clusters to guide model training may limit the clustering performance. Recently, Park et al. <ref type="bibr" target="#b31">[31]</ref> proposed an add-on module for improving the off-the-shelf unsupervised clustering method based on the semi-supervised learning <ref type="bibr" target="#b32">[32]</ref> and label smoothing techniques <ref type="bibr" target="#b33">[33]</ref>, <ref type="bibr" target="#b34">[34]</ref>.</p><p>Based on the comprehensive analysis of existing deep cluttering methods, we present a new framework for image clustering, as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>(e), which can accurately measure the similarity among samples and the discrepancy between clusters for the model training, and effectively reduce the semantic inconsistency for similar samples. In addition to the image clustering methods mentioned above, there are also promising deep learning-based clustering methods focusing on special <ref type="bibr" target="#b35">[35]</ref>, <ref type="bibr" target="#b36">[36]</ref> or multi-view clustering datasets <ref type="bibr" target="#b37">[37]</ref>, <ref type="bibr" target="#b38">[38]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Unsupervised Representation Learning</head><p>Unsupervised representation learning aims to map samples/images into semantically meaningful features without human annotations, which facilitates various down-stream tasks, such as object detection and classification. Previously, various pretext tasks were heuristically designed for this purpose, such as colorization <ref type="bibr" target="#b39">[39]</ref>, rotation <ref type="bibr" target="#b40">[40]</ref>, jigsaw <ref type="bibr" target="#b41">[41]</ref>, etc. Recently, contrastive learning methods combined with data augmentation strategies have achieved great success, such as SimCLR <ref type="bibr" target="#b42">[42]</ref>, MOCO <ref type="bibr" target="#b43">[43]</ref>, and BYOL <ref type="bibr" target="#b44">[44]</ref>, just to name a few. On the other hand, clustering based representation learning methods have also achieved great progress. Caron et al. <ref type="bibr" target="#b45">[45]</ref> proposed to alternatively performs k-means clustering algorithm on the entire dataset and train the classification network using the cluster labels. Without explicitly computing cluster centers, Asano et al. <ref type="bibr" target="#b46">[46]</ref> proposed a self-labeling approach that directly infers the pseudo-labels from the predicted cluster labels of the full dataset based on the Sinkhorn-Knopp algorithm <ref type="bibr" target="#b47">[47]</ref>, and then uses the pseudo labels to the clustering network. Taking the advantages of contrastive learning, SwAV <ref type="bibr" target="#b48">[48]</ref> was proposed to simultaneously cluster the data while enforcing different transformations of the same image having the same cluster assignment. It is worth emphasizing that, different from the unsupervised deep clustering methods in Section II-A, these clustering based representation learning methods aim to learn the representation features by clustering a much larger number of clusters than the number of ground-truth classes. This is consistent with our observation that directly clustering the target number of classes without accurate supervision will harm the representation learning due to the over-compression of instance-level features. Usually, to evaluate the quality of learned features, a linear classifier is independently trained with ground truth labels by freezing the parameters of representation learning models.</p><p>In this work, we aim to achieve unsupervised clustering with the exact number of real classes. On the other hand, we not only train the feature model but also the clustering head without using any annotations. Actually, any unsupervised representation learning methods can be implemented as our feature model, which can be further improved via the joint training in SPICE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Semi-Supervised Classification</head><p>Our method is also related to the semi-supervised classification methods as actually we reformulate the unsupervised </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pseudo-labeling</head><p>Reliable labels clustering task into a semi-supervised learning paradigm in the joint training stage. Semi-supervised classification methods aim to reduce the requirement of labeled data for training a classification model by providing a means of leveraging unlabeled data. In this category, remarkable results were obtained with consistency regularization <ref type="bibr" target="#b49">[49]</ref>, <ref type="bibr" target="#b50">[50]</ref> that constrains the model to output the same prediction for different transformations of the same image, pseudo-labeling <ref type="bibr" target="#b51">[51]</ref> that uses confident predictions of the model as the labels to guide training processes, and entropy minimization <ref type="bibr" target="#b52">[52]</ref>, <ref type="bibr" target="#b51">[51]</ref> that steers the model to output high-confidence predictions. MixMatch <ref type="bibr" target="#b32">[32]</ref> algorithm combines these principles in a unified scheme and achieves an excellent performance, which is further improved by ReMixMatch <ref type="bibr" target="#b53">[53]</ref> along this direction. Recently, FixMatch <ref type="bibr" target="#b54">[54]</ref> proposed a simplified framework that uses the confident prediction of a weakly transformed image as the pseudo label when the model is fed a strong transformation of the same image, delivering superior results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E-Step</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M-Step</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Loss function</head><p>In this work, we target a more challenging task of training the clustering network without using any annotations, sometimes achieving comparable or even better results than the state-of-the-art semi-supervised learning methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHOD</head><p>We aim to cluster a set of N images X = {x i } N i=1 into K classes by training a clustering network without using any annotations. The clustering network can be conceptually divided into two parts: a feature model that maps images to feature vectors, f i = F(x i ; ? F ), and a clustering head that maps feature vectors to the probabilities over K classes, p i = C(f i ; ? C ), where ? F and ? C represent the trainable parameters of the feature model F and the clustering head C, respectively. Different from the existing deep clustering methods, we use the outputs of the feature model to measure the similarity among samples and use the clustering head to identify the discrepancy between clusters for pseudo-labeling, as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. By effectively measuring both the similarity and discrepancy, we design two semantics-aware pseudo-labeling algorithms, prototype pseudo-labeling and reliable pseudolabeling, to generate accurate and reliable self-supervision.</p><p>Specifically, we split the network training into three stages as shown in <ref type="figure" target="#fig_3">Fig. 3</ref>. First, we optimize the feature model F through the instance-level contrastive learning that enforces the features from different transformations of the same image being similar and the features from different images being discriminative from each other. Second, we optimize the clustering head C with the proposed prototype pseudo-labeling algorithm while freezing the feature model learned in the first stage. Third, we optimize the feature model and the clustering head jointly with the proposed reliable pseudolabeling algorithm.</p><p>In the following subsections, we introduce each training stage in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Feature Model Training with Contrastive Learning</head><p>To accurately measure the similarity of instance samples, here we adopt the instance discrimination based unsupervised representation learning method <ref type="bibr" target="#b43">[43]</ref> for training the feature model. As shown in <ref type="figure" target="#fig_3">Fig. 3(a)</ref>, there are two branches taking two random transformations of the same image as inputs, and each branch includes a feature model and a projection head that is a two-layer multilayer perceptron (MLP). During training, we only optimize the lower branch while the upper branch is updated as the moving average of the lower branch. As contrastive learning methods benefit from a large training batch, a memory bank <ref type="bibr" target="#b55">[55]</ref> is used to maintain a queue of encoded negative samples for reducing the requirement of GPU memory size, which is denoted as</p><formula xml:id="formula_0">{z ? 1 , z ? 2 , . . . , z ? Nq }, where N q is the queue size.</formula><p>Formally, given two transformations x and x of an image x, the output of the upper branch is z + = P(F(x ; ? F ); ? P ), and the output of the lower branch is z = P(F(x ; ? F ); ? P ), where P denotes the projection head with the parameters ? P , and ? F and ? P are the moving averaging versions of ? F and ? P . The parameters ? F and ? P are optimized with the following loss function:</p><formula xml:id="formula_1">L f ea = ? log exp(z T z + /? ) Nq i=1 exp(z T z ? i /? ) + exp(z T z + /? ) ,<label>(1)</label></formula><p>where the negative sample z ? i may be computed from any images other than the current image x, and ? is the temperature. Then, the parameters of the upper branch is updated as</p><formula xml:id="formula_2">? F ? ?? F + (1 ? ?)? F , and ? P ? ?? P + (1 ? ?)? P , where ? ? [0, 1)</formula><p>is a momentum coefficient. The queue is updated by adding z + to the end and removing the first item. All hyperparameters including ? = 0.2 and ? = 0.999 are the same as those in <ref type="bibr" target="#b43">[43]</ref>. The finally optimized feature model parameters are denoted as ? s F , which will be used in the next stage. Remark. In practice, any unsupervised representation learning methods and network architectures can be applied in the SPICE framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Clustering Head Training with Prototype Pseudo-Labeling</head><p>Based on the trained feature model, here we train the clustering head by explicitly exploring both the similarity among samples and the discrepancy between clusters. Formally, given the image dataset X and the feature model parameters ? s F obtained in Section III-A, we aim to train the clustering head only for predicting the cluster labels {y s i } N i=1 . The clustering head C is a two-layer MLP mapping the features to the probabilities,</p><formula xml:id="formula_3">p i = C(f i ; ? C ), where f i = F(x i ; ? s F ).</formula><p>However, in the unsupervised setting we do not have the ground truth for training. To address this issue, we propose a prototype pseudolabeling algorithm that alternatively estimates the pseudo labels of batch-wise samples and optimizes the parameters of the clustering head in an EM framework.</p><p>Generally, this training stage is to solve two sets of variables, i.e., the parameters of the clustering head C, ? C , and the cluster labels {y s i } of X over K clusters. Analogous to kmeans clustering algorithm <ref type="bibr" target="#b56">[56]</ref>, we solve two underlying subproblems alternatively in an EM framework: the expectation (E) step is solving {y s i } given ? C , and the maximization (M) step is solving ? C given {y s i }. Taking the advantages of contrastive learning, we clone the feature model into three branches as shown in <ref type="figure" target="#fig_3">Fig. 3(b</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>):</head><p>? The top branch takes original images as inputs and outputs the embedding features f i ; ? The middle branch takes the weakly transformed images as inputs and estimates the probabilities p i over K clusters, which is then combined with f i to generate the pseudo labels y s i through the proposed prototype pseudolabeling algorithm; ? The bottom branch takes strongly transformed images as inputs and optimizes ? C with the pseudo-labels. The EM process for the clustering head training is detailed as follows. Prototype Pseudo-Labeling (E-step). The top branch computes the embedding features,</p><formula xml:id="formula_4">F = [f 1 , f 2 , . . . , f M ] T ? R M ?D , of a mini-batch of samples X b , and the mid- dle branch computes the corresponding probabilities, P = [p 1 , p 2 , . . . , p M ] T ? R M ?K , for the weakly transformed sam- ples, ?(X b ); here, M is mini-batch size,</formula><p>D is the dimension of the feature vector, and ? denotes the weak transformation over the input image.</p><p>Given P and F , the top confident samples are selected to estimate the prototypes for each cluster, and then the indices of the cluster prototypes are assigned to their nearest neighbors as the pseudo labels. Formally, the top confident samples for each cluster, taking the k-th cluster as an example, are selected as:</p><formula xml:id="formula_5">F k = {f i |i ? argtopk(P :,k , M K ), ? i = 1, 2, . . . , M }, (2)</formula><p>where P :,k denotes the k-th column of matrix P and argtopk P :,k , M K returns the top M K confident sample indices from P :,k . Naturally, the cluster centers {? k } K k=1 in the embedding space are computed as</p><formula xml:id="formula_6">? k = K M fi?F k f i , ? k = 1, 2, . . . , K.<label>(3)</label></formula><p>By computing the cosine similarity between embedding features f i and the cluster center ? k , we select M K nearest samples to ? k , denoted by X k , to have the same cluster label, y s i = k, ?x i ? X k . Thus, a mini-batch of images with semantic pseudo-labels, X s , is constructed as</p><formula xml:id="formula_7">X s = {(x i , y s i )|?x i ? X k , k = 1, 2, . . . , K}.<label>(4)</label></formula><p>A toy example of the prototype pseudo-labeling process is shown in <ref type="figure" target="#fig_4">Fig. 4</ref>, where there is a batch of 10 samples and 3 clusters, 3 confident samples for each cluster are selected according to the predicted probabilities to calculate the prototypes in the feature space, and 3 nearest samples to each cluster are selected and labeled. Note that there may exist overlapped samples between different clusters, so there are two options to handle these labels: one is the overlap assignment that one sample may have more than one cluster labels as indicated by the blue and red circles in <ref type="figure" target="#fig_4">Fig. 4</ref>, and the other is non-overlap assignment that all samples have only one cluster label as indicated by the dished red circle. We found that the overlap assignment is better as analyzed in Section IV-F2.</p><p>Training Clustering Head (M-step). Given the labeled samples X s , the clustering head parameters are optimized in a supervised learning manner. Specifically, we compute the probabilities of strong transformations ?(X s ) in the forward pass, where ? denotes the strong augmentation operator. Then, the clustering head C can be optimized in the backward pass by minimizing the following cross-entropy (CE) loss:</p><formula xml:id="formula_8">L clu = 1 M M i=1 L ce (y s i , p i ),<label>(5)</label></formula><p>where p i = softmax(p i ) and p i = A(F(?(x i ); ? s F ); ? A ), L ce is the cross-entropy loss function.</p><p>In Eq. (5), we use double softmax functions before computing CE loss, as p i is already the outputs of a softmax function. Considering that the pseudo-labels are not as accurate as the ground truth labels, the basic idea behind the double softmax implementation is to reduce the learning speed especially when the predictions are of low probabilities, which can benefit the dynamically clustering process during training (please see Appendix A for the detailed analysis of the double softmax implementation).</p><p>The above process for training the clustering head is summarized in Algorithm 1.</p><p>Remark. In this stage, we fix the parameters of feature models from the representation learning, and only optimize the lightweight clustering head. Thus, the computational burden is significantly reduced so that we can train multiple clustering heads simultaneously and independently. By doing so, the instability of clustering from the initialization can be effectively alleviated through selecting the best clustering head. Specifically, the best head with the parameters ? s C can be selected for the minimum loss value of L clu over the whole dataset; i.e., we set M = N and follow E-step and M-step in Algorithm 1 to compute the loss value. During testing, the best clustering head is used to cluster the input images into different clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Joint Training with Reliable Pseudo-Labeling</head><p>The feature model and the clustering head are optimized separately so far, which tends to be a sub-optimal solution. On the one hand, the imperfect feature model may lead to some similar features corresponding to really different clusters; thus, assigning neighbor samples with the same pseudo-label is not always reliable. On the other hand, the imperfect clustering head may assign really dissimilar samples with the same cluster label, such that only using the predicted labels for finetuning is also not always reliable. To overcome these problems, we design a reliable pseudo-labeling algorithm to train the feature model and clustering head jointly for further improving the clustering performance. Reliable Pseudo-Labeling. Given the embedding features and the predicted labels</p><formula xml:id="formula_9">{(x i , f i , y s i )} N i=1</formula><p>obtained in Section III-B, we select N s nearest samples for each sample x i according to the cosine similarity between embedding features. The corresponding labels of these nearest samples are denoted by L i . Then, the semantically consistent ratio r i of the sample x i is defined as</p><formula xml:id="formula_10">r i = 1 N s y?Li 1(y = y s i ).<label>(6)</label></formula><p>Given a predefined threshold ?, if r i &gt; ?, the sample (x i , y s i ) is identified as the reliably labeled for joint training, and otherwise the corresponding label is ignored. Through the reliable pseudo-labeling, a subset of reliable samples X r are selected as:</p><formula xml:id="formula_11">X r = {(x i , y s i )|r i &gt; ?, ? i = 1, 2, . . . , N }.<label>(7)</label></formula><p>Joint Training. Given the above partially labeled samples, the clustering problem can be converted into a semi-supervised learning paradigm to train the clustering network jointly. Here we adapt a simple semi-supervised learning method <ref type="bibr" target="#b54">[54]</ref>. During training, the subset of reliably labeled samples keep fixed. On the other hand, all training samples should be consistently clustered, i.e., different transformations of the same image are constrained to have the consistent prediction. To this end, as shown in <ref type="figure" target="#fig_3">Fig. 3(c)</ref>, the confidently predicted label of weak transformations is used as the pseudo-label for strong transformations of the same image. Formally, the consistency pseudo label y u j of the sample x j is calculated as in Eq. <ref type="formula" target="#formula_12">(8)</ref>:</p><formula xml:id="formula_12">y u j = arg max(p j ) if max(p j ) ? ?, ?1 otherwise<label>(8)</label></formula><p>where p j = C(F(?(x j ); ? F ); ? C )), and ? is the confidence threshold.</p><p>Then, the whole network parameters ? F and ? C are optimized with the following loss function:</p><formula xml:id="formula_13">L joint = 1 L L i=1 L ce (y s i , C(F(?(x i ); ? F ); ? C ))</formula><p>partial samples with reliable pseudo-labels (9)</p><formula xml:id="formula_14">+ 1 U U j=1 1(y u j ? 0)L ce (y u j , C(F(?(x j ); ? F ); ? C ))</formula><p>all samples with consistency pseudo-labels , where the first term is computed with reliably labeled samples (x i , y s i ) drawn from X r , and the second term is computed with pseudo-labeled samples (x i , y u i ) drawn from the whole dataset X, which is dynamically labeled by thresholding the confident predictions as in Eq. <ref type="bibr" target="#b7">(8)</ref>. L and U denote the numbers of labeled and unlabeled images in a mini-batch. Remark. Although we adapt the FixMatch <ref type="bibr" target="#b54">[54]</ref> semisupervised classification method for image clustering in this work, we highlight that other semi-supervised algorithms can also be used here with reliable samples generated by the proposed reliable pseudo-labeling algorithm.</p><p>Note that SPICE sheds light on the importance of utilizing both instance-level similarity and semantic level discrepancy for clustering. With this key idea in mind, this study focuses on developing the semantic pseudo-labeling algorithms that can actually estimate the instance similarity and semantic discrepancy for better clustering results. Actually, SPICE presents a general unsupervised clustering framework that gradually trains the feature model, clustering head, and whole model end-to-end. This framework is able to organically unify advanced unsupervised representation learning and semisupervised learning methods for clustering through the proposed semantic pseudo-labeling method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS AND RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Benchmark Datasets and Evaluation Metrics</head><p>We evaluated the performance of SPICE on six commonly used image clustering datasets, including STL10, CIFAR-10, CIFAR-100-20, ImageNet-10, ImageNet-Dog, and Tiny-ImageNet. The key details of each dataset are summarized in <ref type="table" target="#tab_3">Table I</ref>, where the datasets reflect a diversity of image sizes,  <ref type="bibr" target="#b57">[57]</ref>, Normalized Mutual Information (NMI) <ref type="bibr" target="#b58">[58]</ref>, and clustering Accuracy (ACC) <ref type="bibr" target="#b59">[59]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Implementation Details</head><p>For fair comparison, we mainly adopted two backbone networks, i.e. ResNet18 and ResNet34 <ref type="bibr" target="#b68">[68]</ref>, for representation learning. The classification head in SPICE consists of two fully-connected layers; i.e., D-D-K, where D and K are the dimension of features and the number of clusters, respectively. Specifically, D = 512 for both ResNet18 and ResNet34 backbone networks, and the cluster number K is predefined as the number of classes on the target dataset as shown in <ref type="table" target="#tab_3">Table I</ref>. To show how the joint training (third stage) improves the clustering performance, we refer to SPICE without joint training as SPICE s , where the subscript s indicates the separate training.</p><p>For representation learning, we use MoCo-v2 <ref type="bibr" target="#b43">[43]</ref> in all our experiments, which was also used in SCAN <ref type="bibr" target="#b0">[1]</ref>. For weak augmentation, a standard flip-and-shift augmentation strategy is implemented as in FixMatch <ref type="bibr" target="#b54">[54]</ref>. For strong augmentation, we adopt the same strategies used in SCAN <ref type="bibr" target="#b0">[1]</ref>. Specifically, the images were strongly augmented by composing Cutout <ref type="bibr" target="#b69">[69]</ref> and four randomly selected transformations from RandAugment <ref type="bibr" target="#b70">[70]</ref>.</p><p>In SPICE, we use 10 clustering heads, and select the best head with the minimum loss for the final head in each trial. To select the reliably labeled images in SPICE through reliable pseudo-labeling, we empirically set N s = 100 and ? = 0.95. The hyperparameters involved in FixMatch <ref type="bibr" target="#b54">[54]</ref> keep the same as those in the original paper, including ? = 0.95. We set the batch size M to 1,000.  <ref type="table" target="#tab_3">II  COMPARISON WITH COMPETING METHODS THAT WERE TRAINED AND TESTED ON THE WHOLE DATASET (TRAIN AND TEST SPLIT DATASETS ARE  MERGED AS ONE). NOTE THAT SPICE WAS TRAINED ON THE TARGET DATASETS ONLY WITHOUT USING EXTRA DATA AND WITHOUT USING ANY  ANNOTATIONS, WHICH ARE THE EXACTLY THE SAME AS DATA USED IN THE EXISTING METHODS. THE BEST RESULTS ARE HIGHLIGHTED IN BOLD.   Method  STL10  ImageNet-10  ImageNet-Dog-15  CIFAR-10  CIFAR-100-20  Tiny-ImageNet-200  ACC NMI ARI ACC NMI ARI ACC NMI ARI ACC NMI ARI ACC NMI ARI ACC NMI</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Clustering Performance Comparison</head><p>The existing methods can be divided into two groups according to their training and testing settings. One is to train and test the clustering model on the whole dataset combining the train and test splits as one. The other is to train and test the clustering model on the separate train and test datasets. For fair comparison, the proposed SPICE is evaluated under both two settings and compared with the existing methods accordingly. <ref type="table" target="#tab_3">Table II</ref> shows the comparison results of clustering on the whole dataset. In reference to the recently developed methods <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>, the same backbone, i.e. ResNet34, was used during learning the feature model and clustering head. Duplicating the original settings in FixMatch <ref type="bibr" target="#b54">[54]</ref>, we used WideResNet-28-2 for CIFAR-10, WideResNet-28-8 for CIFAR-100-20, and WideResNet-37-2 for STL-10. For ImageNet-10, ImageNet-Dog, and Tiny-ImageNet datasets that were not used in FixMatch, we simply used the same ResNet34 during joint learning. The results show that SPICE improves ACC, NMI, and ARI by 8.8%, 12.6%, and 14.4% respectively over the previous best results that were recently reported by CC <ref type="bibr" target="#b14">[15]</ref> on STL10. On average, our proposed method also improves ACC, NMI, and ARI by about 10% on ImageNet-Dog-15, CIFAR-10, CIFAR-100-20, and Tiny-ImageNet-200. It is worth emphasizing that, without the joint training stage, SPICE s still performs better than the exiting deep clustering methods using the same network architecture on the most of the datasets. These results convincingly show the superior performance of the proposed method using exactly the same backbone networks and datasets. The final joint training results are obviously better than those from the separate training on all datasets, especially on CIFAR-10 (improved by 8.8% for ACC) and CIFAR-100-20 (improved by 7.0% for ACC). In clustering the images in Tiny-ImageNet-200, although our results are significantly better than the existing results, while still very low. This is mainly due to the class hierarchies; i.e., some classes share the same supper class, as analyzed in <ref type="bibr" target="#b0">[1]</ref>. Due to the low performance, some clusters cannot be reliably labeled based on the reliable pseudo-labeling algorithm so that end-to-end training cannot be applied for further boosting clustering performance. Thus, it is still an open problem for clustering a large number of hierarchical clusters. <ref type="table" target="#tab_3">Table III</ref> shows the comparison results of clustering on the split train and test datasets. For fair comparison, we reimplement SCAN with MoCo <ref type="bibr" target="#b43">[43]</ref> for representation learning, denoted as SCAN MoCo . It can be seen that the results of SCAN MoCo on SLT10 are obviously better than SCAN, while the performance on CIFAR-10 and CIFAR-100-20 drops slightly. Compared with the baseline method SCAN MoCo , SPICE improves ACC, NMI, and ARI by 6.5%, 9.4%, and 11.5% on STL10, by 4.4%, 6.4%, and 8.0% on CIFAR-10, and by 8.0%, 9.3%, and 9.4% on CIFAR-100-20, under the exactly same setting. Without joint learning, SPICE s already </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>STL10 CIFAR-10 CIFAR-100-20 ACC NMI ARI ACC NMI ARI ACC NMI ARI ADC <ref type="bibr" target="#b71">[71]</ref> 0.530 N/A N/A 0.325 N/A N/A 0.160 N/A N/A TSUC <ref type="bibr" target="#b29">[29]</ref> 0.665 N/A N/A 0.810 N/A N/A 0.353 N/A N/A NNM <ref type="bibr" target="#b30">[30]</ref> 0.808 0.694 0.650 0.843 0.748 0.709 0.477 0.484 0.316 SCAN <ref type="bibr" target="#b0">[1]</ref> 0 performs better than SCAN MoCo that contains the pretraining, clustering, and finetuning stages on STL10 and CIFAR100-20. Moreover, we evaluate the SPICE using larger backbone networks as used in the whole dataset setting, the results on STL10 and CIFAR-10 are very similar while the results on CIFAR-100-20 are significantly improved. Remarkably, SPICE significantly reduces the gap between unsupervised and supervised classification. On the STL10 that includes both labeled and unlabeled images, the results of unsupervised methods are better than the supervised as the unsupervised methods can leverage the unlabeled images for representation learning while the supervised cannot. On CIFAR-10 and CIFAR-100-20, all methods using the same images for training and the proposed SPICE further reduces the performance gap compared with the supervised counterpart, particularly, only 2% for ACC gap on CIFAR-10. Table IV provides more detailed comparison results on STL10, where all these three methods use MoCo <ref type="bibr" target="#b43">[43]</ref> for representation learning and were conducted five times for computing the mean and standard deviation of the results. Compared with SCAN * MoCo that explores the instance similarity only without fine-tuning, SPICE s explicitly leverages both the instance similarity and semantic discrepancy for learning clusters. On the other hand, different from k-means that infers the cluster labels with cluster centers, SPICE s uses the nonlinear clustering head to predict the cluster labels. It can be seen that SPICE s is significantly better than MoCo+k-means and SCAN * MoCo in terms of both the mean and standard deviation metrics, demonstrating the superiority of the proposed prototype pseudo-labeling algorithm. Also, the final results of SPICE is significantly better than those of SCAN MoCo in terms of mean performance and the stability.</p><p>Overall, our comparative results systematically demonstrate the superiority of the proposed SPICE method on both the whole and split dataset settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Semi-Supervised Classification Comparison</head><p>In this subsection, we further compare SPICE with the recently proposed semi-supervised learning methods including ?-Model <ref type="bibr" target="#b28">[28]</ref>, Pseudo-Labeling <ref type="bibr" target="#b72">[72]</ref>, Mean Teacher <ref type="bibr" target="#b73">[73]</ref> Mix-Match <ref type="bibr" target="#b32">[32]</ref>, UDA <ref type="bibr" target="#b74">[74]</ref>, ReMinMatch <ref type="bibr" target="#b53">[53]</ref>, and FixMatch <ref type="bibr" target="#b54">[54]</ref>, as shown in <ref type="table" target="#tab_7">Table V</ref>. Here the semi-supervised learning methods use 250 and 1,000 samples with ground truth labels on CIFAR-10 and STL10, respectively. Here the semi-supervised learning results on the commonly used CIFAR-10 and STL10 datasets are from <ref type="bibr" target="#b54">[54]</ref>. SPICE uses the same backbone network in FixMatch for fair comparison and were conducted five times for reporting the mean and standard deviation results. It is found in our experiments that SPICE is comparable to and even better than these state-of-the-art semi-supervised learning methods. Actually, these results demonstrate that SPICE s with the reliable pseudo-labeling algorithm can accurately label a set of images without human interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Unsupervised Representation Learning</head><p>Here we aim to study the effects of the reliable pseudolabeling-based joint training in SPICE on representation features. As in all unsupervised representation learning methods <ref type="bibr" target="#b43">[43]</ref>, the quality of representation features is evaluated by training a linear classifier while freezing the learned feature model using the ground-truth labels. The results in <ref type="table" target="#tab_3">Table VI</ref> show that the quality of representation features on CIFAR-10 and STL10 is clearly improved after joint training, while keeping similar performance on CIAFR-100-20. The interpretation is that the feature improvement with joint learning requires very accurate pseudo-labels (the ACC of reliable labels on STL10 and CIFAR-10 are 97.7% and 96.5%), so that the improvement is not observed on CIFAR-100-20 (the ACC of reliable labels on CIFAR-100-20 is 67.7%). These results indicate that the proposed framework has the potential to improve the unsupervised representation learning by generating accurate and reliable pseudo-labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F. Empirical Analysis</head><p>In this subsection, we empirically analyze the effectiveness of different components and options in the proposed SPICE framework. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semi-supervised</head><p>Unsupervised ?-Model <ref type="bibr" target="#b28">[28]</ref> Pseudo-Labeling <ref type="bibr" target="#b72">[72]</ref> Mean Teacher <ref type="bibr" target="#b73">[73]</ref> MixMatch <ref type="bibr" target="#b32">[32]</ref> UDA <ref type="bibr" target="#b74">[74]</ref> ReMixMatch <ref type="bibr" target="#b53">[53]</ref> FixMatch <ref type="bibr">[</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(a) Nearest samples to prototypes (b) Attention maps of prototypes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) Visualization of cluster semantics:</head><p>We visualize the semantic clusters learned by SPICE s in terms of the prototype samples and the discriminative regions, as shown in <ref type="figure" target="#fig_8">Fig. 5</ref>. Specifically, <ref type="figure" target="#fig_8">Fig. 5(a)</ref> shows the top three nearest samples of the cluster centers representing the cluster prototypes, and in <ref type="figure" target="#fig_8">Fig. 5(b)</ref>, each cluster includes three samples and each sample is visualized with an original image and an attention map to highlight the discriminative regions. The attention maps of each cluster is computed by computing the cosine similarity between the cluster center (with Eqs. <ref type="bibr" target="#b1">(2)</ref> and <ref type="formula" target="#formula_6">(3)</ref>) of the whole dataset and the convolutional feature maps of individual images, and then resized and normalized into [0, 1]. It shows that the prototype samples exactly match the human annotations, and the discriminative regions focus on the semantic objects. For example, the cluster with label '1' captures the 'dog' class, and its most discriminative regions exactly capture the dogs at different locations, and similar results can be observed for all other clusters. The visual results indicate that semantically meaningful clusters are learned, and the cluster center vectors can extract the discriminative features. 2) Ablation study: We evaluate the effectiveness of different components of SPICE s in an ablation study, as shown in <ref type="table" target="#tab_3">Table VII</ref>. In each experiment, we replaced one component of SPICE s with another option, and five trials were conducted to report the mean and standard deviation for each metric.</p><p>We first evaluated the effectiveness of the overlap assignment and non-overlap assignment as described in Section III-B and <ref type="figure" target="#fig_4">Fig. 4</ref>. The results show that the overlap assignment is preferred over the non-overlap assignment, which may be explained by the fact that the non-overlap assignment may introduce extra local inconsistency when assigning the label to a sample far away from the cluster center, as shown in <ref type="figure" target="#fig_4">Fig. 4 (dashed red circle)</ref>.</p><p>During training SPICE s , we only optimize the clustering head while freezing the parameters of the feature model. To demonstrate the effectiveness of this separate training strategy, we compared it with two variants, i.e., jointly training the feature model and a single clustering head (Joint-SH) and jointly training the feature model and multiple clustering heads (Joint-MH). Note that the feature model in the first branch in <ref type="figure" target="#fig_3">Fig. 3(b)</ref> is still fixed for accurately measuring the similarity. The results show that the clustering performance for these two variants became significantly worse. On the one hand, the quality of pseudo labels not only depends on the similarity measurement but also the predictions of the clustering head. On the other hand, the performance of the clustering head is also determined by the quality of representation features. When tuning all parameters during training, the feature model tends to be degraded without accurate labels and the clustering head tends to output incorrect predictions in the initial stage, which will harm the pseudo-labeling quality and get trapped in a bad cycle.</p><p>Usually, maximizing the entropy over different clusters is the necessary to avoid assign all samples into a single or a few clusters, as demonstrated in GATCluster <ref type="bibr" target="#b13">[14]</ref>. Thus, we added another entropy loss during training, and the results were not changed. It indicates that our pseudo-labeling process with balance assignment has the ability to prevent trivial solutions. However, when clustering a large number of hierarchical clusters, e.g. 200 clusters in Tiny-ImageNet, the entropy loss was found necessary to avoid the empty clusters.</p><p>To evaluate the effectiveness of applying double softmax before CE, we replaced it with the plain CE or the CE with a temperature parameter (TCE) <ref type="bibr" target="#b75">[75]</ref>. For TCE, we evaluated different temperature values including 0.01, 0.05, 0.07, 0.1, 0.2, 0.5, 0.8, 2, and found 0.2 achieve the best results that were included for comparison. The results show that TCE is better than CE, which is consistent with the literature <ref type="bibr" target="#b43">[43]</ref>. On the other hand, the results of TCE are inferior to that with the double softmax CE. These experimental results are consistent with the detailed analysis in terms of the derivatives in Appendix A.</p><p>3) Clustering head selection: In unsupervised learning, the training process is hard to converge to the best state without the ground truth supervision, such that usually there is a large standard deviation among different trials. Thus, how to estimate the performance of models in the unsupervised training process to select the potential best model is very important. As introduced in Subsection III-B, we use the classification loss defined in Eq. (5) on the whole test dataset to approximate the classification performance; i.e., the smaller loss, the better clustering performance. The model selection process is shown in <ref type="figure" target="#fig_9">Fig. 6</ref>, it can be seen that the performance of the selected clustering head is very close to that of the ground truth selection, proving the effectiveness of this loss metric. In this way, the bad performance clustering heads can be filtered out. The results in <ref type="table" target="#tab_3">Table IV</ref> show that SPICE has a lower standard deviation compared with the competing methods. Importantly, the light-weight clustering heads can be independently and simultaneously trained without affecting each other and without extra training time. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Effect of reliable labeling:</head><p>In Section III-C, we introduced a reliable pseudo-labeling algorithm to select the reliably labeled images. Here we show the effectiveness of this algorithm in <ref type="figure" target="#fig_10">Fig. 7</ref>, where t-SNE was used to map the representation features of images in CIFAR-10 to 2D vectors for visualization. In <ref type="figure" target="#fig_10">Fig. 7(a)</ref>, some obvious semantically inconsistent samples are evident, and the predicted ACC of SPICE s on all samples is 83.8%. Using these samples directly for joint training, the ACC is not boosted. <ref type="figure" target="#fig_10">Fig. 7(b</ref>   <ref type="table" target="#tab_3">Table VIII</ref>, where Aug1 and Aug2 correspond to data augmentations of the second and the third branches in <ref type="figure" target="#fig_3">Fig. 3(b)</ref>. The results show that when the second branch used the weak augmentation and the third branch used the strong augmentation, the model achieved the best performance. Moreover, the model had relatively worse performance when the the second branch in labeling process uses the strong augmentation, which is due to that the labeling process aims to generate reliable pseudo labels that will be compromised by the strong augmentation. The model performs better when the third branch used the strong augmentation, as it will drive the model to output consistent predictions of different transformations. Overall, the data augmentation has a small impact on the results, because the pre-trained feature model had been already equipped with the transformation invariance ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. DISCUSSIONS</head><p>In this study, the SPICE network significantly improves the image clustering performance over the competing methods and reduces the performance gap between unsupervised and fully-supervised classification. However, there are opportunities for further refinements. First, existing deep clustering methods assume the clustering number K is known. In real applications, we do not always have such a prior. Therefore, how to automatically determine the number of semantically meaningful clusters is an open problem for deep clustering research. Second, to avoid trivial solutions, almost all existing clustering methods assume that the target dataset contains a similar number of samples in each and every cluster, which may or may not be the case in a real-world application. Usually, there are at least two constraints that can be applied to implement this prior, including maximizing the entropy <ref type="bibr" target="#b13">[14]</ref> and balancing assignment <ref type="bibr" target="#b72">[72]</ref> (and SPICE) that is an optimal solution for maximizing entropy. On the other hand, if we do have a prior distribution of samples as a function of the cluster index, the constraints for these methods can be adapted from the uniform distribution to a specific one. The ideal clustering method should work well when neither the number of clusters nor the prior distribution of samples per cluster is known, which is a holy grail in this field. Finally, although the SPICE method achieved the superior results over the existing methods, the progressive training process through the three stages is based on multiple algorithmic ingredients, and could be further unified in an elegant framework that optimizes weak and strong transforms as well, which is beyond the scope of this paper. Nevertheless, our method is both effective and efficient, and easy to optimize and apply, because each training stage only has a single cross-entropy function and is fairly straightforward. Importantly, SPICE is an exemplary workflow to synergize both the instance similarity and semantic discrepancy for superior image clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>VI. CONCLUSION</head><p>We have presented a semantic pseudo-labeling framework for image clustering, with the acronym "SPICE". To accurately measure both the similarity among samples and the discrepancy between clusters for clustering, we divide the clustering network into a feature model and a clustering head, which are first trained separately with the unsupervised representation learning algorithm and the prototype pseudo-labeling algorithm, and then jointly trained with the reliable pseudolabeling algorithm. Extensive experiments have demonstrated the superiority of SPICE over the competing methods on six public datasets with an average performance boost of 10% in terms of adjusted rand index, normalized mutual information, and clustering accuracy. The SPICE is comparable to or even better than the state-of-the-art semi-supervised learning methods and has the ability to improve the representation features. Remarkably, SPICE significantly reduces the gap between unsupervised and fully-supervised classification; e.g., only 2% gap on CIFAR-10. We believe the basic idea behind SPICE has the potential to help cluster other domain datasets, and apply to other learning tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENT</head><p>This work was supported in part by NIH/NCI under Award numbers R01CA237267, and in part by NIH/NHLBI under Award number R01HL151561.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A ANALYSIS OF THE DOUBLE SOFTMAX MECHANISM FOR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PSEUDO-LABELING-BASED IMAGE CLUSTERING</head><p>In this appendix, we give a detailed analysis on the double softmax mechanism for training clustering head based on the pseudo-labels. Considering that the pseudo-labels are not as accurate as the ground truth labels, the basic idea behind the double softmax implementation is to reduce the learning speed especially when the predictions are of low probabilities. Next, we show how the double softmax mechanism affects the gradients relative to the normal single softmax. Specifically, we denote the output score of the fully-connected layer as a = [a 1 , a 2 , . . . , a K ] T , where K represents the number of clusters. Then, the output of the first softmax function is where y k ? {0, 1} is the pseudo label, the derivative of crossentropy loss with respect to a k is:</p><p>? When we use the single softmax, the derivative of L(y, p) with respect to a k is ?L(y, p) ?a k = p k ? y k .</p><p>(A-4)</p><p>? When we use the double softmax composition, the derivative of L(y, p ) with respect to a k is</p><formula xml:id="formula_15">?L(y, p ) ?a k = K j=1 ?L(y, p ) ?p j ?p j ?a k = K j=1 (p j ? y j )p j (? jk ? p k ), (A-5)</formula><p>where ? jk = 1 if k = j, else ? jk = 0.</p><p>Then, we compute the ratio r k = ?L(y,p ) According to Eq. (A-11), we have r k ? p k ? p k as the second term is a constant for a specific prediction p, note that here the index k is the variable. Thus, the overall learning speed for the double softmax is adaptively reduced by a foctor of r k &lt; 1 compared with that for the normal single softmax. Importantly, when k = c, the learning speed for smaller p k is relatively slower than that for larger probabilities. In this way, the double softmax implementation will prevent the low probabilities from being too small after the optimization with current pseudo-labels, which will benefit the training process given imperfect pseudolabels. In another angle, the relatively larger learning speed for the false high probability will accelerate the sample changing between different clusters during training, which will benefit the dynamically searching process for good clusters.</p><p>The corresponding numerical simulation results are shown in <ref type="figure" target="#fig_0">Fig. A.1</ref>, where there are K = 8 clusters and the pseudolabel is c = 2. We can see that, except k = 2, the larger predicted probability p k corresponds to the relatively larger ratio r k . For k = 2, although p k is small, r k is relatively large as there is a big difference between the prediction and the pseudo-label. For the false high-probability, i.e. k = 5, r k is the largest among other ratios. These simulation results are consistent with the above analytical results.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Semantic relevance in the feature space. (a) Neighboring samples of different semantics, where the first image is the query image and the other images are nearest images with closest features provided by SCAN [1]. (b) Instance similarity without semantics, where each point denotes a sample in the feature space, and white lines indicate similar samples. (c) Semanticsaware similarity, where different colors denote different semantic clusters, stars denote cluster centers, the points within large circles are similar to the cluster centers, and the points with yellow circles are semantically inconsistent to neighbor samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Training framework of different deep clustering methods. (a) The initial deep clustering methods that combine traditional clustering algorithms with the deep neural networks, most of them combine with the autoencoders and some combine with an encoder only. (b)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 3 .</head><label>3</label><figDesc>Illustration of the SPICE framework. (a) Train the feature model with the contrastive learning based unsupervised representation learning. (b) Train the clustering head via the prototype pseudo-labeling algorithm in an EM framework. (c) Jointly train the feature model and the clustering head through the reliable pseudo-labeling algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>A toy example for prototype pseudo-labeling. First, given the predicted probabilities of 10 samples over 3 clusters, top 3 confident samples are selected for each cluster, marked as green, blue, and red colors respectively. Then, the selected samples are mapped into the corresponding features (denoted by dots) to estimating the prototypes (denoted by stars) for each cluster, where stars are estimated with connected dots. Finally, the top 3 nearest samples to each cluster prototype (the dots within the same ellipse) are selected and assigned with the index of the corresponding prototype. Other unselected samples are signed with -1 and will not be used for training. The dashed ellipse denotes non-overlap assignment.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Algorithm 1 : 4 E-step: 5 Select 6 ; 7 8 9 M-step: 10 13 t</head><label>14567891013</label><figDesc>Training Clustering Head.Input: Dataset X = {xi} N i=1 , ? s F , K, M , m, T , ?, ? Output: Cluster label y s i of xi ? X 1 Set feature model parameters to ? s F , t = 0, and initialize ? C ; 2 while t &lt; T do 3 for b = 1, 2, . . . , N M do M samples from X as X b ; Compute embedding features F = F (X b ; ? s F ) Predict probabilities P = C(F (?(X b ); ? s F ); ? C ) ;Construct labeled image set X s with Eqs. (2), (3), and (4) ;Compute probabilities P = C(F (?(X b ); ? s F ); ? C ) ;11 Optimize ? C by minimizing Eq. (5) ; 12 end ? t + 1 14 end 15 Select the best clustering head with the minimum loss as ? s C ; 16 foreach xi ? X do 17 pi = C(F (xi; ? s F ); ? s C ]) ; 18 y s i = arg max k (pi); 19 end</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>ARI k-means [56] 0.192 0.125 0.061 0.241 0.119 0.057 0.105 0.055 0.020 0.229 0.087 0.049 0.130 0.084 0.028 0.025 0.065 0.005 SC [60] 0.159 0.098 0.048 0.274 0.151 0.076 0.111 0.038 0.013 0.247 0.103 0.085 0.136 0.090 0.022 0.022 0.063 0.004 AC [61] 0.332 0.239 0.140 0.242 0.138 0.067 0.139 0.037 0.021 0.228 0.105 0.065 0.138 0.098 0.034 0.027 0.069 0.005 NMF [62] 0.180 0.096 0.046 0.230 0.132 0.065 0.118 0.044 0.016 0.190 0.081 0.034 0.118 0.079 0.026 0.029 0.072 0.005 AE [63] 0.303 0.250 0.161 0.317 0.210 0.152 0.185 0.104 0.073 0.314 0.239 0.169 0.165 0.100 0.048 0.041 0.131 0.007 SDAE [17] 0.302 0.224 0.152 0.304 0.206 0.138 0.190 0.104 0.078 0.297 0.251 0.163 0.151 0.111 0.046 0.039 0.127 0.007 DCGAN [64] 0.298 0.210 0.139 0.346 0.225 0.157 0.174 0.121 0.078 0.315 0.265 0.176 0.151 0.120 0.045 0.041 0.135 0.007 DeCNN [65] 0.299 0.227 0.162 0.313 0.186 0.142 0.175 0.098 0.073 0.282 0.240 0.174 0.133 0.092 0.038 0.035 0.111 0.006 VAE [66] 0.282 0.200 0.146 0.334 0.193 0.168 0.179 0.107 0.079 0.291 0.245 0.167 0.152 0.108 0.040 0.036 0.113 0.006 JULE [21] 0.277 0.182 0.164 0.300 0.175 0.138 0.138 0.054 0.028 0.272 0.192 0.138 0.137 0.103 0.033 0.033 0.102 0.006 DEC [2] 0.359 0.276 0.186 0.381 0.282 0.203 0.195 0.122 0.079 0.301 0.257 0.161 0.185 0.136 0.050 0.037 0.115 0.007 DAC [11] 0.470 0.366 0.257 0.527 0.394 0.302 0.275 0.219 0.111 0.522 0.396 0.306 0.238 0.185 0.088 0.066 0.190 0.017 DeepCluster [45] 0.334 N/A N/A N/A N/A N/A N/A N/A N/A 0.374 N/A N/A 0.189 N/A N/A N/A N/A N/A DDC [67] 0.489 0.371 0.267 0.577 0.433 0.345 N/A N/A N/A 0.524 0.424 0.329 N/A N/A N/A N/A N/A N/A IIC [12] 0.610 N/A N/A N/A N/A N/A N/A N/A N/A 0.617 N/A N/A 0.257 N/A N/A N/A N/A N/A DCCM [13] 0.482 0.376 0.262 0.710 0.608 0.555 0.383 0.321 0.182 0.623 0.496 0.408 0.327 0.285 0.173 0.108 0.224 0.038 DSEC [24] 0.482 0.403 0.286 0.674 0.583 0.522 0.264 0.236 0.124 0.478 0.438 0.340 0.255 0.212 0.110 0.066 0.190 0.017 GATCluster [14] 0.583 0.446 0.363 0.762 0.609 0.572 0.333 0.322 0.200 0.610 0.475 0.402 0.281 0.215 0.116 N/A N/A N/A PICA [25] 0.713 0.611 0.531 0.870 0.802 0.761 0.352 0.352 0.201 0.696 0.591 0.512 0.337 0.310 0.171 0.098 0.277 0.040 CC [15] 0.850 0.746 0.726 0.893 0.859 0.822 0.429 0.445 0.274 0.790 0.705 0.637 0.429 0.431 0.266 0.140 0.340 0.071 IDFD [16] 0.756 0.643 0.575 0.954 0.898 0.901 0.591 0.546 0.413 0.815 0.711 0.663 0.425 0.426 0.264 N/A N/A N/A SPICEs 0.908 0.817 0.812 0.921 0.828 0.836 0.646 0.572 0.479 0.838 0.734 0.705 0.468 0.448 0.294 0.305 0.449 0.161 SPICE 0.938 0.872 0.870 0.959 0.902 0.912 0.675 0.627 0.526 0.926 0.865 0.852 0.538 0.567 0.387 N/A N/A N/A</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>.809 0.698 0.646 0.883 0.797 0.772 0.507 0.486 0.333 RUC SCAN [31] 0.867 N/A N/A 0.903 N/A N/A 0.533 N/A N/A SCAN MoCo [1] 0.855 0.758 0.721 0.874 0.786 0.756 0.455 0.472 0.310 SPICE s 0.862 0.756 0.732 0.845 0.739 0.709 0.468 0.457 0.321 SPICE 0.920 0.852 0.836 0.918 0.850 0.836 0.535 0.565 0.404 SPICE Res34 0.929 0.860 0.853 0.917 0.858 0.836 0.584 0.583 0.422 Supervised 0.806 0.659 0.631 0.938 0.862 0.870 0.800 0.680 0.632</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 5 .</head><label>5</label><figDesc>Visualization of learned semantic clusters on STL10. (a) The top three nearest samples to the cluster centers. (b) The attention maps of cluster center on individual images.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 6 .</head><label>6</label><figDesc>Clustering head selection. Each curve represents the changing process of ACC v.s. epoch of a specific classification head. The blue squares mark the selected best classification head for each epoch, and the red stars represent the corresponding best head evaluated with the ground truth. The blue circle denotes the finally selected head. The red circle is the ground truth best head.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Fig. 7 .</head><label>7</label><figDesc>Visualization of reliable labels on CIFAR-10 dataset. Each point denotes a sample in the embedding space, different colors are rendered by the ground-truth labels. (a) The ACC of all samples is 0.838 and the ACC of the jointly trained model using all pseudo-labeled samples is also 0.838. (b) The ACC of the selected reliable labels is 0.959 and the ACC of the jointly trained model using the reliable samples is 0.926.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>? 1 (( 1 ?</head><label>11</label><figDesc>j ? y j )p j (? jk ? p k ) p k ? y k (A-6)During training, we know the pseudo cluster label is c, and y k = 1 if k = c, else y k = 0.? If k = c, we haver c = K j=1 (p j ? 1)p j (? jc ? p c ) p c p j )p j ? K j=1,j =c (1 ? p j )p j 1 ? p c (A-8) = (1 ? p c )p c + p c 1 ? p c K j=1,j =c (1 ? p j )p j . (A-9)According to Eqs. (A-8) (r c &lt; 1) and (A-9) (r c &gt; 0), we have r c ? (0, 1).? If k = c, then r k = K j=1 (p j ? 0)p j (? jk ? p k ) p k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>and G. wang are with Department of Biomedical Engineering, Center for Biotechnology and Interdisciplinary Studies, Rensselaer Polytechnic Institute, Troy, NY USA, 12180. E-mail: niuc@rpi.edu; wangg6@rpi.edu. H. Shan is with the Institute of Science and Technology for Brain-inspired Intelligence and MOE Frontiers Center for Brain Science, Fudan University, Shanghai 200433, China, and also with the Shanghai Center for Brain Science and Brain-Inspired Technology, Shanghai 201210, China. Email: hmshan@fudan.edu.cn.</figDesc><table /><note>Manuscript received xx xx, 2022; revised xx xx, 2022.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE I SPECIFICATIONS</head><label>I</label><figDesc>AND PARTITIONS OF SELECTED DATASETS.</figDesc><table><row><cell>Dataset</cell><cell>Image size</cell><cell cols="3"># Training # Testing # Classes (K)</cell></row><row><cell>STL10</cell><cell>96 ? 96</cell><cell>5,000</cell><cell>8,000</cell><cell>10</cell></row><row><cell>CIFAR-10</cell><cell>32 ? 32</cell><cell>50,000</cell><cell>10,000</cell><cell>10</cell></row><row><cell>CIFAR-100-20</cell><cell>32 ? 32</cell><cell>50,000</cell><cell>10,000</cell><cell>20</cell></row><row><cell>ImageNet-10</cell><cell>224 ? 224</cell><cell>13,000</cell><cell>N/A</cell><cell>10</cell></row><row><cell>ImageNet-Dog</cell><cell>224 ? 224</cell><cell>19,500</cell><cell>N/A</cell><cell>15</cell></row><row><cell>Tiny-ImageNet</cell><cell>64 ? 64</cell><cell>100,000</cell><cell>10,000</cell><cell>200</cell></row><row><cell cols="5">the number of images, and the number of clusters. Different</cell></row><row><cell cols="5">existing methods used different image sizes for training and</cell></row><row><cell cols="5">testing; for example, CC [15] resizes all images of these six</cell></row><row><cell cols="5">datasets into 224 ? 224, and GATCluster [14] studies the</cell></row><row><cell cols="5">effectiveness of different image sizes on ImageNet-10 and</cell></row></table><note>ImageNet-Dog, showing that too large or too small may harm the clustering performance. In this work, we naturally use the original size of images without resizing to a larger size of images. For the ImageNet, we adopt the commonly used image size of 224 ? 224. Three popular metrics are used to evaluate clustering re- sults, including Adjusted Rand Index (ARI)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE III COMPARISON</head><label>III</label><figDesc>WITH COMPETING METHODS ON SPLIT DATASETS (TRAINING AND TESTING IMAGES ARE MUTUALLY EXCLUSIVE). FOR FAIR COMPARISON, BOTH SCAN MOCO AND SPICE USED MOCO FOR FEATURE LEARNING, AND RESNET18 AS BACKBONE IN ALL TRAINING STAGES. HERE THE BEST RESULTS FOR ALL METHODS WERE USED FOR COMPARISON. SPICE RES34 USED THE RESNET34 AS BACKBONE. THE BEST TWO UNSUPERVISED RESULTS ARE HIGHLIGHTED IN BOLD.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE IV MORE</head><label>IV</label><figDesc>DETAILED COMPARISON RESULTS ON STL10. HERE ALL METHODS WERE TRAINED AND TESTED ON THE SPLIT TRAIN AND TEST DATASETS RESPECTIVELY. BOTH THE MEAN AND STANDARD DEVIATION RESULTS WERE REPORTED. EACH METHOD WAS CONDUCTED FIVE TIMES. HERE ALL METHODS USED THE RESNET18 BACKBONE, SCAN MOCO AND SPICE USED MOCO FOR FEATURE LEARNING WITH STL10 IMAGES ONLY. SCAN * MOCO MEANS NO SELF-LABELING.</figDesc><table><row><cell>Method</cell><cell>ACC</cell><cell>NMI</cell><cell>ARI</cell></row><row><cell>Supervised</cell><cell>0.806</cell><cell>0.659</cell><cell>0.631</cell></row><row><cell>MoCo+k-means</cell><cell>0.797?0.046</cell><cell>0.768?0.021</cell><cell>0.624?0.041</cell></row><row><cell>SCAN  *  MoCo</cell><cell>0.787?0.036</cell><cell>0.697?0.026</cell><cell>0.639?0.041</cell></row><row><cell>SCAN MoCo</cell><cell>0.797?0.034</cell><cell>0.701?0.032</cell><cell>0.649?0.044</cell></row><row><cell>SPICE s</cell><cell>0.852?0.011</cell><cell>0.749?0.008</cell><cell>0.719?0.015</cell></row><row><cell>SPICE</cell><cell>0.918?0.002</cell><cell>0.849?0.003</cell><cell>0.836?0.002</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE V COMPARISON</head><label>V</label><figDesc>RESULTS WITH SEMI-SUPERVISED LEARNING ON STL10 AND CIFAR-10. THE BEST THREE RESULTS ARE IN BOLD.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE VI FEATURE</head><label>VI</label><figDesc>QUALITY BEFORE AND AFTER JOINT TRAINING. THE FORMAT OF RESULTS FOR BEFORE JOINT TRAINING MEANS THE ACC OF supervised / unsupervised / reliable labels FOR AFTER JOINT TRAINING MEANS THE ACC OF supervised / unsupervised. THE SUPERVISED RESULTS WERE</figDesc><table><row><cell cols="4">OBTAINED BY TRAINING A LINEAR CLASSIFIER WHILE FIXING THE</cell></row><row><cell></cell><cell></cell><cell>FEATURE MODEL.</cell><cell></cell></row><row><cell>Method</cell><cell>STL-10</cell><cell>CIFAR-10</cell><cell>CIFAR-100-20</cell></row><row><cell cols="4">Before 0.908/0.862/0.977 0.893/0.845/0.965 0.729/0.468/0.677</cell></row><row><cell>After</cell><cell>0.938/0.920</cell><cell>0.922/0.918</cell><cell>0.723/0.535</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE VII ABLATION</head><label>VII</label><figDesc>STUDIES OF SPICEs ON THE WHOLE STL10 DATASET.</figDesc><table><row><cell>Variants</cell><cell>ACC</cell><cell>NMI</cell><cell>ARI</cell></row><row><cell>Non-overlap</cell><cell>0.885?0.002</cell><cell>0.788?0.003</cell><cell>0.771?0.003</cell></row><row><cell>Joint-SH</cell><cell>0.622?0.061</cell><cell>0.513?0.037</cell><cell>0.437?0.053</cell></row><row><cell>Joint-MH</cell><cell>0.687?0.037</cell><cell>0.577?0.029</cell><cell>0.512?0.033</cell></row><row><cell>Entropy</cell><cell>0.907?0.001</cell><cell>0.817?0.003</cell><cell>0.810?0.003</cell></row><row><cell>CE</cell><cell>0.875?0.031</cell><cell>0.784?0.017</cell><cell>0.764?0.033</cell></row><row><cell>TCE</cell><cell>0.895?0.005</cell><cell>0.794?0.010</cell><cell>0.787?0.010</cell></row><row><cell>SPICEs</cell><cell>0.908?0.001</cell><cell>0.817?0.002</cell><cell>0.812?0.002</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>) shows the selected reliable samples, where the ratio of local inconsistency samples is significantly decreased, and the ACC is increased to 95.9% correspondingly. Using the reliable samples for joint training, the ACC of SPICE after joint training is significantly boosted (92.6% v.s. 83.8%) compared with that of SPICE s .</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE VIII RESULTS</head><label>VIII</label><figDesc>OF SPICEs WITH DIFFERENT DATA AUGMENTATION STRATEGIES ON THE WHOLE STL10 DATASET, WHERE RESNET34 WAS USED AS BACKBONE, AND EACH VARIANT WAS CONDUCTED FIVE TIMES. We evaluated the effects of different data augmentations on SPICE s , as shown in</figDesc><table><row><cell>Aug1</cell><cell>Aug2</cell><cell>ACC</cell><cell>NMI</cell><cell>ARI</cell></row><row><cell>Weak</cell><cell>Weak</cell><cell>0.905?0.002</cell><cell>0.815?0.003</cell><cell>0.808?0.003</cell></row><row><cell>Strong</cell><cell>Weak</cell><cell>0.883?0.029</cell><cell>0.799?0.019</cell><cell>0.781?0.031</cell></row><row><cell>Strong</cell><cell>Strong</cell><cell>0.902?0.008</cell><cell>0.812?0.009</cell><cell>0.803?0.013</cell></row><row><cell>Weak</cell><cell>Strong</cell><cell>0.908?0.001</cell><cell>0.817?0.002</cell><cell>0.812?0.002</cell></row><row><cell cols="4">5) Effect of data augmentation:</cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">SCAN: Learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="268" to="285" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Unsupervised deep embedding for clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="478" to="487" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Discriminatively boosted image clustering with fully convolutional auto-encoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PR</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="page" from="161" to="173" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Towards k-meansfriendly spaces: Simultaneous deep learning and clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Sidiropoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICML</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="3861" to="3870" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">DeepCluster: A general clustering framework based on deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECML PKDD</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="809" to="825" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Selfsupervised convolutional subspace clustering network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-G</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Deep clustering via joint convolutional autoencoder embedding and relative entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">G</forename><surname>Dizaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herandi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5747" to="5756" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Variational deep embedding: An unsupervised and generative approach to clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="1965" to="1972" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Deep unsupervised clustering with Gaussian mixture variational autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dilokthanakul</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.02648</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Deep adversarial subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Deep adaptive image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5880" to="5888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Deep comprehensive correlation mining for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">GATCluster: Self-supervised Gaussian-attention network for image clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="735" to="751" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Contrastive clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Peng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Clustering-friendly representation learning via instance discrimination and feature decorrelation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tao</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMLR</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3371" to="3408" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep embedding network for clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1532" to="1537" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Unsupervised multi-manifold clustering by learning deep representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Workshops</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Deep subspace clustering networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Reid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Joint unsupervised learning of deep representations and image clusters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Batra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Agglomerative clustering using the concept of mutual nearest neighbourhood</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chidananda</forename><surname>Gowda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krishna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="112" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint image clustering and labeling by matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feyereisl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1411" to="1424" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Simulation results for double softmax mechanism</title>
	</analytic>
	<monogr>
		<title level="j">Fig. A</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep self-evolution clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="809" to="823" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Deep semantic clustering by partition confidence maximisation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep clustering: On the link between discriminative models and k-means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pedersoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mitiche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">B</forename><surname>Ayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1887" to="1896" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Unsupervised clustering using pseudo-semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sivathanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Semisupervised learning with ladder networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Mitigating embedding and class assignment mismatch in unsupervised image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="768" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Nearest neighbor matching for deep clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Improving unsupervised image clustering with robust learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">MixMatch: A holistic approach to semisupervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">DivideMix: Learning with noisy labels as semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Does label smoothing mitigate label noise?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lukasik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICML</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="6448" to="6458" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">icmsc: Incomplete cross-modal subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="305" to="317" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Pseudo-supervised deep subspace clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5252" to="5263" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Semi-supervised structured subspace learning for multi-view clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Joint learning of latent similarity and local embedding for multi-view clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="6772" to="6784" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Colorful image colorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">9907</biblScope>
			<biblScope unit="page" from="649" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Unsupervised representation learning by predicting image rotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent -a new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Grill</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="271" to="292" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">11218</biblScope>
			<biblScope unit="page" from="139" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Self-labelling via simultaneous clustering and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">M</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rupprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Sinkhorn distances: Lightspeed computation of optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cuturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Caron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Regularization with stochastic transformations and perturbations for deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sajjadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Javanmardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tasdizen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on Challenges in Representation Learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Semi-supervised learning by entropy minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grandvalet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">ReMixMatch: Semi-supervised learning with distribution matching and augmentation anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">FixMatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="596" to="608" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">Y</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5-th Berkeley Symposium on Mathematical Statistics and Probability</title>
		<imprint>
			<date type="published" when="1967" />
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Comparing partitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Arabie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of classification</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="193" to="218" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Cluster ensembles -a knowledge reuse framework for combining multiple partitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Strehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal on Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="583" to="617" />
			<date type="published" when="2002-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">The relationships among various nonnegative matrix factorization methods for clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H Q</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICDM</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="362" to="371" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page" from="849" to="856" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Fast agglomerative clustering using a k-nearest neighbor graph</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Franti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Virmajoki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Hautamaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1875" to="1881" />
			<date type="published" when="2006-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Locality preserving nonnegative matrix factorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCAI</title>
		<imprint>
			<biblScope unit="page" from="1010" to="1015" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Greedy layer-wise training of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Popovici</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Montreal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="153" to="160" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Unsupervised representation learning with deep convolutional generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Metz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Deconvolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Zeiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Deep discriminative clustering analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.01681</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Improved regularization of convolutional neural networks with cutout</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Devries</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Taylor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.04552</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">RandAugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="613" to="631" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Associative deep clustering: Training a classification network with no labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haeusser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Plapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Golkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Aljalbout</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="18" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Pseudo-Label : The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in ICML</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page" from="1195" to="1204" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Unsupervised data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="1904" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS Deep Learning and Representation Learning Workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
