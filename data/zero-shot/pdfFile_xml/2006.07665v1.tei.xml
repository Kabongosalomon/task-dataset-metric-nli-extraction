<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Uncertainty-aware Score Distribution Learning for Action Quality Assessment</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Tang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Lab of Intelligent Technologies and Systems</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zanlin</forename><surname>Ni</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahuan</forename><surname>Zhou</surname></persName>
							<email>jiahuanzhou2013@u.northwestern.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Electrical and Computer Engineering Department</orgName>
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danyang</forename><surname>Zhang</surname></persName>
							<email>zhang-dy16@mails.tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
							<email>lujiwen@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Lab of Intelligent Technologies and Systems</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Wu</surname></persName>
							<email>yingwu@eecs.northwestern.edu</email>
							<affiliation key="aff4">
								<orgName type="department">Electrical and Computer Engineering Department</orgName>
								<orgName type="institution">Northwestern University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
							<email>jzhou@tsinghua.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Automation</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">State Key Lab of Intelligent Technologies and Systems</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Beijing National Research Center for Information Science and Technology</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Tsinghua Shenzhen International Graduate School</orgName>
								<orgName type="institution">Tsinghua University</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Uncertainty-aware Score Distribution Learning for Action Quality Assessment</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T13:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Assessing action quality from videos has attracted growing attention in recent years. Most existing approaches usually tackle this problem based on regression algorithms, which ignore the intrinsic ambiguity in the score labels caused by multiple judges or their subjective appraisals. To address this issue, we propose an uncertainty-aware score distribution learning (USDL) approach for action quality assessment (AQA). Specifically, we regard an action as an instance associated with a score distribution, which describes the probability of different evaluated scores. Moreover, under the circumstance where fine-grained score labels are available (e.g., difficulty degree of an action or multiple scores from different judges), we further devise a multi-path uncertainty-aware score distributions learning (MUSDL) method to explore the disentangled components of a score. We conduct experiments on three AQA datasets containing various Olympic actions and surgical activities, where our approaches set new state-of-the-arts under the Spearman's Rank Correlation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Action quality assessment (AQA), aiming to evaluate how well a specific action is performed, has become an emerging and attractive research topic in computer vision community because of its potential value for various realwide applications such as sport video analysis <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22]</ref>, health care <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b42">43</ref>] and many others <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b43">44]</ref>. Compared with the conventional action recognition problem <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref> focusing on correctly classifying the action sequences from different categories, AQA is <ref type="bibr">Figure 1.</ref> We study the problem of action quality assessment in this paper. The bottom row shows a diving action in Olympic game, in which the final score is calculated based on multiple judges and the difficulty degree as 100.70 = (9.0 + 9.0 + 8.5) ? 3.8. In order to address the uncertainty during the assessment process, we utilize a Gaussian distribution to model the final score (top left) and multiple Gaussian distributions to model the scores from different judges (top right). All figures are best viewed in color. a more challenging task as it requires to deal with the videos from the same category with poor intra-class discriminant.</p><p>Over the past few years, there have been numbers of methods proposed for AQA <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref>. However, most of them simply regard AQA as a regression problem in order to directly predict the action scores. And unfortunately, their performances are indeed limited. The root of such a limitation is that this kind of treatment disregards for the underlying ambiguity of the action score labels, which is one of the key issues for AQA. Such ambiguity is caused by how the action labels are generated in practice. As an example shown in <ref type="figure">Figure 1</ref>, for the diving game, when the athlete finishes his action with the difficulty degree of 3.8, seven judges give their scores as {9.0, 8. <ref type="bibr">5, 9.0, 8.0, 9.0, 8.5, 9.</ref>0}. After eliminating the toptwo and bottom-two scores, the final score is calculated as: s f inal = (9.0 + 9.0 + 8.5) ? 3.8 = 100.70. This suggests the inherent uncertainty of the final score caused by different judges. Moreover, the subjective appraisal of each individual judge might also bring uncertainty into the final score. Besides the diving game, these phenomena exist in many other sports like gymnastic vaults, figure skiing, etc. The complicated score uncertainty makes an accurate AQA pretty difficult. Hence, it is desirable to design a robust model to deal with the uncertainty for AQA.</p><p>To address this, we propose an uncertainty-aware score distribution learning (USDL) method which utilizes a distribution of different scores as the supervisory signal rather than a single score. The adopted score distribution can depict the probability of the AQA score better so that the aforementioned uncertainty issue can be well handled. As illustrated by the top-left of <ref type="figure">Figure 1</ref>, we generate the ground-truth score distribution based on the widely used Gaussian function, of which the mean is set to be the score label. Meanwhile, an action video is fed into a 3D ConvNets to produce its predicted score distribution. Then we optimize the Kullback-Leibler divergence between the groundtruth score distribution and the predicted one. Recall <ref type="figure">Figure 1</ref>, once the fine-grained score labels are available (e.g., difficulty degree of an action or multiple scores from different judges), we further design a multi-path uncertaintyaware score distributions learning (MUSDL) method to fully explore these disentangled components of the final score. Strictly abided by the rule of the game, we fuse the multiple predicted scores to obtain the final score during inference. Through this objective process, we are able to obtain more accurate results. To our best knowledge, this is the original effort to leverage the finer-level score annotation for AQA problem. In order to verify the effectiveness of our approach, we conduct extensive experiments on the AQA-7 <ref type="bibr" target="#b16">[17]</ref>, MTL-AQA <ref type="bibr" target="#b18">[19]</ref> and JIGSAWS <ref type="bibr" target="#b7">[8]</ref> datasets. Experimental results show the superiority of our methods compared with the state-of-the-arts, and demonstrate the advantage of utilizing fine-grained labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Action Quality Assessment: In the past years, there have been a variety of works dedicated to different AQA tasks, such as health care <ref type="bibr" target="#b39">[40]</ref>, instructional video analysis <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref>, sport video analysis <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b21">22]</ref> and many others <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>. For example, Pirsiavash et al. <ref type="bibr" target="#b21">[22]</ref> explored this task firstly based on hand-crafted features on several specific actions, they took the first step to apply the learning approach on the underlying task and trained a linear SVR model to regress the score of the videos. Parmar et al. <ref type="bibr" target="#b17">[18]</ref> proposed C3D-SVR and C3D-LSTM to predict the score of the Olympic events. Additionally, incremental-label training method was introduced to train the LSTM model based on the hypothesis that the final score is an aggregation of the sequential sub-action scores. <ref type="bibr" target="#b16">[17]</ref> and <ref type="bibr" target="#b18">[19]</ref> aimed to improve the scoring performance and the generalization ability of the model simultaneously by exploring all-action models and multi-task learning respectively. Meanwhile, both of them released a new AQA dataset with a larger scale. Xu et al. <ref type="bibr" target="#b36">[37]</ref> designed two new LSTM-based models to learn the multi-scale information of the video. A little different from the works focusing on extracting the whole-scene features, Pan et al. <ref type="bibr" target="#b15">[16]</ref> presented a graph-based model to sufficiently exploit the athletes' pose information. Their approach well balanced the role of the movement of body parts and the coordination among different joints. Different from the aforementioned regression-based AQA methods, our proposed USDL method aims to predict the score distribution for the input action video instead of a single score number so that the severe score uncertainty which largely limits AQA performance can be well handled.</p><p>Label Distribution Learning: Label distribution learning (LDL) is a general learning paradigm, which describes an instance with distribution rather than the original single label or multiple labels. As a pioneering work, Geng et al. <ref type="bibr" target="#b10">[11]</ref> proposed an LDL framework for facial age estimation, which assigned an age distribution to each face image, and learned from such distribution with two algorithms called IIS-LLD (Improved Iterative Scaling-Learning from Label Distributions) and CPNN (Conditional Probability Neural Network). Motivated by the success of <ref type="bibr" target="#b10">[11]</ref> which was based on the hand-crafted features, the following ameliorated works have been proposed for LDL by leveraging the power of deep learning models such as deep convolutional neural network <ref type="bibr" target="#b6">[7]</ref> or LDL forest <ref type="bibr" target="#b24">[25]</ref>. In recent years, LDL has also shown its effectiveness for various computer vision tasks, including head pose estimation <ref type="bibr" target="#b9">[10]</ref>, beauty sensing <ref type="bibr" target="#b23">[24]</ref>, facial landmark detection <ref type="bibr" target="#b26">[27]</ref> and many others <ref type="bibr" target="#b35">[36,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b40">41]</ref>. For video analysis, Geng et al. <ref type="bibr" target="#b8">[9]</ref> proposed a soft grammar parsing method for video parsing, where the video segments are described by the degrees of different sub-action classes. Ling et al. <ref type="bibr" target="#b14">[15]</ref> utilized a mixture of Gaussian distribution to model the gradual change of crowd numbers in different video frames for indoor crowd counting. For our proposed method, by transferring the given single score label to a Gaussian-like score distribution for learning, we are able to directly estimate the score distribution of an action video that provides more accurate AQA results than only predicting a single score. <ref type="figure">Figure 2</ref>. Pipeline of our proposed method for uncertainty-aware score distribution learning. The input video frames are divided into N segments and fed into an I3D backbone to extract features. After passing three fully-connected layers, the obtained features are fused by temporal pooling and passed through softmax layer to generate the predicted distribution. Then we optimize the KL-Loss between the predicted distribution and a Gaussian distribution generated from the score label. dataset containing fine-grained action labels was proposed by <ref type="bibr" target="#b18">[19]</ref>. Besides the final score label of each sequence, the action class and commentary labels are also provided for the usage of multi-label learning. In this work, instead of using extra label information from other tasks, the individual score labels from all judges and the action difficulty label are utilized by our method for multi-label learning with the expectation of a better AQA performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">USDL</head><p>Pipeline Overview: For a given input video with L frames V = {F l } L l=1 , we utilize a sliding window to segment it into N overlapped clips where each clip contains M consecutive frames. The collected clips are further sent into a backbone of Inflated 3D ConvNets (I3D) <ref type="bibr" target="#b1">[2]</ref> followed by three fully connected layers, resulting in N features as {f 1 , f 2 , ...f N }. The weights of the fully connected layers are shared among different clips. As shown in <ref type="figure">Figure 2</ref>, to deal with the extracted features, a straightforward way adopted by the most existing AQA approaches is to fuse them by average pooling or max pooling, and regress it to a final score prediction. In this work, different from those methods, we utilize a USDL framework to deal with the intrinsic ambiguity in the AQA scores, which will be detailed as below. Score Distribution Generation: During the training phase, given a video associated with the labeled score s, we first generate a Gaussian function with the mean of s and standard deviation of ? as follow:</p><formula xml:id="formula_0">g(c) = 1 ? 2?? exp(? (c ? s) 2 2? 2 ).<label>(1)</label></formula><p>Here ? is a hyper-parameter which serves as the level of uncertainty for assessing an action. By uniformly discretizing the score interval into a set of scores c = [c 1 , c 2 , ..., c m ], a vector is utilized to describe the degree of each score as</p><formula xml:id="formula_1">g c = [g(c 1 ), g(c 2 ), ..., g(c m )]. The final score distribution label p c = [p(c 1 ), p(c 2 ), ..., p(c m )] is generated by normal- izing g c as below: p(c i ) = g(c i )/ m j=1 g(c j ), i = 1, 2, ..., m.</formula><p>(2)</p><p>Learning from Score Distribution: In order to learn from the obtained distribution p c , we map the N learned features</p><formula xml:id="formula_2">{f 1 , f 2 , ..., f N } into N predicted scores as {s 1 , s 2 , ..., s N },</formula><p>where s n has the same size with the p c . Then, the temporal average pooling is performed to {s n } N n=1 for an output vector s . After the softmax activation on s , we obtain the final predicted score as s pre = [s pre (c 1 ), s pre (c 2 ), ..., s pre (c m )]. Finally, the learning loss is calculated as the Kullback-Leibler (KL) divergence between s pre and p c :</p><formula xml:id="formula_3">KL{p c ||s pre } = m i=1 p(c i ) log p(c i ) s pre (c i ) .<label>(3)</label></formula><p>Inferring from Score Distribution: During the inferring stage, we forward the input testing video into our optimized model to obtain the corresponding predicted score distribution s pre . The final assessment is obtained by selecting the score with the max probability:</p><formula xml:id="formula_4">s f inal = arg max ci {s pre (c 1 ), s pre (c 2 ), ..., s pre (c m )}. (4)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">MUSDL</head><p>In most existing works on AQA, the network is designed and optimized based on the single score supervision. However, in many Olympic games (e.g., diving, figure skiing, etc.), the final score is calculated based on multiple scores from several judges according to a certain rule. Thanks to the recently released MTL-AQA dataset, the raw annotation of different judges and the difficulty degree are available as the intermediate components. In this subsection, we further introduce a multi-path architecture to leverage these intermediate components for AQA. Learning from Multi-path Score Distributions: As shown in <ref type="figure" target="#fig_0">Figure 3</ref>, for each single-path, we use the same pipeline as our USDL approach. The fully connected layers of different paths are separately trained while the I3D backbone is shared among paths. In the training phase, suppose we have a set of scores {s judge k } K k=1 from K different judges. We first sort the scores in increasing order in order to train the sub-networks representing judges of different rigor. Following Eqn (1), we generate K Gaussian distributions as {p judge c,k } K k=1 . Given a training video, we first feed it through the I3D backbone and obtained the N features as {f 1 , f 2 , ...f N }. The features are then fed into K sub-networks to obtain K final predicted distributions {s judge pre,k } K k=1 as follow:</p><formula xml:id="formula_5">s judge pre,k = ? k (f 1 , f 2 , ...f N ), k = 1, 2, ...K.<label>(5)</label></formula><p>Then the total training loss is calculated as:</p><formula xml:id="formula_6">J multi = K k=1 KL{p judge c,k ||s judge pre,k } (6) = K k=1 m i=1 p(c judge i,k ) log p(c judge i,k ) s judge pre,k (c judge i,k</formula><p>) .</p><p>Rule-based Multi-path Inference: During the inferring phase, we forward each testing video through our multi-path model and obtain K final predicted scores as {s judge f inal,k } K k=1 . According to the rule specific to the diving game, we can obtain the final score as:</p><formula xml:id="formula_7">s f inal = DD ? k ?U s judge f inal,k .<label>(7)</label></formula><p>Here U denotes a subset of {1, 2, .., K} (e.g., the diving game would discard the judges giving the top 2 and the last 2 scores), and DD denotes the difficulty degree of the input action video which will be released in advance. In fact, even the DD is not provided during inference time, we can still train a model to predict DD by introducing a side-network branch for it during training. The predicted DD is directly used for Eqn (7) during inference. We will report the results of these two cases (DD is available or unavailable during testing) in the Experiment Section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Datasets and Experiment Settings</head><p>AQA-7 <ref type="bibr" target="#b16">[17]</ref>: The AQA-7 dataset contains totally 1189 samples from 7 sports: 370 from single diving -10m platform, 176 from gymnastic vault, 175 from big air skiing, 206 from big air snowboarding, 88 from synchronous diving -3m springboard, 91 from synchronous diving -10m platform and 83 from trampoline. We followed the setting in <ref type="bibr" target="#b16">[17]</ref> and excluded the trampoline category in which the videos are much longer than those in the other categories <ref type="bibr" target="#b15">[16]</ref>. There were 803 clips for training and 303 clips for testing. MTL-AQA <ref type="bibr" target="#b18">[19]</ref>: The MTL-AQA dataset is the currently largest dataset for AQA. There are 1412 fine-grained samples collected from 16 different events with various views in MTL-AQA. This dataset covers the events of both individual &amp; synchronous divers, both male &amp; female athletes, both 3m springboard &amp; 10m platform settings. In this dataset, different kinds of annotations are provided to enable the study for different tasks consisting of action quality assessment, action recognition and commentary generation. Furthermore, the raw annotations of the scores from seven judges and the difficulty degree (DD) are available for each action. We followed the evaluation protocol suggested in <ref type="bibr" target="#b18">[19]</ref> to divide the dataset into a 1059-sized training set and a 353-sized test set.</p><p>JIGSAWS <ref type="bibr" target="#b7">[8]</ref>: Besides sport events, we further evaluate our methods on the JIGSAWS <ref type="bibr" target="#b7">[8]</ref> dataset which contains surgical activities. There are 3 tasks as "Suturing (S)", "Needle Passing (NP)" and "Knot Tying (KT)" in this dataset. Since each video is annotated with multiple annotation scores assessing different aspects of a video (e.g., flow of operation, quality of final product, etc.) and the final score is defined as the sum of these sub-scores, we could easily extend our MUSDL based on this rule. There are stereo samples recorded by left and right cameras in this dataset, and we only used the videos from the left view due to the high similarity between the paired captures. We adopt a similar four-fold cross validation <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b15">16]</ref>. Since the concrete splits are not public available for <ref type="bibr" target="#b15">[16]</ref>, and the splits in <ref type="bibr" target="#b2">[3]</ref> are specifically designed for pair-wise rank evaluation, which are not suitable for our work and <ref type="bibr" target="#b15">[16]</ref>, we simply divided the dataset into four folds randomly. Concretely, our splits are released at the project page. Evaluation Protocols: To keep alignment with existing literatures <ref type="bibr" target="#b15">[16]</ref>, we used Spearman's rank correlation (ranging from -1 to 1, the higher the better) to measure the performance of our methods between the ground-truth and predicted score series. Spearman's correlation is defined as:</p><formula xml:id="formula_8">? = i (p i ?p)(q i ?q) i (p i ?p) 2 i (q i ?q) 2 .<label>(8)</label></formula><p>Here p and q represent the ranking of two series respectively. Fisher's z-value <ref type="bibr" target="#b16">[17]</ref> is used to measure the average performance across actions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>Our proposed methods were built on the Pytorch toolbox <ref type="bibr" target="#b19">[20]</ref> and implemented on a system with the Intel(R) Xeon(R) E5-2660 v4 CPU @ 2.00Ghz. We trained our model with two Nvidia GTX 1080 Ti GPUs. We utilized the I3D model pretrained on Kinetics dataset as a feature extractor. It took action sequences containing 16 frames as inputs and output a feature with 1024 dimensions. In AQA-7 and MTL-AQA, the videos are all 103 frames long. We divided each video into ten segments under a certain rule 2 . The MLP block, containing two hidden layers F C(256, ReLU ) and F C(128, ReLU ), together with temporal pooling layer and softmax layer, built the score distribution for each video. We performed temporal pooling at feature-level on MTL-AQA and JIGSAWS for better results. Adam <ref type="bibr" target="#b13">[14]</ref> was adopted for network optimization. In our experiments, we normalized the final total score in both datasets and seven judge scores in MTL-AQA. For the final total score, since it was a float number, we normalized it as: Here S max and S min indicate the maximum and minimum score in the dataset. For judge scores in MTL-AQA dataset, since these scores are inherently discrete but not an integer, so we normalized them by doubling the value of original score to get an integer. After generating normalized score S normalized , we produced a Gaussian function with a mean of S normalized . Note that the produced Gaussian is defined within x ? (??, ?) in first. In practice, we truncated this initial distribution by the score range, and then discretized and renormalized this distribution function as described in Section 3.1.</p><formula xml:id="formula_9">S normalize = S ? S min S max ? S min ? 100.<label>(9)</label></formula><p>We report the performance of the following baseline methods and different versions of our approach. Note that some of them are not evaluated on the AQA-7 dataset due to the absense of multiple scores.</p><p>? Regression: Most existing works adopted this strategy.</p><p>We modified the dimension of the last fc layer in our USDL to produce a single prediction score. During the training phase, we optimized the L2 loss between predicted score and ground-truth score.</p><p>? USDL: The proposed method in Section 3.1.</p><p>? MUSDL and MUSDL * : The proposed methods in Section 3.2, which used the ground-truth and the prediction of difficulty degree during testing respectively.</p><p>? USDL DD : During the training phase, we used scores from seven judges. According to the scoring rules of diving, the top-two and bottom-two scores will be eliminated. We summed the remaining three judge scores to obtain a new score label, and applied USDL to learn this new label. In the inference period, we multiply the predicted score with the ground-truth of difficulty degree DD to generate the final result. <ref type="table">Table 1</ref> shows the experiment results of our methods and the comparison with other AQA approaches. The simple yet effective regression model achieves competitive performance compared with the state-of-the-art C3D-LSTM, C3D-SVR and JRG models. The proposed USDL approach obtains significant improvement for all action classes except Sync. 10m compared to the JRG model, which also utilizes optical flow. The average correlation of our USDL approach gains improvement of 6.3% and 2.5% compared to our baseline regression model and the JRG model respectively. It is also noticed that in action class Snowboard, our proposed model surpasses state-of-the-art models by a large margin about 17%, showing the strong effectiveness of the USDL approach in AQA problems. Study on Different Distributions: We conduct 3 parallel experiments with only the type of distribution changed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on AQA-7 Dataset</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prediction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Groundtruth</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>High</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Low Final Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Olympic Game: Gym_Vault</head><p>Video ID: 042</p><p>x y z <ref type="figure">Figure 4</ref>. Score distribution change in temporal domain. The x, y, z axis represents clip number, score and probability predicted for the certain score. The 7th, 8th clips are highlighted because the athlete fell to the ground, which leads to two salient low score prediction. The ? 2 distribution is generated where the mean s equals to normalized score and degree of freedom equals to onetwentieth of score range. The triangle distribution is symmetric with maximum probability at normalized score. The Gaussian distribution follows the implementation in Section 4.2. And all of the distributions are truncated discretized and renormalized to fit the range of scores. As shown in <ref type="table">Table 2</ref>, Gaussian distribution achieves the highest average correlation while the triangle distribution performs worst. However, note that there is not a distribution that performs best in all action classes. For example, triangle distribution performs best in Diving class and ? 2 distribution performs best in Gym Vault class, while the Gaussian distribution performs best in an average sense. This indicates that the ground-truth score distribution may be complicated and vary a lot among different action classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Visualization of Temporal Evolution:</head><p>We choose a video in Gym Vault class to visualize the temporal evolution of score distribution in <ref type="figure">Figure 4</ref>. We obtain the score distributions of 10 clips and plot them on the graph. The video has a low ground-truth score and network gives a low score prediction. From the temporal evolution of score distribution we can see how the network gives that prediction-in the 7th and the 8th segments, the athlete fell to the ground, leading to two salient low-score prediction. The two distributions thus dominate in the final distribution, and the network finally gives the low score distribution, as expected. See supplementary material for more visualization results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results on MTL-AQA Dataset</head><p>Our method is compared with several state-of-the-arts on MTL-AQA dataset in <ref type="table" target="#tab_2">Table 3</ref>. Still, our regression model  Pose+DCT <ref type="bibr" target="#b21">[22]</ref> 0.2682 C3D-SVR <ref type="bibr" target="#b17">[18]</ref> 0.7716 C3D-LSTM <ref type="bibr" target="#b17">[18]</ref> 0.8489 MSCADC-STL <ref type="bibr" target="#b18">[19]</ref> 0.8472 C3D-AVG-STL <ref type="bibr" target="#b18">[19]</ref> 0.8960 MSCADC-MTL <ref type="bibr" target="#b18">[19]</ref> 0.8612 C3D-AVG-MTL <ref type="bibr" target="#b18">[19]</ref> 0.9044 Ours-Regression 0.8905 Ours-MUSDL 0.9273  <ref type="table" target="#tab_3">Table 4</ref>. The vanilla regression and USDL methods do not exploit the information from DD nor the judge scores. The architecture of USDL DD network is the same as USDL, but the distribution label is generated from multiple judge scores. The final prediction is obtained by combining DD and predicted judge scores, which is the same as MUSDL method. The MUSDL* method adds an Error Threshold ? Cumulative Score (%) <ref type="figure">Figure 6</ref>. Cumulative score curve in MTL-AQA dataset, in which x-axis measures the absolute difference between predition and label and y-axis shows the proportion of the sample within the current error level. The methods using DD outperform baseline methods significantly, and the MUSDL method performs better than other methods using DD by a little margin.</p><p>additional branch to the previous MUSDL method to perform a multi-task learning, i.e., training the network to predict scores from seven judges and DD at the same time.</p><p>In inference stage, we combine the judge scores and DD predicted from network to obtain the final score. From the results we see that the USDL DD outperforms the USDL by 1.7%, indicating that DD is a significant factor in diving score assessment. We believe the reason why using DD can promote better performance is that it "disentangles" the problem, making the main pipeline more specialized in video quality assessment. The MUSDL outperforms the single path method by 0.4%, which shows the fine-grained scores can further improve the performance of network. Visualization: We first evaluate the methods in ablation study using cumulative score (CS) curves as shown in <ref type="figure">Figure 6</ref>. The cumulative prediction accuracy at the error is computed as CS(?) = N ?? N ? 100%. Here N ?? is the number of videos on which the prediction error is not larger than the threshold ?. The figure shows the strong  effectiveness of using DD for learning better distributions. Then we choose the Regression, USDL and MUSDL methods and plot the scatter diagram to make a further comparison, as shown in <ref type="figure" target="#fig_1">Figure 5</ref>. The predicted scores are plotted in scatter points and the ground-truth scores are plotted in dotted line. From the results, we can see that the proposed MUSDL obtains a very satisfactory performance since the predicted points converge well to the ground-truth line.</p><p>We also conduct a case study to analyze the behavior of our network, as shown in <ref type="figure" target="#fig_2">Figure 7</ref>. The first case is a successful case where the final score predicted by MUSDL fully matches with ground-truth, and final score predicted by MUSDL* network is a little higher than ground-truth. The second case is a failure case, with the ground-truth label of the video being zero. This time both of our MUSDL network and MUSDL* network give the score far higher than the ground-truth label. The results indicate that when assessing videos with extreme scores, i.e., too far from the normal score level, the proposed method may not be able to get satisfactory results. This is because the samples with extreme scores are scarce and also because the intrinsic property of our method makes it harder to give extreme results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Results on the JIGSAWS dataset</head><p>We finally conduct experiments on the JIGSAWS dataset for surgical activities. Because the lengths of each videos are much longer that those in AQA-7 and MTL-AQA datasets, we uniformly sampled 160 frames of each videos and divided them into 10 segments as the inputs of our models. <ref type="table" target="#tab_4">Table 5</ref> presents the results of our methods compared with the state-of-the-arts. Our MUSDL achieves best performance of 0.71 (S), 0.69 (NP), 0.70 (Avg. Corr.) and comparable result of 0.71 (KT), which demostrates its effectiveness for action quality assessment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this paper, we have proposed a new uncertainty-aware score distribution learning (USDL) method for action quality assessment, which aims to address the inherent ambiguity in the score label. Moreover, we have devised a multipath uncertainty-aware score distribution (MUSDL) framework to take advantage of additional fine-grained score labels. The experiments on three AQA datasets have demonstrated the effectiveness of our approach. In the future, we plan to apply our methods for instructional video analysis <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b29">30]</ref>. Besides, it is an interesting direction to explore the interpretability of AQA models (e.g., understanding how the network gains the score for a certain action), which is virtually important for real-world applications.   During our experiments, we explored three strategies to divide the videos into multiple segments. <ref type="table" target="#tab_5">Table 6</ref> presents the results on the Diving action of the AQA-7 dataset <ref type="bibr" target="#b16">[17]</ref>, where the length of each video clip is 103 frames. Specifically, "6-seg" denotes the scheme used in <ref type="bibr" target="#b18">[19]</ref>, which first normalized the video into 96 frames, and then divided them into 6 segments where each clip contained 16 frames 3 . In fact, as pointed in the recent work <ref type="bibr" target="#b15">[16]</ref>, 10 is more proper for the number of segments. Based on this, we further studied two schemes. The first used [0, <ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr">50,</ref><ref type="bibr">60,</ref><ref type="bibr">70,</ref><ref type="bibr">80,</ref><ref type="bibr">87]</ref> as the indices of beginning frames for the ten segments (denoted as "10-seg-s1"). Since 103/10 = 10.3, we set the stride to be 10 in most cases. And the last beginning index was set to be 87 due to the length of the video is 103 frames. The second scheme utilized [0, <ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr">48,</ref><ref type="bibr">58,</ref><ref type="bibr">67,</ref><ref type="bibr">77,</ref><ref type="bibr">87]</ref> as the in-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Acknowledgement</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 .</head><label>3</label><figDesc>Multi-path uncertainty-aware score distributions learning. During the training phase, we model the scores from K judges as different Gaussian distributions and utilize a similar strategy to train the model containing K sub-networks. During the testing phase, we obtain the final assessment based on the K predicted scores and the rule of the game.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 5 .</head><label>5</label><figDesc>A comparison of different methods in scatter plot. The plotting points are the predictions of network with y-coordinates being the predicted scores and x-coordinates being the ground-truth scores. The ground-truth samples are plotted in dotted line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 7 .</head><label>7</label><figDesc>Case study with qualitative results, which present the comparisons of MUSDL, MUSDL* and ground-truth.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>This work was supported in part by the National Key Research and Development Program of China under Grant 2017YFA0700802, in part by the National Natural Science Foundation of China under Grant 61822603, Grant U1813218, Grant U1713214, and Grant 61672306, in part by the Shenzhen Fundamental Research Fund (Subject Arrangement) under Grant JCYJ20170412170602564, in part by Tsinghua University Initiative Scientific Research Program, in part by National Science Foundation grant IIS-1619078, IIS-1815561, and in part by the Army Research Office ARO W911NF-16-1-0138. The authors would sincerely thank Xumin Yu, Wanhua Li, Jia-Hui Pan and Paritosh Parmar for their generous helps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 8 .</head><label>8</label><figDesc>Evolution of the score distributions in temporal domain. The x, y, z axis represents clip number, score and probability predicted for the certain score. The two samples are selected from the Diving action in AQA-7<ref type="bibr" target="#b16">[17]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .Table 2 .</head><label>12</label><figDesc>Comparisons of action quality assessment accuracy on the AQA-7 dataset. Diving Gym Vault Skiing Snowboard Sync. 3m Sync. 10m Avg. Corr. Study on different distributions. We use USDL approach with only the type of soft distribution changed. Diving Gym Vault Skiing Snowboard Sync. 3m Sync. 10m Avg. Corr.</figDesc><table><row><cell>Pose+DCT [22]</cell><cell>0.5300</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>ST-GCN [38]</cell><cell>0.3286</cell><cell>0.5770</cell><cell>0.1681</cell><cell>0.1234</cell><cell>0.6600</cell><cell>0.6483</cell><cell>0.4433</cell></row><row><cell cols="2">C3D-LSTM [18] 0.6047</cell><cell>0.5636</cell><cell>0.4593</cell><cell>0.5029</cell><cell>0.7912</cell><cell>0.6927</cell><cell>0.6165</cell></row><row><cell>C3D-SVR [18]</cell><cell>0.7902</cell><cell>0.6824</cell><cell>0.5209</cell><cell>0.4006</cell><cell>0.5937</cell><cell>0.9120</cell><cell>0.6937</cell></row><row><cell>JRG [16]</cell><cell>0.7630</cell><cell>0.7358</cell><cell>0.6006</cell><cell>0.5405</cell><cell>0.9013</cell><cell>0.9254</cell><cell>0.7849</cell></row><row><cell cols="2">Ours-Regression 0.7438</cell><cell>0.7342</cell><cell>0.5190</cell><cell>0.5103</cell><cell>0.8915</cell><cell>0.8703</cell><cell>0.7472</cell></row><row><cell>Ours-USDL</cell><cell>0.8099</cell><cell>0.7570</cell><cell>0.6538</cell><cell>0.7109</cell><cell>0.9166</cell><cell>0.8878</cell><cell>0.8102</cell></row><row><cell>? 2 Distribution</cell><cell>0.7920</cell><cell>0.7697</cell><cell>0.6532</cell><cell>0.6905</cell><cell>0.9041</cell><cell>0.8847</cell><cell>0.8015</cell></row><row><cell>Triangle Distribution</cell><cell>0.8147</cell><cell>0.7452</cell><cell>0.5960</cell><cell>0.6555</cell><cell>0.8987</cell><cell>0.9054</cell><cell>0.7969</cell></row><row><cell cols="2">Gaussian Distribution 0.8099</cell><cell>0.7570</cell><cell>0.6538</cell><cell>0.7109</cell><cell>0.9166</cell><cell>0.8878</cell><cell>0.8102</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Comparisons of performance with existing methods on the MTL-AQA dataset.</figDesc><table><row><cell>Method</cell><cell>Sp. Corr.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Ablation study on the MTL-AQA dataset. For MUSDL * , * denote that DD is only available during the training phase, but unavailable during testing phase.</figDesc><table><row><cell>Method</cell><cell>Soft DD</cell><cell>Judges</cell><cell>Sp. Corr.</cell></row><row><cell>Regression</cell><cell></cell><cell></cell><cell>0.8905</cell></row><row><cell>USDL</cell><cell></cell><cell></cell><cell>0.9066</cell></row><row><cell>USDLDD</cell><cell></cell><cell>single</cell><cell>0.9231</cell></row><row><cell>MUSDL  *</cell><cell cols="2">*  multiple</cell><cell>0.9158</cell></row><row><cell>MUSDL</cell><cell></cell><cell>multiple</cell><cell>0.9273</cell></row><row><cell cols="4">obtains a competitive result compared with the state-of-the-</cell></row><row><cell cols="4">arts and our MUSDL model outperforms all the other ap-</cell></row><row><cell cols="4">proaches listed out. These experiment results convincingly</cell></row><row><cell cols="4">illustrate the effectiveness of our method. It is believed that</cell></row><row><cell cols="4">embedding the MUSDL method into a regression model is</cell></row><row><cell cols="3">able to boost the assessment accuracy.</cell><cell></cell></row><row><cell cols="4">Ablation Study: We compare our final method with 4 other</cell></row><row><cell cols="2">methods as shown in</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Comparisons of action quality assessment accuracy on the JIGSAWS dataset.</figDesc><table><row><cell>Method</cell><cell>S</cell><cell>NP</cell><cell>KT</cell><cell>Avg. Corr.</cell></row><row><cell cols="4">ST-GCN [16, 38] 0.31 0.39 0.58</cell><cell>0.43</cell></row><row><cell>TSN [16, 35]</cell><cell cols="3">0.34 0.23 0.72</cell><cell>0.46</cell></row><row><cell>JRG [16]</cell><cell cols="3">0.36 0.54 0.75</cell><cell>0.57</cell></row><row><cell>Ours-USDL</cell><cell cols="3">0.64 0.63 0.61</cell><cell>0.63</cell></row><row><cell>Ours-MUSDL</cell><cell cols="3">0.71 0.69 0.71</cell><cell>0.70</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>Comparisons of different strategies to segment on the Diving action of AQA-7<ref type="bibr" target="#b16">[17]</ref>.</figDesc><table><row><cell>Method</cell><cell cols="3">6-seg [19] 10-seg-s1 10-seg-s2</cell></row><row><cell>Sp. Corr.</cell><cell>0.7642</cell><cell>0.8099</cell><cell>0.7928</cell></row><row><cell cols="4">Appendix A. Different Strategies for Segment-</cell></row><row><cell></cell><cell>ing Videos</cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Multi-Label Learning: Multi-label learning<ref type="bibr" target="#b32">[33]</ref> is increasingly required by more and more computer vision applications including AQA. Recently, A novel MTL-AQA</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We used I3D model<ref type="bibr" target="#b1">[2]</ref> as the backbone. It took 16 frames as inputs. dices of beginning frames (denoted as "10-seg-s2"). As shown from the results, "10-seg-s1" achieves best result among the three. Hence, we applied this scheme to the other actions in AQA-7 and MTL-AQA datasets in our paper.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Visualization of Temporal Evolution</head><p>In Section 4.3, we present a visualization result on the Gym_Vault action <ref type="bibr" target="#b16">[17]</ref>. Here we further display two visualization results on the Diving action <ref type="bibr" target="#b16">[17]</ref> in <ref type="figure">Figure 8</ref>. As it illustrates, the stage that the player enters the water plays a prominent part for action quality assessment. For example, in the bottom instance, the player causes a large splash from the 8th segment to the 10th segment. Hence, for these segments, the distributions reach the peak at the low-level scores.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Am I a baller? basketball performance assessment from first-person videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gedas</forename><surname>Bertasius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyun</forename><forename type="middle">Soo</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2196" to="2204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Quo vadis, action recognition? A new model and the kinetics dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4724" to="4733" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Who&apos;s better? who&apos;s best? pairwise deep ranking for skill determination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hazel</forename><surname>Doughty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dima</forename><surname>Damen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Walterio</forename><forename type="middle">W</forename><surname>Mayol-Cuevas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6057" to="6066" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The pros and cons: Rank-aware temporal attention for skill determination in long videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hazel</forename><surname>Doughty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Walterio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dima</forename><surname>Mayol-Cuevas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Damen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7862" to="7871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Evaluating surgical skills from kinematic data using convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hassan</forename><surname>Ismail Fawaz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Germain</forename><surname>Forestier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lhassane</forename><surname>Idoumghar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Alain</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="214" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Slowfast networks for video recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6201" to="6210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep label distribution learning with label ambiguity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bin-Bin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Wei</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2825" to="2838" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Jhu-isi gesture and skill assessment working set (jigsaws): A surgical activity dataset for human motion modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixin</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Swaroop</forename><surname>Vedula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carol</forename><forename type="middle">E</forename><surname>Reiley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narges</forename><surname>Ahmidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Balakrishnan</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lingling</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjam?n</forename><surname>Zappella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>B?jar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yuh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MICCAI Workshop: M2CAI</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Soft video parsing by label distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miaogen</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1331" to="1337" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Head pose estimation based on multivariate label distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1837" to="1842" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Facial age estimation by learning from label distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hua</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2401" to="2412" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Automated video assessment of human performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Andrew S Gordon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of AI-ED</title>
		<meeting>AI-ED</meeting>
		<imprint>
			<date type="published" when="1995" />
			<biblScope unit="page" from="16" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Trajectory based assessment of coordinated human activity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marko</forename><surname>Jug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janez</forename><surname>Per?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Branko</forename><surname>De?man</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Kova?i?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Computer Vision Systems</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003" />
			<biblScope unit="page" from="534" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Science</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Indoor crowd counting by mixture of gaussians label distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miaogen</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="page" from="5691" to="5701" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Action assessment by joint relation graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jibin</forename><surname>Jia-Hui Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Shi</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6330" to="6339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Action quality assessment across multiple actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paritosh</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1468" to="1476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning to score olympic events</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paritosh</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><forename type="middle">Tran</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPRW</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="76" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">What and how well you performed? A multitask learning approach to action quality assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paritosh</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brendan</forename><forename type="middle">Tran</forename><surname>Morris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="304" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pytorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>NIPSW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Automatic evaluation of organized basketball activity using bayesian networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Per?e</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janez</forename><surname>Per?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislav</forename><surname>Kova?i?</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Assessing the quality of actions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hamed</forename><surname>Pirsiavash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="556" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A survey on vision-based human action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald</forename><surname>Poppe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Vision Comput</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="976" to="990" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sense beauty by label distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IJCAI</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2648" to="2654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Label distribution learning forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="834" to="843" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Two-stream convolutional networks for action recognition in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="568" to="576" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Soft facial landmark detection by label distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5008" to="5015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">COIN: A large-scale dataset for comprehensive instructional video analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dajun</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongming</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lili</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1207" to="1216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning semantics-preserving attention and contextual interaction for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zian</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TIP</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4997" to="5012" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Comprehensive instructional video analysis: The COIN dataset and performance evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep progressive reinforcement learning for skeleton-based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yansong</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5323" to="5332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning spatiotemporal features with 3d convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Du</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lubomir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manohar</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Paluri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4489" to="4497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Multi-label classification: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grigorios</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Katakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Data Warehousing and Mining (IJDWM)</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Action recognition by dense trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kl?ser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng-Lin</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="3169" to="3176" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Temporal segment networks: Towards good practices for deep action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Limin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="20" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Logistic boosting regression for label distribution learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="4489" to="4497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning to score figure skating sport videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TCSVT</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Spatial temporal graph convolutional networks for skeleton-based action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7444" to="7452" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Sparsity conditional energy label distribution learning for age estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Zhou</surname></persName>
		</author>
		<editor>IJ-CAI</editor>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2259" to="2265" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Relative hidden markov models for video-based evaluation of motion skills in surgical training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoxin</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>TPAMI</publisher>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1206" to="1218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Emotion distribution recognition from facial expressions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Geng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">MM</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1247" to="1250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Automated surgical skill assessment in RMIS training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aneeq</forename><surname>Zia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irfan</forename><forename type="middle">A</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="731" to="739" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Video and accelerometer-based motion analysis for automated surgical skills assessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aneeq</forename><surname>Zia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yachna</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinay</forename><surname>Bettadapura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">L</forename><surname>Sarin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irfan</forename><forename type="middle">A</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="455" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Automated video-based assessment of surgical skills for training and evaluation in medical schools</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aneeq</forename><surname>Zia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yachna</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vinay</forename><surname>Bettadapura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><forename type="middle">L</forename><surname>Sarin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Ploetz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><forename type="middle">A</forename><surname>Clements</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irfan</forename><forename type="middle">A</forename><surname>Essa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Assist. Radiol. Surg</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1623" to="1636" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
