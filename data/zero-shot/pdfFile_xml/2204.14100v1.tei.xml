<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Adversarial Distortion Learning for Medical Image Denoising</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Morteza</forename><surname>Ghahremani</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Mohammad</forename><surname>Khateri</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alejandra</forename><surname>Sierra</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jussi</forename><surname>Tohka</surname></persName>
						</author>
						<title level="a" type="main">Adversarial Distortion Learning for Medical Image Denoising</title>
					</analytic>
					<monogr>
						<title level="j" type="main">IEEE TRANSACTIONS ON MEDICAL IMAGING</title>
						<imprint>
							<biblScope unit="volume">XX</biblScope>
							<biblScope unit="page">1</biblScope>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T14:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Adversarial networks</term>
					<term>Deep learning</term>
					<term>Deep neural network</term>
					<term>Image denoising</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a novel adversarial distortion learning (ADL) for denoising two-and three-dimensional (2D/3D) biomedical image data. The proposed ADL consists of two auto-encoders: a denoiser and a discriminator. The denoiser removes noise from input data and the discriminator compares the denoised result to its noise-free counterpart. This process is repeated until the discriminator cannot differentiate the denoised data from the reference. Both the denoiser and the discriminator are built upon a proposed auto-encoder called Efficient-Unet. Efficient-Unet has a light architecture that uses the residual blocks and a novel pyramidal approach in the backbone to efficiently extract and re-use feature maps. During training, the textural information and contrast are controlled by two novel loss functions. The architecture of Efficient-Unet allows generalizing the proposed method to any sort of biomedical data. The 2D version of our network was trained on ImageNet and tested on biomedical datasets whose distribution is completely different from ImageNet; so, there is no need for re-training. Experimental results carried out on magnetic resonance imaging (MRI), dermatoscopy, electron microscopy and X-ray datasets show that the proposed method achieved the best on each benchmark. Our implementation and pre-trained models are available at https: //github.com/mogvision/ADL.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>I MAGE denoising aims to recover latent noise-free two/three-dimensional (2D/3D) image data x from its noisy counterpart y = x + n, where n denotes noise that is independent with respect to x. The denoising problem tends to be an ill-posed inverse problem as no unique solution exists. Denoising is an essential preprocessing step in many medical imaging applications. A vast number of methods have been proposed over the past decades <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b37">[38]</ref>, and recently, methods based on deep neural networks (DNNs) attract more attention due to their good performance <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b25">[26]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b51">[52]</ref>, <ref type="bibr" target="#b53">[54]</ref>.</p><p>For additive noise, it is possible to establish the Bayesian approach, where the posterior P x|y (x|y) is a combination of The authors are with A. I. Virtanen Institute for Molecular Sciences, University of Eastern Finland, 70211 Kuopio, Finland (email: morteza.ghahremani@uef.fi; mohammad.khateri@uef.fi; alejandra.sierralopez@uef.fi; jussi.tohka@uef.fi).</p><p>the data likelihood P y|x (y|x) and a prior model P x (x), i.e.: The denoising problem Eq. 1 can be also expressed as an optimization of a data term penalized by one or more regularization terms as follows:</p><formula xml:id="formula_0">x = argmin x y ? x p p + ?R(x),<label>(2)</label></formula><p>where . p denotes the p-norm, 1 ? p ? 2. R poses penalty terms on the unknown latent x which is associated with the prior term P x (x) defined in Eq. 1. ? is a Lagrangian parameter, which can be determined manually or automatically <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b44">[45]</ref>. In general, the denoising methods can be divided into modeland learning-based categories. The model-based approach solves Eq. 2 using one or several regularization terms <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b55">[56]</ref>. In the learning-based approach, a model can learn features with supervision <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b33">[34]</ref> or it may learn the features simultaneously during image reconstruction <ref type="bibr" target="#b35">[36]</ref>. Recently, the deep learning-based approaches <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b24">[25]</ref> have reached excellent performance in denoising biomedical images by training DNNs on paired or unpaired images of target clean and noisy data. Despite the success of the existing denoising techniques, the contents of denoised images by such methods still suffer from poor preservation of texture and contrast. Requiring prior knowledge of noise and the lack of generalizability to various types of biomedical image data are other limitations of the current techniques.</p><p>In this study, we propose an adversarial distortion learningbased (ADL) method that does not require any prior knowledge about the noise in images. ADL is a supervised feature learning method that is comprised of a denoiser and a discriminator that iteratively optimizes each other to find high-quality denoised contents. Both the denoiser and the discriminator are built upon a novel network called Efficient-Unet. Efficient-Unet has a light architecture with pyramidal residual blocks backbone that enforces the higher-level features are in consonance with each other hierarchically. A remarkable feature of our approach is that it can be used for denoising any type of 2D/3D biomedical image data with no need for re-training. The light architecture of the proposed method allows a fast evaluation of test data and it considerably reduces the computational time of the conventional modelbased approaches. The key contributions of this study are as follows:</p><p>? We design a novel pyramidal learning scheme, named Efficient-Unet, to further participate high-level features in the output results during training. Efficient-Unet does not need training data whose distribution is close to that of the test data, so improving the generalizability of the proposed network. ? We introduce a novel pyramidal loss function using 'algorithme? trous' (ATW) <ref type="bibr" target="#b41">[42]</ref>. The proposed loss function keeps textural information of the reference data without amplifying noise's side effects in non-textured regions. ? To preserve the histograms of reference images, we propose a novel histogram-based loss function for improving the appearance contents of denoised images. ? We provide both 2D and 3D networks of our method for denoising any sort of 2D/3D biomedical image data. Experimental results show that the proposed ADL achieves state-of-the-art results on all the benchmarks alongside solving overfitting, generalizability to any sort of biomedical data, and computational burdens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK</head><p>Medical image denoising approaches can be grouped into two subcategories: model-based and learning-based methods. In the model-based approach, optimization of Eq. 1 with respect to the likelihood term only is typically ill-posed, so needs one or more regularization terms alongside the data fidelity term to find and stabilize the denoised outputs. Thus far, a wide range of model-based techniques have been developed, ranging from total variation (TV) regularizers <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b55">[56]</ref> to nonlocal self-similarity regularizers <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b29">[30]</ref>. TV-based regularization terms can successfully recover piecewise constant images but cause several artifacts to complex images with rich edges and textures. Since natural images tend to contain repetitive edge and textural information, combination of non-local self-similarity <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref> with the sparse representation <ref type="bibr" target="#b33">[34]</ref> and low-rank approximation <ref type="bibr" target="#b2">[3]</ref> lead to significant improvements over their local counterparts. The regularization terms play an important role in the quality of resultant denoised images. Despite the acceptable performance of the model-based methods in image denoising, there are still several drawbacks with these techniques. Requiring a specific model for a single denoising task, lack of generalizability to various types of data, or the need for manually or semiautomatically tuning parameters are the challenging that is still required to be addressed. Moreover, the non-local selfsimilarity-based methods iteratively optimize Eq. 2 so their convergence often needs considerable time.</p><p>A learning-based method aims at learning the parameters of a model with available datasets. Sparsity-based techniques are well-studied learning approaches, which represent local image structures with a few elemental structures so-called atoms from an off-the-shelf transformation matrix-like Wavelets <ref type="bibr" target="#b13">[14]</ref> or a learned dictionary <ref type="bibr" target="#b35">[36]</ref>, <ref type="bibr" target="#b50">[51]</ref>. In recent years, deep learning methods have been widely used for the enhancement of biomedical images, ranging from MRI <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b42">[43]</ref>, CT <ref type="bibr" target="#b49">[50]</ref>, <ref type="bibr" target="#b51">[52]</ref>, X-ray <ref type="bibr" target="#b11">[12]</ref>, to electron microscopy (EM) <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b34">[35]</ref>. The learning process of DNNs can be categorized into supervised <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b54">[55]</ref> or unsupervised <ref type="bibr" target="#b1">[2]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b56">[57]</ref> approaches. Supervised learning DNNs consider clean and noisy image pairs for training where the noisy counterparts are obtained through adding synthesized noise to the target clean ones. To overcome the lack of availability of sufficient clean data for training, unsupervised methods <ref type="bibr" target="#b15">[16]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b56">[57]</ref> have been developed that estimate the map of noise from unpaired images, leveraging the supervision of clean targets. Unsupervised techniques often explore the noise map by generative adversarial networks (GANs) <ref type="bibr" target="#b12">[13]</ref> and its variants like conditional GAN <ref type="bibr" target="#b30">[31]</ref> or CycleGAN <ref type="bibr" target="#b56">[57]</ref>. Typically, the supervised DNNs have shown superior performance over the unsupervised and conventional model-based approaches. Despite the great success of DNNs in denoising biomedical images, the contents of denoised images still suffer from poor textural information. Although several works <ref type="bibr" target="#b23">[24]</ref>, <ref type="bibr" target="#b39">[40]</ref> show less tendency toward overfitting and being data-driven, their performance is still highly dependent on the training samples. Since clean biomedical images for training are not available or available only in very limited quantities, this aspect of the current DNN techniques limits their generalizability to different sorts of biomedical images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED METHOD</head><p>The intuition of ADL is that the representation of images must be robust against random phenomena like noise. ADL consists of a denoiser and a discriminator, where both have the same Unet-like architecture called Efficient-Unet. There is some minor difference between the Efficient-Unet of the denoiser and that of the discriminator (Section III-A). ADL is trained by minimizing competing multiscale objectives between the denoiser and the discriminator. During training, we enforce the networks on keeping the edges, histogram, and paramedical information of the reference/ground-truth data. The proposed loss functions are detailed in Section III-B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Efficient-Unet</head><p>Let x ? R H?W ?D?C (x ? R H?W ?C for 2D) be the noise-free 3D (/2D) image data, and y ? R H?W ?D?C the observed image data that is generated by adding WGN of standard deviation (?) to its noise-free counterpart x. During training, x plays as a reference, noise level ? is unknown, and the goal is to recover y from x. Efficient-Unet and the training architecture for learning network parameters of the proposed denoiser is depicted in <ref type="figure" target="#fig_1">Fig. 1</ref>. Efficient-Unet consists of an encoder, a bridge, a decoder, a content enhancer, and transformers. Similarly, the framework of Efficient-Unet for the discriminator is depicted in <ref type="figure" target="#fig_2">Fig. 2</ref>.</p><p>The encoder unit is comprised of three consecutive residual blocks with strides one and two (denoted by S in <ref type="figure" target="#fig_1">Fig. 1</ref>) that extracts the features from the observed data. The number of filters in the encoder layers is doubled after each downsampling operation (i.e., S = 2). Several studies <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b54">[55]</ref> have shown the effectiveness of residual blocks in deep learning. We use the residual blocks in our auto-encoder structure for effective denoiser prior modeling. To have large activation maps, we delayed the downsampling of the first layer, where its stride is 1. The extracted features by the encoder are then passed through a bridge with f b filters followed by the decoder unit that provides an estimation of the denoised input dat? x in the feature domain. The features of each decoder layer are mapped into the image domain by the transformer unit T n where n is the index of the corresponding layer. The transformer unit is a set of n residual blocks followed by a 1 ? 1 ? 1 convolution and a sigmoid activation layers. The number of filters in the transformer layers is halved n times 1 and the filter size of 1 ? 1 ? 1 convolution layer is equal to C, which is the number of input channels. Throughout this paper, the kernel size and dilation of the convolutional layers are 3 and 1, respectively, unless otherwise noted.</p><p>Thus far, the only difference between the Efficient-Unet of the denoiser and that of the discriminator is the filter size of convolution layers, i.e. {f 1 , f 2 , f 3 , f b }. It is set as {96, 128, 160, 192} for the denoiser and {48, 64, 80, 96} for the discriminator. The discriminator network needs a lower number of learning parameters compared to the denoiser because the discriminator is a classifier that computes the loss for misclassifying a noise-free instance as noisy or a noisy instance as noise-free. Since the discriminator is a classifier, the output of each transformer is mapped into a binary mask by a mapper which is shown in <ref type="figure" target="#fig_2">Fig. 2</ref>. The mapping layer is comprised of convolution layers with a filter size of 1 followed 1 For example, the filter size of the residual block in</p><formula xml:id="formula_1">T 1 is f 1 2 . Similarly, we have { f 3 2 , f 3 4 , f 3 8 } for the residual blocks in T 3 .</formula><p>by a sigmoid activation layer to map the input to a binary mask. The denoiser has also one extra unit called content enhancer and it is designed to preserve the sparse information like edges and textures that are not or less affected by noise. As shown in <ref type="figure" target="#fig_1">Fig. 1</ref>, the content enhancer is a residual block, wherein the first layer extracts features by three different dilation values, D. Several studies <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b41">[42]</ref> have shown that the structural information, which is mainly edges and textures, exists at different scales. So we consider three convolutions of strides 1, 2, and 4 to extract such features from the input noisy data directly. In the absence of noise, this unit has more activated layers. The content enhancer layer is concatenated by the last layer of the decoder before feeding T 1 . The denoised datax is the output of layer T 1 , shown by a blue rectangle in <ref type="figure" target="#fig_1">Fig. 1</ref>. It is also worth mentioning that the bias parameter in the proposed Efficient-Unet is deactivated since bias-free networks increase the linearity property by canceling the bias parameter 2 <ref type="bibr" target="#b31">[32]</ref>. Moreover, when the magnitude of the bias is much larger than that of filters, the generalizability of the model is limited so less prone to overfitting <ref type="bibr" target="#b53">[54]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Multiscale loss functions</head><p>ADL consists of two auto-encoders: a denoiser G and a discriminator D. Generally, the parameters of adversarial nets are optimized by minimizing a two-player game in an alternating manner <ref type="bibr" target="#b12">[13]</ref>:</p><formula xml:id="formula_2">L D = ? ?E x {log D(x)} ? E y {log (1 ? D(G(y)))}, L G = ? ?E y {log D(G(y))}.<label>(3)</label></formula><p>Denoiser G aims to estimate a clean image while discriminator D distinguishes between reference x and denoised G(y) instances. Eq. <ref type="formula" target="#formula_2">(3)</ref> does not maintain textural, global, and local data representation. To this end, we propose novel multiscale loss functions for both the denoiser and the discriminator. We minimize the loss of denoiser from coarse to fine resolution for enforcing the participation of the decoder's features in the resultant high-resolution denoised image. Likewise, we enforce the discriminator network to discriminate the target and the denoised images from bottom to top. Moving from coarse resolution towards fine one enhances structural features at the corresponding resolution, resulting in rich edge and textural information in the denoised data. 1) Denoiser's loss function (L G ): We define the loss function of the denoiser as a combination of an 1 loss (denoted by L 1 ), a novel pyramidal textural loss L pyr , and a novel histogram loss L Hist that are weighted by ? 1 , ? p , and ? H , respectively:</p><formula xml:id="formula_3">L G = ? ? 1 L 1 + ? p L pyr + ? H L Hist = ?E{| G(y) ? x |} ? ? p E J j=1 | ? j .G(y) ? ? j .x | ? ? H E{logcosh H [G(y)] ? H [x] }. (4) ? L 1 :</formula><p>The data fidelity is an 1 -norm between the denoised and reference instances. Compared to the 2 -norm, the 1 -norm is more robust against outliers. ? L pyr : The pyramidal textural loss aims at preserving edges and texture in to-be-denoised images. Unlike the conventional edge-preserving regularization terms like TV and its variants <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b47">[48]</ref> that compute the differential of given noisy images, our goal is to measure the textural difference between to-be-denoised images and their corresponding reference only. Traditional TVs use first-, second-or higher order-based derivative operators to filter noisy images. The main drawback of such operators is to boost the pixels with high-level noise so it may bias the loss towards dominant values. For this reason, the images denoised by TV-like regularisation terms are often accompanied by smoothness in both textural and non-textural regions. To cope with this problem, we introduce a pyramidal loss function using ATW <ref type="bibr" target="#b41">[42]</ref>. ATW is a stationary Wavelet transform that decomposes an image into several levels by a cubic spline filter and then subtracts any two successive layers to obtain fine images with edges and texture. The low-pass filters in ATW alleviate the side effects of noise so it enables us to include texture information of input images in the loss function. <ref type="figure">Fig. 3</ref> briefs ATW. In short, it decomposes an input image into J levels by a cubic spline finite impulse response that is denoted by h <ref type="bibr" target="#b0">(1)</ref> . Unlike the nonstationary multiscale transforms that downscale the images and then apply a filter, ATW upscales the kernel by inserting '2 j?1 ? 1' zeros between each pair of adjacent elements in h <ref type="bibr" target="#b0">(1)</ref> , where j denotes the j-th decomposition level. Fine images with texture and edges are derived via subtraction of any two successive filtered images. Further details can be found in <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b41">[42]</ref>. In Eq. 4 ? j . denotes the textural image at the j-th level derived by ATW. J is a positive integer that denotes the number of decomposition levels. Typically, four decomposition levels (J = 4) have been able to extract the majority of edges and texture laid in a wide range of sigma values <ref type="bibr" target="#b10">[11]</ref>. ? L Hist : The histogram loss assures that the histograms of G(y) and x are close to each other. This term maintains the global structure of G(y) with respect to x since the added edges and texture information (by ATW) may change the overall histogram of the denoised instance. To compute this loss, we first compute the histogram of both G(y) and x denoted by H. Then, we use an strictly increasing function that computes the loss between H [G(y)] and H [x]. To this end, we use 'logcosh(p) = log(cosh(p))' that is approximately equal to p 2 2 for small p and to log(p) ? log(2) for large p 3 . It is worth noting that here we use the histogram loss for preserving the global structure between the denoised image and its reference, and this is different from other histogram works like <ref type="bibr" target="#b43">[44]</ref>, <ref type="bibr" target="#b57">[58]</ref>. In <ref type="bibr" target="#b57">[58]</ref>, a gradient histogram is used for texture preservation, and Delbracio et al. <ref type="bibr" target="#b43">[44]</ref> proposed a DNN-based histogram as a fidelity term. In Efficient-Unet, features at fine-resolution maps are reconstructed from its coarser ones <ref type="figure" target="#fig_1">(Fig. 1)</ref>. Thus, an inefficiency in coarser spatial scales (or equivalently, higher-level feature maps) may yield poor resultant feature maps. To cope with this problem, we propose a pyramidal version of the loss function defined in Eq. 4 that keeps the consistency between G(y) and its counterpart x at each spatial scale. To compute the proposed multiscale loss, we generalize the transformer unit, introduced in Section III-A, to lower spatial scales (here, two scales T 2 and T 3 ) and then get the corresponding denoised image data. Then, we compute the loss function presented in Eq. 4 at every scale and finally take an average of the losses to yield the denoiser loss:</p><formula xml:id="formula_4">L G = 3 s=1 (? 1 L (s) 1 + ? e L (s) edge + ? H L (s) Hist ),<label>(5)</label></formula><p>where superscript s denotes the scale of the data pyramid and the total number of scales is set to 3 in the study.</p><p>2) Discriminator's loss function (L D ): Most discriminators are based on an encoder that determines whether the input instance is fake or real. Schonfeld et al. <ref type="bibr" target="#b38">[39]</ref> have shown that using an Unet structure for discriminator could increase the performance of the generator (here, the denoiser). Borrowed the same concepts from <ref type="bibr" target="#b38">[39]</ref> and similar to Eq.5, we propose the following loss function for the discriminator (see <ref type="figure" target="#fig_2">Fig. 2</ref>):</p><formula xml:id="formula_5">L D = L D b + 3 s=1 L (s) D dec ,<label>(6)</label></formula><p>where L D b is the bridge loss and it is defined as</p><formula xml:id="formula_6">L D b = ?E m,n min(0, ?1 + D b (x) m,n ? E m,n min(0, ?1 ? D b (x) m,n . (7)</formula><p>Here, subscripts {m, n} denote discriminator decision at pixel (m, n). Likewise, L D dec in Eq. 6 is defined as follows:</p><formula xml:id="formula_7">L (s) D dec = ?E m,n min(0, ?1 + D dec (x) m,n ? E m,n min(0, ?1 ? D dec (x) m,n , s ? {1, 2, 3}. (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Training details</head><p>We implemented ADL for both 2D and 3D data. To show the generalizability of the denoiser, we trained the 2D model on ImageNet <ref type="bibr" target="#b36">[37]</ref>, whose data distribution is different from that of biomedical images. The training and the validations sets contain 1,281,168 and 50,000 images of size 224 ? 224, respectively. The denoiser model was trained on color and <ref type="figure">Fig. 3</ref>. ATW decomposition for image data. Since 2D kernel h is separable, the ATW decomposition for 3D image data is obtained by convolving three 1D cubic kernels in the x, y, and z directions. ATW is comprised of inherently low-pass filters that attenuate the side effects of noise.</p><p>gray-scale images separately. We augmented the data by rotation, ? ? {90 ? , 180 ? , 270 ? }, and flips. We added zeromean WGN to input images with ? that was randomly selected in interval [0,55]. The noisy images were not clipped into the interval [0,255], making sure that the distribution of added noise was still WGN. The 3D model was trained on the IXI Dataset 4 , containing approximately 570 8-bit T1, T2 and PDweighted MR images acquired at three different hospitals in London: Hammersmith Hospital using a Philips 3T system, Guy's Hospital using a Philips 1.5T system, and Institute of Psychiatry using a GE 1.5T system. The size of MRI volumes is 256?256?n, where n ? <ref type="bibr" target="#b27">[28,</ref><ref type="bibr">150]</ref>. We randomly cropped the volumes into sub-volumes of 128?128?48 to facilitate the training. we added zero-mean white Gaussian (? ? [0, 55]), Rician (? ? [0, 25] and ? ? [0, 15]), and Rayleigh (? ? [0, 25]) noise to input MRI volumes. Likewise to the 2D training, the values of the parameters in the above-mentioned intervals were randomly selected . We used the Adam algorithm <ref type="bibr" target="#b18">[19]</ref> as an optimizer with the ReduceLRonPlateau scheduler <ref type="bibr" target="#b46">[47]</ref>. The optimization started with a learning rate of 10 ?4 and it was reduced (by the ReduceLRonPlateau scheduler) until the PSNR of validation has stopped improving. The weights in Eq. 5, i.e. {? 1 , ? e , ? H }, were set to 1.</p><p>Reproducibility: The reference implementation of ADL is based on TensorFlow. All the experiments were conducted on 4 A-100 GPUs. The implementation and pre-trained models are available at https://github.com/mogvision/ ADL. We also provided PyTorch and Colab implementation of ADL on the GitHub.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Datasets:</head><p>We used five biomedical imaging datasets from different modalities (3D brain and knee MRI), EM, X-ray, and dermatoscopy to evaluate our model. The datasets are summarized below and an example image from each dataset is shown in <ref type="figure" target="#fig_3">Fig. 4</ref>. Note that our method was trained on data fully independent (ImageNet for 2D and IXI for 3D) on these five test datasets and the training set was used for training of the competing deep learning techniques.</p><p>? BrainWeb database (3D) <ref type="bibr" target="#b5">[6]</ref> contains simulated 3D brain MRI based on healthy and multiple sclerosis (MS) anatomical models. MRI volumes have been simulated modelling three pulse sequences (T1-, T2-and PDweighted), five slice thicknesses (1, 3, 5, 7, and 9 mm; pixel size is 1 mm 2 ), clean and noisy samples with five levels of Rician noise (1%, 3%, 5%, 7%, 9%), and three levels of intensity non-uniformity (INU) 0%, 20%, and 40%. In total, this results in 30 reference (clean, no INU) and 510 noisy MRI volumes of size 181?217?n, where n = 181, 60, 36, 26, 20 depending on slice thickness. ? The NYU fastMRI Initiative database (fastmri.med.nyu.edu) (3D) <ref type="bibr" target="#b52">[53]</ref> contains PD-weighted knee MRI scans with and without fat suppression with in-plane size 320 ? 320 and the number of slices varying from 27 to 45. We randomly sampled 200 volumes from the database for evaluation. ? MitoEM Challenge <ref type="bibr" target="#b48">[49]</ref>   , 3D knee MRI <ref type="bibr" target="#b52">[53]</ref>, EM <ref type="bibr" target="#b48">[49]</ref>, chest X-ray <ref type="bibr" target="#b17">[18]</ref>, and dermatoscopic RGB <ref type="bibr" target="#b45">[46]</ref>. different modalities. We set the training/test set ratio to 80%-20% . For 2D databases, we compared the proposed ADL to improved BM3D <ref type="bibr" target="#b28">[29]</ref> 5 as the conventional model-based method, and three deep learning-based methods, Dynamic Residual Attention Network (DRAN) <ref type="bibr" target="#b39">[40]</ref>, DnCNN-S <ref type="bibr" target="#b54">[55]</ref>, and recentlydeveloped SwinIR <ref type="bibr" target="#b23">[24]</ref>. We compared the 3D version of our model to BM4D <ref type="bibr" target="#b26">[27]</ref> that is widely used for denoising 3D biomedical image data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experiments with 2D data with synthetic noise</head><p>Synthesised WGN with ? ? <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b49">50]</ref> were added into the test images of the skin <ref type="bibr" target="#b45">[46]</ref>, chest <ref type="bibr" target="#b17">[18]</ref>, and EM <ref type="bibr" target="#b48">[49]</ref> datasets. The PSNR (dB) and SSIM results for different methods are represented in <ref type="table" target="#tab_0">Table I</ref>. According to the PSNR and SSIM results, one can see that the deep learning techniques yield better results compared to the model-based BM3D. The results of ADL are on par with those of the other methods, and it outperforms the other competing methods by a large margin for almost any noise level. The standard deviation measures the compactness of the denosing results. Although our method was not trained on the training sets (see Section IV), its PSNR's standard deviation are on par with the conventional techniques' ones. The SSIM results report that ADL gained the most compact results over all the noise levels. <ref type="figure" target="#fig_4">Fig. 5</ref> shows a denoising example of different methods on the 2D datasets with noise level 35. To save space, we only show the results of model-based BM3D and SwinIR as SwinIR was the best one among the competing deep learning-based techniques. The example images are accompanied by profile lines. In the HAM10000 dataset (see <ref type="figure" target="#fig_4">Fig. 5(a)</ref>), ADL could recover much sharper edges than BM3D and SwinIR while maintaining the contrast of the reference image. The RGB profile lines of ADL have the highest similarity with the reference ones while the competing methods failed to preserve the contrast.</p><p>In the Chest X-Ray dataset ( <ref type="figure" target="#fig_4">Fig. 5(b)</ref>), although the profile lines of all the methods were highly correlated to the reference one, ADL preserved more textural information compared to the others. BM3D resulted in blurred texture regions and SwinIR smoothed out the bones while the proposed ADL recovered more fine details and textures. The same trend is seen in the EM results depicted in <ref type="figure" target="#fig_4">Fig. 5(c)</ref>, where SwinIR yielded a toy-like result and BM3D blurred the borders. The smoothness of BM3D and SwinIR is apparaent in their profile lines while the profile line of ADL tracked the reference one tightly. This means that ADL could successfully preserve the contrast and edges of the reference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments with 3D data with synthetic noise</head><p>Similarly to the 2D experiment, synthesised WGN with ? ? <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b49">50]</ref> were added into the test images in the fastMRI <ref type="bibr" target="#b52">[53]</ref> dataset. The quantitative results are tabulated in <ref type="table" target="#tab_0">Table II</ref>. The noise in the simulated BrainWeb images has Rayleigh statistics in the background and Rician statistics in the signal regions. The average PSNR (dB) and SSIM   results of the BM4D and the proposed ADL on the BrainWeb database are plotted in <ref type="figure" target="#fig_6">Fig. 7</ref>. ADL was able to reduce the noise effects to a greater extent as compared to BM4D. The results of both the databases verify the high performance of ADL in noise and RF distortion removal. <ref type="figure" target="#fig_5">Fig. 6</ref> provides a comparison of the visual results of BM4D and ADL on a noisy T2-weighted image of BrainWab with noise level of 9 and RF 40%. From the appearance perspective, ADL preserved the histogram better than BM4D. Since the edges are blur in the BM4D result, in particular the zoom region, ADL restored the texture successfully. In short, the results of 3D are in consonance with 2D results and ADL well restored both the appearance and texture information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Experiments with noisy data with no reference</head><p>We experimented the denoising with a T1-weighted brain MRI from OASIS3-project <ref type="bibr" target="#b20">[21]</ref>, selected randomly (male, cognitively normal, 87 years), and with a high-resolution EM dataset from rats' corpus callosum <ref type="bibr" target="#b0">[1]</ref>. The input noisy images, the denoised results by ADL, and the histogram of images are depicted in <ref type="figure">Fig. 8(b)</ref>. Both the denoised results and the histogram plots verify that ADL successfully denoised the noisy images and preserved structural information with high precision. <ref type="table" target="#tab_0">Table III</ref> reports the running time of the methods. The size of data for 2D and 3D experiments is 256?256 and 256?256? 256, respectively. For 2D data, our denoiser needs less than 5 M parameters which is much lower than 11.9M of SwinIR. ADL also needs 2G FLOPs which is considerably lower than that of SwinIR. For this reason, we named the proposed Unet as Efficient-Unet. For 3D data, Our denoiser does not require the cumbersome calculation of BM4D and this characteristic of our method is more appealing for real-time applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Computational complexity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Ablation study</head><p>Multiscale loss functions: <ref type="figure">Fig. 9</ref> compares the performance of ADL for different loss functions. The average PSNR results on the validation dataset when ? ? [10, 50] is reported here. It is seen that the pyramidal loss function considerably enhanced PSNR. This scheme was further improved by adding the histogram loss into the training.</p><p>Content Enhancer block: As described in Section III-A, this block contributes to the denoising process directly when the depth of noise is low. In other words, the aim of the Content Enhancer block is to alleviate the vanishing-gradient problem in DNNs when the input noise is low, so it improves the convergence pace. We plotted the response of a few filters in the Content Enhancer block in <ref type="figure" target="#fig_1">Fig. 10</ref>. We also reported the correlation between the filer responses and the denoised images by ADL. It is worth noting that the filter responses for edges and texture are not reported here because it is not straightforward to measure the texture similarity between the edge-oriented filters and the denoised contents. For noise levels less than 10, one can observe that filters' responses are highly correlated to the denoised contents and this scheme is reduced (a) Brain MRI (b) EM <ref type="figure">Fig. 8</ref>. ADL results on no-reference noisy images. From left to right: noisy, ADL, and histograms of the input noisy and the denoised image. <ref type="figure">Fig. 9</ref>. PSNR (dB) results of ADL for the validation using different loss functions. The results are averaged over noise levels <ref type="bibr">10, 15, 25, 35, and 50.</ref> by increasing the level of AWGN noise. It can be referred from the results that the filters of the Content Enhancer block are highly contributed to the denoised content when the level of noise is small. Since the ADL outcomes remained almost unchanged over high-level noise, we deduce that the network switched to the decoders' filters in this condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION</head><p>In this study, we have proposed a novel adversarial distortion learning technique, named ADL, for efficiently restoring images from noisy and distorted observations. The key idea is to design an auto-encoder called Efficient-Unet that preserves texture and appearance during distortion removal. Efficient-Unet is based on a hierarchical approach in which low-level features are highly dependent on high-level ones. This enforces the model to restore the images from coarse to fine scales. To alleviate the vanishing-gradient problem and to improve the convergence pace, we added the Content Enhancer block to Efficient-Unet. The proposed model has been implemented for both 2D and 3D image data. For training the ADL's parameters, we have proposed a pyramidal loss function for preserving textural information in different scales. We have also introduced a histogram loss to keep the appearance of the denoised contents. Experimental results and a comparative study with the conventional techniques over several publicly accessible 2D and 3D datasets have shown that ADL can restore more accurate images in the shortest time, which makes it more suitable for real-time applications.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>y|x (y|x) + log P x (x). (1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Framework of the Efficient-Unet for denoiser with the training steps. Efficient-Unet is composed of the encoder, decoder, and Content Enhancer blocks. The output of the decoder at every scale is mapped into the image domain by a Transformer block. We then enforce consistency between the outputs of the decoder and their counterparts x. Low-level features further contribute into the denoised image by the Content Enhancer block. When the noise level is low, the filters of this block are activated improving the convergence with no need for high-level features.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Framework of the proposed Efficient-Unet for discriminator with the training steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Fig. 4 .</head><label>4</label><figDesc>A sample of each dataset used for evaluation in this study. From top to bottom and left to right: 3D Brain MRI<ref type="bibr" target="#b5">[6]</ref></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 5 .</head><label>5</label><figDesc>Color and gray-scale image denoising results on a) skin, b) chest, and c) EM images with noise level 35. From left to right: Reference, noisy, BM3D, SwinIR, and the proposed ADL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 6 .</head><label>6</label><figDesc>Denoising results of BM4D and the proposed ADL on the BrainWeb data with noise level 9 and RF 40%. From left to right: Reference, noisy, BM4D, and proposed ADL.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 7 .</head><label>7</label><figDesc>Average PSNR(dB) and SSIM of BM4D<ref type="bibr" target="#b26">[27]</ref> and the proposed ADL on the BrainWeb database<ref type="bibr" target="#b5">[6]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 10 .</head><label>10</label><figDesc>Performance of the Content Enhancer block in the Efficient-Unet for different noise levels. Top: Visual comparison of the response of few filters. Bottom: The correlation between the response of the filters and the ADL outcome.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I PSNR</head><label>I</label><figDesc>(DB) AND SSIM RESULTS (AVERAGE ? STANDARD DEVIATION) OF DIFFERENT METHOD ON THE IMAGE-BASED DATASETS FOR NOISE LEVELS 10, 15, 25, 35, 50. THE BEST AND SECOND BEST RESULTS ARE HIGHLIGHTED IN BOLDFACE AND IN italic, RESPECTIVELY. 4?1.3 37.5?1.1 38?1.4 38.4?1.4 38.8?1.3 0.91?0.02 0.93?0.02 0.91?0.02 0.92?0.02 0.95?0.02 15 35.9?1.3 36.9?1.4 35.8?1.7 37.1?1.4 37.5?1.3 0.90?0.03 0.91?0.03 0.91?0.03 0.92?0.02 0.94?0.02 HAM10000 [46] 25 34.4?1.5 34.5?1.5 34.9?1.6 35.5?1.6 36.1?1.4 0.88?0.03 0.85?0.04 0.86?0.04 0.90?0.03 0.93?0.02 35 33.4?1.6 32.6?1.5 33.9?1.7 34.8?1.7 35.2?1.5 0.85?0.04 0.82?0.05 0.84?0.05 0.86?0.05 0.93?0.02 50 32.3?1.6 30.5?1.9 31.2?1.8 33.6?1.7 34.2?1.6 0.85?0.04 0.81?0.05 0.82?0.05 0.87?0.04 0.92?0.03 10 38.6? 1.1 38.6?1.6 38.8?1.1 38.9?1.2 39.6?1.1 0.94?0.02 0.95?0.02 0.94?0.02 0.96?0.02 0.96?0.02 15 37.6?1.1 37.9?1.8 38.5?1.2 38.7?1.2 38.6?1.2 0.93?0.02 0.94?0.03 0.93?0.02 0.94?0.02 0.94?0.02 Chest X-Ray [18] 25 35.4?0.9 36.5?1.7 35.8?1 36.9?1.1 37.1?1.2 0.91?0.02 0.92?0.04 0.92?0.02 0.92?0.02 0.93?0.02 35 33.8?0.9 35?1.8 34.5?0.9 35.1?1 35.7?1.1 0.89?0.02 0.90?0.04 0.90?0.02 0.91?0.03 0.92?0.03 50 32.1?0.7 32.7?1.8 32.9?1 34.1?1.1 34.4?1.2 0.87?0.03 0.89?0.05 0.88?0.03 0.90?0.03 0.91?0.03 10 30.5?0.3 31.2?0.5 31.1?0.3 31?0.3 31.5?0.3 0.91?0.02 0.91?0.03 0.89?0.01 0.91?0.03 0.93?0.02 15 28.2?0.3 29?0.5 28.9?0.3 29.1?0.3 29.3?0.3 0.85?0.02 0.87?0.02 0.86?0.01 0.87?0.02 0.88?0.01 EM [49] 25 25.6?0.4 26.5?0.6 26.3?0.4 26.6?0.4 27?0.4 0.76?0.03 0.79?0.04 0.78?0.03 0.79?0.02 0.80?0.02 35 24?0.4 24.9?0.5 24.7?0.4 25?0.5 25.3?0.4 0.69?0.04 0.74?0.04 0.72?0.03 0.73?0.03 0.75?0.03 50 22.4?0.5 22.8?0.6 23.2?0.5 23.3?0.6 23.7?0.5 0.61?0.04 0.66?0.04 0.65?0.03 0.66?0.03 0.68?0.03</figDesc><table><row><cell>Dataset</cell><cell>Noise Level</cell><cell>BM3D</cell><cell cols="3">PSNR ? DRAN DnCNN-S SwinIR</cell><cell>ADL</cell><cell>BM3D</cell><cell cols="3">SSIM ? DRAN DnCNN-S SwinIR</cell><cell>ADL</cell></row><row><cell></cell><cell></cell><cell>[29]</cell><cell>[40]</cell><cell>[55]</cell><cell>[24]</cell><cell>(ours)</cell><cell>[29]</cell><cell>[40]</cell><cell>[55]</cell><cell>[24]</cell><cell>(ours)</cell></row><row><cell></cell><cell>10</cell><cell>37.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II PSNR</head><label>II</label><figDesc>(DB) AND SSIM RESULTS (AVERAGE ? STANDARD DEVIATION) OF BM4D [27] AND THE PROPOSED ADL ON THE 3D MRI KNEE DATASET [53] FOR NOISE LEVELS 10, 15, 25, 35, 50. THE BEST RESULTS ARE HIGHLIGHTED IN BOLDFACE.</figDesc><table><row><cell>Dataset</cell><cell>Noise Level</cell><cell cols="2">PSNR? BM4D ADL</cell><cell cols="2">SSIM? BM4D</cell><cell>ADL</cell></row><row><cell></cell><cell></cell><cell>[27]</cell><cell>(ours)</cell><cell>[27]</cell><cell>(ours)</cell></row><row><cell></cell><cell>10</cell><cell cols="2">37.1?1.8 38.3?1</cell><cell cols="2">0.89?0.04 0.92?0.02</cell></row><row><cell></cell><cell>15</cell><cell cols="4">35.9?1.6 36.9?1.1 0.87?0.05 0.90?0.03</cell></row><row><cell>fastMRI [53]</cell><cell>25</cell><cell cols="4">34.3?1.4 35.1?1.1 0.85?0.05 0.89?0.03</cell></row><row><cell></cell><cell>35</cell><cell cols="2">33.1?1.2 34.1?1</cell><cell cols="2">0.82?0.04 0.88?0.03</cell></row><row><cell></cell><cell>50</cell><cell cols="4">31.5?1.1 33.1?0.9 0.78?0.04 0.86?0.04</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III COMPUTATIONAL</head><label>III</label><figDesc>COMPLEXITY AND RUNNING TIME OF DIFFERENT METHODS OVER 256?256 2D AND 256?256?256 3D MRI DATA.</figDesc><table><row><cell></cell><cell>Method</cell><cell cols="3">Model Parameters FLOPs Running Time (M ) (G)</cell></row><row><cell>2D</cell><cell>SwinIR [24] ADL (ours)</cell><cell>11.9 4.75</cell><cell>71.2 2.1</cell><cell>539 ms 143 ms</cell></row><row><cell>3D</cell><cell>BM4D [27] ADL (ours)</cell><cell>-14.8</cell><cell>-121</cell><cell>597.6 s 14.6 s</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">In<ref type="bibr" target="#b31">[32]</ref>, it is shown that for any input p and any non-negative constant ?, we have h(?p) is equal to ?h(p) if the feed-forward network uses ReLU as the activation function with no additive constant terms (bias) in any layer.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">If the number of color channels is more than one, i.e. C &gt; 1, we first compute the histogram loss between corresponding channels and then take the average of losses as the final histogram loss.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://brain-development.org/ixi-dataset</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://pypi.org/project/bm3d/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>We acknowledge the HPC resources by Bioinformatics Center, University of Eastern Finland. Data were provided in part by OASIS-3: PIs: T. Benzinger, D. Marcus, J. Morris; NIH P50 AG00561, P30 NS09857781, P01 AG026276, P01 AG003991, R01 AG043434, UL1 TR000448, R01 EB009352.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deepacson automated segmentation of white matter in 3d electron microscopy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abdollahzadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Belevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications biology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Noise conscious training of non local neural network powered by self attentive spectral normalized markovian patch gan for low dose ct denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biswas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3663" to="3673" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Cine cone beam ct reconstruction using low-rank matrix factorization: algorithm and a proof-of-principle study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1581" to="1591" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">An augmented lagrangian method for total variation video restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stanley H Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khoshabeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3097" to="3111" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Denoising of diffusion mri data via graph framelet matching in xq space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2838" to="2848" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Online interface to a 3d mri simulated brain database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cocosco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kollokian</surname></persName>
		</author>
		<ptr target="https://brainweb.bic.mni.mcgill.ca/" />
	</analytic>
	<monogr>
		<title level="m">NeuroImage. Citeseer, 1997. The dataset is available at</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-d transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Foi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Denoising of dynamic contrast-enhanced mr images using dynamic nonlocal means</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mehnert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="302" to="310" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rudin-osher-fatemi total variation denoising using split bregman</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Getreuer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Image Processing On Line</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="74" to="95" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Ffd: Fast feature detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghahremani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tiddeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="1153" to="1168" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Medical image denoising using convolutional denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gondara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE international conference on data mining workshops (ICDMW)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="241" to="246" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pouget-Abadie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Weighted averaging for denoising with overcomplete dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Onur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Guleryuz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3020" to="3034" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Noise-powered disentangled representation for unsupervised speckle reduction of optical coherence tomography images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2600" to="2614" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A review of denoising medical images using machine learning approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kaur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current medical imaging</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="675" to="685" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Identifying medical diagnoses and treatable diseases by image-based deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kermany</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Goldbaum</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia" />
	</analytic>
	<monogr>
		<title level="j">Cell</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1122" to="1131" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>The dataset is available at</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A new 4-d nonlocal transformdomain filter for 3-d magnetic resonance images denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="941" to="954" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Oasis-3: Longitudinal neuroimaging, clinical, and cognitive dataset for normal aging and alzheimer disease. medRxiv</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lamontagne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Benzinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Iscl: Interdependent self-cooperative learning for unpaired image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jeong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3238" to="3248" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Assessing the impact of deep neural networkbased image denoising on binary signal detection tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2295" to="2305" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Image restoration using swin transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1833" to="1844" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Applications of deep learning to mri images: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data Mining and Analytics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Cycle structure and illumination constrained gan for medical image enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on medical image computing and computer-assisted intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="667" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Nonlocal transform-domain filter for volumetric data denoising and reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maggioni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Katkovnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="133" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Non-local sparse models for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="2272" to="2279" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Collaborative filtering of correlated noise: Exact transform-domain variance for improved shrinkage and patch matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>M?kinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Azzari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Foi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="8339" to="8354" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Adaptive non-local means denoising of mr images with spatially varying noise levels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>V Manj?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Coup?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Magnetic Resonance Imaging</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="192" to="203" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Osindero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1411.1784</idno>
		<title level="m">Conditional generative adversarial nets</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kadkhodaie</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.05478</idno>
		<title level="m">Robust and interpretable blind image denoising via bias-free convolutional neural networks</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">A combined first and second order variational approach for image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papafitsoros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sch?nlieb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of mathematical imaging and vision</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="308" to="338" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Convolutional dictionary learning via local processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>V Papyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Romano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5296" to="5304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Removing imaging artifacts in electron microscopy using an asymmetrically cyclic adversarial network without paired training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Quan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hildebrand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3804" to="3813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">An unsupervised deep learning framework for medical image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Patra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.06575</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>O Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A review on medical image denoising algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Sagheer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>George</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedical signal processing and control</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page">102036</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A u-net based discriminator for generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Schonfeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khoreva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8207" to="8216" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning medical image denoising with deep dynamic residual attention network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Naqvi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biswas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">2192</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Image reconstruction in circular cone-beam computed tomography by constrained, total-variation minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sidky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics in Medicine &amp; Biology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page">4777</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">The undecimated wavelet decomposition and its reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Fadili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Murtagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="297" to="309" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Multi-modal deep guided filtering for comprehensible medical image processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Syben</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1703" to="1711" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Projected distribution loss for image enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Talebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Delbracio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Milanfar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Principal component wavelet networks for solving linear inverse problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tiddeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ghahremani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Symmetry</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1083</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">The HAM10000 dataset, a large collection of multisource dermatoscopic images of common pigmented skin lesions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Tschandl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">ReduceLROnPlateau -TensorFlow Core v2.8.0 documentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tensorflow</surname></persName>
		</author>
		<ptr target="https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ReduceLROnPlateau" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Structural similarity-based nonlocal variational models for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Im. Proc</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="4260" to="4272" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Mitoem dataset: Large-scale 3d mitochondria instance segmentation from em images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
		<ptr target="https://mitoem.grand-challenge.org/" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention, 2020. The dataset is available at</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Self-supervised dynamic ct perfusion image denoising with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Radiation and Plasma Medical Sciences</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="350" to="361" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Low-dose x-ray ct reconstruction via dictionary learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1682" to="1697" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Low-dose ct image denoising using a generative adversarial network with wasserstein distance and perceptual loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Med. Imaging</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1348" to="1357" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Knoll</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.08839</idno>
		<ptr target="https://fastmri.org/dataset/" />
	</analytic>
	<monogr>
		<title level="m">An open dataset and benchmarks for accelerated mri</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Plug-and-play image restoration with deep denoiser prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zuo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Image Process</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="3142" to="3155" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Statistical iterative reconstruction using adaptive fractional order regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biomedical optics express</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1015" to="1029" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Unpaired image-to-image translation using cycleconsistent adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2223" to="2232" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Texture enhanced image denoising via gradient histogram preservation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="1203" to="1210" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
