<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RobeCzech: Czech RoBERTa, a monolingual contextualized language representation model</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
							<email>straka@ufal.mff.cuni.cz</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Faculty of Mathematics and Physics</orgName>
								<orgName type="department" key="dep2">Institute of Formal and Applied Linguistics</orgName>
								<orgName type="institution">Charles University</orgName>
								<address>
									<addrLine>Malostransk? n?m. 25</addrLine>
									<postCode>118 00</postCode>
									<settlement>Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">RobeCzech: Czech RoBERTa, a monolingual contextualized language representation model</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1007/978-3-030-83527-9</idno>
					<note>This paper was published in TSD 2021 -please cite the published version https:// 17 instead.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:49+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>RobeCzech ? Czech RoBERTa ? RoBERTa</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present RobeCzech, a monolingual RoBERTa language representation model trained on Czech data. RoBERTa is a robustly optimized Transformer-based pretraining approach. We show that RobeCzech considerably outperforms equally-sized multilingual and Czech-trained contextualized language representation models, surpasses current state of the art in all five evaluated NLP tasks and reaches state-of-the-art results in four of them. The RobeCzech model is released publicly at https://hdl.handle.net/11234/1-3691 and https://huggingface.co/ufal/ robeczech-base.</p></div>
			</abstract>
		</profileDesc>
		<revisionDesc>
				<date type="submission" when="-1" />
		</revisionDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We introduce RobeCzech: Czech RoBERTa, a Czech contextualized language representation model based on the Transformer architecture and trained solely on Czech data. RobeCzech is a monolingual version of RoBERTa <ref type="bibr" target="#b23">[23]</ref>, a robustly optimized BERT <ref type="bibr" target="#b8">[8]</ref> pretraining approach.</p><p>In this paper, we describe the RobeCzech training process and we evaluate RobeCzech in comparison with current multilingual and Czech-trained contextualized language representation models: multilingual BERT <ref type="bibr" target="#b8">[8]</ref>, multilingual XLM-RoBERTa <ref type="bibr" target="#b5">[6]</ref> (base and large), Slavic BERT <ref type="bibr" target="#b0">[1]</ref> tuned on 4 Slavic languages, including Czech; and Czert <ref type="bibr" target="#b36">[36]</ref>, another monolingual, Czech BERT model.</p><p>We show that RobeCzech considerably outperforms all models of similar size, and at the same time, it reaches new state-of-the-art results in four NLP tasks: morphological tagging and lemmatization, dependency parsing, named entity recognition and semantic parsing. In the last evaluated task, the sentiment analysis, RobeCzech also improves over state of the art and delivers the best results of all models of similar size, only being surpassed by XLM-RoBERTa large <ref type="bibr" target="#b5">[6]</ref>, a model 4 times the size of all the other evaluated models ( <ref type="table" target="#tab_0">Table 1)</ref>.</p><p>We release the RobeCzech model for public use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Contextualized language representation models have recently accelerated progress in NLP. Significant advances have been reached particularly with Bidirectional Encoder Representations from Transformers, widely known as BERT <ref type="bibr" target="#b8">[8]</ref>, inspiring interest in Transformer-like architectures. We especially highlight RoBERTa <ref type="bibr" target="#b23">[23]</ref> and its derivation XLM-RoBERTa <ref type="bibr" target="#b5">[6]</ref>. The above mentioned language representation models were trained either only on English or as multilingual, though with an (implicit) strength in the most represented languages (i. e., English). Therefore, research has recently been focusing on monolingual BERT models, giving birth to national BERT mutations, e.g. French <ref type="bibr" target="#b26">[26]</ref>, Finnish <ref type="bibr" target="#b43">[43]</ref>, Romanian <ref type="bibr" target="#b27">[27]</ref> and Czech <ref type="bibr" target="#b36">[36]</ref>.</p><p>Our model is similar to the above mentioned Czert <ref type="bibr" target="#b36">[36]</ref> in the sense that it is also a Czech contextualized language representation model, but unlike Czert, which is based on BERT, we trained a Czech version of RoBERTa. According to both the original Czert results <ref type="bibr" target="#b36">[36]</ref> and the hereby presented evaluation on five NLP tasks, RobeCzech is better than Czert in all experiments by a considerable margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Training the Czech RoBERTa</head><p>We trained RobeCzech on a collection of the following publicly available texts:</p><p>-SYN v4 <ref type="bibr" target="#b21">[21]</ref>, a large corpus of contemporary written Czech, 4,188M tokens; -Czes <ref type="bibr" target="#b6">[7]</ref>, a collection of Czech newspaper and magazine articles, 432M tokens; documents with at least 400 tokens from the Czech part of the web corpus W2C <ref type="bibr" target="#b24">[24,</ref><ref type="bibr" target="#b25">25]</ref>, tokenized with MorphoDiTa <ref type="bibr" target="#b40">[40]</ref>, 16M tokens; plain texts extracted from Czech Wikipedia dump 20201020 using WikiExtractor, 1 tokenized with MorphoDiTa <ref type="bibr" target="#b40">[40]</ref>, 123M tokens. All these corpora contain whole documents, even if the SYN v4 is block-shuffled (blocks with at most 100 words respecting sentence boundaries are permuted in a document) and in total contain 4,917M tokens.</p><p>The texts are tokenized into subwords with a byte-level BPE (BBPE) tokenizer <ref type="bibr" target="#b33">[33]</ref>. The tokenizer is trained on the entire corpus and we limit its vocabulary size to 52,000 items.</p><p>The RobeCzech model is trained using the official code released in the Fairseq library. <ref type="bibr" target="#b1">2</ref> The training batch size is <ref type="bibr" target="#b8">8,</ref><ref type="bibr">192</ref> and each training batch consists of sentences sampled contiguously, even across document boundaries, such that the total length of each sample is at most 512 tokens (FULL-SENTENCES setting <ref type="bibr" target="#b23">[23]</ref>). We use Adam optimizer <ref type="bibr" target="#b16">[16]</ref> with ? 1 = 0.9 and ? 2 = 0.98 to minimize the masked language-modeling objective. The learning rate is adapted using the polynomial decay schema with 10,000 warmup updates and the peak learning rate set to 7 ? 10 ?4 . A total amount of 91,075 optimization steps were performed, which took approximately 3 months on 8 QUADRO P5000 GPU cards. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>Embedding Transformer Total Parameters</p><formula xml:id="formula_0">mBERT uncased 82M 85M 167M Czert 24M 85M 109M Slavic BERT 92M 85M 177M XLM-R base 192M 85M 277M XLM-R large 257M 302M 559M RobeCzech 40M 85M 125M</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Tasks</head><p>We evaluate our Czech RoBERTa model on five NLP tasks in comparison with a variety of recently proposed mono-and multi-lingual contextualized language representation models (to our best knowledge, these are all publicly available models trained at least partially on Czech): -mBERT <ref type="bibr" target="#b8">[8]</ref>: well-known multilingual BERT language representation model.</p><p>-Czert <ref type="bibr" target="#b36">[36]</ref>: the first Czech monolingual model based on BERT.</p><p>-Slavic BERT <ref type="bibr" target="#b0">[1]</ref>: multilingual BERT tuned specifically for NER on 4 Slavic languages data (Russian, Bulgarian, Czech and Polish). -XLM-RoBERTa <ref type="bibr" target="#b5">[6]</ref>, base and large: multilingual contextualized representations trained at large scale. Except for XLM-RoBERTa large, which is 4 times larger than others, all models are of base size <ref type="bibr" target="#b8">[8]</ref>, see <ref type="table" target="#tab_0">Table 1</ref>.</p><p>We evaluate RobeCzech in five NLP tasks, three of them leveraging frozen contextualized word embeddings, two approached with fine-tuning:</p><p>-morphological analysis and lemmatization: frozen contextualized word embeddings, -dependency parsing: frozen contextualized word embeddings, -named entity recognition: frozen contextualized word embeddings, -semantic parsing: fine-tuned, -sentiment analysis: fine-tuned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Morphological Tagging and Lemmatization on PDT 3.5</head><p>Dataset We evaluate the morphological POS tagging and lemmatization on the morphological layer of the Prague Dependency Treebank 3.5 <ref type="bibr" target="#b14">[14]</ref>.</p><p>Metric The morphological POS tagging and lemmatization is evaluated using accuracy.</p><p>Architecture We adopt the UDPipe 2 architecture <ref type="bibr" target="#b38">[38]</ref>, reproducing the methodology of <ref type="bibr" target="#b39">[39]</ref>. After embedding input words, three bidirectional LSTM layers <ref type="bibr" target="#b15">[15]</ref> are applied, followed by a softmax classification layer for POS and lemmas. In case of lemmas, the network predicts a simple edit script from input form to desired lemma. Since edit patterns are shared between lemmas due to regularities in morphology, the output categorization layer is reduced from the full vocabulary to only 1568 classes (in PDT 3.5 <ref type="bibr" target="#b14">[14]</ref>). In all our experiments, we use the same word embeddings as <ref type="bibr" target="#b39">[39]</ref>: pretrained word2vec embeddings <ref type="bibr" target="#b28">[28]</ref>, end-to-end word embeddings and character-level word embeddings <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b22">22]</ref>. The contextualized word embeddings are used frozen-style as additional inputs to the neural network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Dependency Parsing on PDT 3.5</head><p>Dataset We evaluate the dependency parsing on the analytical layer of the Prague Dependency Treebank 3.5 <ref type="bibr" target="#b14">[14]</ref>.</p><p>Metric In evaluation, we compute both the unlabeled attachment score (UAS) and labeled attachment score (LAS).</p><p>Architecture We perform dependency parsing jointly with POS tagging and lemmatization, following the experiments of <ref type="bibr" target="#b39">[39]</ref> showing that this approach is superior to using predicted POS tags and lemmas on input. We utilize the UDPipe 2 architecture <ref type="bibr" target="#b39">[39]</ref>: after embeddings input words and three bidirectional LSTM layers <ref type="bibr" target="#b15">[15]</ref>, a biaffine attention layer <ref type="bibr" target="#b10">[10]</ref> produces labeled dependency trees. The input word embeddings are the same as in the previous Section 4.1 and the contextualized word embeddings are additionally concatenated to the baseline input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Morphosyntactic Analysis on Universal Dependencies</head><p>Dataset We further evaluate the joint morphosyntactic analysis on the UD Czech PDT treebank of the Universal Dependencies 2.3 <ref type="bibr" target="#b30">[30]</ref>.</p><p>Metric We use the standard evaluation script from CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies <ref type="bibr" target="#b45">[45]</ref>, which produces the following metrics:</p><p>-UPOS -universal POS tags accuracy, -XPOS -language-specific POS tags accuracy, -UFeats -universal subset of morphological features accuracy, -Lemmas -lemmatization accuracy, -UAS -unlabeled attachment score, LAS -labeled attachment score, -MLAS -morphology-aware LAS, BLEX -bi-lexical dependency score.</p><p>Architecture Following Section 4.2, we employ the UDPipe 2 <ref type="bibr" target="#b39">[39]</ref> architecture with frozen contextualized word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Named Entity Recognition</head><p>Dataset We evaluate the Czech NER on all versions of the Czech Named Entity Corpus, both the original <ref type="bibr" target="#b35">[35]</ref> with nested entities and the CoNLL version <ref type="bibr" target="#b19">[19]</ref> with reduction to flat entities only.</p><p>Metric The standard evaluation metric for NER is F1 score computed over detected named entities spans.</p><p>Architecture We reproduce the the current NER SoTA architecture <ref type="bibr" target="#b41">[41]</ref>, using the LSTM-CRF and seq2seq variants for flat and nested NER, respectively. All experiments include the Czech FastText word embeddings <ref type="bibr" target="#b3">[4]</ref> of dimension 300, end-to-end trained word embeddings and character-level word embeddings <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b11">11,</ref><ref type="bibr" target="#b22">22]</ref> as inputs to the network. The contextualized word embeddings are used as frozen, additional inputs to the network.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Semantic Parsing on Prague Tectogrammatical Graphs</head><p>Dataset We use the Prague Tectogrammatical Graphs (PTG) provided for the CoNLL 2020 shared task, Cross-Framework Meaning Representation Parsing (MRP 2020) <ref type="bibr" target="#b31">[31]</ref>. The original annotation comes from the tectogrammatical layer of the Prague Dependency Treebank <ref type="bibr" target="#b14">[14]</ref>; the graphs for the shared task were obtained by relaxing its original limitation to trees -for example by explicitly modeling co-reference by additional edges instead of special node attributes <ref type="bibr" target="#b44">[44]</ref>.</p><p>Metric We employ the official metric from MRP 2020, which first finds the maximum common edge subgraph to align the evaluated and the target graph. Then, it computes the micro-averaged F1 score over different features of the semantic graphs -top nodes, node labels, node properties, anchors, edges between nodes and edge attributes.</p><p>Architecture We reimplement the current SoTA architecture for PTG parsing called PERIN <ref type="bibr" target="#b34">[34]</ref>. This model does not assume any hard-coded ordering of the graph nodes, but instead dynamically finds the best matching between the predicted and the target ones. Following UDify <ref type="bibr" target="#b17">[17]</ref>, we compute the contextualized subword embedding by taking the weighted sum of all hidden layers in a language representation model. The scalar weight for each layer is a learnable parameter. To obtain a single embedding for every token, we sum the embeddings of all its subwords. Finally, the summed embeddings are normalized with layer normalization <ref type="bibr" target="#b2">[3]</ref> to stabilize the training.</p><p>The pretrained encoder is finetuned with a lower learning rate than the rest of the model. The learning rate follows the inverse square root schedule with warmup and is frozen for the first 2000 steps before the warmup starts. The warmup phase takes 6000 steps and the learning rate peak is 6 ? 10 ?5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Sentiment Analysis</head><p>Dataset We evaluate sentiment analysis on Czech Facebook dataset (CFD) <ref type="bibr" target="#b12">[12,</ref><ref type="bibr" target="#b13">13]</ref>. This dataset contains 2,587 positive, 5,174 neutral and 1,991 negative posts (the 248 bipolar posts are ignored, following <ref type="bibr" target="#b13">[13,</ref><ref type="bibr" target="#b36">36]</ref>).</p><p>Metric The performance is evaluated using macro-averaged F1 score. Because the dataset has no designed test set, we follow the approach of the dataset authors <ref type="bibr" target="#b13">[13]</ref> and perform 10-fold cross-validation, reporting mean and standard deviation of the folds' F1 scores. Architecture We employ the standard text classification architecture consisting of a BERT encoder, followed by a softmax-activated classification layer processing the computed embedding of the given document text obtained from the CLS token embedding from the last layer <ref type="bibr" target="#b8">[8,</ref><ref type="bibr" target="#b23">23]</ref>. We train the models using a lazy variant of the Adam optimizer <ref type="bibr" target="#b16">[16]</ref> with a batch size of 64. During the first epoch, the BERT encoder is frozen and only the classifier is trained with the default learning rate of 10 ?3 . From the second epoch, the whole model is updated, starting by 4 epochs of cosine warm-up from zero to a specified peak learning rate, followed by 10 epochs of cosine decay back to zero.</p><p>We consider peak learning rates 10 ?5 , 2 ? 10 ?5 , 3 ? 10 ?5 and 5 ? 10 ?5 . In order to choose the peak learning rate, we put aside random 10% of the train data for each fold as a development set and evaluate each trained model on its corresponding development set. Finally, we choose a single peak learning rate for every model according to the 10-fold means of the development macro-averaged F1 scores. The selected peak learning rates are reported for each evaluated model. <ref type="table" target="#tab_1">Table 2</ref> summarizes the overall results of all considered language representation models in all evaluated tasks. RobeCzech improves over current state of the art in all five evaluated NLP tasks, and at the same time, clearly outperforms current multilingual and Czech-trained contextualized language representation models, being surpassed only in one of the five tasks by a model 4 times its size (XLM-RoBERTa large <ref type="bibr" target="#b5">[6]</ref>, <ref type="table" target="#tab_1">Table 2</ref>). Notably, RobeCzech reaches 25% error reduction in POS tagging both on PDT 3.5 and UD 2.3, and 15% error reduction in dependency parsing on PDT 3.5, significantly improving performance of Czech morphosyntactic analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Furthermore, for each of the evaluated tasks, we show the detailed results in <ref type="table">Tables 3, 4</ref>, 5, 6, 7 and 8.</p><p>The results demonstrate that the large variant of XLM-RoBERTa reaches considerably better results compared to base size of other multilingual models.  Yet, RobeCzech still surpasses it on four tasks, most notably in the frozen scenario. We hypothesize that in the frozen scenario the larger model cannot capitalize on its superior capacity, compared to for example sentiment analysis, where its capacity proves determining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We introduced RobeCzech, a Czech contextualized language representation model based on RoBERTa. We described the training process and we evaluated RobeCzech in comparison with, to our best knowledge, currently known multilingual and Czech-trained contextualized language representation models. We show that RobeCzech considerably improves over state of the art in all five evaluated NLP tasks. Notably, it yields 25% error reduction in POS tagging both on PDT 3.5 and UD 2.3 and 15% error reduction in dependency parsing on PDT 3.5. We publish RobeCzech publicly at https://hdl.handle.net/11234/1-3691 and https://huggingface.co/ufal/robeczech-base.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Number of parameters.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Overall results.</figDesc><table><row><cell></cell><cell cols="2">Morphosynt. Morphosynt.</cell><cell>NER</cell><cell cols="2">Semant. Sentim.</cell></row><row><cell></cell><cell>PDT3.5</cell><cell>UD2.3</cell><cell>CNEC1.1</cell><cell>PTG</cell><cell>CFD</cell></row><row><cell></cell><cell cols="3">POS LAS XPOS LAS nested flat</cell><cell>Avg.</cell><cell>F1</cell></row><row><cell>mBERT</cell><cell>98.00 89.74</cell><cell cols="2">97.61 92.34 86.71 86.45</cell><cell>90.62</cell><cell>75.43</cell></row><row><cell>Czert</cell><cell>98.43 90.68</cell><cell cols="2">98.07 93.13 85.38 84.69</cell><cell>90.66</cell><cell>78.52</cell></row><row><cell>Slavic BERT</cell><cell>97.70 88.50</cell><cell cols="2">97.29 91.49 85.85 85.12</cell><cell>91.27</cell><cell>74.85</cell></row><row><cell>XLM-R base</cell><cell>97.62 88.14</cell><cell cols="2">97.29 91.30 83.25 82.76</cell><cell>91.55</cell><cell>79.40</cell></row><row><cell>XLM-R large</cell><cell>98.41 91.27</cell><cell cols="2">98.15 93.49 87.41 86.86</cell><cell>92.11</cell><cell>82.29</cell></row><row><cell>RobeCzech</cell><cell cols="4">98.50 91.42 98.31 93.77 87.82 87.47 92.36</cell><cell>80.13</cell></row><row><cell cols="2">previous SoTA 98.05 89.89</cell><cell cols="2">97.71 93.38 86.88 86.57</cell><cell>92.24</cell><cell>76.55</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .Table 4 .Table 5 .</head><label>345</label><figDesc>Morpological tagging and lemmatization on PDT3.5. Dependency parsing on PDT3.5. Morphosyntactic analysis on UD 2.3. Models marked f are fine-tuned, otherwise with frozen embeddings.</figDesc><table><row><cell>Model</cell><cell></cell><cell cols="8">Without Dictionary POS Lemmas Both POS Lemmas Both With Dictionary</cell></row><row><cell>mBERT</cell><cell></cell><cell>97.86</cell><cell>98.69</cell><cell cols="2">97.21 98.00</cell><cell></cell><cell></cell><cell>98.96</cell><cell>97.59</cell></row><row><cell>Czert</cell><cell></cell><cell>98.30</cell><cell>98.73</cell><cell cols="2">97.65 98.43</cell><cell></cell><cell></cell><cell>98.98</cell><cell>98.02</cell></row><row><cell>Slavic BERT</cell><cell></cell><cell>97.51</cell><cell>98.58</cell><cell cols="2">96.81 97.70</cell><cell></cell><cell></cell><cell>98.89</cell><cell>97.27</cell></row><row><cell>XLM-R base</cell><cell></cell><cell>97.43</cell><cell>98.56</cell><cell cols="2">96.76 97.62</cell><cell></cell><cell></cell><cell>98.85</cell><cell>97.20</cell></row><row><cell>XLM-R large</cell><cell></cell><cell>98.30</cell><cell>98.76</cell><cell cols="2">97.69 98.41</cell><cell></cell><cell></cell><cell>98.98</cell><cell>98.01</cell></row><row><cell>RobeCzech</cell><cell></cell><cell>98.43</cell><cell>98.79</cell><cell cols="3">97.83 98.50</cell><cell cols="2">99.00</cell><cell>98.11</cell></row><row><cell>Mor?e (2009) [37]</cell><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>95.67</cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">MorphoDiTa (2016) [40]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>95.55</cell><cell></cell><cell></cell><cell>97.85</cell><cell>95.06</cell></row><row><cell cols="2">LemmaTag (2018) [18]</cell><cell>96.90</cell><cell>98.37</cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell></row><row><cell cols="3">UDPipe 2+mBERT+Flair [39] 97.94</cell><cell>98.75</cell><cell cols="2">97.31 98.05</cell><cell></cell><cell></cell><cell>98.98</cell><cell>97.65</cell></row><row><cell>Model</cell><cell></cell><cell></cell><cell cols="2">UAS LAS</cell><cell cols="4">Joint POS Lemmas Joint</cell></row><row><cell>mBERT</cell><cell></cell><cell></cell><cell cols="3">93.01 89.74 97.62</cell><cell></cell><cell></cell><cell>98.49</cell></row><row><cell>Czert</cell><cell></cell><cell></cell><cell cols="3">93.57 90.68 98.10</cell><cell></cell><cell></cell><cell>98.53</cell></row><row><cell>Slavic BERT</cell><cell></cell><cell></cell><cell cols="3">92.14 88.50 97.20</cell><cell></cell><cell></cell><cell>98.29</cell></row><row><cell>XLM-R base</cell><cell></cell><cell></cell><cell cols="3">91.80 88.14 97.22</cell><cell></cell><cell></cell><cell>98.34</cell></row><row><cell>XLM-R large</cell><cell></cell><cell></cell><cell cols="3">94.07 91.27 98.12</cell><cell></cell><cell></cell><cell>98.54</cell></row><row><cell>RobeCzech</cell><cell></cell><cell></cell><cell cols="3">94.14 91.42 98.28</cell><cell></cell><cell cols="2">98.62</cell></row><row><cell cols="6">UDPipe 2+mBERT+Flair [39] 93.07 89.89 97.72</cell><cell></cell><cell></cell><cell>98.51</cell></row><row><cell>Model</cell><cell cols="9">UPOS XPOS UFeats Lemmas UAS LAS MLAS BLEX</cell></row><row><cell>mBERT</cell><cell cols="3">99.31 97.61 97.55</cell><cell cols="6">99.06 94.27 92.34 87.75 89.91</cell></row><row><cell>Czert</cell><cell cols="3">99.32 98.07 98.05</cell><cell cols="6">99.09 94.75 93.13 89.19 90.92</cell></row><row><cell>Slavic BERT</cell><cell cols="3">99.22 97.29 97.22</cell><cell cols="6">98.99 93.53 91.49 86.37 88.79</cell></row><row><cell>XLM-R base</cell><cell cols="3">99.18 97.29 97.24</cell><cell cols="6">99.02 93.32 91.30 86.18 88.62</cell></row><row><cell>XLM-R large</cell><cell cols="3">99.36 98.15 98.10</cell><cell cols="6">99.17 95.15 93.49 89.64 91.40</cell></row><row><cell>RobeCzech</cell><cell cols="3">99.36 98.31 98.28</cell><cell cols="6">99.18 95.36 93.77 90.18 91.82</cell></row><row><cell>UDPipe 2 +mBERT+Flair [39]</cell><cell cols="3">99.34 97.71 97.67</cell><cell cols="6">99.12 94.43 92.56 88.09 90.22</cell></row><row><cell>UDify f [17]</cell><cell>99.24</cell><cell>-</cell><cell>94.77</cell><cell cols="4">98.93 95.07 93.38</cell><cell>-</cell><cell>-</cell></row><row><cell>Czert f [36]</cell><cell>99.30</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell></cell><cell>-</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 6 .Table 7 .Table 8 .</head><label>678</label><figDesc>Named entity recognition F1 scores (3 runs average) in comparison with previous reports. Models marked f are fine-tuned, otherwise with frozen embeddings. Semantic parsing F1 scores on Prague Tectogrammatical Graphs. Sentiment analysis 10-fold macro F1 scores on Czech Facebook dataset.</figDesc><table><row><cell>Model</cell><cell cols="4">CNEC1.1 CNEC2.0</cell><cell cols="2">CoNLL CNEC1.1</cell><cell>CoNLL CNEC2.0</cell></row><row><cell>mBERT</cell><cell></cell><cell>86.71</cell><cell>84.21</cell><cell></cell><cell></cell><cell>86.45</cell><cell>87.04</cell></row><row><cell>Czert</cell><cell></cell><cell>85.38</cell><cell>82.84</cell><cell></cell><cell></cell><cell>84.69</cell><cell>85.33</cell></row><row><cell>Slavic BERT</cell><cell></cell><cell>85.85</cell><cell>82.71</cell><cell></cell><cell></cell><cell>85.12</cell><cell>85.28</cell></row><row><cell>XLM-R base</cell><cell></cell><cell>83.25</cell><cell>80.33</cell><cell></cell><cell></cell><cell>82.76</cell><cell>82.85</cell></row><row><cell>XLM-R large</cell><cell></cell><cell>87.41</cell><cell>84.46</cell><cell></cell><cell></cell><cell>86.86</cell><cell>87.06</cell></row><row><cell>RobeCzech</cell><cell></cell><cell>87.82</cell><cell>85.51</cell><cell></cell><cell></cell><cell>87.47</cell><cell>87.49</cell></row><row><cell cols="2">seq2seq+mBERT [39,41]</cell><cell>86.73</cell><cell>84.66</cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">seq2seq+mBERT+Flair [39,41]</cell><cell>86.88</cell><cell>84.27</cell><cell></cell><cell></cell><cell>-</cell><cell>-</cell></row><row><cell>LSTM-CRF, LDA [20]</cell><cell></cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell>81.77</cell><cell>-</cell></row><row><cell>LSTM-CRF [42]</cell><cell></cell><cell>83.15</cell><cell>-</cell><cell></cell><cell></cell><cell>83.27</cell><cell>84.22</cell></row><row><cell cols="2">LSTM-CRF+BERT [29]</cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell><cell>86.39</cell></row><row><cell>Czert f [36]</cell><cell></cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell>86.27</cell><cell>-</cell></row><row><cell>mBERT f [8], by [36]</cell><cell></cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell>86.23</cell><cell>-</cell></row><row><cell cols="2">Slavic BERT f [1], by [36]</cell><cell>-</cell><cell>-</cell><cell></cell><cell></cell><cell>86.57</cell><cell>-</cell></row><row><cell>Model</cell><cell cols="7">Labels Properties Anchors Edges Attributes Average</cell></row><row><cell>mBERT</cell><cell>95.72</cell><cell>92.60</cell><cell>97.20</cell><cell cols="2">80.77</cell><cell>72.83</cell><cell>90.62</cell></row><row><cell>Czert</cell><cell>95.72</cell><cell>92.69</cell><cell>97.23</cell><cell cols="2">80.91</cell><cell>72.37</cell><cell>90.66</cell></row><row><cell>Slavic BERT</cell><cell>95.92</cell><cell>92.91</cell><cell>97.51</cell><cell cols="2">82.48</cell><cell>75.08</cell><cell>91.27</cell></row><row><cell>XLM-R base</cell><cell>96.09</cell><cell>93.12</cell><cell>97.60</cell><cell cols="2">83.03</cell><cell>76.16</cell><cell>91.55</cell></row><row><cell>XLM-R large</cell><cell>96.42</cell><cell>93.31</cell><cell>97.92</cell><cell cols="2">84.46</cell><cell>77.89</cell><cell>92.11</cell></row><row><cell>RobeCzech frozen</cell><cell>95.85</cell><cell>92.76</cell><cell>97.41</cell><cell cols="2">82.60</cell><cell>74.95</cell><cell>91.23</cell></row><row><cell>RobeCzech</cell><cell>96.57</cell><cell>93.58</cell><cell>97.97</cell><cell cols="2">84.92</cell><cell>78.29</cell><cell>92.36</cell></row><row><cell>HUJI-KU+mBERT [2]</cell><cell>-</cell><cell>72.44</cell><cell>72.10</cell><cell cols="2">44.91</cell><cell>-</cell><cell>58.49</cell></row><row><cell>HIT-SCIR+mBERT [9]</cell><cell>84.14</cell><cell>79.01</cell><cell>92.34</cell><cell cols="2">64.96</cell><cell>47.68</cell><cell>77.93</cell></row><row><cell>Hitachi+mBERT [32]</cell><cell>87.69</cell><cell>91.48</cell><cell>93.99</cell><cell cols="2">76.90</cell><cell>66.07</cell><cell>87.35</cell></row><row><cell cols="2">UFAL+XLM-R large [34] 96.23</cell><cell>93.56</cell><cell>97.86</cell><cell cols="2">84.61</cell><cell>78.62</cell><cell>92.24</cell></row><row><cell>Model</cell><cell cols="2">10-fold Macro F1</cell><cell cols="3">10-fold Std</cell><cell cols="2">Chosen LR</cell></row><row><cell>mBERT</cell><cell cols="2">75.43</cell><cell cols="2">?1.38</cell><cell></cell><cell cols="2">5 ? 10 ?5</cell></row><row><cell>Czert</cell><cell cols="2">78.52</cell><cell cols="2">?1.16</cell><cell></cell><cell cols="2">2 ? 10 ?5</cell></row><row><cell>Slavic BERT</cell><cell cols="2">74.85</cell><cell cols="2">?1.27</cell><cell></cell><cell cols="2">5 ? 10 ?5</cell></row><row><cell>XLM-R base</cell><cell cols="2">79.40</cell><cell cols="2">?1.07</cell><cell></cell><cell cols="2">1 ? 10 ?5</cell></row><row><cell>XLM-R large</cell><cell cols="2">82.29</cell><cell cols="2">?1.19</cell><cell></cell><cell cols="2">1 ? 10 ?5</cell></row><row><cell>RobeCzech</cell><cell cols="2">80.13</cell><cell cols="2">?1.21</cell><cell></cell><cell cols="2">3 ? 10 ?5</cell></row><row><cell>Czert [36]</cell><cell cols="2">76.55</cell><cell>-</cell><cell></cell><cell></cell><cell cols="2">3 ? 10 ?6</cell></row><row><cell>MaxEnt [13]</cell><cell>69.4</cell><cell></cell><cell>-</cell><cell></cell><cell></cell><cell>-</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/attardi/wikiextractor 2 https://github.com/pytorch/fairseq/blob/master/examples/roberta/</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The research described herein has been supported by the Czech Science Founda </p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tuning Multilingual Transformers for Language-Specific Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arkhipov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Trofimova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kuratov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sorokin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 7th Workshop on Balto-Slavic Natural Language Processing</title>
		<meeting>the 7th Workshop on Balto-Slavic Natural Language Processing<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08" />
			<biblScope unit="page" from="89" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">HUJI-KU at MRP 2020: Two Transition-based Neural Parsers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Arviv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hershcovich</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.conll-shared.7</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.conll-shared.7" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</title>
		<meeting>the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</meeting>
		<imprint>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="73" to="82" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<title level="m">Layer normalization</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Enriching Word Vectors with Subword Information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merrienboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bahdanau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Unsupervised Cross-lingual Representation Learning at Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chaudhary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wenzek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Guzm?n</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="8440" to="8451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Czes</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11858/00-097C-0000-0001-CCCF-C" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<title level="m">LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (?FAL), Faculty of Mathematics and Physics</title>
		<imprint/>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">HIT-SCIR at MRP 2020: Transition-based Parser and Iterative Inference Parser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.conll-shared.6</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.conll-shared.6" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</title>
		<meeting>the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Deep Biaffine Attention for Neural Dependency Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno>abs/1611.01734</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Framewise phoneme classification with bidirectional LSTM and other neural network architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="page" from="5" to="6" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Facebook data for sentiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pt??ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinberger</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11858/00-097C-0000-0022-FE82-7" />
	</analytic>
	<monogr>
		<title level="m">LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (?FAL), Faculty of Mathematics and Physics</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Sentiment Analysis in Czech Social Media Using Supervised Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pt??ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Steinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</title>
		<meeting>the 4th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis<address><addrLine>Atlanta, Georgia</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06" />
			<biblScope unit="page" from="65" to="74" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haji?</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11234/1-2621" />
	</analytic>
	<monogr>
		<title level="m">LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics (?FAL), Faculty of Mathematics and Physics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Long Short-Term Memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">75 Languages, 1 Model: Parsing Universal Dependencies Universally</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kondratyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1279</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1279" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11" />
			<biblScope unit="page" from="2779" to="2795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">LemmaTag: Jointly Tagging and Lemmatizing for Morphologically Rich Languages with BRNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kondratyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gaven?iak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haji?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4921" to="4928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">CRF-Based Czech Named Entity Recognizer and Consolidation of Czech NER Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Konkol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Konop?k</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013-09" />
			<biblScope unit="page" from="153" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Konop?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Praz?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hor?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kopecek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text, Speech, and Dialogue -21st International Conference</title>
		<editor>Pala, K.</editor>
		<meeting><address><addrLine>Brno, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-09-11" />
			<biblScope unit="volume">11107</biblScope>
			<biblScope unit="page" from="58" to="66" />
		</imprint>
	</monogr>
	<note>LDA in Character-LSTM-CRF Named Entity Recognition</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>K?en</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cvr?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>?apka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>?erm?kov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hn?tkov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chlumsk?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jel?nek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kov???kov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Petkevi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Proch?zka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Skoumalov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>?krabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Trune?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vond?i?ka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zasina</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11234/1-1846" />
		<title level="m">LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (?FAL), Faculty of Mathematics and Physics</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
	<note>SYN v4: large corpus of written Czech</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lu?s</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Marujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Astudillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Amir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Trancoso</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>abs/1907.11692</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Majli?</surname></persName>
		</author>
		<idno>11858/ 00-097C-0000-0022-6133-9</idno>
		<ptr target="http://hdl.handle.net/" />
		<title level="m">LINDAT/CLARIAH-CZ digital library at the Institute of Formal and Applied Linguistics (?FAL), Faculty of Mathematics and Physics</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
	<note>W2C -Web to Corpus -Corpora</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Language richness of the web</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Majli?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>?abokrtsk?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<meeting>the Eighth International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-05" />
			<biblScope unit="page" from="2927" to="2934" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">CamemBERT: a Tasty French Language Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Ortiz Su?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>De La Clergerie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="7203" to="7219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">RoBERT -A Romanian BERT Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Masala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ruseti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dascalu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics<address><addrLine>Barcelona, Spain (Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-12" />
			<biblScope unit="page" from="6626" to="6637" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?t?p?n</forename><surname>M?ller</surname></persName>
		</author>
		<title level="m">Text Summarization Using Named Entity Recognition. Master&apos;s thesis</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
		<respStmt>
			<orgName>Czech Technical University in Prague</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/11234/1-2895" />
	</analytic>
	<monogr>
		<title level="m">LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics (?FAL), Faculty of Mathematics and Physics</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
		<respStmt>
			<orgName>Charles University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">MRP 2020: The Second Shared Task on Cross-Framework and Cross-Lingual Meaning Representation Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Abend</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Abzianidze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hajic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hershcovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>O&amp;apos;gorman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeman</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.conll-shared.1</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.conll-shared.1" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</title>
		<meeting>the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Hitachi at MRP 2020: Text-to-Graph-Notation Transducer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ozaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Morio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Koreeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Morishita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyoshi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.conll-shared.4</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.conll-shared.4" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</title>
		<meeting>the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="40" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">OpenAI blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">?FAL at MRP 2020: Permutation-invariant Semantic Parsing in PERIN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Samuel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</title>
		<meeting>the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="53" to="64" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Named Entities in Czech: Annotating Data and Developing NE Tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>?ev??kov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>?abokrtsk?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kr?za</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 10th International Conference on Text, Speech and Dialogue</title>
		<editor>Matou?ek, V., Mautner, P.</editor>
		<meeting>the 10th International Conference on Text, Speech and Dialogue<address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">4629</biblScope>
			<biblScope unit="page" from="188" to="195" />
		</imprint>
	</monogr>
	<note>Lecture Notes in Computer Science</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Pra??k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>P?ib??</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pa?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sej?k</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Konop?k</surname></persName>
		</author>
		<title level="m">Czert -Czech BERT-like Model for Language Representation</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Semi-Supervised Training for the Averaged Perceptron POS Tagger</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Spoustov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haji?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Raab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Spousta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Conference of the European Chapter</title>
		<meeting>the 12th Conference of the European Chapter</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009-03" />
			<biblScope unit="page" from="763" to="771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">UDPipe 2.0 Prototype at CoNLL 2018 UD Shared Task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of CoNLL 2018: The SIGNLL Conference on Computational Natural Language Learning</title>
		<meeting>CoNLL 2018: The SIGNLL Conference on Computational Natural Language Learning<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="197" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Czech Text Processing with Contextual Embeddings: POS Tagging, Lemmatization, Parsing and NER</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Strakov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haji?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 22nd International Conference on Text</title>
		<meeting>the 22nd International Conference on Text</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="137" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Open-Source Tools for Morphology, Lemmatization, POS Tagging and Named Entity Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Strakov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haji?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Baltimore, MD, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="13" to="18" />
		</imprint>
		<respStmt>
			<orgName>Johns Hopkins University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Neural Architectures for Nested NER through Linearization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Strakov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haji?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5326" to="5331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Hlubok? u?en? v automatick? anal?z? cesk?ho textu</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Strakov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haji?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Slovo a slovesnost</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="306" to="327" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Multilingual is not enough: BERT for Finnish</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Virtanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ilo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luoma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luotolahti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salakoski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<idno>abs/1912.07076</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">FGD at MRP 2020: Prague Tectogrammatical Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hajic</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.conll-shared.3</idno>
		<ptr target="https://doi.org/10.18653/v1/2020.conll-shared.3" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</title>
		<meeting>the CoNLL 2020 Shared Task: Cross-Framework Meaning Representation Parsing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-11" />
			<biblScope unit="page" from="33" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zeman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haji?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ginter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Petrov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies</title>
		<meeting>the CoNLL 2018 Shared Task: Multilingual Parsing from Raw Text to Universal Dependencies<address><addrLine>Brussels; Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-10" />
			<biblScope unit="page" from="1" to="21" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
