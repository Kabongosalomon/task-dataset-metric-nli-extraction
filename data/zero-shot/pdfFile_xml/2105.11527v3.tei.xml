<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Unsupervised Visual Representation Learning by Online Constrained K-Means</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<postCode>98004</postCode>
									<settlement>Bellevue</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhong</forename><surname>Xu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhua</forename><surname>Hu</surname></persName>
							<email>juhuah@uw.edu</email>
							<affiliation key="aff2">
								<orgName type="department">School of Engineering and Technology</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<postCode>98402</postCode>
									<settlement>Tacoma</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Alibaba Group</orgName>
								<address>
									<settlement>Hangzhou</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
							<email>jinrong.jr@alibaba-inc.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Alibaba Group</orgName>
								<address>
									<postCode>98004</postCode>
									<settlement>Bellevue</settlement>
									<region>WA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Unsupervised Visual Representation Learning by Online Constrained K-Means</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T03:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cluster discrimination is an effective pretext task for unsupervised representation learning, which often consists of two phases: clustering and discrimination. Clustering is to assign each instance a pseudo label that will be used to learn representations in discrimination. The main challenge resides in clustering since prevalent clustering methods (e.g., k-means) have to run in a batch mode. Besides, there can be a trivial solution consisting of a dominating cluster. To address these challenges, we first investigate the objective of clustering-based representation learning. Based on this, we propose a novel clustering-based pretext task with online Constrained K-means (CoKe). Compared with the balanced clustering that each cluster has exactly the same size, we only constrain the minimal size of each cluster to flexibly capture the inherent data structure. More importantly, our online assignment method has a theoretical guarantee to approach the global optimum. By decoupling clustering and discrimination, CoKe can achieve competitive performance when optimizing with only a single view from each instance. Extensive experiments on Im-ageNet and other benchmark data sets verify both the efficacy and efficiency of our proposal. Code is available at https://github.com/idstcv/CoKe.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Recently, many research efforts have been devoted to unsupervised representation learning that aims to leverage the massive unlabeled data to obtain applicable models. Different from supervised learning, where labels can provide an explicit discrimination task for learning, designing an appropriate pretext task is essential for unsupervised representation learning. Many pretext tasks have been proposed, e.g., instance discrimination <ref type="bibr" target="#b11">[12]</ref>, cluster discrimination <ref type="bibr" target="#b2">[3]</ref>, invariant mapping <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b15">16]</ref>, solving jigsaw puzzles <ref type="bibr" target="#b27">[28]</ref>, patch inpainting <ref type="bibr" target="#b28">[29]</ref>, etc. Among them, instance discrimination that identifies each instance as an individual class <ref type="bibr" target="#b11">[12]</ref> is  <ref type="figure">Figure 1</ref>. Illustration of CoKe. When a mini-batch arrives, each instance will be assigned to a cluster with our online assignment method. Then, in epoch t, representations from the encoder network are optimized by discrimination using pseudo labels and cluster centers obtained from epoch t ? 1. The pseudo labels from epoch t ? 1 were stored to be retrieved in epoch t using the unique id for each image. popular due to its straightforward objective. However, this pretext task can be intractable on large-scale data sets. Consequently, contrastive learning is developed to mitigate the large-scale challenge <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b37">38]</ref> with a memory bank <ref type="bibr" target="#b16">[17]</ref> or training with a large mini-batch of instances <ref type="bibr" target="#b5">[6]</ref>, which requires additional computation resources.</p><p>Besides instance discrimination, cluster discrimination is also an effective pretext task for unsupervised representation learning <ref type="bibr">[1, 3-5, 25, 41, 42]</ref>. Compared with instance discrimination that assigns a unique label to each instance, cluster discrimination partitions data into a predefined number of groups that is significantly less than the total number of instances. Therefore, the classification task after clustering becomes much more feasible for large-scale data. Furthermore, learning representations with clusters will push similar instances together, which may help explore potential semantic structures in data. Unfortunately, the clustering phase often needs to run multiple iterations over the entire data set, which has to be conducted in a batch mode to access representations of all instances <ref type="bibr" target="#b2">[3]</ref>. Therefore, online clustering is adopted to improve the ef-ficiency, while the collapsing problem (i.e., a dominating cluster that contains most of instances) becomes challenging for optimization. To mitigate the problem, ODC <ref type="bibr" target="#b40">[41]</ref> has to memorize representations of all instances and decompose the dominating large cluster with a conventional batch mode clustering method. Instead, SwAV <ref type="bibr" target="#b3">[4]</ref> incorporates a balanced clustering method <ref type="bibr" target="#b0">[1]</ref> and obtains assignment with a batch mode solver for instances from only the last few mini-batches, which outperforms the vanilla online clustering in ODC <ref type="bibr" target="#b40">[41]</ref> significantly. However, using only a small subset of data to generate pseudo labels can fail to capture the global distribution. Besides, balanced clustering constrains that each cluster has exactly the same number of instances, which can result in a suboptimal partition of data.</p><p>To take the benefits of cluster discrimination but mitigate the challenge, we, for the first time, investigate the objective of clustering-based representation learning from the perspective of distance metric learning <ref type="bibr" target="#b29">[30]</ref>. Our analysis shows that it indeed learns representations and relationships between instances simultaneously, while the coupled variables make the optimization challenging. By decoupling those variables appropriately, the problem can be solved in an alternating manner between two phases, that is, clustering and discrimination. When fixing representations, clustering is to discover relationship between instances. After that, the representations can be further refined by discrimination using labels from clustering. This finding explains the success of existing cluster discrimination methods. However, most existing methods have to conduct expensive clustering in a batch mode, while our analysis shows that an online method is feasible to optimize the objective.</p><p>Based on the observation, we propose a novel pretext task with online Constrained K-means (CoKe) for unsupervised representation learning. Concretely, in the clustering phase, we propose a novel online algorithm for constrained k-means that lower-bounds the size of each cluster. Different from balanced clustering, our strategy is more flexible to model inherent data structure. In addition, our theoretical analysis shows that the proposed online method can achieve a near-optimal assignment. In the discrimination phase, we adopt a standard normalized Softmax loss with labels and centers recorded from the last epoch to learn representations. By decoupling the clustering and discrimination phases, CoKe can learn representations with a single view from each instance effectively and can be optimized with a small batch size. In addition, two variance reduction strategies are proposed to make the clustering robust for augmentations. <ref type="figure">Fig. 1</ref> illustrates the framework of CoKe, which demonstrates a simple framework without additional components (e.g., momentum encoder <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17]</ref>, batch mode solver <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b40">41]</ref>, etc.). Besides, only one label for each instance is kept in memory, which is an integer and the storage cost is negligible.</p><p>Extensive experiments are conducted on both downstream tasks and clustering to demonstrate the proposal. With only a single view from each instance for training, CoKe already achieves a better performance than MoCo-v2 <ref type="bibr" target="#b7">[8]</ref> that requires two views. By including additional views in optimization, CoKe demonstrates state-of-the-art performance on ImageNet and clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Various pretext tasks have been proposed for unsupervised representation learning. We briefly review instance discrimination and cluster discrimination that are closely related to our work, while other representative methods include BYOL <ref type="bibr" target="#b15">[16]</ref>, SimSiam <ref type="bibr" target="#b8">[9]</ref> and Barlow Twins <ref type="bibr" target="#b39">[40]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Instance Discrimination</head><p>Instance discrimination is a straightforward pretext task for unsupervised representation learning, which tries to pull different augmentations from the same instance together but push them away from all other instances. Early work in this category optimizes the instance classification directly (i.e., each instance has one unique label), which implies an Nclass classification problem, where N is the total number of instances <ref type="bibr" target="#b11">[12]</ref>. Although promising results are obtained, this requires a large classification layer for deep learning. To improve the efficiency, the non-parametric contrastive loss is developed to mitigate the large-scale challenge <ref type="bibr" target="#b37">[38]</ref>. After that, many variants such as MoCo <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b16">17]</ref> and Sim-CLR <ref type="bibr" target="#b5">[6]</ref> are developed to approach or even outperform supervised pre-trained models on downstream tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Cluster Discrimination</head><p>Instance discrimination focuses on individual instances and ignores the similarity between different instances. Therefore, clustering-based method is developed to capture the data structure better, which often consists of two phases: clustering and discrimination. DeepCluster <ref type="bibr" target="#b2">[3]</ref> adopts a standard k-means for clustering, while SeLa <ref type="bibr" target="#b0">[1]</ref> proposes to solve an optimal transport problem for balanced assignment. After obtaining the pseudo labels, the representation will be learned by optimizing the corresponding classification problem. The bottleneck of these methods is that labels need to be assigned offline in a batch mode with representations of all instances to capture the global information.</p><p>To reduce the cost of batch mode clustering, ODC <ref type="bibr" target="#b40">[41]</ref> applies the standard online clustering to avoid the multiple iterations over the entire data set, while representations of all instances need to be kept in memory to address the collapsing problem. SwAV <ref type="bibr" target="#b3">[4]</ref> extends a batch mode optimal transport solver <ref type="bibr" target="#b0">[1]</ref> to do an online assignment to mitigate the collapsing problem. The assignment problem in SwAV is defined within a mini-batch of instances to save the storage for representations. To improve the effectiveness, the method stores representations from the last few mini-batches of instances to capture additional information. However, this is still a small subset compared to the whole data and thus the global information may not be exploited sufficiently. After that, DINO <ref type="bibr" target="#b4">[5]</ref> proposes to have the additional momentum encoder to stabilize the clustering without memorizing representations and can achieve the similar performance as SwAV with ResNet-50.</p><p>Besides clustering-based pretext tasks, some work proposes to leverage nearest neighbors for each instance to capture semantic similarity between different instances <ref type="bibr" target="#b12">[13]</ref>. However, a large batch size and memory bank are required to capture the appropriate neighbors, which is expensive for optimization. In this work, we aim to improve the clustering phase with an online constrained k-means method, which gives better flexibility on cluster size and has a theoretical guarantee on the online assignment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Objective for Clustering-Based Method</head><p>We begin our analysis with the supervised representation learning. Given supervised label information, distance metric learning <ref type="bibr" target="#b35">[36]</ref> has been studied extensively to learn representations by optimizing triplet constraints including some efficient proxy-based variants <ref type="bibr" target="#b26">[27,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31]</ref>. When there are K classes in data, let C = [c 1 , . . . , c K ] ? R d?K denote K proxies with each corresponding to one class. The triplet constraint defined with proxies is</p><formula xml:id="formula_0">?x i , c k:k? =yi , ?x i ? c k ? 2 2 ? ?x i ? c yi ? 2 2 ? ?,</formula><p>where y i is the label of x i . To maximize the margin, the optimization problem for supervised representation learning can be cast as</p><formula xml:id="formula_1">min x,C i k:k? =yi ?x i ? c yi ? 2 2 ? ?x i ? c k ? 2 2<label>(1)</label></formula><p>which can be solved effectively with deep learning <ref type="bibr" target="#b29">[30]</ref>. Without supervised label information, we assume that there are K clusters in data. Besides proxies for each cluster, we have an additional variable ? such that ? i,k = 1 assigning the i-th instance to the k-th cluster. We constrain the domain of ? as ? = {?|?i, k ? i,k = 1, ?i, k, ? i,k ? {0, 1}}. It implies that each instance will only be assigned to a single cluster. The objective for the proxy-based unsupervised representation learning can be written as min x,C,??? i</p><formula xml:id="formula_2">(K ? 1) K k=1 ? i,k ?xi ? c k ? 2 2 ? K q=1 (1 ? ?i,q)?xi ? cq? 2 2<label>(2)</label></formula><p>The coupled variables in Eqn. 2 make the optimization challenging. Hence, we can solve the problem in an alternating way. It should be noted that there are three groups of variables {x, C, ?} and different decomposition can result in different algorithms.</p><p>We demonstrate a prevalent strategy that optimizes {x} and {?, C} alternatively. When fixing assignment ? and centers C, the subproblem becomes</p><formula xml:id="formula_3">min x i K q:q? =?i ?x i ? c? i ? 2 2 ? ?x i ? c q ? 2 2</formula><p>where? i = arg max k ? i,k is the pseudo label of the i-th instance. Given pseudo labels, it can be solved with a supervised method as for Eqn. 1, which is the discrimination phase in representation learning. When fixing representations x, the subproblem can be simplified due to the empirical observation that the distribution of learned representations on the unit hypersphere has a mean that is close to zero <ref type="bibr" target="#b34">[35]</ref> as</p><formula xml:id="formula_4">min C,??? i K k=1 ? i,k ?x i ? c k ? 2 2<label>(3)</label></formula><p>It is a standard k-means clustering problem as the clustering phase in representation learning. The analysis shows that decoupling clustering and discrimination <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4]</ref> is corresponding to an alternating solver for the objective in Eqn 2.</p><p>In this work, we further decouple ? and C in Eqn. 3 for efficient online clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Online Constrained K-Means</head><p>Since the clustering phase is more challenging, we address the problem in Eqn. 3 first. As indicated in <ref type="bibr" target="#b0">[1]</ref>, the original formulation may incur a trivial solution that most of instances go to the same cluster. To mitigate the problem, we adopt the constrained k-means <ref type="bibr" target="#b1">[2]</ref> instead, that is, controlling the minimal size of clusters to avoid collapsing. Given a set of N unlabeled data {x i } and the number of clusters K, the objective for constrained k-means is</p><formula xml:id="formula_5">min C,??? i=N,k=K i=1,k=1 ? i,k ?x i ? c k ? 2 2 s.t. ?k N i=1 ? i,k ? ? k (4)</formula><p>where ? k is the lower-bound of cluster size for the k-the cluster. Consequently, the final objective for unsupervised representation learning becomes</p><formula xml:id="formula_6">min x,C,??? i (K ? 1) K k=1 ? i,k ?xi ? c k ? 2 2 ? K q=1 (1 ? ?i,q)?xi ? cq? 2 2 s.t. ?k N i=1 ? i,k ? ? k<label>(5)</label></formula><p>The problem in Eqn. 4 can be solved in batch mode. However, neural networks are often optimized with stochastic gradient descent (SGD) that can access only a mini-batch of instances at each iteration. Therefore, we propose a novel online algorithm to handle the problem with a theoretical guarantee as follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Online Assignment</head><p>We consider the alternating solver for the problem in Eqn. 4. When C is fixed, the problem for updating ? can be simplified as an assignment problem</p><formula xml:id="formula_7">max ??? ? i k s i,k ? i,k s.t. ?k n i=1 ? i,k ? ? k<label>(6)</label></formula><p>where the value of ? can be relaxed from the discrete space to the continuous space as ? i,k ? [0, 1] and s i,k is the similarity between the i-th instance and the k-th cluster. In this work we assume that x and c have unit norm and thus</p><formula xml:id="formula_8">s i,k = x ? i c k .</formula><p>Let ? * denote the optimal solution for the problem in Eqn. 6. The standard metric for online learning is</p><formula xml:id="formula_9">R(?) = i k s i,k ? * i,k ? i k s i,k ? i,k V(?) = max k {? k ? i ? i,k }</formula><p>where R(?) and V(?) denote regret and violation accumulated over N instances, respectively. Since ? * can be a solution with continuous values, the regret with ? * is no less than that defined with a discrete assignment. Consequently, the performance to the optimal integer solution can be guaranteed if we can bound this regret well.</p><p>To solve the problem in Eqn. 6, we first introduce a dual variable ? k for each constraint i ? i,k ? ? k . To be consistent with the training scheme in deep learning, we assume that each instance arrives in a stochastic order. When the i-th instance arrives at the current iteration, the assignment can be obtained by solving the problem</p><formula xml:id="formula_10">max ?i?? ? k s i,k ? i,k + k ? i?1 k ? i,k<label>(7)</label></formula><p>where {? i?1 k } are the dual variables from the last iteration and ? i = [? i,1 , . . . , ? i,K ]. The problem in Eqn. 7 has a closed-form solution as</p><formula xml:id="formula_11">? i,k = 1 k = arg max k s i,k + ? i?1 k 0 o.w.<label>(8)</label></formula><p>Note that the domain for the assignment is a continuous space, but our solution implies an integer assignment. Besides, dual variables control the violation over the cluster size constraints. The method degrades to a greedy strategy without the dual variables. After assignment, dual variables will be updated as</p><formula xml:id="formula_12">? i = ? ?? (? i?1 ? ?(? i ? [? 1 , . . . , ? K ] N ))</formula><p>where ? ?? projects the dual variables to the domain ? ? = {?|?k, ? k ? 0, ??? 1 ? ? }. The performance of online assignment algorithm can be guaranteed in Theorem 1. Complete proofs can be found in the appendix.</p><p>Theorem 1. If instances arrive in the stochastic order, by</p><formula xml:id="formula_13">setting ? = ? / ? 2N , we have E[R(?)] ? O( ? N ), E[V(?)] ? O( ? N )</formula><p>Remark Theorem 1 indicates that compared with the optimal solution consisting of continuous assignment, the regret of our method with integer assignment can be well bounded. Besides, the violation is also bounded by O( ? N ) for the constraints accumulated over all instances. It illustrates that for each assignment, the gap to optimum can be bounded by O(1/ ? N ) and our assignment method can achieve a near-optimal result even running online. Moreover, the theorem implies that the violation can be avoided by increasing ? k with a small factor.</p><p>For training with SGD, a mini-batch of instances rather than a single instance will arrive at each iteration. If the size of the mini-batch is b, we will assign pseudo labels for each instance with the closed-form solution in Eqn. 8. The dual variables will be updated with the averaged gradient as</p><formula xml:id="formula_14">? i = ? ?? (? i?1 ? ? 1 b b s=1 (? s i ? [? 1 , . . . , ? K ] N ))<label>(9)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Online Clustering</head><p>With the proposed online assignment, we can update the assignment and centers for constrained k-means in an online manner. Concretely, for the t-th epoch, we first fix C t?1 and assign pseudo labels for each mini-batch of instances.</p><p>After training with an epoch of instances, the centers can be updated as</p><formula xml:id="formula_15">c t k = ? ?c?2=1 ( N i ? t i,k x t i N i ? t i,k )<label>(10)</label></formula><p>where ? t is the assignment at the t-th epoch and x t i denotes a single view of the i-th instance at the t-th epoch.</p><p>Since our method does not memorize representations of instances, the variables in constrained k-means, especially centers, will only be updated once with an epoch of instances. However, k-means requires multiple iterations to converge as a batch mode method. Fortunately, clustering each epoch of data to optimum is not necessary for representation learning. According to the objective in Eqn. 5, we can further decompose ? and C. When fixing x t and C t?1 , the assignment can be updated by the proposed online assignment method. When fixing x t and ? t , centers have a closed-form solution as in Eqn. 10. Therefore, a single step of updating is applicable for optimizing the target objective and the cost of clustering can be mitigated. Intuitively, representations are improved with more epochs of training while the clustering is gradually optimized simultaneously.</p><formula xml:id="formula_16">Algorithm 1 Online Constrained K-Means (CoKe) Input: Data set {x i } N i=1 , #clusters K, #epochs T , batch size b Randomly initialize C 0 for t = 1 to T do Initialize C t 0 = C t?1 and m = 0 for r = 1 to N/b do</formula><p>Obtain assignment ? t as in <ref type="formula" target="#formula_11">(8)</ref> Update dual variables ? i as in <ref type="formula" target="#formula_14">(9)</ref> Update centers C t m+b as in (11) m = m + b end for end for return {? T , C T } Furthermore, inspired by mini-batch k-means <ref type="bibr" target="#b33">[34]</ref>, we can update the centers aggressively to accelerate the convergence of clustering process. Concretely, centers can be updated after each mini-batch as</p><formula xml:id="formula_17">c t k:m = ? ?c?2=1 ( m i ? t i,k x t i m i ? t i,k )<label>(11)</label></formula><p>where m denotes the total number of received instances in the t-th epoch. After a sufficient training, we may switch to update centers only once in each epoch to reduce the variance from a mini-batch. Alg. 1 summarizes the proposed online clustering method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Discrimination</head><p>With pseudo labels and centers obtained from the (t ? 1)-th epoch, we can learn representations by optimizing a standard normalized Softmax loss for instances at the t-th iteration as</p><formula xml:id="formula_18">? cls (x t i ) = ? log( exp(x t? i c t?1 y t?1 i /?) K k=1 exp(x t? i c t?1 k /?) )<label>(12)</label></formula><p>where? t?1 i is the pseudo label implied by ? t?1 and ? is the temperature. Since ? i is a one-hot vector, we can keep a single label for each instance in the memory, where the storage cost is negligible. x i and c k have the unit norm. By decoupling clustering and discrimination, our method can optimize the objective in Eqn. 5 effectively in an alternating way. To initialize the pseudo labels and centers for representation learning, we scan one epoch of instances without training the model to obtain ? 0 and C 0 .</p><p>Finally, we show that our method converges.</p><formula xml:id="formula_19">Corollary 1.</formula><p>The proposed method will converge if keeping ? t?1 when ? t provides no loss reduction.</p><p>Although the theory requires to check the optimality of ? t , we empirically observe that CoKe works well with the vanilla implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Variance Reduction for Robust Clustering</head><p>Variance from different views of each instance provides essential information for representation learning. However, it may perturb the clustering and make the optimization slow. Therefore, we propose two strategies to reduce the variance incurred to the assignment step.</p><p>Moving Average Ensemble is an effective way to reduce variance. Therefore, we propose to accumulate clustering results from the second stage. Concretely, for t &gt; T ? , assignment and centers will be updated a?</p><formula xml:id="formula_20">C t = (1 ? 1 t?T ? )? t?1 + 1 t?T ? C t ; y t = (1 ? 1 t?T ? )? t?1 + 1 t?T ?? t</formula><p>where C t and? t are obtained at the t-th epoch and? t denotes the one-hot vector of? t . The formulation averages the clustering results from the last T ? T ? epochs to reduce the variance from augmentations. Unlike? i ,? i is not a one-hot vector due to ensemble and can contain multiple non-zero terms. We adopt the loss defined with soft labels as</p><formula xml:id="formula_21">? soft cls (x t i ) = ? k? t?1 i,k log( exp(x t? ic t?1 k /?) K j=1 exp(x t? ic t?1 j /?) )</formula><p>Two Views Learning representations with two views from the same image is prevalent in contrastive learning. Our proposed method can be considered as leveraging two views from different epochs and thus a single view is sufficient for each epoch. Nevertheless, CoKe can be further improved by accessing two views at each iteration. Given two views of an image, the constraint for assignment is that both views share the same label. Therefore, the assignment problem in Eqn. 7 becomes</p><formula xml:id="formula_22">max ?i?? ? 1 2 k ? i,k 2 j=1 s j i,k + k ? i?1 k ? i,k</formula><p>where s j i,k denotes the similarity between the j-th view of the i-th instance and the k-th center. Hence, it is equivalent to obtaining a label for the mean vector averaged over two views as</p><formula xml:id="formula_23">? i,k = 1 k = arg max k 1 2 2 j=1 s j i,k + ? i?1 k 0 o.w.<label>(13)</label></formula><p>Then, the loss in Eqn. 12 will be averaged over two views. Compared with the single view, multiple views can reduce the variance from different augmentations and make the assignment more stable. Besides variance reduction for the one-hot assignment, the other advantage with the additional view is that it can Algorithm 2 Pseudo-code of CoKe with Two Views. Then, the cross entropy loss for view 1 can be optimized with? t i:1 instead. Alg. 2 summarizes the pseudo-code of CoKe with two views, which can be extended to multiple views easily.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We conduct experiments of unsupervised representation learning on ImageNet <ref type="bibr" target="#b32">[33]</ref> to evaluate the proposed method. For fair comparison, we follow settings in benchmark methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8]</ref>. More details can be found in the appendix.</p><p>For the parameters in CoKe, we set the learning rate as 1.6 and temperature ? = 0.1. Besides the learning rate for model, CoKe contains another learning rate ? for updating dual variables as in Eqn. 9. We empirically observe that it is insensitive and set ? = 20. Finally, the batch size is 1, 024 such that all experiments of CoKe except the one with multi-crop can be implemented on a standard server with 8 GPUs and 16G memory on each GPU.</p><p>An important parameter in CoKe is the minimal cluster size. To reduce the number of parameters, we assign the same constraint for different clusters as ? 1 = ? ? ? = ? K = ?. Considering that ? = N/K denotes the balanced clustering, we introduce a parameter ? ? as ? = ? ? N/K and tune ? ? in lieu of ? for better illustration. In the experiments, we observe that the maximal value of dual variables is well bounded, so we simplify the updating criterion for dual variables as</p><formula xml:id="formula_24">? i k = max{0, ? i?1 k ? ? 1 b b s=1 (? s i,k ? ? ? K )}<label>(14)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Ablation Study</head><p>First, we empirically study the effect of each component in CoKe. All experiments in this subsection train 200 epochs and each instance has a single view of augmentation at each iteration. After obtaining the model, the learned representations are evaluated by learning a linear classifier on ImageNet. The training protocol for linear classifier follows that in MoCo <ref type="bibr" target="#b16">[17]</ref> except that we change the weight decay to 10 ?6 and learning rate to 1 for our pre-trained model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Balanced vs. Constrained Clustering</head><p>In the previous work <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b3">4]</ref>, balanced clustering that constrains each cluster to have the same number of instances demonstrates a good performance for representation learning. Constrained clustering that lower-bounds the size of each cluster is a more generic setting, but has been less investigated. With the proposed method, we compare constrained clustering to balanced clustering in <ref type="table">Table 1</ref> We fix the number of centers as K = 3, 000 while varying ? ? to evaluate the effect of cluster size constraint. When ? ? = 1, each cluster has to contain N/K instances that becomes the balanced clustering. We let "#Cons", "#Min", "#Max" denote the constrained cluster size, the actual size of the smallest cluster and that of the largest cluster from the last epoch of CoKe, respectively. As illustrated in Table 1, the balanced clustering can achieve 63.1% accuracy when training with a single view. It confirms that balanced clustering is effective for learning representations. If decreasing the ratio, each cluster can have a different number of instances that is more flexible to capture the inherent data structure. For example, when ? ? = 0.8, the minimum size of clusters is reduced from 403 to 338 while the largest cluster has more than double of instances in balanced clustering.</p><p>Meanwhile, the imbalanced partition helps to improve the accuracy by 0.7%. With an even smaller ratio of 0.4, our method surpasses the balanced clustering with a significant margin of 1.4% and it demonstrates that constrained clustering is more appropriate for unsupervised representation learning. The performance will degrade when ? ? = 0 since it may incur the collapsing problem without a sufficient number of instances in each cluster. We will fix ? ? = 0.4 in the following experiments.</p><p>Besides the accuracy on linear classification, we further investigate the violation of constraints in <ref type="table">Table 1</ref>. For balanced clustering, each cluster has the same number of instances which is a strong constraint. Compared to the constraint, the violation of our online assignment is only 5% when ? ? = 1. If ? ? is less than 1, the constraint is relaxed and the violation can be reduced to less than 1%, which illustrates the effectiveness of our method. Compared with the online assignment strategy that only optimizes the constraints over a small subset of data in SwAV <ref type="bibr" target="#b3">[4]</ref>, we optimize the assignment globally and can explore the distribution of data sufficiently. Interestingly, we find that there is no dominating cluster even when ? ? = 0.4. In that scenario, the largest cluster only contains 2, 371 instances. It illustrates that clustering is effective to learn an appropriate partition for unlabeled data. If ? ? = 0, more than 449, 000 instances will be assigned to the same cluster, which confirms the importance of cluster size constraint to mitigate the collapsing problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Coupled Clustering and Discrimination</head><p>Then, we study the effect of coupling clustering and discrimination. In CoKe, we decouple clustering and discrimination by collecting clustering results from the last epoch to discriminate data from the current epoch. <ref type="table" target="#tab_1">Table 2</ref> compares the performance with different labels and centers where {C t?1 ,? t?1 } and {C t ,? t } are from the last epoch and the current epoch, respectively. First, we can observe that with labels and centers from the last epoch, CoKe demonstrates the best performance. It verifies that CoKe solves the problem in Eqn. 5 effectively in an alternating way. Second, with current centers C t , the performance decreases more than 10%, which shows the importance of keeping centers from the last epoch in CoKe. Finally, the other two variants with? t fail to learn meaningful representations. It is consistent with our analysis for the objective in Eqn. 5. Note that ? is the additional variables introduced by unsupervised learning and decoupling x and ? is crucial for clustering-based representation learning.</p><formula xml:id="formula_25">Settings {C t?1 ,? t?1 } {C t?1 ,? t } {C t ,? t?1 } {C t ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.3">Number of Clusters</head><p>The number of clusters is a key parameter in k-means. When K is small, the relationship between similar instances may not be exploited sufficiently. However, additional noise can be introduced with a large K. Instance classification can be considered as a special case when K = N . <ref type="table" target="#tab_3">Table 3</ref> summarizes the performance with different K's. We observe that CoKe with 1, 000 clusters is about 1% worse than that with K = 3, 000. It is because that a small K is hard to capture all informative patterns due to a coarse granularity.  However, obtaining an appropriate K for clustering is a challenging problem in k-means. Moreover, clustering can provide different results even with the same representations, which is researched in multi-clustering <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b20">21]</ref>. This phenomenon is due to the fact that objects can be similar in different ways (e.g., color, shape, etc.). Multiclustering has been explored in previous representation learning work <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b24">25]</ref> and we also apply it to learn representations with a multi-task framework. Each task is defined as a constrained k-means problem with a different K, while the final loss will be averaged over multiple tasks. This strategy mitigates the parameter setting problem in kmeans by handling multiple k-means problems with diverse parameters simultaneously.  <ref type="table" target="#tab_4">Table 4</ref> shows the results of learned representations with multi-clustering. When including a task with K = 2, 000, the accuracy is improved from 64.5% to 65.0%. With a more fine-grained task of K = 4, 000, the performance of learned representations is even better and achieves 65.2% in accuracy. Then, we evaluate the triple k-means task with two different settings, that is, same K and different K's. It can be observed that different K's can further improve the performance. We will adopt the strategy in rest experiments for the explicit multi-clustering. More ablation study can be found in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison with State-of-the-Art on ImageNet</head><p>In this subsection, we compare our proposal with stateof-the-art methods by learning a linear classifier on learned representations for ImageNet. All methods have ResNet-50 as the backbone. The results of methods with similar configurations (e.g., 2-layer MLP, 128-dimensional representations, etc.) are summarized in <ref type="table">Table 5</ref>. Explicitly, baseline methods have to learn representations with two views of augmentations from an individual instance at each iteration for the desired performance. On the contrary, CoKe can work with a single view using online optimization. It can be observed that the accuracy of representations learned by CoKe with 800 epochs can achieve 71.4%, which performs slightly better than MoCo-v2 but with only a half number of views for optimization. It illustrates that leveraging relations between instances can learn more informative patterns than instance discrimination. Second, compared to the clustering-based methods, CoKe outperforms SwAV and DeepCluster by 1% when training with the same number of views. This further demonstrates the effectiveness of CoKe. Finally, we compare the running time for training one epoch of data in <ref type="table" target="#tab_6">Table 6</ref>. With a single view for optimization, the learning efficiency can be significantly improved as in CoKe. Then, we apply more sophisticated settings proposed by recent methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16]</ref> for CoKe and compare with methods using different settings. Concretely, we include 3layer MLP, an additional 2-layer prediction head and 1, 000 epochs for training. More details can be found in the appendix. <ref type="table" target="#tab_8">Table 7</ref> summarizes the comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MoCo-v2</head><p>First, we can observe that CoKe with single view performs slightly better than MoCo-v2 again and it demonstrates that optimizing with single view is able to obtain an applicable pre-trained model. Second, by equipping  with two views, CoKe can achieve 74.9% accuracy on Im-ageNet, which is a competitive result but with much lighter computational cost. Furthermore, the superior performance of NNCLR and CoKe shows that capturing relations between instances can learn better representations. However, NNCLR has to obtain appropriate nearest neighbors with a large memory bank and is sensitive to the batch size. On the contrary, CoKe learns relationship by online clustering, which is feasible for small batch size and leads to a simple framework without memory bank and momentum encoder. Finally, with the standard multi-crop trick, CoKe can achieve 76.4% accuracy on ImageNet that is close to the supervised counterpart, i.e., 76.5%. In summary, CoKe is more resource friendly (e.g., a standard server with 8 GPUs is sufficient) with superb performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Comparison on Downstream Tasks</head><p>Besides linear classification on ImageNet, we evaluate CoKe on various downstream tasks in <ref type="table">Table 8</ref>. Methods with public available pre-trained models are included for comparison. For a fair comparison, we search parameters for all baselines with the codebase from MoCo. Evidently, CoKe provides a better performance than the strong baselines with multi-crop training, which confirms the effectiveness of our method. Detailed empirical settings and additional experiments on clustering are in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we propose a novel learning objective for cluster discrimination pretext task. An online constrained k-means method with theoretical guarantee is developed to obtain pseudo labels, which is more appropriate for stochastic training in representation learning. The empirical study shows that CoKe can learn effective representations with less computational cost by leveraging the ag- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Theoretical Analysis</head><p>A.1. Proof of Theorem 1</p><p>Proof. Let the Lagrangian function at the i-th iteration be</p><formula xml:id="formula_26">L i (? i , ? i?1 ) = k s i,k ? i,k + k ? i?1 k (? i,k ? ? k /N )</formula><p>where ? i ? R K , and the solution for assignment is</p><formula xml:id="formula_27">? i,k = 1 k = arg max k s i,k + ? i?1 k 0 o.w.<label>(15)</label></formula><p>It is the maximal solution for the subproblem, and we have</p><formula xml:id="formula_28">?? i , L i (? i , ? i?1 ) ? L i (? i , ? i?1 )<label>(16)</label></formula><p>where ? i is an arbitrary assignment and? i is the assignment implied in Eqn. 15. If fixing? i and assuming k ? k ? N , which is due to the fact that ? k is the lower-bound for each cluster size, we have the inequality for the arbitrary dual variables ? from the target convex domain as</p><formula xml:id="formula_29">L i (? i , ? i?1 ) ? L i (? i , ?) = k (? i?1 k ? ? k )(? i,k ? ? k /N ) ? ?? i?1 ? ?? 2 2 ? ?? i ? ?? 2 2 2? + ?<label>(17)</label></formula><p>Combining Eqns. 16 and 17, we have</p><formula xml:id="formula_30">L i (? i , ? i?1 ) ? L i (? i , ?) ? ?? i?1 ? ?? 2 2 ? ?? i ? ?? 2 2 2? + ?</formula><p>With the constraint ??? 1 ? ? and adding i from 1 to N , we have</p><formula xml:id="formula_31">N i=1 L i (? i , ? i?1 ) ? L i (? i , ?) ? ? 2 2? + ?N By setting ? = ? ? 2N , it becomes N i=1 L i (? i , ? i?1 ) ? L i (? i , ?) ? ? ? 2N</formula><p>Taking ? as the optimal solution for the original linear programming problem as ? * , we have</p><formula xml:id="formula_32">R(?) + k ? k (? k ? i? i,k ) ? i k ? i?1 k (? k /N ? ? * i,k ) + ? ? 2N</formula><p>Let ? be the one-hot vector if there is violation.</p><formula xml:id="formula_33">? k = ? k = arg max k ? k ? i? i,k and V(?) &gt; 0 0 o.w.</formula><p>Then, we can obtain the relationship between regret and violation as</p><formula xml:id="formula_34">R(?) + ? V(?) ? i k ? i?1 k (? k /N ? ? * i,k ) + ? ? 2N</formula><p>By assuming that the instances arrive in a stochastic order, we have E[? k /N ? ? * i,k ] ? 0 and the bound becomes</p><formula xml:id="formula_35">E[R(?)] ? ? ? 2N ; ? E[V(?)] ? ? ? 2N ? E[R(?)]</formula><p>Now, we try to lower bound R(?). The following analysis is for the case of V(?) &gt; 0. Since the violation is V(?), we shrink the current solution? by a factor of ? = min k ? k ? k +KV(?) such that there is no cluster with the number of instances more than ? k or there is at least KV(?) unassigned instances. The shrunk solution with the re-assignment for the extra instances can be a feasible solution for the original assignment problem, so we have</p><formula xml:id="formula_36">? i k s i,k?i,k ? OPT</formula><p>where OPT denotes the optimal feasible result from ? * . The lower-bound for R(?) is</p><formula xml:id="formula_37">E[R(?)] ? E[(1 ? 1 ? )OP T ] ? ? KE[V(?)] min k ? k OPT</formula><p>Taking it back to the inequality for the violation and let ? be sufficiently large, the bound for the violation is obtained as</p><formula xml:id="formula_38">E[V(?)] ? 1 1 ? KOPT ? min k ? k ? 2N</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Proof of Corollary 1</head><p>Proof. Since {x, C, ?} are sequentially updated, with L ? (x, C, ?) denoting the objective min x,C,??? i</p><formula xml:id="formula_39">(K ? 1) K k=1 ? i,k ?xi ? c k ? 2 2 ? K q=1 (1 ? ?i,q)?xi ? cq? 2 2 (18) we have L ? (x t?1 , C t?1 , ? t?1 ) ? L ? (x t , C t?1 , ? t?1 ) and L ? (x t , C t?1 , ? t ) ? L ? (x t , C t , ? t )</formula><p>. Therefore, the convergence for the bounded loss in Eqn. 18 can be guaranteed if</p><formula xml:id="formula_40">L ? (x t , C t?1 , ? t?1 ) ? L ? (x t , C t?1 , ? t ).</formula><p>Since Theorem 1 indicates that ? t is a near-optimal solution, it can reduce the loss effectively to make the inequality hold. Theoretically, we can keep ? t?1 when ? t provides no loss reduction to guarantee the convergence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Implementation Details</head><p>CoKe is learned with LARS optimizer <ref type="bibr" target="#b38">[39]</ref>, where weight decay is 10 ?6 and momentum is 0.9. Batch size is set to 1, 024, where all experiments except the one with the multi-crop trick can be implemented on a server with 8 GPUs and 16G memory for each GPU. CoKe with two 224?224 crops and six 96?96 crops costs about 20G memory on each GPU and is implemented on a server with 8 GPUs and 32G memory for each GPU. Learning rate is 1.6 with cosine decay and the first 10 epochs are used for warmup. Batch normalization <ref type="bibr" target="#b21">[22]</ref> is synchronized across different GPUs as in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref>. Augmentation is important for the performance of unsupervised representation learning <ref type="bibr" target="#b7">[8]</ref>, and we apply the same augmentation as in others <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6]</ref> that includes random crop, color jitter, random grayscale, Gaussian blur, and random horizontal flips. ResNet-50 <ref type="bibr" target="#b18">[19]</ref> is adopted as the backbone and we apply a 2-layer MLP head to the backbone as suggested in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b7">8]</ref> for ablation experiments. The output dimension after MLP projection is 128, which is also the same as benchmark methods <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>To compare with state-of-the-art methods, we apply more sophisticated settings proposed by recent methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16]</ref>, e.g., 1000 epoch training, 3-layer projection MLP and 2-layer prediction MLP. The training epoch for CoKe with multi-view is 800. For Coke with two views, we set ? = 0.2 and the ablation study for ? can be found in the appendix. The temperature for CoKe with two/multi-view is reduced to 0.05. Other settings, including batch size, dimension of representations, etc. remain the same. Following <ref type="bibr" target="#b9">[10]</ref>, the linear classifier is optimized with SGD while the batch size and the number of epochs is 1, 024 and 90, respectively. We conduct the ablation study for these additional components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Ablation study B.2.1 Small Batch Training</head><p>Since our objective for representation learning is a classification problem, it is insensitive to small batch size. To validate the claim, we have the experiments with the batch size of {256, 512, 1024} in <ref type="table">Table 9</ref>. The learning rate for the batch size 256 and 512 is set to 0.8 and 1.2, respectively. We can observe from <ref type="table">Table 9</ref> that the performance of size 256 is similar to that of 1, 024. It confirms that the Batch Size 256 512 1,024 Acc% 64.2 64.7 64.5 <ref type="table">Table 9</ref>. Comparison of different batch size.</p><p>proposed method is applicable with small batch size. Note that the ablation study has 200 epochs for pre-training, and additional training epochs can further mitigate the gap as illustrated in SwAV <ref type="bibr" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.2 Single View with Moving Average</head><p>Here, we investigate the effect of the proposed moving average strategy as a two-stage training scheme. To keep the label vector sparse, we fix the number of non-zero terms in a label vector to be 5 in the second stage, where the performance is quite stable with other values in {10, 20, 30}. The sparse label will be further smoothed by a Softmax operator as? T ? is the number of epochs for the first stage and different settings of T ? is compared in <ref type="table" target="#tab_10">Table 10</ref>. It can be observed that a single stage training strategy achieves 65.3% accuracy, while smoothing the labels and centers in the last 40 epochs can further improve the performance to 65.8%. It shows that the averaging strategy is effective for our framework. However, the performance will degrade if we begin moving average at an early stage as T ? = 120, which is due to that the model has not been trained sufficiently in the first stage. Given T , we will set T ? according to the ratio of 160/200 for CoKe of single view.</p><formula xml:id="formula_41">i,k = exp(? i,k /? ? )/Z? i,k &gt; 0 0? i,k = 0 where Z = k I(? i,k &gt; 0) exp(? i,k /? ? ) and ? ? = 0.5 in</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.3 Optimization with Two Views</head><p>Now we evaluate the model with sophisticated settings. When optimizing CoKe with two views, we keep the onestage training scheme but improve pseudo labels as follow?</p><formula xml:id="formula_42">y t i:1 = ?? t?1 i + (1 ? ?)p t?1 i:2 where p t?1 i:j,q = exp(x j? i c t?1 q /?) K k=1 exp(x j? i c t?1 k /?)</formula><p>The only parameter in the formulation is ? that balances the one-hot label from the last epoch and soft label from the other view. The effect by varying ? is summarized in <ref type="table">Table 11</ref>. It demonstrates that a sufficiently large ?, which contains the information from the last epoch, is essential for improving the performance. We will fix ? = 0.2 for rest experiments.</p><p>? 0.1 0.2 0.3 0.4 Acc% 73.9 74.9 74.5 74.4 <ref type="table">Table 11</ref>. CoKe of two views with different ?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.4 Optimization with Prediction MLP</head><p>We illustrate the different architectures with additional prediction head for existing methods <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b15">16]</ref> and CoKe in <ref type="figure" target="#fig_2">Fig. 2</ref>. Most of existing methods constrain that the representation after the prediction head is close to the representation of the other view after the projection head. Unlike those methods, CoKe tries to pull the representation of each instance to its corresponding cluster center. Therefore, both of representations after the projection MLP and prediction MLP can be leveraged for optimization as shown in <ref type="figure" target="#fig_2">Fig. 2 (b)</ref>. Let ? pred and ? proj denote the classification loss for the representations from prediction and projection MLP, respectively. The final loss can be obtained as</p><formula xml:id="formula_43">? = ?? pred + (1 ? ?)? proj</formula><p>The effect of ? is summarized in <ref type="table" target="#tab_1">Table 12</ref> for CoKe with single view and two views. Note that the clustering phase including obtaining centers is applied to the representations after projection MLP only. From the comparison, it demonstrates that the additional prediction MLP is helpful for learning better representations. Interestingly, if optimizing the loss defined on representations from the prediction only, the performance of CoKe with two views can be degenerated. It may be due to that the dense soft label in two-view optimization is generated from the representation of the projection head. Without the corresponding loss, it is hard to optimize the prediction MLP solely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2.5 Long Training</head><p>Finally, we compare the performance of 800-epoch training to that of 1000-epoch training in <ref type="table" target="#tab_3">Table 13</ref>. Evidently, a #epochs 800 1,000 Acc% 74.5 74.9 <ref type="table" target="#tab_3">Table 13</ref>. CoKe of two views with different training epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3. Comparison on Downstream Tasks</head><p>After evaluating the performance on ImageNet, we apply the pre-trained models on downstream tasks for object detection, instance segmentation and classification. Four benchmark data sets are included for comparison. Concretely, we fine-tune Faster R-CNN <ref type="bibr" target="#b31">[32]</ref> with R50-C4 as the backbone on PASCAL VOC <ref type="bibr" target="#b13">[14]</ref> and Mask R-CNN <ref type="bibr" target="#b17">[18]</ref> with R50-FPN as the backbone and "1?" training paradigm on COCO <ref type="bibr" target="#b25">[26]</ref>. The codebase of MoCo 1 with Detec-tron2 [37] is adopted. The standard fine-tuning procedure is applied for classification on CIFAR-10 <ref type="bibr" target="#b23">[24]</ref> and CIFAR-100 <ref type="bibr" target="#b23">[24]</ref>.</p><p>For object detection and instance segmentation, we follow the settings in MoCo <ref type="bibr" target="#b16">[17]</ref> for a fair comparison while only the learning rate is tuned. To obtain the optimal performance for each model, we search the learning rate in [0.02, 0.12] and [0.01, 0.05] with a step size of 0.01 for all methods on VOC and COCO, respectively. For classification, we search the learning rate in {1, 10 ?1 , 10 ?2 , 10 ?3 } and weight decay in {10 ?5 , 10 ?6 , 0}, respectively. Besides, the learning rate for the last fully-connected layer is 10 times larger than others since it is randomly initialized without pre-training. The best performance for baseline methods is reported. CoKe with two-view optimization is evaluated in this subsection. <ref type="table" target="#tab_4">Table 14</ref> summarizes the standard metric on VOC, COCO and CIFAR. Explicitly, CoKe can outperform the supervised pre-trained model. It implies that an effective pre-trained model can be learned without supervision. Detailed reports on COCO can be found in <ref type="table" target="#tab_6">Tables 15 and 16</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4. Comparison on Clustering</head><p>As a deep clustering method, we compare CoKe to the benchmark clustering algorithms on CIFAR-10 and CIFAR-100 <ref type="bibr" target="#b23">[24]</ref> in <ref type="table" target="#tab_8">Tables 17 and 18</ref>, respectively. We follow the evaluation protocol in SCAN that trains models on training set and then evaluates the performance on test set with the prediction from the model directly. For CIFAR-100, 20 superclass labels are used for comparison.</p><p>CoKe with two-view optimization is adopted for comparison. Compared with ImageNet, the resolution of images in CIFAR is only 32 ? 32. Therefore, we change the parameter of random crop from [0.08, 1] to [0.3, 1] to keep the semantic information of the image. The model is optimized with SGD for 400 epochs. The batch size is 128 and the learning rate is 0.2. Since CIFAR is a balanced data set, the lower-bound constraint is set to 0.9 and the learning rate for the dual variables is 0.1. Other settings remain the same and we have the same parameters for different data sets. To compare with SCAN, we have the same ResNet-18 as the backbone in CoKe. SCAN has 10 clustering heads with the same number of clusters for multi-clustering. To have explicit multi-clustering, CoKe has 10 clustering heads with different number of clusters. Concretely, we have [10, 100] with a step of 10 for CIFAR-10 and <ref type="bibr" target="#b19">[20,</ref><ref type="bibr">200]</ref> with a step size of 20 for CIFAR-100-20. The head with the target number of clusters is adopted for evaluation. The result averaged over 10 trails is reported.  <ref type="table" target="#tab_8">Tables 17 and 18</ref> show that CoKe as an end-to-end clustering framework can achieve the superior performance without any fine-tuning. On the contrary, SCAN has a twostage training strategy that learns representations in the first stage with instance discrimination and fine-tunes the model for clustering with different objectives and augmentations in the second stage. Therefore, the representation from the first stage may degenerate the performance of clustering. Finally, <ref type="figure" target="#fig_3">Fig. 3</ref> shows the exemplars that are close to cluster centers from CoKe on CIFAR. We can find that CoKe can recover the exact classes on CIFAR-10, which confirms the effectiveness of CoKe for clustering. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc># f: encoder network for input images # u: pseudo one-hot labels (Nx1) # C: cluster centers # rho: dual variable for constraints (Kx1) # gamma: lower-bound of cluster size # lambda: temperature # alpha: ratio between labelsfor z in loader: # load a minibatch with b samples z_1, z_2 = aug(z), aug(z) # two random views from z x_1, x_2 = f(z_1), f(z_2) # encoder representations s_1, s_2 = x_1C, x_2C # logits over centers y = u(z_id) # retrieve label from last epoch # compute reference distribution for each view p_1 = softmax(s_1/lambda) p_2 = softmax(s_2/lambda) # obtain soft label for discrimination y_1 = alpha * y + (1-alpha) * p_2 y_2 = alpha * y + (1-alpha) * p_1 # loss over two views loss = 0.5 * (-y_1 * log(p_1) -y_2 * log(p_2)) loss.backward() # update encoder # update clustering x_mean = 0.5 * (x_1+x_2) # mean vector of two views u(z_id) = update(x_mean, C, rho) # as in Eqn. 13 C = update(C, x_mean, u(z_id)) # as in Eqn. 11 rho = update(rho, gamma, u(z_id)) # as in Eqn. 14 provide a reference label distribution for the other view. Let p i:j denote the predicted probability over labels p t?1 i:j,q = exp(x j? i c t?1 q /?) K k=1 exp(x j? i c t?1 k /?) We can obtain the soft label for view 1 with the reference from view 2 as? t i:1 = ?? t?1 i + (1 ? ?)p t?1 i:2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Illustration of architecture with the additional prediction head. The yellow bounding box denotes the results from the last epoch. longer training still can improve the performance slightly.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 .</head><label>3</label><figDesc>Exemplars obtained by CoKe on CIFAR.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Comparison of labels and centers from different epochs.</figDesc><table><row><cell>? t }</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table /><note>Comparison of number of clusters K in k-means.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 .</head><label>4</label><figDesc>Multi-clustering with different K combinations.</figDesc><table><row><cell cols="2">K(?1, 000) 3</cell><cell cols="2">2+3 3+4 3+3+3 3+4+5</cell></row><row><cell>Acc%</cell><cell cols="2">64.5 65.0 65.2 65.2</cell><cell>65.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 .</head><label>6</label><figDesc>Comparison of running time (mins) for training one epoch of data on ImageNet. All methods are evaluated on the same server. CoKe* applies automatic mixed precision training provided by PyTorch.</figDesc><table><row><cell></cell><cell cols="3">SwAV CoKe CoKe*</cell></row><row><cell>18.3</cell><cell>20.8</cell><cell>11.1</cell><cell>8.4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 .</head><label>7</label><figDesc>Comparison with state-of-the-art methods on ImageNet by linear classification. ME and MB denote momentum encoder and memory bank, respectively.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 .</head><label>10</label><figDesc>all experiments. We also update centers only after each epoch in the second stage as discussed in Sec. 3.2.2. Moving average with different T ? .</figDesc><table><row><cell>T ?</cell><cell>120 160 200</cell></row><row><cell cols="2">Acc% 64.3 65.8 65.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 12 .</head><label>12</label><figDesc>CoKe with different settings of prediction MLP.</figDesc><table><row><cell>?</cell><cell>0</cell><cell>0.5</cell><cell>1</cell></row><row><cell cols="4">single-view 72.3 72.5 72.5</cell></row><row><cell>two-view</cell><cell cols="3">74.4 74.9 73.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 14 .Table 15 .Table 16 .</head><label>141516</label><figDesc>https://github.com/facebookresearch/moco/tree/main/detection Comparison on downstream tasks. * denotes the usage of the multi-crop training trick. Top-2 best models are underlined. Comparison of object detection on COCO. Comparison of instance segmentation on COCO.</figDesc><table><row><cell></cell><cell>VOC</cell><cell cols="2">COCO</cell><cell>C10</cell><cell>C100</cell></row><row><cell>Methods</cell><cell cols="5">Ap50 Ap bb Ap mk Acc% Acc%</cell></row><row><cell>Supervised</cell><cell>81.3</cell><cell>38.9</cell><cell>35.4</cell><cell>97.3</cell><cell>86.6</cell></row><row><cell>MoCo-v2</cell><cell>83.0</cell><cell>39.6</cell><cell>35.9</cell><cell>97.9</cell><cell>86.1</cell></row><row><cell cols="2">Barlow Twins 81.5</cell><cell>40.1</cell><cell>36.9</cell><cell>98.0</cell><cell>87.4</cell></row><row><cell>BYOL</cell><cell>82.9</cell><cell>40.5</cell><cell>36.9</cell><cell>98.1</cell><cell>87.9</cell></row><row><cell>SwAV  *</cell><cell>82.1</cell><cell>40.4</cell><cell>37.1</cell><cell>97.7</cell><cell>87.5</cell></row><row><cell>DINO  *</cell><cell>82.0</cell><cell>40.2</cell><cell>36.8</cell><cell>97.7</cell><cell>87.6</cell></row><row><cell>CoKe</cell><cell>83.2</cell><cell>40.9</cell><cell>37.2</cell><cell>98.2</cell><cell>88.2</cell></row><row><cell cols="2">Methods</cell><cell cols="2">Ap bb Ap bb 50</cell><cell>Ap bb 75</cell><cell></cell></row><row><cell cols="2">Supervised</cell><cell cols="2">38.9 59.6</cell><cell>42.7</cell><cell></cell></row><row><cell cols="2">MoCo-v2</cell><cell cols="2">39.6 60.5</cell><cell>43.4</cell><cell></cell></row><row><cell cols="4">Barlow Twins 40.1 61.6</cell><cell>43.9</cell><cell></cell></row><row><cell>BYOL</cell><cell></cell><cell cols="2">40.5 61.8</cell><cell>44.2</cell><cell></cell></row><row><cell>SwAV  *</cell><cell></cell><cell cols="2">40.4 61.8</cell><cell>44.0</cell><cell></cell></row><row><cell>DINO  *</cell><cell></cell><cell cols="2">40.2 61.7</cell><cell>43.8</cell><cell></cell></row><row><cell>CoKe</cell><cell></cell><cell cols="2">40.9 62.3</cell><cell>44.7</cell><cell></cell></row><row><cell>Methods</cell><cell></cell><cell cols="2">Ap mk Ap mk 50</cell><cell>Ap mk 75</cell><cell></cell></row><row><cell cols="2">Supervised</cell><cell>35.4</cell><cell>56.5</cell><cell>38.1</cell><cell></cell></row><row><cell cols="2">MoCo-v2</cell><cell>35.9</cell><cell>57.4</cell><cell>38.4</cell><cell></cell></row><row><cell cols="3">Barlow Twins 36.9</cell><cell>58.5</cell><cell>39.6</cell><cell></cell></row><row><cell>BYOL</cell><cell></cell><cell>36.9</cell><cell>58.6</cell><cell>39.5</cell><cell></cell></row><row><cell>SwAV  *</cell><cell></cell><cell>37.1</cell><cell>58.7</cell><cell>39.8</cell><cell></cell></row><row><cell>DINO  *</cell><cell></cell><cell>36.8</cell><cell>58.3</cell><cell>39.5</cell><cell></cell></row><row><cell>CoKe</cell><cell></cell><cell>37.2</cell><cell>59.1</cell><cell>39.9</cell><cell></cell></row></table><note>.1</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 17 .Table 18 .</head><label>1718</label><figDesc>]+k-means 65.9?5.7 59.8?2.0 50.9?3.7 SCAN [15] 81.8?0.3 71.2?0.4 66.5?0.4 CoKe 85.7?0.2 76.6?0.3 73.2?0.4 Comparison of clustering on CIFAR-10. SCAN is a twostage method including pre-training and fine-tuning for clustering. ]+k-means 39.5?1.9 40.2?1.1 23.9?1.1 SCAN [15] 42.2?3.0 44.1?1.0 26.7?1.3 CoKe 49.7?0.7 49.1?0.4 33.5?0.4 Comparison of clustering on CIFAR-100-20.</figDesc><table><row><cell></cell><cell></cell><cell>CIFAR-10</cell><cell></cell></row><row><cell></cell><cell>ACC</cell><cell>NMI</cell><cell>ARI</cell></row><row><cell>Supervised</cell><cell>93.8</cell><cell>86.2</cell><cell>87.0</cell></row><row><cell>DeepCluster [3]</cell><cell>37.4</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>IIC [23]</cell><cell>61.7</cell><cell>51.1</cell><cell>41.1</cell></row><row><cell>Pretext [6Methods</cell><cell>ACC</cell><cell>CIFAR-100-20 NMI</cell><cell>ARI</cell></row><row><cell>Supervised</cell><cell>80.0</cell><cell>68.0</cell><cell>63.2</cell></row><row><cell>DeepCluster [3]</cell><cell>18.9</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>IIC [23]</cell><cell>25.7</cell><cell>22.5</cell><cell>11.7</cell></row><row><cell>Pretext [6</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Self-labelling via simultaneous clustering and representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><forename type="middle">Markus</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Rupprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Constrained k-means clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristin</forename><forename type="middle">P</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayhan</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Demiriz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page">0</biblScope>
			<pubPlace>Microsoft Research, Redmond</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deep clustering for unsupervised learning of visual features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Emerging properties in self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>CoRR, abs/2104.14294, 2021. 1, 3, 8</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Big self-supervised models are strong semi-supervised learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<editor>Hugo Larochelle, Marc&apos;Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin</editor>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Improved baselines with momentum contrastive learning. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Exploring simple siamese representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="15750" to="15758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">An empirical study of training self-supervised vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<idno>abs/2104.02057</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<editor>ICLR. OpenReview.net</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with exemplar convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><forename type="middle">A</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1734" to="1747" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">With a little help from my friends: Nearest-neighbor contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debidatta</forename><surname>Dwibedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuf</forename><surname>Aytar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>CoRR, abs/2104.14548, 2021. 3, 8</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The pascal visual object classes (VOC) challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">SCAN: learning to classify images without labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Wouter Van Gansbeke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Vandenhende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Georgoulis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Proesmans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science</title>
		<editor>Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm</editor>
		<imprint>
			<biblScope unit="volume">12355</biblScope>
			<biblScope unit="page">14</biblScope>
			<date type="published" when="2020" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent -A new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><forename type="middle">H</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo?vila</forename><surname>Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bilal</forename><surname>Piot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R?mi</forename><surname>Munos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Valko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mask R-CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Subspace multi-clustering: a review. Knowledge and information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="257" to="284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Finding multiple stable clusterings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghuo</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowl. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="991" to="1021" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Invariant information clustering for unsupervised image classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Prototypical contrastive learning of unsupervised representations. CoRR, abs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Microsoft COCO: common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">8693</biblScope>
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">No fuss distance metric learning using proxies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Movshovitz-Attias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Toshev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">K</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="360" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Unsupervised learning of visual representations by solving jigsaw puzzles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mehdi</forename><surname>Noroozi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paolo</forename><surname>Favaro</surname></persName>
		</author>
		<editor>Bastian Leibe, Jiri Matas, Nicu Sebe, and Max Welling</editor>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">9910</biblScope>
			<biblScope unit="page" from="69" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Context encoders: Feature learning by inpainting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepak</forename><surname>Pathak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Kr?henb?hl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2536" to="2544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Softtriple loss: Deep metric learning without triplet sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baigui</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juhua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Large-scale distance metric learning with uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiasheng</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghuo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rong</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8542" to="8550" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Faster R-CNN: towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><forename type="middle">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei-Fei</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Int. J. Comput. Vis</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Web-scale k-means clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<editor>Michael Rappa, Paul Jones, Juliana Freire, and Soumen Chakrabarti</editor>
		<imprint>
			<date type="published" when="2010" />
			<publisher>WWW</publisher>
			<biblScope unit="page" from="1177" to="1178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Understanding contrastive representation learning through alignment and uniformity on the hypersphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongzhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page" from="9929" to="9939" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Distance metric learning for large margin nearest neighbor classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><forename type="middle">K</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="207" to="244" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wan-Yen</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Detectron2</surname></persName>
		</author>
		<idno>2019. 13</idno>
		<ptr target="https://github.com/facebookresearch/detectron2" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via non-parametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stella</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Scaling SGD batch size to 32k for imagenet training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Igor</forename><surname>Gitman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boris</forename><surname>Ginsburg</surname></persName>
		</author>
		<idno>abs/1708.03888</idno>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Barlow twins: Self-supervised learning via redundancy reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jure</forename><surname>Zbontar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">St?phane</forename><surname>Deny</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Marina Meila and Tong Zhang</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="12310" to="12320" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Yew-Soon Ong, and Chen Change Loy. Online deep clustering for unsupervised representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohang</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Local aggregation for unsupervised learning of visual embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chengxu</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><forename type="middle">Lin</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Yamins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6001" to="6011" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
