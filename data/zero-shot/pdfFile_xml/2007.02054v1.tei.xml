<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Inference Stage Optimization for Cross-scenario 3D Human Pose Estimation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuecheng</forename><surname>Nie</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Yitu Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Inference Stage Optimization for Cross-scenario 3D Human Pose Estimation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Existing 3D human pose estimation models suffer performance drop when applying to new scenarios with unseen poses due to their limited generalizability. In this work, we propose a novel framework, Inference Stage Optimization (ISO), for improving the generalizability of 3D pose models when source and target data come from different pose distributions. Our main insight is that the target data, even though not labeled, carry valuable priors about their underlying distribution. To exploit such information, the proposed ISO performs geometry-aware self-supervised learning (SSL) on each single target instance and updates the 3D pose model before making prediction. In this way, the model can mine distributional knowledge about the target scenario and quickly adapt to it with enhanced generalization performance. In addition, to handle sequential target data, we propose an online mode for implementing our ISO framework via streaming the SSL, which substantially enhances its effectiveness. We systematically analyze why and how our ISO framework works on diverse benchmarks under cross-scenario setup. Remarkably, it yields new state-of-the-art of 83.6% 3D PCK on MPI-INF-3DHP, improving upon the previous best result by 9.7%. Code will be released.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>3D human pose estimation aims to localize 3D human body joints in images or videos. As a fundamental task in computer vision, it is widely applied to human-robot interaction <ref type="bibr" target="#b14">[15]</ref>, action recognition <ref type="bibr" target="#b51">[52]</ref>, human tracking <ref type="bibr" target="#b31">[32]</ref>, etc. This task is commonly resolved in a fully-supervised manner with golden annotations <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b53">54]</ref> that are collected in well-controlled laboratorial environments <ref type="bibr" target="#b21">[22]</ref>. Despite their success in constrained scenarios, these methods are hardly generalized to new scenarios (e.g., in-the-wild scenes), due to severe differences in the underlying distributions (e.g., varying poses, camera viewpoints, body sizes and appearances).</p><p>Recent works address such a generalization challenge by leveraging either data augmentation strategies such as image composition <ref type="bibr" target="#b31">[32]</ref> and synthesis <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b47">48]</ref>, or more complicated model learning strategies like introducing kinematics priors <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b11">12]</ref>, separating 2D and depth features <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b16">17]</ref> or adopting adversarial learning <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b49">50]</ref>. However, they are still limited to the cases where training and test samples have similar poses and otherwise tend to suffer large performance drop, since their trained model is commonly biased to the training distribution and hardly generalizes well to an unseen one that is very different.</p><p>In this work, we propose a novel scheme named Inference Stage Optimization (ISO). Instead of focusing on improving model training, ISO improves and adapts the model at its inference stage before making predictions ( <ref type="figure">Fig. 1)</ref>. Our insight is that the target samples, although not labeled, carry valuable information about their distribution, which could be exploited to help adapt the model in the inference stage for correcting unfavorable training bias and improving generalization performance. <ref type="figure">Figure 1</ref>: Illustration on our main idea. We consider cross-scenario setting where the model is trained on the source scenario (e.g., indoor scenes) but applied to a new target scenario (e.g., in-the-wild scenes). Existing methods (upper panel) usually use the trained model for predictions directly, which would suffer performance drop under such cross-scenario setup. Different from them, ISO adapts the model at its inference stage via performing self-supervised learning (SSL) on unlabeled target samples before making predictions (bottom panel), which largely improves its generalizability. Red arrow represents back-propagation based model update. Errors are labeled in black arrows.</p><p>However, exploiting such prior from unlabeled data is highly non-trivial. Inspired by recent success of self-supervised learning (SSL) techniques for learning good representations from unlabeled samples in other domains, we propose to leverage SSL to explore the underlying prior from unlabeled target instances. Different from general objects, human poses present clear and informative geometry structure, thus we deploy two different SSL methods, namely random projection adversary <ref type="bibr" target="#b13">[14]</ref> and geometric cycle consistency <ref type="bibr" target="#b6">[7]</ref>, which are simple but effective at learning geometry-aware representations. ISO therefore enables the model to mine both geometric and distributional information from target instances and quickly adapt to the target scenario. As such, the model can estimate 3D poses more reliably across different scenarios, even in presence of severe distribution shifts.</p><p>Concretely, when training on labeled source data, instead of only performing fully-supervised learning (FSL) <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b53">54]</ref>, our proposed ISO trains the model with FSL and SSL jointly. Such a training scheme enables the model to leverage geometry-wise feedback from SSL to learn representations and estimate 3D poses. This also facilitates model optimization in the inference stage. During inference, ISO adapts the model parameters to the new scenario and distribution via performing SSL on each target instance. Equipped with such instance-specific adaptation, the model can estimate 3D pose for each sample from the new target scenario accurately. In addition, we also develop an online ISO to accumulate the learned adaptation knowledge from a sequence of target samples, which would speed up model adaptation and reduce computational overhead.</p><p>We conduct extensive experiments under cross-scenario setup: training a model on Human3.6M <ref type="bibr" target="#b21">[22]</ref> and evaluate it on MPI-INF-3DHP <ref type="bibr" target="#b30">[31]</ref> and 3DPW <ref type="bibr" target="#b48">[49]</ref>. Notably, ISO achieves new state-of-the-art accuracy, 83.6% 3D PCK on MPI-INF-3DHP, improving upon the previous best result by 9.7%.</p><p>Our contributions are four-fold. 1) To our best knowledge, we are among the first to explore the practical cross-scenario 3D pose estimation task and develop an effective solution (i.e., ISO). Distinguished from existing works, we explore how to effectively adapt the models during the inference stage. 2) We identify and investigate two simple SSL techniques suitable for 3D pose estimation under the ISO framework, to exploit geometric and distributional knowledge from unlabeled target data. 3) We develop an online ISO framework, which can handle sequential data effectively and naturally apply to practical scenes where data usually come online sequentially. 4) We provide understandings on why and how ISO works for cross-scenario generalization by conducting systematic analysis, which may inspire future works on improving generalization of human pose estimation.</p><p>2 Related work 3D pose estimation. Lots of deep methods have been proposed for 3D pose estimation from 2D representations (e.g., images or poses) <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b42">43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b54">55]</ref>, which highly rely on well-annotated datasets. These methods easily overfit to distribution-specific patterns such as camera views and pose subjects, and can hardly generalize to new scenarios. To improve their generalizability, semi-and weakly-supervised methods <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b35">36]</ref> have been developed. Some <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b35">36]</ref> use kinematics priors for regularization or post-processing; others <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b49">50]</ref> leverage adversarial training or separate 2D and depth features <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b16">17]</ref> for domain adaptation. Despite encouraging results, the applicability of these methods is still restricted in scope defined by the datasets they are trained on. Recently, several geometry-driven self-supervised methods <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b27">28]</ref> use geometry consistency or epipolar constraint to generate 3D poses automatically. Different from all above methods, we are the first to learn distributional information from target instances at inference stage via SSL, which is demonstrated an effective method for out-of-distribution 3D pose estimation.</p><p>Learning on target instances. Learning on target instances has emerged as a powerful technique for mining complex data distributions and priors. Bau et al. <ref type="bibr" target="#b2">[3]</ref> improve photo manipulation performance by adapting image priors to the statistics of an individual target image. Sun et al. <ref type="bibr" target="#b44">[45]</ref> leverage rotation prediction pretext task for solving domain shift in image classification. Shocher et al. <ref type="bibr" target="#b39">[40]</ref> perform super-resolution of a target image via learning to recover it from its downsampled counterpart. However, these methods cannot be directly applied to 3D pose estimation. In this work, we propose a novel ISO framework to improve 3D pose estimation under cross-scenario setup through mining geometric and distributional knowledge from target instances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem formulation</head><p>Let I denotes an image and x ? R J?2 denotes 2D spatial coordinates of J keypoints of the human in the image. X ? R J?3 denotes the corresponding 3D joints position. We consider such cross-scenario setup: the model is trained on a source scenario D s (e.g., indoor scenes) with pose distribution P, and applied to a new scenario D t (e.g., in-the-wild scenes) with unseen poses, viewpoints, body sizes and appearances drawn from a different distribution Q.</p><p>Empirically, a pose distribution P can be disentangled to appearance and geometry factors <ref type="bibr" target="#b37">[38]</ref>. The cross-scenario setup is faced with the pose distribution drift w.r.t. both of them. However, drift of appearance distribution can be well solved by powerful off-the-shelf 2D pose estimators. Thus we focus on addressing the drift w.r.t. pose geometry (i.e., poses, viewpoints, etc). We directly work with skeleton data and aim to obtain a 3D pose model that can lift 2D poses to 3D ones with good adaptive capability to a new scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Suppose we have a pair of 2D and corresponding 3D poses</head><formula xml:id="formula_0">{(x i , X i )} N i=1 drawn i.i.d.</formula><p>from the source distribution P. Existing methods usually train a 3D pose model on these training samples and apply it directly on target samples drawn from the target distribution Q. In particular, the model with parameter ? is trained in a fully supervised learning (FSL) scheme:</p><formula xml:id="formula_1">min ? 1 N N i=1 L f (x i , X i ; ?),<label>(1)</label></formula><p>where L f is a fully-supervised loss. Generally, L f is defined as mean squared errors (MSE) of the predicted and ground truth (GT) poses <ref type="bibr" target="#b29">[30]</ref>. Several earlier works complement such a loss with a bone supervision loss <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b53">54]</ref>. Accordingly, L f is formulated as</p><formula xml:id="formula_2">L f = X ? X 2 2 + B ? B 2 2 .<label>(2)</label></formula><p>Here X and X denote the GT and predicted 3D poses, respectively; B and B denote the GT and predicted bone vectors computed from X and X, respectively <ref type="bibr" target="#b42">[43]</ref>. The obtained model is typically biased to the training samples and thus suffers limited generalizability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inference stage optimization</head><p>We introduce our Inference Stage Optimization (ISO) framework that allows a 3D pose model to mine geometric and distributional knowledge from target instances during the inference stage, and adapt to new scenarios with improved generalization performance. For simplicity, we consider a 3D </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Training</head><p>Similar to existing methods, when training on the source scenario D s , our model parameters ? can be updated by solving the optimization problem in Eqn. <ref type="bibr" target="#b0">(1)</ref>. We call this the fully-supervised learning (FSL) task. However, our ISO also performs a self-supervised learning (SSL) task with self-supervised loss L s (x) to train the pose estimation model so that it can learn to adapt via SSL feedback in the inference stage.</p><p>We choose two geometry-aware SSL methods to exploit pose geometry information from the skeleton data: random projection adversary <ref type="bibr" target="#b13">[14]</ref> and geometric cycle consistency <ref type="bibr" target="#b6">[7]</ref>, which are effective at geometry adaptation. Note with our framework, more SSL methods can be explored in the future.</p><p>ISO-Adversary. The idea of random projection adversary SSL is that if a 2D pose is lifted to 3D accurately, and rotated and projected with randomly generated camera view, the resulting 'synthetic' 2D pose should lie within the valid 2D poses distribution. We build a pose discriminator D to classify each input 2D pose as real or fake (randomly projected from 3D poses). The loss is defined as</p><formula xml:id="formula_3">L adv = E(log(D(r))) + E(log(1 ? D(y))),<label>(3)</label></formula><p>where r and y denote real and fake 2D poses, respectively. We follow <ref type="bibr" target="#b13">[14]</ref> to generate random camera view by sampling an azimuth angle between [??, ?] and an elevation angle between [??/9, ?/9].</p><p>ISO-Cycle. The geometric cycle consistency SSL complements ISO-Adversary with cycle consistency among 2D and 3D spaces. Specifically, by lifting the randomly projected 2D pose y back to 3D and then re-projecting it to the original camera view, the resulting 3D and 2D poses should be consistent with the original ones. The training can thus be supervised by exploiting the cycle-consistency of the lift-project-lift process. Combined with the adversarial loss in Eqn. <ref type="formula" target="#formula_3">(3)</ref>, the loss is</p><formula xml:id="formula_4">L cyc = L adv + ? 2D x ? x 2 2 + ? 3D X ? X 2 2 ,<label>(4)</label></formula><p>where x and x denote original and re-projected 2D poses, X and X denote lifted and re-lifted 3D poses, ? 2D = 10 and ? 3D = 0.1 are weights for 2D and 3D loss terms, respectively.</p><p>During training, we optimize both FSL and SSL tasks to update network parameters. Following standard multi-task learning framework <ref type="bibr" target="#b4">[5]</ref>, the SSL task shares some of the network parameters ? e = (? 1 , . . . , ? ? ) with the FSL task, where ? ? {1, . . . , K}. We call these shared ? layers as shared feature extractor. The SSL task uses its task-specific parameters ? s = (? ?+1 , . . . , ? K ). We call these unshared parameters ? s the SSL head, and ? f = (? ?+1 , . . . , ? K ) the FSL head. As shown in <ref type="figure" target="#fig_0">Fig. 2</ref> (a), the joint architecture has a shared bottom and two heads. Both heads output a J ? 3 vector, indicating the 3D pose prediction. The only difference between them is that their network parameters are updated by solving different optimization problems.</p><p>We train the model in a multi-task learning fashion on the same data drawn from P. The joint-training problem is formulated as</p><formula xml:id="formula_5">min ?e,? f ,?s max ? d 1 N N i=1 L f (x i , X i ; ? e , ? f ) + ?L s (x i ; ? e , ? s , ? d ) .<label>(5)</label></formula><p>where ? d denotes network parameters of the pose discriminator D and ? = 0.1 is a relative weight for balancing different loss terms. Here L s denotes the self-supervised loss in Eqn. <ref type="bibr" target="#b2">(3)</ref> or Eqn. (4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Inference</head><p>After minimizing Eqn. (5) on data from D s with distribution P, we obtain the network parameters ? P e , ? P f , ? P s and ? P d for the shared featured extractor, FSL head, SSL head and pose discriminator, respectively. During inference, ISO performs SSL on each single target instance x to update the shared feature extractor, SSL head and pose discriminator ( <ref type="figure" target="#fig_0">Fig. 2 (b)</ref>), which can be formulated as</p><formula xml:id="formula_6">min ?e,?s max ? d L s (x; ? e , ? s , ? d ).<label>(6)</label></formula><p>The SSL process is done using standard gradient descent (or a variant) with learning rate ? and iteration T . Additionally, a mini-batch contains several copies of x such that a single optimization iteration can involve adversarial samples (i.e., randomly projected 2D poses) as much as possible, which ensures better performance. After optimizing Eqn. <ref type="formula" target="#formula_6">(6)</ref>, we obtain the updated parameter ? * e of the shared feature extractor, and make a prediction using ? * = (? * e , ? P f ) <ref type="figure" target="#fig_0">(Fig. 2 (c)</ref>). The motivation behind this formulation is that the joint training scheme (FSL+SSL at the training phase) enables the FSL head to be adaptive to the representations learned from SSL. In this way, the FSL head, though being frozen, can be directly applied for making accurate predictions over the representations updated by the SSL branch during inference.</p><p>We implement ISO in a vanilla mode, i.e., performing SSL on each target instance individually before making prediction on it. For vanilla ISO, the optimization problem in Eqn. (6) is always initialized with parameters ? P e , ? P s and ? P d . After performing T iterations SSL on i th instance x i , we obtain the updated parameters ? i e , ? i s , ? i d . After making a prediction on x i , ? i e , ? i s and ? i d are discarded. Besides vanilla ISO, when the target instances arrive sequentially, we propose a corresponding online ISO by streaming the SSL to continuously exploit distributional knowledge among them. Specifically, the online ISO solves the same optimization problem to update network parameters. However, when learning on x i , ? e , ? s and ? d are instead initialized with ? i?1 e , ? i?1 s and ? i?1 d updated on the previous instance x i?1 . This allows the model to benefit from the distributional information available in instances x 1 , . . . , x i?1 as well as x i , and thus speeds up the model adaptation.</p><p>The summary of both vanilla and online ISO on target instances during inference is illustrated in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Network details</head><p>Our 3D pose estimation model primarily consists of the residual block (RB) proposed in <ref type="bibr" target="#b29">[30]</ref>. Each RB consists of two linear layers, Batch Normalization (BN) <ref type="bibr" target="#b20">[21]</ref>, leaky ReLU <ref type="bibr" target="#b17">[18]</ref> and dropout <ref type="bibr" target="#b40">[41]</ref> with residual connection <ref type="bibr" target="#b18">[19]</ref>. The feature dimension and dropout probability are set to 1,024 and 0.5, respectively. Specifically, the shared feature extractor consists of a linear layer followed by three stacked RBs. It first transforms the input 2J-dimension vector to a 1024-dimension vector, which is then fed to the FSL and SSL heads separately. Both the FSL and SSL heads contain an unshared RB followed by a linear layer for 3D pose estimation. The pose discriminator takes as input the 2J-dimension vector (2D pose) and outputs classification results (real or fake). We use three stacked RBs but remove all BN layers. For the 2-way classifier used for representation learning analysis (Sec. 4.3), we use the same architecture as the pose discriminator, except for the first layer since it takes 3D poses as inputs. The hidden feature used for visualization is extracted from the final residual block of the classifier (1024-dimension vector). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We aim to answer the following questions through experiments: 1) Is ISO able to improve crossscenario generalization performance of 3D pose estimation? 2) How does ISO take effect to boost generalization performance? 3) Does ISO introduce too much overhead in the inference stage?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experiment setup</head><p>We quantitatively evaluate the generalizability of our method in cross-scenario setup, i.e., training a model on Human3.6M and evaluate its performance on the more challenging 3D pose benchmarks MPI-INF-3DHP <ref type="bibr" target="#b30">[31]</ref> and 3DPW <ref type="bibr" target="#b48">[49]</ref>, which feature more diverse motions and scenes. We train our model on subjects S1, S5, S6, S7 and S8 of Human3.6M <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b55">56]</ref> and evaluate it on the official test set of MPI-INF-3DHP and 3DPW. For MPI-INF-3DHP, we use Mean Per Joint Position Error (MPJPE), 3D Percentage of Correct Keypoints (PCK) with a threshold 150mm and the corresponding Area Under Curve (AUC) as metrics and adopt three evaluation protocols <ref type="bibr" target="#b16">[17]</ref>: (i) unscaled (US); (ii) glob. scaled (GS); (iii) procrustes (PA). For 3DPW, we follow <ref type="bibr" target="#b24">[25]</ref> to use Procrustes Aligned MPJPE (PA-MPJPE) and 3D PCK as metrics. In addition, we use MPII <ref type="bibr" target="#b0">[1]</ref> and LSP <ref type="bibr" target="#b22">[23]</ref>, the standard 2D pose benchmarks with diverse scenes that reflect challenging factors such as strong pose deformations and abundant viewpoints in the real world, to qualitatively verify the effectiveness of our method. We train our model for 200 epochs on Human3.6M, adopting Adam <ref type="bibr" target="#b25">[26]</ref> as optimizer with an initial learning rate of 2 ? 10 ?4 and using exponential decay and mini-batch size of 64. We use horizontal flip augmentation at both training and inference. During inference, for both 3DHP and 3DPW, we freeze batch normalization layers and perform SSL on each single target instance before making prediction. Specifically, for both vanilla and online ISO, we adopt Adam optimizer with learning rate ? = 2 ? 10 ?5 . We set iteration T as 10 and 1 for vanilla and online ISO, respectively. In following experiments, unless otherwise stated we use ISO-Cycle SSL technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Does ISO boost generalization?</head><p>We compare ISO (online) with several state-of-the-art approaches on 3DHP and 3DPW datasets. Some methods consider domain adaptation <ref type="bibr" target="#b52">[53]</ref>, or use complex network architectures <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b12">13]</ref> and training schemes <ref type="bibr" target="#b49">[50,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b45">46]</ref>. We use Baseline to denote the plain model trained with only FSL task; Joint is the model trained with FSL and SSL tasks jointly; Vanilla refers to the model adapted using vanilla ISO; Online is the model adapted using online ISO.</p><p>Results on 3DHP. We compare ISO against the methods in <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b5">6]</ref> under cross-scenario setup. We directly report their results from original papers. Note some of them have missing metrics or do not specify evaluation protocols. Additionally, we implement and compare with methods <ref type="bibr" target="#b53">[54,</ref><ref type="bibr" target="#b49">50]</ref> based on their released code. <ref type="bibr" target="#b0">1</ref>  <ref type="table" target="#tab_0">Table 1</ref> shows the results under different metrics and protocols. Our method achieves the highest accuracy in terms of 3D PCK and MPJPE across all evaluation protocols, outperforming the second best by a large margin. This verifies the generalizability of our approach.</p><p>Results on 3DPW. We also compare ISO with state-of-the-art approaches on 3DPW. Some methods exploit temporal information <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b12">13]</ref>, while some others are trained on the training set of 3DPW <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b45">46]</ref>. <ref type="table" target="#tab_2">Table 2</ref> reports the results. Our method outperforms several approaches in terms of PA-MPJPE and even achieves comparable results with the fully-supervised method <ref type="bibr" target="#b45">[46]</ref>. This shows the generalization capability of our method.  Qualitative results. We visualize some 3D pose estimations of ISO on the challenging LSP, MPII, 3DHP and 3DPW datasets in <ref type="figure" target="#fig_1">Fig. 3</ref>. Most of the involved poses and camera views are unseen to our model. However, our ISO can still achieve good results even in presence of self-occlusion (1st column), large pose variations (2nd, 3rd column), and unusual views (4th column). Additionally, ISO compared with Baseline produces more geometrically plausible results. These verify the superior generalizability of ISO to challenging new scenarios. How does the choice of self-supervised learning technique impact accuracy? We first study the influence of different SSL techniques on the model's generalizability. We use Adv and Cyc to represent ISO-Adversary and ISO-Cycle SSL techniques, respectively. The results are shown in <ref type="table" target="#tab_3">Table 3</ref>. We can observe Adv (Joint, Vanilla and Online settings) improves accuracy upon Baseline by a large margin. In addition, we observe Cyc achieves even better results than Adv on all three settings by adding additional geometric cycle consistency constraint. These observations demonstrate the importance of adversarial learning and geometric knowledge to cross-scenario 3D pose estimation, which may motivate more SSL techniques in the future.</p><p>How does hyper-parameters impact accuracy? We then analyze the sensitivity of our method to hyper-parameters i.e., learning rate ? and training iteration T used when performing ISO (Cyc). Specifically, we report 3D PCK for both vanilla and online ISO, and show the results in <ref type="figure">Fig. 4</ref>. We first analyze the impact of T by varying T while fixing ? to 2e ?5 . From <ref type="figure">Fig. 4 (Left)</ref> we can observe that increasing T from 1 to 10 for vanilla ISO, the accuracy is consistently increased from 81.5% PCK to 82.5% PCK, due to the geometric knowledge mined from the target instances. However, further increasing T degrades the performance, caused by overfitting to the SSL task. We can also see that the model adapted under online ISO achieves best performance 83.6% PCK when T = 1, and the performance decreases when adopting a larger T . The main reason is performing SSL under online mode with T &gt; 1 will make the model quickly overfit to the SSL task, thus hamper 3D pose estimation. Then we fix T to 10 and 1 for vanilla and online ISO, respectively, and apply different ? Errors are labeled in black arrows. Please refer to supplement for more qualitative results.</p><p>(ranging from 2e ?3 to 2e ?7 ) to study the influence of learning rate on performance. <ref type="figure">Fig. 4 (Right)</ref> shows that both modes achieve best performance when ? = 2e ?5 . Further decreasing learning rate, the performance of both modes gradually degrades and gets close to Joint (i.e., the model without adapting) with 81.3% PCK. However, performing ISO with a large ? (e.g., 2e ?3 ), the accuracy quickly drops, especially for online mode (70.9% PCK), since training with a large learning rate, the model easily overfits to the SSL task and thus restricts performance. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Why ISO performs well?</head><p>We investigate why and how ISO can improve cross-scenario generalization. All below experiments are conducted on 3DHP using Online under the unscaled protocol, unless otherwise specified.</p><p>Geometric distribution alignment. Our main insight is performing ISO on target instances enables the model to mine geometric knowledge (e.g., limb length ratios and body parts symmetry) about the target distribution. To verify this, we inspect the distribution alignment in geometry of output poses from Baseline and ISO (Online). Specifically, we compute the limb length ratios of upper to lower arms and legs (both for left and right sides), and torso <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b6">7]</ref>. The results are shown in <ref type="figure">Fig. 5</ref>. We can observe the ratio distributions generated by ISO are sharper and closer to the real  ratio distributions of 3DHP, compared with those by Baseline. Additionally, ISO produces more symmetric ratio distributions for the left and right sides of arms and legs than Baseline, which verifies its ability to capture the symmetry of body parts. All these results clearly demonstrate the model adapted via ISO can mine geometric knowledge about the target distribution and thus generalize well to it, without requiring any prior for regularization <ref type="bibr" target="#b11">[12]</ref> or post-processing <ref type="bibr" target="#b55">[56]</ref>.</p><p>Representation learning. To further analyze how ISO helps during inference, we train a 2-way classifier to predict which dataset (Human3.6M or 3DHP) a given 3D pose comes from. The classifier after trained can achieve averagely 99.5% accuracy on both datasets, demonstrating the classifier's ability to accurately capture the inter-dataset difference of geometry and judge the dataset (or distribution) a 3D pose comes from. Then, we apply this classifier to distinguish whether the 3D poses estimated by Baseline and ISO are close to the distribution of GT 3D poses from 3DHP. The classifier only identifies 52.6% of the 3D poses estimated by Baseline drawn from the target 3DHP distribution, while 83.4% of the 3D poses estimated by ISO drawn from 3DHP. This demonstrates the representations adapted by ISO are more similar to the target ones. Additionally, we visualize the hidden feature (1024-dimension vector) of the classifier by t-SNE <ref type="bibr" target="#b28">[29]</ref> in <ref type="figure" target="#fig_3">Fig. 6</ref>. We can see performing SSL on target instances draws the feature distribution of the generated 3D poses closer to those of GTs (blue and green circles). All these results clearly demonstrate ISO enables the model to adapt to the real distribution of 3DHP during inference stage.</p><p>Per body-part improvement. In addition to distribution alignment, we also study the performance improvement of our method on each body part. We first divide all skeleton joints into eight parts: Hip, Spine, Shoulder, Head, Elbow, Wrist, Knee and Ankle. Then we compute mean 3D PCK for each part and present the results in <ref type="figure" target="#fig_4">Fig. 7</ref>. We can see Online improves over Baseline by a large margin for Head, Elbow, Wrist and Ankle. All these parts are difficult to estimate especially for samples from new scenarios, due to high flexibility. However, Online successfully estimates these parts, which demonstrates the effectiveness of our method for cross-scenario generalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Is ISO costly or sensitive to noise?</head><p>Inference time analysis. Our ISO scheme is slightly slower than a regular inference scheme, which only performs a single forward pass for each sample. Here, we provide two potential solutions to improve the computational efficiency. For vanilla ISO, we set iteration T to 1 (instead of 10) and learning rate ? to 2e ?4 (instead of 2e ?5 ). The new setup is denoted as Vanilla-lr. For online ISO, since T is already 1, we propose to perform SSL once per 10 samples, denoted as Online-skip. For all settings, we count average per-sample inference time in seconds and show results in <ref type="table" target="#tab_4">Table 4</ref>. <ref type="bibr" target="#b1">2</ref> We observe by adopting the new inference setup, the computational efficiency can be improved by nearly 8? and 7? speedup for vanilla and online ISO, respectively, with good performance almost the same as the original. Significantly, we see Online-skip achieves almost the same efficiency as the regular inference scheme while improving the performance by a large margin.</p><p>Robustness to noisy observations. We evaluate robustness of our method under different levels of noise by adding noise to the input 2D poses. Specifically, we add Gaussian noise N (0, ?) to the GT 2D poses, where ? is the standard deviation in pixel <ref type="bibr" target="#b29">[30]</ref>. The results are shown in <ref type="table" target="#tab_5">Table 5</ref>. The accuracy decreases linearly with ?, which indicates the noise of 2D poses has major impact on the results.  However, this issue can be alleviated by using state-of-the-art 2D pose estimators <ref type="bibr" target="#b34">[35,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b9">10]</ref> or training with synthetic error <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b5">6]</ref>. Note the maximum person size from head to foot is approximately 200px in the input data. Thus, Gaussian noise with ? = 10 is considered as extremely large. However, even under such large noise, ISO produces a better result (79.6% 3D PCK) than Baseline (78.9% 3D PCK with GT 2D inputs), which verifies its robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>We propose a new ISO framework for improving the generalizability of 3D pose estimation models. It explores underlying priors in target instances and leverages SSL techniques to mine such knowledge for estimating 3D poses accurately even under strong distribution shifts between source and target scenarios. ISO achieves state-of-the-art performance on challenging MPI-INF-3DHP benchmark under cross-scenario setting. In future, we plan to investigate more SSL techniques in our framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader impact</head><p>We propose Inference Stage Optimization (ISO) framework for cross-scenario 3D human pose estimation, which enables the 3D pose estimation model to mine distributional knowledge about the target scenario and quickly adapt to it with enhanced generalization. It can be applied to lots of 3D pose estimation related applications including human-robot interaction, action recognition, human tracking, etc., which are all important research topics in artificial intelligence. Generally, improving generalization performance for the 3D human pose estimation task may have many applications, which could be positive, negative or more complicated, but would depend on the nature of the organization using them and what task they use these applications for.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Overall pipeline of ISO. (a) We first train our model by solving optimization of both FSL and SSL tasks in the source scenario with labeled data. During inference, given each unlabeled target sample, (b) we first perform SSL on it to update network parameters and (c) exploit the adapted network for final pose estimation. pose model implemented by a K-layer neural network with parameters ? k for layer k. The stacked parameter vector ? = (? 1 , . . . , ? K ) specifies the entire model for 3D pose estimation. The overall pipeline is illustrated in Fig. 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Example 3D pose estimations from LSP, MPII (top row) and 3DHP, 3DPW (bottom row). ISO results are shown in the left four columns. The rightmost column shows results of Baseline.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :Figure 5 :</head><label>45</label><figDesc>Analysis on hyper-parameters. Left: Training iteration T . Right: Learning rate ?. For online ISO, the best T and ? are set to 1 and 2e ?5 . Further increasing them causes poor performance. For vanilla ISO, the best T and ? are set to 10 and 2e ?5 . Distribution of limbs length ratio produced by ISO and Baseline on 3DHP. Left: Ratio of upper to lower arm. Middle: Ratio of upper to lower leg. Right: Ratio of upper to lower torso. Ground truth ratios are ? 1.3, ? 1.3 and ? 1.0 for arm, leg and torso, respectively. L and R indicate left and right body parts, respectively.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 :</head><label>6</label><figDesc>Visualization of hidden features using t-SNE.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :</head><label>7</label><figDesc>Per body-part accuracy on 3DHP. PCK of each part is computed as the PCK of corresponding skeleton joints.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>Inference Stage Optimization. :target instances {xi} N i=1 , pre-trained network parameters ? P e , ? P f , ? P s , ? P d , learning rate ?, training iteration T . Output :3D pose estimations {Xi} N i=1 .</figDesc><table><row><cell cols="2">Input Initialization: ? 0  *  ? ? P  *  with  *  ? {e, s, d}</cell></row><row><cell>for i = 1 to N do</cell><cell></cell></row><row><cell cols="2">if vanilla ISO then</cell></row><row><cell cols="2">? i  *  ? ? 0  *  with  *  ? {e, s, d}</cell></row><row><cell>else</cell><cell></cell></row><row><cell cols="2">// online ISO</cell></row><row><cell>? i  *  ? ? i?1  *</cell><cell>with  *  ? {e, s, d}</cell></row><row><cell>end</cell><cell></cell></row><row><cell cols="2">for t = 1 to T do</cell></row><row><cell cols="2">Compute gradients ? ? *  Ls(xi; ? i e , ? i s , ? i d ) (Eqn. (6)) where  *  ? {e, s, d}.</cell></row><row><cell cols="2">Update parameters: ? i  *  ? ? i  *  ? ?? ? *  Ls(xi; ? i e , ? i s , ? i d ) where  *  ? {e, s, d}.</cell></row><row><cell>end</cell><cell></cell></row><row><cell cols="2">Predict 3D pose Xi using the network parameters ? i = (? i e , ? P f ) .</cell></row><row><cell>end</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Results on 3DHP. * denotes our implementation. US, GS and PA denote different protocols.</figDesc><table><row><cell>Method</cell><cell>PCK ?</cell><cell>AUC ?</cell><cell>MPJPE ?</cell></row><row><cell>Yang [53]</cell><cell>69.0</cell><cell>32.0</cell><cell>-</cell></row><row><cell>Ci [11]</cell><cell>74.0</cell><cell>36.7</cell><cell>-</cell></row><row><cell>Chang [6]</cell><cell>76.5</cell><cell>40.2</cell><cell>-</cell></row><row><cell>Wandt [50]</cell><cell>81.8</cell><cell>54.8</cell><cell>92.5</cell></row><row><cell>Zhao [54]  *  (US)</cell><cell>76.2</cell><cell>42.8</cell><cell>126.1</cell></row><row><cell>Ours (US)</cell><cell>83.6</cell><cell>48.2</cell><cell>92.2</cell></row><row><cell>Zhao [54]  *  (GS)</cell><cell>77.1</cell><cell>45.5</cell><cell>108.0</cell></row><row><cell>Ours (GS)</cell><cell>84.5</cell><cell>50.9</cell><cell>88.4</cell></row><row><cell>Wandt [50]  *  (PA)</cell><cell>81.6</cell><cell>47.0</cell><cell>95.4</cell></row><row><cell>Zhao [54]  *  (PA)</cell><cell>86.0</cell><cell>46.7</cell><cell>96.8</cell></row><row><cell>Ours (PA)</cell><cell>91.3</cell><cell>54.0</cell><cell>75.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Our results (14-joints) on 3DPW. * denotes training using GT data.</figDesc><table><row><cell>Method</cell><cell>PCK ?</cell><cell>PA-MPJPE ?</cell></row><row><cell>Martinez [30]</cell><cell>-</cell><cell>157.0</cell></row><row><cell>Dabral [12]</cell><cell>-</cell><cell>92.3</cell></row><row><cell>Kanazawa [24]</cell><cell>84.1</cell><cell>76.7</cell></row><row><cell>Kanazawa [25]</cell><cell>86.4</cell><cell>80.1</cell></row><row><cell>Arnab [2]  *</cell><cell>-</cell><cell>77.2</cell></row><row><cell>Doersch [13]</cell><cell>-</cell><cell>74.7</cell></row><row><cell>Sun [46]  *</cell><cell>-</cell><cell>69.5</cell></row><row><cell>Ours</cell><cell>82.0</cell><cell>70.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Ablation of different SSL techniques on MPI-INF-3DHP.</figDesc><table><row><cell>Method</cell><cell>PCK</cell><cell>AUC</cell><cell>MPJPE</cell></row><row><cell>Baseline</cell><cell>78.9</cell><cell>43.7</cell><cell>103.8</cell></row><row><cell>Joint-Adv</cell><cell>80.9</cell><cell>46.1</cell><cell>97.0</cell></row><row><cell>Vanilla-Adv</cell><cell>82.1</cell><cell>47.2</cell><cell>95.3</cell></row><row><cell>Online-Adv</cell><cell>83.0</cell><cell>47.6</cell><cell>93.1</cell></row><row><cell>Joint-Cyc</cell><cell>81.3</cell><cell>46.9</cell><cell>96.2</cell></row><row><cell>Vanilla-Cyc</cell><cell>82.5</cell><cell>47.6</cell><cell>94.1</cell></row><row><cell>Online-Cyc</cell><cell>83.6</cell><cell>48.2</cell><cell>92.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Inference time analysis of different inference modes of ISO.</figDesc><table><row><cell>Method</cell><cell>PCK</cell><cell>AUC</cell><cell>MPJPE</cell><cell>Time[s]</cell></row><row><cell>Vanilla</cell><cell>82.5</cell><cell>47.6</cell><cell>94.1</cell><cell>0.244</cell></row><row><cell>Vanilla-lr</cell><cell>82.1</cell><cell>47.3</cell><cell>94.6</cell><cell>0.027</cell></row><row><cell>Online</cell><cell>83.6</cell><cell>48.2</cell><cell>92.2</cell><cell>0.027</cell></row><row><cell>Online-skip</cell><cell>83.0</cell><cell>48.0</cell><cell>92.7</cell><cell>0.004</cell></row><row><cell>Baseline</cell><cell>78.9</cell><cell>43.7</cell><cell>103.8</cell><cell>0.003</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 :</head><label>5</label><figDesc>Performances with different levels 2D pose noise from N (0, ?).</figDesc><table><row><cell>Method</cell><cell>PCK</cell><cell>AUC</cell><cell>MPJPE</cell></row><row><cell>ISO</cell><cell>83.6</cell><cell>48.2</cell><cell>92.2</cell></row><row><cell>ISO (? = 5)</cell><cell>82.5</cell><cell>47.4</cell><cell>94.0</cell></row><row><cell>ISO (? = 10)</cell><cell>79.6</cell><cell>43.7</cell><cell>103.4</cell></row><row><cell>Baseline</cell><cell>78.9</cell><cell>43.7</cell><cell>103.8</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Implementation is based on source code: SemGCN and RepNet for<ref type="bibr" target="#b53">[54]</ref> and<ref type="bibr" target="#b49">[50]</ref>, respectively.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">The time is counted on single GPU TITAN X and CPU Intel I7-5820K 3.3GHz.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">2d human pose estimation: New benchmark and state of the art analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Exploiting temporal context for 3d human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Semantic photo manipulation with a generative image prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hendrik</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Peebles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Exploiting spatial-temporal relationships for 3d pose estimation via graph convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujun</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuhao</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Jen</forename><surname>Cham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsong</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><forename type="middle">Magnenat</forename><surname>Thalmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Multitask learning. Machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rich</forename><surname>Caruana</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="41" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Absposelifter: Absolute 3d human pose lifting network from a single noisy 2d human pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juyong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised 3d pose estimation with geometric self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hang</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambrish</forename><surname>Tyagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Drover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rohith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Stojanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Synthesizing training images for boosting human 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenzheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangyan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhe</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baoquan</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Weakly-supervised discovery of geometry-aware representation for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kwan-Yee</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Bottom-up higher-resolution networks for multi-person pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<editor>CoRR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimizing network structure for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Ci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxuan</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yizhou</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Learning 3d human pose from structure and motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rishabh</forename><surname>Dabral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Mundhada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uday</forename><surname>Kusupati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Safeer</forename><surname>Afaque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sim2real transfer learning for 3d human pose estimation: motion to the rescue</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Ambrish Tyagi, and Cong Phuoc Huynh. Can 3d pose be learned from 2d projections alone? In ECCVw</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Drover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">V</forename><surname>Rohith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ching-Hang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amit Agrawal</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Human-computer interaction. An Introduction to Cyberpsychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Errity</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page">241</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning pose grammar to encode human body configuration for 3d pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanlu</forename><surname>Hao-Shu Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song-Chun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">In the wild human pose estimation using explicit 2d features and intermediate 3d representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ikhsanul</forename><surname>Habibie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing human-level performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Adversarial inverse graphics networks: Learning 2d-to-3d lifting and image-to-image translation from unpaired supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William Seto Katerina Fragkiadaki Hsiao-Yu Fish</forename><surname>Tung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><forename type="middle">W</forename><surname>Harley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Human3. 6m: Large scale datasets and predictive methods for 3d human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1325" to="1339" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Clustered pose and nonlinear appearance models for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning 3d human dynamics from video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><forename type="middle">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Panna</forename><surname>Felsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Self-supervised learning of 3d human pose using multi-view geometry</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Muhammed</forename><surname>Kocabas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salih</forename><surname>Karagoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Akbas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Geometry-driven self-supervised method for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congzhentao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard Yi Da</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingsheng</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael I Jordan</forename></persName>
		</author>
		<title level="m">Learning transferable features with deep adaptation networks</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">A simple yet effective baseline for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julieta</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rayat</forename><surname>Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">J</forename><surname>Little</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Monocular 3d human pose estimation in the wild using improved cnn supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<idno>3DV</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Vnect: Real-time 3d human pose estimation with a single rgb camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleksandr</forename><surname>Sotnychenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Shafiei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. on Graphics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">44</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Posefix: Model-agnostic general human pose refinement network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juyong</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">3d human pose estimation with 2d marginal heatmaps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aiden</forename><surname>Nibali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Prendergast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Single-stage multi-person pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuecheng</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">3d human pose estimation in video with temporal convolutions and semi-supervised training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dario</forename><surname>Pavllo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Domes to drones: Self-supervised active triangulation for 3d human pose reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksis</forename><surname>Pirinen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><surname>G?rtner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised geometry-aware representation for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Monocular 3d human pose estimation by generation and ordinal ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saurabh</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavan</forename><forename type="middle">Teja</forename><surname>Varigonda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prashast</forename><surname>Bindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arjun</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">zero-shot&quot; super-resolution using deep internal learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Assaf</forename><surname>Shocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadav</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Irani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nitish</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Compositional human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxiang</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Integral human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuang</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Test-time training for out-of-distribution generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Alexei</forename><surname>Efros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moritz</forename><surname>Hardt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Human mesh recovery from monocular images via a skeleton-disentangled representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenpeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yili</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Direct prediction of 3d body poses from motion compensated sequences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Artem</forename><surname>Bugra Tekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Rozantsev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lepetit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning from synthetic humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gul</forename><surname>Varol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Recovering accurate 3d human pose in the wild using imus and a moving camera</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roberto</forename><surname>Timo Von Marcard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Henschel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Bodo Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pons-Moll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Repnet: Weakly supervised training of an adversarial reprojection network for 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Generalizing monocular 3d human pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Keyuan</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mude</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">S</forename><surname>Ren</surname></persName>
		</author>
		<editor>ICCVw</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Spatial temporal graph convolutional networks for skeletonbased action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">3d human pose estimation in the wild by adversarial learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Semantic graph convolutional networks for 3d human pose regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Long</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubbasir</forename><surname>Kapadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitris</forename><forename type="middle">N</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Hemlets pose: Learning part-centric heatmap triplets for accurate 3d human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoguang</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianjuan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kui</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangbo</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Towards 3d human pose estimation in the wild: a weakly-supervised approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qixing</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
