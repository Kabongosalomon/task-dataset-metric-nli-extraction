<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Learning to Bootstrap for Combating Label Noise</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuyin</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianhang</forename><surname>Li</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengze</forename><surname>Liu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Johns Hopkins University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuxi</forename><surname>Chen</surname></persName>
							<affiliation key="aff2">
								<address>
									<settlement>Austin</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lequan</forename><surname>Yu</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">The University of Hong</orgName>
								<address>
									<settlement>Kong</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cihang</forename><surname>Xie</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Santa Cruz</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><forename type="middle">P</forename><surname>Lungren</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Xing</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Stanford University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Learning to Bootstrap for Combating Label Noise</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T02:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Deep neural networks are powerful tools for representation learning, but can easily overfit to noisy labels which are prevalent in many realworld scenarios. Generally, noisy supervision could stem from variation among labelers, label corruption by adversaries, etc. To combat such label noises, one popular line of approach is to apply customized weights to the training instances, so that the corrupted examples contribute less to the model learning. However, such learning mechanisms potentially erase important information about the data distribution and therefore yield suboptimal results. To leverage useful information from the corrupted instances, an alternative is the bootstrapping loss, which reconstructs new training targets on-the-fly by incorporating the network's own predictions (i.e., pseudo-labels).</p><p>In this paper, we propose a more generic learnable loss objective which enables a joint reweighting of instances and labels at once. Specifically, our method dynamically adjusts the per-sample importance weight between the real observed labels and pseudo-labels, where the weights are efficiently determined in a meta process. Compared to the previous instance reweighting methods, our approach concurrently conducts implicit relabeling, and thereby yield substantial improvements with almost no extra cost. Extensive experimental results demonstrated the strengths of our approach over existing methods on multiple natural and medical image benchmark datasets, including CIFAR-10, CIFAR-100, ISIC2019 and Clothing 1M. The code is publicly available at https://github.com/yuyinzhou/L2B. Recent advances in deep learning have achieved great success on various computer vision applications, where large-scale clean datasets are available. However, 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>noisy labels or intentional label corruption by an adversarial rival could easily cause dramatic performance drop <ref type="bibr" target="#b24">[24]</ref>. This problem is even more crucial in the medical field, given that the annotation quality requires great expertise. Therefore, understanding, modeling, and learning with noisy labels has gained great momentum in recent research efforts <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b23">23,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b34">34,</ref><ref type="bibr" target="#b47">47,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b48">48]</ref>.</p><p>Existing methods of learning with noisy labels primarily take a loss correction strategy. One popular direction is to first estimate the noise corruption matrix and then use it to correct the loss function <ref type="bibr" target="#b26">[26,</ref><ref type="bibr" target="#b5">6]</ref>. However, correctly estimating the noise corruption matrix is usually challenging and often involves assumptions about the noise generation process <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b9">10]</ref>. Other research efforts focus on selecting clean samples from the noisy data <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b3">4]</ref> by treating samples with small loss as clean ones <ref type="bibr" target="#b1">[2]</ref>. Instead of directly discarding those "unclean" examples, an extension of this idea is focusing on assigning learnable weights to each example in the noisy training set <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b30">30]</ref>, where noisy samples have low weights. However, discarding or attending less to a subset of the training data (e.g., noisy samples) can erase important information about the data distribution.</p><p>To fully exploit the corrupted training samples, another direction is to leverage the network predictions (i.e., pseudo-labels <ref type="bibr" target="#b13">[14]</ref>) to correct or reweight the original labels <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b31">31]</ref>, so that the holistic data distribution information could be preserved during network training. One representative work is the bootstrapping loss <ref type="bibr" target="#b27">[27]</ref>, which introduces a perceptual consistency term in the learning objective that assigns a weight to the pseudo-labels to compensate for the erroneous guiding of noisy samples. While in this strategy, the weight for the pseudo-labels is manually selected and remains the same for all training samples, which does not prevent fitting the noisy ones and can even lead to low-quality label correction <ref type="bibr" target="#b0">[1]</ref>. To tackle this challenge, Arazo et al. <ref type="bibr" target="#b0">[1]</ref> designed a dynamic bootstrapping strategy to adjusts the label weight by fitting a mixture model. Instead of separately reweighting labels or instances, in this paper, we propose a more generic learning strategy to enable a joint instance and label reweighting. We term our method as Learning to Bootstrap (L2B), where we aim to leverage the learner's own predictions to bootstrap itself up for combating label noise from a meta-learning perspective.</p><p>During each training iteration, L2B learns to dynamically re-balance the importance between the real observed labels and pseudo-labels, where the persample weights are determined by the validation performance on a separated clean set in a meta network. Unlike the bootstrapping loss used in <ref type="bibr" target="#b27">[27,</ref><ref type="bibr" target="#b0">1,</ref><ref type="bibr" target="#b46">46]</ref> which explicitly conducts relabeling by taking a weighted sum of the pseudoand the real label, L2B reweights the two losses associated with the pseudo-and the real label instead (where the weights need not be summed as 1). In addition, we theoretically prove that our formulation, which reweights different loss terms, can be reduced to the original bootstrapping loss and therefore conducts an implicit relabeling instead. By learning these weights in a meta-process, our L2B yields substantial improvement (e.g., +8.9% improvement on CIFAR-100 with 50% noise) compared with the instance reweighting baseline with almost no extra cost. We conduct extensive experiments on public natural image datasets (i.e., CIFAR-10, CIFAR-100, and Clothing 1M) and medical image dataset (i.e., ISIC2019), under different types of simulated noise and real-world noise. Our method outperforms various existing explicit label correction and instance reweighting works, demonstrating the strengths of our approach.</p><p>Our main contributions are as follows:</p><p>? We propose a generic learnable loss objective which enables a joint instance and label reweighting, for combating label noise in deep learning models.</p><p>? We prove that our new objective is, in fact, a more general form of the bootstrapping loss, and propose L2B to efficiently solve for the weights in a meta-learning framework.</p><p>? Compared with previous instance re-weighting methods, L2B exploits noisy examples more effectively without discarding them by jointly re-balancing the contribution of real and pseudo labels.</p><p>? We show the theoretical convergence guarantees for L2B, and demonstrate its superior results on natural and medical image recognition tasks under both synthetic and real-world noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Learning through explicit relabeling. To effectively handle noisy supervision, many works propose to directly correct the training labels through estimating the noise transition matrix <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b26">26]</ref> or modeling noise by graph models or neural networks <ref type="bibr" target="#b38">[38,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b14">15]</ref>. Patrini et al. <ref type="bibr" target="#b26">[26]</ref> estimate the label corruption matrix to directly correct the loss function. Hendrycks et al. <ref type="bibr" target="#b9">[10]</ref> further propose to improve the corruption matrix by using a clean set of data, which then enables training a corrected classifier. However, these methods usually require assumptions about noise modeling. For instance, Hendrycks et al. <ref type="bibr" target="#b9">[10]</ref> assume that the noisy label is only dependent on the true label and independent of the data. Another line of approaches proposes to leverage the network prediction for explicit relabeling. Some methods <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b43">43]</ref> relabel the samples by directly using pseudo-labels in an iterative manner. Han et al. use generated prototypes as pseudo-labels to be more noise tolerant <ref type="bibr" target="#b7">[8]</ref>. Instead of assigning the pseudo-labels as supervision, Reed et al. <ref type="bibr" target="#b27">[27]</ref> propose to generate new training targets by a convex combination of the real and pseudo labels. In a recent study, Ortego et al. <ref type="bibr" target="#b25">[25]</ref> directly apply this strategy for classification refinement, and combine it with contrastive learning for training noise-robust models. However, using a fixed weight for all samples does not prevent fitting the noisy ones could even limit the label correction. To tackle this challenge, Arazo et al. propose a dynamic bootstrapping strategy, which calculates sample weights by modeling per-sample loss with a beta mixture model <ref type="bibr" target="#b0">[1]</ref>. Zhang et al. further propose to learn this weight in a meta step, and combine semi-supervised learning for furthering the performance <ref type="bibr" target="#b46">[46]</ref>.</p><p>Instance reweighting. To reduce the negative effect of corrupted examples, many research efforts have also been dedicated to selecting or reweighting training instances so that noisy samples contribute less to the loss <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b3">4]</ref>. Based on the observation deep neural networks tend to learn simple patterns first before fitting label noise <ref type="bibr" target="#b1">[2]</ref>, many methods treat samples with small loss as clean ones <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b35">35]</ref>. Among those methods, Co-teaching <ref type="bibr" target="#b6">[7]</ref> and Co-teaching+ <ref type="bibr" target="#b44">[44]</ref> train two networks where each network selects small-loss samples in a mini-batch to train the other. Li et al. <ref type="bibr" target="#b15">[16]</ref> further propose to incorporate semi-supervised learning techniques to better leverage the noisy examples. Jiang et al. <ref type="bibr" target="#b10">[11]</ref> propose to use curriculum learning to improve convergence and generalization by ordering instances. Rather than directly selecting clean examples for training, meta-learning-based instance reweighting methods are also gaining momentum recently <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b39">39]</ref>. In these methods, the example weights and the network parameters are updated in a bi-level optimization to determine the contribution of each training sample. This line of approach has also been successfully applied for robust medical image analysis <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b21">22]</ref>. Different from the aforementioned approaches which separately handle instance reweighting and label reweighting, we propose a new general learning objective to simultaneously adjust the per-sample loss weight while implicitly relabeling the training samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminary</head><p>Given a set of N training samples, i.e., D tra = {(x i , y i )|i = 1, ..., N }, where x i ? R W ?H denotes the i-th image and y i is the observed noisy label. In this work, we also assume that there is a small unbiased and clean validation set</p><formula xml:id="formula_0">D val = {(x v i , y v i )|i = 1, .</formula><p>.., M } and M N , where the superscript v denotes the validation set. Let F(:, ?) denote the neural network model parameterized by ?. Given an input-target pair (x, y), we consider the loss function of L(F(x, ?), y) (e.g., cross-entropy loss) to minimize during the training process. Our goal, in this paper, is to properly utilize the small validation set D val to guide the model training on D tra , for reducing the negative effects brought by the noisy annotation.</p><p>To establish a more robust training procedure, Reed et al. proposed the bootstrapping loss <ref type="bibr" target="#b27">[27]</ref> to enable the learner to "disagree" with the original training label, and effectively re-label the data during the training. Specifically, the training targets will be generated using a convex combination of training labels and predictions of the current model (i.e., pseudo-labels <ref type="bibr" target="#b13">[14]</ref>), for purifying the training labels. Therefore, for a L-class classification problem, the loss function for optimizing ? can be derived as follows: <ref type="figure">Figure 1</ref>: (a) The original bootstrapping loss <ref type="bibr" target="#b27">[27]</ref> is sensitive to the reweighting hyperparameter ?. Under different noise levels, the optimal ? is different (NF stands for noise fraction). (b) Schematic description of our Learning to Bootstrap (i.e., L2B) method. The reweighting hyper-parameters are learned in a meta-process.</p><formula xml:id="formula_1">y pseudo i = arg max l=1,..,L P(x i , ?),<label>(1)</label></formula><formula xml:id="formula_2">? * = arg min ? N i=1 L(F(x i , ?), ?y real i + (1 ? ?)y pseudo i ),<label>(2)</label></formula><p>where ? is used for balancing the weight between the real labels and the pseudolabels. P(x i , ?) is the model output. y real and y pseudo denote the observed label and the pseudo-label respectively. However, in this method, ? is manually selected and fixed for all training samples, which does not prevent fitting the noisy ones and can even lead to low-quality label correction <ref type="bibr" target="#b0">[1]</ref>. Moreover, we observe that this method is quite sensitive to the selection of the hyperparameter ?. For instance, as shown in <ref type="figure">Figure 1</ref>(a), even a similar ? selection (i.e., ? = 0.6/? = 0.8) behaves differently under disparate noise levels, making the selection of ? even more intractable. Another limitation lies in that Eq. <ref type="formula" target="#formula_2">(2)</ref> treats all examples as equally important during training, which could easily cause overfitting for biased training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Learning to Bootstrap through Meta-Learning</head><p>To address these above challenges, in this paper, we aim to learn to bootstrap the model by conducting a joint label reweighting and instance reweighting. To achieve this, we propose to generate meta-learned weights for guiding our main learning objective:</p><formula xml:id="formula_3">? * (?, ?) = arg min ? N i=1 ? i L(F(x i , ?), y real i ) +? i L(F(x i , ?), y pseudo i ),<label>(3)</label></formula><formula xml:id="formula_4">with {? i , ? i } N i=1</formula><p>being the balance weights. Here we note that this new learning objective can be regarded as a general form of the original bootstrapping loss, as Eq. (3) can be reduced to Eq. (2) when ? i + ? i = 1 given that L(?) is the cross-entropy loss (see details in Appendix A). By relaxing this constraint such that ?, ? ? 0, we can see that the optimization of Eq. (3) not only allows the main learner to explore the optimal combination between the two loss terms but also concurrently adjust the contribution of different training samples. In addition, compared with Eq. (2), the optimization of Eq. (3) does not rely on explicitly generating new training targets (i.e., ?y real i + (1 ? ?)y pseudo i ), but rather conducts implicit relabeling during training by reweighting different loss terms. We note that the key to L2B is that the sum of ? i and ? i need not be 1, which results in +8.9% improvement on CIFAR-100 with 50% noise (Section 4.3).</p><p>Note that this form is also similar to self-distillation in <ref type="bibr" target="#b18">[19]</ref>. But different from <ref type="bibr" target="#b18">[19]</ref> where the weights are determined by heuristics, our weights ?, ? are meta-learned based on its performance on the validation set D val , that is</p><formula xml:id="formula_5">? * , ? * = arg min ?,??0 1 M M i=1 L(F(x v i , ? * (?, ?)), y v i ).<label>(4)</label></formula><p>It is necessary to constrain ? i , ? i ? 0 for all i to avoid potential unstable training <ref type="bibr" target="#b28">[28]</ref>. Both the meta learner (i.e., Eq. (4)) and the main learner (i.e., Eq. <ref type="formula" target="#formula_3">(3)</ref>) are optimized concurrently, which allows the model to maximize the performance on the clean validation set D val by adjusting the importance weights of the observed and the pseudo-labels in a differentiable manner.</p><p>Online Approximation. For each step t at training, a mini-batch of training examples {(x i , y i ), 1 ? i ? n} with n N is sampled to estimate a temporary adjustment to the parameters based on the descent direction of the loss function. For simplicity, let</p><formula xml:id="formula_6">f i (?) denote L(F(x i , ?), y real i ) and g i (?) denote L(F(x i , ?), y pseudo i</formula><p>) in the following sections. Given any ?, ?, we us?</p><formula xml:id="formula_7">? t+1 = ? t ? ??( n i=1 ? i f i (?) + ? i g i (?)) ?=?t (5)</formula><p>to approach the solution of Eq. (3). Here ? is the step size. We then estimate the corresponding optimal ?, ? as</p><formula xml:id="formula_8">? * 1 M M i=1 f v i (? t+1 ).<label>(6)</label></formula><p>However, directly solving for Eq. (6) at every training step requires too much computation cost. To reduce the computational complexity, we apply one step gradient descent of ? t , ? t on a mini-batch of validation set</p><formula xml:id="formula_9">{(x v i , y v i ), 1 ? i ? m} with m ? M as an approximation. Specifically, (? t,i , ? t,i ) = ???( m i=1 f v i (? t+1 )) ?i=0,?i=0 ,<label>(7)</label></formula><p>where ? is the step size for updating ?, ?. To ensure that the weights are non-negative, we apply the following rectified function:</p><formula xml:id="formula_10">? t,i = max(? t,i , 0),? t,i = max(? t,i , 0).<label>(8)</label></formula><p>Algorithm 1 Learning to Bootstrap</p><formula xml:id="formula_11">Require: ? 0 , D tra , D val , n, m, L Ensure: ? T 1: for t = 0 ... T ? 1 do 2: {x i , y i } ? SampleMiniBatch(D tra , n) 3: {x v i , y v i } ? SampleMiniBatch(D val , m) 4:</formula><p>For the i-th sample of D tra , compute y pseudo</p><formula xml:id="formula_12">i = arg max l=1,..,L P(x i , ? t ) 5:</formula><p>Learnable weights ?, ? 6:</p><formula xml:id="formula_13">Compute training loss l f ? n i=1 ? i f i (? t ) + ? i g i (? t ) 7:? t+1 ? ? t ? ??l f ?=?t 8: Compute validation loss l g ? 1 m m i=1 f v i (? t+1 ) 9: (? t , ? t ) ? ???l g ?=0,?=0 10:? t,i ? max(? t,i , 0),? t,i ? max(? t,i , 0) 11:? t,i ?? t,i n i? t,i+?t,i ,? t,i ?? t,i n i? t,i+?t,i</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12:</head><p>Apply learned weights ?, ? to reweight the training loss asl</p><formula xml:id="formula_14">f ? n i=1 ? t,i f i (? t ) + ? t,i g i (? t ) 13: ? t+1 ? ? t ? ??l f ?=?t 14: end for</formula><p>To stabilize the training process, we also normalize the weights in a single training batch so that they sum up to one:</p><formula xml:id="formula_15">? t,i =? t,i n i? t,i +? t,i ,? t,i =? t,i n i? t,i +? t,i .<label>(9)</label></formula><p>Finally, we estimate ? t+1 based on the updated ? t , ? t so that ? t+1 can consider the meta information included in ? t , ? t :</p><formula xml:id="formula_16">? t+1 = ? t ? ??( n i=1 ? t,i f i (?) + ? t,i g i (?)) ?=?t .<label>(10)</label></formula><p>See Appendix B for detailed calculation of the gradient in Eq. <ref type="bibr" target="#b9">(10)</ref>. A schematic description of our Learning to Bootstrap algorithm is illustrated in <ref type="figure">Figure 1</ref>(b) and the overall optimization procedure can be found in Algorithm 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Convergence Analysis</head><p>In proposing Eq. (3), we show that with the first-order approximation of ?, ? in Eq. <ref type="bibr" target="#b6">(7)</ref> and some mild assumptions, our method guarantees to convergence to a local minimum point of the validation loss, which yields the best combination of ?, ?. Details of the proof are provided in Appendix C.</p><p>Theorem 1. Suppose that the training loss function f, g have ?-bounded gradients and the validation loss f v is Lipschitz smooth with constant L. With a small enough learning rate ?, the validation loss monotonically decreases for any training batch B, namely,</p><formula xml:id="formula_17">G(? t+1 ) ? G(? t ),<label>(11)</label></formula><p>where ? t+1 is obtained using Eq. (10) and G is the validation loss</p><formula xml:id="formula_18">G(?) = 1 M M i=1 f v i (?),<label>(12)</label></formula><p>Furthermore, Eq. (11) holds for all possible training batches only when the gradient of validation loss function becomes 0 at some step t, namely, G(? t+1 ) = G(? t ) ?B ? ?G(? t ) = 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>CIFAR-10 &amp; CIFAR-100. Both CIFAR-10 and CIFAR-100 contain 50K training images and 10K test images of size 32 ? 32. Following previous works <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b15">16]</ref>, we experimented with both symmetric and asymmetric label noise. In our method, we used 1,000 clean images in the validation set D val following <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b28">28,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b47">47]</ref>.</p><p>ISIC2019. Following <ref type="bibr" target="#b40">[40]</ref>, we also evaluated our algorithm on a medical image dataset, i.e., skin lesion classification data, under different symmetric noise levels. The dataset contains nine different diagnostic categories: Melanoma, Melanocytic nevus, Basal cell carcinoma, Actinic keratosis, Benign keratosis, Dermatofibroma, Vascular lesion and Squamous cell carcinoma. Our experiments were conducted on the 25,331 dermoscopic images of the 2019 ISIC Challenge 1 , where we used 20400 images as the training set D tra , 640 images as the validation set D val , and tested on 4291 images.</p><p>Clothing 1M. We also evaluate on a large-scale real-world noisy dataset, Clothing 1M <ref type="bibr" target="#b38">[38]</ref>, which has 1 million training images collected from online shopping websites with labels generated from surrounding texts. In addition, the Clothing 1M benchmark also provides an official validation set of 14,313 images and a test set of 10,526 images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>For all CIFAR-10 and CIFAR-100 comparison experiments, we used an 18-layer PreActResNet <ref type="bibr" target="#b8">[9]</ref> as the baseline network following the setups in <ref type="bibr" target="#b15">[16]</ref>, unless otherwise specified. The model was trained using SGD with a momentum of 0.9, a weight decay of 0.0005, and a batch size of 256 for CIFAR-100 and 512 for CIFAR-10. The network was trained from scratch for 300 epochs. We set the learning rate as 0.15 initially with a cosine annealing decay. Following <ref type="bibr" target="#b15">[16]</ref>, we set the warm up period as 10 epochs for both CIFAR-10 &amp; CIFAR-100. The optimizer and the learning rate schedule remained the same for both the main and the meta model. Gradient clipping is applied to stabilize training. All experiments were conducted with one V100 GPU, except for the experiments on Clothing 1M which were conducted with one RTX A6000 GPU.</p><p>For ISIC2019 experiments, we used ResNet-50 with ImageNet pretrained weights. A batch size of 64 was used for training with an initial learning rate of 0.01. The network was trained for 30 epochs in total with the warmup period as 1 epoch. All other implementation details remained the same as above. For Clothing 1M experiments, we used an ImageNet pre-trained 18-layer ResNet <ref type="bibr" target="#b8">[9]</ref> as our baseline. We finetuned the network with a learning rate of 0.005 for 300 epochs. The model was trained using SGD with a momentum of 0.9, a weight decay of 0.0005, and a batch size of 256. Following <ref type="bibr" target="#b15">[16]</ref>, to ensure the labels (noisy) were balanced, for each epoch, we sampled 250 mini-batches from the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Performance Comparisons</head><p>Experiments on CIFAR-10 &amp; CIFAR-100 . We compare our method with different baselines: 1) Bootstrapping, which modifies the training loss by generating new training targets 2 , 2) Distillation <ref type="bibr" target="#b18">[19]</ref>, which transfers the knowledge distilled from the small clean dataset; 3) L2RW <ref type="bibr" target="#b28">[28]</ref>, which reweights different instances through meta-learning; 4) GLC <ref type="bibr" target="#b9">[10]</ref>, which uses the trusted clean data to correct losses; and 5) Cross-Entropy (the standard training) under different levels of symmetric labels noise ranging from 20% ? 50%. To ensure a fair comparison, we report the best epoch for all comparison approaches. All results are summarized in <ref type="table" target="#tab_0">Table 1</ref> and <ref type="table" target="#tab_1">Table 2</ref>, which shows L2B significantly outperforms all other competing methods by a large margin across all noise fractions. It is also observed that compared with previous meta-learning-based instance reweighting method L2RW, the performance improvement is substantial especially under larger noise fraction, which suggests the advantages of jointly We also test our model with asymmetric noise labels (i.e., 40% noise fractions) and summarize the testing accuracy in <ref type="table" target="#tab_2">Table 3</ref>. Among all compared methods, we re-implement L2RW under the same setting and report the performance of all other competitors from previous papers <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b15">16]</ref>. Compared with previous meta-learning-based instance reweighting methods (i.e., LR2W <ref type="bibr" target="#b28">[28]</ref>, MW-Net <ref type="bibr" target="#b30">[30]</ref>), a dynamic bootstrapping method (M-correction <ref type="bibr" target="#b0">[1]</ref>) and other explicit relabeling methods (i.e., F-correction <ref type="bibr" target="#b26">[26]</ref>, Tanaka et al. <ref type="bibr" target="#b31">[31]</ref>), our L2B achieves superior performance with 40% asymmetric noise. Note that we mainly compare with methods which do not use any augmentation techniques, as our L2B does not rely on those. However, we do notice that our method outperforms M-correction which is built on top of mixup augmentation <ref type="bibr" target="#b45">[45]</ref>, demonstrating the benefits of our joint instance and label reweighting mechanisms for tackling asymmetric noise. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>CIFAR-10 Cross-Entropy 85.0 F-correction <ref type="bibr" target="#b26">[26]</ref> 87.2 M-correction <ref type="bibr" target="#b0">[1]</ref> 87.2 Chen et al. <ref type="bibr" target="#b2">[3]</ref> 88.6 P-correction <ref type="bibr" target="#b43">[43]</ref> 88.5 Tanaka et al. <ref type="bibr" target="#b31">[31]</ref> 88.9 MLNT <ref type="bibr" target="#b16">[17]</ref> 89.2 L2RW <ref type="bibr" target="#b28">[28]</ref> 89.2 MW-Net <ref type="bibr" target="#b30">[30]</ref> 89.7 NLNL <ref type="bibr" target="#b11">[12]</ref> 89.9 JNPL <ref type="bibr" target="#b12">[13]</ref> 90.7 L2B (Ours) 91.8</p><p>Alleviate potential overfitting to noisy examples. We also plot the testing accuracy curve under different noise fractions in <ref type="figure" target="#fig_0">Figure 2</ref>, which shows that our proposed L2B would help preventing potential overfitting to noisy samples compared with standard training. Meanwhile, compared to simply sample reweighting (L2RW), our L2B introduces pseudo-labels for bootstrapping the learner and is able to converge to a better optimum. Generalization to real-world noisy labels. We test L2B on Clothing 1M <ref type="bibr" target="#b38">[38]</ref>, a large-scale dataset with real-world noisy labels. To further illustrate the effectiveness of our approach, we compare with: 1) Tanaka et al. <ref type="bibr" target="#b31">[31]</ref>, 2) MLNT <ref type="bibr" target="#b16">[17]</ref>, 3) MW-Net <ref type="bibr" target="#b30">[30]</ref>, 4) GLC <ref type="bibr" target="#b9">[10]</ref>, and 5) MLC <ref type="bibr" target="#b47">[47]</ref> using the same validation and testing splits provided by the benchmark. The results of all competitors are reported from <ref type="bibr" target="#b47">[47]</ref>. As shown in <ref type="table" target="#tab_3">Table 4</ref>, our L2B achieves an average performance of 77.5% accuracy from 3 independent runs with different random seeds, outperforming all competing methods on the Clothing 1M benchmark. Generalization to medical image analysis. <ref type="table" target="#tab_4">Table 5</ref> demonstrates the generalizability of our proposed L2B to medical image analysis <ref type="bibr" target="#b40">[40]</ref>. Compared with 1) L2RW <ref type="bibr" target="#b28">[28]</ref>, which has also been applied to skin lesion classification/segmentation <ref type="bibr" target="#b40">[40,</ref><ref type="bibr" target="#b21">22]</ref> with noisy supervision; 2) Distillation <ref type="bibr" target="#b18">[19]</ref>; 3) Mixup <ref type="bibr" target="#b45">[45]</ref>; and 4) Bootsrapping <ref type="bibr" target="#b27">[27]</ref>, our method achieves better results under all different noise levels. Stability of experimental results. We repeated the experiments 5 times with different random seeds for network initialization and label noise generation, and report mean ? standard deviation under different experimental settings.</p><p>As can be seen from <ref type="table" target="#tab_5">Table 6</ref>, with different noise fractions and datasets, the standard deviation among the 5 runs are consistently less that 0.5%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Ablation Study</head><p>On the importance of ?, ?. To understand why our proposed new learning objective can outperform previous meta-learning-based instance reweighting methods, we conduct the following analysis to understand the importance of hyper-parameter ? and ? in our method. Specifically, we set ? = 0 and ? = 0 respectively to investigate the importance of each loss term in Eq. (3).</p><p>In addition, we also show how the restriction of ? i + ? i = 1 (Eq. <ref type="formula" target="#formula_2">(2)</ref>) would deteriorate our model performance as follows.</p><p>? ? = 0. As shown in <ref type="table" target="#tab_6">Table 7</ref>, in this case, the performance even decreases compared with the baseline approach. This is due to that when only pseudo-labels are included in the loss computation, the error which occurs in the initial pseudo-label will be reinforced by the network during the following iterations.</p><p>? ? = 0. From Eq. (3), we can see that setting ? as 0 is essentially equivalent to the baseline meta-learning-based instance reweighting method L2RW <ref type="bibr" target="#b28">[28]</ref>. In this case, the performance is largely improved compared to the baseline, but still inferior to our method, which jointly optimizes ? and ?.</p><p>? ? + ? = 1. We also investigate whether the restriction of ? + ? = 1 is required for obtaining optimal weights during the meta-update, as in <ref type="bibr" target="#b46">[46]</ref>. As shown in <ref type="table" target="#tab_6">Table 7</ref>, L2B (?, ? ? 0) consistently achieves superior results than L2B (? + ? = 1) under different noise levels on CIFAR-100. The reason may be the latter is only reweighting different loss terms, whereas the former not only explores the optimal combination between the two loss terms but also jointly adjusts the contribution of different training samples.</p><p>We also demonstrate a set of qualitative examples to illustrate how our proposed L2B benefits from the joint instance and label reweighting paradigm. In <ref type="figure" target="#fig_1">Figure 3</ref>, we can see that when the estimated pseudo label is of high-quality, i.e., the pseudo label is different from the noisy label but equal to the clean label, our model will automatically assign a much higher weight to ? for corrupted  When the estimated pseudo label is of high-quality, i.e., the pseudo label is different from the noisy label but equal to the clean label, our model will automatically assign a much higher weight to ? than to ? for corrupted training samples. When the pseudo label is equal to the noisy label (i.e., the two loss terms are equal to each other), ? and ? are almost identical.</p><p>training samples. On the contrary, ? can be near zero in this case. This indicates that our L2B algorithm will pay more attention to the pseudo label than the real noisy label when computing the losses. In addition, we also show several cases where the pseudo label is equal to the noisy label, where we can see that ? and ? are almost identical under this circumstance since the two losses are of the same value. Note that the relatively small values of ? and ? are due to that we use a large batch size (i.e., 512) for CIFAR-10 experiments. By normalizing the weights in each training batch (see Eq. <ref type="formula" target="#formula_15">(9)</ref>), the value of ? and ? can be on the scale of 10 ?4 .</p><p>Parameter normalization. We note that the normalization of ? and ? is one key component for accelerating the training process. However, we observe that different normalization methods of ? and ? behave quite differently for different datasets. To further investigate this, we apply the following normalization functions to each ? i and ? i on ISIC2019, CIFAR-100 and Clothing 1M: 1) Eq. (9) as in <ref type="bibr" target="#b28">[28]</ref>, 2) Sigmoid function, </p><formula xml:id="formula_19">? t,i = 1 1 + e ??t,i , ? t,i = 1 1 + e ??t,i ,<label>(13)</label></formula><p>where t stands for the training iteration and ? denotes the temperature parameter for scaling the weight distribution. ? is set as 10.0 when using the Softmax function for normalization. The comparison among these three different normalization methods is summarized in <ref type="figure" target="#fig_3">Figure 4</ref> on ISIC2019 and CIFAR-100 datasets with 40% symmetric noise. We can see that while Eq. (9) achieves the best result on CIFAR-100, it yields large training instability on the ISIC2019 dataset. Changing the normalization function to Sigmoid and Softmax can make the training procedure much more stable on the ISIC2019 dataset. In addition, we notice that Softmax (e.g., using the Softmax function with a temperature scaling of 10.0 instead of Eq. (9) to normalize ? and ?) slightly outperforms Sigmoid for ISIC2019. Future research should address how to develop a unified normalization function which can be generalizable for different learning tasks.</p><p>Comparison with meta-learning-based label correction. One recent study <ref type="bibr" target="#b47">[47]</ref> has proposed meta label correction to explicitly relabel the noisy examples via a meta-network. Unlike our L2B which conducts implicit relabeling via reweighting different loss components, this method uses a meta-model for explicit label correction. We re-implement the results with the public code by using PreActResNet-18 as the backbone network and the comparison results on CIFAR-10 are show in <ref type="table" target="#tab_7">Table 8</ref>. We can see that our method consistently outperforms MLC for noise ratios ranging from 10% to 50% on CIFAR-10. Training cost. We list our training time on CIFAR-10 compared with the previous meta-learning based instance reweighting methods, i.e., MLNT <ref type="bibr" target="#b16">[17]</ref>, L2RW <ref type="bibr" target="#b28">[28]</ref>, in <ref type="table" target="#tab_8">Table 9</ref>. The training times are reported based on PreActResNet-18 on a single V100 GPU card. Our method L2B is directly built on top of L2RW, and our method (which applies a joint instance reweighting and label reweighting) incurs almost no extra training cost when using the same architecture and hardware conditions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Discussion &amp; Limitation</head><p>L2B is designed for building robust representation models, which is crucial for many real-world applications in healthcare, vision, etc. For example, high intraand inter-physician variations are well-known in medical diagnostic tasks, which lead to erroneous labels that could derail our learning algorithms. L2B can help rectify such noisy data distributions and prevent potential overfitting during training and thus reduce the risking of medical errors. This paper specifically focuses on the situation where a small clean validation set is accessible (e.g., Clothing 1M <ref type="bibr" target="#b38">[38]</ref>). However, we do note that the extra validation dataset is not a requirement in meta-learning as we can use a subset of pseudo-labeled training data as the validation data <ref type="bibr" target="#b39">[39]</ref>. How to properly select a high-quality pseudo-labeled set and how it affects the algorithm compared to the external validation set should be investigated in the future. Future study should also analyze the role of L2B in conjunction with other meta-learning-based instance reweighting methods such as MW-Net <ref type="bibr" target="#b30">[30]</ref>, and semi-supervised/selfsupervised learning methods <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref>, for furthering the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we present L2B, a simple and effective method for training noiserobust models. Concretely, we propose a novel and generic learning objective to enable joint reweighting of instances and labels for combating the label noise in deep representation learning. A meta process is employed to dynamically adjust the per-sample importance weight between real observed labels and pseudo-labels. Our L2B outperforms prior instance reweighting or label reweighting works under both synthetic and real-world noise with almost no extra cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Equivalence of the two learning objectives</head><p>We show that Eq. (3) is equivalent with Eq. (2) when ?i ? i + ? i = 1. For convenience, we denote y real i , y pseudo i , F(x i , ?) using y r i , y p i , p i respectively.</p><formula xml:id="formula_21">? i L(p i , y r i ) + ? i L(p i , y p i ) = L l=1 ? i y r i,l log p i,l<label>(15)</label></formula><formula xml:id="formula_22">+ ? i y p i,l log p i,l = L l=1 (? i y r i,l + ? i y p i,l ) log p i,l<label>(16)</label></formula><p>Due to that L(?) is the cross-entropy loss, we have</p><formula xml:id="formula_23">L l=1 y r i,l = L l=1 y p i,l = 1. Then L l=1 ? i y r i,l + ? i y p i,l = ? i + ? i . So if ? i + ? i = 1, we have L l=1 (? i y r i,l + ? i y p i,l ) log p i,l = L(p i , ? i y r i + ? i y p i ) (17) = L(p i , (1 ? ? i )y r i + ? i y p i )<label>(18)</label></formula><p>B Gradient used for updating ?</p><p>We derivative the update rule for ?, ? in Eq. <ref type="bibr" target="#b9">(10)</ref>.</p><formula xml:id="formula_24">? t,i = ?? ? ?? i ( m j=1 f v j (? t+1 )) ?i=0 (19) = ?? m j=1 ?f v j (? t+1 ) T ?? t+1 ?? i ?i=0 (20) = ?? m j=1 ?f v j (? t+1 ) T (21) ?(? t ? ??( k ? k f k (?) + ? k g k (?)) ?=?t ) ?? i ?i=0 (22) = ?? m j=1 ?f v j (? t ) T ?f i (? t )<label>(23)</label></formula><formula xml:id="formula_25">? t,i = ?? ? ?? i ( m j=1 f v j (? t+1 )) ?i=0 (24) = ?? m j=1 ?f v j (? t+1 ) T ?? t+1 ?? i ?i=0 (25) = ?? m j=1 ?f v j (? t+1 ) T (26) ?(? t ? ??( k ? k g k (?) + ? k g k (?)) ?=?t ) ?? i ?i=0 (27) = ?? m j=1 ?f v j (? t ) T ?g i (? t )<label>(28)</label></formula><p>Then ? t+1 can be calculated by Eq. (10) using the updated ? t,i , ? t,i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C Convergence</head><p>This section provides the proof for covergence (Theorem 1)</p><p>Theorem. Suppose that the training loss function f, g have ?-bounded gradients and the validation loss f v is Lipschitz smooth with constant L. With a small enough learning rate ?, the validation loss monotonically decreases for any training batch B, namely,</p><formula xml:id="formula_26">G(? t+1 ) ? G(? t ),<label>(29)</label></formula><p>where ? t+1 is obtained using Eq. (10) and G is the validation loss</p><formula xml:id="formula_27">G(?) = 1 M M i=1 f v i (?),<label>(30)</label></formula><p>Furthermore, Eq. (29) holds for all possible training batches only when the gradient of validation loss function becomes 0 at some step t, namely, G(? t+1 ) = G(? t ) ?B ? ?G(? t ) = 0</p><p>Proof. At each training step t, we pick a mini-batch B from the union of training and validation data with |B| = n. From section B we can derivative ? t+1 as follows:</p><formula xml:id="formula_28">? t+1 = ? t ? ? n i=1 (? t,i ?f i (? t ) + ? t,i ?g i (? t )) (31) = ? t ? ?? 2 M n i=1 (?G T ?f i ?f i + ?G T ?g i ?g i )<label>(32)</label></formula><p>We omit ? t after every function for briefness and set m in section B equals to M . Since G(?) is Lipschitz-smooth, we have</p><formula xml:id="formula_29">G(? t+1 ) ? G(? t ) + ?G T ?? + L 2 ||??|| 2 .<label>(33)</label></formula><p>Then we show ?G T ?? + L 2 ||??|| 2 ? 0 with a small enough ?. Specifically,</p><formula xml:id="formula_30">?G T ?? = ??? 2 M i (?G T ?f i ) 2 + (?G T ?g i ) 2 .<label>(34)</label></formula><p>Then since f i , g i have ?-bounded gradients, we have</p><formula xml:id="formula_31">L 2 ||??|| 2 ? L? 2 ? 4 M 2 2 i (?G T ?f i ) 2 ||?f i || 2 (35) + (?G T ?g i ) 2 ||?g i || 2 (36) ? L? 2 ? 4 M 2 ? 2 2 i (?G T ?f i ) 2 + (?G T ?g i ) 2<label>(37)</label></formula><p>Then if ? 2 &lt; 2 ?? 2 M L ,</p><formula xml:id="formula_32">?G T ?? + L 2 ||??|| 2 ? ( L? 2 ? 4 M 2 ? 2 2 ? ?? 2 M )<label>(38)</label></formula><p>i (?G T ?f i ) 2 + (?G T ?g i ) 2 ? 0.</p><p>Finally we prove G(? t+1 ) = G(? t ) ?B ? ?G(? t ) = 0: If ?G(? t ) = 0, from section B we have ? t,i = ? t,i = 0, then ? t+1 = ? t and thus G(? t+1 ) = G(? t ) ?B. Otherwise, if ?G(? t ) = 0, we have</p><formula xml:id="formula_34">0 &lt; ||?G|| 2 = ?G T ?G = 1 M M i=1 ?G T ?f v i ,<label>(40)</label></formula><p>which means there exists a k such that ?G T ?f v k &gt; 0. So for the mini-batch B k that contains this example, we have</p><formula xml:id="formula_35">G(? t+1 ) ? G(? t ) ? ?G T ?? + L 2 ||??|| 2 (41) ? ( L? 2 ? 4 M 2 ? 2 2 ? ?? 2 M ) (42) i?B (?G T ?f i ) 2 + (?G T ?g i ) 2 (43) ? ( L? 2 ? 4 M 2 ? 2 2 ? ?? 2 M )?G T ?f v k<label>(44)</label></formula><p>&lt; 0.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Test set accuracy versus the number of epochs on CIFAR-100 under the noise fraction of 20% and 40%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Examples of ? and ? on CIFAR-10 with asymmetric noise fraction of 20%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>and 3 )</head><label>3</label><figDesc>Softmax function, ? t,i = e ?t,i/? n i e ?t,i/? + e ?t,i/? , ? t,i = e ?t,i/? n i e ?t,i/? + e ?t,i/? ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Comparison among different normalization functions (i.e., Eq. (9) as in<ref type="bibr" target="#b28">[28]</ref>, Sigmoid function and Softmax function). (a) Testing accuracy curve with different normalization functions under 40% symmetric noise label on the ISIC dataset. (b) Testing accuracy curve with different normalization under 40% symmetric label noise on CIFAR-100.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Comparison of different methods in test accuracy (%) on CIFAR-10 with symmetric noise. NF stands for the noise fraction.</figDesc><table><row><cell>Method</cell><cell cols="4">CIFAR-10 20% NF 30% NF 40% NF 50% NF</cell></row><row><cell>Cross-Entropy</cell><cell>86.9</cell><cell>84.9</cell><cell>83.3</cell><cell>81.3</cell></row><row><cell>Bootstrapping [27]</cell><cell>85.2</cell><cell>84.8</cell><cell>82.9</cell><cell>79.2</cell></row><row><cell>Distillation [19]</cell><cell>88.0</cell><cell>86.8</cell><cell>85.5</cell><cell>80.0</cell></row><row><cell>GLC [10]</cell><cell>91.4</cell><cell>90.3</cell><cell>88.5</cell><cell>86.4</cell></row><row><cell>L2RW [28]</cell><cell>90.6</cell><cell>89.0</cell><cell>86.6</cell><cell>85.3</cell></row><row><cell>L2B (Ours)</cell><cell>92.2</cell><cell>90.7</cell><cell>89.9</cell><cell>88.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison with different methods in test accuracy (%) on CIFAR-100 with symmetric noise. NF stands for the noise fraction.</figDesc><table><row><cell>Method</cell><cell cols="4">CIFAR-100 20% NF 30% NF 40% NF 50% NF</cell></row><row><cell>Cross-Entropy</cell><cell>59.6</cell><cell>52.2</cell><cell>49.2</cell><cell>44.4</cell></row><row><cell>Bootstrapping [27]</cell><cell>61.8</cell><cell>54.2</cell><cell>50.2</cell><cell>45.8</cell></row><row><cell>Distillation [19]</cell><cell>62.7</cell><cell>57.3</cell><cell>53.7</cell><cell>45.7</cell></row><row><cell>GLC [10]</cell><cell>68.8</cell><cell>65.9</cell><cell>62.1</cell><cell>57.9</cell></row><row><cell>L2RW [28]</cell><cell>67.8</cell><cell>63.8</cell><cell>59.7</cell><cell>55.6</cell></row><row><cell>L2B (Ours)</cell><cell>71.8</cell><cell>69.5</cell><cell>67.3</cell><cell>64.5</cell></row><row><cell cols="5">reweighting different loss terms. For example, on CIFAR-100, the accuracy</cell></row><row><cell cols="5">improvement of our proposed L2B reaches 7.6% and 8.9% under 40% and 50%</cell></row><row><cell>noise fraction, respectively.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Comparison with asymmetric noise.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Comparison with state-of-the-art methods in test accuracy (%) under realworld noise on Clothing 1M. Our results are reported from 3 independent runs with different random seeds. All other results are reported from<ref type="bibr" target="#b47">[47]</ref>.</figDesc><table><row><cell>Method</cell><cell>Tanaka et al. [31]</cell><cell cols="4">MLNT MW-Net GLC MLC [17] [30] [10] [47]</cell><cell>L2B (Ours)</cell></row><row><cell>Accuracy</cell><cell>72.2</cell><cell>73.5</cell><cell>73.7</cell><cell>73.7</cell><cell cols="2">75.8 77.5 ? 0.2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Comparison with different methods in test accuracy (%) on ISIC with symmetric noise.</figDesc><table><row><cell>Method</cell><cell>20% NF</cell><cell>30% NF</cell><cell>40% NF</cell><cell>50% NF</cell></row><row><cell>Cross-Entropy</cell><cell>79.4</cell><cell>77.5</cell><cell>75.3</cell><cell>73.7</cell></row><row><cell>Bootstrapping [27]</cell><cell>80.8</cell><cell>77.7</cell><cell>75.7</cell><cell>74.8</cell></row><row><cell>Distillation [19]</cell><cell>80.1</cell><cell>78.8</cell><cell>76.8</cell><cell>74.4</cell></row><row><cell>Mixup [45]</cell><cell>80.2</cell><cell>77.9</cell><cell>76.8</cell><cell>74.9</cell></row><row><cell>L2RW [28]</cell><cell>80.1</cell><cell>77.7</cell><cell>76.3</cell><cell>74.1</cell></row><row><cell>L2B (Ours)</cell><cell>81.1</cell><cell>80.2</cell><cell>78.6</cell><cell>76.8</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Multiple-runs experiments under the noise fraction of 20% NF and 40% NF.</figDesc><table><row><cell>Datasets</cell><cell>20% NF</cell><cell>40 % NF</cell></row><row><cell>CIFAR-10</cell><cell>91.99? 0.10</cell><cell>89.39? 0.22</cell></row><row><cell cols="3">CIFAR-100 71.78 ? 0.38 67.23 ? 0.33</cell></row><row><cell>ISIC 2019</cell><cell cols="2">81.16 ? 0.29 78.26 ? 0.45</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Ablation study under the noise fraction of 20% and 40%. L2B (?, ? ? 0) consistently achieves superior results to L2B (? + ? = 1) under different noise levels on CIFAR-100.</figDesc><table><row><cell>Method</cell><cell>20% NF</cell><cell>40% NF</cell></row><row><cell>Cross-Entropy</cell><cell>59.6</cell><cell>49.2</cell></row><row><cell>? = 0</cell><cell>55.7</cell><cell>47.1</cell></row><row><cell>? = 0</cell><cell>63.2</cell><cell>57.5</cell></row><row><cell>? + ? = 1</cell><cell>64.8</cell><cell>59.1</cell></row><row><cell>?, ? ? 0</cell><cell>71.8</cell><cell>67.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 :</head><label>8</label><figDesc>Comparison with MLC<ref type="bibr" target="#b47">[47]</ref> in test accuracy (%) on CIFAR-10 with symmetric noise.</figDesc><table><row><cell>Method</cell><cell>10% NF</cell><cell>20% NF</cell><cell>30% NF</cell><cell>40% NF</cell><cell>50% NF</cell></row><row><cell>MLC</cell><cell>90.1</cell><cell>90.1</cell><cell>88.3</cell><cell>87.2</cell><cell>86.0</cell></row><row><cell>L2B (Ours)</cell><cell>93.6</cell><cell>92.2</cell><cell>90.7</cell><cell>89.9</cell><cell>88.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 9 :</head><label>9</label><figDesc>Training time comparison of MLNT<ref type="bibr" target="#b16">[17]</ref>, L2RW<ref type="bibr" target="#b28">[28]</ref> and L2B (Ours). Our L2B incurs almost no additional training cost when using the same architecture and hardware conditions.</figDesc><table><row><cell>MLNT [17]</cell><cell>L2RW [28]</cell><cell>L2B (Ours)</cell></row><row><cell>8.6 h</cell><cell>6.5h</cell><cell>6.5h</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">t , ? * t = arg min ?,??0</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://challenge2019.isic-archive.com/data.html</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We set ? = 0.8 in Eq. (2) following the default setting in<ref type="bibr" target="#b27">[27]</ref>.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O&amp;apos;</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="312" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devansh</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanislaw</forename><surname>Jastrzkebski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maxinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tegan</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Asja</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Understanding and utilizing deep neural networks trained with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><forename type="middle">Ben</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1062" to="1070" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Rethinking importance weighting for deep learning under distribution shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongtong</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<editor>Neurips</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beno?t</forename><surname>Fr?nay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michel</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="845" to="869" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Training deep neural-networks using a noise adaptation layer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Goldberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ehud</forename><surname>Ben-Reuven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quanming</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weihua</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Deep self-learning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangfan</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5138" to="5147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mantas</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Duncan</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyuan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nlnl: Negative learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junho</forename><surname>Yim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juseung</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Joint negative and positive learning for noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juseung</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyounguk</forename><surname>Shon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junmo</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="9442" to="9451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong-Hyun</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop on challenges in representation learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Cleannet: Transfer learning for scalable image classifier training with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kuang-Huei</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linjun</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5447" to="5456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dividemix: Learning with noisy labels as semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning to learn from noisy labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongkang</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohan</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5051" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Learning from noisy data with robust representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junnan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Caiming</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021-10" />
			<biblScope unit="page" from="9485" to="9494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Learning from noisy labels with distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuncheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yale</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangliang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiebo</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1910" to="1918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Early-learning regularization prevents memorization of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Niles-Weed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Narges</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Fernandez-Granda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="20331" to="20342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Classification with noisy labels by importance reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dacheng</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="447" to="461" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning to segment skin lesions from noisy annotations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Mirikharaji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqi</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghassan</forename><surname>Hamarneh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Domain Adaptation and Representation Transfer and Medical Image Learning with Less Labels and Imperfect Data</title>
		<imprint>
			<biblScope unit="page" from="207" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Springer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nagarajan</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Inderjit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pradeep</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ambuj</forename><surname>Ravikumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tewari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1196" to="1204" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A study of the effect of different types of noise on the precision of supervised learning techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>David F Nettleton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Albert</forename><surname>Orriols-Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fornells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial intelligence review</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="275" to="306" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Multi-objective interpolation training for robustness to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="6606" to="6615" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgio</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><forename type="middle">Krishna</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lizhen</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenyuan</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4334" to="4343" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Learning with bad training data via iterative trimmed loss minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyao</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sujay</forename><surname>Sanghavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5739" to="5748" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lixuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanping</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongben</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daiki</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Toshihiko</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kiyoharu</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5552" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Toward robustness against label noise in training deep discriminative neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arash</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning from noisy large-scale datasets with minimal supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Veit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Alldrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gal</forename><surname>Chechik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Krasin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="839" to="847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning image labels on-the-fly for training robust classification models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyue</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leo</forename><surname>Tam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daguang</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.10325</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Combating noisy labels by agreement: A joint training method with co-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Ngc: A unified framework for learning with open-world noisy data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Fan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwen</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaojie</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingqian</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Feng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="62" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Are anchor points really indispensable in label-noise learning? In Neurips</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobo</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nannan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Faster meta update strategy for noise-robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youjiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linchao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="144" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Robust learning at noisy labeled medical images: Applied to skin lesion classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Cheng Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueying</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1280" to="1283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Jo-src: A contrastive approach for combating noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhou</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeren</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fumin</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenmin</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="5192" to="5201" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Dual t: Reducing estimation error for transition matrix in label-noise learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
		<editor>Neurips</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Probabilistic end-to-end noise correction for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7017" to="7025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">How does disagreement help generalization against label corruption?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingrui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangchao</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivor</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masashi</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7164" to="7173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">mixup: Beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Distilling effective supervision from severe label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zizhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sercan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Arik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pfister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9294" to="9303" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Meta label correction for noisy label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqing</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><surname>Hassan Awadallah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Susan</forename><surname>Dumais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th AAAI Conference on Artificial Intelligence</title>
		<meeting>the 35th AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Learning with noisy labels via sparse regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deming</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjun</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyang</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="72" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A second-order approach to learning with instance-dependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tongliang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2021-06" />
			<biblScope unit="page" from="10113" to="10123" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
