<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MEMORY-ENRICHED COMPUTATION AND LEARNING IN SPIKING NEURAL NETWORKS THROUGH HEBBIAN PLASTICITY</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2022-05-24">May 24, 2022</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Limbacher</surname></persName>
							<email>thomas.limbacher@igi.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Theoretical Computer Science</orgName>
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<postCode>8010</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>?zdenizci</surname></persName>
							<email>ozan.ozdenizci@igi.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Theoretical Computer Science</orgName>
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<postCode>8010</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">TU Graz -SAL Dependable Embedded Systems Lab, Silicon Austria Labs</orgName>
								<address>
									<postCode>8010</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Legenstein</surname></persName>
							<email>robert.legenstein@igi.tugraz.at</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Theoretical Computer Science</orgName>
								<orgName type="institution">Graz University of Technology</orgName>
								<address>
									<postCode>8010</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MEMORY-ENRICHED COMPUTATION AND LEARNING IN SPIKING NEURAL NETWORKS THROUGH HEBBIAN PLASTICITY</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2022-05-24">May 24, 2022</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Spiking Neural Networks ? Hebbian Plasticity ? Memory ? Few-shot learning</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Memory is a key component of biological neural systems that enables the retention of information over a huge range of temporal scales, ranging from hundreds of milliseconds up to years. While Hebbian plasticity is believed to play a pivotal role in biological memory, it has so far been analyzed mostly in the context of pattern completion and unsupervised learning. Here, we propose that Hebbian plasticity is fundamental for computations in biological neural systems. We introduce a novel spiking neural network architecture that is enriched by Hebbian synaptic plasticity. We show that Hebbian enrichment renders spiking neural networks surprisingly versatile in terms of their computational as well as learning capabilities. It improves their abilities for out-of-distribution generalization, one-shot learning, cross-modal generative association, language processing, and reward-based learning. As spiking neural networks are the basis for energy-efficient neuromorphic hardware, this also suggests that powerful cognitive neuromorphic systems can be build based on this principle.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Spiking Neural Networks (SNNs) are a well-established model of neural computation <ref type="bibr" target="#b0">[1]</ref>. In contrast to conventional artificial neural networks (ANNs), neurons in an SNN communicate via stereotypical pulses-so-called spikes-and temporally integrate incoming information in their membrane potential. Since these are key features of biological neurons, SNNs are heavily used to model information processing in the brain. Furthermore, SNNs are well-suited for implementation in neuromorphic hardware, leading to highly energy-efficient AI applications.</p><p>For a long time, SNNs have been inferior to ANNs in terms of performance on standard pattern recognition tasks. However, a number of recent advances in SNN research have changed the picture, showing that SNNs can achieve performances similar to ANNs <ref type="bibr" target="#b1">[2]</ref>. In particular, the use of surrogate gradients for SNN training <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b5">[6]</ref> and the use of longer adaptation time constants in recurrent SNNs have been instrumental in this respect <ref type="bibr" target="#b6">[7]</ref>. Nevertheless, SNNs still lack many capabilities of their biological counterparts-for some of which biologically implausible ANN solutions have been proposed.</p><p>Since computations in SNNs have-in contrast to computations in feed-forward ANNs-a strong temporal component, they have been proposed to be particularly suited for temporal computing tasks <ref type="bibr" target="#b6">[7]</ref>. Here, it has turned out that the ability to retain information on several time scales is crucial. The most basic time-constant in spiking neurons is the membrane time constant on the order of tens of milliseconds. In principle, arbitrary time constants can be realized by recurrent connections in recurrent SNNs. However, such recurrent retention of information is rather brittle and hard to learn. Instead, there were several suggestions to utilize longer time constants available in biological neuronal circuits such as short-term plasticity <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> on the order of 100s of milliseconds, and adaptation time constants of neurons output recall store IE <ref type="figure">Figure 1</ref>: Schematic of the SNN model. Inputs x are encoded by an input encoder (IE). Memory induction: The encoded input z s,enc activates some neurons in the key-and value-layer through weight matrices W s,key and W s,value , respectively. Since the key-neurons z key and the value-neurons z value are pre-and post-synaptic to the synapses in W assoc , their activity induces weight changes there. Memory recall: The encoded input z r,enc activates some neurons in the key-layer through the weight matrix W r,key . This activity activates some neurons in the value-layer through synapses W assoc , thus potentially recalling some information that has been stored previously. Finally, value neurons z value project to a layer of output neurons o.</p><p>To allow for a memory recall based on previously recalled information, activity in the value-layer is fed back to the key-layer with some delay d feedback .</p><p>[3], <ref type="bibr" target="#b6">[7]</ref> on the order of seconds. The inclusion of such time constants has been shown to extend the computational capabilities of SNNs. However, typical cognitive tasks are frequently situated on a much slower time scale of minutes or longer. For example, when we watch a movie, we have to rapidly memorize facts in order to follow the story and draw conclusions as the narrative evolves. For such tasks, time constants on the order of seconds are insufficient.</p><p>Here we consider Hebbian synaptic plasticity <ref type="bibr" target="#b9">[10]</ref> as a mechanism to extend the range of time constants and therefore the computational capabilities of SNNs. Hebbian synaptic plasticity is abundant in both neocortex and hippocampus <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b12">[13]</ref>. While many forms, in particular in sensory cortical areas, are believed to shape processing on a very slow developmental scale, there is also evidence for rapid plasticity that can in principle be utilized for online processing on the behavioral time scale, most prominently in the hippocampus <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. We show that Hebbian synaptic plasticity renders SNNs rather flexible in terms of their computational as well as learning capabilities. This single principle can give rise to SNNs that are capable of out-of-distribution generalization, one-shot learning, cross-modal generative association, answering questions about stories of various types, and learning to play card games from rewards. Hence, our results show that Hebbian plasticity enhances the computational capabilities of SNNs in several directions. This suggests that Hebbian plasticity is a central component of information processing in the brain which is tightly interwoven with cognitive neuronal processing. Since local Hebbian plasticity can easily be implemented in neuromorphic hardware, this also suggests that powerful cognitive neuromorphic systems can be build based on this principle.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Spiking Neural Networks with associative memory</head><p>We consider networks of standard leaky integrate-and-fire (LIF) neurons modeled in discrete time steps ?t. The membrane potential V j of neuron j at time t is given by</p><formula xml:id="formula_0">V j (t + ?t) = ?V j (t) + (1 ? ?)I j (t) ? ?z j (t),<label>(1)</label></formula><p>where ? defines the membrane potential decay per time step. The total synaptic input current I j (t) = i W ji z i (t) is given by the sum over all pre-synaptic neuron's output spike trains weighted by the corresponding synaptic weights W ji . When the neuron's membrane potential V j (t) is above some threshold ?, the neuron spikes (z j (t) = 1) and the membrane potential is reset (last term in <ref type="formula" target="#formula_0">(1)</ref>). If the neuron does not spike, we define z j (t) = 0.</p><p>The considered network model is shown in <ref type="figure">Fig. 1</ref>. At the core of the network is a heteroassociative memory <ref type="bibr" target="#b15">[16]</ref>, that is, a single layer feed-forward SNN. Here, spiking neurons z key in the key-layer project to neurons z value in the value-layer with synaptic weights W assoc ji that are subject to rapid Hebbian plasticity. We used 100 neurons in the key-and value-layer respectively in all simulations. The use of this simple hetero-associative memory architecture is motivated from the hippocampal circuitry where it was shown that rapid plasticity is found in the connections from region CA3 to CA1, resembling a similar single-layer architecture with key-layer corresponding to CA3 and the value-layer corresponding to CA1 <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b14">[15]</ref>. From a machine learning perspective, this architecture can be motivated from memory-augmented neural networks, a class of ANN models that were shown to outperform standard ANNs in memory-dependent computational tasks. This class includes networks with key-value memory systems such as memory-networks <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, Hebbian memory networks <ref type="bibr" target="#b18">[19]</ref>, and transformers <ref type="bibr" target="#b19">[20]</ref>. The latter have been shown to be particularly powerful for language-processing, giving rise to language models such as GPT-3 <ref type="bibr" target="#b20">[21]</ref>.</p><p>In our model, neurons in the key-layer (key neurons) receive input from two spiking neuron populations, z s,enc and z r,enc , responsible for storing (s) and recalling (r) information to and from the memory respectively (see below). Similarly, neurons in the value-layer (value neurons) receive input from two sites, namely from z s,enc and from the key layer neurons z key . Consider an input x from which some aspects should be stored in memory. It is first encoded by an input encoder (IE in <ref type="figure">Fig. 1</ref>; the architecture of the encoder depends on the task at hand, see below) giving rise to a spike response z s,enc . The synaptic connections to the key-layer activate some key neurons, while the synaptic connections to the value-layer activate some value neurons. As these neurons are pre-and post-synaptic to the synapses in W assoc , this induces weight changes there (see Methods for the Hebbian plasticity model). Which information about the input x is stored depends on the synaptic weights from z s,enc to the key-and value-layers. Now consider an input x that should trigger a memory recall. In this case, the encoded input z r,enc activates the key neurons through the weight matrix W r,key giving rise to activity in the key-layer. This activity activates neurons in the value-layer through association synapses W assoc , thus potentially recalling information that has been stored previously. Finally, these neurons project to a layer of output neurons o. For some tasks, it might be beneficial to perform a recall based on previously recalled information. For example, when you are asked "Can Tweety fly?", you may first recall that Tweety is a canary and then remember that canaries can fly to arrive at the correct answer. We therefore included a feedback loop in the model from the value neurons to the key neurons (see loop on the right side of <ref type="figure">Fig. 1</ref>). In this way, recalled activity can influence the recall itself after some delay. We set the feedback delay d feedback to 1 ms if not otherwise stated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Memorizing associations</head><p>We first tested the ability of our model to one-shot memorize associations and to use these associations later when needed. Here we conducted experiments on a task that requires to form associations between random continuous-valued vectors and integer labels that were sequentially presented to the network.</p><p>In each instance of this task, we randomly drew N real vectors where each element of a vector was sampled from a uniform distribution on the interval [0, 1). We then generated input sequences of N tuples each containing one of the random vectors and an associated label from 1 to N ( <ref type="figure" target="#fig_0">Fig. 2A, right)</ref>. After all those vector-label pairs have been presented to the network, it received a query vector. The query vector was equal to one of the N vectors and was randomly selected for each input sequence. The network was required to output the label of the query vector.</p><p>The model was trained for 4250 iterations using backpropagation through time (BPTT) <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b21">[22]</ref>. We used two dense layers as input encoder in this task. Each layer consisted of 80 LIF neurons. One layer was used to encode each of the random input vectors and another layer was used to encode the integer labels. Inputs were applied to these layers for 100 ms each, giving rise to spike trains z s,enc and z r,enc (see Section Model and training details in the Supplementary for more details to the model and the training setup). <ref type="figure" target="#fig_0">Fig. 2A</ref> (bottom right) shows the network activity after training for one test example with a sequence length N of eight vector-label pairs.</p><p>In <ref type="figure" target="#fig_0">Fig. 2B</ref> we compare the performance of our model for various sequence lengths (number of vector-label pairs) to the standard generic artificial and spiking recurrent network models: the standard LSTM network <ref type="bibr" target="#b22">[23]</ref> and the long short-term memory spiking neural network (LSNN) <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b6">[7]</ref>. The LSTM network consisted of 100 LSTM units. The LSNN consisted of 150 regular spiking and 150 adaptive neurons. For both models, we used the same architecture for the input encoder and the output layer as in our model. For short sequences, the performance of the LSTM network and the LSNN is comparable to our model. While the accuracy of the LSTM and LSNN drastically drops at some point, the accuracy of our model stays above 90 % for sequences containing up to 50 vector-label pairs.</p><p>To test the out-of-distribution generalization capability of our model in this task, we trained it with a sequence length N train of five vector-label pairs and tested the model on shorter and longer sequences of up to 30. Note that the labels in this task were randomly chosen from {1, . . . , 30} and, consequently, the output layer was of size 30. In <ref type="figure" target="#fig_0">Fig. 2C</ref>, we compare its performance to an LSTM network in terms of the test accuracy. While both models generalize to shorter sequences, our model shows superior generalization to longer sequences. . After all those vector-label pairs have been presented to the network, it receives a query vector (x9). The query vector is equal to one of the vectors presented as facts (randomly selected; vector with label 2 in the shown example). The network is required to output the label of the query vector. Inputs are encoded as spike trains z s,enc and z r,enc (100 ms for each input). Synaptic connections to the key-layer activate some key neurons z key , while the synaptic connections to the value-layer activate some value neurons z value . Spikes in these layers during storing of the third vector-label pair x3 and during recall are shown within red, green, and blue rectangles, respectively. Neurons that are both active during storing of x3 and recalling are highlighted with saturated color. (B) Performance comparison of our model with an LSTM network and an LSNN in this task. Shown is the test accuracy for various sequence lengths N . While the accuracy of our model stays above 90 % for sequences with up to 50 vector-label pairs, the performance of the LSTM network and the LSNN quickly decreases with increasing sequence length. (C) Out-of-distribution generalization capability. We trained models with a sequence length of Ntrain = 5 and evaluated the models generalization capability to test sets with shorter and longer sequence lengths Ntest. Comparison to LSTM network: While both models generalize to new test sets with shorter sequences, our model shows superior generalization to longer sequences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>One-shot Learning</head><p>While standard deep learning approaches need large numbers of training examples during training, humans can learn new concepts based on a single exposure (one-shot learning) <ref type="bibr" target="#b23">[24]</ref>. A large number of few-shot learning approaches have been proposed using artificial neural networks <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b25">[26]</ref>, but biologically plausible SNN models are very rare <ref type="bibr" target="#b26">[27]</ref>. We wondered whether Hebbian plasticity could endow SNNs with one-shot learning capabilities. To that end, we applied our model to the problem of one-shot classification on the Omniglot <ref type="bibr" target="#b27">[28]</ref> data set. Omniglot consists of 1623 handwritten characters from 50 different alphabets. There are 20 examples of each character, each hand drawn by a different person. Following <ref type="bibr" target="#b28">[29]</ref>, we resized all the image to 28 ? 28 and augmented the data set with rotations in multiples of 90 degrees. We trained on 1028 characters (4112 classes in total with rotations) and tested on 423 characters (1692 classes with rotations).</p><p>In each instance of this task, we randomly drew five different Omniglot classes. We then generated input sequence of tuples each containing a randomly drawn instance of one of the five Omniglot classes and an associated label from 1 to 5 <ref type="figure" target="#fig_1">(Fig. 3A right)</ref>. After all those image-label pairs have been presented to the network, it received a query image. The query image showed another randomly drawn sample from one of these five Omniglot classes. The network was required to output the label that appeared together with an image of the same class as the query image (1-shot 5-way classification).</p><p>We trained our model for 200 epochs with 200 iterations per epoch. In each iteration we randomly drew a batch of 256 input sequences, each containing five different Omniglot classes along with an associated label from 1 to 5, and one query image. We used a convolutional neural network (CNN) as input encoder for the Omniglot image, which was pre-trained using the prototypical loss <ref type="bibr" target="#b24">[25]</ref> and then converted into a spiking CNN by using a threshold-balancing algorithm <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> (see Section Converting pre-trained CNNs in the Supplementary for details to the conversion algorithm). The spiking CNN was then fine-tuned during end-to-end training. We treated the grayscale values of an Omniglot image as a constant input current, applied for 100 ms to 784 LIF neurons, to produce input spikes to the CNN. The final layer of the CNN consisted of 64 LIF neurons. A single dense layer consisting also of 64 LIF neurons was used to encode the integer labels as spike trains with a duration of 100 ms per label (see Section Model and training details in the Supplementary for more details to the model and the training setup).</p><p>The rationale for this network architecture is that, given a suitable generalizing representation of the character, the Hebbian weight matrix can easily associate characters to labels, thus performing one-shot memorization of previously unseen classes to arbitrary labels. In biology, suitable representations could emerge from evolutionary optimized networks potentially fine-tuned by unsupervised plasticity processes. In our setup, these representations are provided by the CNN encoder, where the prototypical loss ensures that similar inputs are mapped to similar representations <ref type="bibr" target="#b24">[25]</ref>. The network model can thus be seen as a spiking implementation of a prototypical network. However, the biologically unrealistic nearest-neighbor algorithm used to determine the output of the latter is replaced here by a simple hetero-associative memory. In <ref type="figure" target="#fig_1">Fig. 3B</ref> we show a sample t-SNE visualization of the embeddings produced by the spiking CNN that was used as image encoder in this task. Despite the shown characters being rather diverse, the network is able to represent them as well-separated clusters. This clustering can also be observed in the learned keyand value-representations of the inputs (inset of <ref type="figure" target="#fig_1">Fig. 3B</ref>). Overall, the SNN achieved an accuracy of 92.2 % when tested on 1-shot 5-way classification of novel character classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Cross-modal associations</head><p>Humans are able to imagine features of previously encountered stimuli. For example, when you hear the name of a person, you can imagine a mental image of its face. Here, in contrast to the associations considered above, not just classes are associated but (approximate) mental images. We therefore asked whether Hebbian plasticity can enable SNNs to perform such cross-modal associations. We trained our model in an autoencoder-like fashion. We used the FSDD <ref type="bibr" target="#b31">[32]</ref> and the MNIST <ref type="bibr" target="#b32">[33]</ref> data set in this task. FSDD is an audio/speech data set consisting of recordings of spoken digits. The data set contains 3000 recordings of 6 speakers (50 of each digit per speaker).</p><p>In each instance of the task we randomly drew three unique digits between 0 and 9. For each digit we then generated a tuple containing a randomly drawn instance of this digit as audio file from the FSDD data set, and a randomly drawn image of the same digit from the MNIST data set ( <ref type="figure" target="#fig_2">Fig. 4A right)</ref>. After these audio-image pairs have been presented to the network, it received an additional audio query. The audio query was another randomly drawn instance from the FSDD data set of one of the previously presented digits. The network was required to generate the image of the handwritten digit that appeared together with the spoken digit of the same class as the audio query. We used one CNN to encode the audio input (more specifically the mel-frequency cepstrum coefficients (MFCCs), see Section Model and training details in the Supplementary), and one CNN to encode the MNIST images. The CNNs were pre-trained on FSDD/MNIST classification tasks respectively and the pre-trained models were converted into spiking CNNs by using the threshold-balancing algorithm <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> (see Section Converting pre-trained CNNs in the Supplementary for details to the conversion algorithm). We removed the final classification layers of the CNNs and used the penultimate layer consisting of 64 LIF neurons as the encoding of the input stimuli. The spiking CNN was then fine-tuned during end-to-end training (see Section Model and training details in the Supplementary for more details to the model and the training setup). Following the value layer of the model, the image reconstruction was produced by a two-layer fully-connected network with 256 and 784 LIF neurons, respectively.</p><p>In <ref type="figure" target="#fig_2">Fig. 4B</ref> we show example MNIST images from the test set and the corresponding images that were reconstructed by the network. One can see that not just a typical image for the digit class was imagined by the network, but rather an image that is very similar to the image presented previously with the audio cue. This shows that the network did not just memorize the digit class in its associative memory, but rather features that benefit the reconstruction of this specific sample. To quantify the reconstruction performance of our model, we computed the mean squared difference (MSD) between the image produced by the network and all MNIST images in an input sequence. The MSD was 0.03 ? 0.02 (mean ? standard deviation; median was 0.02 with a lower and upper quartile of 0.01 and 0.03, respectively) between the reconstructed image and the target image, and 0.1 ? 0.04 between the reconstructed image and the two other MNIST images in the input sequence (statistics are over 1000 examples in the test set).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Question Answering</head><p>The bAbI data set <ref type="bibr" target="#b16">[17]</ref> is a standard benchmark for cognitive architectures with memory. The data set contains 20 different types of synthetic question-answering (QA) tasks, designed to test a variety of reasoning abilities on stories. Each of these tasks consist of a sequence of sentences followed by a question whose answer is typically a single word (in a few tasks, answers are multiple words; see <ref type="table" target="#tab_0">Table S1</ref> in the Supplementary for example stories and questions). We provided the answer to the model as supervision during training, and it had to predict it at test time on a separate test set.</p><p>The performance of the model was measured using the average error on the test data set over all tasks and the number of failed tasks (according to the convention of <ref type="bibr" target="#b16">[17]</ref>, a model had failed to solve a task if the test error was above 5 % for that task). Each instance of a task consists of a sequence of M sentences x m , . . . , x M , where the last sentence is a question, and an answer a. We represent each word j in a given sentence x m by a one-hot vector w m,j of length V (where V is the vocabulary size). We limited the number of sentences in a story to 50 (similar to previous work <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b33">[34]</ref>).</p><p>We used a dense layer consisting of 80 LIF neurons as input encoder in this task. We found it helpful to let the model choose for itself which type of sentence encoding to use. We therefore used a learned encoding (see Section Model and training details in the Supplementary and <ref type="bibr" target="#b33">[34]</ref>). Each sentence was encoded as a spike train with a duration of 100 ms. Similar to previous work <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b33">[34]</ref>, we performed three independent runs with different random initializations and report the results of the model with the highest validation accuracy in these runs.</p><p>In <ref type="table" target="#tab_0">Table 1</ref> we compare our model to the Spiking RelNet <ref type="bibr" target="#b34">[35]</ref> and to the H-Mem model <ref type="bibr" target="#b18">[19]</ref>, a non-spiking memory network model. Similar to the feedback-loop from the value-layer to the input of the key-layer in our model, the H-Mem model can utilize several memory accesses conditioned on previous memory recalls. The results of H-Mem were reported for a single memory access (1-hop) and three memory accesses <ref type="bibr">(3-hop)</ref>. It turned out that multiple memory hops were necessary to solve some of the bAbI tasks. Similarly, we found that in our model, an instantaneous feedback loop (with a delay d feedback of 1 ms) struggled with a few tasks that could be solved with a delay of 30 ms, corresponding roughly to three hops during the network inference that lasted 100 ms. We compared the performance of these models in terms of their mean error, error on individual tasks, and the number of failed tasks. Our model with 1 ms feedback solved 13 of the 20 tasks. By increasing the feedback delay d feedback from 1 ms to 30 ms it was able to solve 16 of the 20 tasks. This result indicates that the spiking network can make use of multiple memory accesses in an asynchronous manner, i.e., simply through a delayed feedback loop without the need for discrete memory access steps. The spiking RelNet model solved 17 of the 20. Note however that this model is much more complex, makes heavy use of weight sharing and employs pre-trained LSNNs for word embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Reinforcement Learning</head><p>While supervisory signals are arguably scarce in nature, it is well-established that animals learn from rewards <ref type="bibr" target="#b35">[36]</ref>. In order to test whether memory can also serve SNNs in the reward-based setting, we evaluated our model on an episodic reinforcement learning task. The task is based on the popular children's game Concentration. The game Concentration requires good memorization skills and is played with a deck of n pairs of cards. The cards in each pair are identical. At the start of each game the cards are shuffled and laid out face down. A player's turn consists of flipping over any two of the cards. If the cards match then they are removed from the game and the current player moves again. Otherwise the cards are turned face down again and the next player proceeds. The player that collects more pairs wins the game.</p><p>Here we consider a one-player solitaire version of the game <ref type="figure" target="#fig_3">(Fig. 5A</ref>). In this version of the game the objective is to find all matching pairs with as few card flips as possible. The cards are arranged on a one-dimensional grid of cells, each of which may be empty or may contain one card. The grid is just large enough to hold all of the 2n cards. Each card may either be face up or face down on any given time step (initially all cards are face down). The agent's available actions are to flip over any of the cards at a given time step. More precisely, the action space is an integer from {1, 2, . . . , 2n}. Whenever two cards are face up but do not match, they automatically turn face down in the next time step. Whenever Histogram of the number of flips an agent takes to finish a game with four cards (blue) and six cards (green). Shown is the histogram for a random agent (left), our agent after training (middle), and an agent that has perfect memory and that follows an optimal strategy (right). Histograms are computed from 1000 games each and are scaled to the same width.</p><p>two cards match they are removed from the grid and the agent is rewarded. The agent receives a small penalty for each card flip. The game continues until all cards are removed.</p><p>Instead of using images, we define each card face to be a 10-dimensional random continuous-valued vector. The agent's observation vector s (see <ref type="figure" target="#fig_3">Fig. 5A</ref>) contains three components: (a) a one-hot vector for each cell that encodes the state of the cell (a cell can either be empty, containing a face down card, or a face up card), (b) a one-hot vector encoding the previous action taken by the agent (i.e, a one-hot vector encoding which grid position was flipped), and (c) a 10-dimensional real vector for the image of the card the agent had flipped in the previous time step (this is a zero vector if the card is face down after the flip or if the agent's action was to flip an empty cell). In contrast to the other considered tasks, where we sequentially presented some facts followed by a query to which the network should respond with an output, here instead, in each time step, the network had to figure out by itself when to store and recall information, given only the current observation vector.</p><p>The performance was evaluated in terms of the number of flips performed until all matching pairs had been removed from the grid. Agents were trained with proximal policy optimization (PPO) <ref type="bibr" target="#b36">[37]</ref> in actor-critic style using 64 asynchronous vectorized environments (see Section Model and training details in the Supplementary for details to the model and the training setup). We evaluated our model on a deck of four cards and a deck of six cards. The evolution of the number of card flips the agent takes to finish a game over the number of training steps is shown <ref type="figure" target="#fig_3">Fig. 5B</ref>. After training we evaluated the agents on 1000 games and recorded the number of card flips the agent takes to finish each game. <ref type="figure" target="#fig_3">Fig 5C shows</ref> the histogram of the number of card flips in this evaluation for a random agent, our agent, and an agent that has perfect memory and that follows an optimal strategy. If an agent has no memory at all, and plays by simply flipping cards at random, then the expected number of flips the agent takes to finish a game with n pairs of cards is (2n) 2 . For an optimal agent the length lies between 2n and 4n ? 2 where the expected number of flips is (6 ? 4 ln 2)n + 7/8 ? 2 ln 2 as n ? ? <ref type="bibr" target="#b37">[38]</ref>. For the four card-game, the SNN reached an optimal performance (mean number of flips: 5.33; optimal: 5.33). An average of 8 flips were achieved within 8235 games. The six-card game was harder to train. Still, the final network's performance was again close to optimal (see <ref type="figure" target="#fig_3">Fig. 5C</ref>). Re-drawing the random vectors at the beginning of each game (i.e., using a new deck of cards in each game) marginally decreased the performance (mean number of flips was 5.35 for the four-card game, and 10.88 for the six-card game, where the optimum is 8.65 flips).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Discussion</head><p>We have presented a novel SNN model that integrates Hebbian plasticity in its network dynamics. We found that this memory-enrichment renders SNNs surprisingly flexible.</p><p>While only local plasticity is needed during inference, our model was trained with BPTT. Since BPTT is biologically implausible, we cannot claim that our network is a model for how the functionality could be learned by an organism. Instead, our results provide an existence proof for powerful memory-enhanced SNNs. One can speculate that brain networks were shaped by evolution to make use of Hebbian plasticity processes. In this sense, BPTT can be seen as a replacement for evolutionary processes. For example, the brain might have evolved networks for one-shot learning <ref type="figure" target="#fig_1">(Fig. 3</ref>) that are particularly tuned to behaviorally relevant stimuli. In addition to evolutionary optimization, local approximations of BPTT such as the recently introduced e-prop algorithm <ref type="bibr" target="#b38">[39]</ref> could then further shape the evolved circuits for specific functionality.</p><p>The integration of synaptic plasticity for inference in artificial neural networks was used in <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref> and adopted recently <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>. In the latter, input representations were bound to labels with Hebbian plasticity. Memory-augmented neural networks use explicit memory modules which are a differentiable version of a digital memory <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref>, <ref type="bibr" target="#b43">[44]</ref>- <ref type="bibr" target="#b47">[48]</ref>. Our model utilizes biological Hebbian plasticity instead. In <ref type="bibr" target="#b48">[49]</ref>, training of networks with synaptic plasticity was explored, but there the parameters of the plasticity rule were optimized instead of the surrounding control networks.</p><p>The inclusion of Hebbian plasticity can be viewed as the introduction of another long time constant in the network dynamics. Previous work has shown that longer time constants can significantly improve the temporal computing capabilities of SNNs. In this direction, short-term synaptic plasticity <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref> and neuronal adaptation <ref type="bibr" target="#b6">[7]</ref> have been exploited. One-shot learning of SNNs has been studied in <ref type="bibr" target="#b26">[27]</ref>. Instead of Hebbian plasticity, this model relied on a more elaborate three-factor learning rule. Another SNN model, the Spiking RelNet, was tested on the bAbI task set <ref type="bibr" target="#b34">[35]</ref>.</p><p>We have compared this model to ours in <ref type="table" target="#tab_0">Table 1</ref>. The architecture of this model is quite different from our proposal. As a spiking implementation of relational networks, it is rather complex and makes heavy use of weight sharing. Both these models perform well on similar tasks of the bAbI task set, but interestingly, there are some differences. For example, our model solves task 2 "two supporting facts" on which the Spiking RelNet fails. This might be due to the possibility of multiple memory accesses through the feedback loop in our model. On the other hand, our model fails at task 17 "positional reasoning" which is solved by the Spiking RelNet. We suspect that this is due to the more complex network structure of the Spiking RelNet. To the best of our knowledge, no previous spiking (or artificial) neural network model is performing well on both, one-shot learning and bAbI tasks, as well as on the other tasks we presented.</p><p>Hebbian plasticity is spatially and temporally local, i.e., the synaptic weight change depends only on a filtered version of the pre-and post-synaptic spikes and on the current weight value. This is a very desirable feature of any plasticity rule, as it can easily be implemented both in biological synaptic connections, and in neuromorphic hardware. In fact, current neuromorphic designs support this type of plasticity <ref type="bibr" target="#b49">[50]</ref>. Hence, our results indicate that Hebbian plasticity can serve as a fundamental building block in cognitive architectures based on energy-efficient neuromorphic hardware.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Neuron Model</head><p>Neurons in our model are standard LIF neurons modeled in discrete time steps ?t. The membrane potential V j of a neuron j at time t is given by</p><formula xml:id="formula_1">V j (t + ?t) = ?V j (t) + (1 ? ?)I j (t) ? ?z j (t),<label>(2)</label></formula><p>where ? = exp(? ?t ?m ) defines the membrane potential decay per time step. The total synaptic input current I j is defined as the weighted sum of spikes from pre-synaptic neurons</p><formula xml:id="formula_2">I j (t) = i W ji z i (t),<label>(3)</label></formula><p>where the sum goes over all pre-synaptic neurons i and where W ji is the weight of the corresponding synapse. A neuron j spikes as soon as its membrane potential V j exceeds a firing threshold ?. The spike train of a neuron j is modeled as binary sequence z j ? {0, 1}. After having fired a spike (z j (t) = 1), the neurons membrane potential is reset by subtracting the threshold value ? (last term in (2)) and the neuron enters an absolute refractory period ? abs where it cannot spike again (for parameter values, see <ref type="table" target="#tab_1">Table 2</ref>).</p><p>On the basis of the above formalism, it is apparent that only the spikes are communicated to other neurons. Hence, we interpret z j as the output of a neuron j and V j as its hidden state. For simplicity, in the following, we will not state the hidden dynamics of the neurons in the model, but only the synaptic input current and the output spike train.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Model</head><p>Our model takes a sequence of inputs x 1 , . . . , x M . Each input x m can either be a fact or a query to which the network should respond with an output?.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Input encoder</head><p>Let x 1 , . . . , x M be the given input sequence. Each x m is converted into a spike train of duration ? sim = 100 ms by using an input encoder (IE). We do not restrict the type of input encoder. It has to be chosen for the task at hand. In the simplest case we use a single dense layer E consisting of d LIF neurons. Depending on whether the input x m represents some fact that might be useful to store, or a query to which the network should respond with an output, we denote the resulting spike train as z s,enc i and z r,enc i , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Memory induction</head><p>Consider an input from which some aspect should be stored in memory. Here, the spike train encoding that input, that is z s,enc i , is fed to two single-layer networks K and V comprising of l LIF neurons each. The input current to a neuron j in layer K-we call it the key-layer-is given by</p><formula xml:id="formula_3">I key j (t) = i W s,key ji z s,enc i (t),<label>(4)</label></formula><p>where W s,key is a synaptic-weight matrix of size l ? d. We denote the spike train of a neuron j in the key-layer as z key j . The input current to a neuron k in the value-layer, layer V, is given by</p><formula xml:id="formula_4">I value k (t) = i W s,value ki z s,enc i (t) + c j W assoc kj (t)z key j (t),<label>(5)</label></formula><p>where W s,value is a synaptic-weight matrix of size l ? d, c = 0.2 is a constant, and where W assoc are association synapses represented as a square matrix of size l ? l. The first term represents the contribution of the spikes from the input encoder to this current, and the second term represent the contribution of the spikes that travel from the key-layer via W assoc to a neuron in layer V. We denote the spike train of a neuron k in this layer as z value k .</p><p>Synapses W assoc are subject to Hebbian plasticity. An association between the activity in the key-and value-layer neurons is established via weight changes given by:</p><formula xml:id="formula_5">?W assoc kj (t) = ? + (w max ? W assoc kj (t)) ? value k (t)? key j (t) ? ? ? W assoc kj (t)? key j (t) 2 ,<label>(6)</label></formula><p>where ? + &gt; 0, ? ? &gt; 0, w max are constants, and where ? key j and ? value k are exponential activity traces of z key j and z value k , respectively (for parameter values, see <ref type="table" target="#tab_1">Table 2</ref>). Traces are updated by an amount 1 ? exp(??t/? trace ) at the moment of spike arrival and decay exponentially with time constant ? trace in the absence of spikes.</p><p>The first term in (6) implements a soft upper bound w max on the weights. The Hebbian term ? value k (t)? key j (t) strengthens connections between co-active neurons in the key-and value-layers. Finally, the last term generally weakens connections from the currently active key-neurons. Since the Hebbian component strengthens connections to active value-neurons, this emphasizes the current association and de-emphasizes old ones. This update is similar to Oja's rule <ref type="bibr" target="#b50">[51]</ref>, but note that the quadratic term acts on the pre-synaptic neuron. Association synapses are then updated according to W assoc (t + ?t) = W assoc (t) + ?W assoc (t).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3">Memory recall</head><p>Now consider an input that should trigger a memory recall. In this case, we feed the encoded input z r,enc i and, via delayed feedback connections, the activity in the value layer z value k to the key-layer K. The input current to a neuron j in this layer is then given by</p><formula xml:id="formula_6">I key j (t) = i?d W r,key ji z r,enc i (t) + d?k?d+l W r,key jk z value k?d (t ? d feedback ),<label>(7)</label></formula><p>where W r,key is a synaptic-weight matrix of size l ? d + l, and where d feedback is the synaptic delay in the feedback connections. As before, we denote the spike train of a neuron j in this layer as z key j . This activity activates some neurons in the value-layer through synapses W assoc , thus potentially recalling some information that has been stores previously. The synaptic current to a neuron k in the value-layer is given by</p><formula xml:id="formula_7">I value k (t) = j W assoc kj (t)z key j (t).<label>(8)</label></formula><p>As before, we denote the spike train of a neuron k in this layer as z value k .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.4">Generating the final prediction</head><p>The architecture of the output module depends on the task at hand. In the simplest case, the network output was determined by taking the sum of z value k over the last ? read time steps and passing the result through a final weight matrix</p><formula xml:id="formula_8">W out :? j = k W out jk ? read t =0 z value k (M ? sim ? t ).<label>(9)</label></formula><p>The weights W s,key , W s,value , W r,key , and W out are learned during training by minimizing the cross-entropy loss between the softmax of? and the target output o using the Adam optimizer <ref type="bibr" target="#b51">[52]</ref>. The gradient is backpropagated through spikes by replacing the non-existent derivative of the membrane potential at the time of a spike by a pseudo-derivative, as done in <ref type="bibr" target="#b2">[3]</ref>, that smoothly increases from 0 to 1, and then decays back to 0:</p><formula xml:id="formula_9">dz j (t) dv j (t) := ? max{0, 1 ? |v j (t)|}<label>(10)</label></formula><p>where v j (t) =</p><formula xml:id="formula_10">Vj (t)?? ?</formula><p>is the normalized membrane potential of neuron j and ? ? 1 is a dampening factor which was set to 1. Association synapses W assoc were represented by a square matrix which was initialized for each input sequence x m with all its values set to zeros.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Availability</head><p>The Omniglot data set <ref type="bibr" target="#b27">[28]</ref> is freely available at https://github.com/brendenlake/omniglot. The FSDD data set <ref type="bibr" target="#b31">[32]</ref> is freely available at https://github.com/Jakobovski/free-spoken-digit-dataset. The MNIST data set <ref type="bibr" target="#b32">[33]</ref> is freely available at http://yann.lecun.com/exdb/mnist. The bAbI data set <ref type="bibr" target="#b16">[17]</ref> is freely available at https://research.fb.com/downloads/babi.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code Availability</head><p>The models were implemented in PyTorch <ref type="bibr" target="#b52">[53]</ref> and the code is available at https://github.com/IGITUGraz/ MemoryDependentComputation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary Model and training details</head><p>Here we give details to our models, and to the encoding and representation of inputs used in our models. The models were simulated with a time step ?t of 1 ms. We used the Euler method for the integration of the neuron dynamics. Every neuron state, that is, membrane potential, remaining refractory period, etc. are represented by fixed size state vectors that are updated at each time step of the simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spike rate regularization</head><p>To achieve biologically plausible neuron and network activity, we used an L 2 activity regularizer, which encourages solutions with sparse spiking. For any particular layer with N neurons, the spike rate regularization loss is calculated according to</p><formula xml:id="formula_11">L ? = ? ? 1 N N i=1 (? 0 ? ? i ) 2 ,<label>(1)</label></formula><p>where ? ? is the regularization factor, ? 0 = 0 is the target firing rate, and ? i is the average firing rate of neuron i. The average is across the entire simulation duration of a given layer and the entire batch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Converting pre-trained CNNs</head><p>We considered the pre-trained CNN parameters as the synaptic weights while computing the weighted sum-of-spikes from pre-synaptic neurons via convolution operations. We replaced the post-convolution ReLU activations with integrate-and-fire (IF) neuron dynamics which implements V j (t + ?t) = V j (t) + I j (t) ? ?z j (t) without membrane potential leaks within the CNN layers, as opposed to the LIF neurons which are used in our models otherwise. Finally, we determine the layer-wise IF neuron firing thresholds within the CNN using the ANN-to-SNN conversion by thresholdbalancing algorithm <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>. The algorithm obtains a firing threshold for each CNN layer sequentially. We initialize all four layer-wise CNN firing thresholds with zeros. We treat the model inputs (i.e., grayscale Omniglot/MNIST pixel intensities or MFCC values) as a constant current applied for 100 ms to LIF neurons, to produce input spikes to this CNN. We used training set samples converted into input spikes (all training samples for MNIST and MFCC encoders, and 12 800 randomly drawn images for Omniglot which we found to be sufficient to obtain stable threshold estimates) and performed an initial forward pass from the first layer of the CNN. While doing so, we record the value of the maximum input current (incoming weighted sum-of-spikes) observed across all used training samples at any time step during the 100 ms, and set the firing threshold of the first CNN layer to have this value at the end. After the firing threshold of the first layer is set, we perform a forward pass of these spiking inputs starting from the first CNN layer once again using the set firing threshold, and then determine the firing threshold for the second layer in a similar way. We continue this process sequentially for all four layers of the CNN to determine layer-wise firing thresholds.</p><p>Following ANN-to-SNN conversion, spiking CNN synaptic weights were fine-tuned during end-to-end training of the models. At this stage, in cross-modal associations experiments, we also introduced additional (non-zero) bias terms for all convolution kernels in the CNNs. Note that this allows us to also fine-tune the conversion-based preset layer-wise firing thresholds individually for each CNN convolution kernel. In one-shot learning experiments, however, we did not (find it beneficial to) introduce bias terms to fine-tune the preset layer-wise CNN firing thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details to: Memorizing associations</head><p>We used two dense layers as input encoder in this task. Each layer consisted of 80 LIF neurons. One layer was used to encode each of the random input vectors and another layer was used to encode the integer labels. We trained models using different values for N (ranging from 2 to 55). We tuned the hyper-parameters using a validation set which contained 1000 sequences. The models were tested on 2000 sequences. We generated a data set for every iteration of BPTT. We trained for 4250 iterations using mini batches of size 512. The models were trained with Adam <ref type="bibr" target="#b51">[52]</ref> using a learning rate of ? = 0.003, that was reduced by 15 % every 340 iterations. The output of the network was produced by passing the number of spikes over the last 30 ms of z value through a final output layer with weights W out and a softmax. The error was computed when the network produced its prediction after the query and gradients were propagated through all time steps of the computation. Weights were initialized using Glorot uniform initialization <ref type="bibr" target="#b53">[54]</ref> with a gain of ? 2. The feedback delay d feedback was set to 1 ms. Starting from iteration 0, we applied L 2 activity regularization to all spiking neurons of the model (see Section Spike rate regularization for details). The regularization factor ? ? was set to 1 ? 10 ?5 . Gradients with an L 2 -norm larger than 40.0 were normalized to have norm 40.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details to: One-shot Learning</head><p>We used a CNN as input encoder for the Omniglot images. The CNN consisted of four weight layers and had the following structure: 4 ? (Conv2D ? Activation ? MaxPooling) ? Flatten. Each block comprises a 64-filter convolution with a kernel size of 3 ? 3 (stride = 1, zero-padding = 1 for each dimension) without bias terms. We used a 2 ? 2 pool size in the max pooling layers. When applied to the 28 ? 28 Omniglot images this architecture results in a 64-dimensional output space. This CNN was pre-trained using the prototypical loss <ref type="bibr" target="#b24">[25]</ref> with a ReLU function as the activation after convolutions (i.e., as a conventional ANN). We converted the pre-trained CNN into a spiking CNN that uses IF neuron dynamics as post-convolution activations, and used a threshold-balancing algorithm to set layer-wise firing thresholds <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> (detailed in Section Converting pre-trained CNNs). The converted spiking CNN synaptic weights were later fine-tuned during end-to-end training. We treated the grayscale values of an Omniglot image as a constant input current, applied for 100 ms to 784 LIF neurons, to produce input spikes to this CNN. The final layer of the CNN consisted of 64 LIF neurons. A single dense layer consisting also of 64 LIF neurons was used to encode the integer labels as spike trains with a duration of 100 ms per label.</p><p>We tuned the hyper-parameters using a held-out validation set of 172 characters (688 classes with rotations). We trained for 200 epochs with 200 iterations per epoch using mini batches of size 256. The models were trained with Adam <ref type="bibr" target="#b51">[52]</ref> using a learning rate of ? = 0.001, that was reduced by 15 % every 20 epochs. The output of the network was produced by taking the sum of spikes over the last 30 ms of z value , and by passing that value through a final output layer with weights W out and a softmax. The error was computed when the network produced its prediction after the query and gradients were propagated through all time steps of the computation. Weights were initialized using Glorot uniform initialization <ref type="bibr" target="#b53">[54]</ref> with a gain of ? 2. The feedback delay d feedback was set to 1 ms. We applied L 2 activity regularization after an initial training period of one epoch to all spiking neurons of the model (see Section Spike rate regularization for details). The regularization factor ? ? was set to 1 ? 10 ?6 . Gradients with an L 2 -norm larger than 40.0 were normalized to have norm 40.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details to: Cross-modal associations</head><p>We used version 1.0.10 of the FSDD data set available on GitHub, and the MNIST data set from the torchvision data set API (we kept the default train-test split of these data sets). We used one CNN to encode the audio input and one CNN to encode the MNIST images. We extracted 20 MFCCs from the audio signal before feeding it to the convolutional encoder network (we computed 21 MFCCs, but we discarded the constant offset coefficient, that is, the 0th coefficient; MFCCs were zero padded to 30 time samples and scaled such that each coefficient dimension had zero mean and unit variance). The CNNs consisted of four weight layers and had the following structure: 4 ? (Conv2D ? Activation ? MaxPooling) ? Flatten. Each block comprises a 64-filter convolution with a kernel size of 3 ? 3 (stride = 1, zero-padding = 1 for each dimension) without bias terms. We used a 2 ? 2 pool size in the max pooling layers. When applied to the 30 ? 20 MFCC features, to the 28 ? 28 MNIST images, this architecture results in a 64-dimensional output space. These CNNs were respectively pre-trained on FSDD/MNIST 10-class digit classification tasks with ReLU functions used as activations after convolutions (i.e., as a conventional ANN), and additional 64 ? 10 dimensional linear classification layers at the output. Following pre-training we discarded the final classification layers. We converted the pre-trained CNNs into spiking CNNs that uses IF neuron dynamics as post-convolution activations, and used a threshold-balancing algorithm to set layer-wise firing thresholds <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref> (detailed in Section Converting pre-trained CNNs). The converted spiking CNN synaptic weights were later fine-tuned during end-to-end training. Input spikes to the CNNs were produced by applying the grayscale values of the MNIST images and MFCC features to 784 and 600 LIF neurons, respectively (we treated these values as constant input current over 100 ms per input). The final layers of both CNNs consisted of 64 LIF neurons encoding the input stimuli.</p><p>We tuned the hyper-parameters using a validation set which contained 1000 sequences. To encourage the model to learn to associate a specific instance of the FSDD data set to a specific instance of the MNIST data set, we generated training examples as follow: We randomly choose three digits between 0 and 9. We then generated three tuples each containing a randomly drawn instance of these digits as audio file from the FSDD data set, and a randomly drawn instance of these digits as image from the MNIST data set. The query was another randomly drawn sample from one of the FSDD classes in the sequence. Test examples were generated as described in the main text. The image reconstruction was produced by a two-layer fully-connected network with 256 and 784 LIF neurons, respectively. The image was reconstructed by taking the sum of spikes of each neuron in the last layer, scaling the result by <ref type="bibr">1 15</ref> , and reshaping it to 28 ? 28. We trained our model for 4680 iterations using mini batches of size 256. The models were trained with Adam [52] using a learning rate of ? = 0.001, that was reduced by 15 % every 780 iterations. During training, all network weights are jointly learned by minimizing the mean squared error (MSE) between the output of the model and the target MNIST image. The error was computed when the network produced its output after the query and gradients were propagated through all time steps of the computation. Weights were initialized using Glorot uniform initialization <ref type="bibr" target="#b53">[54]</ref> with a gain of ? 2. The feedback delay d feedback was set to 1 ms. Starting from iteration 0, we applied L 2 activity regularization to all spiking neurons of the model (see Section Spike rate regularization for details). The regularization factor ? ? was set to 1 ? 10 ?7 . Gradients with an L 2 -norm larger than 40.0 were normalized to have norm 40.0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details to: Question Answering</head><p>We used version 1.2 of the bAbI data set (we kept the default train-test split of the data set). We used a learned encoding (LE) for sentences as proposed in <ref type="bibr" target="#b33">[34]</ref>. The encoding is given by e m = j f j ? Aw m,j , where w m,j is a word of a sentence x m = {w m,1 , w m,2 , . . . , w m,J } and where A is the embedding matrix and ? denotes the Hadamard product. The vectors f j were constant across time steps and were trained jointly with the other parameters of our model. We treated e m as constant input current, applied for 100 ms to a layer of 80 LIF neurons, to produces input spikes to our model. We tuned the hyper-parameters on a held-out validation set which was 10 % of the training set. The networks were trained for 200 epochs on 10 000 examples per task with a batch size of 256. The models were trained with Adam <ref type="bibr" target="#b51">[52]</ref> using a learning rate of ? = 0.003, that was reduced by 15 % every 20 epochs. The output of the network was produced by taking the sum of spikes over the last 30 ms of z value , and by passing that value through a final output layer with weights W out and a softmax. The error was computed when the network produced its prediction after the query and gradients were propagated through all time steps of the computation. Weights were initialized using Glorot uniform initialization <ref type="bibr" target="#b53">[54]</ref> with a gain of ? 2. We applied L 2 activity regularization after an initial training period of one epoch to all spiking neurons of the model (see Section Spike rate regularization for details). The regularization factor ? ? was set to 1 ? 10 ?5 . Gradients with an L 2 -norm larger than 40.0 were normalized to have norm 40.0. Since the number of sentences and the number of words per sentence varied within and between tasks, a null symbol was used to pad them to a fixed size. The embedding of the null symbol was constraint to be zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Details to: Reinforcement Learning</head><p>We used a dense layer consisting of 80 LIF neurons as input encoder in this task. Agents were trained with PPO <ref type="bibr" target="#b36">[37]</ref> in actor-critic style using 64 asynchronous vectorized environments. We trained for 4000 iterations. In each iteration, we performed 10 steps (100 steps for 6-card games) in each environment. The surrogate loss was then updated over 4 epochs and 16 training mini batches using Adam <ref type="bibr" target="#b51">[52]</ref> with a learning rate of ? = 0.0003. We used a value function coefficient of 0.1, an entropy coefficient of 0.01, and a discount factor of 0.9. The PPO clip parameter was set to 0.2. The agent received a reward of 25 for finding a matching pair and a small penalty of 0.5 for each card flip. The feedback delay d feedback was set to 1 ms. Gradients with an L 2 -norm larger than 0.5 were normalized to have norm 0.5. Actions were produced by taking the sum of spikes over the last 30 ms of z value , and by passing that value through a three-layer fully-connected network with 100, 100, and 4 (6 for 6-card games) neurons, respectively. We used hyperbolic tangent (tanh) activation functions except for the last layer. The critic was also a three-layer fully-connected network comprising of 100, 100, and 1 neurons, respectively. Again, we used tanh activation functions except for the last layer. The critic network received as input, in addition to the sum of spikes over the last 30 ms of z value , also the agent's observations. Actor and critic networks were initialized using orthogonal initialization <ref type="bibr" target="#b54">[55]</ref> with a gain of ? 2. Biases in these networks were zero initialized. Other weights in our model were initialized using Glorot uniform initialization <ref type="bibr" target="#b53">[54]</ref> with a gain of ? 2. <ref type="table" target="#tab_0">Table S1</ref>: Sample stories and questions from the bAbI data set <ref type="bibr" target="#b16">[17]</ref>. Lily is a swan. The triangle is to the right of the blue square. The football fits in the suitcase. Lily is white.</p><p>The red square is on top of the blue square. The suitcase fits in the cupboard. Bernhard is green.</p><p>The red sphere is to the right of the blue square. The box is smaller than the football. Greg is a swan. Q: Is the red sphere to the right of the blue square? Q: Will the box fit in the suitcase? Q: What color is Greg?</p><p>A: yes A: yes A: white</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task 19: Path Finding Task 20: Agent's Motivations</head><p>The kitchen is north of the hallway. John is hungry. The bathroom is west of the bedroom.</p><p>John goes to the kitchen. The den is east of the hallway.</p><p>John grabbed the apple there. The office is south of the bedroom.</p><p>Daniel is hungry. Q: How do you go from the den to the kitchen? Q: Where does Daniel go? A: west, north A: kitchen</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>Association task and out-of-distribution generalization. (A) Schematic of the network model (left), the network input for an input sequence of length N = 8 (top right), and the network activity after training (bottom right). Eight 10-dimensional random vectors along with an associated label from 1 to 8 are presented sequentially as facts (x1 to x8)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Omniglot one-shot task and a visualization of the embeddings learned by the encoder CNN in this task. (A) Schematic of the network model (left) and the network input (right). Five images from the Omniglot data set along with an associated label from 1 to 5 are presented sequentially as facts (x1 to x5). After all those image-label pairs have been presented to the network, it receives a query image (x6). The network is required to output the label that appeared together with an image of the same class as the query image. (B) A t-SNE visualization of the embeddings learned by the encoder CNN. A subset of the Tengwar script is shown (an alphabet in the test set). Misclassified characters are highlighted in red along with arrows pointing to the correct cluster. Inset: A t-SNE visualization of the learned key-and value-representation of the inputs. Colors indicate character class.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 :</head><label>4</label><figDesc>Audio to image synthesis task and examples of generated images. (A) Schematic of the network model (left) and the network input (right). Three audio-image pairs are presented sequentially as facts. Input pairs (x1, x2, and x3) contain a spoken digit from the FSDD data set and an image of the same digit from the MNIST data set. After all those audio-image pairs have been presented to the network, it receives an audio query (x4). The network is required to generate an image of the handwritten digit that appeared together with the spoken digit of the same class as the audio query. (B) Example MNIST images from the test set (top) and the corresponding images that were reconstructed by the network (bottom). The reconstructed images are not just typical images for the digit classes, but rather images that are very similar to the images presented previously with the audio cues (compare the three rightmost image pairs).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>An SNN learns to play the game Concentration from rewards. (A) Example game moves for a Concentration game with four cards played as a solitaire. The objective of the game is to turn over pairs of matching cards with as few card flips as possible. Shown is-for each time step ti-the agent's observation si, the action ai taken by the agent, and the resulting card configuration ci after taking action ai. The agent's observation s contains the state of the cells (face down card, illustrated by square with diamond pattern; face up card, square; or empty, grayed out square), the previous action taken by the agent, and the face of the card the agent had flipped in the previous time step. At time t1 all cards are face down. Flipping card 1 (action a1) results in configuration c1 (i.e., card 1, showing a blue triangle, is face up). Flipping card 2 in time step t2 reveals an orange disc (configuration c2). The two cards do not match, hence they are turned face down again in the next time step t3. In time step t3, card 4, that shows a blue triangle, is flipped. By recalling that the matching card is card 1, the agent flips card 1 in t4. Matching face up cards are then removed from the board. The game continues until the remaining two cards are removed. Board configurations at which the agent receives a reward are indicated by a red rectangle. (B) Evolution of the number of card flips the agent takes to finish a game over the number of games during training. Shown is the evolution of the number of flips for a deck of four cards (blue) and six cards (green). The mean number of flips is shown as saturated solid line. Black dashed lines show the mean number of flips required when the agent has perfect memory and follows an optimal strategy (5.33 for a deck of four cards and 8.65 for a deck of six cards). (C)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Test error rates (in %) on the 20 bAbI QA tasks. Comparison of our model to the Spiking RelNet model<ref type="bibr" target="#b34">[35]</ref> and to the non-spiking memory-based model H-Mem<ref type="bibr" target="#b18">[19]</ref> performing one memory access (1-hop) and three memory accesses(3-hop). Shown are mean error, error on individual tasks, and the number of failed tasks (according to the convention of<ref type="bibr" target="#b16">[17]</ref>, a model had failed to solve a task if the test error was above 5 % for that task; results of the alternative models were taken from the respective papers). Keys: mem. acc. = number of memory accesses; fb. delay = synaptic delay d feedback in feedback loop.</figDesc><table><row><cell></cell><cell>Spiking</cell><cell cols="2">H-Mem</cell><cell>ours</cell><cell></cell></row><row><cell></cell><cell>RelNet</cell><cell cols="2">mem. acc.</cell><cell cols="2">fb. delay</cell></row><row><cell>Task</cell><cell></cell><cell>1-hop</cell><cell>3-hop</cell><cell>1 ms</cell><cell>30 ms</cell></row><row><cell>1: Single Supporting Fact</cell><cell>1.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>2: Two Supporting Facts</cell><cell>-</cell><cell>64.2</cell><cell>0.2</cell><cell>10.4</cell><cell>3.3</cell></row><row><cell>3: Three Supporting Facts</cell><cell>-</cell><cell>58.6</cell><cell>26.9</cell><cell>58.6</cell><cell>59.2</cell></row><row><cell>4: Two Arg. Relations</cell><cell>0.1</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>5: Three Arg. Relations</cell><cell>2.3</cell><cell>4.1</cell><cell>1.3</cell><cell>1.4</cell><cell>2.1</cell></row><row><cell>6: Yes/No Questions</cell><cell>0.4</cell><cell>12.2</cell><cell>1.2</cell><cell>28.2</cell><cell>4.2</cell></row><row><cell>7: Counting</cell><cell>1.4</cell><cell>0.8</cell><cell>0.8</cell><cell>3.2</cell><cell>3.4</cell></row><row><cell>8: Lists/Sets</cell><cell>0.9</cell><cell>0.4</cell><cell>0.5</cell><cell>0.8</cell><cell>0.5</cell></row><row><cell>9: Simple Negation</cell><cell>0.7</cell><cell>15.5</cell><cell>3.3</cell><cell>1.4</cell><cell>2.7</cell></row><row><cell>10: Indefinite Knowledge</cell><cell>1.7</cell><cell>21.3</cell><cell>1.5</cell><cell>5.8</cell><cell>3.9</cell></row><row><cell>11: Basic Coreference</cell><cell>2.1</cell><cell>0.1</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>12: Conjunction</cell><cell>4.2</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.1</cell></row><row><cell>13: Compound Coref.</cell><cell>3.6</cell><cell>2.3</cell><cell>0.0</cell><cell>0.3</cell><cell>0.0</cell></row><row><cell>14: Time Reasoning</cell><cell>0.0</cell><cell>7.9</cell><cell>1.1</cell><cell>4.4</cell><cell>2.7</cell></row><row><cell>15: Basic Deduction</cell><cell>0.0</cell><cell>1.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>16: Basic Induction</cell><cell>-</cell><cell>54.2</cell><cell>54.8</cell><cell>54.1</cell><cell>53.4</cell></row><row><cell>17: Positional Reasoning</cell><cell>2.3</cell><cell>38.8</cell><cell>28.7</cell><cell>37.7</cell><cell>15.7</cell></row><row><cell>18: Size Reasoning</cell><cell>0.2</cell><cell>4.8</cell><cell>1.9</cell><cell>0.8</cell><cell>1.8</cell></row><row><cell>19: Path Finding</cell><cell>3.7</cell><cell>74.7</cell><cell>77.1</cell><cell>66.5</cell><cell>65.8</cell></row><row><cell>20: Agent's Motivations</cell><cell>0.4</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>Mean error</cell><cell>1.5</cell><cell>18.0</cell><cell>10.0</cell><cell>13.9</cell><cell>10.9</cell></row><row><cell>Failed tasks (err. &gt; 5 %)</cell><cell>3</cell><cell>9</cell><cell>4</cell><cell>7</cell><cell>4</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Neuron and plasticity parameters.</figDesc><table><row><cell>?</cell><cell>Firing threshold</cell><cell>0.1</cell></row><row><cell>? abs</cell><cell>Refractory period</cell><cell>3 ms</cell></row><row><cell>?m</cell><cell>Membrane time constant</cell><cell>20 ms</cell></row><row><cell>?trace</cell><cell>Time constant of synaptic trace</cell><cell>20 ms</cell></row><row><cell>w max</cell><cell>Soft maximum of Hebbian weights</cell><cell>1.0</cell></row><row><cell>?+</cell><cell>Write factor of Hebbian update rule</cell><cell>0.3</cell></row><row><cell>??</cell><cell>Forget factor of Hebbian update rule</cell><cell>0.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Task 16: Basic Induction Task 17: Positional Reasoning Task 18: Size Reasoning</head><label></label><figDesc>The office is north of the bedroom.Mary gave the cake to Fred. John moved to the playground. The bedroom is north of the bathroom.Fred gave the cake to Bill. Daniel went to the bathroom. The kitchen is west of the garden.Jeff was given the milk by Bill.John is either in the classroom or the garden. Daniel was in the kitchen. Mary and Jeff went to the kitchen. Sandra is in the garden.Then he went to the studio. Then Jeff went to the park. Q: Is John in the classroom?Sandra was in the office.Daniel and Sandra journeyed to the office. In the afternoon Julie went to the park. Sheep are afraid of wolves. Then they went to the garden.Yesterday Julie was at school. Cats are afraid of dogs. Sandra and John travelled to the kitchen.Julie went to the cinema this evening. Mice are afraid of cats. After that they moved to the hallway.</figDesc><table><row><cell>Task 1: Single Supporting Fact</cell><cell>Task 2: Two Supporting Facts</cell><cell>Task 3: Three Supporting Facts</cell></row><row><cell>Mary went to the bathroom.</cell><cell>John is in the playground.</cell><cell>John picked up the apple.</cell></row><row><cell>John moved to the hallway.</cell><cell>John picked up the football.</cell><cell>John went to the office.</cell></row><row><cell>Mary travelled to the office.</cell><cell>Bob went to the kitchen.</cell><cell>John went to the kitchen.</cell></row><row><cell>Q: Where is Mary?</cell><cell>Q: Where is the football?</cell><cell>John dropped the apple.</cell></row><row><cell>A: office</cell><cell>A: playground</cell><cell>Q: Where was the apple before the kitchen?</cell></row><row><cell></cell><cell></cell><cell>A: office</cell></row><row><cell>Task 4: Two Argument Relations</cell><cell>Task 5: Three Argument Relations</cell><cell>Task 6: Yes/No Questions</cell></row><row><cell></cell><cell></cell><cell>John went back to the hallway.</cell></row><row><cell>Q: What is north of the bedroom?</cell><cell>Q: Who gave the cake to Fred?</cell><cell>Q: Is John in the playground?</cell></row><row><cell>A: office</cell><cell>A: Mary</cell><cell>A: no</cell></row><row><cell>Task 7: Counting</cell><cell>Task 8: Lists/Sets</cell><cell>Task 9: Simple Negation</cell></row><row><cell>Daniel picked up the football.</cell><cell>Daniel picks up the football.</cell><cell>Sandra travelled to the office.</cell></row><row><cell>Daniel dropped the football.</cell><cell>Daniel drops the newspaper.</cell><cell>Fred is no longer in the office.</cell></row><row><cell>Daniel got the milk.</cell><cell>Daniel picks up the milk.</cell><cell>Q: Is Fred in the office?</cell></row><row><cell>Daniel took the apple.</cell><cell>John took the apple.</cell><cell>A: no</cell></row><row><cell>Q: How many objects is Daniel holding?</cell><cell>Q: What is Daniel holding?</cell><cell>Q: Is Sandra in the office?</cell></row><row><cell>A: two</cell><cell>A: milk, football</cell><cell>A: yes</cell></row><row><cell>Task 10: Indefinite Knowledge</cell><cell>Task 11: Basic Coreference</cell><cell>Task 12: Conjunction</cell></row><row><cell></cell><cell></cell><cell>: Where is Mary?</cell></row><row><cell>A: maybe</cell><cell>Q: Where is Daniel?</cell><cell>A: kitchen</cell></row><row><cell>Q: Is John in the office?</cell><cell>A: studio</cell><cell>Q: Where is Jeff?</cell></row><row><cell>A: no</cell><cell></cell><cell>A: park</cell></row><row><cell>Task 13: Compound Coreference</cell><cell>Task 14: Time Reasoning</cell><cell>Task 15: Basic Deduction</cell></row><row><cell></cell><cell>: Where did Julie go after the park?</cell><cell>Gertrude is a sheep.</cell></row><row><cell>Q: Where is Daniel?</cell><cell>A: cinema</cell><cell>Q: What is Gertrude afraid of?</cell></row><row><cell>A: garden</cell><cell>Q: Where was Julie before the park?</cell><cell>A: wolves</cell></row><row><cell></cell><cell>A: school</cell><cell></cell></row></table><note>QQ</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by the CHIST-ERA grant CHIST-ERA-18-ACAI-004, by the Austrian Science Fund (FWF) project number I 4670-N (project SMALL), and by the "University SAL Labs" initiative of Silicon Austria Labs (SAL). We thank Wolfgang Maass and Arjun Rao for initial discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pulsed neural networks</title>
		<imprint>
			<publisher>MIT press</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Deep learning in spiking neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tavanaei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghodrati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Kheradpisheh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Masquelier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Maida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural networks</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="47" to="63" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Long short-term memory and learningto-learn in networks of spiking neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bellec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Subramoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2018/file/c203d8a151612acf12457e4d67635a95-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gradient descent for spiking neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Superspike: Supervised learning in multilayer spiking neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zenke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1514" to="1541" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to spiking neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">O</forename><surname>Neftci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Mostafa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zenke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Magazine</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="51" to="63" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Spike frequency adaptation supports network computations on temporally dispersed information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Subramoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kraisnikovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bellec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Real-time computing without stable states: A new framework for neural computation based on perturbations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Natschl?ger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Markram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2531" to="2560" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Synaptic theory of working memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mongillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Barak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tsodyks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">319</biblScope>
			<biblScope unit="issue">5869</biblScope>
			<biblScope unit="page" from="1543" to="1546" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The organization of behavior: A neuropsychological theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">O</forename><surname>Hebb</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Long-lasting potentiation of synaptic transmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Bliss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>L?mo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of physiology</title>
		<imprint>
			<biblScope unit="volume">232</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="331" to="356" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Long-term potentiation-a decade of progress</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Malenka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Nicoll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">285</biblScope>
			<biblScope unit="issue">5435</biblScope>
			<biblScope unit="page" from="1870" to="1874" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Learning-induced ltp in neocortex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-S</forename><surname>Rioult-Pedotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Donoghue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">science</title>
		<imprint>
			<biblScope unit="volume">290</biblScope>
			<biblScope unit="issue">5491</biblScope>
			<biblScope unit="page" from="533" to="536" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Behavioral time scale synaptic plasticity underlies ca1 place fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Bittner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Milstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Grienberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Romani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Magee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">357</biblScope>
			<biblScope unit="issue">6355</biblScope>
			<biblScope unit="page" from="1033" to="1036" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Rapid synaptic plasticity contributes to a learned conjunctive code of position and choice-related information in the hippocampus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Spruston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="96" to="108" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Willshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">P</forename><surname>Buneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">C</forename><surname>Longuet-Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Non-holographic associative memory</title>
		<imprint>
			<date type="published" when="1969" />
			<biblScope unit="volume">222</biblScope>
			<biblScope unit="page" from="960" to="962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Towards AI-complete question answering: A set of prerequisite toy tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Merri?nboer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.05698</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">End-to-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2015/file/8fb21ee7a2207526da55a679f0332de2-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">H-mem: Harnessing synaptic plasticity with hebbian memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Limbacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Legenstein ; H. Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Balcan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/f6876a9f998f6472cc26708e27444456-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="627" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin ; I. Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Language models are few-shot learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2020/file/1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1877" to="1901" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Backpropagation through time: What it does and how to do it</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Werbos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1550" to="1560" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Building machines that learn and think like people</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Ullman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and brain sciences</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Prototypical networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel ; I. Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2017/file/cb8da6767461f2812ae4290eac7cbc42-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<ptr target="https://proceedings.mlr.press/v70/finn17a.html" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<editor>D. Precup and Y. W. Teh</editor>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
	<note>ser. Proceedings of Machine Learning Research</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">One-shot learning with spiking neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scherr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>St?ckl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<idno>bioRxiv:2020.06.17.156513</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">bioRxiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Human-level concept learning through probabilistic program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">350</biblScope>
			<biblScope unit="issue">6266</biblScope>
			<biblScope unit="page" from="1332" to="1338" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2016/file/90e1357833654983612fb05e3ec9148c-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing</title>
		<editor>Systems, D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="3630" to="3638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Fast-classifying, high-accuracy spiking deep networks through weight and threshold balancing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">U</forename><surname>Diehl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Neil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Binas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pfeiffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Joint Conference on Neural Networks (IJCNN)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Going deeper in spiking neural networks: VGG and residual architectures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sengupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Neuroscience</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">95</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Jackson</surname></persName>
		</author>
		<ptr target="https://github.com/Jakobovski/free-spoken-digit-dataset" />
		<title level="m">Spoken digit</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">MNIST handwritten digit database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist" />
	</analytic>
	<monogr>
		<title level="m">ATT Labs</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Tracking the world state with recurrent entity networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Henaff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1612.03969</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A long short-term memory for AI applications in spike-based neuromorphic hardware</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wild</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.03992</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Getting formal with dopamine and reward</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="263" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wolski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Klimov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.06347</idno>
		<title level="m">Proximal policy optimization algorithms</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">What to expect in a game of memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Velleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">S</forename><surname>Warrington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Mathematical Monthly</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="787" to="805" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A solution to the learning dilemma for recurrent networks of spiking neurons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bellec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Scherr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Subramoney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hajek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Salaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Legenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Maass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Using fast weights to deblur old memories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Plaut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the ninth annual conference of the Cognitive Science Society</title>
		<meeting>the ninth annual conference of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="page" from="177" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Learning to control fast-weight memories: An alternative to dynamic recurrent networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="139" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Using fast weights to attend to the recent past</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mnih</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Z</forename><surname>Leibo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ionescu</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2016/file/9f44e956e3a2b7b5598c625fcc802c36-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing</title>
		<editor>Systems, D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="4331" to="4339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Metalearning with hebbian fast weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Munkhdalai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.05076</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Hybrid computing using a neural network with dynamic external memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Danihelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Grabska-Barwi?ska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Colmenarejo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ramalho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Agapiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">538</biblScope>
			<biblScope unit="issue">7626</biblScope>
			<biblScope unit="page" from="471" to="476" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-H</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03126</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dynamic memory networks for visual and textual question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Merity</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2397" to="2406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Hierarchical memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tesauro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1605.07427</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Dynamic neural turing machine with continuous and discrete addressing schemes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gulcehre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chandar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="857" to="884" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Differentiable plasticity: Training plastic neural networks with backpropagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miconi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3559" to="3568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Loihi: A neuromorphic manycore processor with on-chip learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srinivasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chinya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Choday</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dimou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Imam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Micro</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="82" to="99" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Simplified neuron model as a principal component analyzer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Oja</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of mathematical biology</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="273" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">PyTorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tejani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chilamkurthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<ptr target="http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="8024" to="8035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Understanding the difficulty of training deep feedforward neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the thirteenth international conference on artificial intelligence and statistics, JMLR Workshop and Conference Proceedings</title>
		<meeting>the thirteenth international conference on artificial intelligence and statistics, JMLR Workshop and Conference Proceedings</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="249" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Exact solutions to the nonlinear dynamics of learning in deep linear neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mcclelland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ganguli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
