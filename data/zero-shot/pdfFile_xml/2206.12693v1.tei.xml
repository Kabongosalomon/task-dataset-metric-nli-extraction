<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TEVR: IMPROVING SPEECH RECOGNITION BY TOKEN ENTROPY VARIANCE REDUCTION</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hajo</forename><forename type="middle">Nils</forename><surname>Krabbenh?ft</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erhardt</forename><surname>Barth</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Institute for Neuro-and Bioinformatics</orgName>
								<orgName type="institution">hajo UG</orgName>
								<address>
									<settlement>Quarnbek</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of L?beck</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TEVR: IMPROVING SPEECH RECOGNITION BY TOKEN ENTROPY VARIANCE REDUCTION</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T11:16+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents TEVR, a speech recognition model designed to minimize the variation in token entropy w.r.t. to the language model. This takes advantage of the fact that if the language model will reliably and accurately predict a token anyway, then the acoustic model doesn't need to be accurate in recognizing it. We train German ASR models with 900 million parameters and show that on CommonVoice German, TEVR scores a very competitive 3.64% word error rate, which outperforms the best reported results by a relative 16.89% reduction in word error rate. We hope that releasing our fully trained speech recognition pipeline to the community will lead to privacy-preserving offline virtual assistants in the future.</p><p>1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Automated speech recognition has improved at an astonishing pace in recent years. This progress has been enabled in part by access to sufficient computing power for training very large models, such as the wav2vec 2.0 XLS-R 1B <ref type="bibr" target="#b5">Conneau et al., 2020;</ref><ref type="bibr" target="#b1">Babu et al., 2021)</ref>, which has 900 million parameters. But the crucial ingredient for success have been more advanced models, which massively reduced the cost for obtaining training data.</p><p>The invention of the CTC Loss <ref type="bibr" target="#b7">(Graves et al., 2006)</ref> has made it possible to use unaligned text as the ground-truth signal for speech recognition. Previously, characters and/or phonemes needed to be manually aligned in time to the input audio signal, which was very time consuming. In effect, the CTC Loss has made the preparation of supervised training data 99% cheaper, thereby paving the way for large data-hungry models.</p><p>Similarly, the wav2vec 2.0 contrastive loss function has made it possible to use arbitrary speech audio data without any ground-truth text for unsupervised pre-training. The result in practice is that researchers can use the audio from unlabeled videos for pre-training their models up to the point where only a few hours of supervised fine-tuning are necessary to produce excellent results.</p><p>Regarding the language models, stochastic techniques such as KenLM's on-disk Kneser-Ney smoothing <ref type="bibr" target="#b9">(Heafield, 2011;</ref><ref type="bibr" target="#b10">Heafield et al., 2013)</ref> have enabled researchers to extract spelling and grammar knowledge out of very large unstructured text collections, such as the OSCAR dataset.</p><p>Continuing this tradition, we present TEVR, a stochastic approach for designing recognition tokens based on a large unstructured text collection in such a way that they maximize the information gained by the acoustic speech recognition model without increasing computational complexity or training time.</p><p>Our work builds on the pre-trained XLS-R 1B model released by <ref type="bibr" target="#b1">Babu et al. (2021)</ref> which itself is a larger variant of XLSR <ref type="bibr" target="#b5">(Conneau et al., 2020)</ref> which is the cross-lingual extension of wav2vec 2.0 .</p><p>The model works on partially overlapping 25 ms chunks of audio signal sampled at 16 kHz which are processed with multiple layers of convolutional embedding followed by multiple attention layers to produce a contextual encoding which is then transformed by a typical linear language head into token logits. Such an architecture is currently considered state of the art.</p><p>Current speech recognition models such as the aforementioned XLS-R 1B are trained using the CTC loss. The CTC loss minimizes an unweighted sum of the cross-entropies for each time-step. During inference, however, the acoustic model is almost always paired with a stochastic language model. This means that the information gained by correctly recognising a given acoustic token varies strongly based on how this token will later be used by the language model.</p><p>To illustrate this concept, consider that "Danke Herr Tajani" and "Dank? Her? Tajani" contain almost the same acoustic information because both unknown tokens indicated by question marks can be reliably and accurately inferred by the language model. Training to accurately recognize these tokens at the acoustic level is, therefore, superfluous. In fact, it might even reduce overall recognition accuracy by taking up resources which otherwise could have learned more useful features.</p><p>In this work, we aim to correct this loss misallocation by introducing multi-character tokens, which are designed to minimize the inter-token variance of the entropies of the combined acoustic and linguistic likelihood distributions used to predict the token sequence representing the recognized text.</p><p>2 TRAINING AND TESTING DATA <ref type="bibr" target="#b1">Babu et al. (2021)</ref> pre-trained the XLS-R 1B model on a total of 436K hours of publicly available audio data from VoxPopuli <ref type="bibr" target="#b1">(Wang et al., 2021)</ref>, Multilingual Librispeech <ref type="bibr" target="#b15">(Pratap et al., 2020)</ref>, Com-monVoice <ref type="bibr" target="#b0">(Ardila et al., 2020)</ref>, VoxLingua107 <ref type="bibr" target="#b18">(Valk &amp; Alum?e, 2020)</ref>, and BABEL <ref type="bibr" target="#b6">(Gales et al., 2014)</ref>.</p><p>We combine the pre-trained convolutional embedding of XLS-R 1B with our own attention encoder and language model and perform additional pre-training matching the instructions in <ref type="bibr" target="#b1">Babu et al. (2021)</ref>, followed by stochastic language modelling and task-specific fine-tuning.</p><p>We perform TEVR token extraction on the training texts from CommonVoice 8.0, Multilingual Librispeech, EuroParl <ref type="bibr" target="#b17">(Tiedemann, 2012)</ref>, and OSCAR <ref type="bibr" target="#b14">(Ortiz Su'arez et al., 2020;</ref><ref type="bibr" target="#b13">Ortiz Su'arez et al., 2019)</ref>.</p><p>We fine-tune for the German Speech Recognition task using CommonVoice 8.0 <ref type="bibr" target="#b0">(Ardila et al., 2020)</ref>. For easier comparison to literature, e.g. <ref type="bibr" target="#b3">Bermuth et al. (2021)</ref>, we use CommonVoice 6.1 <ref type="bibr" target="#b0">(Ardila et al., 2020)</ref> for testing.</p><p>For testing, we generate 4-gram and 5-gram language models based on the texts from Common-Voice 8.0, Multilingual Librispeech, and EuroParl <ref type="bibr" target="#b17">(Tiedemann, 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">EXPERIMENTAL SETUP</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">TEVR TOKEN EXTRACTION</head><p>As explained in Section 1, TEVR tokens are introduced to prevent the loss misallocation caused by uniform weighting of single-character tokens during training of the acoustic model.</p><formula xml:id="formula_0">G i ? ?(t i ? gt i ) = 1 if t i = gt i 0 otherwise (1) P i ? LM (t 0 , . . . , t i?1 ) (2) lm-entropy(i) := ? x?X P Gi (x)[logP Pi (x)]<label>(3)</label></formula><p>lm-entropy(i) = ?logP Pi (gt i )</p><p>We define lm-entropy(i) to mean the sparse categorical cross-entropy for the correct prediction of an unknown token t i based on the likelihood distribution generated by the ByT5 language model conditioned upon the known tokens t 0 to t i?1 .</p><p>We model the sparse categorical ground-truth distribution for token t i at time-step i with Equation 1. As indicated by the ? notation, the G i are considered random variables which are sampled independently from the ?(t i ? gt i ) distributions. Correspondingly, the predictions P i are considered random variables, which are independently sampled for each i from the distributions generated by a fully trained causal deep learning language model LM conditioned on t 0 to t i?1 , as specified in Equation 2. With set X containing the entire vocabulary from which tokens are selected, we use P Pi (x) and P Gi (x) for x ? X to designate the discrete probability density functions of random variables P i and G i respectively. Calculating the cross-entropy of the distribution of P i relative to the distribution of G i independently for each time-step i results in Equation 3. Please note that we treat the time index i as a parameter and do not sum the cross-entropies over time.</p><p>Due to the sparseness of the distribution of each G i , this can be simplified to Equation 4, where tokens gt i are the ground-truth for the language model's prediction for each time-step i. When used without a parameter and in reference to a token, we define lm-entropy to mean lm-entropy(i) with i being the index inside the sentence of the current token. As a result, the lm-entropy of a token is a measure for the amount of information, which the acoustic model needs to generate in order for the language model to accurately predict said token. <ref type="figure" target="#fig_0">Figure 1</ref> shows each letter of the sentence "Die Katze ist niedlich" in row <ref type="formula">(1)</ref>. Row <ref type="formula">(2)</ref> shows the entropies of the likelihood distributions generated by the acoustic model for predicting each single-character token when optimized with a stock CTC loss. Row <ref type="formula" target="#formula_0">(3)</ref> shows the per-character lm-entropies, meaning the entropies of the likelihood distributions generated by a stochastic language model for predicting the next single-character token based on knowledge of previous singlecharacter tokens. This sequence of lm-entropies observed in the real world has a variance of ? 2 = 5.0, but the CTC loss formula assumes an uniform distribution. Obviously, such a discrepancy between theory and practice heavily skews the gradient, thereby optimizing the acoustic model towards the wrong goal.</p><p>TEVR tokens greatly alleviate the issue by reducing the variance of the lm-entropies, hence the name "Token Entropy Variance Reduction". This is achieved in three steps:</p><p>First and as a prerequisite, we need to calculate the per-character lm-entropies for a large collection of words. Inspired by the suggestion in <ref type="bibr" target="#b20">Xue et al. (2021)</ref> to use raw unicode bytes as tokens for training large T5 <ref type="bibr" target="#b16">(Raffel et al., 2019)</ref> transformer language models, we determine the lm-entropy of each character by training a T5 model on a large unstructured collection of German texts consisting of roughly 22 billion words. During training, we predict the next character conditioned upon the beginning of the sentence so far and use the cross-entropy as loss signal. We train the model until convergence.</p><p>Second, we sample the fully trained model by predicting the next character following each possible prefix of each sentence. We record the sequence of lm-entropy(c = Groundtruth i , i) ?i and obtain the values shown in <ref type="figure" target="#fig_0">Figure 1</ref> row <ref type="formula" target="#formula_0">(3)</ref>. For example, the partial word "niedl???" can be reliably corrected to "niedlich" by the language model, since the "i c h" characters have low lm-entropies in row (3). Third, we then use these per-character lm-entropies to extract compound tokens. For each character and each sentence in the CommonVoice training split we iterate over all sub-strings to find the lowest-lm-entropy snippets of a given length. For each sentence, we only retain the 20% lowest-lm-entropy snippets. We then select the most-common snippets over all sentences as our TEVR tokens for any given length.</p><p>Our model variant M consists of 40 4-character tokens, 80 3-character tokens, 96 2-character tokens, and the 40 single-character tokens used in variant S. For lists of the specific tokens used for each model variant, please see the appendix or our source code release at https://huggingface.co/fxtentacle/wav2vec2-xls-r-1b-tevr.</p><p>Row <ref type="formula" target="#formula_1">(4)</ref> of <ref type="figure" target="#fig_0">Figure 1</ref> shows the tokenization of the example sentence using the TEVR tokens from model variant M. Row <ref type="formula">(5)</ref> shows the per-token lm-entropies for these compound character tokens, as obtained by summing up the individual per-character lm-entropies of contained characters. Row (6) then shows the effective per-character lm-entropies used for gradient estimation when the model variant M is trained with TEVR tokens. With ? 2 = 1.4, the lm-entropy sequence of these tokens is much closer to the uniform distribution assumed by the CTC loss, thereby greatly reducing the gradient skew during training.</p><p>To highlight that the performance improvement of TEVR is caused by the lm-entropy variance reduction and not just by introducing multi-character tokens, we also train and evaluate model variant L which contains almost all multi-character tokens seen in any training sentence, but chosen exhaustively and, hence, without considering the per-character lm-entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">GERMAN SPEECH RECOGNITION</head><p>We use the wav2vec 2.0 implementation available from HuggingFace <ref type="formula">(2022)</ref> with a configuration of 48 hidden layers using 1280 hidden states each and feed-forward blocks with an inner dimension of 5120. Together with the LM head, that results in 918 million to 919 million parameters depending on variant. We use gradient checkpointing <ref type="bibr" target="#b4">(Chen et al., 2016)</ref> to conserve GPU memory, and the Adam optimizer (Kingma &amp; Ba, 2014) with a learning rate warm-up followed by linear decay. Due to memory constraints, we exclude audio recordings that exceed a length of 295,488 samples. Each training batch then consists of 8 complete audio recordings. A 0.005 weigh decay was used.</p><p>We train 3 variants of the model for up to 4 epochs each with varying warm-up and learning rates, as summarized in <ref type="table" target="#tab_0">Table 1 and Table 2</ref>.</p><p>Epoch Warm-up Steps Learning Rate 1 500 1.0 ? 10 ?4 2 1500 0.5 ? 10 ?4 3 1500 0.1 ? 10 ?4 4 1500 0.1 ? 10 ?4      <ref type="table">Table 6</ref>: Overview of our word error rates and results from literature on German CommonVoice 6.1. The entries marked with * indicate self-reported results on the Community Models tab on paperswithcode.com. We successfully replicated their results based on the source code provided by them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>The raw word error rates without language model obtained by each of the 3 variants after each of the 4 training epochs are shown in <ref type="table" target="#tab_2">Table 3</ref>. After 4 epochs, variant M with TEVR tokens reduces the raw word error rate by a relative 5.74% in comparison to variant S, which is the unmodified wav2vec 2.0 XLS-R 1B architecture. As will be shown later, this performance improvement is amplified when using a word model. For character error rates, see <ref type="table" target="#tab_3">Table 4</ref>. Unsurprisingly, using single character tokens resulted in the lowest raw character error rate while the model variant with the highest number of distinct tokens also had the highest error rate.</p><p>We performed a parameter sweep using a small 4-gram word model on a validation split of the data, which confirmed our hypothesis that the TEVR-enhanced model variant M performs best, this time with a relative 15.38% improvement in word error rate over the unmodified wav2vec 2.0 XLS-R 1B architecture. Please also note that model variant L, which contains even more multi-character tokens, performs worse than variant M. This strongly suggest that the performance improvement is indeed caused by the entropy variance reduction and not merely by introducing multi-character tokens. The results are provided in <ref type="table" target="#tab_4">Table 5</ref>.</p><p>We chose model variant M with 4 epochs of training as the acoustic model and built a full recognition pipeline (including language model) based on it for our final evaluation on the German testing split of CommonVoice 6.1. We obtained a very competitive word error rate of 3.64% with a 5-gram language model (? = 0.7, ? = 0.75).</p><p>For comparison, we consulted the top results from paperswithcode.com (retrieved 02.06.2022), which were Bermuth et al. (2021) (6.6% WER) in the literature and an unmodified wav2vec 2.0 XLS-R 1B architecture self-reported as a community model by <ref type="bibr" target="#b21">Zimmermeister (2022)</ref>. Accordingly, instead of attempting to build our own unmodified wav2vec 2.0 XLS-R 1B recognition pipeline for comparison, we successfully verified the community results of Zimmermeister (2022) (4.38% WER with LM) and Grosman (2021) (12.06% WER without LM). See <ref type="table">Table 6</ref> for a comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">CONCLUSION</head><p>We have shown that when combined with an appropriately tuned language model, the TEVRenhanced model outperforms the best German automated speech recognition result from literature by a relative 44.85% reduction in word error rate. It also outperforms the best self-reported community model by a relative 16.89% reduction in word error rate.</p><p>We have shown that TEVR tokens outperform generically chosen multi-character tokens of a similar length, which suggests that it is the entropy variance reduction technique that leads to the increased model performance. We observe that the TEVR tokens -which were chosen with the goal of reducing entropy variance -coincide with linguistically meaningful word endings, such as "k?tzchen", "nied-lich", "funk-tion", and "glaub-haft". This hints at redundancy in the German language which TEVR tokens can exploit, but single-character tokens such as those used in the unmodified wav2vec 2.0 XLS-R 1B architecture cannot. See the appendix for a full list of the tokens used for all 3 model variants.</p><p>Due to budget constraints, we did not attempt to train a full TEVR-enhanced speech recognition pipeline for English. For professional clean studio-quality audiobook recordings, such as those in the LibriSpeech English dataset, we would expect TEVR to yield only a low relative improvement, because in those situations there are only few acoustic ambiguities. When operating under difficult conditions, such as the real-world dictation examples in the CommonVoice English dataset, however, we would expect TEVR to also significantly improve English ASR performance. We plan to explore this in a future work.</p><p>Our final German speech recognition pipeline consisting of the acoustic model, a matching language model, and necessary source code for inference and evaluation will be made publicly available on:</p><p>https://huggingface.co/fxtentacle/wav2vec2-xls-r-1b-tevr</p><p>We're hoping to see privacy-preserving offline virtual assistants in the future and we hope that releasing a fully trained working German ASR pipeline will help to make progress towards that goal. 6 APPENDIX 6.1 TOKENS USED BY MODEL VARIANT S This is an unmodified wav2vec 2.0 XLS-R 1B architecture with single-character tokens: <ref type="bibr">n, t, h, r, i, s, d, g, l, c, a, u, m, k, f, o, z, b, w, p, v,?,?, j,?, y, q, x,?,?,?, ae,?,?,?, ?</ref> 6.2 TOKENS USED BY MODEL VARIANT M These are the TEVR tokens obtained by grouping multiple low-lm-entropy characters into mediumlm-entropy compound tokens: <ref type="bibr">chen, sche, lich, isch, icht, iche, eine, rden, tion, urde, haft, eich, rung, chte, ssen, chaf, nder, tlic, tung, eite, iert, sich, ngen, erde, scha, nden, unge, lung, mmen, eren, ende, inde, erun, sten, iese, igen, erte, iner, tsch, keit, der, die, ter, und, ein, ist, den, ten, ber, ver, sch, ung, ste, ent, ach, nte, auf, ben, eit, des, ers, aus, das, von, ren, gen, nen, lle, hre, mit, iel, uch, lte, ann, lie, men, dem, and, ind, als, sta, elt, ges, tte, ern, wir, ell, war, ere, rch, abe, len, ige, ied, ger, nnt, wei, ele, och, sse, end, all, ahr, bei, sie, ede, ion, ieg, ege, auc, che, rie, eis, vor, her, ang, f?r, ass, uss, tel, er, in, ge, en, st, ie, an, te, be, re, zu, ar, es, ra, al, or, ch, et, ei, un, le, rt, se, is, ha, we, at, me, ne, ur, he, au, ro, ti, li, ri, eh, im, ma, tr, ig, el, um, la, am, de, so, ol, tz, il, on, it, sc, sp, ko, na, pr, ni, si, fe, wi, ns, ke, ut, da, gr, eu, mi, hr, ze, hi, ta, ss, ng, sa, us, ba, ck, em, kt, ka, ve, fr, bi, wa, ah, gt, di, ab, fo, to, rk, as, ag, gi, hn, s, t, n, m, r, l, f, e, a, b, d, h, k, g, o, i, u, w, p, z,?,?, v,?, j, c, y, x, q,?,?,?,?,?,?,?, ?</ref> 6.3 TOKENS USED BY MODEL VARIANT L This is an almost exhaustive list of all multi-character sequences seen in the training data and was chosen without regards to lowering lm-entropy variance:</p><formula xml:id="formula_2">e,</formula><p>aben, ache, acht, afte, aftl, agen, ahme, ahre, alen, alle, alls, alte, altu, amen, amme, ande, anis, annt, <ref type="bibr">asse, aten, atet, atio, ativ, atte, auch, beit, biet, chaf, chen, cher, ches, chie, chke, chla, chli, chne, chst, chte, chti, chts, chtu, chun, ckel, cklu, delt, dene, dent, dere, dern, ders, dert, deru, dete, dier, dies, dige, ding, dlic, dlun, dnet, doch, dung, eben, eche, echt, eden, eder, edoc, egen, ehen, ehme, eh?r, eich, eide, eind, eine, eise, eist, eite, eits, elen, eler, elle, ellt, elte, ende, enen, ensc, ente, entl, erde, erem, eren, erli, erne, ersc, ersi, erst, erte, erun, esch, esem, esen, eser, esse, essl, este, eten, eter, etzt, eute, fall, fent, ffen, ften, ftig, ftli, gend, gene, gisc, gkei, glic, glie, grei, gten, gung, haft, halb, heit, hend, hied, hkei, hlan, hlic, hlie, hlre, hmen, hnet, hnun, hren, hrer, hrte, hrun, hsel, hste, hten, hter, htet, htig, htun, hule, hung, h?rt, iche, ichk, ichn, icht, iden, iebe, iede, iegt, iele, iell, ielt, iere, iert, iese, iess, igen, iger, igke, igte, igun, ilie, inde, inem, inen, iner, ines, inge, ings, inie, insa, iona, ione, irat, isch, isse, issi, iste, iten, iter, itet, itig, itik, itio, itis, itte, it?t, jahr, kann, keit, klun, krie, ktio, kung, lame, land, ldet, ldun, lich, lied, lien, lies, lige, lisc, liti, llem, llen, llte, llun, logi, lrei, lsch, lten, ltkr, ltun, lung, luss, mati, mein, ment, miss, mmen, mung, nahm, nale, nand, nden, nder, ndes, ndet, ndig, ndun, nete, nfal, ngen, nger, ngli, nich, nier, nige, nisc, nlic, nnen, nnte, nsam, nsch, nten, nter, ntli, nung, olge, olgt, omme, onal, onde, onen, op?i, oren, osse, piel, p?is, rach, rate, rati, rbei, rche, rdem, rden, rdin, reic, rend, rere, rger, rhei, rich, rieb, rieg, rier, rige, risc, ritt, rlic, ropa, rop?, rsch, rsit, rste, rten, rund, rung, scha, sche, schl, send, serd, sere, sich, side, sier, sind, sion, sisc, sit?, slic, sond, spie, ssen, sser, ssig, ssio, ssli, sste, sten, ster, sung, tadt, tand, teht, teil, tell, tere, tern, ters, tete, tier, tige, tigt, tion, tisc, tive, tkri, tlic, trie, tsch, ttel, tten, tter, tung, tzen, tzte, tzun, unge, ungs, unkt, urch, urde, utsc, utun, vers, weis, weit, werd, wird, wort, wurd, zeit, ziel, zier, zlic, zten, zung,?chs,?isc,?ndi,?ter,?cht,?nne,?rte,?ber,?hrt,?ngl,?sse, abe, ach, age, ahl, ahn, ahr, akt, ale, ali, all, als, alt, ame, amt, and, ang, ank, ann, ans, ant, anz, ara, arb, are, ari, ark, art, ass, ast, ate, atz, aub, aue, auf, aus, aut, bar, bau, bed, bef, beg, bei, bek, bel, ben, ber, bes, bet, bew, bez, bil, bis, ble, bli, bra, bst, bur, cha, che, chi, chr, chs, chw, cke, dan, dar, das, dem, den, der, des, deu, die, dor, dre, ebt, eck, ege, egi, ehr, eil, eim, ein, eis, eit, ekt, ele, ell, elt, eme, enn, ens, ent, era, erb, ere, erf, erg, erh, eri, erk, erl, ern, err, ers, ert, erw, erz, est, etr, eue, eut, fel, fen, fer, ffe, for, fra, fre, f?r, gan, geb, gef, geh, gel, gem, gen, ger, ges, gew, gib, gra, han, hat, hau, hei, her, hie, hin, hle, hne, hre, ial, ibt, ich, ick, iel, ien, ier, iff, ige, ihn, ihr, ill, imm, ina, ind, ine, ing, ini, inn, ins, inz, ion, ist, jah, ken, ker, kom, kon, kte, lag, lan, lau, leg, lei, len, ler, lie, lig, lis, lle, mal, man, mar, meh, mei, men, mer, mis, mit, mmt, mte, mus, nac, nde, nen, ner, net, neu, nge, nie, nis, nke, nne, noc, nor, nst, ntr, nur, nze, obe, och, ode, ohn, oll, ord, org, ori, orm, ort, par, pen, per,</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of the entropy variance reduction effect, as explained in Section 3.1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>: Training Schedule</cell></row><row><cell cols="2">Variant Number</cell><cell>Total</cell><cell>Notes</cell></row><row><cell></cell><cell>of Tokens</cell><cell>Parameters</cell></row><row><cell>S</cell><cell>40</cell><cell cols="2">918 million Unmodified wav2vec 2.0 XLS-R 1B architecture with sin-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>gle character tokens, as used by Babu et al. (2021) in their</cell></row><row><cell></cell><cell></cell><cell></cell><cell>evaluation.</cell></row><row><cell>M</cell><cell>256</cell><cell cols="2">918 million In addition to all single-character tokens from variant S,</cell></row><row><cell></cell><cell></cell><cell></cell><cell>40 TEVR 4-character tokens, 80 TEVR 3-character to-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>kens, and 96 TEVR 2-character tokens were added.</cell></row><row><cell>L</cell><cell>904</cell><cell cols="2">919 million This variant contains the majority of all 4-character, 3-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>character, and 2-character sub-strings, thereby nullifying</cell></row><row><cell></cell><cell></cell><cell></cell><cell>the variance reduction effect.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell cols="4">Epoch WER Variant S WER Variant M WER Variant L</cell></row><row><cell>1</cell><cell>14.83%</cell><cell>14.59%</cell><cell>15.10%</cell></row><row><cell>2</cell><cell>12.69%</cell><cell>12.25%</cell><cell>12.72%</cell></row><row><cell>3</cell><cell>11.38%</cell><cell>10.81%</cell><cell>11.21%</cell></row><row><cell>4</cell><cell>10.72%</cell><cell>10.10%</cell><cell>10.53%</cell></row></table><note>Model Variants. See Section 3.1 for an explanation of how the tokens were obtained.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Raw Word Error Rates for each model variant after each epoch. These error rates were calculated without a language model. The best result in each epoch is highlighted in bold.</figDesc><table><row><cell cols="4">Epoch CER Variant S CER Variant M CER Variant L</cell></row><row><cell>1</cell><cell>3.74%</cell><cell>4.10%</cell><cell>4.54%</cell></row><row><cell>2</cell><cell>3.18%</cell><cell>3.42%</cell><cell>3.76%</cell></row><row><cell>3</cell><cell>2.82%</cell><cell>2.96%</cell><cell>3.27%</cell></row><row><cell>4</cell><cell>2.64%</cell><cell>2.78%</cell><cell>3.06%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell cols="5">Alpha Beta WER Variant S WER Variant M WER Variant L</cell></row><row><cell>0.5</cell><cell>0.5</cell><cell>5.95%</cell><cell>4.93%</cell><cell>5.95%</cell></row><row><cell>0.6</cell><cell>0.5</cell><cell>5.79%</cell><cell>4.93%</cell><cell>5.84%</cell></row><row><cell>0.7</cell><cell>0.5</cell><cell>5.59%</cell><cell>4.73%</cell><cell>5.54%</cell></row><row><cell>0.8</cell><cell>0.5</cell><cell>5.95%</cell><cell>4.88%</cell><cell>5.54%</cell></row><row><cell>0.5</cell><cell>0.75</cell><cell>5.95%</cell><cell>4.98%</cell><cell>5.84%</cell></row><row><cell>0.6</cell><cell>0.75</cell><cell>5.69%</cell><cell>4.93%</cell><cell>5.79%</cell></row><row><cell>0.7</cell><cell>0.75</cell><cell>5.59%</cell><cell>4.73%</cell><cell>5.59%</cell></row><row><cell>0.8</cell><cell>0.75</cell><cell>5.69%</cell><cell>4.83%</cell><cell>5.54%</cell></row><row><cell>0.5</cell><cell>1.0</cell><cell>5.79%</cell><cell>4.93%</cell><cell>5.74%</cell></row><row><cell>0.6</cell><cell>1.0</cell><cell>5.39%</cell><cell>4.93%</cell><cell>5.79%</cell></row><row><cell>0.7</cell><cell>1.0</cell><cell>5.34%</cell><cell>4.73%</cell><cell>5.64%</cell></row><row><cell>0.8</cell><cell>1.0</cell><cell>5.64%</cell><cell>4.83%</cell><cell>5.54%</cell></row></table><note>Raw Character Error Rates for each model variant after each epoch. These error rates were calculated without a language model. The best result in each epoch is highlighted in bold.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Parameter sweep on a validation split for identifying the best ? and ? parameters for decoding with a 4-gram language model. For every set of parameters, model variant M performed significantly better than variant S and L. Our final parameter selection of ? = 0.7, ? = 0.75 is highlighted in bold.</figDesc><table><row><cell>Architecture</cell><cell cols="2">Language Model WER</cell><cell>Source</cell></row><row><cell cols="2">wav2vec 2.0 XLS-R 1B + TEVR 5-gram</cell><cell cols="2">3.64% our best result</cell></row><row><cell cols="2">wav2vec 2.0 XLS-R 1B + TEVR 4-gram</cell><cell>3.70%</cell><cell>our ablation 4-gram LM</cell></row><row><cell>wav2vec 2.0 XLS-R 1B</cell><cell>5-gram</cell><cell>4.38%</cell><cell>Zimmermeister (2022) *</cell></row><row><cell>QuartzNet15x5DE (D37)</cell><cell>5-gram</cell><cell>6.6%</cell><cell>Bermuth et al. (2021)</cell></row><row><cell cols="2">wav2vec 2.0 XLS-R 1B + TEVR no LM</cell><cell cols="2">10.10% our ablation no LM</cell></row><row><cell>wav2vec 2.0 XLS-R</cell><cell>no LM</cell><cell cols="2">12.06% Grosman (2021) *</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Common voice: A massively-multilingual speech corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rosana</forename><surname>Ardila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megan</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelly</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Kohler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josh</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Henretty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reuben</forename><surname>Morais</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lindsay</forename><surname>Saunders</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francis</forename><surname>Tyers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregor</forename><surname>Weber</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/2020.lrec-1.520" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 12th Language Resources and Evaluation Conference</title>
		<meeting>the 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-05" />
			<biblScope unit="page" from="4218" to="4222" />
		</imprint>
	</monogr>
	<note>European Language Resources Association</note>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Xls-r: Self-supervised cross-lingual speech representation learning at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arun</forename><surname>Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andros</forename><surname>Tjandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kushal</forename><surname>Lakhotia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiantong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naman</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kritika</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yatharth</forename><surname>Patrick Von Platen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Saraf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Baevski</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2111.09296" />
		<imprint>
			<date type="published" when="2021" />
			<pubPlace>Alexis Conneau, and Michael Auli</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Abdelrahman Mohamed, and Michael Auli. wav2vec 2.0: A framework for self-supervised learning of speech representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Zhou</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2006.11477" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Scribosermo: Fast speech-to-text models for german and other languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Bermuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Poeppel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Reif</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2110.07982" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Training deep nets with sublinear memory cost</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianqi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chiyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Guestrin</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1604.06174" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Unsupervised cross-lingual representation learning for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexei</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2006.13979" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Speech recognition and keyword spotting for low-resource languages: Babel project research at cued</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark John Francis</forename><surname>Gales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kate</forename><surname>Knill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><surname>Ragni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shakti Prasad</forename><surname>Rath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SLTU</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Graves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santiago</forename><surname>Fern?ndez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faustino</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="DOI">10.1145/1143844.1143891</idno>
		<ptr target="https://doi.org/10.1145/1143844.1143891" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd International Conference on Machine Learning, ICML &apos;06</title>
		<meeting>the 23rd International Conference on Machine Learning, ICML &apos;06<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="369" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Xlsr wav2vec2 german by jonatas grosman</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonatas</forename><surname>Grosman</surname></persName>
		</author>
		<ptr target="https://huggingface.co/jonatasgrosman/wav2vec2-large-xlsr-53-german" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">KenLM: Faster and smaller language model queries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W11-2123" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>the Sixth Workshop on Statistical Machine Translation<address><addrLine>Edinburgh, Scotland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-07" />
			<biblScope unit="page" from="187" to="197" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Scalable modified Kneser-Ney language model estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Pouzyrevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">H</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P13-2121" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sofia, Bulgaria, Au</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="690" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Huggingface</surname></persName>
		</author>
		<ptr target="https://huggingface.co/facebook/wav2vec2-xls-r-1b" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1412.6980" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro Javier Ortiz</forename><surname>Su&amp;apos;arez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Romary</surname></persName>
		</author>
		<idno type="DOI">10.14618/ids-pub-9021</idno>
		<ptr target="http://nbn-resolving.de/urn:nbn:de:bsz" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff</title>
		<meeting>the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019. Cardiff<address><addrLine>Mannheim</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07-22" />
			<biblScope unit="page" from="39" to="90215" />
		</imprint>
	</monogr>
	<note>Leibniz-Institut f&quot;ur Deutsche Sprache</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A monolingual approach to contextualized word embeddings for mid-resource languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro Javier Ortiz</forename><surname>Su&amp;apos;arez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurent</forename><surname>Romary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benoit</forename><surname>Sagot</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.acl-main.156" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-07" />
			<biblScope unit="page" from="1703" to="1714" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">MLS: A large-scale multilingual dataset for speech research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vineel</forename><surname>Pratap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiantong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuroop</forename><surname>Sriram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronan</forename><surname>Collobert</surname></persName>
		</author>
		<idno>doi: 10. 21437/interspeech.2020-2826</idno>
		<ptr target="https://doi.org/10.21437%2Finterspeech" />
	</analytic>
	<monogr>
		<title level="m">Interspeech 2020. ISCA</title>
		<imprint>
			<date type="published" when="2020-10" />
			<biblScope unit="page" from="2020" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Exploring the limits of transfer learning with a unified text-to-text transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Matena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanqi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1910.10683" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">European Language Resources Association (ELRA)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thierry</forename><surname>Declerck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bente</forename><surname>Mehmet Ugur Dogan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maegaard</surname></persName>
		</author>
		<idno>978-2-9517408-7-7</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<editor>Odijk, and Stelios Piperidis</editor>
		<meeting>the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-05" />
		</imprint>
	</monogr>
	<note>Parallel data, tools and interfaces in opus</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Voxlingua107: a dataset for spoken language recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Valk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanel</forename><surname>Alum?e</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2011.12998" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Voxpopuli: A large-scale multilingual speech corpus for representation learning, semi-supervised learning and interpretation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changhan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgane</forename><surname>Riviere</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anne</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaitanya</forename><surname>Talnikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Haziza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mary</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juan</forename><surname>Pino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emmanuel</forename><surname>Dupoux</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.80</idno>
		<imprint>
			<biblScope unit="volume">01</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Byt5: Towards a token-free future with pre-trained byte-to-byte models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linting</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Barua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noah</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rami</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharan</forename><surname>Narang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mihir</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Colin</forename><surname>Raffel</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2105.13626" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Wav2vec2 xls-r 1b german with lm by florian zimmermeister</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Zimmermeister</surname></persName>
		</author>
		<ptr target="https://huggingface.co/flozi00/wav2vec2-xls-r-1b-5gram-german" />
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
