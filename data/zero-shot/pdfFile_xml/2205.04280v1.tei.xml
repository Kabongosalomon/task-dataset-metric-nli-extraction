<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">TGANet: Text-guided attention for improved polyp segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikhil</forename><surname>Kumar Tomar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">NepAL Applied Mathematics and Informatics Institute for Research (NAAMII)</orgName>
								<address>
									<settlement>Kathmandu</settlement>
									<country key="NP">Nepal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debesh</forename><surname>Jha</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Radiology</orgName>
								<orgName type="department" key="dep2">Feinberg School of Medicine</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<settlement>Chicago</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulas</forename><surname>Bagci</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Radiology</orgName>
								<orgName type="department" key="dep2">Feinberg School of Medicine</orgName>
								<orgName type="institution">Northwestern University</orgName>
								<address>
									<settlement>Chicago</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sharib</forename><surname>Ali</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Institute of Biomedical Engineering</orgName>
								<orgName type="department" key="dep2">Department of Engineering Science</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<postCode>OX3 7DQ</postCode>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">NIHR Oxford Biomedical Research Centre</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">TGANet: Text-guided attention for improved polyp segmentation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Label embedding ? polyp ? multi-scale features ? attention</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Colonoscopy is a gold standard procedure but is highly operatordependent. Automated polyp segmentation, a precancerous precursor, can minimize missed rates and timely treatment of colon cancer at an early stage. Even though there are deep learning methods developed for this task, variability in polyp size can impact model training, thereby limiting it to the size attribute of the majority of samples in the training dataset that may provide sub-optimal results to differently sized polyps. In this work, we exploit size-related and polyp number-related features in the form of text attention during training. We introduce an auxiliary classification task to weight the text-based embedding that allows network to learn additional feature representations that can distinctly adapt to differently sized polyps and can adapt to cases with multiple polyps. Our experimental results demonstrate that these added text embeddings improve the overall performance of the model compared to state-of-the-art segmentation methods. We explore four different datasets and provide insights for size-specific improvements. Our proposed text-guided attention network (TGANet) can generalize well to variable-sized polyps in different datasets. Codes are available at https://github.com/nikhilroxtomar/TGANet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Colorectal cancer (CRC) is one of the leading causes of cancer-related deaths <ref type="bibr" target="#b15">[16]</ref> worldwide. However, high operator-dependence and subjectivity during gold standard colonoscopic procedures remain high. This is also due to the complex topology of organ, severe artefacts, constant deformation of organ, debris and stool etc. Even though cleansing of the bowel is done to improve detection rates of cancer and cancer precursor lesions such as polyps, the missed rate is still high that accounts for 26.8% for polyps located on the right colon and 21.4% to polyps on the left colon <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b11">12]</ref>. In addition, the missed rate for flat or sessile polyps (diminutive polyps) is grim (nearly 32.7%). An automated system is thus clearly needed to minimize the operator subjectivity and missed rate. Semantic segmentation can classify each pixel into a class category, allowing the opportunity to learn meaningful semantic representations of polyps and their complex surroundings. Several methods do exist in the literature <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14]</ref> but most them focus on exploiting only localized spatial context. However, the nature and occurrence of polyps in colonic mucosa can be confused with colonic folds. Exploiting associated attributes such as size and occurrence (one or a few) could be used to infer and improve segmentation for hard samples.</p><p>Encoder-decoder networks has been widely used for polyp segmentation using various modifications to boost network performance <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b13">14]</ref>. PraNet <ref type="bibr" target="#b2">[3]</ref> applied area and boundary cues in reverse attention to focus on the polyp boundary regions. The high-level feature aggregation and boundary attention blocks in the network help to calibrate some of the misaligned predictions and improve the segmentation accuracy. Similarly, HRENet <ref type="bibr" target="#b13">[14]</ref> designed an informative context enhancement (ICE) technique and adaptive feature aggregation (AFA) module and trained the model on their edge and structure consistency aware loss (ES-CLoss), and obtained superior performance. Other works such as PolypSeg <ref type="bibr" target="#b17">[18]</ref> and MSRFNet <ref type="bibr" target="#b14">[15]</ref> uses modules incorporating multiple-scale information. An adaptive scale context module (ASCM) and semantic global context module (SGCM) was used in PolypSeg <ref type="bibr" target="#b17">[18]</ref>. The ASCM tackles the size variations among the polyp and improves the better feature representation capability, while SGCM enhances the feature fusion between the high-level and low-level features and remove noise in the low-level features to improve the segmentation accuracy. Similarly, MSRFNet <ref type="bibr" target="#b14">[15]</ref> integrated cross-scale fusion modules to propagate both high resolution and low-resolution features and an added shape stream network to prune polyp boundaries.</p><p>Most of these works in the literature <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref> focuses on size variation, boundary curves, background regions, dense skip connections and dense residual scale fusions that can boost performance. However, these adjustments are made using additional layers and explicit extensions of networks and their connections. This adds to the complexity of the model that can adversely affect the generalization of test samples coming from a similar distribution and require a large dataset. In addition, it can also affect images with underrepresented polyp sizes. In this work, we propose incorporating a text guided attention mechanism using a simple byte-pair encoding for the attributes comprising polyp number and its size. In addition, we use the same encoder layer of the network to provide weights for each of these attributes.</p><p>The main contributions of the presented work include -1) text guided attention to learn different features in the context of the number of polyps presence (one or many) and size (small, medium and large), 2) feature enhancement module to strengthen the features of the encoder and pass them to the decoder, and 3) multi-scale feature aggregation to capture features learned by different  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concat: Concatenation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>BN: Batch normalization</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>The proposed TGANet is a polyp segmentation architecture with text guided attention that enables to enhance feature representations such that the polyps present in images are segmented optimally independent of their size variability and occurrence. Our TGANet architecture consists of various components that are shown in <ref type="figure" target="#fig_0">Figure 1</ref> and elaborated below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Encoder module</head><p>TGANet is built upon a pre-trained ResNet50 <ref type="bibr" target="#b3">[4]</ref> as backbone encoder network for which we use its four different encoding blocks, e i , i ? 1, 2, 3, 4. These blocks are consecutively used for our auxiliary attribute classification task and for main polyp segmentation task. For the text-attribute classification, we use the output from the fourth encoder block as two classification task modules separately, i.e., number of polyps (one or many) and their size (small, medium and large). Here, softmax probabilities ? no polyp (.) and ? sz polyp (.) are predicted. For the main segmentation task, we take the output from each ResNet50 block and passes them through the feature enhancement module (FEM, f i , i ? 1, 2, 3, 4) that is responsible for strengthening the features by applying multiple dilated convolutions and an attention mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feature enhancement module</head><p>Feature enhancement module (FEM) (see <ref type="figure" target="#fig_0">Figure 1</ref> (b)) begins with four parallel dilated convolutions Conv with a dilation rate r = {1, 6, 12, 18}. Each dilation is followed by a batch normalization BN and a rectified linear unit ReLU which we refer as CBR. The output features are passed through a channelattention module CAM <ref type="bibr" target="#b16">[17]</ref> to capture the explicit relationship between the feature channels. The highlighted features from these four dilated convolutions are then concatenated and passed through a Conv 3?3 followed by BN layer and added with the original input features through a Conv 1?1 . The resulting features are then followed by a ReLU activation function, and a spatial attention mechanism SAM [17] is applied to suppress the irrelevant regions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Label attention</head><p>Label attention module is designed to provide learned text-based attention to the output features of the decoder blocks in our TGANet. Here, we use three label attention modules, l i , i ? 1, 2, 3, as soft channel-wise attention to the three decoder outputs that enables larger weights to the representative features and suppress the redundant ones. The first label attention module uses the output of the embedding fusion E(.) obtained by element-wise dot product between the softmax probability concatenation {? one , ? many , ? small , ? medium , ? large } with the encoded text embedding. Say, A = {one, many, small, medium, large} be the attributes that are encoded using byte-pair encoding <ref type="bibr" target="#b4">[5]</ref> and denoted by A encode with {a k j } as vector embedding for each attribute j of length |k|, then E(.) that is given by:</p><formula xml:id="formula_0">E = ? j a k j , ?k.<label>(1)</label></formula><p>The output of the label attention module is referred to as label features l f in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Decoder</head><p>The decoder in the proposed TGANet is comprised of three different decoder blocks d i , i ? 1, 2, 3, of which each takes the input features to upsample it and pass it through some convolutional layers to produce the output. This output is refined using the label attention module l i and passed to the subsequent decoder blocks d i (see <ref type="figure" target="#fig_0">Figure 1 (c)</ref>). The first decoder block takes the output of the fourth FEM f 4 to upsample it using bilinear interpolation by a factor of two, and then it is concatenated with the output features from the third FEM f 3 . The resulting concatenated feature is passed through a Conv 1?1 -BN-ReLU referred as CBR followed by a sequence of three Conv 3?3 -BN, further accompanied by their multiple residual connections and a ReLU activation function with subsequent convolutional block attention module represented as d cbam i . An element-wise multiplication is done to allow additional soft-attention from the computed label features l f using a sigmoid function for each decoder block output d out i , i ? 1, 2, 3 given by:</p><formula xml:id="formula_1">d out i = d cbam i ?([Conv ? ReLU ? Conv]l f ), ?i ? 1, 2, 3<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Multi-scale feature aggregation</head><p>Multi-scale feature aggregation (MSFA) module (see supplementary <ref type="figure" target="#fig_0">Figure 1</ref>) is used to fuse multi-scale feature representations at various decoder outputs d out i , i ? 1, 2, 3 that allows to capture learned features. We take the first two features {d out 1 , d out 2 } and pass them through a bilinear upsampling to ensure that all three features have the exact spatial dimensions followed by linear 1 ? 1 convolution layers, BN and ReLU activation before concatenation. To boost the capture of non-linear features we further apply a series of convolutional layers, BN and ReLU together with multiple residual connections for improved flow of information. The output is represented as m f which is responsible for our predicted segmentation map I pred mask given by: I pred mask = ?(Conv 1?1 (m f )). Joint loss optimization: We jointly minimize loss for both the auxiliary classification tasks (cross-entropy losses, CE loss1 , CE loss2 ) and the segmentation task (binary cross entropy, BCE loss3 and dice loss, DSC loss4 ) with equal weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Datasets</head><p>To evaluate the performance of our TGANet, we have used four publicly available polyp segmentation benchmark datasets including Kvasir-SEG <ref type="bibr" target="#b8">[9]</ref>, CVC-ClinicDB <ref type="bibr" target="#b0">[1]</ref>, BKAI <ref type="bibr" target="#b10">[11]</ref>, and Kvasir-Sessile <ref type="bibr" target="#b7">[8]</ref> (details are presented in supplementary <ref type="table" target="#tab_1">Table 1</ref>). Relevant to our experiment, Kvasir-Sessile <ref type="bibr" target="#b7">[8]</ref> contains 196 small, diminutive, sessile and flat polyps that are less than 10 mm in size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Implementation Details</head><p>All models are trained on NVIDIA GeForce RTX 3090 GPU, and images are resized to 256 ? 256 pixels with 80:10:10 training, validation, and testing splits except for Kvasir-SEG, where we adopted the official split of 880/120 for training and testing. Simple data augmentation strategy including random rotation, vertical flipping, horizontal flipping, and coarse dropout are used. All models are trained on a similar hyperparameters configuration with a learning rate of 1e ?4 , batch size of 16, and optimized with Adam optimizer. An early stopping mechanism and ReduceLROnPlateau is used to prevent models from overfitting. Standard medical image segmentation metrics such as mean intersection over union (mIoU), mean S?rensen-dice coefficient (mDSC), recall, precision, F2score and frame per second (FPS) are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results</head><p>We have compared our results with five SOTA methods that include UNet <ref type="bibr" target="#b12">[13]</ref>, HarDNet-MSEG <ref type="bibr" target="#b5">[6]</ref>, ColonSegNet <ref type="bibr" target="#b6">[7]</ref>, DeepLabv3+ <ref type="bibr" target="#b1">[2]</ref>, and PraNet <ref type="bibr" target="#b2">[3]</ref>. These algorithms are widely used baselines in both polyp segmentation and general medical image segmentation. The quantitative results are presented in <ref type="table" target="#tab_1">Table 1</ref>. <ref type="table">Table 2</ref>: mDSC for different sizes and polyp counts on Kvasir-SEG <ref type="bibr" target="#b8">[9]</ref> Method small medium large one many Results on Kvasir-SEG: <ref type="table" target="#tab_1">Table 1</ref> shows that TGANet outperforms all the SOTA methods with a mIoU of 0.8330 and mDSC of 0.8982. Our TGANet outperforms most competitive PraNet [3] by 1.58% in mIoU and 1.45% mDSC.</p><p>Results on CVC-ClinicDB: For CVC-ClinicDB dataset, TGANet outperforms all SOTA methods reporting the highest mIoU and mDSC of 0.8990 and 0.9457, respectively. Our method outperformed the most competitive DeepLabV3+ <ref type="bibr" target="#b1">[2]</ref> with a mIoU of 0.17% and mDSC of 0.66%. <ref type="table" target="#tab_1">Table 1</ref> shows the comparison of the result on the BKAI dataset that show that our proposed TGANet obtains mIoU of 0.8409 and mDSC of 0.9023 and outperforms the best performing DeepLabV3+ <ref type="bibr" target="#b1">[2]</ref> by 0.95% on mIoU and 0.86% on mDSC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results on BKAI:</head><p>Results on Kvasir-Sessile: Kvasir-Sessile dataset is clinically most relevant as it has flat and sessile polyps. On this dataset, it can be observed (see <ref type="table" target="#tab_1">Table 1</ref>) that our TGANet surpasses all the other methods in all the evaluation metrics. It outperforms the best performing PraNet <ref type="bibr" target="#b2">[3]</ref> by a large margin of 2.39% on mIoU and 2.44% on mDSC. Similarly, almost 10% improvement is observed compared to the DeepLabV3+ <ref type="bibr" target="#b1">[2]</ref> in this case which is a significant improvement.  <ref type="table">Table 2</ref> that our model outperforms the best SOTA methods for almost all cases. For the 'small', 'medium' and 'many cases', the improvement ranges from nearly 1-2%. Our qualitative results (see <ref type="figure">Figure 2</ref>) demonstrate a clear improvement of our text-based attention method for different sizes and number polyp samples. It is evident that both PraNet <ref type="bibr" target="#b2">[3]</ref> and DeepLabV3+ <ref type="bibr" target="#b1">[2]</ref> failed to capture sample with two polyps (4th row) and also provided over segmentation for the small (1st row) and medium polyps (2nd row). Additionally, we have provided the total number of parameters, flops and FPS in supplementary material <ref type="table">Table 2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Ablation study</head><p>To validate the effectiveness and importance of the core components used in the network, we compare TGANet with its five variants, which is presented in <ref type="table" target="#tab_2">Table 3</ref>. The results suggest that the introduction of the text guided attention along with the label boosts the performance of the network. The results show that TGANet improves the baseline without the label and classifier (#1) by 2.26% on mIoU and 1.96% on mDSC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We proposed a text-guided attention architecture (TGANet) to tackle polyps' variable size and number for robust polyp segmentation. We have used multiple feature enhancement modules connected with different encoder blocks to achieve this. An auxiliary task is learned together with the main task to compliment both the size-based and number-based feature representations and used as label attentions in the decoder blocks. Additionally, the multi-scale fusion of the features at the decoder enabled our network to deal with these attribute changes. Our experimental results demonstrated the effectiveness of our TGANet outperformed and provided higher segmentation performance on flat and sessile polyps that are clinically important.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 :</head><label>1</label><figDesc>Block diagram of the proposed TGANet decoder blocks. We have evaluated our TGANet on four publicly available polyp datasets and compared it with five SOTA medical image segmentation methods.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>DeepLabV3+ [ 2 Fig. 2 :</head><label>22</label><figDesc>Qualitative results comparison on the Kvasir-SEG dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Quantitative results on the experimented polyp datasets.</figDesc><table><row><cell>Method</cell><cell cols="4">Backbone mIoU mDSC Recall Precision F2</cell></row><row><cell cols="2">Dataset: Kvasir-SEG [9]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>U-Net [13]</cell><cell>-</cell><cell>0.7472 0.8264 0.8504</cell><cell>0.8703</cell><cell>0.8353</cell></row><row><cell cols="3">HarDNet-MSEG [6] HardNet68 0.7459 0.8260 0.8485</cell><cell>0.8652</cell><cell>0.8358</cell></row><row><cell>ColonSegNet [7]</cell><cell>-</cell><cell>0.6980 0.7920 0.8193</cell><cell>0.8432</cell><cell>0.7999</cell></row><row><cell>DeepLabV3+ [2]</cell><cell cols="2">ResNet50 0.8172 0.8837 0.9014</cell><cell>0.9028</cell><cell>0.8904</cell></row><row><cell>PraNet [3]</cell><cell cols="4">Res2Net 0.8296 0.8942 0.9060 0.9126 0.8976</cell></row><row><cell cols="5">TGANet (Ours) ResNet50 0.8330 0.8982 0.9132 0.9123 0.9029</cell></row><row><cell cols="2">Dataset: CVC-ClinicDB [1]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>U-Net [13]</cell><cell>-</cell><cell>0.8428 0.8978 0.9001</cell><cell>0.9209</cell><cell>0.8981</cell></row><row><cell cols="3">HarDNet-MSEG [6] HardNet68 0.8388 0.8967 0.8929</cell><cell>0.9216</cell><cell>0.8938</cell></row><row><cell>ColonSegNet [7]</cell><cell>-</cell><cell>0.8248 0.8862 0.8828</cell><cell>0.9017</cell><cell>0.8826</cell></row><row><cell>DeepLabV3+ [6]</cell><cell cols="3">ResNet50 0.8973 0.9391 0.9441 0.9442</cell><cell>0.9389</cell></row><row><cell>PraNet [3]</cell><cell cols="2">Res2Net 0.8866 0.9318 0.9347</cell><cell>0.9479</cell><cell>0.9333</cell></row><row><cell cols="5">TGANet (Ours) ResNet50 0.8990 0.9457 0.9437 0.9519 0.9439</cell></row><row><cell cols="2">Dataset: BKAI [11]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>U-Net [13]</cell><cell>-</cell><cell>0.7599 0.8286 0.8295</cell><cell>0.8999</cell><cell>0.8264</cell></row><row><cell>HarDNet-MSEG</cell><cell cols="2">HardNet68 0.6734 0.7627 0.7532</cell><cell>0.8344</cell><cell>0.7528</cell></row><row><cell>ColonSegNet [7]</cell><cell>-</cell><cell>0.6881 0.7748 0.7852</cell><cell>0.8711</cell><cell>0.7746</cell></row><row><cell>DeepLabV3+ [2]</cell><cell cols="4">ResNet50 0.8314 0.8937 0.8870 0.9333 0.8882</cell></row><row><cell>PraNet [3]</cell><cell cols="2">Res2Net 0.8264 0.8904 0.8901</cell><cell>0.9247</cell><cell>0.8885</cell></row><row><cell cols="5">TGANet (Ours) ResNet50 0.8409 0.9023 0.9026 0.9208 0.9002</cell></row><row><cell cols="2">Dataset: Kvasir-Sessile [8]</cell><cell></cell><cell></cell><cell></cell></row><row><cell>U-Net [13]</cell><cell>-</cell><cell>0.2472 0.3688 0.7237</cell><cell>0.3264</cell><cell>0.4635</cell></row><row><cell>HarDNet-MSEG</cell><cell cols="2">HardNet68 0.1565 0.2558 0.5403</cell><cell>0.2236</cell><cell>0.3298</cell></row><row><cell>ColonSegNet [7]</cell><cell>-</cell><cell>0.2113 0.3278 0.5234</cell><cell>0.3336</cell><cell>0.3868</cell></row><row><cell>DeepLabV3+ [2]</cell><cell cols="2">ResNet50 0.5927 0.7078 0.7085</cell><cell>0.8225</cell><cell>0.7009</cell></row><row><cell>PraNet [3]</cell><cell cols="2">Res2Net 0.6671 0.7736 0.8069</cell><cell>0.8244</cell><cell>0.7871</cell></row><row><cell cols="5">TGANet (Ours) ResNet50 0.6910 0.7980 0.7925 0.8588 0.7879</cell></row><row><cell cols="5">Training dataset: Kvasir-SEG -Test dataset: CVC-ClinicDB</cell></row><row><cell>U-Net [13]</cell><cell>-</cell><cell>0.5433 0.6336 0.6982</cell><cell>0.7891</cell><cell>0.6563</cell></row><row><cell cols="3">HarDNet-MSEG [6] HardNet68 0.6058 0.6960 0.7173</cell><cell>0.8528</cell><cell>0.7010</cell></row><row><cell>ColonSegNet [7]</cell><cell>-</cell><cell>0.5090 0.6126 0.6564</cell><cell>0.7521</cell><cell>0.6246</cell></row><row><cell>DeepLabV3+ [2]</cell><cell cols="3">ResNet50 0.7388 0.8142 0.8331 0.8735</cell><cell>0.8198</cell></row><row><cell>PraNet [3]</cell><cell cols="2">Res2Net 0.7286 0.8046 0.8188</cell><cell>0.8968</cell><cell>0.8077</cell></row><row><cell cols="5">TGANet (Ours) ResNet50 0.7444 0.8196 0.8290 0.8879 0.8207</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Ablation study of TGANet on Kvasir-SEG To explore the generalization capability of our proposed TGSNet, we train the model on Kvasir-SEG and test it on the CVC-ClinicDB. The cross-dataset test (Table 1) also suggested improvements compared to all SOTA methods and obtained an increment of 0.56% on mIoU and 0.54% on mDSC compared to the SOTA DeepLabv3+<ref type="bibr" target="#b1">[2]</ref>. Results on size and number-based sampled polyps: To show the effectiveness of our proposed TGANet, we evaluated test samples of Kvasir-SEG-based on the attributes used in training. It can be observed in</figDesc><table><row><cell cols="2">No Method</cell><cell cols="3">mIoU mDSC Recall Precision F2</cell></row><row><cell cols="3">#1 TGANet w/o label and classifier 0.8104 0.8786 0.8987</cell><cell>0.8970</cell><cell>0.8850</cell></row><row><cell cols="2">#2 TGANet w/o MSFA</cell><cell>0.8151 0.8832 0.9061</cell><cell>0.8999</cell><cell>0.8907</cell></row><row><cell cols="2">#3 TGANet w/o FEM</cell><cell>0.8084 0.8766 0.8968</cell><cell>0.9010</cell><cell>0.8838</cell></row><row><cell></cell><cell>TGANet w/o (label+classifier+</cell><cell></cell><cell></cell><cell></cell></row><row><cell>#4</cell><cell>MSFA+FEM)</cell><cell>0.8063 0.8747 0.8963</cell><cell>0.8971</cell><cell>0.8798</cell></row><row><cell cols="2">#5 TGANet (Ours)</cell><cell cols="3">0.8330 0.8982 0.9132 0.9123 0.9029</cell></row><row><cell cols="2">Results on cross dataset:</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplementary material</head><p>Suuplementary <ref type="table">Table 1</ref>: Polyp datasets used in our experiments with number of images, input size and their availability. For some indicated dataset test data are not available (e.g. BKAI) for which we used training data and split it into 80:10:10 for train, validation and test. Also, we use small, flat and sessile polyps in Kvasir-SEG.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>Images Input size Availability </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">WM-DOVA maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bernal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>S?nchez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Fern?ndez-Esparrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Vilari?o</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Pranet: Parallel reverse attention network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International conference on medical image computing and computer-assisted intervention (MICCAI)</title>
		<meeting>the International conference on medical image computing and computer-assisted intervention (MICCAI)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="263" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition (CVPR)</title>
		<meeting>the IEEE conference on computer vision and pattern recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heinzerling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the International Conference on Language Resources and Evaluation (LREC 2018)</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">L</forename><surname>Lin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2101.07172</idno>
		<title level="m">HarDNet-MSEG A Simple Encoder-Decoder Polyp Segmentation Neural Network that Achieves over 0.9 Mean Dice and 86 FPS</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Real-time polyp detection, localization and segmentation in colonoscopy using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Tomar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rittscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Access</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="40496" to="40510" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>De Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">A comprehensive study on Colorectal Polyp Segmentation With ResUNet++, Conditional Random Field and Test-Time Augmentation</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="2029" to="2040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Kvasir-SEG: a segmented polyp dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Smedsrud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Lange</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Multimedia Modeling (MMM)</title>
		<meeting>the International Conference on Multimedia Modeling (MMM)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="451" to="462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Miss rate of colorectal neoplastic polyps and risk factors for missed polyps in consecutive colonoscopies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">S</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Jeong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">I</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Intestinal research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">411</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>An</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Hang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Van Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">Q</forename><surname>Trung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">T</forename><surname>Thuy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Sang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.05023</idno>
		<title level="m">NeoUNet: towards accurate colon polyp segmentation and neoplasm detection</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Colonoscopic miss rates of adenomas determined by back-to-back colonoscopies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Rex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Cutler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Lemmel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">Y</forename><surname>Rahmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Helper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">A</forename><surname>Lehman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Gastroenterology</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="28" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional Networks for Biomedical Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Medical image computing and computer-assisted intervention (MICCAI)</title>
		<meeting>the International Conference on Medical image computing and computer-assisted intervention (MICCAI)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Hrenet: A hard region enhancement network for polyp segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Q H</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</title>
		<meeting>the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="559" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">MSRF-Net: A Multi-scale Residual Fusion Network for Biomedical Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chanda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Journal of biomedical imaging and health informatics</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Global cancer statistics 2020: Globocan estimates of incidence and mortality worldwide for 36 cancers in 185 countries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ferlay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Siegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Laversanne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Soerjomataram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jemal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CA: a cancer journal for clinicians</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="249" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Cbam: Convolutional block attention module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Polypseg: An efficient contextaware network for polyp segmentation from colonoscopy videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</title>
		<meeting>the International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="285" to="294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Suuplementary Figure 1: Block diagram of the proposed multi-scale fusion aggregation module that takes different scale features from three decoder blocks and concatenates them using upsampling, convolution, batch normalization and ReLU activations. Also, we apply residual-connections for different layers as shown</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Number of model parameters, flops, image size and frame-per-second is provided for both state-of-the-art (SOTA) methods and proposed TGANet. Method Parameters (Million) Flops (GMac) Image Size FPS</title>
		<imprint/>
	</monogr>
	<note>Suuplementary Table 2: Algorithm complexity of methods used in the study</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
