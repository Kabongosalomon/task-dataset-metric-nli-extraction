<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
							<email>chuanqi.tcq@alibaba-inc.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
							<email>songfang.hsf@alibaba-inc.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
							<email>f.huang@alibaba-inc.com</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Alibaba Group</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Tsinghua University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:52+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Nested entities are observed in many domains due to their compositionality, which cannot be easily recognized by the widely-used sequence labeling framework. A natural solution is to treat the task as a span classification problem. To learn better span representation and increase classification performance, it is crucial to effectively integrate heterogeneous factors including inside tokens, boundaries, labels, and related spans which could be contributing to nested entities recognition. To fuse these heterogeneous factors, we propose a novel triaffine mechanism including triaffine attention and scoring. Triaffine attention uses boundaries and labels as queries and uses inside tokens and related spans as keys and values for span representations. Triaffine scoring interacts with boundaries and span representations for classification. Experiments show that our proposed method outperforms previous span-based methods, achieves the state-ofthe-art F 1 scores on nested NER datasets GE-NIA and KBP2017, and shows comparable results on ACE2004 and ACE2005.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity recognition (NER) is a fundamental natural language processing task that extracts entities from texts. Flat NER has been well studied and is usually viewed as a sequence labeling problem <ref type="bibr" target="#b13">(Lample et al., 2016)</ref>. However, nested entities also widely exist in real-world applications due to their multi-granularity semantic meaning <ref type="bibr" target="#b0">(Alex et al., 2007;</ref><ref type="bibr" target="#b37">Yuan et al., 2020)</ref>, which cannot be solved by the sequence labeling framework since tokens have multiple labels <ref type="bibr" target="#b5">(Finkel and Manning, 2009)</ref>.</p><p>Various paradigms for nested NER have been proposed in recent years. A representative direction is the span-based approach that learns deep representation for every possible span and then classifies it to the corresponding type <ref type="bibr">(Zheng et al.,</ref>  2019; <ref type="bibr" target="#b34">Xia et al., 2019;</ref><ref type="bibr" target="#b27">Tan et al., 2020;</ref><ref type="bibr" target="#b40">Yu et al., 2020)</ref>. By leveraging the large-scale pretrained language model, several works show that the simple model structure for span representation and classification can achieve satisfactory results <ref type="bibr" target="#b42">Zhong and Chen, 2021)</ref>. However, we still believe that explicit modeling of some relevant features will further benefit the span representation and classification under the complex nested setting. Taking <ref type="figure" target="#fig_0">Figure 1</ref> as an example, we claim that the following factors are critical for recognizing whether a span is an entity. (1) Tokens: It is obvious that tokens of the given span contribute to the recognition. (2) Boundaries: We emphasize boundaries (or boundary tokens) because they are special tokens with rich semantics. Works with simple structure may just produce the span representation based on the concatenation or biaffine transformation of boundary representation <ref type="bibr" target="#b7">Fu et al., 2021)</ref>. Some other works take boundary detection as additional supervision for better representation learning <ref type="bibr" target="#b41">(Zheng et al., 2019;</ref><ref type="bibr" target="#b27">Tan et al., 2020)</ref>. More importantly, a unilateral boundary cannot determine the entity type since it can exist in multiple entities with different labels (e.g., "NF", "B", and "cells") under the nested setting. (3) Labels: As mentioned above, tokens could belong to entities with different labels. Therefore, we propose that the model should learn label-aware span representation to take into consideration of the different arXiv:2110.07480v3 [cs.CL] 2 Apr 2022 token contributions at the label level. 1 For example, "NF" may contribute more to "protein" type when classifying the span "NF -chi B", as well as "chi B" and "site" contribute more to "DNA" type when classifying the span "NF -chi B site". (4) Related spans: Interactions among spans are important in nested entities <ref type="bibr" target="#b23">(Luo and Zhao, 2020;</ref><ref type="bibr" target="#b7">Fu et al., 2021)</ref>. The insider and outsider entities may hint at each other's types. For example, entities inside "EBV-transformed B cells" have more possibilities to be cell-related entities. Interactions can also help the non-entity span like "transformed B cells" to validate its partialness by looking at outer entity "EBV -transformed B cells".</p><p>Although some of the factors may have been explored in previous works, to the best of our knowledge, it is the first work to fuse all these heterogeneous factors into a unified network. As the traditional additive, multiplicative attention, or biaffine transformation cannot interact with such multiple heterogeneous factors simultaneously, we propose a novel triaffine mechanism as the tensor multiplication with three rank-1 tensors (vectors) and a rank-3 tensor, which makes it possible to jointly consider high-order interactions among multiple factors. Specifically, our method follows the pipeline of span representation learning and classification. At the stage of span representation learning, we apply the triaffine attention to aggregate the label-wise span representations by considering boundaries and labels as queries as well as inside tokens as keys and values. Then, a similar triaffine attention is applied to produce the label-wise crossspan representations by querying boundaries and labels with related spans. At the stage of span classification, we fuse the span representations and boundaries for label-wise classification with a triaffine score function. In practice, we add an auxiliary object function to classify spans without the cross-span interaction, which benefits learning robust span representation and can be used as a span filter to speed up both training and inference without performance degradation.</p><p>We conduct experiments on four nested NER datasets: ACE2004, ACE2005, GENIA, and KBP2017. Our model achieves <ref type="bibr">88.56, 88.83, 81.23, and 87.27</ref> scores in terms of F 1 , respectively. Using the BERT encoder, our model outperforms stateof-the-art methods on GENIA and KBP2017 and 1 Label is the perdition object that we cannot touch in representation learning. Here, leveraging label information only means we need label-aware representation learning.</p><p>shows comparable performances on ACE2004 and ACE2005 with the latest generative methods. Ablation studies show the effectiveness of each factor and the superiority of the triaffine mechanism.</p><p>Our contributions are summarized as 2 :</p><p>? We propose that heterogeneous factors (i.e., tokens, boundaries, labels, related spans) should be taken into consideration in the spanbased methods for nested NER.</p><p>? We propose a span-based method with a novel triaffine mechanism including triaffine attention and scoring to fuse the above-mentioned heterogeneous factors for span representations and classification.</p><p>? Experiments show that our proposed method performs better than existing span-based methods and achieves state-of-the-arts performances on GENIA and KBP17.</p><p>2 Related Work</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Nested NER</head><p>Nested NER approaches do not have a unified paradigm. Here we mainly focus on span-based methods since they are close to our work. The span-based methods are one of the most mainstream ways for the nested NER. With the development of pre-training, it is easy to obtain the span representation by the concatenation of boundary representation <ref type="bibr" target="#b42">Zhong and Chen, 2021)</ref> or the aggregated representation of tokens <ref type="bibr" target="#b41">(Zheng et al., 2019;</ref>, and then follow a linear layer <ref type="bibr" target="#b34">(Xia et al., 2019)</ref> or biaffine transformation  for classification. Several works improve the span-based methods with additional features or supervision. <ref type="bibr" target="#b41">Zheng et al. (2019)</ref>; <ref type="bibr" target="#b27">Tan et al. (2020)</ref> point out the importance of boundaries and therefore introduce the boundary detection task.  propose Pyramid to allow interactions between spans from different layers. <ref type="bibr" target="#b7">Fu et al. (2021)</ref> adopt TreeCRF to model interactions between nested spans. Compared with previous methods, our method can jointly fuse multiple heterogeneous factors with the proposed triaffine mechanism.</p><p>Other methods for nested NER vary greatly. Earlier research on nested NER is rule-based <ref type="bibr" target="#b38">(Zhang et al., 2004)</ref>. <ref type="bibr" target="#b21">Lu and Roth (2015)</ref>; <ref type="bibr" target="#b11">Katiyar and Cardie (2018)</ref>;  leverage the hypergraph to represent all possible nested structures, which needs to be carefully designed to avoid spurious structures and structural ambiguities. ; <ref type="bibr" target="#b6">Fisher and Vlachos (2019)</ref> predict the transition actions to construct nested entities.  propose an anchor-based method to recognize entities. There are other works that recognize entities in a generative fashion <ref type="bibr" target="#b35">(Yan et al., 2021;</ref>. Generally, it is not a unified framework for nested NER, and we model it with a span-based method since it is most straightforward. <ref type="bibr" target="#b4">Dozat and Manning (2017)</ref> introduce the biaffine transformation in the dependency parsing task for arc classification. Later, it is widely used in many tasks that need to model bilateral representations <ref type="bibr" target="#b40">Yu et al., 2020)</ref>. The triaffine transformation is further introduced to extend biaffine transformation for high-order interaction in the field of dependency parsing <ref type="bibr" target="#b33">(Wang et al., 2019;</ref> and semantic role labeling <ref type="bibr" target="#b18">(Li et al., 2020b)</ref>. Except for the similar formula of vectors' interactions, the motivation and the use of triaffine are different in our paper. Firstly, they only model the homogeneous features such as three tokens, but our triaffine transformation can model heterogeneous factors including labels, boundaries, and related spans. Secondly, they usually leverage triaffine transformation to obtain log potentials for CRFs, but we apply it for span representation and classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Affine Transformations in NLP</head><p>3 Approach <ref type="figure" target="#fig_2">Figure 2</ref> shows an overview of our method. We will first introduce the triaffine transformations, which lie in the heart of our model to fuse heterogeneous factors. Then, we will introduce our model including triaffine attention and triaffine scoring based on the proposed triaffine transformations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Deep Triaffine Transformation</head><p>We define the deep triaffine transformation with vectors u, v, w ? R d and a tensor W ? R d+1 ? R d ? R d+1 which outputs a scalar by applying distinct MLP (multi-layer perceptron) transformations on input vectors and calculating tensor vector multiplications. A constant 1 is concatenated with inputs to retain the biaffine transformation.</p><formula xml:id="formula_0">u = MLP a (u) 1 , v = MLP c (v) 1 (1) w =MLP b (w) (2) TriAff(u, v, w, W) =W ? 1 u ? 2 w ? 3 v (3)</formula><p>where ? n is the mode-n tensor vector multiplication and MLP t is a t-layer MLP (0-layer MLP is equal to identify function). The tensor W is initialized using N (0, ? 2 ). In our approach, we use boundary representations as u and v. Inside tokens or span representations are used as w. We denote the tensors in the triaffine attention as {W r } and triaffine scoring as {V r }, which decouples attention weights and scores for different labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Text Encoding</head><p>We <ref type="formula">follow</ref>  </p><formula xml:id="formula_1">X = [x 1 , x 2 , ..., x N ]</formula><p>with N tokens, we first generate the contextual embedding x c i with the pre-trained language model,</p><formula xml:id="formula_2">x c 1 , x c 2 , ..., x c N = PLM(x 1 , x 2 , ..., x N )<label>(4)</label></formula><p>Then, we concatenate x c i with word embedding x w i , part-of-speech embedding x p i and character embedding x ch i , and feed the concatenated embedding x i into a BiLSTM <ref type="bibr" target="#b8">(Hochreiter and Schmidhuber, 1997)</ref> to obtain the token representations {h i }.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Triaffine Attention for Span Representations</head><p>To fuse heterogeneous factors for better span representation, we propose a triaffine attention mechanism shown in <ref type="figure" target="#fig_3">Figure 3a</ref>. To interact tokens with labels and boundaries, we learn the label-wise span representation h i,j,r with the triaffine attention ? i,j,k,r for the span (i, j):</p><formula xml:id="formula_3">s i,j,k,r = TriAff(h i , h j , h k , W r ) (5) ? i,j,k,r = exp(s i,j,k,r ) j k =i exp(s i,j,k ,r ) (6) h i,j,r = j k=i ? i,j,k,r MLP(h k )<label>(7)</label></formula><p>Boundary representations (h i , h j ) and the labelwise parameters (W r ) can be viewed as attention queries, and tokens (h k ) can be viewed as keys For each span, we have head and tail representations in yellow and label-wise span representations in different colors. The grey color indicates None class. and values. Compared with the general attention framework (additive or multiplicative attention), our triaffine attention permits all high-order interactions between heterogeneous queries and keys.</p><formula xml:id="formula_4">? ! ? " ? ? ! ! ,$ ! ,% ? % % !$&amp;% !$&amp;% !$&amp;% softmax (a) Triaffine Attention (b) Triaffine Scoring 1,4 ? 1 2 3 4 5 % ? ! ? " ? ",</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Triaffine Attention for Cross-span Representations</head><p>Motivated by the span-level interactions in the nested setting, we fuse related spans information into cross-span representations. We view the boundaries of the span and labels as attention queries, related spans (containing the span itself) as attention keys and values to obtain cross-span representations. Similar to the Equation 7, we obtain label-wise cross-span representations h c i,j,r for the span (i, j) based on triaffine attention ? i,j,g,r .</p><formula xml:id="formula_5">q i,j,g,r = TriAff(h i , h j , h ig,jg,r , W r ) (8) ? i,j,g,r = exp(q i,j,g,r ) g exp(q i,j,g ,r ) (9) h c i,j,r = g ? i,j,g,r MLP(h ig,jg,r )<label>(10)</label></formula><p>where {(i g , j g )} are the related spans. One can treat all enumerated spans as related spans, and we will introduce how we select them in Section 3.6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Triaffine Scoring for Span Classification</head><p>To classify the entity type of the span, we calculate label-wise scores based on cross-span representations. Since boundary information has been proved effective in previous works <ref type="bibr" target="#b7">Fu et al., 2021)</ref>, we leverage the boundaries information and cross-span representations for span classification via triaffine scoring. Specifically, we estimate the log probabilities p c i,j,r of the span (i, j) for label r using boundaries h i , h j and cross-span</p><formula xml:id="formula_6">representations h c i,j,r . p c i,j,r = TriAff(h i , h j , h c i,j,r , V r )<label>(11)</label></formula><p>Since h c i,j,r are composed by h ig,jg,r , we can decompose Equation 11 into following if and only if the layer of MLP transformation on h c i,j,r is 0:</p><formula xml:id="formula_7">t i,j,g,r = TriAff(h i , h j , h ig,jg,r , V r )<label>(12)</label></formula><formula xml:id="formula_8">p c i,j,r = g ? i,j,g,r t i,j,g,r<label>(13)</label></formula><p>Figure 3b and 3c show the mechanism of triaffine scoring and the decomposition. We also apply the similar decomposition functions in the auxiliary span classification task, which applies the triaffine scoring on boundary representations and intermediate span representations h i,j,r to estimate log probabilities p i,j,r as intermediate predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Training and Inference</head><p>In practice, it is expensive and non-informative to consider interactions between all spans. Therefore, we propose an auxiliary task to classify spans with intermediate span representations. Then, we can rank all spans based on the maximum of log probabilities (except None) from the intermediate predictions p i,j = max R r=1 p i,j,r , and retain top-m spans {(i l , j l )} m l=1 as candidates. We calculate cross-span representations h c i l ,j l ,r for retained spans by considering the full interactions among them, and estimate the classification logits p c i l ,j l ,r . Thus, we have two groups of predictions in our model {p i,j,r } 1?i?j?N and {p c i l ,j l ,r } 1?l?m . {p i,j,r } are calculated for every possible span, and {p c i l ,j l ,r } are calculated only on top-m spans.</p><p>In the training phase, we jointly minimize two groups of cross-entropy losses:</p><formula xml:id="formula_9">L aux = ? 2 N (N + 1) i,j log exp(p i,j,r ij ) r exp(p i,j,r )<label>(14)</label></formula><formula xml:id="formula_10">L main = ? 1 m 1?l?m log exp(p c i l ,j l ,r i l ,j l ) r exp(p c i l ,j l ,r )<label>(15)</label></formula><formula xml:id="formula_11">L =? aux L aux + L main<label>(16)</label></formula><p>where r ij is the label of span (i, j).</p><p>In both the training and inference phase, {p i,j,r } are used to select spans with high possibilities based on the supervision from L aux . We inference the labels of selected spans using {p c i l ,j l ,r } by assigning labelr i l ,j l = arg r max p c i l ,j l ,r , and we assign None class for others.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Datasets</head><p>We conduct our experiments on the ACE2004 3 , ACE2005 4 <ref type="bibr" target="#b3">(Doddington et al., 2004)</ref>, GENIA <ref type="bibr" target="#b12">(Kim et al., 2003)</ref> and KBP2017 5 <ref type="bibr" target="#b9">(Ji et al., 2017)</ref>  To fairly compare with previous works, we follow the same dataset split with <ref type="bibr" target="#b21">Lu and Roth (2015)</ref> for ACE2004 and ACE2005 and use the split from  for GENIA and KBP2017 datasets. The statistics of all datasets are listed in <ref type="table" target="#tab_2">Table 1</ref>. Following previous work, we measure the results using span-level precision, recall, and F 1 scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Implementation Details</head><p>We use BERT-large-cased <ref type="bibr" target="#b2">(Devlin et al., 2019)</ref> and albert-xxlarge-v2 <ref type="bibr" target="#b14">(Lan et al., 2020)</ref> as the contextual embedding, fastText <ref type="bibr" target="#b1">(Bojanowski et al., 2017)</ref> as the word embedding in ACE2004, ACE2005 and KBP2017 dataset. We use BioBERT-v1.1 <ref type="bibr" target="#b15">(Lee et al., 2020)</ref> and BioWordVec  as the contextual and word embedding in the GENIA dataset respectively. We truncate the input texts with context at length 192. The part-of-speech embeddings are initialized with dimension 50. The char embeddings are generated by a one-layer BiLSTM with hidden size 50. The two-layers BiLSTM with a hidden size of 1,024 is used for the token representations. For triaffine transformations, we use d = 256 for the ACE2004, ACE2005, and KBP2017 dataset, and d = 320 for the GENIA dataset, respectively. We set ? aux to 1.0, and select m = 30 in both training and inference. We use AdamW <ref type="bibr" target="#b20">(Loshchilov and Hutter, 2019)</ref> to optimize our models with a linear learning rate decay. Detailed training parameters are presented in Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Baselines</head><p>DYGIE  uses multi-task learning to extract entities, relations, and coreferences. MGNER <ref type="bibr" target="#b34">(Xia et al., 2019)</ref> uses a detector to find span candidates and a classifier for categorization. BENSC <ref type="bibr" target="#b27">(Tan et al., 2020)</ref> trains the boundary detection and span classification tasks jointly. TreeCRF <ref type="bibr" target="#b7">(Fu et al., 2021)</ref> views entities as nodes in a constituency tree and decodes them with a Masked Inside algorithm. Biaffine  classifies spans by a biaffine function between boundary representations. Pyramid  designs pyramid layer and inverse pyramid layer to decode nested entities.</p><p>We also report the results of models with other paradigms, including hypergraph-based methods , transition-based methods <ref type="bibr" target="#b6">(Fisher and Vlachos, 2019)</ref>, generative methods <ref type="bibr" target="#b35">(Yan et al., 2021;</ref>, and so on. We do not compare to BERT-MRC <ref type="table" target="#tab_2">(Li   ACE2004   ACE2005  GENIA  KBP2017  Train  Dev  Test  Train  Dev  Test  Train  Test  Train  Dev</ref>       and PURE <ref type="bibr" target="#b42">(Zhong and Chen, 2021)</ref> use different splits of the ACE datasets which are not comparable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>We compare our method with baseline methods in <ref type="table" target="#tab_3">Table 2</ref> for the ACE2004, ACE2005, and GENIA datasets and <ref type="table" target="#tab_4">Table 3</ref> for the KBP2017 dataset, respectively. With BERT as the encoder, our model achieves <ref type="bibr">87.40, 86.82, 81.23, and 85</ref>.05 scores in terms of F 1 , outperforming all other span-based methods such as BENSC, Pyramid, TreeCRF, and Biaffine (+0.70 on ACE2004, +1.42 on ACE2005, +0.73 on GENIA). Compared with methods in other paradigms, our model also achieves the state-of-theart results on the GENIA (+0.69 vs. Locate and Label) and KBP2017 dataset (+1.00 vs. Locate and Label) and shows comparable performances on ACE2004 (-0.01 vs. Locate and Label) and ACE2005 (-0.23 vs. Sequence to Set). With a stronger encoder ALBERT, our model achieves 88.56, 88.83, and 87.27 scores in terms of F 1 on ACE2004, ACE2005, and KBP2017 respectively, which exceeds all existing baselines including the Pyramid model with ALBERT (+0.82 on ACE2004, +2.49 on ACE2005) and the previous state-of-theart method on KBP2017 dataset (+3.22 vs. Locate and Label).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Ablation Study</head><p>Considering we leverage multiple factors in multiple parts of the model, we design the following ablation settings to validate the effectiveness of each factor and the proposed triaffine mechanism.  (a) To show the effectiveness of triaffine mechanism, we use a baseline biaffine model with the combination of boundary representations:</p><formula xml:id="formula_12">p i,j,r = h i 1 T V r h j 1 (17) (b)</formula><p>To show the effectiveness of boundaries in scoring, we remove boundaries factor from scoring:</p><formula xml:id="formula_13">p i,j,r = V r h i,j,r + b r<label>(18)</label></formula><p>(c) To show the effectiveness of labels in representation, we remove label factor in attention:</p><formula xml:id="formula_14">s i,j,k,r = TriAff(h i , h j , h k , W)<label>(19)</label></formula><p>(d) To show the effectiveness of boundaries in representation, we remove boundaries factor in attention:</p><formula xml:id="formula_15">s i,j,k,r = s k,r = q r ? h k<label>(20)</label></formula><p>(e) To show the effectiveness of the triaffine mechanism in representations, we replace triaffine attention with linear attention:</p><formula xml:id="formula_16">s i,j,k,r = W r (h i h j h k ) + c r<label>(21)</label></formula><p>(f) To show the effectiveness of triaffine scoring, we replace triaffine scoring to linear scoring:</p><formula xml:id="formula_17">p i,j,r = V r (h i h j h i,j,r ) + b r<label>(22)</label></formula><p>(g) To show the effectiveness of cross-span interactions, we use our partial model with intermediate predictions (model (a)-(g) use p i,j,r ).</p><p>(h) Our full model (i.e, use p c i l ,j l ,r as predictions). <ref type="table" target="#tab_6">Table 4</ref> shows the results of ablation studies on ACE2004 and GENIA datasets. We use BERT-large-cased as the backbone encoder on ACE2004 and BioBERT-v1.1 on GENIA, respectively. By comparing (a) with (g), we observe significant performances drop (-0.87 on ACE2004, -1.87 on GENIA), which indicates that our proposed triaffine mechanism with multiple heterogeneous factors performs better than the biaffine baseline. Comparing (b) with (g), we find that the boundary information contributes to span classification. Comparing (c) and (d) with (g) supports that either label or boundary in the triaffine attention improves the performance. The setting (g) performs better than (e) and (f), which shows the superiority of the triaffine transformation over the linear function. We observe that (h) performs better than (g) (+0.28 on ACE2004, +0.39 on GENIA), proving the strength of triaffine attention with interactions among related spans. The above studies support that our proposed triaffine mechanism with associated heterogeneous factors is effective for span representation and classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Discussion</head><p>We compare the F 1 scores of GENIA between triaffine model (g) and biaffine model (a) grouped by entity lengths in <ref type="figure">Figure 4</ref>. In all columns, the F 1 score of our method is better than the baseline. Furthermore, the right columns show that the F 1 score of the baseline gradually decreases with the incremental entity lengths. However, our method based on the triaffine mechanism with heterogeneous factors takes advantage of the interaction from boundaries and related spans, which keeps consistent results and outperforms the baseline.</p><p>The results grouped by flat or nested entities are shown in <ref type="table" target="#tab_9">Table 6</ref>. Our method has consistent improvements than the baseline, especially for the nested setting. Based on the above observations, our method is good at solving long entities that are   more likely to be nested, which supports our model is built upon the characteristics of nested NER. At the stage of cross-span interactions, we only select top-m spans in practice. In <ref type="figure" target="#fig_4">Figure 5</ref>, we analyze the number m in two aspects. Firstly, we check the recall of entity spans. We observe that taking top-30 spans achieves a recall of 99.89, which means it covers almost all entities. As the maximum number of entities is 25, we believe it is enough to select top-30 spans. Secondly, we check the model performance. With top-30 spans, the model achieves 81.23 scores in terms of F 1 and there is no obvious performance improvement with more candidates. Based on two above observations, we choose m = 30, which can well balance the performance and efficiency.</p><p>Finally, we test the efficiency of the decomposition. Compared with the naive triaffine scoring that takes <ref type="bibr">638.1ms (509.4ms in GPU + 128.7ms</ref> in CPU), the decomposed triaffine scoring takes 432.7ms (330.5ms in GPU + 102.2ms in CPU) for 10 iterations, which leads to approximately 32% speedup (details are shown in Appendix B).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Case Study</head><p>To analyze the effect of fusing information from related spans with the cross-span interaction, we show two examples from ACE2004 and GENIA datasets in <ref type="table" target="#tab_8">Table 5</ref>. In the first example, the model first predicts "the trading population" as "GPE", however, it revises to "PER" correctly by considering span interactions with the outer span "the rest of the trading population". In the second example, it first predicts "MnlI-AluI" as "protein". By interacting with surrounding entities "MnlI-AluI fragment", the model corrects its label to None.</p><p>In this paper, we propose a span-based method for nested NER. Heterogeneous factors including tokens, boundaries, labels, and related spans are introduced to improve span classification with a novel triaffine mechanism. Experiments show our method outperforms all span-based methods and achieves state-of-the-art performance on four nested NER datasets. Ablation studies show the introduced heterogeneous factors and triaffine mechanism are helpful for nested setting. Despite that large-scale pretrained language models have shown consistent improvement over many NLP tasks, we argue that the well-designed features and model structures are still useful for complex tasks like nested NER. Furthermore, although we only verify our triaffine mechanism in nested NER, we believe it can also be useful in tasks requiring high order interactions like parsing and semantic role labeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Reproducibility Checklist</head><p>We set seeds of torch, torch.cuda, numpy, and random in Python to ensure reproducibility. We use a grid search to find the best hyperparameters depending on development set performances. We search contextual embedding learning rate among {1e-5,3e-5}. If the contextual embedding learning rate is 1e-5, we use static embedding learning rate and task learning rate as 1e-4 and 1e-5. If the contextual embedding learning rate is 3e-5, we use static embedding learning rate and task learning rate as 5e-4 and 3e-5. We search batch size among {8,48,72}. We search MLP dropout ratio among {0.1,0.2}. The final hyperparameters we used for four datasets are listed in <ref type="table" target="#tab_11">Table 7 and Table 8</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B The Decomposition of Triaffine Scoring</head><p>We introduce the decomposition of triaffine scoring in calculating p i,j,r and p c i,j,r . The naive calculation procedure of p i,j,r is:</p><formula xml:id="formula_18">s i,j,k,r = TriAff(h i , h j , h k , W r ) (23) ? i,j,k,r = exp(s i,j,k,r ) j k =i exp(s i,j,k ,r ) (24) h i,j,r = j k=i ? i,j,k,r MLP(h k )<label>(25)</label></formula><formula xml:id="formula_19">p i,j,r = TriAff(h i , h j , h i,j,r , V r )<label>(26)</label></formula><p>For our proposed decomposition of p i,j,r , we first calculate ? i,j,k,r as equations 23 and 24. And we calculate:</p><formula xml:id="formula_20">o i,j,k,r = TriAff(h i , h j , h k , V r ) (27) p i,j,r = j k=i ? i,j,k,r o i,j,k,r<label>(28)</label></formula><p>The main difference between naive calculation and decomposition calculation is between Equation <ref type="formula" target="#formula_19">26</ref> and Equation 27. We suppose our batch size as B, sequence count as N , output dimensions of MLP layers as d, the count of spans for calculating cross span representations as m, and label count as R (including None class). The shapes of tensors</p><formula xml:id="formula_21">[h i ], [h j ], [h k ] are B ? N ? d. The shape of tensor [h i,j,r ] is B ? N ? N ? R ? d.</formula><p>We benchmark the performances of Equation 26 and Equation 27 in PyTorch for 10 iterations. We use the same hyper-parameters and devices as our main experiments. We levearge opt_einsum 6 to calculate triaffine transformations in both equations. <ref type="table">Table 9</ref> shows the time usage comparison between Equation 26 and Equation 27. Equation 26 uses 309.7ms (300.5ms in GPU + 9.2ms in CPU) and Equation 27 uses 150.1ms (145.6ms in GPU + 4.4ms in CPU). The larger tensor size and higher rank of [h i,j,r ] results in slower calculations of aten::bmm, aten::copy_ and aten::permute in Equation 26. The time usage differences are clearly dominated by the function aten::copy_, which is optimized by our decomposition.</p><p>We also compare the time usage between the naive triaffine scoring and the decomposed triaffine 6 https://github.com/dgasmith/opt_ einsum scoring in <ref type="table">Table 9</ref>. The naive triaffine scoring takes 638.1ms (509.4ms in GPU + 128.7ms in CPU), and the decomposed triaffine scoring takes 432.7ms (330.5ms in GPU + 102.2ms in CPU) for 10 iterations, which leads to approximately 32% speedup. The GPU time usages are reasonable since they both need to calculate two triaffine transformations. The CPU time usages increase for both naive and decomposition triaffine scoring. Additional CPU time usages come from function aten::einsum, aten::permute, and aten::reshape, and the naive calculation increases more due to slower aten::einsum. Overall, the decomposition triaffine scoring uses less time on both GPU and CPU than the naive triaffine scoring.</p><p>Futhermore, we also test the time usage of p c i,j,r using two calculation procedures. We find using the decomposition triaffine scoring still has about 6% speed up  <ref type="table">Table 9</ref>: Time usage compared with naive triaffine scoring and decomposed triaffine scoring.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>*Figure 1 :</head><label>1</label><figDesc>Work done at Alibaba DAMO Academy. a defective NF -chi B site was completely inactive in EBV -transformed B cells , ? An example sentence with nested entities from the GENIA dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Ju et al. (2018); Shen et al. (2021); Tan et al. (2021) to encode the text. For text</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>The architecture of our method. Green cubes indicate triaffine attention. Blue cubes indicate triaffine scoring. Orange arrows mean boundary information. Blue arrows mean inside tokens or related spans information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 :</head><label>3</label><figDesc>Visualization of triaffine attention, triaffine scoring, and the decomposition of triaffine scoring.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 :</head><label>5</label><figDesc>Recall for entity spans and F 1 scores with different numbers of candidate spans in GENIA dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>datasets.</figDesc><table /><note>3 https://catalog.ldc.upenn.edu/ LDC2005T094 https://catalog.ldc.upenn.edu/ LDC2006T065 https://catalog.ldc.upenn.edu/ LDC2019T12</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Statistics of nested NER datasets ACE2004, ACE2005, GENIA, and KBP2017.</figDesc><table><row><cell>Model + Encoder</cell><cell></cell><cell>ACE2004</cell><cell></cell><cell></cell><cell>ACE2005</cell><cell></cell><cell></cell><cell>GENIA</cell><cell></cell></row><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>Span-based Methods</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DYGIE (Luan et al., 2019) + LSTM</cell><cell>-</cell><cell>-</cell><cell>84.7</cell><cell>-</cell><cell>-</cell><cell>82.9</cell><cell>-</cell><cell>-</cell><cell>76.2</cell></row><row><cell>MGNER (Xia et al., 2019) + ELMo</cell><cell>81.7</cell><cell>77.4</cell><cell>79.5</cell><cell>79.0</cell><cell>77.3</cell><cell>78.2</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>BENSC (Tan et al., 2020)</cell><cell>85.8</cell><cell>84.8</cell><cell>85.3</cell><cell>83.8</cell><cell>83.9</cell><cell>83.9</cell><cell>79.2</cell><cell>77.4</cell><cell>78.3</cell></row><row><cell>TreeCRF (Fu et al., 2021)</cell><cell>86.7</cell><cell>86.5</cell><cell>86.6</cell><cell>84.5</cell><cell>86.4</cell><cell>85.4</cell><cell>78.2</cell><cell>78.2</cell><cell>78.2</cell></row><row><cell>Biaffine (Yu et al., 2020)</cell><cell>87.3</cell><cell>86.0</cell><cell>86.7</cell><cell>85.2</cell><cell>85.6</cell><cell>85.4</cell><cell>81.8</cell><cell>79.3</cell><cell>80.5</cell></row><row><cell>Pyramid (Wang et al., 2020)</cell><cell cols="9">86.08 86.48 86.28 83.95 85.39 84.66 79.45 78.94 79.19</cell></row><row><cell cols="10">Pyramid (Wang et al., 2020) + ALBERT 87.71 87.78 87.74 85.30 87.40 86.34 80.33 78.31 79.31</cell></row><row><cell>Others</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>SH (Wang and Lu, 2018) + LSTM</cell><cell>78.0</cell><cell>72.4</cell><cell>75.1</cell><cell>76.8</cell><cell>72.3</cell><cell>74.5</cell><cell>77.0</cell><cell>73.3</cell><cell>75.1</cell></row><row><cell>ARN (Lin et al., 2019) + LSTM</cell><cell>76.2</cell><cell>73.6</cell><cell>74.9</cell><cell>75.8</cell><cell>73.9</cell><cell>74.8</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>BiFlag (Luo and Zhao, 2020) + LSTM</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>75.0</cell><cell>75.2</cell><cell>75.1</cell><cell>77.4</cell><cell>74.6</cell><cell>76.0</cell></row><row><cell>Merge Label (Fisher and Vlachos, 2019)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>82.7</cell><cell>82.1</cell><cell>82.4</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Seq2seq (Strakov? et al., 2019)</cell><cell>-</cell><cell>-</cell><cell>84.40</cell><cell>-</cell><cell>-</cell><cell>84.33</cell><cell>-</cell><cell>-</cell><cell>78.31</cell></row><row><cell>Second-best (Shibuya and Hovy, 2020)</cell><cell cols="9">85.94 85.69 85.82 83.83 84.87 84.34 77.81 76.94 77.36</cell></row><row><cell>BartNER (Yan et al., 2021) + BART</cell><cell cols="9">87.27 86.41 86.84 83.16 86.38 84.74 78.87 79.60 79.23</cell></row><row><cell>Sequence to Set (Tan et al., 2021)</cell><cell cols="9">88.46 86.10 87.26 87.48 86.63 87.05 82.31 78.66 80.44</cell></row><row><cell>Locate and Label (Shen et al., 2021)</cell><cell cols="9">87.44 87.38 87.41 86.09 87.27 86.67 80.19 80.89 80.54</cell></row><row><cell>Triaffine (Ours)</cell><cell cols="9">87.13 87.68 87.40 86.70 86.94 86.82 80.42 82.06 81.23</cell></row><row><cell>Triaffine (Ours) + ALBERT</cell><cell cols="6">88.88 88.24 88.56 87.39 90.31 88.83</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>Results on the ACE2004, ACE2005, and GENIA datasets. BERT is the default encoder if not specified.</figDesc><table><row><cell>Model + Encoder</cell><cell></cell><cell>KBP2017</cell><cell></cell></row><row><cell></cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell>ARN + LSTM</cell><cell>77.7</cell><cell>71.8</cell><cell>74.6</cell></row><row><cell>BiFlag + LSTM</cell><cell>77.1</cell><cell>74.3</cell><cell>75.6</cell></row><row><cell>Sequence to Set</cell><cell cols="3">84.91 83.04 83.96</cell></row><row><cell>Locate and Label</cell><cell cols="3">85.46 82.67 84.05</cell></row><row><cell>Triaffine (Ours)</cell><cell cols="3">86.50 83.65 85.05</cell></row><row><cell cols="4">Triaffine (Ours) + ALBERT 89.42 85.22 87.27</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Results on the KBP2017 dataset. BERT is the default encoder if not specified. et al., 2020a) since they use additional resources as queries. DYGIE++</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>Ablation tests on ACE2004 development set and GENIA test set. Cross means using cross attention for span classification. Lin. means linear transformation, bi. means biaffine transformation, and tri. means triaffine transformation.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Cisco]ORG's been slammed, but once [they]ORG're exposed to [the rest of [the trading population]PER]PER ...</figDesc><table><row><cell></cell><cell></cell><cell>pi,j,r</cell><cell></cell><cell></cell><cell>p c i,j,r</cell></row><row><cell>Span</cell><cell>Type</cell><cell cols="2">Probability Rank</cell><cell>Type</cell><cell>Probability</cell></row><row><cell>... [Cisco</cell><cell>ORG</cell><cell>1.00</cell><cell>1</cell><cell>ORG</cell><cell>1.00</cell></row><row><cell>they</cell><cell>ORG</cell><cell>1.00</cell><cell>2</cell><cell>ORG</cell><cell>1.00</cell></row><row><cell>the rest of the trading population</cell><cell>PER</cell><cell>1.00</cell><cell>3</cell><cell>PER</cell><cell>1.00</cell></row><row><cell>the trading population</cell><cell>GPE</cell><cell>0.50</cell><cell>4</cell><cell>PER</cell><cell>0.68</cell></row><row><cell>population</cell><cell>None</cell><cell>1.00</cell><cell>5</cell><cell>None</cell><cell>1.00</cell></row><row><cell cols="6">... simian virus 40 enhancer activity was blocked by the [MnlI-AluI fragment]DNA in [HeLa cells]cl but not in [B cells]ct.</cell></row><row><cell>HeLa cells</cell><cell>cell line</cell><cell>0.99</cell><cell>1</cell><cell>cell line</cell><cell>0.99</cell></row><row><cell>B cells</cell><cell>cell type</cell><cell>0.97</cell><cell>2</cell><cell>cell type</cell><cell>0.88</cell></row><row><cell>MnlI-AluI fragment</cell><cell>DNA</cell><cell>0.96</cell><cell>3</cell><cell>DNA</cell><cell>0.95</cell></row><row><cell>simian virus 40 enhancer</cell><cell>DNA</cell><cell>0.90</cell><cell>4</cell><cell>DNA</cell><cell>0.89</cell></row><row><cell>MnlI-AluI</cell><cell>protein</cell><cell>0.43</cell><cell>5</cell><cell>None</cell><cell>0.41</cell></row><row><cell>40 enhancer</cell><cell>None</cell><cell>0.99</cell><cell>6</cell><cell>None</cell><cell>1.00</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>Case study on ACE2004 and GENIA dataset. Colored brackets indicate the boundaries and semantic types of entities in true labels. "cl" and "ct" is the abbreviation of cell line and cell type, respectively.</figDesc><table><row><cell cols="5">Figure 4: Comparison between triaffine and biaffine</cell></row><row><cell cols="5">models on GENIA with different lengths of entities.</cell></row><row><cell cols="4">Entity counts are in the parentheses.</cell><cell></cell></row><row><cell></cell><cell cols="2">ACE2004</cell><cell cols="2">GENIA</cell></row><row><cell></cell><cell>Flat</cell><cell>Nested</cell><cell>Flat</cell><cell>Nested</cell></row><row><cell></cell><cell cols="4">(1,422) (1,092) (4,307) (1,199)</cell></row><row><cell>(a)</cell><cell>88.51</cell><cell>84.19</cell><cell>80.09</cell><cell>74.23</cell></row><row><cell>(h)</cell><cell>89.54</cell><cell>85.45</cell><cell>82.18</cell><cell>77.24</cell></row><row><cell>?</cell><cell>+1.03</cell><cell>+1.26</cell><cell>+2.09</cell><cell>+ 3.01</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Comparison between triaffine and biaffine models on ACE2004 and GENIA grouped by flat or nested entities. Entity counts are in the parentheses.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7 :</head><label>7</label><figDesc>Hyper-parameters for using BERT encoder.</figDesc><table><row><cell>Parameters</cell><cell cols="3">ACE04 ACE05 KBP17</cell></row><row><cell>Epoch</cell><cell>10</cell><cell>10</cell><cell>10</cell></row><row><cell>PLM lr</cell><cell>1e-5</cell><cell>1e-5</cell><cell>3e-5</cell></row><row><cell>Static emb. lr</cell><cell>1e-4</cell><cell>1e-4</cell><cell>5e-4</cell></row><row><cell>Task lr</cell><cell>1e-5</cell><cell>1e-5</cell><cell>3e-5</cell></row><row><cell>?</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>Batch size</cell><cell>8</cell><cell>8</cell><cell>72</cell></row><row><cell>d</cell><cell>256</cell><cell>256</cell><cell>256</cell></row><row><cell>m</cell><cell>30</cell><cell>30</cell><cell>30</cell></row><row><cell>Adam</cell><cell>1e-8</cell><cell>1e-8</cell><cell>1e-8</cell></row><row><cell>Warmup ratio</cell><cell>0.0</cell><cell>0.0</cell><cell>0.0</cell></row><row><cell>Emb. dropout</cell><cell>0.2</cell><cell>0.2</cell><cell>0.2</cell></row><row><cell>MLP dropout</cell><cell>0.1</cell><cell>0.1</cell><cell>0.2</cell></row><row><cell>Weight decay</cell><cell>0.01</cell><cell>0.01</cell><cell>0.01</cell></row><row><cell>Clipping grad</cell><cell>0.1</cell><cell>0.1</cell><cell>0.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 8 :</head><label>8</label><figDesc>Hyper-parameters for using ALBERT encoder.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>(naive:125.8ms in GPU + 15.0ms in CPU vs. decomposition:115.5ms in GPU + 16.8ms in CPU) regardless the relatively small size of h c i,j,r (The shape of tensor [h c i,j,r ] is B ? m ? R ? d).</figDesc><table><row><cell>Method</cell><cell>Function</cell><cell cols="2">CPU Time</cell><cell cols="2">GPU Time</cell></row><row><cell></cell><cell></cell><cell>Usage</cell><cell>Percentage</cell><cell>Usage</cell><cell>Percentage</cell></row><row><cell cols="2">Equation 26 aten::copy_</cell><cell>0.5ms</cell><cell>5.9%</cell><cell>223.7ms</cell><cell>74.5%</cell></row><row><cell></cell><cell>aten::bmm</cell><cell>0.5ms</cell><cell>5.0%</cell><cell>38.2ms</cell><cell>12.7%</cell></row><row><cell></cell><cell>aten::mm</cell><cell>1.5ms</cell><cell>15.7%</cell><cell>37.1ms</cell><cell>12.3%</cell></row><row><cell></cell><cell>Total</cell><cell>9.2ms</cell><cell>100.0%</cell><cell>300.5ms</cell><cell>100.0%</cell></row><row><cell cols="2">Equation 27 aten::copy_</cell><cell>0.2ms</cell><cell>4.7%</cell><cell>62.5ms</cell><cell>42.9%</cell></row><row><cell></cell><cell>aten::bmm</cell><cell>0.4ms</cell><cell>10.0%</cell><cell>47.4ms</cell><cell>32.6%</cell></row><row><cell></cell><cell>aten::mm</cell><cell>0.3ms</cell><cell>6.0%</cell><cell>34.4ms</cell><cell>23.7%</cell></row><row><cell></cell><cell>Total</cell><cell>4.4ms</cell><cell>100.0%</cell><cell>145.6ms</cell><cell>100.0%</cell></row><row><cell>Naive</cell><cell>aten::copy_</cell><cell>7.3ms</cell><cell>5.7%</cell><cell>302.3ms</cell><cell>59.3%</cell></row><row><cell></cell><cell>aten::bmm</cell><cell>1.2ms</cell><cell>0.9%</cell><cell>109.3ms</cell><cell>21.5%</cell></row><row><cell></cell><cell>aten::mm</cell><cell>1.7ms</cell><cell>1.4%</cell><cell>74.4ms</cell><cell>14.6%</cell></row><row><cell></cell><cell>aten::einsum</cell><cell>61.8ms</cell><cell>48.0%</cell><cell>1.1ms</cell><cell>0.2%</cell></row><row><cell></cell><cell>aten::permute</cell><cell>36.7ms</cell><cell>28.5%</cell><cell>0.8ms</cell><cell>0.2%</cell></row><row><cell></cell><cell>aten::reshape</cell><cell>1.3ms</cell><cell>3.1%</cell><cell>0.5ms</cell><cell>0.1%</cell></row><row><cell></cell><cell>Total</cell><cell>128.7ms</cell><cell>100.0%</cell><cell>509.4ms</cell><cell>100.0%</cell></row><row><cell cols="2">Decompose aten::copy_</cell><cell>0.7ms</cell><cell>0.8%</cell><cell>136.7ms</cell><cell>41.4%</cell></row><row><cell></cell><cell>aten::bmm</cell><cell>1.2ms</cell><cell>1.2%</cell><cell>102.6ms</cell><cell>31.0%</cell></row><row><cell></cell><cell>aten::mm</cell><cell>5.4ms</cell><cell>5.3%</cell><cell>69.0ms</cell><cell>20.9%</cell></row><row><cell></cell><cell>aten::einsum</cell><cell>32.0ms</cell><cell>31.3%</cell><cell>1.1ms</cell><cell>0.3%</cell></row><row><cell></cell><cell>aten::permute</cell><cell>15.4ms</cell><cell>15.1%</cell><cell>0.7ms</cell><cell>0.2%</cell></row><row><cell></cell><cell>aten::reshape</cell><cell>37.4ms</cell><cell>36.6%</cell><cell>0.5ms</cell><cell>0.2%</cell></row><row><cell></cell><cell>Total</cell><cell>102.2ms</cell><cell>100.0%</cell><cell>330.5ms</cell><cell>100.0%</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Codes and models are available at https://github. com/GanjinZero/Triaffine-nested-ner.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank the anonymous reviewers for their helpful comments and suggestions. We thank Yao Fu, Yongliang Shen, Shengxuan Luo, Hongyi Yuan, Zhengyun Zhao, Xu Chen, and Jiayu Li for their help. This work was supported by Alibaba Group through Alibaba Research Intern Program.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Recognising nested named entities in biomedical text</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Beatrice</forename><surname>Alex</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Grover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Biological, translational, and clinical language processing</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="65" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Enriching word vectors with subword information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="DOI">10.1162/tacl_a_00051</idno>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Long and Short Papers</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The automatic content extraction (ace) program-tasks, data, and evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexis</forename><surname>George R Doddington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Przybocki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lance</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephanie</forename><forename type="middle">M</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><forename type="middle">M</forename><surname>Strassel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Lrec</title>
		<meeting><address><addrLine>Lisbon</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="837" to="840" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Deep biaffine attention for neural dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Dozat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Toulon, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-04-24" />
		</imprint>
	</monogr>
	<note>Conference Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Rose</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2009 conference on empirical methods in natural language processing</title>
		<meeting>the 2009 conference on empirical methods in natural language processing</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Merge and label: A novel neural network architecture for nested NER</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Vlachos</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1585</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5840" to="5850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Nested named entity recognition with partially-observed treecrfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosha</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songfang</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="12839" to="12847" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Overview of tac-kbp2017 13 languages entity discovery and linking. Theory and Applications of Categories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoman</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boliang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joel</forename><surname>Nothman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cash</forename><surname>Costello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A neural layered model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meizhi</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Makoto</forename><surname>Miwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sophia</forename><surname>Ananiadou</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1131</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>New Orleans, Louisiana</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1446" to="1459" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Nested named entity recognition revisited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Long Papers</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="861" to="871" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Genia corpus-a semantically annotated corpus for bio-textmining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J-D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomoko</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuka</forename><surname>Tateisi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun&amp;apos;ichi</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">suppl_1</biblScope>
			<biblScope unit="page" from="180" to="182" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Neural architectures for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N16-1030</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">ALBERT: A lite BERT for self-supervised learning of language representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenzhong</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingda</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piyush</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Soricut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04-26" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhyuk</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wonjin</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungdong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghyeon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sunkyu</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chan</forename><surname>Ho So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaewoo</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A unified MRC framework for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoya</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingrong</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxian</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinghong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwei</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.519</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5849" to="5859" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dependency or span, end-to-end uniform semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shexia</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuosheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="6730" to="6737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">High-order semantic role labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuchao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Parnow</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.findings-emnlp.102</idno>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: EMNLP 2020</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1134" to="1151" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequence-to-nuggets: Nested entity mention detection via anchor-region networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaojie</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianpei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1511</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5182" to="5192" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Decoupled weight decay regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-05-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Joint mention extraction and classification with mention hypergraphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="857" to="867" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">A general framework for information extraction using dynamic span graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dave</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luheng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mari</forename><surname>Ostendorf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1308</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3036" to="3046" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bipartite flat-graph network for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hai</forename><surname>Zhao</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.571</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6408" to="6418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Locate and label: A two-stage identifier for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongliang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Nested named entity recognition via second-best sequence learning and decoding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takashi</forename><surname>Shibuya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="605" to="620" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Neural architectures for nested NER through linearization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jana</forename><surname>Strakov?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milan</forename><surname>Straka</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1527</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5326" to="5331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Boundary enhanced neural span classification for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mosha</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="9016" to="9023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">A sequence-to-set network for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeqi</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongliang</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yueting</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 30th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 30th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">21</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Entity, relation, and event extraction with contextualized span representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Wadden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ulme</forename><surname>Wennberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hannaneh</forename><surname>Hajishirzi</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1585</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5784" to="5789" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Neural segmental hypergraphs for overlapping mention recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1019</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="204" to="214" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">A neural transition-based model for nested mention recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bailin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongxia</forename><surname>Jin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-1124</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1011" to="1017" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Pyramid: A layered model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lidan</forename><surname>Shou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="5918" to="5928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Second-order semantic dependency parsing with end-to-end neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingxian</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kewei</forename><surname>Tu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1454</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4609" to="4618" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multi-grained named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Congying</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenwei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xian</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fenglong</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1138</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1430" to="1440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A unified generative framework for various NER subtasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junqi</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qipeng</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xipeng</forename><surname>Qiu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2021.acl-long.451</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5808" to="5822" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Named entity recognition as dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juntao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernd</forename><surname>Bohnet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Massimo</forename><surname>Poesio</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.577</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6470" to="6476" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised multi-granular chinese word segmentation and term discovery via graph partition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiuyang</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobin</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sheng</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page">103542</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Enhancing hmm-based biomedical named entity recognition by studying special phenomena</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chew-Lim</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="411" to="422" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Biowordvec, improving biomedical word embeddings with subword information and mesh</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongfei</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Efficient second-order TreeCRF for neural dependency parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenghua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.302</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3295" to="3305" />
		</imprint>
	</monogr>
	<note>Online. Association for Computational Linguistics</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A boundary-aware neural model for nested named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Changmeng</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingyun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guandong</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A frustratingly easy approach for entity and relation extraction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zexuan</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danqi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">North American Association for Computational Linguistics (NAACL)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
