<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Invariant Risk Minimization Games</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kartik</forename><surname>Ahuja</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Thomas J. Watson Research Center</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthikeyan</forename><surname>Shanmugam</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Thomas J. Watson Research Center</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kush</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Thomas J. Watson Research Center</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amit</forename><surname>Dhurandhar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">IBM Research</orgName>
								<orgName type="institution" key="instit2">Thomas J. Watson Research Center</orgName>
								<address>
									<settlement>Yorktown Heights</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Invariant Risk Minimization Games</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T06:23+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The standard risk minimization paradigm of machine learning is brittle when operating in environments whose test distributions are different from the training distribution due to spurious correlations. Training on data from many environments and finding invariant predictors reduces the effect of spurious features by concentrating models on features that have a causal relationship with the outcome. In this work, we pose such invariant risk minimization as finding the Nash equilibrium of an ensemble game among several environments. By doing so, we develop a simple training algorithm that uses best response dynamics and, in our experiments, yields similar or better empirical accuracy with much lower variance than the challenging bi-level optimization problem of [1]. One key theoretical contribution is showing that the set of Nash equilibria for the proposed game are equivalent to the set of invariant predictors for any finite number of environments, even with nonlinear classifiers and transformations. As a result, our method also retains the generalization guarantees to a large set of environments shown in <ref type="bibr" target="#b0">[1]</ref>. The proposed algorithm adds to the collection of successful game-theoretic machine learning algorithms such as generative adversarial networks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The annals of machine learning are rife with embarrassing examples of spurious correlations that fail to hold outside a specific training (and identically distributed test) distribution. In <ref type="bibr" target="#b1">[2]</ref> the authors trained a convolutional neural network (CNN) to classify camels from cows. The training dataset had one source of bias, i.e., most of the pictures of cows had green pastures, while most pictures of camels were in deserts. The CNN picked up the spurious correlation, i.e., it associated green pastures with cows and failed to classify pictures of cows on sandy beaches correctly. In another case, a neural network used a brake light indicator to continue applying brakes, which was a spurious correlation in the training data <ref type="bibr" target="#b2">[3]</ref>; the list of such examples goes on.</p><p>To address the problem of models inheriting spurious correlations, the authors in <ref type="bibr" target="#b0">[1]</ref> show that one can exploit the varying degrees of spurious correlation naturally present in data collected from multiple data sources to learn robust predictors. The authors propose to find a representation ? such that the optimal classifier given ? is invariant across training environments. This formulation leads to a challenging bi-level optimization, which the authors relax by fixing a simple linear classifier and learning a representation ? such that the classifier is "approximately locally optimal" in all the training environments.</p><p>In this work, we take a very different approach. We create an ensemble of classifiers with each environment controlling one component of the ensemble. Each environment uses the entire ensemble to make predictions. We let all the environments play a game where each environment's action is to decide its contribution to the ensemble such that it minimizes its risk. Remarkably, we establish that the set of predictors that solve the ensemble game is equal to the set of invariant predictors across the training environments; this result holds for a large class of non-linear classifiers.</p><p>This brings us to the question: how do we solve the game? We use classic best response dynamics <ref type="bibr" target="#b3">[4]</ref>, which has a very simple implementation. Each environment periodically takes its turn and moves its classifier in the direction that minimizes the risk specific to its environment. Empirically, we establish that the invariant predictors found by our approach lead to better or comparable performance with much lower standard deviation than <ref type="bibr" target="#b0">[1]</ref> on several different datasets. A nice consequence of our approach is we do not restrict classifiers to be linear, which was emphasized as an important direction for future work by <ref type="bibr" target="#b0">[1]</ref>.</p><p>Broadly speaking, we believe that the game-theoretic perspective herein can open up a totally new paradigm to address the problem of invariance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Invariance Principles in Causality</head><p>The invariant risk minimization formulation of <ref type="bibr" target="#b0">[1]</ref> is the most related work, and is motivated from the theory of causality and causal Bayesian networks (CBNs) <ref type="bibr" target="#b4">[5]</ref>. A variable y is caused by a set of non-spurious actual causal factors x Pa(y) if and only if in all environments where y has not been intervened on, the conditional probability P (y|x Pa(y) ) remains invariant. This is called the modularity condition <ref type="bibr" target="#b5">[6]</ref>. Related and similar notions are the independent causal mechanism principle <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref> and the invariant causal prediction principle <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11]</ref>. These principles imply that if all the environments (train and test) are modeled by interventions that do not affect the causal mechanism of target variable y, then a classifier conservatively trained on the transformation that involves the causal factors (?(x) = x Pa(y) ) to predict y is robust to unseen interventions.</p><p>In general, for finite sets of environments, there may be other invariant predictors. If one has information about the CBN structure, one can find invariant predictors that are maximally predictive using conditional independence tests and other graph-theoretic tools <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13]</ref>.</p><p>The above works select subsets of features, primarily using conditional independence tests, that make the optimal classifier trained on the selected features be invariant. In <ref type="bibr" target="#b0">[1]</ref> the authors give an optimization-based reformulation of this invariance that facilitates searching over transformations in a continuous space, making their work widely applicable in areas such as computer vision where the causal features are latent (see <ref type="figure" target="#fig_17">Figure 6</ref> in <ref type="bibr" target="#b0">[1]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Sample Reweighting, Domain Adaptation, and Robust Optimization</head><p>Statistical machine learning has dealt with the distribution shift between the training distribution and test distribution in a number of ways. Conventional approaches are sample weighting, domain adaptation, and robust optimization. Importance weighting or more generally sample weighting attempts to match test and train distributions by reweighting samples <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17]</ref>. It typically assumes that the probability of labels given all covariates does not shift, and in more general cases, requires access to test labels. Domain adaptation tries to find a representation ? whose distribution is invariant across source and target domains <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21]</ref>. Domain adaptation is known to have serious limitations even when the marginal distribution of labels shift across environments <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b22">23]</ref>. When only training data sources are given, robust optimization techniques find the worst case loss over all possible convex combinations of the training sources <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>. This assumes that the test distribution is within the convex hull of training distributions, which is not true in many settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Preliminaries</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Game Theory Concepts</head><p>We begin with some basic concepts from game theory <ref type="bibr" target="#b27">[28]</ref> that we will use. Let ? = (N, {S i } i?N , {u i } i?N ) be the tuple representing a standard normal form game, where N is the finite set of players. Player i ? N takes actions from a strategy set S i . The utility of player i is u i : S ? R, where we write the joint set S = ? i?N S i . The joint strategy of all the players is given as s ? S, the strategy of player i is s i and the strategy of the rest of players is s ?i = (s i ) i =i . If the set S is finite, then we call the game ? a finite game. If the set S is uncountably infinite, then the game ? is a continuous game. Nash equilibrium in pure strategies. A strategy s * is said to be a pure strategy Nash equilibrium (NE) if it satisfies</p><formula xml:id="formula_0">u i (s * i , s * ?i ) ? u i (k, s * ?i ), ?k ? S i , ?i ? N</formula><p>We continue the discussion on other relevant concepts in game theory in the Appendix Section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Invariant Risk Minimization</head><p>We describe the invariant risk minimization (IRM) of <ref type="bibr" target="#b0">[1]</ref>. Consider datasets {(x e i , y e i )} ne i=1 from multiple training environments e ? E tr . The feature value x e i ? X and the corresponding labels</p><formula xml:id="formula_1">y e i ? Y, where X ? R n and Y ? R k . 1 Define a predictor f : X ? R k .</formula><p>The goal of IRM is to use these multiple datasets to construct a predictor f that performs well across many unseen environments E all . Define the risk achieved by f in environment e as R e (f ) = E X e ,Y e (f (X e ), Y e ) , where is the loss when f (X) is the predicted value and Y is the corresponding label. To assume that f maps to real values is not restrictive; for instance, in a k-class classification problem, the output of the function f is the score for each class, which can be converted into a hard label by selecting the class with the highest score.</p><p>Invariant predictor: We say that a data representation ? : X ? Z ? R d elicits an invariant predictor w ? ? across environments e ? E if there is a classifier w : Z ? R k that achieves the minimum risk for all the environments w ? arg minw ?Hw R e (w ? ?). The set of all the mappings ? is given as H ? and the set of all the classifiers is given as H w . IRM may be phrased as the following constrained optimization problem <ref type="bibr" target="#b0">[1]</ref>:</p><formula xml:id="formula_2">min ??H?,w?Hw e?Etr R e (w ? ?) s.t. w ? arg min w?Hw R e (w ? ?), ?e ? E tr .<label>(1)</label></formula><p>If (?, w) satisfies the above constraints, then w ? ? is an invariant predictor across the environments E tr . Define the set of representations and the corresponding classifiers, (?, w) that satisfy the constraints in the above optimization problem (1) as S IV , where IV stands for invariant. Also, separately define the set of invariant predictors</p><formula xml:id="formula_3">w ? ? as? IV = {w ? ? |(?, w) ? S IV }.</formula><p>Remark. The sets S IV ,? IV depend on the choice of classifier class H w and representation class H ? . We avoid making this dependence explicit until later sections.</p><p>Members of S IV are equivalently expressed as the solutions to</p><formula xml:id="formula_4">R e (w ? ?) ? R e (w ? ?), ?w ? H w , ?e ? E tr .<label>(2)</label></formula><p>The main result of <ref type="bibr" target="#b0">[1]</ref> states that if H w and H ? are from the class of linear models, i.e., w(z) = w t z, where w ? R d , and ?(x) = ?x with ? ? R d?n , then under certain conditions on the data generation process and training environments E tr , the solution to (2) remains invariant in E all .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Ensemble Invariant Risk Minimization Games</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Game-Theoretic Reformulation</head><p>Optimization problem (1) can be quite challenging to solve. We introduce an alternate characterization based on game theory to solve it. We endow each environment with its own classifier w e ? H w . We use a simple ensemble to construct an overall classifier w av : . These scores are input to a softmax; the final probability assigned to class j for an input z is e w av j (z) e w av 1 (z) +e w av 2 (z) . We require all the environments to use this ensemble w av . We want to solve the following new optimization problem.</p><formula xml:id="formula_5">Z ? R k defined as w av = 1 |Etr| |Etr| q=1 w q , where for each z ? Z, w av (z) = 1 |Etr| |Etr| q=1 w q (z</formula><formula xml:id="formula_6">min ??H?,w av ?Hw e?Etr R e (w av ? ?) s.t. w e ? arg min w e ?Hw R e ? ? 1 |E tr | w e + q =e w q ? ? ? ? , ?e ? E tr</formula><p>We can equivalently restate the above as:</p><formula xml:id="formula_7">min ??H?,w av e?Etr R e (w av ? ?) s.t. R e ? ? 1 |E tr | w e + q =e w q ? ? ? ? ? R e ? ? 1 |E tr | w e + q =e w q ? ? ? ? ?w e ? H w ?e ? E tr<label>(3)</label></formula><p>What are the advantages of this formulation (3)?</p><p>? Using the ensemble automatically enforces invariance across environments.</p><p>? Each environment is free to select the classifier w e from the entire set H w , unlike in (1), where all environments' choices are required to be the same. ? The constraints in (3) are equivalent to the set of pure NE of a game that we define next. The game is played between |E tr | players, with each player corresponding to an environment e. The set of actions of the environment e are w e ? H w . At the start of the game, a representation ? is selected from the set H ? , which is observed by all the environments. The utility function for an environment e is defined as u e [w e , w ?e , ?] = ?R e (w av , ?), where w ?e = {w q } q =e is the set of choices of all environments but e. We call this game Ensemble Invariant Risk Minimization (EIRM) and express it as a tuple</p><formula xml:id="formula_8">? EIRM = E tr , H ? , {H w } |Etr| q=1 , {u e } e?Etr .</formula><p>We represent a pure NE as a tuple ?, {w q } |Etr| q=1 . Since each pure NE depends on ?, we include it as a part of the tuple. <ref type="bibr" target="#b1">2</ref> We define the set of pure NE as S EIRM . We construct a set of all the ensemble predictors constructed from NE as 3?</p><formula xml:id="formula_9">EIRM = 1 |E tr | |Etr| q=1 w q ? ? | (?, {w q } |Et| q=1 ) ? S EIRM .</formula><p>Members of S EIRM are equivalently expressed as the solutions to</p><formula xml:id="formula_10">u e [w e , w ?e , ?] ? u e [w e , w ?e , ?], ?w e ? H w , ?e ? E tr .<label>(4)</label></formula><p>If we replace u e [w e , w ?e , ?] with ?R e (w av , ?), we obtain the inequalities in (3). So far we have defined the game and given its relationship to the problem in (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Equivalence Between NE and Invariant Predictors</head><p>What is the relationship between the predictors obtained from NE? EIRM and invariant predictors? IV ? Remarkably, these two sets are the same under very mild conditions. Before we show this result, we establish a stronger result and this result will follow from it.</p><p>We use the set S EIRM to construct a new set. To each tuple ?, {w q } |Etr| q=1 ) ? S EIRM augment the ensemble classifier w av = 1 |Etr| |Etr| q=1 w q to get ?, {w q } |Etr| q=1 , w av . We call the set of these new tuplesS EIRM .</p><p>We use the set S IV to construct a new set. Consider an element (?, w) ? S IV . We define a decomposition for w in terms of the environment-specific classifiers as follows: w = 1 |Etr| |Etr| q=1 w q , where w q ? H w . w q = w, ?q ? E tr is one trivial decomposition. We use each such decomposition and augment the tuple to obtain ?, {w q } |Etr| q=1 , w . We call this set of new tuplesS IV . Both the setsS IV andS EIRM consist of tuples of representation, set of environment specific classifiers, and the ensemble classifier. We ask an even more interesting question than the one above. Is the set of representations, environment specific classifiers, and the ensembles found by playing EIRM (4) or solving IRM (2) the same? If these two sets are equal, then equality between? EIRM and S IV follows trivially.</p><p>We state the only assumption we need.</p><p>Assumption 1. Affine closure: The class of functions H w is closed under the following operations.</p><p>? Finite sum: If w 1 ? H w and w 2 ? H w , then</p><formula xml:id="formula_11">w 1 + w 2 ? H w , where for every z ? Z, (w 1 + w 2 )(z) = w 1 (z) + w 2 (z) ? Scalar multiplication: For any c ? R and w ? H w , cw ? H w , where for every z ? Z, (cw)(z) = c ? w(z)</formula><p>The addition of the functions and scalar multiplication are defined in a standard pointwise manner. Therefore, the class H w also forms a vector space.</p><p>Examples of functions that satisfy affine closure. Linear classifiers, kernel based classifiers <ref type="bibr" target="#b28">[29]</ref> (functions in RKHS space), ensemble models with arbitrary number of weak learners <ref type="bibr" target="#b29">[30]</ref>, functions in L p space <ref type="bibr" target="#b30">[31]</ref>, ReLU networks with arbitrary depth. We provide the justification for each of these functions in the Appendix Section. We now state the main result.  ? From a computational standpoint, this equivalence permits tools from game theory to find NE of the EIRM game and, as a result, the invariant predictors. ? From a theoretical standpoint, this equivalence permits to use game theory to analyze the solutions of the EIRM game and understand the invariant predictors. ? In Theorem 9 of <ref type="bibr" target="#b0">[1]</ref>, it was shown for linear classifiers and linear representations that the invariant predictors generalize to a large set of unseen environments under certain conditions. Since our result holds for linear classifiers (but is even broader), the generalization result continues to hold for the predictors found by playing the EIRM game. Role of representation ?. We investigate the scenario when we fix ? to the identity mapping; this will motivate one of our approaches. Define the set S EIRM (?) as the set of ensemble predictors arrived at by playing the EIRM game using a fixed representation representation ?. <ref type="bibr" target="#b3">4</ref> Similarly, we define a set? IV (?) as the set of invariant predictors derived using the representation ?. From Theorem 1, it follows that? EIRM (?) =? IV (?). We modify some of the earlier notations for results to follow. The set of predictors that result from the EIRM game? EIRM and the sets of invariant predictors? IV are defined for a family of maps ? with co-domain Z. We make the co-domain Z explicit in the notation. We write? EIRM Z for? EIRM and? IV Z for? IV .</p><formula xml:id="formula_12">4 ? ?? EIRM (?) =? EIRM Assumption 2. ? ? H ? satisfies the following ? Bijective: ? ? ?1 : Z ? X such that ?x ? X , ? ?1 ? ? (x) = x, and ?z ? Z ? ? ? ?1 (z) = z.</formula><p>Both X and Z are subsets of R n ? ? is differentiable and Lipschitz continuous.</p><p>We define L p (Z) as the set of functions f :</p><formula xml:id="formula_13">Z ? R s.t. Z |f | p d? &lt; ? Assumption 3. H w = L p (Z).</formula><p>Define a subsetS IV Z ?? IV Z consisting of invariant predictors that are in L p (X ), i.e.,S IV Z = {u | u ?? IV Z and u ? L p (X )}. Let ? = I, where I : X ? X is the identity mapping. Following the above notation, the set of invariant predictors and the set of ensemble predictors obtained from NE are? IV X (I) and? EIRM X (I) respectively.</p><p>Theorem 2. If Assumptions 2 and 3 are satisfied andS IV Z is non-empty, then</p><formula xml:id="formula_14">S IV Z =? IV X (I) =? EIRM X (I)</formula><p>Significance of Theorem 2. If we fix the representation to identity and play the EIRM game, then it is sufficient to recover all the invariant predictors (with bounded L p norm) that can be obtained using all the representations ? ? H ? . Therefore, we can simply fix ? = I and use game-theoretic algorithms for learning equilibria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Existence of NE of ? EIRM and Invariant Predictors</head><p>In this section, we first argue that there are many settings when both invariant predictors and the NE exist.</p><p>Illustration through generative models. We use a simplified version of the model described by <ref type="bibr" target="#b9">[10]</ref>. In each environment e, the random variable X e = [X e 1 , ..., X e n ] corresponds to the feature vector and Y e corresponds to the label. The data for each environment is generated by i.i.d. sampling (X e , Y e ) from the following generative model. Assume a subset S * ? {1, ..., n} is causal for the label Y e . For all the environments e, X e has an arbitrary distribution and Y e = g(X e S * ) + e where X e S * is the vector X e with indices in S * , g : R |S * | ? R is some underlying function and e ? F e , E[ e ] = 0, e ? X e S * . Let be the squared error loss function. We fix the representation ? * (X e ) = X e S * . With ? * as the representation, the optimal classifier w among all the functions is g(X e S * ) (this follows from the generative model). If we assume that g ? H w , then for each environment e, w e * = g is the optimal classifier in H w . Therefore, w e * ? ? * = g is the invariant predictor. If H w satisfies affine closure, then any decomposition of g is a pure NE of the EIRM game. We have illustrated existence of NE and invariant predictor when the data is generated as above and when the class H w is sufficiently expressive to capture g. Next, we discuss the case when we do not know anything about the underlying data generation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Assumption 4.</head><p>? H w is a class of linear models, where w : Z ? R and w(z) = w t z, where z ? Z. We write H w as the set of vectors w. H w is a closed, bounded and convex set. The interior of H w is non-empty.</p><p>? The loss function (w t z, Y ), where Y ? R is the label, is convex and continuous in w. For e.g., if loss is cross-entropy for binary classification or loss is mean squared error for regression, then this assumption is automatically satisfied.</p><p>Theorem 3. If Assumption 4 is satisfied, then a pure strategy Nash equilibrium of the game ? EIRM exists. If the weights of all the individual classifiers in the NE are in the interior of H w , then the corresponding ensemble predictor is an invariant predictor among all the linear models.</p><p>The family H w of bounded linear functions does not satisfy affine closure, which is why existence of NE does not immediately imply the existence of invariant predictor (from Theorem 1). However, if the solution is in the interior of H w , then it is the globally optimal solution among all the linear functions, which in fact actually satisfy affine closure. As a result, in this case the invariant predictor also exists.</p><p>Significance of Theorem 3 Our approach is based on finding the NE. Therefore, it is important to understand when the solutions are guaranteed to exist. In the above theorem, we proved the result for linear models only, but there were no assumptions made on the representation class. In the Appendix Section, we show that for a large class of models, pure NE may not exist but mixed NE (a relaxation of pure NE) are guaranteed to exist. Following the sufficient condition for existence of invariant predictors, understanding what conditions cause the NEs to be in the interior or on the boundary of H w can help further the theory of invariant prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Algorithms for Finding NE of ? EIRM</head><p>There are different strategies in the literature to compute the equilibrium, such as best response dynamics (BRD) and fictitious play <ref type="bibr" target="#b3">[4]</ref>, but none of these strategies are guaranteed to arrive at equilibria in continuous games except for special classes of games <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35]</ref>. BRD is one the most popular methods given its intuitive and natural structure. The training of GANs also follows an approximate BRD <ref type="bibr" target="#b35">[36]</ref>. BRD is not known to converge to equilibrium in GANs. Instead a modification of it proposed recently, <ref type="bibr" target="#b36">[37]</ref> achieves mixed NE. Our game ? EIRM is a non-zero sum game with continuous actions unlike GANs. Since there are no known techniques that are guaranteed to compute the equilibrium (pure or mixed) for these games, we adopt the classic BRD approach.</p><p>In our first approach, we use a fixed representation ?. Recall in Theorem 2, we showed how just fixing ? to identity can be a very effective approach. Hence, we can fix ? to be identity mapping or we can select ? as some other mapping such as approximation of the map for Gaussian kernel <ref type="bibr" target="#b37">[38]</ref>. Once we fix ?, the environments play according to best response dynamics as follows.</p><p>? Each environment takes its turn (in a periodic manner with each environment going once) and minimizes its respective objective. ? Repeat this procedure until a certain criterion is achieved, e.g., maximum number of epochs or desired value of training accuracy. The above approach does not give much room to optimize ?. We go back to the formulation in (3) and use the upper level optimization objective as a way to guide search for ?. In this new approach, ? is updated by the representation learner periodically using the objective in (3) and between two updates of ? the environments play according to best response dynamics as described above.</p><p>We now make assumptions on H w and H ? and give a detailed algorithm (see Algorithm 1) that we use in experiments. We assume that w e is parametrized by family of neural networks ? w ? ? w and ? is parametrized by family of neural networks ? ? ? ? ? . In the Algorithm 1, one of the variables Fixed-Phi (for our first approach) or Variable-Phi is set to true, and then accordingly ? remains fixed or is updated periodically. In <ref type="figure" target="#fig_0">Figure 1</ref>, we also show an illustration of the best response training when there are two environments and one representation learner.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Benchmarks</head><p>The most important benchmark for comparison is <ref type="bibr" target="#b0">[1]</ref>, which we refer to as IRM in the comparisons. We use the architecture described in their work (details in the Appendix Section). We also compare with</p><p>? Variants of empirical risk minimization: ERM on entire training data (ERM), ERM on each environment separately (ERM e refers to ERM trained on environment e), and ERM on data with no spurious correlations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Best Response Training</head><p>Input: Data for each environment and combined data</p><formula xml:id="formula_15">while iter ? iter max do if Fixed-Phi then ? cur = I end if if Variable-Phi then ? nxt = SGD e R e (w av cur ?? cur ) , SGD[.]: update using stochastic gradient descent ? cur = ? nxt end if for p ? {1, ..K} do for e ? {1, .., |E tr |} do w e nxt = SGD R e (w av cur ? ? cur ) w e cur = w e nxt end for iter = iter + 1 w av cur = 1 |Etr| e w e</formula><p>cur end for end while</p><p>? Robust min-max training: In this method, we minimize the maximum loss across the multiple environments. We have two approaches for EIRM games: one that uses a ? fixed to the identity and the other that uses a variable ?, which we refer to as the F-IRM and V-IRM game, respectively. The details on architectures, hyperparameters, and optimizers used for all the methods are in the Appendix Section. The source-code is available at https://github.com/IBM/IRM-games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Datasets</head><p>In <ref type="bibr" target="#b0">[1]</ref>, the comparisons were done on a colored digits MNIST dataset. We create the same dataset for our experiments. In addition, we also create two other datasets that are inspired from Colored MNIST: Colored Fashion MNIST and Colored Desprites. We also create another dataset: Structured Noise Fashion MNIST. In this dataset, instead of coloring the images to establish spurious correlations, we create small patches of noise at specific locations in the image, where the locations are correlated with the labels (detailed description of the datasets is in the Appendix Section). In all the comparisons, we averaged the performance of the different approaches over ten runs.</p><p>Colored MNIST <ref type="table" target="#tab_1">(Table 1</ref>) Standard ERM based approaches, and robust training based approach achieve between 10-15 percent accuracy on the testing set. F-IRM game achieves 59.9 ? 2.7 percent testing accuracy. This implies that the model is not using spurious correlation unlike the ERM based approaches,  and robust training based approach, that is present in the color of the digit. F-IRM has a comparable mean and a much lower standard deviation than IRM, which achieves 62.75 ? 9.5 percent. ERM grayscale is ERM on uncolored data, which is why it is better than all. Colored Fashion MNIST ( <ref type="table" target="#tab_2">Table 2</ref>) We observe that the V-IRM game performs the best both in terms of the mean and the standard deviation achieving 70.2 ? 1.5 percent.</p><p>Colored Desprites ( <ref type="table" target="#tab_3">Table 3</ref>) We observe that V-IRM game achieves 50.0 ? 0.2 percent while IRM achieves 51.8 ? 6 percent.</p><p>Structured Noise Fashion MNIST ( <ref type="table" target="#tab_4">Table 4</ref>) We observe that F-IRM achieves 62.0 ? 2.0 percent and is comparable with IRM that achievs 63.9 ? 10.9 percent; again observe that we have a lower standard deviation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Analyzing the Experiments</head><p>In this section, we use plots of F-IRM game played on Colored Fashion MNIST (plots for both F-IRM and V-IRM on all other datasets are similar and are in the Appendix Section). In <ref type="figure" target="#fig_4">Figure 2</ref>, we show the accuracy of the ensemble model on the entire data and the two environments separately. In the initial stages, the training accuracy increases and eventually it starts to oscillate. Best response dynamics can often oscillate <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b32">33]</ref>. Next, we demistify these oscillations and explain their importance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.1">Explaining the mechanism of oscillations</head><p>The oscillation has two states. In the first state, the ensemble model performs well 88 % accuracy. In the second state, the accuracy dips to 75 %. In <ref type="figure" target="#fig_5">Figure 3</ref>, we plot the correlation between the ensemble model and the color. When the oscillations appear in training accuracy in <ref type="figure" target="#fig_4">Figure 2</ref>, the correlation also start to   <ref type="figure" target="#fig_5">Figure 3</ref>. In the first state when the model performs well, the model is heavily correlated (negative correlation) with the color. In the second state, the model performs worse, observe that the model now has much less correlation (close to zero) with the color. We ask two questions: (i) Why do the oscillations persist in the training accuracy plot ( <ref type="figure" target="#fig_4">Figure 2</ref>) and correlation plot <ref type="figure" target="#fig_5">(Figure 3</ref>)?, and (ii) How do the oscillations emerge?</p><p>Why do the oscillations persist? In our experiments there are two environments, the labels are binary, and we want to maximize the log-likelihood. Let s j be the score vector from environment j's classifier, p be the softmax of s and? be the one hot encoded vector of labels. The gradient of the log-likelihood w.r.t. the scores given by each model for a certain instance x (see derivation in the Appendix Section) is:</p><formula xml:id="formula_16">? log(p y ) ?s j =? ? p =?.<label>(5)</label></formula><p>where? is the error vector. The error? is determined by the both the models (both models impact p), it backpropagates and impacts individual weights. We argue next that the examples over which error occur are very different in the  Consider the step when the correlation (absolute value) between the ensemble model and color is high. In this step, it is the turn of Model 1 to train. Observe that the accuracy of the model is high because the ensemble model is exploiting the spurious correlations with the color. We approximate this mathematically. The score from Model j for Label 1 is</p><formula xml:id="formula_17">s 1 j ?s 0 j ? ? t j ? nc j (x)+? j ? c j (x),</formula><p>where ? nc j are the features that are not correlated with the color, ? c j is the indicator of the color. From <ref type="figure" target="#fig_7">Figure 4</ref>, ? 1 and ? 2 should have opposite signs, i.e. positive and negative respectively. In the current step, ? 2 dominates ? 1 , which is why the ensemble model has a heavy negative correlation. The errors (5) that backpropagate come from the examples for which exploiting spurious correlation with color does not work, i.e., the color is not indicative of the digit. During this step Model 1 is trained, backpropagation will change the weights such that ? 1 increases. As a result, the ensemble model's correlation with the color decreases (as we see in <ref type="figure" target="#fig_5">Figure 3</ref>). In the next step, it is the turn of Model 2 to train. Model 2's environment has more examples than environment 1 where exploiting the color can help improve its accuracy. As a result, error from these examples backpropagate and ? 2 decreases. This brings the ensemble model back to being negatively correlated with colors and also the training accuracy back to where it was approximately. This cycle of push and pull between the models continues.</p><p>How do these cycles emerge? The oscillations are weak at the beginning of the training. In the beginning, when Model 2 trains, the impact of the errors (from examples where spurious correlations can be exploited) on changing the weights are much stronger than when Model 1 trains, as the number of examples that benefit from spurious correlations is much larger in comparison. As the training proceeds, this impact decreases as many examples are classified correctly by using spurious correlations while the weights continue to accumulate for Model 1, thus giving rise to oscillations.</p><p>How to terminate? We terminate training when the oscillations are stable and when the ensemble model is in the lower accuracy state, which corresponds to the state with lower correlation with color. To ensure the oscillations are stable, we do not terminate until a certain number of steps have been completed (in our experiments we set this duration to be number of steps= (training data size)/(batch size)). To capture the model in a state of lower correlation with color, we set a threshold on accuracy (we decide the threshold by observing the accuracy plot); we terminate only when the training accuracy falls below this threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We developed a new framework based on game-theoretic tools to learn invariant predictors. We work with data from multiple environments. In our framework, we set up an ensemble game; we construct an ensemble of classifiers with each environment controlling one portion of the ensemble. Remarkably, the set of solutions to this game is exactly the same as the set of invariant predictors across training environments. The proposed framework performs comparably to the existing framework of <ref type="bibr" target="#b0">[1]</ref> and also exhibits lower variance. We hope this framework opens new ways to address other problems pertaining to invariance in causal inference using tools from game theory. which is a vector spaces of functions. Therefore, kernel based classifiers <ref type="bibr" target="#b28">[29]</ref> satisfy affine closure. ? Ensemble models: Consider binary classification and boosting models <ref type="bibr" target="#b29">[30]</ref>. Let H weak be the set of weak learners ? : X ? R. The final function that is input to a sigmoid is w = k m=1 ? m ? m , where each ? m ? R. The set of functions spanned by the weak learners is defined as</p><formula xml:id="formula_18">Span(H weak ) = { k m=1 ? m ? m |?m ? {1, .., k}, ? m ? R, k ? N}. Span(H weak )</formula><p>forms a vector space. Therefore, ensemble models that may use arbitrary number of weak learners satisfy affine closure.</p><formula xml:id="formula_19">? L p spaces. The set of functions f : X ? R for which f p = [ X |f (x)| p dx] 1 p &lt; ? is defined as L p (X ). L p (X )</formula><p>is a vector space <ref type="bibr" target="#b30">[31]</ref>. ReLU networks with arbitrary depth: Neural networks are known to be universal function approximators. Let us assume X to be a compact subset of R n . The output of a ReLU network is a continuous function on X , which implies it is bounded and thus the function described by a ReLU network is in L 1 (X ) space. It is clear that the set of functions parametrized by ReLU networks are a subset of functions in L 1 (X ) space. In the other direction, from <ref type="bibr" target="#b39">[40]</ref>, we know that ReLU networks can come arbitrarily close to any function in L 1 sense. Since ReLU networks come arbitrarily close to the function and are not exactly equal we cannot argue that affine closure is satisfied. However, we argue later that since the networks can arbitrarily approximate any function in L 1 (X ) it is sufficient to prove our results (our main result Theorem 1 and Corollary 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Theorems and Proofs</head><p>In this section, we discuss the proofs to the lemmas, theorems, and corollaries in the paper. Theorem 1. If Assumption 1 holds, thenS IV =S EIRM Proof. In the first part, we want to show thatS IV ?S EIRM . We will use proof by contradiction.</p><p>Let us assume that there exists an element (?, {w q } |Etr| q=1 , w) ?S IV , which does not belong toS EIRM . This implies that there exists at least one e ? E tr in the ensemble game, which strictly prefers the actionw e ? H w to following its current action w e . In other words, at least one of the inequalities in <ref type="formula" target="#formula_7">(3)</ref> is not satisfied, which can be written as</p><formula xml:id="formula_20">R e w e + q =e w q |E tr | ? ? &lt; R e (w ? ?)<label>(6)</label></formula><p>The function w =w e + q =e w q |Etr| ? H w (From Assumption 1). Therefore, w is a strictly better classifier than w with a fixed representation ? for environment e, which contradicts the condition that w ? arg minw ?Hw R e (w ? ?) (which follows from (?, {w q } |Etr| q=1 , w) ?S IV ). This proves the first part. In the second part, we want to show thatS EIRM ?S IV . Let us assume that there exists an element (?, {w q } |Etr| q=1 , w) ?S EIRM , which does not belong toS IV . Following Assumption 1, w lies in H w . Since (?, {w q } |Etr| q=1 , w) ?S IV there exists at least one e ? E tr and a classifier w ? H w strictly better than w for a fixed representation ?. If this were not the case, w will be an invariant predictor w.r.t. ? across E tr , which would contradict (?, {w q } |Etr| q=1 , w) ?S IV . Therefore</p><formula xml:id="formula_21">R e (w ? ?) &lt; R e (w ? ?)<label>(7)</label></formula><p>Let us construct a new auxiliary classifierw e as follows.w e = w |E tr | ? q =e w q . It follows from Assumption 1 thatw e ? H w . Observe that the ensemble defined asw e + q =e w q |Etr| simplifies to w . This means that environment e can deviate from w e tow e ? H w and strictly gain from this deviation. This contradicts the fact that {w q }  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Extending Theorem 1 and Corollary 1 to ReLU networks</head><p>In the proof of Theorem 1, we used the affine closure property in <ref type="formula" target="#formula_20">(6)</ref> and <ref type="bibr" target="#b6">(7)</ref>. However, in <ref type="formula" target="#formula_20">(6)</ref> and <ref type="formula" target="#formula_21">(7)</ref>, we only need to construct models that can achieve risk arbitrarily close to the models in the LHS of equations (6) and <ref type="bibr" target="#b6">(7)</ref>. Let H w the set of functions of ReLU networks with arbitrary depth defined on compact sets X . These functions are in L 1 class as explained earlier. From <ref type="bibr" target="#b39">[40]</ref>, we can choose ReLU networks from H w that approximate the classifiers in the LHS of (6) and <ref type="formula" target="#formula_21">(7)</ref> arbitrarily. We elaborate on this. Suppose the function to be approximated in the LHS is f . From <ref type="bibr" target="#b39">[40]</ref>, for each &gt; 0, there exists a ReLU networkf such</p><formula xml:id="formula_22">that E X [|f ?f |] ? . The question is does E X [|f ?f |] ? also ensure that the difference in risks is mitigated |R e (f, Y ) ? R e (f , Y )| ?? .</formula><p>If the loss function is Lipschitz in the scores (e.g., cross-entropy loss, hinge loss), then if the functions are arbitrarily close the risks will also be arbitrarily close. We show this below.</p><formula xml:id="formula_23">|R e (f, Y ) ? R e (f , Y )| = |E e [ (f (X), Y ) ? (f (X), Y )]| ? E e [| (f (X), Y ) ? (f (X), Y )|] ? E e [L|f (X) ?f (X)|]<label>(8)</label></formula><p>where L is the Lipschitz constant for .</p><p>Below we illustrate an example of Lipschitz continuous loss . Consider cross entropy for binary classification (labels Y = 0 and Y = 1). Suppose f (x) = s is the score assigned to class 1, it is converted into probability as e s /(1 + e s ). The cross-entropy loss is simplified as </p><formula xml:id="formula_24">(s, Y ) = Y s ? log(1 + e s )<label>(9)</label></formula><formula xml:id="formula_25">Observe ? (s,Y ) ?s = Y ? 1 1+e s and | ? (s,Y ) ?s | ? 1. Therefore, (s, Y ) is Lispchitz continuous in s.</formula><formula xml:id="formula_26">? ? H ? , w ? ? ?1 ? L p (Z).</formula><p>Proof. To show w ?? ?1 ? L p (Z) let us first express the integral Z |w (? ?1 (z))| p dz by using substitution rules <ref type="bibr" target="#b40">[41]</ref>. We can use the substitution rule because both X and Z are n dimensional, the function ? is bijective, differentiable and Lipshitz continuous (From Asumption 2 and 3). Substitute z = ?(x). Then,</p><formula xml:id="formula_27">Z |w (? ?1 (z))| p dz = ? ?1 (Z) |w (x)| p det(J(?(x)))dx .</formula><p>Here J(?(x)) is the Jacobian of the transformation ?. Since ? is a Lipschitz continuous map, its determinant is also bounded. We show this as follows.</p><p>Lipschitz continuity implies that for any x, x ? X , ?(x)??(x ) ? ? x?x where ? is the Lipschitz constant. In particular, since ?(?) is differentiable (Assumption 2), this means that the length of any partial derivative vector ??(x) ?xi ? ? for any coordinate i ? [n]. Now, we apply the Hadamard inequality <ref type="bibr" target="#b41">[42]</ref> for the determinant of the square matrix J(?(x)):</p><formula xml:id="formula_28">det(J(?(x))) ? i?[n] ??(x) ?xi ? ? n . Therefore, Z |w (? ?1 (z))| p dz = ? ?1 (Z) |w (x)| p det(J(?(x)))dx ? ? n ? ?1 (Z) |w (x)| p dx ? ? n X |w (x)| p dx<label>(10)</label></formula><p>Since, w ? L p (X ) (Assumption 3) we have that w ? ? ?1 ? L p (Z) from the above inequality. Proof. In the first part, we want to show thatS IV Z ?? IV X (I). We will use proof by contradiction.</p><p>Suppose (w ? ?) ?S IV Z but not in? IV X (I). First note that w ? ? ? L p (X ) (From definition of the setS IV Z ). This implies that there must exist an environment e and a classifier w : X ? Y which is better than (w ? ?). Therefore, we can state that</p><formula xml:id="formula_29">R e (w ) &lt; R e (w ? ?)<label>(11)</label></formula><p>Define a classifierw = w ? ? ?1 . From Lemma 1 it followsw ? L p (Z). Define the risk achieved by this classifier as R e (w ? ?). We simplify this as follows.</p><formula xml:id="formula_30">R e (w ? ?) = R e ((w ? ? ?1 ) ? ?) = R e (w ? (? ?1 ? ?)) = R e (w ? I) = R e (w )<label>(12)</label></formula><p>Therefore, the risk ofw ? ? is better than the risk achieved by w ? ?. This contradicts that w ? ? is an invariant predictor. We show this as follows. Since w ? ? is an invariant predictor with ? as the representation it implies w ? arg minw R e (w ? ?). However,w is clearly better than w with ? as the representation <ref type="bibr" target="#b11">(12)</ref> , which leads to a contradiction. This proves the first part.</p><p>The second side? IV X (I) ?S IV Z . Suppose w ?? IV X (I) but not inS IV Z . Select any ? : X ? Z from the set of representations for which invariant predictors exist in the setS IV Z (recall that we assumedS IV Z is not empty). Define a predictor w = w ? ? ?1 . Since w ? L p (X ), from Lemma 1 we know thatw is in L p (Z). There should exist an environment e for whichw is not the optimal classifier given ? otherwise w will be in the setS IV Z , which would be a contradiction. ? is a representation for which an invariant predictor exists, let w be the classifier and w ? ? be the invariant predictor inS IV Z . ? an environment e for which w is strictly better thanw given ?. We write this condition as</p><formula xml:id="formula_31">R e (w ? ?) &lt; R e (w ? ?) = R e (w)<label>(13)</label></formula><p>w ? ? ?S IV Z and from the definition of the set it follows that w ? ? ? L p (X ). Also, w ? ? is better than w from <ref type="bibr" target="#b12">(13)</ref>. However, w is an invariant predictor with ? = I, which leads to contradiction.</p><p>From Theorem 2 it follows that? EIRM X (I) =? IV X (I). This completes the proof.</p><p>When ? = I, can the game recover the solution that focuses on causal parents? We will consider the following data generation process. The data for each environment is generated by i.i.d. sampling (X e , Y e ) from the following generative model. Assume a subset S * ? {1, ..., n} is causal for the label Y e . For all the environments e, X e has an arbitrary distribution and</p><formula xml:id="formula_32">Y e ? g(X e S * ) + e</formula><p>where X e S * is the vector X e with indices in S * , g : [?u, u] |S * | ? R is some underlying function and e ? F e , E[ e ] = 0, e ? X e S * . We assume g ? L p ([?u, u] |S * | ) and H w = L p ([?u, u] |S * | ). Let be the squared error loss function. We fix the representation ? * (X e ) = X e S * . With ? * as the representation, the optimal classifier w among all the functions is g(X e S * ) (this follows from the generative model). For each environment e, w e * = g is the optimal classifier in H w . Therefore, w e * ? ? * = g is the invariant predictor. Since H w is affine closed 1 |Etr| e w e * ? ? * is an invariant predictor obtained from the EIRM game. Define a functiong(X e ) = g(X e S * ). Since g ? L p ([?u, u] |S * | ),g ? L p ([?u, u] n ). We claim that ? = I elicitsg ? I as an invariant predictor. Suppose this was not the case then for some environment e, there exists? ? L p ([?u, u] n ) which achieves a lower risk thang, i.e. R e (?) &lt; R e (g). Consider</p><formula xml:id="formula_33">min g?L p ([?u,u] n ) E[(Y e ??) 2 ]</formula><p>We simplify the objective as follows</p><formula xml:id="formula_34">E[(Y e ??) 2 ] = E[(g ??) 2 + ( e ) 2 + 2(g ??) e ] = E[(g ??) 2 + ( e ) 2 ] ? E[( e ) 2 ] g =g is an optimal solution since E[(Y e ?g) 2 ] = E[( e ) 2 ]. This contradicts that E[(Y e ??) 2 ] &lt; E[(Y e ?g) 2 ].</formula><p>Therefore, to conclude even when ? = I the EIRM game will recover the invariant predictor that focuses on the causal parents of Y .</p><p>When ? = I, can the game recover the solution when causal parents are not directly observed?</p><p>We consider a similar generative process as described above except, we now assume that the causal features are not directly observed</p><formula xml:id="formula_35">Y e ? g(Z e S * ) + e</formula><p>where Z e S * is the vector Z e with indices in S * , g :</p><formula xml:id="formula_36">[?u, u] |S * | ? R, g ? L p ([?u, u] |S * | )</formula><p>. We assume that we do not observe Z e directly and instead observe X e ? f (Z e ), where f is an invertible map. In addition, we assume that f satisfies the Assumption 2. Let ? * = f ?1 and define P S * as the projection function that projects the input onto indices in S * . Observe that g ? P S * ? f ?1 (X e ) = g(Z e S * ). Fix w * e = g ? P S * . Therefore w e * ? ? * is an invariant predictor. Observe that g ? P S * ? H w = L p ([?u, u] n ). Since H w is affine closed 1 |Etr| e w e * ? ? * is an invariant predictor obtained from the EIRM game. What happens when ? = I?</p><formula xml:id="formula_37">Is (g ? P S * ? f ?1 ) ? I an invariant predictor? Note that g ? P S * ? f ?1 ? L p ([?u, u] n ) (</formula><p>To see why this is the case, use the following observations. g ? P S * ? L p ([?u, u] n ), f satisfies Assumption 2, and use Lemma 1). From the generative model it is clear that there cannot be another classifier that is strictly better than g ? P S * ? f ?1 for any environment. Therefore,  Proof. We will use the classic result from <ref type="bibr" target="#b42">[43]</ref>, which shows the sufficient conditions for the existence of pure Nash equilibrium in continuous action games. We provide this result in the next section Theorem 5, where we continue the discussion on concepts in game theory. Informally speaking, the result states that if the game is concave with compact and convex action sets, then the pure Nash equilibrium exists.</p><formula xml:id="formula_38">g ? P S * ? f ?1 is indeed an invariant predictor. Since g ? P S * ? f ?1 ? L p ([?u, u] n ) and L p ([?u, u] n ) is affine closed, g ? P S * ? f ?1 is</formula><p>The set of actions of each environment H w is a closed bounded and convex subset (following the Assumption 4). Recall the definition of the utility of a player e in the EIRM game is given as</p><formula xml:id="formula_39">u e [w e , w ?e , ?] = ?R e (w av ? ?) = = ?E e [ ((w av ? ?)(x), Y )]<label>(14)</label></formula><p>Following Assumption 4, we simplify the inner term in the expectation as follows.</p><formula xml:id="formula_40">((w av ? ?)(x), Y ) = (?(x) t [ 1 |E tr | |Etr| q=1 w q ], Y )<label>(15)</label></formula><formula xml:id="formula_41">(?(x) t w, Y ) = h Y (w). h Y (w) is a convex function of w (From Assumption 4). Define g : R d ? R d ... ? R d ? R d as g(w 1 , ..., w |Etr| ) = 1</formula><p>|Etr| k w k . Note that g is an affine mapping. The function in <ref type="bibr" target="#b14">(15)</ref> can be expressed as h Y <ref type="figure" target="#fig_0">(g(w 1 , ...w |Etr| )</ref>). The composition of a convex function with an affine function is also convex <ref type="bibr" target="#b43">[44]</ref>. We use this to conclude that the composition h Y <ref type="figure" target="#fig_0">(g(w 1 , ...w |Etr| )</ref>) is a convex function in w 1 , ...w |Etr| . We express <ref type="bibr" target="#b13">(14)</ref> in terms of h and g as</p><formula xml:id="formula_42">u e [w e , w ?e , ?] = ?E e [h Y (g(w 1 , ...w |Etr| ))]<label>(16)</label></formula><p>Each term inside the expectation above is concave. Therefore, u e is concave in w e (follows directly from Jensen's inequality applied to u e ). h Y is a continuous function in w (from Assumption 4) and g is a continuous function as well, the composition of the two continuous functions is also continuous. As a result u e is continuous. Therefore, the EIRM game above satisfies the assumptions in Theorem 5 ( <ref type="bibr" target="#b42">[43]</ref>, which implies that a pure NE exists. This proves the first part of the theorem. We now discuss the second part of the which provides a simple condition for the existence of invariant predictor.</p><p>Say the weights that comprise one of the NE are given as {w q * } |Etr| q=1 . This set of weights satisfy w e * = arg min</p><formula xml:id="formula_43">w e ?Hw ?u e (w e , w ?e * , ?)<label>(17)</label></formula><p>From Assumption 4, w e * is in the interior of H w . Therefore, we can construct a ball around it in which it is the smallest point, which implies it is a local minima of ?u e (w e , w ?e * , ?). Since local minima is also the global minima for convex functions; it follows that the solution would be equivalent to searching over the space of all the linear functions, i.e. </p><p>The above argument holds for all the environments because each solution w e * is in the interior. Therefore, we can transform the EIRM game from the current restricted space H w to the space of all the linear functions. The space of the linear functions satisfy affine closure property unlike the space of bounded linear functions H w . From Theorem 1 it follows that the ensemble classifier 1 |Etr| |Etr| q=1 w q * composed with ? will be an invariant predictor.</p><p>In Theorem 3 we assumed that the model and the representation are both linear functions. We now discuss the existence under a more general class of models.</p><p>Assumption 5 H w is a family of functions parametrized by ? ? ?. We assume that ? is compact. We assume w ? ? H w , where w ? : R d ? R is continuous in its inputs.</p><p>Consider a multilayer perceptron (MLP) with say ReLU activation. Each weight in the network belongs [w min , w max ]. This family of neural networks satisfies the Assumption 5 above.</p><p>Suppose that each environment is looking to solve for a probability distribution over the parameters of the neural network written as vector w e given as p w e . We rewrite the expected loss of the environments as follows.</p><p>u e (p w e , p w ?e , p ? ) = E ?ep w e ?p? u e (w e , w ?e , ?)</p><p>. We use? e as the utility of each environment in the EIRM game.</p><p>Theorem 4. If Assumption 5 is satisfied, then a mixed strategy Nash equilibrium of ? EIRM is guaranteed to exist.</p><p>Proof. The proof is a direct consequence of the existence result <ref type="bibr" target="#b44">[45]</ref>, which we restate in Theorem 7.</p><p>The main message of the above theorem is that we relax the requirement of having a deterministic classifier, then we are guaranteed to have a solution for general models as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Game Theory Concepts Continued</head><p>This section is a continuation to the Section 3.1 on Game Theory Concepts. We discuss some classic results on the existence of NE. Let us now consider continuous action games. We make the following assumption.</p><p>Assumption NE 1 For each i:</p><formula xml:id="formula_45">? S i is a compact, convex subset of R ni ? u i (s i , s ?i ) is continuous in s ?i ? u i (s i , s ?i )</formula><p>is continuous and concave in s i .</p><p>Theorem 5. <ref type="bibr" target="#b42">[43]</ref> If Assumption NE 1 is satisfied for game ?, then a pure strategy Nash equilibrium exists.</p><p>We extend the definition of pure strategy NE to mixed strategies (discussion on mixed strategies given in the next section, where we continue the discussion on concepts in game theory), where instead of choosing an action deterministically, each player chooses a probability distribution over the set of actions. We assume that each set S i is a compact subset of R ni . Define the set of Lesbegue measures over S i as ?(S i ). Each player i, draws a probability distribution ? i from ?(S i ). The joint strategy played by all the players is the product of their individual distributions written as ? k?N ? k Nash equilibrium in mixed strategies. A strategy ? * = ? k?N ? * k is said to be a mixed strategy Nash Equilibrium (NE) if it satisfies</p><formula xml:id="formula_46">E ? * u i (S i , S * ?i ) ? E ? * ?i u i (k, S ?i ) , ?k ? S i , ?i where ? * ?i = ? k =i ? * k .</formula><p>Theorem 6. <ref type="bibr" target="#b45">[46]</ref> Every finite game has a mixed strategy Nash equilibrium.</p><p>Next, we relax some of the above assumptions. Assumption NE 2 For each i ? S i is a non empty, compact subset of R ni ? u i (s i , s ?i ) is continuous in s i and s ?i Theorem 7. <ref type="bibr" target="#b44">[45]</ref> If Assumption NE 2 is satisfied, then the game has a mixed strategy Nash equilibrium.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Deriving the expression for backpropagation</head><p>For instance x, the predicted score from Environment 1,2 (Model 1,2) for class k is given as w k 1 ? x, w k 2 ? x respectively, where w k j is the score output by neural network j for class k. The overall score is given as w k</p><formula xml:id="formula_47">1 ? x + w k 2 ? x.</formula><p>We take the softmax to get the overall probability for class k as</p><formula xml:id="formula_48">p k = exp w k 1 ? x + w k 2 ? x j exp w j 1 ? x + w j 2 ? x<label>(19)</label></formula><p>The softmax vector is p = [p 0 , p 1 ]. Denote w k j ? x = s k j . The log-likelihood for instance x with label y is given as</p><formula xml:id="formula_49">log[p y ] = w y 1 ? x + w y 2 ? x ? log j exp w j 1 ? x + w j 2 ? x = s y 1 + s y 2 ? log j exp s j 1 + s j 2<label>(20)</label></formula><p>The gradient of log-likelihood w.r.t score of each model is given as</p><formula xml:id="formula_50">? log[p y ] ?s k j = I(k = y) ? exp s k 1 + s k 2 j exp s j 1 + s j 2 = I(k = y) ? p k<label>(21)</label></formula><p>We convert y into a one hot encoded vector? and simplify the above expression as</p><formula xml:id="formula_51">? log[p u ] ?s j =? ? p =?<label>(22)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Computing Environment</head><p>The experiments were done on 2.3 GHZ Intel Core i9 processor with 32 GB memory (2400 MHz DDR4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6">Description of the Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.1">Colored MNIST Digits</head><p>We use the exact same environment as in <ref type="bibr" target="#b0">[1]</ref>. <ref type="bibr" target="#b0">[1]</ref> propose to create an environment for training to classify digits in MNIST digits data 5 , where the images in MNIST are now colored in such a way that the colors spuriously correlate with the labels. The task is to classify whether the digit is less than 5 (not including 5) or more than 5. There are three environments (two training containing 30,000 points each, one test containing 10,000 points) We add noise to the preliminary label (? = 0 if digit is between 0-4 and? = 1 if the digit is between 5-9) by flipping it with 25 percent probability to construct the final label. We sample the color id z by flipping the final labels with probability p e , where p e is 0.2 in the first environment, 0.1 in the second environment, and 0.9 in the third environment. The third environment is the testing environment. We color the digit red if z = 1 or green if z = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.2">Colored Fashion MNIST</head><p>We modify the fashion MNIST dataset 6 in a manner similar to the MNIST digits dataset. Fashion MNIST data has images from different categories: "t-shirt", "trouser", "pullover", "dress", "coat", "sandal", "shirt", "sneaker", "bag", "ankle boots". We add colors to the images in such a way that the colors correlate with the labels. The task is to classify whether the image is that of foot wear or a clothing item. There are three environments (two training, one test) We add noise to the preliminary label (? = 0: "t-shirt", "trouser", "pullover", "dress", "coat", "shirt" and? = 1: "sandle", "sneaker", "ankle boots") by flipping it with 25 percent probability to construct the final label. We sample the color id z by flipping the noisy label with probability p e , where p e is 0.2 in the first environment, 0.1 in the second environment, and 0.9 in the third environment, which is the test environment. We color the object red if z = 1 or green if z = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.3">Colored Desprites Dataset</head><p>We modify the Desprites dataset 7 in a manner similar to the MNIST digits dataset. The task is to classify if the image is a circle or a square. We take the preliminary binary labels? = 0 for a circle and? = 1 for a square. We add noise to the preliminary label by flipping it with 25 percent probability to construct the final label. We sample the color id z by flipping the noisy label with probability p e , where p e is 0.2 in the first environment, 0.1 in the second environment, and 0.9 in the third environment, which is the test environment. We color the object red if z = 1 or green if z = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.4">Structured Noise in Fashion MNIST</head><p>In the previous three experiments, we used color in the images to create correlations. In this experiment, we use a different mechanism to create correlations in Fashion MNIST dataset. We add a small square (3? 3), in the top left corner of some images and an even smalller square <ref type="bibr">(2 ? 2)</ref> in the bottom right corner of other images. The location of the box is correlated with labels. The preliminary labels are the same as in the other experiment with Fashion MNIST. There are three environments (two training, one test). We add noise to the preliminary label by flipping it with 25 percent probability to construct the final label. We sample the location id z by flipping the noisy label with probability p e , where p e is 0.2 in the first environment, 0.1 in the second environment, and 0.9 in the third environment, which is the test environment. We place the square in the top left if z = 1 or bottom right if z = 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.6.5">Architecture, Hyperparameter and Training Details</head><p>Architecture for 2 player EIRM game with fixed ? In the game with fixed ?, we used the following architecture for the two models. The model used is a simple multilayer perceptron with following parameters.</p><p>? Input layer: Input batch (batch, len, wid, depth) ? Flatten ? Layer 1: Fully connected layer, output size = 390, activation = ELU, L2-regularizer = 1.25e-3, Dropout = 0.75 ? Layer 2: Fully connected layer, output size = 390, activation = ELU, L2-regularizer = 1.25e-3, Dropout = 0.75 ? Output layer: Fully connected layer, output size = 2 We use the above architecture across all the experiments. The shape of the input in the above architecture depends on the dimensions of the data that are input.</p><p>Architecture for 2 player EIRM game with variable ? In the game with variable ?, we used the following architecture. The architecture for the representation learner is ? Input layer: Input batch (batch, len, wid, depth) ? Flatten ? Layer 1: Fully connected layer, output size = 390, activation = ELU, L2-regularizer = 1.25e-3, Dropout = 0.75 ? Output layer: Fully connected layer, output size = 390, activation = ELU, L2-regularizer = 1.25e-3, Dropout = 0.75 The output from the representation learner above is fed into two MLPs one for each environment (we use the same architecture for both environments).</p><p>? Layer 1: Fully connected layer, output size = 390, activation = ELU, L2-regularizer = 1.25e-3, Dropout = 0.75 ? Layer 2: Fully connected layer, output size = 390, activation = ELU, L2-regularizer = 1.25e-3, Dropout = 0.75 ? Output layer: Fully connected layer, output size = 2 We use the above architecture across all the experiments. The shape of the input in the above architecture depends on the dimensions of the data that are input.</p><p>Optimizer and other hyperparameters We used Adam optimizer for training with learning rate set to 2.5e-4. We optimize the cross-entropy loss function. We set the batch size to 256. We terminate the algorithm according to the rules we explained in the paper. Thus the number of training steps can vary across different trials. There is a warm start phase for all the methods; we set the warm start phase to be equal to the number of steps in one epoch, where one epoch is the (training data size/ batch size). For the setup with fixed ?, we set the period to be 2, i.e. in one step first model trains and in the other step the second model trains and this cycle repeats throughout the training. For the setup with variable ?, we let the two environments and representation learner take turns to update their respective models, environment 1 trains in one step, environment 2 trains in the next step, representation learner trains, and this cycle continues.</p><p>Architecture for IRM <ref type="bibr" target="#b0">[1]</ref> We used the same architecture that they described in the github repository. <ref type="bibr" target="#b7">8</ref> . We describe their architecture below.</p><p>? Input layer: Input batch (batch, len, wid, depth) ? Flatten ? Fully connected layer, output size = 390, activation = ReLU, L2-regularizer = 1.1e-3 ? Fully connected layer, output size = 390, activation = ReLU, L2-regularizer = 1.1e-3 ? Output layer: Fully connected layer, output size= 2 Optimizer, hyperparameters and some remarks We used Adam optimizer for training with learning rate set to 4.89e-4. We optimize the cross-entropy loss function. We set the batch size to 256. The total number of steps is set to 500. The penalty weight is set to 91257. The penalty term is only used after 190 steps. The code from <ref type="bibr" target="#b0">[1]</ref> uses a normalization trick to the loss to avoid gradient explosion. We found that this strategy was not useful in all settings. Therefore, we carried out experiments for both the cases (with and without normalization of loss) and report the case for which the accuracy is higher.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.7">Figures Continued</head><p>In this section, we provide the figures for all the datasets and for both V-IRM and F-IRM game. In <ref type="figure" target="#fig_4">Figure 2-4</ref> in the Experiments Section, we let each model in its turn use ltr (ltr=5) SGD step updates before the turn of the next model. We show the figure with ltr=5 to visually illustrate the oscillations better. In our experiments (                  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Theorem 1 .</head><label>1</label><figDesc>If Assumption 1 holds, thenS IV =S EIRM The proofs of all the results are in the Appendix Section.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Corollary 1 .</head><label>1</label><figDesc>If Assumption 1 holds, then? IV =? EIRM Significance of Theorem 1 and Corollary 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 1 :</head><label>1</label><figDesc>Illustration of best response training with 2 environments and representation learner. Dotted lines for backpropagation and solid lines for forward pass.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 2 :</head><label>2</label><figDesc>F-IRM, Colored Fashion MNIST: Comparing accuracy of ensemble model's correlation with color</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 3 :</head><label>3</label><figDesc>F-IRM, Colored Fashion MNIST: Correlation of the ensemble model with color oscillate in</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>F-IRM, Colored Fashion MNIST: Correlations of the individual models with color two states and that is the reason for oscillations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>1</head><label>1</label><figDesc>Examples of hypothesis classes that satisfy affine closure ? Linear classifiers: The sum of linear functions (polynomial) leads to a linear function (polynomial), and so does scalar multiplication. Therefore, linear classifiers satisfy affine closure. ? Reproducing Kernel Hilbert Space (RKHS): RKHS is a Hilbert space,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>|Etr| q=1 is a Nash equilibrium ({w q } |Etr| q=1 is a Nash equilibrium because (?, {w q } |Etr| q=1 , w) ?S EIRM ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Corollary 1 .</head><label>1</label><figDesc>If Assumption 1 holds, then? IV =? EIRM Proof. The proof follows straightaway from Theorem 1. For each w ? ? ?? IV we look at the corresponding tuple (?, {w q } |Etr| q=1 , w) ?S IV . From Theorem 1, (?, {w q } |Etr| q=1 , w) ?S EIRM . Therefore, w ? ? ?? EIRM . The other side follows the same way.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Lemma 1 .</head><label>1</label><figDesc>If Assumptions 2 and 3 are satisfied, then for any w ? H w and</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Theorem 2 .</head><label>2</label><figDesc>If Assumptions 2 and 3 are satisfied andS IV Z is not empty, then S IV Z =? IV X (I) =? EIRM X (I)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>also a solution obtained from the EIRM game with ? = I.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Theorem 3 .</head><label>3</label><figDesc>If Assumption 4 is satisfied, then a pure strategy Nash equilibrium of the game ? EIRM exists. If the weights of all the individuals in the NE are in the interior of H w , then the corresponding ensemble predictor is an invariant predictor among all linear models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>w e * = arg min w e ?R d ?u e (w e , w ?e * , ?)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Figure 5 - 36 .Figure 5 :</head><label>5365</label><figDesc>The captions under the plot describe the dataset and the corresponding game (F-IRM/V-IRM). All the plots inFigure 5-36 use the termination criteria we described in the Experiments Section. We observe the same trends that we observed and explained in Experiments Section across all the figures.To illustrate what happens if we let the training go on, inFigure 36-40 we F-IRM, Colored Fashion MNIST: Comparing accuracy of ensemble accuracy diffeerence (e2-e1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head>Figure 6 :</head><label>6</label><figDesc>F-IRM, Colored Fashion MNIST: Difference in accuracy of the ensemble model between the two environments let the training for V-IRM on Desprites dataset continue for many more training steps.Figures 36-40illustrate that the oscillations are stable and persist. As a result, we continue to encounter the state in which the ensemble does not exploit spurious correlations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Figure 7 :</head><label>7</label><figDesc>F-IRM, Colored Fashion MNIST: Ensemble's correlation with color</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head>Figure 8 :Figure 9 :Figure 10 :</head><label>8910</label><figDesc>F-IRM, Colored Fashion MNIST: Compare individual model correlations V-IRM Colored Fashion MNIST: Comparing accuracy of ensemble V-IRM Colored Fashion MNIST: Difference in accuracy of the ensemble model between the two environments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head>Figure 11 :</head><label>11</label><figDesc>V-IRM Colored Fashion MNIST: Ensemble's correlation with color</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Figure 12 :Figure 13 :Figure 14 :</head><label>121314</label><figDesc>V-IRM Colored Fashion MNIST: Compare individual model correlations. F-IRM Colored Digits MNIST: Comparing accuracy of ensemble F-IRM Colored Digits MNIST: Difference in accuracy of the ensemble model between the two environments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_23"><head>Figure 15 :</head><label>15</label><figDesc>F-IRM Colored Digits MNIST: Ensemble's correlation with color</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_24"><head>Figure 16 :Figure 17 :</head><label>1617</label><figDesc>F-IRM Colored Digits MNIST: Compare individual model correlations. V-IRM Colored Digits MNIST: Comparing accuracy of ensemble</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_25"><head>Figure 18 :</head><label>18</label><figDesc>V-IRM Colored Digits MNIST: Difference in accuracy of the ensemble model between the two environments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_26"><head>Figure 19 :</head><label>19</label><figDesc>V-IRM Colored Digits MNIST: Ensemble's correlation with color</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_27"><head>Figure 20 :Figure 21 :Figure 22 :Figure 23 :Figure 25 :Figure 26 :CorrelationFigure 27 :Figure 28 :Figure 29 :</head><label>202122232526272829</label><figDesc>V-IRM Colored Digits MNIST: Compare individual model correlations F-IRM Colored Desprites: Comparing accuracy of ensemble F-IRM Colored Desprites: Difference in accuracy of the ensemble model between the two environments F-IRM Colored Desprites: Ensemble's correlation with color V-IRM Colored Desprites: Comparing accuracy of ensemble V-IRM Colored Desprites: Difference in accuracy of the ensemble model between the two environments V-IRM Colored Desprites: Correlation of the ensemble model with color V-IRM Colored Desprites: Compare individual model correlations F-IRM Structured Noise Fashion MNIST: Comparing accuracy of ensemble</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_28"><head>Figure 30 :</head><label>30</label><figDesc>F-IRM Structured Noise Fashion MNIST: Difference in accuracy of the ensemble model between the two environments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_29"><head>Figure 31 :</head><label>31</label><figDesc>F-IRM Structured Noise Fashion MNIST: Correlation of the ensemble model with color</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_30"><head>Figure 32 :Figure 33 :Figure 34 :</head><label>323334</label><figDesc>F-IRM Structured Noise Fashion MNIST: Individual model correlation with color V-IRM Structured Noise Fashion MNIST: Comparing accuracy of ensemble V-IRM Structured Noise Fashion MNIST: Difference in accuracy of the ensemble model between the two environments,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_31"><head>Figure 35 :</head><label>35</label><figDesc>V-IRM Structured Noise Fashion MNIST: Ensemble's correlation with color</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_32"><head>Figure 36 :Figure 37 :Figure 38 :Figure 39 :Figure 40 :</head><label>3637383940</label><figDesc>V-IRM Structured Noise Fashion MNIST: Individual model correlation with color V-IRM Colored Desprites: Comparing accuracy of ensemble (More train steps) V-IRM Colored Desprites: Difference in accuracy of the ensemble model between the two environments (More train steps) V-IRM Colored Desprites: Ensemble's correlation with color (More train steps) V-IRM Colored Desprites: Individual model correlations (More train steps)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>). (The av stands for average.) Consider the example of binary classification with two environments {e 1 , e 2 }; w e = [w e 1 , w e 2 ] is the classifier of environment e, where each component is the score for each class. We define the component j of the ensemble classifier w av</figDesc><table><row><cell>as w av j =</cell><cell>w j +w e 1 j e 2 2</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Colored MNIST: Comparison of methods in terms of training, testing accuracy (mean ? std deviation).</figDesc><table><row><cell>Algorithm</cell><cell cols="2">Train accuracy Test accuracy</cell></row><row><cell>ERM</cell><cell>84.88 ? 0.16</cell><cell>10.45 ? 0.66</cell></row><row><cell>ERM 1</cell><cell>84.84 ? 0.21</cell><cell>10.86 ? 0.52</cell></row><row><cell>ERM 2</cell><cell>84.95 ? 0.20</cell><cell>10.05 ? 0.23</cell></row><row><cell>Robust min max</cell><cell>84.25 ? 0.43</cell><cell>15.24 ? 2.45</cell></row><row><cell>F-IRM game</cell><cell>63.37 ? 1.14</cell><cell>59.91 ? 2.69</cell></row><row><cell>V-IRM game</cell><cell>63.97 ? 1.03</cell><cell>49.06 ? 3.43</cell></row><row><cell>IRM</cell><cell>59.27 ? 4.39</cell><cell>62.75 ? 9.59</cell></row><row><cell>ERM grayscale</cell><cell>71.81 ? 0.47</cell><cell>71.36? 0.65</cell></row><row><cell>Optimal</cell><cell>75</cell><cell>75</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Colored Fashion MNIST: Comparison of methods in terms of training, testing accuracy (mean ? std deviation).</figDesc><table><row><cell>Algorithm</cell><cell cols="2">Train accuracy Test accuracy</cell></row><row><cell>ERM</cell><cell>83.17 ? 1.01</cell><cell>22.46 ? 0.68</cell></row><row><cell>ERM 1</cell><cell>81.33 ? 1.35</cell><cell>33.34 ? 8.85</cell></row><row><cell>ERM 2</cell><cell>84.39 ? 1.89</cell><cell>13.16 ? 0.82</cell></row><row><cell>Robust min max</cell><cell>82.81 ? 0.11</cell><cell>29.22 ? 8.56</cell></row><row><cell>F-IRM game</cell><cell>62.31 ? 2.35</cell><cell>69.25 ? 5.82</cell></row><row><cell>V-IRM game</cell><cell>68.96 ? 0.95</cell><cell>70.19 ? 1.47</cell></row><row><cell>IRM</cell><cell>75.01 ? 0.25</cell><cell>55.25 ? 12.42</cell></row><row><cell>ERM grayscale</cell><cell>74.79 ? 0.37</cell><cell>74.67? 0.48</cell></row><row><cell>Optimal</cell><cell>75</cell><cell>75</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Colored Desprites: Comparison of methods in terms of training, testing accuracy (mean ? std deviation).</figDesc><table><row><cell>Algorithm</cell><cell cols="2">Train accuracy Test accuracy</cell></row><row><cell>ERM</cell><cell>85.01 ? 0.03</cell><cell>9.97 ? 0.05</cell></row><row><cell>ERM 1</cell><cell>81.33 ? 1.35</cell><cell>33.34 ? 8.85</cell></row><row><cell>ERM 2</cell><cell>84.39 ? 1.89</cell><cell>13.16 ? 0.82</cell></row><row><cell>Robust min max</cell><cell>84.94 ? 0.09</cell><cell>10.28 ? 0.33</cell></row><row><cell>F-IRM game</cell><cell>53.36 ? 1.40</cell><cell>48.61 ? 3.06</cell></row><row><cell>V-IRM game</cell><cell>56.31 ? 4.94</cell><cell>50.04 ? 0.15</cell></row><row><cell>IRM</cell><cell>52.67 ? 2.40</cell><cell>51.82 ? 5.95</cell></row><row><cell>ERM grayscale</cell><cell>67.67 ? 0.58</cell><cell>66.97? 0.69</cell></row><row><cell>Optimal</cell><cell>75</cell><cell>75</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Structured Noise Fashion MNIST: Comparison of methods in terms of training, testing accuracy (mean ? std deviation).</figDesc><table><row><cell>Algorithm</cell><cell cols="2">Train accuracy Test accuracy</cell></row><row><cell>ERM</cell><cell>83.49 ? 1.22</cell><cell>20.13 ? 8.06</cell></row><row><cell>ERM 1</cell><cell>81.80 ? 1.50</cell><cell>30.94 ? 1.01</cell></row><row><cell>ERM 2</cell><cell>84.66 ? 0.40</cell><cell>11.98 ? 0.23</cell></row><row><cell>Robust min max</cell><cell>82.78 ? 1.32</cell><cell>25.59 ? 9.14</cell></row><row><cell>F-IRM game</cell><cell>51.54 ? 2.96</cell><cell>62.03 ? 2.02</cell></row><row><cell>V-IRM game</cell><cell>47.70 ? 1.69</cell><cell>61.46 ? 0.53</cell></row><row><cell>IRM</cell><cell>52.57 ? 9.95</cell><cell>63.92 ? 10.95</cell></row><row><cell>ERM no noise</cell><cell>74.79 ? 0.37</cell><cell>74.67? 0.48</cell></row><row><cell>Optimal</cell><cell>75</cell><cell>75</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1</head><label>1</label><figDesc>-4) we set ltr =1; we show the figures corresponding to all our experiments (Table 1-4) in</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The setup applies to both continuous and categorical data. If any feature or label is categorical, we one-hot encode it.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We can also express each environment's action as a mapping from ? : H ? ? Hw but we don't to avoid complicated notation.<ref type="bibr" target="#b2">3</ref> We don't double count compositions leading to the same predictor.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data 6 https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/ load_data 7 https://github.com/deepmind/dsprites-dataset</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">https://github.com/facebookresearch/InvariantRiskMinimization</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Invariant risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.02893</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Recognition in terra incognita</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Beery</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Van Horn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="456" to="473" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Causal confusion in imitation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>De Haan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jayaraman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The theory of learning in games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fudenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Levine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT press</publisher>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Local characterizations of causal bayesian networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bareinboim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graph Structures for Knowledge Representation and Reasoning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1" to="17" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">On causal and anticausal learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1206.6471</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Causal inference using the algorithmic markov condition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="5168" to="5194" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Information-geometric approach to inferring causal directions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lemeire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zscheischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Daniu?is</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">182</biblScope>
			<biblScope unit="page" from="1" to="31" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Causal inference by using invariant prediction: identification and confidence intervals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>B?hlmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society: Series B (Statistical Methodology)</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="947" to="1012" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Invariant causal prediction for nonlinear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Heinze-Deml</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Meinshausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Causal Inference</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Domain adaptation by using causal inference to predict invariant conditional distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Magliacane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Van Ommen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Claassen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bongers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Versteeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10" to="846" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Should i include this edge in my prediction? analyzing the stability-performance tradeoff</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Subbaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saria</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.11374</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Improving predictive inference under covariate shift by weighting the log-likelihood function</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shimodaira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of statistical planning and inference</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="227" to="244" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Direct importance estimation for covariate shift adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nakajima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>B?nau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of the Institute of Statistical Mathematics</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="699" to="746" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Covariate shift by kernel mean matching</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gretton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schmittfull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Borgwardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Dataset shift in machine learning</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Metric-optimized example weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Fard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10582</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Domain-adversarial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.4446</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Analysis of representations for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ben-David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blitzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Crammer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Domain adaptation for large-scale sentiment classification: A deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Domain-adversarial training of neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ganin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ustinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ajakan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Germain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Laviolette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2096" to="2030" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">On learning invariant representation for domain adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Combes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Gordon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.09453</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Support and invertibility in domain-invariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Johansson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ranganath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sontag</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03448</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Agnostic federated learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sivek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Suresh</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.00146</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Algorithms and theory for multiplesource adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mohri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="8246" to="8256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Minimax statistical learning with wasserstein distances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raginsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2687" to="2696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Statistics of robust optimization: A generalized empirical likelihood approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Duchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Glynn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Namkoong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1610.03425</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Game theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fudenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tirole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cambridge, Massachusetts</title>
		<imprint>
			<biblScope unit="volume">393</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">80</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Kernel methods in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The annals of statistics</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1171" to="1220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A short introduction to boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Abe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal-Japanese Society For Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">1612</biblScope>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Probability and measure theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Ash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Doleans-Dade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Catherine</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Best response dynamics for continuous zero-sum games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hofbauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sorin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete and Continuous Dynamical Systems Series B</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">215</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Best response dynamics for continuous games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Barron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goebel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the American Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">138</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1069" to="1083" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Learning in games with continuous action sets and unknown payoff functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mertikopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematical Programming</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="465" to="507" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Learning and convergence to nash in games with continuous action sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bervoets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bravo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Faure</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Working paper, Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Generative adversarial nets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pouget-Abadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mirza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Warde-Farley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2672" to="2680" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Finding mixed nash equilibria of generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-P</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cevher</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1811.02002</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Random features for large-scale kernel machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1177" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Best-response cycles in perfect information games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-J</forename><surname>Herings</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Predtetchinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mathematics of Operations Research</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="427" to="433" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The expressive power of neural networks: A view from the width</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Pu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6231" to="6239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Real and complex analysis (mcgraw-hill international editions: Mathematics series)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Rudin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Inequalities: a journey into linear analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Garling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A social equilibrium existence theorem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Debreu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="886" to="893" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Vandenberghe</surname></persName>
		</author>
		<title level="m">Convex optimization</title>
		<imprint>
			<publisher>Cambridge university press</publisher>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">A further generalization of the kakutani fixed point theorem, with application to nash equilibrium points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">L</forename><surname>Glicksberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the American Mathematical Society</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="170" to="174" />
			<date type="published" when="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Equilibrium points in n-person games</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Nash</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the national academy of sciences</title>
		<meeting>the national academy of sciences</meeting>
		<imprint>
			<date type="published" when="1950" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="48" to="49" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
