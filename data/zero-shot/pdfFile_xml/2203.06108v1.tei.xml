<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ActiveMLP: An MLP-like Architecture with Active Token Mixer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoqiang</forename><surname>Wei</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhizheng</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cuiling</forename><surname>Lan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Lu</surname></persName>
							<email>yanlu@microsoft.comchenzhibo@ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="institution">Microsoft Research Asia</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhibo</forename><surname>Chen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Science and Technology of China</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">ActiveMLP: An MLP-like Architecture with Active Token Mixer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents ActiveMLP, a general MLP-like backbone for computer vision. The three existing dominant network families, i.e., CNNs, Transformers and MLPs, differ from each other mainly in the ways to fuse contextual information into a given token, leaving the design of more effective token-mixing mechanisms at the core of backbone architecture development. In ActiveMLP, we propose an innovative token-mixer, dubbed Active Token Mixer (ATM), to actively incorporate contextual information from other tokens in the global scope into the given one. This fundamental operator actively predicts where to capture useful contexts and learns how to fuse the captured contexts with the original information of the given token at channel levels. In this way, the spatial range of token-mixing is expanded and the way of token-mixing is reformed. With this design, ActiveMLP is endowed with the merits of global receptive fields and more flexible contentadaptive information fusion. Extensive experiments demonstrate that ActiveMLP is generally applicable and comprehensively surpasses different families of SOTA vision backbones by a clear margin on a broad range of vision tasks, including visual recognition and dense prediction tasks. The code and models will be available at https://github.com/microsoft/ActiveMLP.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Convolutional neural networks (CNNs) <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b9">10]</ref> serve as the most commonly used vision backbones for a long time. Inspired by the successes in Natural Language Processing (NLP), Carion et al. <ref type="bibr" target="#b10">[11]</ref> and Dosovitskiy et al. <ref type="bibr" target="#b11">[12]</ref> introduce self-attention based model, i.e., Transformer, into computer vision. Afterwards, Transformers spring up and make splendid breakthroughs on various vision tasks <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>. Most recently, the multi-layer perceptrons (MLPs) based architectures <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29]</ref> have regained their light and been demonstrated capable of achieving stunning results on vision tasks <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34]</ref>. A situation in which these three families of backbone architectures are contending has been formed.</p><p>Those three categories of backbone architectures described above differ from each other mainly in the different ways of token mixing. Here, we refer to each feature vector as one token for different architectures uniformly. CNN-based architectures <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b9">10,</ref><ref type="bibr" target="#b8">9]</ref> locally mix tokens within a shifted window with the fixed shape. Transformer-based architectures <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39]</ref> perform message passing from other tokens into the query token based on the calculated pairwise attention weights, depending on the affinities between tokens in the embedding space. MLPbased architectures mostly enable information interaction through spatial fully connections across all tokens <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b33">34]</ref> or across certain tokens selected with hand-crafted rules in a deterministic manner <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b41">42]</ref>. However, the fully connection across all tokens makes the network incapable of coping with variable input resolutions, limiting the usage on downstream tasks (e.g., object detection and segmentation). Manually designing deterministic rules to restrict the spatial information interaction within fixed regions <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref> eliminates this resolution-fixed constraint but suffers from the lack of adaptability to various visual contents with diverse feature patterns in information interaction.</p><p>In this work, we endeavor to design a more powerful backbone from the perspective of advancing token-mixing mechanism. As known, different spatial locations of image correspond to visual contents with different scales and deformations. In the feature space, different semantic attributes of a token would distribute in different channels <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>. This makes the relationship among different tokens complex to model. In this paper, we devise an MLP-like architecture named ActiveMLP with the merit of content-adaptive token-mixing, which explores multiple semantics meticulously in the non-local range. To this end, we introduce an Active Token Mixer (ATM) to adaptively predict the locations of tokens whose information should be incorporated into the query token at the channel level. The proposed ATM decouples this process along the horizontal and vertical dimensions, i.e., learning the channel-level offsets along each axial independently, making the offset learning easier to the point that one FC layer could work well per direction. We recompose the selected token elements at the channel level according to the predicted offsets along axial directions separately, then weighted fuse the recomposed tokens and the original token into a new one as the final result of token-mixing. In this way, the proposed ATM endows ActiveMLP with high flexibility and adaptability to the visual contents, as well as the ability to achieve information interaction in the global scope efficiently (see <ref type="figure" target="#fig_0">Fig.1</ref> for its superiority on image classification). Besides, ActiveMLP is also capable of dealing with variable input resolutions and has linear computational complexity to the input resolution.</p><p>Our contributions can be summarized below:</p><p>? We propose a novel and efficient MLP-like vision backbone ActiveMLP, which is generally applicable to various vision tasks, including but not limited to image recognition and dense prediction tasks. ? We propose the Active Token Mixer (ATM), a key design of ActiveMLP, which expands the range and reforms the way of message passing in token mixing, as well as enhances the capability of multiple semantics modelling. ? ActiveMLP achieves strong performance over different model scales and across various vision tasks. For image classification, only trained on ImageNet-1K <ref type="bibr" target="#b44">[45]</ref>, ActiveMLP achieves 82.0% top-1 accuracy with 27M parameters and reaches 83.6% when scaling up to 76M parameters. Moreover, ActiveMLP outperforms recent prevalent backbones on dense prediction tasks by a significant margin with comparable or even less parameters and computation cost.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">CNN based Models</head><p>Convolutional neural networks (CNNs) have been the mainstream in computer vision for a long time. CNN model is originally presented in <ref type="bibr" target="#b45">[46]</ref> for document recognition. Beginning with the significant success of AlexNet <ref type="bibr" target="#b0">[1]</ref> in ILSVRC 2012, various CNN-based architectures are designed or searched, e.g., Inception <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>, VGG <ref type="bibr" target="#b1">[2]</ref>, ResNet <ref type="bibr" target="#b6">[7]</ref>, DenseNet <ref type="bibr" target="#b7">[8]</ref>, ResNeXt <ref type="bibr" target="#b8">[9]</ref>, ResNeSt <ref type="bibr" target="#b9">[10]</ref>, EfficientNet <ref type="bibr" target="#b46">[47]</ref>, MNASNet, <ref type="bibr" target="#b47">[48]</ref> and others <ref type="bibr" target="#b48">[49,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b50">51,</ref><ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b52">53]</ref>. In addition, there are a series of works dedicated to improving the convolution layers from different perspectives, e.g., depthwise separable convolution <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b54">55]</ref> for lower computation cost, deformable convolution <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref> for deformable objects and dilated convolution <ref type="bibr" target="#b57">[58]</ref> for larger receptive field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Self-attention based Models</head><p>The self-attention based Transformer architecture <ref type="bibr" target="#b58">[59]</ref> is originally developed for the natural language processing (NLP) tasks. Dosovitskiy et al. <ref type="bibr" target="#b11">[12]</ref> firstly introduce a pure self-attention based backbone to computer vision, i.e., ViT, which achieves promising performance on image classification especially trained with extremely large-scale data. Touvron et al. <ref type="bibr" target="#b12">[13]</ref> improve the training strategy of ViT and propose a knowledge distillation method, which helps ViT achieve performance comparable with CNNs trained only on ImageNet. Then various works endeavor to explore efficient vision Transformer architecture designs, e.g., PVT <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b34">35]</ref>, Swin <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b59">60]</ref>, Twins <ref type="bibr" target="#b14">[15]</ref>, MViT <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b36">37]</ref>, and others <ref type="bibr" target="#b60">[61,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b61">62,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b62">63,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b63">64]</ref>. Transformer also presents its superiority on various tasks, e.g., object detection <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b22">23]</ref>, segmentation <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b64">65]</ref>, pose estimation <ref type="bibr" target="#b21">[22,</ref><ref type="bibr" target="#b21">22]</ref>, tracking <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b65">66]</ref> and GAN <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b66">67]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">MLP-like Models</head><p>Recently, MLP-like models have been reinvigorated. The pioneering works MLP-Mixer <ref type="bibr" target="#b27">[28]</ref> and ResMLP <ref type="bibr" target="#b29">[30]</ref> stack two types of MLP layers, i.e., token-mixing MLP and channel-mixing MLP, repeatedly. The token-mixing encodes the spatial information by interacting across all tokens while the channel-mixing mixes information across all channels within each token. ViP <ref type="bibr" target="#b39">[40]</ref> and sMLP <ref type="bibr" target="#b33">[34]</ref> encode the feature representations along two axial dimensions to improve MLPs' efficiency and capability. Shift <ref type="bibr" target="#b40">[41]</ref>, ASMLP <ref type="bibr" target="#b28">[29]</ref> and S 2 MLP [32] perform spatial information mixing with spatial shift operations along different dimensions. CycleMLP <ref type="bibr" target="#b30">[31]</ref>, WaveMLP <ref type="bibr" target="#b41">[42]</ref> and MorphMLP <ref type="bibr" target="#b32">[33]</ref> restrict the spatial information interaction within hand-craft local windows in a deterministic way.</p><p>Our ActiveMLP is an MLP-like architecture with an adaptive token mixer, i.e., ATM. In contrast to existing MLP-based designs, our ActiveMLP achieves content-adaptive token-mixing, which considers multiple semantics meticulously in the non-local field. It provides high flexibility and strong modeling capacity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A Unified Perspective</head><p>For most prevailing backbones, the input image is first patchified into a lower-resolution feature tensor X ? R H?W ?C with the height H, the width W and the number of channels C. X consists of H ? W feature vectors, where each x ? R C is referred to as one token. For a visual signal, we inevitably represent or understand it cross tokens since the contextual information is necessary. Hence, token-mixing is important for the model architecture design, greatly affecting the effectiveness and efficiency of models. Before introducing our proposed design, we firstly review and compare different token mixing mechanisms in the existing vision backbones, including CNNs, Transformers, and MLPs, from a unified perspective. Mathematically, we denote the token mixing with a unified function as:</p><formula xml:id="formula_0">f (X)| x q = k?N (x q ) ? k?q * g(x k ),<label>(1)</label></formula><p>where x q denotes the query token while N (x q ) refers to a set of its corresponding contextual tokens. ? k?q is the weight that determines the degree of message passing from x k to x q . g(?) is an embedding function that in general does not change the dimensions of token. * is a unified form of element-wise or matrix multiplication.</p><p>With this unified formulation, we revisit and compare the token-mixing mechanisms in different families of vision backbones. For conventional CNNs, g(?) is an identity function, and ? k?q ? R C?C corresponds to the convolutional kernels which restrict the message passing within a fixed-size N (?), i.e., a shifted window. ? k?q is shared for different query tokens <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b6">7]</ref>. Transformers achieve a non-local N (?) and adopt a computation-sophisticated ? k?q ? R C through calculating the affinity between x k and x q in the embedding space. In recent MLP-like backbones <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b41">42]</ref>, N (?) and ? k?q are manually designed to perform token-mixing in a deterministic way, leading to the lack of content adaptivity. In Transformers or MLPs, g(?) is a trainable embedding function commonly implemented with Fully-Connected (FC) layers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Our ActiveMLP Network</head><p>We elaborate our proposed ActiveMLP in this section. Starting with the core design (Active Token Mixer) ATM of ActiveMLP, we first introduce the token-mixing process along one axial direction, and draw inferences about other directions from this instance. Then, we describe the fusion manner between the actively captured contextual information and the original query token. Finally, we present how we establish ActiveMLP and introduce the architecture variants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Active Token Mixer (ATM)</head><p>Based on the token-mixing behaviors in existing architectures detailed in Sec. 3.1, we have two key observations: 1) For the spatial dimension, visual objects/stuffs present diverse shapes and deformations, leading information-mixing within a fixed range N (?) <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29]</ref> to be inefficient and inadequate.The adaptive ? k?q and N (?) for message passing is desirable for visual representations.</p><p>2) For the channel dimension, multiple semantic attributes carried in one token would distribute in its different channels <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44]</ref>. The token-level message passing with ? k?q ? R shared over channels can not treat different semantics adaptively and limits their full use, thus is less effective <ref type="bibr" target="#b29">[30,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b27">28]</ref>. In this work, we pinpoint the importance of more fine-grained message passing, for adaptively treating different semantics, on effective backbone design.</p><p>In this paper, we propose a new token-mixing mechanism as shown in <ref type="figure" target="#fig_1">Fig. 2</ref>. It first predicts the locations of helpful contextual tokens along each direction at channel level, then learns to fuse the information of contextual tokens and query token. These two steps correspond to learn where the helpful context tokens locate in and how to fuse them with the original information, respectively. Drawing on the success of multi-branch design in <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b35">36,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b67">68]</ref>, we propose a three-branch architecture for our proposed token-mixer. Two branches of them are responsible for recomposing tokens into a new one along two axial directions separately as illustrated in <ref type="figure" target="#fig_1">Fig. 2</ref> (a). The two recomposed tokens and the original query token are further mixed as the final output.</p><p>In <ref type="figure" target="#fig_1">Fig. 2 (b)</ref>, we illustrate the mixing operation along the horizontal (i.e., width) dimension, denoted by ATM W . Given the query token x q (marked in " "), we first feed it into a FC layer to adaptively</p><formula xml:id="formula_1">predict C offsets O = {o i } C i=1 in total.</formula><p>Note that we impose no constraint on the offset generation, thus N (x q ) is allowed to extend to all spatial positions. In this way, ActiveMLP could incorporate the information from theglobal scope, wherever needed, into x q in a flexible and active manner. The predicted offsets help locate the selected tokens in N (?) per channel, which are used to recompose a tokenx W ? R C with mixing horizontally as output of ATM W :</p><formula xml:id="formula_2">AT M W (X)| x q =x W = X [i,j+o1,1] , X [i,j+o2,2] , . . . , X [i,j+o C ,C] T ,<label>(2)</label></formula><p>where X [i,j+o,c] denotes the c th channel element of token at position [i, j + o], and [i, j] is the position of x q . ATM W is capable of mixing information across the entire row.</p><p>Likewise, another ATM H branch is adopted to recompose a tokenx H along the vertical (i.e., height) dimension. In addition, we preserve the original information of the query token with an identity function in the third branch as illustrated in <ref type="figure" target="#fig_1">Fig. 2 (a)</ref>.</p><p>Here, we set forth how to fuse the recomposedx W ,x H and the originalx I into the final token-mixing result. First, we adopt three FC layers to embedx W ,x H andx I intox W ,x H andx I , which are then mixed with learned weights, formulated by:</p><formula xml:id="formula_3">x = ? W x W + ? H x H + ? I x I ,<label>(3)</label></formula><p>where denotes element-wise multiplication. ? {W,H,I} ? R C are learned from the summationx of x W ,x H andx I with three independent FCs with parameters W {W,H,I} ? R C?C :</p><formula xml:id="formula_4">[? W , ? H , ? I ] = sof tmax([W W ?x , W H ?x , W I ?x ]),<label>(4)</label></formula><p>where sof tmax(?) is used to normalize for each channel separately.</p><p>Analysis. Our ATM has three hallmarks: 1) Content adaptivity. The determination of context selection is adaptively learned for the query token in an active way, instead of being passively determined by manual designs <ref type="bibr" target="#b30">[31,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33]</ref>. 2) Flexibility. The proposed ATM enables selecting context tokens at the channel level from a global range N (?) dynamically, compatible with visual contents with various scales and deformations. 3) Efficiency. The computation complexity of ATM is O HW C 2 , which is linear with the input resolution and is agnostic to the receptive fields, making it computation-friendly to larger-size images used in object detection and segmentation tasks. In practice, we further reduce the number of generated offsets |O| from C to C N with N ? (0, C). Compared with the conventional convolutions, ATM enjoys the same computation complexity with 1?1 convolution, i.e., fully convolution <ref type="bibr" target="#b68">[69]</ref>, but ATM is able to enlarge its receptive field to a global-scope one flexibly. Compared with the multi-head self-attention in Transformers, ATM is also capable of mixing global token information per channel/head, with the actively learned offsets, avoiding the computation-laborious global attention calculation. ATM may be reminiscent of the deformable convolution <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref>. In fact, there are two crucial differences: 1) The learned offsets in deformable convolutions are shared over all channels. Our ATM, embedded in MLP-like backbones, can incorporate contextual information per channel in a more flexible manner. The superiority of our more flexible ATM is demonstrated through experiments later. 2) We decouple the offset learning along different directions while <ref type="bibr" target="#b55">[56,</ref><ref type="bibr" target="#b56">57]</ref> do not, making ours easier to be optimized.</p><p>Network Constitution with ATMs. Our ActiveMLP is straightforwardly composed of multiple ATM blocks in sequence. Here, we introduce the architecture of an ActiveMLP block. For the feature X l-1 of the (l ? 1)-th layer, we feed it to ATM for token-mixing. Further, we use an MLP module to further modulate the feature along the channel dimension. Skip connections <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b27">28</ref>] are adopted to help training. The entire process can be formulated as:</p><formula xml:id="formula_5">X l = AT M l (LN (X l-1 )) + X l-1 ,<label>(5)</label></formula><formula xml:id="formula_6">X l = M LP l (LN (X l )) +X l ,<label>(6)</label></formula><p>where LN denotes LayerNorm <ref type="bibr" target="#b69">[70]</ref>.</p><p>Architecture Variants. Following the typical hierarchical architecture designs <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b35">36]</ref>, we provide five four-stage architecture variants with different channel dimensions and numbers of the ATM blocks, which are ActiveMLP-xT, ActiveMLP-T, ActiveMLP-S, ActiveMLP-B, and ActiveMLP-L, respectively. We find that it is not necessary to generate new offsets for each ATM block, instead we generate new offsets every K layers in each stage, where K = 2, 2, 6, 6, 6 for the five variants respectively. Note that the offset generation layer is shared over the tokens within each ATM branch. Here, the awareness of the position of query token can facilitate the prediction of offsets. We thus introduce one positional encoding generator (PEG) <ref type="bibr" target="#b60">[61]</ref> for each stage before ATM, which helps a little for dense prediction tasks. <ref type="table" target="#tab_0">Table 1</ref> summaries the model size (#P.), computation complexity (FLOPs) and the performance of different variants. More detailed configurations are shown in the Supplementary. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">ImageNet-1K Classification</head><p>Settings. We train our models on the ImageNet-1K dataset <ref type="bibr" target="#b44">[45]</ref> from scratch, which contains 1.2M training images and 50K validation images evenly spreading 1,000 categories. We report the top-1 accuracy on the validation set following the standard practice in this community. For fair comparison, our training strategy is mostly adopted from DeiT <ref type="bibr" target="#b12">[13]</ref>, which includes RandAugment <ref type="bibr" target="#b76">[77]</ref>, Mixup <ref type="bibr" target="#b77">[78]</ref>, Cutmix <ref type="bibr" target="#b78">[79]</ref>, Random erasing <ref type="bibr" target="#b79">[80]</ref> and stochastic depth <ref type="bibr" target="#b80">[81]</ref>. AdamW <ref type="bibr" target="#b81">[82]</ref> and cosine learning rate schedule with the initial value of 1 ? 10 ?3 are adopted. All models are trained for 300 epochs with 5-epoch warm-up on Tesla V100 GPUs with the batch size of 1024. More details are shown in the Supplementary.</p><p>Results. We report the top-1 accuracy comparison between our ActiveMLP with recent CNN-, Transformer-and MLP-based backbones in <ref type="table" target="#tab_1">Table 2</ref>, where all methods are categorized into different groups w.r.t. the model size (#Parameters) and computation complexity (FLOPs). All our different variants achieve higher accuracy compared with the scale-comparable methods. 1) Our ActiveMLP-T, -B, and -L variants outperform the prominent Transformer Swin-T, -S, and -B <ref type="bibr" target="#b13">[14]</ref> by +0.8%, +0.3% and +0.1% with comparable parameters and FLOPs. 2) Our ActiveMLP also surpasses all recent MLPlike backbones (e.g., ASMLP <ref type="bibr" target="#b28">[29]</ref>, CycleMLP <ref type="bibr" target="#b30">[31]</ref>, gMLP <ref type="bibr" target="#b73">[74]</ref>, ViP <ref type="bibr" target="#b39">[40]</ref>, and etc). Compared with the pioneering ResMLP-S24 <ref type="bibr" target="#b29">[30]</ref> and -B24, ActiveMLP-T and -L achieves +2.6% and +2.6% higher accuracy with -33% and -47% (lower) computation cost. Compared with the recent CycleMLP  For the small models, our extremely tiny variant ActiveMLP-xT achieves 79.7% with only 15M parameters and 2.2G FLOPs, which is on par with or even higher than the larger DeiT-S <ref type="bibr" target="#b12">[13]</ref>, PVT-S <ref type="bibr" target="#b15">[16]</ref>, gMLP-S <ref type="bibr" target="#b73">[74]</ref>, EAMLP-14 <ref type="bibr" target="#b72">[73]</ref> and ResMLP-S24 <ref type="bibr" target="#b29">[30]</ref>, where the last two involves even twice computation cost than ActiveMLP-xT. For larger models, it is observed that the performance of previous MLP-like backbones are limited with model scale increasing, e.g., Shift-B <ref type="bibr" target="#b40">[41]</ref>, CycleMLP-B <ref type="bibr" target="#b30">[31]</ref>, S 2 MLP-W <ref type="bibr" target="#b31">[32]</ref>, ViP-L <ref type="bibr" target="#b39">[40]</ref> and ASMLP-B <ref type="bibr" target="#b28">[29]</ref> lags behind Swin-B, owing to the limitation of the stereotyped token-mixing rules. In contrast, our ATM's flexibility and effectiveness of tokenmixing helps our largest variant ActiveMLP-L achieves 83.6% accuracy with only 76M parameters and 12G FLOPs, which is -14% and -20% than that of Swin-B respectively. The comparison results with some prevailing MLPs and Swin are also illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>Note that most MLP-like backbones (e.g., MLP-Mixer <ref type="bibr" target="#b27">[28]</ref>, ResMLP <ref type="bibr" target="#b29">[30]</ref>, gMLP <ref type="bibr" target="#b73">[74]</ref>, ResMLP <ref type="bibr" target="#b29">[30]</ref>, ViP <ref type="bibr" target="#b39">[40]</ref>, sMLP <ref type="bibr" target="#b33">[34]</ref> and etc) in <ref type="table" target="#tab_1">Table 2</ref> are not validated in downstream dense prediction tasks, where the most architectures are not compatible with various input resolutions. In contrast, our ActiveMLP is capable of dealing with different input scales, and shows pronounced performance on dense prediction tasks, which will be shown in the following sections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Semantic Segmentation</head><p>Settings. Following the common practice <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b40">41]</ref>, we evaluate the potential of Ac-tiveMLP on the challenging semantic segmentation task on ADE20K <ref type="bibr" target="#b74">[75]</ref>, which contains 20K training and 2K validation images. We adopt two widely used frameworks, Semantic FPN <ref type="bibr" target="#b82">[83]</ref> and UperNet <ref type="bibr" target="#b84">[85]</ref>, with ActiveMLP pretrained on ImageNet-1K as backbone. For Semantic FPN, we mostly follow the setting of PVT <ref type="bibr" target="#b15">[16]</ref> to train 40K iterations with batchsize of 32. For UperNet, we mostly follow the setting of Swin <ref type="bibr" target="#b13">[14]</ref> to train 160K steps with batchsize of 16. Stochastic depth augmentation is adopted to avoid model overfitting. More experimental details can be found in the Supplementary.</p><p>Results of Semantic FPN. The mIoU comparisons are shown in <ref type="table" target="#tab_2">Table 3</ref>. It is appealing that our smallest model ActiveMLP-xT achieves 43.0% mIoU, which is on par with some Tiny-level backbones (e.g., Twins-S <ref type="bibr" target="#b14">[15]</ref>, MorphMLP-T <ref type="bibr" target="#b32">[33]</ref>), or even surpasses Swin-T (+1.5%) and PVT-T (+3.2%) with a clear margin. For the larger models, our ActiveMLP-S attains the best result (47.3% mIoU) with only 42.4M parameters. When scaling up to 80+M models, ActiveMLP-L outperforms previous state-of-the-art Twins-L by +1.4% mIoU with -23% parameters and -16% GFLOPs.</p><p>Results of UperNet. We compare with the recent backbones under the more powerful framework UperNet <ref type="bibr" target="#b84">[85]</ref> in <ref type="table" target="#tab_3">Table 4</ref>. For all different model scales, ActiveMLP outperforms all previous methods with comparable computation cost. Our largest model ActiveMLP-L achieves the new state-ofthe-art (51.1% MS mIoU), which surpasses the representative Swin-B by +1.4% mIoU with -10% parameters. The ActiveMLP-L also achieves higher segmentation mIoU compared with previous CNN-based methods, and SETR <ref type="bibr" target="#b64">[65]</ref> whose backbone is pretrained on the larger-scale ImageNet-22K.</p><p>From <ref type="table" target="#tab_2">Table 3</ref> and <ref type="table" target="#tab_3">Table 4</ref>, it is observed that most previous MLP-like backbones (e.g., CycleMLP, ASMLP, MorphMLP) behave better than Transformer-based Swin/Twins for smaller models, but lag behind Swin/Twins for larger models clearly. The manually designed token-mixing manner heavily limits them from exploring the flexible features patterns, while the global-scope attention in Transformers allows extracting better representations when model scaling up. In contrast, Ac-tiveMLP shows its strong capability for semantic segmentation for various scale models, especially the larger ones. We reckon the superiority of ActiveMLP lies in the flexibility of ATM, which provides models with great capability to exploit sufficient feature patterns from visual signals with various scales and deformations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Object Detection</head><p>Settings. We further evaluate the performance of our ActiveMLP on object detection task on the COCO <ref type="bibr" target="#b75">[76]</ref> dataset. To thoroughly compare our ActiveMLP with other methods, we adopt three representative detection frameworks, i.e., Mask R-CNN <ref type="bibr" target="#b89">[90]</ref>, RetinaNet <ref type="bibr" target="#b90">[91]</ref> and Casecade Mask R-CNN <ref type="bibr" target="#b91">[92,</ref><ref type="bibr" target="#b89">90]</ref>. We report the standard 1? schedule (12 epochs) and 3? MS schedule (36 epochs) detection results on COCO 2017 val. We also conduct 1? MS experiments, following Swin's setting <ref type="bibr" target="#b13">[14]</ref>, with (Cascade) Mask R-CNN. Stochastic depths are adopted to avoid model overfiting. Detailed configurations can be found in the Supplementary.</p><p>Results. The object detection results for Mask R-CNN 1? and RetinaNet 1?, together with the instance segmentation results for Mask R-CNN 1?, are shown in <ref type="table" target="#tab_4">Table 5</ref>. Thanks to the ATM's flexibility and effectiveness for token-mixing, our ActiveMLP obtains promising results on the challenging object detection task. ActiveMLP achieves the state-of-the-art for the most model scales with different detectors. Compared with recent MLP-like methods, ActiveMLP's improvement is pronounced. For example, ActiveMLP-xT, -T, -S and -L outperform the best MLPs WaveMLP <ref type="bibr" target="#b41">[42]</ref> variants (-T, -S, -M and -B) by +0.8%, +0.2%, +0.6% and +1.9% mAP b respectively for the RetinaNet 1? setting. ActiveMLP-S's performance is also on top of that of Transformers. For the Mask R-CNN 1? setting, our different model variants outperform the corresponding parametercomparable Swin variants by +2.6%/+1.9% , +1.7%/+1.6% and +1.9%/+1.1% mAP b /mAP m respectively, which demonstrates the ActiveMLP's superiority on dense prediction task, where the input is usually with larger resolution. For the largest models, ActiveMLP-L surpasses the state-ofthe-art Twins-L by +1.5% and +0.4% mAP b , with -20% and -23% parameters, for Mask R-CNN and RetinaNet respectively</p><p>We also report the results for the Mask R-CNN 1? MS and RetinaNet 3? settings in <ref type="table" target="#tab_5">Table 6</ref>, where ActiveMLP-L outperforms Swin-B by +0.8% and +1.7% mAP, with -10% and -13% parameters, for two settings respectively. The results for Mask R-CNN 3? and Cascade Mask R-CNN 1?/3? with similar trends are in the Supplementary due to the space constraint.</p><p>From the object detection results, we find again that previous MLP-like backbones (e.g., CycleMLP, WaveMLP) show inferior performance on larger models, though they show their superiority on smaller models, owing to the limitation induced by the manually designed token-mixing fashion. In contrast, our flexible ATM shows its capability for efficient spatial information interaction for various scale models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Analysis</head><p>We conduct our ablation experiments with a simplified ActiveMLP-T * , where we only generate one set of offsets for each stage. The ablation study results are shown in <ref type="table" target="#tab_6">Table 7</ref>, where the baseline model x is only composed of channel-mixing MLPs, i.e., all offsets in our ActiveMLP are set to 0.  <ref type="figure">Figure 3</ref>: Histogram of learned horizontal offsets for the center token from different layers of stage 3, which is counted on 1K images randomly sampled from COCO dataset. The spatial resolution of feature is 38 ? 50 with the input size of 600 ? 800.</p><p>The effectiveness of ATM. Though there is no information interaction between different tokens in the MLP-based baseline x, it still achieves 79.3% classification accuracy on ImageNet-1K due to model overfitting. However, the performance on the dense prediction tasks (e.g., object detection and instance segmentation) is quite bounded, where the pretrained model is difficult to be adapted to downstream tasks. This also validates that the token information mixing is vital for the dense prediction tasks. With our proposed ATM w/o PEG <ref type="bibr" target="#b60">[61]</ref> (y), the classification accuracy is improved by +2.5%, and the performance on the dense prediction task is significantly improved by a large margin (+8.2% mAP b and +6.0% mAP m on COCO). Our proposed ATM brings efficient token information interaction to help extract more powerful feature representations with negligible additional computation overhead. The PEG <ref type="bibr" target="#b60">[61]</ref> module is introduced for providing position information for the offset generation procedure, which has no influence on image classification, but helps a little for object detection.</p><p>Comparison with the token-level deformable operation. To show the effectiveness of our ATM, we conduct a comparison experiment {, where we replace ATM with the token-level deformable operator, i.e., the number of generated offsets |O| = 1 for each query token. In contrast, our ActiveMLP allows respective offsets for different channels to capture the diverse channel semantics. The results of { plummet drastically, due to the improper token-mixing. Our ATM is more efficient at information interaction with negligible computation overhead.</p><p>Distribution of offsets. We show the histogram of the learned horizontal offsets for the center token from different layers, averaged over randomly sampled 1000 images from COCO, in <ref type="figure">Fig. 3</ref>. The receptive field is enlarged with layer going deeper. For the 19 th layer of stage 3, the selected tokens spread in the maximum range of 44 with width W = 50. This validates that ActiveMLP's superiority of capturing global information with the flexible ATM, which is required for dense prediction tasks. More visualizations of offsets are shown in the Supplementary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this work, we present a generally applicable MLP-like backbone ActiveMLP for computer vision. In ActiveMLP, we propose an innovative token mixer mechanism, ATM, which actively and adaptively learns to incorporate contextual information from other tokens in the global scope into the given query token. Equipped with ATM, ActiveMLP is capable of capturing flexible and diverse visual patterns efficiently. Comprehensive experiments demonstrate our ActiveMLP is applicable across various vision tasks, and it shows remarkable performance on image classification, object detection and semantic segmentation. In the future work, we will exploit ActiveMLP's potential of dealing with temporal video signals.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>The comparison of the Top-1 accuracy on ImageNet-1K and the computation complexity (FLOPs) for different backbones. The circle size corresponds to the amount of model parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of a) the proposed Active Token Mixer (ATM) module and b) the detailed ATM on the horizontal (width) dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Model settings and performance for different variants. The FLOPs results are calculated with the input resolution of 224?224. ImageNet-1K: top-1 accuracy. COCO: mAP for detection and segmentation with Mask R-CNN 1x MS setting.</figDesc><table><row><cell></cell><cell>xTiny</cell><cell>Tiny</cell><cell>Small</cell><cell>Base</cell><cell>Large</cell></row><row><cell>#Param. (M)</cell><cell>15.4</cell><cell>27.2</cell><cell>38.6</cell><cell>51.9</cell><cell>76.4</cell></row><row><cell>FLOPs (G)</cell><cell>2.2</cell><cell>4.0</cell><cell>6.9</cell><cell>10.1</cell><cell>12.3</cell></row><row><cell>ImageNet-1K (%)</cell><cell>79.7</cell><cell>82.0</cell><cell>83.0</cell><cell>83.5</cell><cell>83.6</cell></row><row><cell>COCO (mAP)</cell><cell cols="5">42.9 39.3 45.8 41.6 46.8 42.5 47.0 42.7 47.4 43.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Comparison with sota models on ImageNet-1K without extra data. All models are trained with input resolution of 224?224, except ? with 384?384. #P: number of model parameters. FLOPs are evaluated on 224?224 resolution.</figDesc><table><row><cell>Model</cell><cell>Arch.</cell><cell>#P. (M)</cell><cell>FLOPs (G)</cell><cell>Top-1 (%)</cell><cell>Model</cell><cell>Arch.</cell><cell>#P. (M)</cell><cell>FLOPs (G)</cell><cell>Top-1 (%)</cell></row><row><cell>ResNet18[7]</cell><cell>CNN</cell><cell>12</cell><cell>1.8</cell><cell>69.8</cell><cell>PVT-L [16]</cell><cell>Trans</cell><cell>61</cell><cell>9.8</cell><cell>81.7</cell></row><row><cell>PVTv2-B1 [35]</cell><cell>Trans</cell><cell>13</cell><cell>2.1</cell><cell>78.7</cell><cell>Swin-S [14]</cell><cell>Trans</cell><cell>50</cell><cell>8.7</cell><cell>83.2</cell></row><row><cell cols="2">ResMLP-S12 [30] MLP</cell><cell>15</cell><cell>3.0</cell><cell>76.6</cell><cell>Twins-B [15]</cell><cell>Trans</cell><cell>56</cell><cell>8.6</cell><cell>83.2</cell></row><row><cell cols="2">CycleMLP-B1 [31] MLP</cell><cell>15</cell><cell>2.1</cell><cell>78.9</cell><cell>GFNet-H-B [72]</cell><cell>FFT</cell><cell>54</cell><cell>8.4</cell><cell>82.9</cell></row><row><cell>ActiveMLP-xT</cell><cell>MLP</cell><cell>15</cell><cell>2.2</cell><cell>79.7</cell><cell>Mixer-B/16 [28]</cell><cell>MLP</cell><cell>59</cell><cell>12.7</cell><cell>76.4</cell></row><row><cell>ResNet50[7] Deit-S[13]</cell><cell>CNN Trans</cell><cell>26 22</cell><cell>4.1 4.6</cell><cell>78.5 79.8</cell><cell>EAMLP-19 [73] S 2 MLP-D [32]</cell><cell>MLP MLP</cell><cell>55 51</cell><cell>-10.5</cell><cell>79.4 80.7</cell></row><row><cell>PVT-S[16]</cell><cell>Trans</cell><cell>25</cell><cell>3.8</cell><cell>79.8</cell><cell>ViP-M [40]</cell><cell>MLP</cell><cell>55</cell><cell>16.3</cell><cell>82.7</cell></row><row><cell>Swin-T[14]</cell><cell>Trans</cell><cell>29</cell><cell>4.6</cell><cell>81.2</cell><cell>Shift-S [41]</cell><cell>MLP</cell><cell>50</cell><cell>8.8</cell><cell>82.8</cell></row><row><cell>TwinsP-S [15]</cell><cell>Trans</cell><cell>24</cell><cell>3.8</cell><cell>81.2</cell><cell cols="2">CycleMLP-B4 [31] MLP</cell><cell>52</cell><cell>10.1</cell><cell>83.0</cell></row><row><cell>TNT-S [71]</cell><cell>Trans</cell><cell>24</cell><cell>5.2</cell><cell>81.3</cell><cell>ASMLP-S [29]</cell><cell>MLP</cell><cell>50</cell><cell>8.5</cell><cell>83.1</cell></row><row><cell>Twins-S [15]</cell><cell>Trans</cell><cell>24</cell><cell>2.9</cell><cell>81.7</cell><cell cols="2">MorphMLP-B [33] MLP</cell><cell>58</cell><cell>10.2</cell><cell>83.2</cell></row><row><cell>GFNet-H-S [72]</cell><cell>FFT</cell><cell>32</cell><cell>4.5</cell><cell>81.5</cell><cell>ActiveMLP-B</cell><cell>MLP</cell><cell>52</cell><cell>10.1</cell><cell>83.5</cell></row><row><cell>EAMLP-14 [73]</cell><cell>MLP</cell><cell>30</cell><cell>-</cell><cell>78.9</cell><cell>ViT-B/16 ? [12]</cell><cell>Trans</cell><cell>86</cell><cell>55.4</cell><cell>77.9</cell></row><row><cell cols="2">ResMLP-S24 [30] MLP</cell><cell>30</cell><cell>6.0</cell><cell>79.4</cell><cell>Deit-B [13]</cell><cell>Trans</cell><cell>86</cell><cell>17.5</cell><cell>81.8</cell></row><row><cell>gMLP-S [74]</cell><cell>MLP</cell><cell>20</cell><cell>4.5</cell><cell>79.4</cell><cell>CPVT-B [61]</cell><cell>Trans</cell><cell>88</cell><cell>17.6</cell><cell>82.3</cell></row><row><cell>ASMLP-T [29]</cell><cell>MLP</cell><cell>28</cell><cell>4.4</cell><cell>81.3</cell><cell>Deit-B ? [13]</cell><cell>Trans</cell><cell>86</cell><cell>55.4</cell><cell>83.1</cell></row><row><cell>ViP-S [40]</cell><cell>MLP</cell><cell>25</cell><cell>6.9</cell><cell>81.5</cell><cell>Swin-B [14]</cell><cell>Trans</cell><cell>88</cell><cell>15.4</cell><cell>83.5</cell></row><row><cell cols="2">MorphMLP-T [33] MLP</cell><cell>23</cell><cell>3.9</cell><cell>81.6</cell><cell>S 2 MLP-W [32]</cell><cell>MLP</cell><cell>71</cell><cell>14.0</cell><cell>80.0</cell></row><row><cell cols="2">CycleMLP-B2[31] MLP</cell><cell>27</cell><cell>3.9</cell><cell>81.6</cell><cell cols="2">ResMLP-B24 [30] MLP</cell><cell>116</cell><cell>23.0</cell><cell>81.0</cell></row><row><cell>Shift-T [41]</cell><cell>MLP</cell><cell>29</cell><cell>4.5</cell><cell>81.7</cell><cell>gMLP-B [74]</cell><cell>MLP</cell><cell>73</cell><cell>15.8</cell><cell>81.6</cell></row><row><cell>ActiveMLP-T</cell><cell>MLP</cell><cell>27</cell><cell>4.0</cell><cell>82.0</cell><cell cols="2">CycleMLP-B5 [31] MLP</cell><cell>76</cell><cell>15.3</cell><cell>83.1</cell></row><row><cell>PVT-M [16]</cell><cell>Trans</cell><cell>44</cell><cell>6.7</cell><cell>81.2</cell><cell>ViP-L [40]</cell><cell>MLP</cell><cell>88</cell><cell>24.4</cell><cell>83.2</cell></row><row><cell>TwinsP-B [15]</cell><cell>Trans</cell><cell>44</cell><cell>6.7</cell><cell>82.7</cell><cell>Shift-B [41]</cell><cell>MLP</cell><cell>89</cell><cell>15.6</cell><cell>83.3</cell></row><row><cell>GFNet-B [72]</cell><cell>FFT</cell><cell>43</cell><cell>7.9</cell><cell>80.7</cell><cell>ASMLP-B [29]</cell><cell>MLP</cell><cell>88</cell><cell>15.2</cell><cell>83.3</cell></row><row><cell cols="2">MorphMLP-S [33] MLP</cell><cell>38</cell><cell>7.0</cell><cell>82.6</cell><cell>MorphMLP-L</cell><cell>MLP</cell><cell>76</cell><cell>12.5</cell><cell>83.4</cell></row><row><cell cols="2">CycleMLP-B3 [31] MLP</cell><cell>38</cell><cell>6.9</cell><cell>82.6</cell><cell cols="2">CyceleMLP-B [31] MLP</cell><cell>88</cell><cell>15.2</cell><cell>83.4</cell></row><row><cell>ActiveMLP-S</cell><cell>MLP</cell><cell>39</cell><cell>6.9</cell><cell>83.0</cell><cell>ActiveMLP-L</cell><cell>MLP</cell><cell>76</cell><cell>12.3</cell><cell>83.6</cell></row><row><cell cols="2">4 Experiments</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>In Sec. 4.1, 4.2 and 4.3, we evaluate ActiveMLP on three vision tasks, including image classification, semantic segmentation based on two different frameworks on ADE20K dataset [75] and object detection based on three different frameworks on COCO dataset [76] under seven settings. More analyses are presented in Sec. 4.4.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Semantic segmentation results on ADE20K val with Semantic FPN<ref type="bibr" target="#b82">[83]</ref>. FLOPs are evaluated on 512?512 resolution. All backbones are pretrained on ImageNet-1K.</figDesc><table><row><cell>Model</cell><cell>Arch.</cell><cell>#P. (M)</cell><cell>FLOPs (G)</cell><cell>mIoU</cell><cell>Model</cell><cell>Arch.</cell><cell>#P. (M)</cell><cell>FLOPs (G)</cell><cell>mIoU</cell></row><row><cell>ResNet18 [7]</cell><cell cols="2">CNN 15.5</cell><cell>32</cell><cell>32.9</cell><cell>ResNet101 [7]</cell><cell>CNN</cell><cell>47.5</cell><cell>65</cell><cell>38.8</cell></row><row><cell>PVT-T [16]</cell><cell cols="2">Trans 17.0</cell><cell>33</cell><cell>35.7</cell><cell>PVT-M [16]</cell><cell cols="2">Trans 48.0</cell><cell>61</cell><cell>41.6</cell></row><row><cell>P2T-T [84]</cell><cell cols="2">Trans 14.9</cell><cell>32</cell><cell>39.5</cell><cell>TwinsP-B [15]</cell><cell cols="2">Trans 48.1</cell><cell>55</cell><cell>44.9</cell></row><row><cell cols="3">CycleMLP-B1 [31] MLP 18.9</cell><cell>33</cell><cell>40.8</cell><cell>Swin-S [14]</cell><cell cols="2">Trans 53.2</cell><cell>70</cell><cell>45.2</cell></row><row><cell cols="3">WaveMLP-T [42] MLP 19.3</cell><cell>-</cell><cell>41.2</cell><cell>Twins-B [15]</cell><cell cols="2">Trans 60.4</cell><cell>67</cell><cell>45.3</cell></row><row><cell>ActiveMLP-xT</cell><cell cols="2">MLP 19.1</cell><cell>33.1</cell><cell>43.0</cell><cell cols="2">CycleMLP-B3 [31] MLP</cell><cell>42.1</cell><cell>58</cell><cell>44.3</cell></row><row><cell>ResNet50 [7]</cell><cell cols="2">CNN 28.5</cell><cell>46</cell><cell>36.7</cell><cell cols="2">WaveMLP-M [42] MLP</cell><cell>43.3</cell><cell>-</cell><cell>46.8</cell></row><row><cell>PVT-S [16]</cell><cell cols="2">Trans 28.2</cell><cell>45</cell><cell>39.8</cell><cell>ActiveMLP-S</cell><cell>MLP</cell><cell>42.4</cell><cell>57.8</cell><cell>47.3</cell></row><row><cell>Swin-T [14]</cell><cell cols="2">Trans 31.9</cell><cell>46</cell><cell>41.5</cell><cell>ResNeXt101 [9]</cell><cell>CNN</cell><cell>86.4</cell><cell>104</cell><cell>40.2</cell></row><row><cell>Twins-S [15]</cell><cell cols="2">Trans 28.3</cell><cell>37</cell><cell>43.2</cell><cell>PVT-L [16]</cell><cell cols="2">Trans 65.1</cell><cell>80</cell><cell>42.1</cell></row><row><cell>TwinsP-S [15]</cell><cell cols="2">Trans 28.4</cell><cell>40</cell><cell>44.3</cell><cell>Swin-B [14]</cell><cell cols="2">Trans 91.2</cell><cell>107</cell><cell>46.0</cell></row><row><cell>P2T-S [84]</cell><cell cols="2">Trans 26.8</cell><cell>42</cell><cell>44.4</cell><cell>TwinsP-L [15]</cell><cell cols="2">Trans 65.3</cell><cell>71</cell><cell>46.4</cell></row><row><cell>GFNet-T [72]</cell><cell>FFT</cell><cell>26.6</cell><cell>-</cell><cell>41.0</cell><cell>Twins-L [15]</cell><cell cols="2">Trans 103.7</cell><cell>102</cell><cell>46.7</cell></row><row><cell cols="3">MorphMLP-T [33] MLP 26.4</cell><cell>-</cell><cell>43.0</cell><cell cols="2">CycleMLP-B5 [31] MLP</cell><cell>79.4</cell><cell>86</cell><cell>45.5</cell></row><row><cell cols="3">CycleMLP-B2 [31] MLP 30.6</cell><cell>42</cell><cell>43.4</cell><cell cols="2">MorphMLP-B [33] MLP</cell><cell>59.3</cell><cell>-</cell><cell>45.9</cell></row><row><cell cols="3">Wave-MLP-S [42] MLP 31.2</cell><cell>-</cell><cell>44.4</cell><cell>ActiveMLP-B</cell><cell>MLP</cell><cell>55.9</cell><cell>74.7</cell><cell>47.7</cell></row><row><cell>ActiveMLP-T</cell><cell cols="2">MLP 30.9</cell><cell>42.4</cell><cell>45.8</cell><cell>ActiveMLP-L</cell><cell>MLP</cell><cell>79.8</cell><cell>86.6</cell><cell>48.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc><ref type="bibr" target="#b30">[31]</ref>, our five variants outperforms the corresponding CycleMLP variants by +0.8%, +0.4%, +0.4%, +0.5% and +0.5% respectively, with comparable computation cost.</figDesc><table><row><cell>Method</cell><cell>Backbone</cell><cell>#P. (M)</cell><cell>FLOPs (G)</cell><cell>SS mIoU</cell><cell>MS mIoU</cell><cell>Method</cell><cell>Backbone</cell><cell>#P. (M)</cell><cell>FLOPs (G)</cell><cell>SS mIoU</cell><cell>MS mIoU</cell></row><row><cell>UperNet [85]</cell><cell>ResNet101</cell><cell>86</cell><cell>1029</cell><cell>43.8</cell><cell>44.9</cell><cell></cell><cell>Swin-S [14]</cell><cell>81</cell><cell>1038</cell><cell>47.6</cell><cell>49.5</cell></row><row><cell>OCRNet [86]</cell><cell>HRNet-w48</cell><cell>71</cell><cell>664</cell><cell>-</cell><cell>45.7</cell><cell></cell><cell>TwinsP-B [15]</cell><cell>74</cell><cell>1073</cell><cell>47.1</cell><cell>48.4</cell></row><row><cell>ACNet [87] DNL [88] DLabV3+ [89] SETR-PUP [65] SETR-MLA [65]</cell><cell>ResNet101 ResNet101 ResNeSt-200 ViT-L ? ViT-L ?</cell><cell>69 69 88 310 308</cell><cell>1119 1249 1381 --</cell><cell>---48.6 48.6</cell><cell>45.9 46.0 48.4 50.1 50.3</cell><cell>UperNet [85]</cell><cell>Twins-B [15] ConvNeXt-T [53] ASMLP-S [29] CycleMLP-S [31] ActiveMLP-S</cell><cell>89 82 81 81 69</cell><cell>1078 1027 1024 1024 988</cell><cell>47.7 ---48.4</cell><cell>48.9 49.6 49.2 49.6 49.5</cell></row><row><cell>UperNet [85]</cell><cell>ActiveMLP-xT</cell><cell>45</cell><cell>889</cell><cell>44.3</cell><cell>45.4</cell><cell></cell><cell>ActiveMLP-B</cell><cell>82</cell><cell>1055</cell><cell>48.7</cell><cell>49.8</cell></row><row><cell></cell><cell>Swin-T [14]</cell><cell>60</cell><cell>945</cell><cell>44.5</cell><cell>45.8</cell><cell></cell><cell>Swin-B [14]</cell><cell>121</cell><cell>1188</cell><cell>48.1</cell><cell>49.7</cell></row><row><cell>UperNet [85]</cell><cell>Twins-S [15] TwinsP-S [15] ConvNeXt-T [53] ASMLP-T [29] CycleMLP-T [31]</cell><cell>54 55 60 60 60</cell><cell>931 983 939 937 937</cell><cell>46.2 46.2 ---</cell><cell>47.1 47.5 46.7 46.5 47.1</cell><cell>UperNet [85]</cell><cell cols="2">TwinsP-L [15] Twins-L [15] ConvNeXt-T [53] 122 92 133 ASMLP-B [29] 121 CycleMLP-B [31] 121</cell><cell>1179 1236 1170 1166 1166</cell><cell>48.6 48.8 ---</cell><cell>49.8 50.2 49.9 49.5 49.7</cell></row><row><cell></cell><cell>ActiveMLP-T</cell><cell>57</cell><cell>927</cell><cell>46.5</cell><cell>47.6</cell><cell></cell><cell>ActiveMLP-L</cell><cell>108</cell><cell>1106</cell><cell>50.1</cell><cell>51.1</cell></row></table><note>Semantic segmentation results on ADE20K val with UperNet [85]. FLOPs are evaluated on 512?2048 resolution. All backbones are pretrained on ImageNet-1K, except ? pretrained on ImageNet-22K. SS/MS: single-/multi-scale inference. Methods colored with gray are previous state-of-the-arts with different backbones, others are UperNet with different backbones.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>Object detection results on COCO val2017 with Mask R-CNN<ref type="bibr" target="#b89">[90]</ref> and RetinaNet<ref type="bibr" target="#b90">[91]</ref>. FLOPs comparisons can be found in theSupplementary.</figDesc><table><row><cell>Model</cell><cell cols="6">Mask R-CNN 1? #P/M AP b AP b 50 AP b 75 AP m AP m 50</cell><cell>AP m 75</cell><cell cols="7">RetinaNet 1? #P/M AP b AP b 50 AP b 75 APS APM APL</cell></row><row><cell>ResNet18 [7]</cell><cell>31</cell><cell>34.0</cell><cell>54.0</cell><cell>36.7</cell><cell>31.2</cell><cell>51.0</cell><cell>32.7</cell><cell>21</cell><cell>31.8</cell><cell>49.6</cell><cell>33.6</cell><cell>16.3</cell><cell>34.3</cell><cell>43.2</cell></row><row><cell>PVT-T [16]</cell><cell>33</cell><cell>36.7</cell><cell>59.2</cell><cell>39.3</cell><cell>35.1</cell><cell>56.7</cell><cell>37.3</cell><cell>23</cell><cell>36.7</cell><cell>56.9</cell><cell>38.9</cell><cell>22.6</cell><cell>38.8</cell><cell>50.0</cell></row><row><cell cols="2">CycleMLP-B1 [31] 35</cell><cell>39.4</cell><cell>61.4</cell><cell>43.0</cell><cell>36.8</cell><cell>58.6</cell><cell>39.1</cell><cell>25</cell><cell>38.6</cell><cell>59.1</cell><cell>40.8</cell><cell>21.9</cell><cell>41.8</cell><cell>50.7</cell></row><row><cell>WaveMLP-T [42]</cell><cell>35</cell><cell>41.5</cell><cell>63.7</cell><cell>45.4</cell><cell>38.2</cell><cell>60.9</cell><cell>40.7</cell><cell>25</cell><cell>40.4</cell><cell>61.0</cell><cell>43.4</cell><cell>24.9</cell><cell>43.7</cell><cell>51.7</cell></row><row><cell>ActiveMLP-xT</cell><cell>35</cell><cell>42.8</cell><cell>64.9</cell><cell>46.9</cell><cell>39.5</cell><cell>62.1</cell><cell>42.5</cell><cell>25</cell><cell>41.2</cell><cell>62.3</cell><cell>43.7</cell><cell>24.4</cell><cell>45.3</cell><cell>54.2</cell></row><row><cell>ResNet-50 [7]</cell><cell>44</cell><cell>38.0</cell><cell>58.6</cell><cell>41.4</cell><cell>34.4</cell><cell>55.1</cell><cell>36.7</cell><cell>38</cell><cell>36.3</cell><cell>55.3</cell><cell>38.6</cell><cell>19.3</cell><cell>40.0</cell><cell>48.8</cell></row><row><cell>PVT-S [16]</cell><cell>44</cell><cell>40.4</cell><cell>62.9</cell><cell>43.8</cell><cell>37.8</cell><cell>60.1</cell><cell>40.3</cell><cell>34</cell><cell>40.4</cell><cell>61.3</cell><cell>43.0</cell><cell>25.0</cell><cell>42.9</cell><cell>55.7</cell></row><row><cell>Swin-T [14]</cell><cell>48</cell><cell>42.2</cell><cell>64.6</cell><cell>46.2</cell><cell>39.1</cell><cell>61.6</cell><cell>42.0</cell><cell>29</cell><cell>41.5</cell><cell>62,1</cell><cell>44.2</cell><cell>25.1</cell><cell>44.9</cell><cell>55.5</cell></row><row><cell>TwinsP-S [15]</cell><cell>44</cell><cell>42.9</cell><cell>65.8</cell><cell>47.1</cell><cell>40.0</cell><cell>62.7</cell><cell>42.9</cell><cell>34</cell><cell>43.0</cell><cell>64.1</cell><cell>46.0</cell><cell>27.5</cell><cell>46.3</cell><cell>57.3</cell></row><row><cell>Twins-S [15]</cell><cell>44</cell><cell>43.4</cell><cell>66.0</cell><cell>47.3</cell><cell>40.3</cell><cell>63.2</cell><cell>43.4</cell><cell>34</cell><cell>43.0</cell><cell>64.2</cell><cell>46.3</cell><cell>28.0</cell><cell>46.4</cell><cell>57.5</cell></row><row><cell cols="2">CycleMLP-B2 [31] 47</cell><cell>42.1</cell><cell>64.0</cell><cell>45.7</cell><cell>38.9</cell><cell>61.2</cell><cell>41.8</cell><cell>37</cell><cell>40.9</cell><cell>61.8</cell><cell>43.4</cell><cell>23.4</cell><cell>44.7</cell><cell>53.4</cell></row><row><cell>WaveMLP-S [42]</cell><cell>47</cell><cell>44.0</cell><cell>65.8</cell><cell>48.2</cell><cell>40.0</cell><cell>63.1</cell><cell>42.9</cell><cell>37</cell><cell>43.4</cell><cell>64.4</cell><cell>46.5</cell><cell>26.6</cell><cell>47.1</cell><cell>57.1</cell></row><row><cell>ActiveMLP-T</cell><cell>47</cell><cell>44.8</cell><cell>66.9</cell><cell>49.0</cell><cell>41.0</cell><cell>64.2</cell><cell>44.3</cell><cell>37</cell><cell>43.6</cell><cell>64.9</cell><cell>46.8</cell><cell>27.2</cell><cell>47.5</cell><cell>57.9</cell></row><row><cell>ResNet-101 [7]</cell><cell>63</cell><cell>40.4</cell><cell>61.1</cell><cell>44.2</cell><cell>36.4</cell><cell>57.7</cell><cell>38.8</cell><cell>57</cell><cell>38.5</cell><cell>57.8</cell><cell>41.2</cell><cell>21.4</cell><cell>42.6</cell><cell>51.1</cell></row><row><cell>PVT-M [16]</cell><cell>64</cell><cell>42.0</cell><cell>64.4</cell><cell>45.6</cell><cell>39.0</cell><cell>61.6</cell><cell>42.1</cell><cell>54</cell><cell>41.9</cell><cell>63.1</cell><cell>44.3</cell><cell>25.0</cell><cell>44.9</cell><cell>57.6</cell></row><row><cell>TwinsP-B [15]</cell><cell>64</cell><cell>44.6</cell><cell>66.7</cell><cell>48.9</cell><cell>40.9</cell><cell>63.8</cell><cell>44.2</cell><cell>54</cell><cell>44.3</cell><cell>65.6</cell><cell>47.3</cell><cell>27.9</cell><cell>47.9</cell><cell>59.6</cell></row><row><cell>Swin-S [14]</cell><cell>69</cell><cell>44.8</cell><cell>66.6</cell><cell>48.9</cell><cell>40.9</cell><cell>63.4</cell><cell>44.2</cell><cell>60</cell><cell>44.5</cell><cell>65.7</cell><cell>47.5</cell><cell>27.4</cell><cell>48.0</cell><cell>59.9</cell></row><row><cell>Twins-B [15]</cell><cell>76</cell><cell>45.2</cell><cell>67.6</cell><cell>49.3</cell><cell>41.5</cell><cell>64.5</cell><cell>44.8</cell><cell>67</cell><cell>45.3</cell><cell>66.7</cell><cell>48.1</cell><cell>28.5</cell><cell>48.9</cell><cell>60.6</cell></row><row><cell cols="2">CycleMLP-B3 [31] 58</cell><cell>43.4</cell><cell>65.0</cell><cell>47.7</cell><cell>39.5</cell><cell>62.0</cell><cell>42.4</cell><cell>48</cell><cell>42.5</cell><cell>63.2</cell><cell>45.3</cell><cell>25.2</cell><cell>45.5</cell><cell>56.2</cell></row><row><cell>WaveMLP-M [42]</cell><cell>60</cell><cell>45.3</cell><cell>67.0</cell><cell>49.5</cell><cell>41.0</cell><cell>64.1</cell><cell>44.1</cell><cell>49</cell><cell>44.8</cell><cell>65.8</cell><cell>47.8</cell><cell>28.0</cell><cell>48.2</cell><cell>59.1</cell></row><row><cell>ActiveMLP-S</cell><cell>58</cell><cell>46.0</cell><cell>68.2</cell><cell>50.4</cell><cell>42.0</cell><cell>65.3</cell><cell>45.5</cell><cell>48</cell><cell>45.4</cell><cell>66.7</cell><cell>48.5</cell><cell>28.3</cell><cell>49.7</cell><cell>59.7</cell></row><row><cell>ActiveMLP-B</cell><cell>72</cell><cell>46.5</cell><cell>68.6</cell><cell>51.0</cell><cell>42.5</cell><cell>66.1</cell><cell>45.8</cell><cell>62</cell><cell>45.2</cell><cell>66.7</cell><cell>48.4</cell><cell>28.1</cell><cell>49.1</cell><cell>59.9</cell></row><row><cell>X101-64 [9]</cell><cell>102</cell><cell>42.8</cell><cell>63.8</cell><cell>47.3</cell><cell>38.4</cell><cell>60.6</cell><cell>41.3</cell><cell>96</cell><cell>41.0</cell><cell>60.9</cell><cell>44.0</cell><cell>23.9</cell><cell>45.2</cell><cell>54.0</cell></row><row><cell>PVT-L [16]</cell><cell>81</cell><cell>42.9</cell><cell>65.0</cell><cell>46.6</cell><cell>39.5</cell><cell>61.9</cell><cell>42.5</cell><cell>71</cell><cell>42.6</cell><cell>63.7</cell><cell>45.4</cell><cell>25.8</cell><cell>46.0</cell><cell>58.4</cell></row><row><cell>TwinsP-L [15]</cell><cell>81</cell><cell>45.4</cell><cell>-</cell><cell>-</cell><cell>41.5</cell><cell>-</cell><cell>-</cell><cell>71</cell><cell>45.1</cell><cell>66.4</cell><cell>48.4</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Twins-L [15]</cell><cell>120</cell><cell>45.9</cell><cell>-</cell><cell>-</cell><cell>41.6</cell><cell>-</cell><cell>-</cell><cell>111</cell><cell>45.7</cell><cell>67.1</cell><cell>49.2</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Swin-B [14]</cell><cell>107</cell><cell>45.5</cell><cell>-</cell><cell>-</cell><cell>42.1</cell><cell>-</cell><cell>-</cell><cell>98</cell><cell>44.7</cell><cell>65.9</cell><cell>47.8</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell cols="2">CycleMLP-B5 [31] 95</cell><cell>44.1</cell><cell>65.5</cell><cell>48.4</cell><cell>40.1</cell><cell>62.8</cell><cell>43.0</cell><cell>86</cell><cell>42.7</cell><cell>63.3</cell><cell>45.3</cell><cell>24.1</cell><cell>46.3</cell><cell>57.4</cell></row><row><cell>WaveMLP-B [42]</cell><cell>75</cell><cell>45.7</cell><cell>67.5</cell><cell>50.1</cell><cell>27.8</cell><cell>49.2</cell><cell>59.7</cell><cell>66</cell><cell>44.2</cell><cell>65.1</cell><cell>47.1</cell><cell>27.1</cell><cell>47.8</cell><cell>58.9</cell></row><row><cell>ActiveMLP-L</cell><cell>96</cell><cell>47.4</cell><cell>69.9</cell><cell>52.0</cell><cell>43.2</cell><cell>67.3</cell><cell>46.5</cell><cell>86</cell><cell>46.1</cell><cell>67.4</cell><cell>49.4</cell><cell>29.9</cell><cell>50.1</cell><cell>61.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>Object detection results on COCO val2017 with Mask R-CNN<ref type="bibr" target="#b89">[90]</ref> and RetinaNet<ref type="bibr" target="#b90">[91]</ref>. The FLOPs and the complete table with more results are in the Supplementary.</figDesc><table><row><cell>Model</cell><cell cols="6">Mask R-CNN 1? MS #P/M AP b AP b 50 AP b 75 AP m AP m 50</cell><cell>AP m 75</cell><cell cols="7">RetinaNet 3? #P/M AP b AP b 50 AP b 75 APS APM APL</cell></row><row><cell>PVT-T [16]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>23</cell><cell>39.4</cell><cell>59.8</cell><cell>42.0</cell><cell>25.5</cell><cell>42.0</cell><cell>52.1</cell></row><row><cell cols="2">ActiveMLP-xT 35</cell><cell>42.9</cell><cell>65.5</cell><cell>47.0</cell><cell>39.3</cell><cell>62.3</cell><cell>42.1</cell><cell>25</cell><cell>43.7</cell><cell>64.7</cell><cell>46.7</cell><cell>28.9</cell><cell>47.4</cell><cell>57.4</cell></row><row><cell>PVT-S [16]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>34</cell><cell>42.2</cell><cell>62.7</cell><cell>45.0</cell><cell>26.2</cell><cell>45.2</cell><cell>57.2</cell></row><row><cell>Swin-T [14]</cell><cell>48</cell><cell>43.7</cell><cell>66.6</cell><cell>47.7</cell><cell>39.8</cell><cell>63.3</cell><cell>42.7</cell><cell>39</cell><cell>45.0</cell><cell>65.9</cell><cell>48.4</cell><cell>29.7</cell><cell>48.9</cell><cell>58.1</cell></row><row><cell>ActiveMLP-T</cell><cell>47</cell><cell>45.8</cell><cell>68.3</cell><cell>50.3</cell><cell>41.6</cell><cell>65.2</cell><cell>44.2</cell><cell>37</cell><cell>45.8</cell><cell>66.9</cell><cell>49.2</cell><cell>29.9</cell><cell>49.3</cell><cell>59.9</cell></row><row><cell>PVT-M [16]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>54</cell><cell>43.2</cell><cell>63.8</cell><cell>46.1</cell><cell>27.3</cell><cell>46.3</cell><cell>58.9</cell></row><row><cell>Swin-S [14]</cell><cell>69</cell><cell>46.4</cell><cell>68.9</cell><cell>51.1</cell><cell>41.7</cell><cell>65.5</cell><cell>44.8</cell><cell>60</cell><cell>46.4</cell><cell>67.0</cell><cell>50.1</cell><cell>31.0</cell><cell>50.1</cell><cell>60.3</cell></row><row><cell>ActiveMLP-S</cell><cell>58</cell><cell>46.8</cell><cell>69.2</cell><cell>51.4</cell><cell>42.5</cell><cell>66.3</cell><cell>45.8</cell><cell>47</cell><cell>46.3</cell><cell>68.0</cell><cell>49.5</cell><cell>30.4</cell><cell>50.6</cell><cell>59.9</cell></row><row><cell>ActiveMLP-B</cell><cell>72</cell><cell>47.0</cell><cell>69.6</cell><cell>51.7</cell><cell>42.7</cell><cell>66.6</cell><cell>46.0</cell><cell>62</cell><cell>46.6</cell><cell>67.7</cell><cell>50.1</cell><cell>30.4</cell><cell>50.4</cell><cell>61.0</cell></row><row><cell>PVT-L [16]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>71</cell><cell>43.4</cell><cell>63.6</cell><cell>46.1</cell><cell>26.1</cell><cell>46.0</cell><cell>59.5</cell></row><row><cell>Swin-B [14]</cell><cell>107</cell><cell>46.9</cell><cell>69.8</cell><cell>51.2</cell><cell>42.1</cell><cell>66.3</cell><cell>44.9</cell><cell>98</cell><cell>45.8</cell><cell>66.4</cell><cell>49.1</cell><cell>29.9</cell><cell>49.4</cell><cell>60.3</cell></row><row><cell>ActiveMLP-L</cell><cell>96</cell><cell>47.7</cell><cell>70.3</cell><cell>52.4</cell><cell>43.1</cell><cell>67.5</cell><cell>46.2</cell><cell>86</cell><cell>47.5</cell><cell>68.8</cell><cell>51.2</cell><cell>31.5</cell><cell>51.4</cell><cell>62.0</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>Ablation study on ImageNet-1K and COCO. The third method z is our ActiveMLP-T * . The FLOPs are calculated with the input resolution of 224?224. COCO: Mask R-CNN 1? MS. ?2.0 43.1 ?6.4 39.5 ?4.6</figDesc><table><row><cell>ID.</cell><cell>Variants</cell><cell>#P.(M)</cell><cell>FLOPs(G)</cell><cell>Top-1 acc.</cell><cell cols="2">COCO mAP b mAP m</cell></row><row><cell>x</cell><cell>Baseline</cell><cell>26.8</cell><cell>3.9</cell><cell>79.3</cell><cell>36.7</cell><cell>34.9</cell></row><row><cell>y</cell><cell>+ATM w/o PEG</cell><cell>26.9</cell><cell>3.9</cell><cell>81.8 ?2.5</cell><cell cols="2">45.1 ?8.4 41.1 ?6.2</cell></row><row><cell>z</cell><cell>+ATM w/ PEG</cell><cell>26.9</cell><cell>3.9</cell><cell>81.8 ?2.5</cell><cell cols="2">45.6 ?8.9 41.5 ?6.6</cell></row><row><cell>{</cell><cell>z with |O| = 1</cell><cell>26.8</cell><cell>3.9</cell><cell>81.3</cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Imagenet classification with deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page">25</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Inception-v4, inceptionresnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1251" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Densely connected convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4700" to="4708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Aggregated residual transformations for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1492" to="1500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chongruo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhongyue</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Manmatha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08955</idno>
		<title level="m">Split-attention networks</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georg</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sylvain</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Training data-efficient image transformer distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herve</forename><surname>Jegou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2021-07" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="10347" to="10357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Swin transformer: Hierarchical vision transformer using shifted windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="10012" to="10022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Twins: Revisiting the design of spatial attention in vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxia</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Pyramid vision transformer: A versatile backbone for dense prediction without convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng-Ping</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="568" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Multiview transformers for video recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuehan</forename><surname>Shen Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhichao</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mi</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cordelia</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmid</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2201.04288</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Transreid: Transformer-based object re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuting</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pichao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15013" to="15022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Transformer meets tracker: Exploiting temporal context for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wengang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houqiang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1571" to="1580" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Segformer: Simple and efficient design for semantic segmentation with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiding</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anima</forename><surname>Anandkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Per-pixel classification is not all you need for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">End-to-end human pose and mesh reconstruction with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1954" to="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deformable {detr}: Deformable transformers for end-to-end object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xizhou</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijie</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lewei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Maskedattention mask transformer for universal image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bowen</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Schwing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rohit</forename><surname>Girdhar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.01527</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Transgan: Two pure transformers can make one strong gan, and that can scale up</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Keeping your eye on the ball: Trajectory attention in video transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mandela</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dylan</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Asano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Metze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jo?o F</forename><surname>Henriques</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Masked autoencoders are scalable vision learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.06377</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mlp-mixer: An all-mlp architecture for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Ilya O Tolstikhin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Houlsby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucas</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohua</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jessica</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Steiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">As-mlp: An axial shifted mlp architecture for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongze</forename><surname>Lian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xing</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenghua</forename><surname>Gao</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alaaeldin</forename><surname>El-Nouby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edouard</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gautier</forename><surname>Izacard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.03404</idno>
		<title level="m">Feedforward networks for image classification with data-efficient training</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">CycleMLP: A MLP-like architecture for dense prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shoufa</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Chongjian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Runjian</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">S2-mlp: Spatial-shift mlp architecture for vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunfeng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Morphmlp: A self-attention free, mlp-like backbone for image and video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David Junhao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunchang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yali</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shashwat</forename><surname>Chandra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luoqi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mike</forename><forename type="middle">Zheng</forename><surname>Shou</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.12527</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Sparse mlp for image recognition: Is self-attention really necessary?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanxin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yucheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenxuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Pvtv2: Improved baselines with pyramid vision transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenhai</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enze</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deng-Ping</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaitao</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Visual Media</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Cswin transformer: A general vision transformer backbone with cross-shaped windows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyi</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongdong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nenghai</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.00652</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Improved multiscale vision transformers for classification and detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanghao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chao-Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karttikeya</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Mangalam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Feichtenhofer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2112.01526</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Going deeper with image transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexandre</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Herv?</forename><surname>J?gou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="32" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Focal self-attention for local-global interactions in vision transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianwei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiyang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Vision permutator: A permutable mlp-like architecture for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">When shift operation meets vision transformer: An extremely simple alternative to attention mechanism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yucheng</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chuanxin</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">An image patch is a wave: Phase-aware vision mlp</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yehui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanxi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.12294</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Understanding the role of individual units in a deep neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Bau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun-Yan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hendrik</forename><surname>Strobelt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Agata</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="30071" to="30078" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Stylespace analysis: Disentangled controls for stylegan image generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongze</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dani</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="12863" to="12872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6105" to="6114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Mnasnet: Platform-aware neural architecture search for mobile</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruoming</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2820" to="2828" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Deep high-resolution representation learning for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Borui</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaorui</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yadong</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingkui</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinggang</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="3349" to="3364" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Repvgg: Making vgg-style convnets great again</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohan</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ningning</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungong</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guiguang</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="13733" to="13742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Designing network design spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilija</forename><surname>Radosavovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raj</forename><forename type="middle">Prateek</forename><surname>Kosaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="10428" to="10436" />
		</imprint>
	</monogr>
	<note>Kaiming He, and Piotr Doll?r</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Rupesh Kumar Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schmidhuber</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.00387</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">Highway networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanzi</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao-Yuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<title level="m">Trevor Darrell, and Saining Xie. A convnet for the 2020s. CVPR</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijun</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Andreetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1704.04861</idno>
		<title level="m">Mobilenets: Efficient convolutional neural networks for mobile vision applications</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Sandler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menglong</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrey</forename><surname>Zhmoginov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
		<title level="m">Mobilenetv2: Inverted residuals and linear bottlenecks</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4510" to="4520" />
		</imprint>
	</monogr>
	<note>CVPR</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haozhi</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuwen</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guodong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yichen</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="764" to="773" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deformable convnets v2: More deformable, better results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xizhou</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jifeng</forename><surname>Dai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9308" to="9316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Multi-scale context aggregation by dilated convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladlen</forename><surname>Koltun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>ICLR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Attention is all you need. NeurIPS, 30</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Swin transformer v2: Scaling up capacity and resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ze</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutong</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuliang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenda</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yixuan</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Furu</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baining</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangxiang</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaxia</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2102.10882</idno>
		<title level="m">Conditional positional encodings for vision transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alaaeldin</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthijs</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ivan</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Natalia</forename><surname>Neverova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Verbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cross-covariance image transformers. NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Is space-time attention all you need for video understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gedas</forename><surname>Bertasius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">ICML</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Uniformer: Unified transformer for efficient spatiotemporal representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kunchang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yali</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guanglu</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Qiao</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">2022</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sixiao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiachen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hengshuang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiatian</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zekun</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yabiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanwei</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="6881" to="6890" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Transformer tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawen</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8126" to="8135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Loy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.13107</idno>
		<title level="m">Stransgan: An empirical study on transformer in gans</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Strip pooling: Rethinking spatial pooling for scene parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qibin</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4003" to="4012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Evan</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Trevor</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><forename type="middle">Lei</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><forename type="middle">Ryan</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.06450</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">Layer normalization. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Transformer in transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">An</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyuan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunjing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhe</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Global filter networks for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongming</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenliang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwen</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">Beyond self-attention: External attention using two linear layers for visual tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng-Ning</forename><surname>Meng-Hao Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tai-Jiang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shi-Min</forename><surname>Mu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.02358</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Pay attention to mlps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanxiao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zihang</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Semantic understanding of scenes through the ade20k dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xavier</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanja</forename><surname>Fidler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adela</forename><surname>Barriuso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonio</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="302" to="321" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc V</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="702" to="703" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moustapha</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Yann N Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lopez-Paz</surname></persName>
		</author>
		<title level="m">mixup: Beyond empirical risk minimization. ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Cutmix: Regularization strategy to train strong classifiers with localizable features</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sangdoo</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyoon</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyuk</forename><surname>Seong Joon Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junsuk</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youngjoon</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6023" to="6032" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Random erasing data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhun</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoliang</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaozi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="13001" to="13008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Deep networks with stochastic depth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Sedra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="646" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Decoupled weight decay regularization. ICLR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Hutter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Panoptic feature pyramid networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6399" to="6408" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Huan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Ming</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.12011</idno>
		<title level="m">P2t: Pyramid pooling transformer for scene understanding</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Unified perceptual parsing for scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tete</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingcheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bolei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="418" to="434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Object-contextual representations for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhui</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xilin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingdong</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="173" to="190" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Disentangled non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minghao</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuliang</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiu</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="191" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Liang-Chieh Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Cascade r-cnn: Delving into high quality object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaowei</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nuno</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6154" to="6162" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
