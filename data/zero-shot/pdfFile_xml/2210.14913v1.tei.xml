<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">AltUB: Alternating Training Method to Update Base Distribution of Normalizing Flow for Anomaly Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yeongmin</forename><surname>Kim</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Freshman</orgName>
								<orgName type="institution">KAIST</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiwon</forename><surname>Jang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematical Science</orgName>
								<orgName type="institution">KAIST</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongkeon</forename><surname>Lee</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">KAIST</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ho-Jin</forename><surname>Choi</surname></persName>
							<email>hojinc@kaist.ac.kr</email>
							<affiliation key="aff2">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">KAIST</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">AltUB: Alternating Training Method to Update Base Distribution of Normalizing Flow for Anomaly Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T16:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Unsupervised anomaly detection is coming into the spotlight these days in various practical domains due to the limited amount of anomaly data. One of the major approaches for it is a normalizing flow which pursues the invertible transformation of a complex distribution as images into an easy distribution as N (0, I). In fact, algorithms based on normalizing flow like FastFlow and CFLOW-AD establish state-of-the-art performance on unsupervised anomaly detection tasks. Nevertheless, we investigate these algorithms convert normal images into not N (0, I) as their destination, but an arbitrary normal distribution. Moreover, their performances are often unstable, which is highly critical for unsupervised tasks because data for validation are not provided. To break through these observations, we propose a simple solution AltUB which introduces alternating training to update the base distribution of normalizing flow for anomaly detection. AltUB effectively improves the stability of performance of normalizing flow. Furthermore, our method achieves the new state-of-the-art performance of the anomaly segmentation task on the MVTec AD dataset with 98.8% AUROC.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automated detection of anomalies has become an important area of computer vision in a variety of practical domains, including industrial <ref type="bibr" target="#b1">(Bergmann et al. 2019)</ref>, medical <ref type="bibr" target="#b18">(Zhou et al. 2020</ref>) field, and autonomous driving systems <ref type="bibr">(Jung et al. 2021)</ref>. The essential goal of anomaly detection (AD) is to classify whether an object is normal or abnormal, and localize the regions of an anomaly if the object is classified as an anomaly ). However, it is challenging to obtain a large number of abnormal images in real-world problems.</p><p>An unsupervised anomaly detection task has been introduced to address this imbalance in the dataset due to the lack of defected samples. To do so, it aims at detecting defection by using only the non-defected samples. That is why many recent approaches for unsupervised anomaly detection try to obtain representations of normal data and detect anomalies by comparing them with test samples' representations.</p><p>Learning representations of normal data in an unsupervised anomaly detection task is closely related to the goal of normalizing flow: the model learns invertible mapping of a complex distribution of normal samples into a simple distribution such as the normal distribution. The original usages of the normalizing flow are density estimation and generating data efficiently using invertible mappings <ref type="bibr" target="#b3">(Dinh, Sohl-Dickstein, and Bengio 2017;</ref><ref type="bibr">Kingma and Dhariwal 2018)</ref>, whereas some recent approaches <ref type="bibr" target="#b8">(Rudolph, Wandt, and Rosenhahn 2021;</ref><ref type="bibr" target="#b15">Yu et al. 2021;</ref><ref type="bibr">Gudovskiy, Ishizaka, and Kozuka 2022)</ref> begin to utilize the normalizing flow to tackle the unsupervised anomaly detection tasks. In particular, they have achieved state-of-the-art performance on the MVTec AD <ref type="bibr" target="#b1">(Bergmann et al. 2019</ref>) of the industrial domain.</p><p>Despite the success of normalizing flow-based anomaly detection models, they have a limitation for the unsupervised task: performances are unstable in many cases. Specifically, their test performances often fluctuate while training the model for a long time (e.g. 200 or 400 epochs). This drawback will be critical in every practical domain because one must use the unsupervised trained models that have been trained sufficiently. One possible reason is the limited expressive power of normalizing flow with the fixed base (prior) distribution. Current approaches as <ref type="bibr" target="#b8">Rudolph, Wandt, and Rosenhahn (2021)</ref>; <ref type="bibr" target="#b15">Yu et al. (2021)</ref>; <ref type="bibr">Gudovskiy, Ishizaka, and Kozuka (2022)</ref> fix the base distribution of normalizing flow as N (0, I). However, as depicted in Figures 1 (b) and (c), most outputs of the model do not follow N (0, I), while they utilize the likelihoods in the base distribution as a score function:</p><formula xml:id="formula_0">? exp 1 |C| c?C ? z T c z c 2 ,<label>(1)</label></formula><p>where C is an index set for output channels. Even the score function requires an assumption for the theoretical validity that normal samples are transformed to the base distribution while training, it fails for the models to learn N (0, I). This phenomenon occurs pervasively for normalizing flow-based anomaly detection models. To tackle this problem by considering the reason mentioned above, we propose an algorithm called the Alternating Training method to Update Base distribution (AltUB) that performs better and learns more stably with normalizing flow-based anomaly detection models. Our method introduces alternating updates to learn a base distribution more actively and to allow the model to adapt to   <ref type="bibr" target="#b10">(Shapiro and Wilk 1965)</ref> applied to values of each spatial location of each channel among outputs from normal images. The distribution with a p-value &gt; 0.05 is usually considered normal. (b) The result of the Kolmogorov-Smirnov test (KS-test) (Massey 1951) applied to the same ones with (a). p-value &gt; 0.05 implies the distribution is highly likely to be N (0, 1). (c) Visualization of one of the distributions. Ideally, it should follow N (0, 1). However its distribution is roughly N (2, 0.5). While training, the model learns so that likelihood is high and the anomaly score is low for normal samples.</p><p>the changed base distribution gradually. This simple but effective updating scheme improves the expressive power of the normalizing flow, especially for anomaly detection.</p><p>To verify the stability of our method under the unsupervised anomaly detection task, we measure the average performance for some training epoch intervals as well as the best performance. In the experimental results, our method improves the stability of normalizing flow-based anomaly detection models. In addition, our method achieves stateof-the-art performance on anomaly segmentation of both MVTec AD and BTAD datasets. These results support that our method is learning-stable and performing better.</p><p>Contributions In summary, we propose AltUB for the anomaly detection tasks with the following contributions.</p><p>? We investigate that normalizing flow models for anomaly detection commonly fail to transform normal images into N (0, I). ? We suggest the update of the base distribution can solve the above defect, and propose a proper method to update the base distribution: Alternating training. ? Our model achieves state-of-the-art performance on anomaly detection of MVTec AD and BTAD datasets.</p><p>2 Related work 2.1 Normalizing flow-based anomaly detection models</p><p>Unsupervised anomaly detection models based on normalizing flow have shown high performance on various practical tasks <ref type="bibr" target="#b8">(Rudolph, Wandt, and Rosenhahn 2021;</ref><ref type="bibr" target="#b15">Yu et al. 2021;</ref><ref type="bibr">Gudovskiy, Ishizaka, and Kozuka 2022)</ref>. Normalizing flowbased models first obtain representations of normal images from a pre-trained feature extractor. They utilize the representations to learn a distribution of normal data. Because of their simple yet powerful idea of invertible mappings, they effectively describe the distribution. To detect anomalies, they estimate the likelihood of the base distribution of test samples. However, their expressive power is not enough as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. It might cause of their low stability on performance while learning i.e. performance decreases as learning progresses. In this paper, we suggest a simple method to increase the expressive power of normal data to improve the AUROC score.  gressive prior by using ConvLSTMs to increase the expressive power of split coupling layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Methods</head><p>However, these approaches are not appropriate for anomaly detection tasks for the following reasons. First, the output seems to follow not only channel-wise but also spatial dimensional normal distribution. Second, the layers can't distinguish normal images and abnormal ones because these layers train not parameters of distribution but the way to get them from inputs. Note that reflection of the sample statistics from anomaly disrupts the detection.</p><p>Nevertheless, a methodology specially designed to train the distribution for anomaly detection has not been suggested yet. To address issues, we propose a proper method to update the base distribution for anomaly detection tasks.</p><p>3 Preliminary: Normalizing flow 3.1 Notation ? and ? represent the parameters of the normalizing flow and that of the base distribution, respectively. We use p(?) as a distribution and the probability density function of the distribution. p Z (?; ?) indicates the base distribution and p X (?; ?, ?) denotes the distribution induced from the base distribution by normalizing flow. In addition, p * X (?) is the data distribution that the model aims to learn, e.g. distribution of images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Fitting methodology</head><p>The idea of normalizing flow is from a change of random variables as</p><formula xml:id="formula_1">p X (x) = p Z (z) det ?z ?x .<label>(2)</label></formula><p>This implies that a complex distribution p X (?; ?, ?) can be factorized to simple and known distribution p Z (?; ?) using invertible mapping f ? : X ? Z. In general, the normalizing flow stack the invertible neural layers, f ? = f ?1 ? f ?2 ? ? ? ? ? f ?n to form the invertible mapping, where f ?i is the layer of neural network. To find the correct invertible mapping f ? with respect to the Z and X, we can use maximum likelihood estimation: estimating the parameters of distribution with random samples from the distribution. In particular, maximizing the likelihood can be done by maximizing log-likelihood, which is</p><formula xml:id="formula_2">log p X (x; ?, ?) = log p Z (f ? (x); ?)+log det ?f ? (x) ?x .</formula><p>(3) This objective function is based on the fact that maximizing the log-likelihood is equivalent to minimizing Monte Carlo <ref type="bibr" target="#b5">(Papamakarios et al. 2021</ref>).</p><formula xml:id="formula_3">approximation of D KL [ p * X (x) p X (x; ?, ?) ] on sample x from p * X (x)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">AltUB</head><p>In this section, we introduce AltUB, an effective method to update the base distribution of normalizing flow to enhance the expressive power of the flow and increase stability in detecting anomalies. We first state the limitations of prior normalizing flow-based works for anomaly detection, which affect the stability. Then, we propose our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Limitations of Non-trainable base distribution of normalizing flow</head><p>Normalizing flow-based anomaly detection models <ref type="bibr" target="#b8">(Rudolph, Wandt, and Rosenhahn 2021;</ref><ref type="bibr" target="#b15">Yu et al. 2021</ref>; Gudovskiy, Ishizaka, and Kozuka 2022) define normalizing flow f ? : X ? Z as a mapping from extracted features of images to simple, fixed distribution. e.g. N (0, I). The normalizing flow architecture is used for learning a distribution of representation of normal samples to detect out-of-distribution samples. However, <ref type="figure" target="#fig_0">Figure 1</ref> shows that the models seem to transform normal images into not N (0, I) as their purpose, but into several different normal distributions of CHW dimensions due to their low expressive power. The most simple way to enhance the expressive power is to stack more layers. In fact, Komologorov-Smirnov statistics and the train loss(negative log-likelihood) decrease as flow gets deeper as shown in <ref type="figure" target="#fig_2">Figure 3</ref> (a) and <ref type="figure" target="#fig_2">Figure 3 (b)</ref>. Nevertheless, the average of mean square tends to increase while adding more layers for shallow depth, which indicates the phenomenon of <ref type="figure" target="#fig_0">Figure 1</ref> (mean-shift) occurs. We guess the reason as follows: while an arbitrary distribution is transformed toward N (0, 1) along multiple layers of flow, the conversion into the normal distribution takes precedence over the proper adjustment of specific parameters as mean and variance. <ref type="figure" target="#fig_2">Figure 3</ref> (a) represents that the mean-shift decreases in the deeper depth than 8. We are able to easily figure out that the mean-shift phenomenon can be solved by increasing expressive power. However, stacking layers may not lead to higher performance (see <ref type="figure" target="#fig_2">Figure 3</ref> (c)) because of overfitting. In the other words, stacking more and more layers may disrupt learning the distribution of normal samples, even if it increases expressive power. Therefore, the flow model with non-trainable base distribution cannot break through the mean-shift simply.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Trainable base distribution of normalizing flow</head><p>As <ref type="figure" target="#fig_0">Figure 1</ref> and Section 4.1 show, a method that increases expressive power with a few layers is required to match the model output and score function. This method may improve the performance by using the right score function to find anomalies. Meanwhile, (Papamakarios, Pavlakou, and Murray 2017) proves that the following equation holds:</p><formula xml:id="formula_4">D KL [ p * X (x) p X (x; ?, ?) ] = D KL [ p * Z (z; ?) p Z (z; ?) ] ,<label>(4)</label></formula><p>where p * X (?) is a target distribution in X and p * Z (?; ?) is the induced from p * X (?) by normalizing flow f ? . The equation 4 means that the effective update of p Z (z; ?) toward p * Z (z; ?) leads p X (x; ?) to be similar as p * X (x). Therefore, we can increase the expressive power of models by updating the base distribution. Based on this fact, AltUB assumes the base distribution of the models to be N (?, ?), i.e. normal distribution with learnable parameters of CHW dimensions.</p><p>In our method, along with the parameters of normalizing flow ?, the parameters of base distribution ? are also trained with stochastic gradient-based methods using the gradient of negative log-likelihood (loss) as follows:</p><formula xml:id="formula_5">? ? L(?, ?) = ?? ? log pZ (f ? (x); ?) ? ? ? log det ?f ? (x) ?x ? ? L(?, ?) = ?? ? log pZ (f ? (x); ?),<label>(5)</label></formula><p>where L(?, ?) = ? log p X (x; ?, ?) is the negative loglikelihood of samples from X.</p><p>As an anomaly score of a test sample with C channels, we use the likelihoods in the base distribution:</p><formula xml:id="formula_6">? exp ?1 2|C| c?C (zc ? ?c) T ? ?1 (zc ? ?c) + ln | det ?c| ,<label>(6)</label></formula><p>Because we obtain the appropriate parameters of the base distribution from AltUB, our score function will detect the anomalies more precisely. </p><formula xml:id="formula_7">{Initialized to zero.} for batch B in X do Feature ? ?(B) Output ? f ? (Feature) Loss ? ? ln(Likelihood(Output, N (?, ?)) if E ? 0 mod FreezingInterval then U pdate({?, ?} , lr : ? 1 ) else ? ? ? ? ? 2 ?? end if end for</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">The method to train base distribution</head><p>When we assume the base distribution as N (?, ?), the gradient of negative log-likelihood of Equation 5 becomes as follows:</p><formula xml:id="formula_8">??L(?, ?, ?) = ? ?1 (? ? f ? (x)) ??L(?, ?, ?) = 1 2 ? ?1 I ? (f ? (x) ? ?)(f ? (x) ? ?) T ? ?1 .<label>(7)</label></formula><p>The loss function consists of subtraction, hence the gradients will be small. However, we observe that some outputs like <ref type="figure" target="#fig_0">Figure 1</ref> (c) are quite far from N (0, 1). Therefore, the parameters of the base distribution are not able to be trained effectively with the original learning rate of the main models, e.g. 0.001 of FastFlow. In addition, because the normalizing flow model learns slowly to find the distribution of representations of normal images, a consistently high learning rate for parameters of base distribution will harm the model. To train the base distribution well yet not harm the model to learn, the alternating training method is introduced. In general, a normalizing flow model and the base distribution are trained together with the original optimizer and learning rate ? 1 . But only the base distribution is trained with the larger learning rate ? 2 using an SGD optimizer once in a freezing interval. The detail is depicted in Algorithm 1.</p><p>Due to the high dimensionality of the space for base distribution, AltUB may suffer from computational complexity when using ?. This is because of the computational complexity to calculate ? ?1 in the gradients (about O(n 3 )). Therefore, we assume the independence of each dimension of the base distribution, as <ref type="bibr" target="#b8">(Rudolph, Wandt, and Rosenhahn 2021;</ref><ref type="bibr" target="#b15">Yu et al. 2021</ref>; Gudovskiy, Ishizaka, and Kozuka 2022) did. i.e. ? is assumed to be the diagonal matrix.</p><p>AltUB trains the value of parameters of the base distribution effectively, hence increasing the expressive power while helping to detect anomalies. Because AltUB is simple and independent of an upstream model, the proposed method can be applied to any normalizing flow model for anomaly detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setups</head><p>Datasets We evaluate our method on two datasets: MVTec AD <ref type="bibr" target="#b1">(Bergmann et al. 2019</ref>) and beanTech Anomaly Detection(BTAD) <ref type="bibr">(Mishra et al. 2021a)</ref> which are well-known as benchmark of anomaly detection models.</p><p>MVTec AD is a widely utilized dataset specifically designed for unsupervised anomaly detection. It consists of 5354 high-resolution images of industrial objects or patterns. In detail, it is composed of a total of 15 categories with 3629 images for training and validation and 1725 images for testing. We compare the proposed method with SSP-CAB+DRAEM <ref type="bibr" target="#b6">(Ristea et al. 2022;</ref><ref type="bibr" target="#b17">Zavrtanik, Kristan, and Skocaj 2021)</ref>, PatchCore <ref type="bibr" target="#b7">(Roth et al. 2021)</ref>, and CS-Flow <ref type="bibr" target="#b9">(Rudolph et al. 2022)</ref> which are current state-of-the-art models.</p><p>BTAD is a real-world dataset for industrial unsupervised anomaly detection. It comprises 2540 images divided into three categories of industrial products. The performance of our method on BTAD is compared with PatchSVDD (Yi and Yoon 2020), VT-ADL <ref type="bibr" target="#b4">(Mishra et al. 2021b)</ref>, and the method introduced in <ref type="bibr" target="#b12">(Tsai, Wu, and Lai 2022)</ref>.</p><p>Both MVTec AD and BTAD have only normal images in the training set whereas normal images and abnormal images are together in the test set.</p><p>Metrics The performance of models is measured by the Area Under the Receiver Operating Characteristic curve (AUROC) at the image or pixel level. which is a general metric for the evaluation of anomaly detection models. Meanwhile, the expected value of the performance is more practical than the best performance during training in unsupervised tasks because the validation set is not provided in the real world. In particular, the variance of the performance is also significant for stability. To achieve the purpose of realworld anomaly detection tasks, both the best and the average value of AUROC evaluated during the training process (from 100th epochs to 300th epochs) are adopted for comparison of normalizing flow-based models. We provide (mean, standard deviation) for average performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Anomaly detection and segmentation performance</head><p>We apply AltUB to FastFlow and CFLOW-AD which are well-known and well-performed NF models for anomaly detection. To be specific, we compare the performance of these original models and those of applied AltUB.</p><p>ResNet18 <ref type="formula">(</ref>  <ref type="figure">Figure 4</ref>: The pixel-wise AUROC is measured on the pill category of the MVTec AD dataset. FastFlow based on CaiT and that applied AltUB are compared.</p><p>FastFlow clearly achieves the new state-of-the-art performance on the anomaly segmentation task of the MVTec AD dataset. In addition, AltUB improves the stability of performance of NF models as <ref type="table" target="#tab_5">Table 2</ref>, in terms of the point that AltUB enhances the average performance and reduces its variance in most cases. One sample is depicted in <ref type="figure">Figure  4</ref>. This observation is consistent with FastFlow based on the other feature extractors. The full information about the performance is provided in the supplementary material A1.</p><p>BTAD For generalization, we evaluate the proposed method with BTAD. As <ref type="table" target="#tab_6">Table 3 and Table 4</ref>, AltUB also increases both the best performance and the stability of performance on BTAD except in one case. Our method also establishes the state-of-the-art performance on the anomaly segmentation task of BTAD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Examination for normalization</head><p>To examine whether AltUB is effective to update the base distribution, a one-sample Kolmogorov-Smirnov test (KStest) is utilized. One-sample KS statistic for an empirical cumulative density function (cdf) F n and a given cdf F is defined as</p><formula xml:id="formula_9">KS(F n , F ) = sup x |F n (x) ? F (x)| ? [0, 1],<label>(8)</label></formula><p>where n is the number of independent and identically distributed samples for the empirical distribution. KS(?, ?) converges to 0 as the two distribution is similar. Ideally, each spatial location of each channel of outputs corresponding to normal inputs shows the N (0, 1).</p><p>Let z = f ? <ref type="figure">(?(B)</ref>) be the output of flow model with the shape [B, C, H, W ]. Then, we can expect that z[:, c, h, w] ? N (0, 1) for every c, h, w. This also implies that z <ref type="bibr">[:, c, :, :]</ref> should follow N (0, 1).</p><p>For an original flow model, N (0, 1) and z[:, c, , ] are compared while N (0, 1) and (z[:, c, :, :] ? ?[c, :, :]) /?[c, :, :] are compared for our method by the KS-statistics. <ref type="table" target="#tab_8">Table 5</ref> apparently shows that our method achieves the lower KS statistic, <ref type="table">Table 1</ref>: Official anomaly detection and segmentation performance on MVTec AD dataset with the format (detection AUROC, segmentation AUROC). The performance of the proposed method is recorded as the best one during the training process. For FastFlow, the best one is chosen between the four distinct feature extractors. The performance with bold letters means the best one among these models. meaning that the base distribution is trained effectively. This observation supports our hypothesis that targets the expressive power and reveals the reason why AltUB can achieve higher and more stable performance effectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Comparison with other methods to update the base distribution</head><p>To justify the necessity of alternating training, we compare AltUB with other methods to train the base distribution in <ref type="table" target="#tab_9">Table 6</ref>. As we mentioned before, the general training (stereotype) with an original learning rate isn't effective as the learning rate isn't large enough. Update using CNN decreases the performance because CNN can't distinguish anomalies and the parameters of the base distribution are sensitive to the weight of CNN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Inference time</head><p>Because AltUB doesn't require complex calculations, the inference time has hardly increased. The analysis results are shown in <ref type="table" target="#tab_10">Table 7</ref>. The inference time is measured by Intel(R) CPU i7-12700K and NVIDIA GeForce RTX 3060.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Implementation details</head><p>In our method, ln ? 1 2 is trained instead of ? to have negative values for itself. In addition, ? and ln ? 1 2 are initialized to zero not to disrupt the initial training of the flow model.</p><p>We set the freezing interval as 5 epochs and ? 2 as a product of a constant and the original learning rate ? 1 , The constant is determined that the maximum value of ? 2 equals 0.05. Exceptionally AltUB is not applied during the warmup process of CFLOW-AD. We apply gradient clipping as much as 100 to the base distribution for FastFlow to prevent divergence of loss. Layer normalization is applied to outputs of FastFlow with WRN50 and CaiT. We fix the other hyperparameters of flow models as their original papers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we propose a simple yet effective method Al-tUB to enhance the expressive power of normalizing flow for anomaly detection. Our key idea is an alternating training method to learn the base distribution. In our experimental results, we prove the proposed method improves the stability of flow models for anomaly detection.</p><p>Limitations and future works Despite the success of our method, the performance still fluctuates in some cases. This fact implies that a more suitable training methodology can be suggested. From the point that our simple idea achieves meaningful progress for anomaly detection, an essential approach toward the higher expressive power to detect anomalies will be required.      </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Histograms of outputs of FastFlow. This figure shows that outputs of normalizing flow follow an arbitrary normal distribution, not the base distribution N (0, I). Feature extractor: CaiT, input: MVTec AD capsule category. (a) The result of the Shapiro-Wilk test</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The training process of AD flow+AltUB. The shaded (Flow, ?, ?) are trainable, and the two backward lines (blue solid line and red dotted line) indicate the alternating updates.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Various statistics and performance depend on the depth of normalizing flow. FastFlow with R18 is applied to the capsule category on MVTec AD. (a) The average of Kolmogorov-Smirnov statistics and mean square of outputs at 200th epochs. These statistics are calculated from each CHW dimension. (b) The pixel-level AUROCs were measured during the training. (1 &lt; 16 &lt; 8 &lt; 4 &lt; 2) (c) The training loss measured during the training. (16 &lt; 8 &lt; 4 &lt; 2 &lt; 1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>We do not perform detection with FastFlow as the way how to define anomaly score at image level is not clear.</figDesc><table><row><cell></cell><cell>0.990</cell><cell></cell><cell></cell><cell></cell></row><row><cell>pixel?level AUROC</cell><cell>0.975 0.980 0.985</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>FastFlow</cell></row><row><cell cols="2">R18) (He et al. 2016), WideResNet50 (WRN50) (Zagoruyko and Komodakis 2016), CaiT (Touvron et al. 2021b), and DeiT (Touvron et al. 2021a) for FastFlow, WRN50 for CFLOW-AD are utilized for feature extractors. We use anomalib (Akcay et al. 2022) for FastFlow imple-mentation because the official code of FastFlow is not pro-vided yet. 0.970</cell><cell>0</cell><cell>100</cell><cell>epoch</cell><cell>200 FastFlow+AltUB(Ours) 300</cell></row></table><note>MVTec AD First of all, the best performance during the training process is compared in Table 1. Our method with</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Anomaly detection and segmentation performance on MVTec AD dataset with the format (average of AUROC, standard deviation of AUROC). AUROCs are measured from the 100th epoch. For FastFlow, performances with the same feature extractor inTable 1are recorded for each category. The better performance between an original model and the one with AltUB is marked in bold letters.</figDesc><table><row><cell>Task type</cell><cell></cell><cell cols="2">Segmentation</cell><cell></cell><cell cols="2">Detection</cell></row><row><cell>Base model</cell><cell></cell><cell>FastFlow</cell><cell></cell><cell>CFLOW-AD</cell><cell></cell></row><row><cell></cell><cell>-</cell><cell>+ AltUB</cell><cell>-</cell><cell>+ AltUB</cell><cell>-</cell><cell>+ AltUB</cell></row><row><cell>Carpet</cell><cell cols="6">(98.5,0.22) (98.8,0.13) (99.2,0.09) (99.2,0.08) (97.6,0.24) (97.6,0.30)</cell></row><row><cell>Grid</cell><cell cols="6">(99.2,0.17) (99.3,0.02) (98.7,0.08) (98.7,0.08) (95.5,1.77) (96.0,1.51)</cell></row><row><cell>Leather</cell><cell cols="5">(99.6,0.03) (99.7,0.01) (99.6,0.04) (99.6,0.04) (100,0.02)</cell><cell>(100,0.03)</cell></row><row><cell>Tile</cell><cell cols="6">(96.9,0.55) (97.0,0.44) (97.8,0.17) (97.8,0.13) (99.2,0.22) (99.3,0.17)</cell></row><row><cell>Wood</cell><cell cols="6">(95.4,0.57) (96.4,0.21) (96.1,0.56) (96.2,0.50) (98.6,0.16) (98.3,0.19)</cell></row><row><cell>Bottle</cell><cell cols="5">(98.6,0.56) (98.9,0.06) (98.9,0.05) (98.9,0.06) (100,0.00)</cell><cell>(100,0.00)</cell></row><row><cell>Cable</cell><cell cols="6">(97.9,0.11) (98.1,0.08) (97.5,0.05) (97.5,0.08) (96,3,0.42) (97.2,0.22)</cell></row><row><cell>Capsule</cell><cell cols="6">(98.7,0.07) (98.9,0.05) (99.0,0.03) (98.9,0.04) (97.2,0.53) (97.5,0.34)</cell></row><row><cell>Hazelnut</cell><cell cols="5">(98.8,0.17) (98.9,0.13) (98.8,0.03) (98.8,0.02) (100,0.00)</cell><cell>(100,0.00)</cell></row><row><cell>Metal nut</cell><cell cols="6">(97.8,0.18) (97.9,0.19) (98.5,0.06) (98.5,0.04) (98.4,0.30) (98.7,0.34)</cell></row><row><cell>Pill</cell><cell cols="6">(97.9,0.28) (98.8,0.10) (98.9,0.05) (98.9,0.02) (94.4,1.20) (94.7,0.76)</cell></row><row><cell>Screw</cell><cell cols="6">(99.3,0.15) (99.4,0.11) (98.7,0.05) (98.7,0.07) (85.2,1.76) (88.8,1.29)</cell></row><row><cell cols="7">ToothBrush (98.9,0.09) (99.0,0.06) (98.9,0.29) (98.9,0.08) (94.1,1.28) (95.6,1.16)</cell></row><row><cell>Transistor</cell><cell cols="6">(96.2,1.32) (96.8,0.21) (98.0,0.09) (98.1,0.07) (94.4,0.46) (93.3,0.79)</cell></row><row><cell>Zipper</cell><cell cols="6">(98.6,0.29) (98.7,0.12) (99.0,0.07) (99.0,0.07) (96.7,0.23) (96.7,0.26)</cell></row><row><cell>Overall</cell><cell cols="6">(98.2,0.33) (98.4,0.13) (98.5,0.11) (98.5,0.09) (96.5, 0.57) (96.9,0.49)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Official anomaly segmentation performance on BTAD dataset. The best performances during the training process of the proposed method are recorded for each category. WRN50 is utilized as the feature extractor. Zhang, X.; Ren, S.; and Sun, J. 2016. Deep Residual Learning for Image Recognition. In 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 770-778. Jung, S.; Lee, J.; Gwak, D.; Choi, S.; and Choo, J. 2021. Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation. In 2021 IEEE/CVF International Conference on Computer Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, 2021, 15405-15414. IEEE. Kingma, D. P.; and Dhariwal, P. 2018. Glow: Generative</figDesc><table><row><cell>Model</cell><cell cols="3">P-SVDD VT-ADL Tsai et al.</cell><cell cols="2">FastFlow</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>+AltUB</cell></row><row><cell>1</cell><cell>94.9</cell><cell>76.3</cell><cell>97.3</cell><cell>95</cell><cell>97.1</cell></row><row><cell>2</cell><cell>92.7</cell><cell>88.9</cell><cell>96.8</cell><cell>96</cell><cell>97.6</cell></row><row><cell>3</cell><cell>91.7</cell><cell>80.3</cell><cell>99.0</cell><cell>99</cell><cell>99.8</cell></row><row><cell>Overall</cell><cell>93.1</cell><cell>81.8</cell><cell>97.7</cell><cell>97</cell><cell>98.2</cell></row><row><cell cols="6">on Learning Representations, ICLR 2017, Toulon, France,</cell></row><row><cell cols="6">April 24-26, 2017, Conference Track Proceedings. OpenRe-</cell></row><row><cell>view.net.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Gudovskiy, D. A.; Ishizaka, S.; and Kozuka, K. 2022.</cell></row><row><cell cols="6">CFLOW-AD: Real-Time Unsupervised Anomaly Detection</cell></row><row><cell cols="6">with Localization via Conditional Normalizing Flows. In</cell></row><row><cell cols="6">IEEE/CVF Winter Conference on Applications of Computer</cell></row><row><cell cols="6">Vision, WACV 2022, Waikoloa, HI, USA, January 3-8, 2022,</cell></row><row><cell cols="2">1819-1828. IEEE.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>He, K.;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>Anomaly segmentation performance on BTAD dataset with the format (average of AUROC, standard deviation of AUROC). AUROCs are measured from the 100th epoch. AsTable 3, WRN50 is utilized as the feature extractor. The better performance between an original model and the one with AltUB is marked in bold letters.</figDesc><table><row><cell>AltUB</cell><cell>w/o</cell><cell>w</cell></row><row><cell>1</cell><cell cols="2">(94.3, 0.71) (96.7, 0.12)</cell></row><row><cell>2</cell><cell cols="2">(95.8, 0.23) (96.2, 0.19)</cell></row><row><cell>3</cell><cell cols="2">(99.2, 0.11) (98.9, 0.16)</cell></row><row><cell cols="3">Overall (96.4, 0.35) (97.3, 0.16)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 5 :</head><label>5</label><figDesc>95% confidence interval of Kolmogorov-Smirnov statistics (%). KS test is applied to each channel of outputs of FastFlow, i.e output[:,C,:,:] once in 10 epochs. 39?0.01 8.08?0.01 7.72?0.04 9.13?0.03 w 5.14?0.01 5.65?0.01 3.68?0.01 3.65?0.01 Flow with Invertible 1x1 Convolutions. In Bengio, S.; Wallach, H. M.; Larochelle, H.; Grauman, K.; Cesa-Bianchi, N.; and Garnett, R., eds., Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, 3-8 December 2018, Montr?al, Canada, 10236-10245. Massey, F. J. 1951. The Kolmogorov-Smirnov test for goodness of fit. Journal of the American Statistical Association, 46(253): 68-78.</figDesc><table><row><cell>AltUB</cell><cell>R18</cell><cell>WRN50</cell><cell>DeiT</cell><cell>CaiT</cell></row><row><cell>w/o</cell><cell>7.</cell><cell></cell><cell></cell><cell></cell></row></table><note>Mishra, P.; Verk, R.; Fornasier, D.; Piciarelli, C.; and Foresti, G. L. 2021a. VT-ADL: A Vision Transformer Network</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 :</head><label>6</label><figDesc>Anomaly segmentation performance on the capsule category of MVTec AD dataset with the format (average of AUROC, standard deviation of AUROC). Various methods to update the base distribution are applied to FastFlow. Ster: Stereotype, CNN: A single layer of convolution neural network.</figDesc><table><row><cell></cell><cell>R18</cell><cell>WRN50</cell><cell>DeiT</cell><cell>CaiT</cell></row><row><cell cols="5">None (98.3,0.09) (98.8,0.09) (98.1,0.12) (98.7,0.07)</cell></row><row><cell>Ster</cell><cell cols="4">(98.5,0.04) (98.8,0.10) (98.1,0.15) (98.6,0.09)</cell></row><row><cell cols="2">CNN (98.0,0.89)</cell><cell>Crashes</cell><cell cols="2">(97.7,2.40) (95.3,7.22)</cell></row><row><cell cols="5">Ours (98.6,0.02) (98.6,0.10) (98.6,0.04) (98.9,0.05)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 7 :</head><label>7</label><figDesc>Inference time (millisecond) per one image comparison between FastFlow with AltUB and without it for the various feature extractors.</figDesc><table><row><cell cols="4">AltUB R18 WRN50 DeiT</cell><cell>CaiT</cell></row><row><cell>w/o</cell><cell>2.58</cell><cell>12.39</cell><cell cols="2">15.26 234.79</cell></row><row><cell>w</cell><cell>2.65</cell><cell>12.77</cell><cell cols="2">15.33 234.91</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Appendix</head><p>We fix a random seed as 25 for the main results of our paper for reproducibility. In addition, We provide more information about performance in <ref type="table">Table A1</ref> (Please check the next page). As our paper, the performance gets higher and more stable in the other feature extractors consistently. <ref type="table">Table A1</ref>: Anomaly segmentation performance on MVTec AD dataset with the format (average of AUROC, standard deviation of AUROC). AUROCs are measured from the 100th epochs to 300th epochs. The full performances depending on each feature extractor are provided. On each category, the feature extractor utilized in our paper is marked with an underline. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Akcay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ameln</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaidya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshmanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ahuja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Genc</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.08341</idno>
		<title level="m">Anomalib: A Deep Learning Library for Anomaly Detection</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">MVTec AD -A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sattlegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Steger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<publisher>Computer Vision Foundation / IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9592" to="9600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Normalizing Flows with Multi-scale Autoregressive Priors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schiele</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Density estimation using Real NVP</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sohl-Dickstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference for Image Anomaly Detection and Localization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note>30th IEEE/IES International Symposium on Industrial Electronics (ISIE)</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">VT-ADL: A Vision Transformer Network for Image Anomaly Detection and Localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mishra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Verk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fornasier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Piciarelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Foresti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">30th IEEE/IES International Symposium on Industrial Electronics (ISIE)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Normalizing Flows for Probabilistic Modeling and Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">T</forename><surname>Nalisnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Rezende</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Lakshminarayanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Papamakarios</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pavlakou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">; U V</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">22</biblScope>
		</imprint>
	</monogr>
	<note>Guyon, I.; Luxburg,</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N.-C</forename><surname>Ristea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nasrollahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">S</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Moeslund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pemula</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zepeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gehler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.08265</idno>
		<title level="m">Towards Total Recall in Industrial Anomaly Detection</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Same Same But DifferNet: Semi-Supervised Defect Detection with Normalizing Flows</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Winter Conference on Applications of Computer Vision, WACV 2021</title>
		<meeting><address><addrLine>Waikoloa, HI, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021-01-03" />
			<biblScope unit="page" from="1906" to="1915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Fully Convolutional Cross-Scale-Flows for Imagebased Defect Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rudolph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Wehrbein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wandt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An analysis of variance test for normality (complete samples)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Wilk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="591" to="611" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Training data-efficient image transformers &amp; distillation through attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Touvron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Douze</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sablayrolles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jegou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">PMLR. Touvron, H.; Cord, M.; Sablayrolles, A.; Synnaeve, G.; and J?gou, H. 2021b. Going deeper with Image Transformers</title>
		<editor>Meila, M.</editor>
		<editor>and Zhang, T.</editor>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="32" to="42" />
		</imprint>
	</monogr>
	<note>2021 IEEE/CVF International Conference on Computer Vision (ICCV)</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Multi-Scale Patch-Based Representation Learning for Image Anomaly Detection and Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-C</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="3065" to="3073" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning Unsupervised Metaformer for Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-S</forename><surname>Fuh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/CVF International Conference on Computer Vision, ICCV 2021</title>
		<meeting><address><addrLine>Montreal, QC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2021-10-10" />
			<biblScope unit="page" from="4349" to="4358" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Patch SVDD: Patch-level SVDD for Anomaly Detection and Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asian Conference on Computer Vision (ACCV)</title>
		<meeting>the Asian Conference on Computer Vision (ACCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<title level="m">FastFlow: Unsupervised Anomaly Detection and Localization via 2D Normalizing Flows</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Wide Residual Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
		<idno>1-87.12. BMVA Press. ISBN 1- 901725-59-6</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the British Machine Vision Conference (BMVC)</title>
		<editor>Richard C. Wilson, E. R. H.</editor>
		<editor>and Smith, W. A. P.</editor>
		<meeting>the British Machine Vision Conference (BMVC)</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">87</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">DRAEM -A Discriminatively Trained Reconstruction Embedding for Surface Anomaly Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Zavrtanik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Skocaj</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="8330" to="8339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Encoding Structure-Texture Relation with P-Net for Anomaly Detection in Retinal Images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>0003</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>0001</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 -16th</title>
		<editor>Vedaldi, A.</editor>
		<editor>Bischof, H.</editor>
		<editor>Brox, T.</editor>
		<editor>and Frahm, J.-M.</editor>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<title level="m">Proceedings, Part XX</title>
		<meeting>Part XX<address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">12365</biblScope>
			<biblScope unit="page" from="360" to="377" />
		</imprint>
	</monogr>
	<note>European Conference</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
