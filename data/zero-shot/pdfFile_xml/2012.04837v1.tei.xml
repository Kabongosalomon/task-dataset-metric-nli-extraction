<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep Unsupervised Image Anomaly Detection: An Information Theoretic Framework</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Ye</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huangjie</forename><surname>Zheng</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoqin</forename><surname>Huang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ya</forename><surname>Zhang</surname></persName>
						</author>
						<title level="a" type="main">Deep Unsupervised Image Anomaly Detection: An Information Theoretic Framework</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>JOURNAL OF L A T E X CLASS FILES, NOVEMBER 2020 1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Anomaly detection</term>
					<term>information theoretic frame- work</term>
					<term>mutual information</term>
					<term>entropy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Surrogate task based methods have recently shown great promise for unsupervised image anomaly detection. However, there is no guarantee that the surrogate tasks share the consistent optimization direction with anomaly detection. In this paper, we return to a direct objective function for anomaly detection with information theory, which maximizes the distance between normal and anomalous data in terms of the joint distribution of images and their representation. Unfortunately, this objective function is not directly optimizable under the unsupervised setting where no anomalous data is provided during training. Through mathematical analysis of the above objective function, we manage to decompose it into four components. In order to optimize in an unsupervised fashion, we show that, under the assumption that distribution of the normal and anomalous data are separable in the latent space, its lower bound can be considered as a function which weights the trade-off between mutual information and entropy. This objective function is able to explain why the surrogate task based methods are effective for anomaly detection and further point out the potential direction of improvement. Based on this object function we introduce a novel information theoretic framework for unsupervised image anomaly detection. Extensive experiments have demonstrated that the proposed framework significantly outperforms several state-of-the-arts on multiple benchmark data sets. Source code will be made publicly available.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>It seems straightforward to make assumptions on the distribution of anomalous data and model unsupervised anomaly detection as a one-class classification problem. Several methods have explored in this direction. Scholkopf et al. <ref type="bibr" target="#b1">[2]</ref> and Oza et al. <ref type="bibr" target="#b2">[3]</ref> assumed the anomalous distribution to be the origin and the zero centered Gaussian distribution accordingly. Ruff et al. <ref type="bibr" target="#b3">[4]</ref> assumed that the anomalous distribution to be a uniform distribution in latent space. However, the simple assumption of the anomalous distribution can not force the network to extract effective features. Making it inevitable to rely on the pre-trained model, resulting in a two-step optimizing process.</p><p>Other than directly learning to separate anomalous and normal data, surrogate based approaches attempt to first learn feature representation with an unsupervised alternative objective function, and then assume that model will lead to poor performance to the anomalous data, which are not exposed to the training, so that they can be distinguished from the normal data. Two types of surrogate tasks are typically adopted: reconstruction <ref type="bibr" target="#b4">[5]</ref>- <ref type="bibr" target="#b7">[8]</ref> and self-labeling <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>. For selflabeling based method, Golan et al. <ref type="bibr" target="#b8">[9]</ref> applied dozens of image geometric transforms and created a self-labeled dataset for transformation classification. Wang et al. <ref type="bibr" target="#b9">[10]</ref> introduced more self-label method like patch re-arranging and irregular affine transformations. Recently, a new surrogate task: restoration <ref type="bibr" target="#b10">[11]</ref> is introduced which assumes that through restoring the erased information, the model is effectively forced to learn what is erased, and the feature embedding can thus be controlled by the corresponding information erasing. While surrogate approaches have become the mainstream method for anomaly detection in recent years and have shown promising results, it is hard to ensure that the surrogate tasks share the consistent optimization direction with anomaly detection.</p><p>In this paper, we return to a direct objective function for anomaly detection, which maximizes the distance between normal and anomalous data in terms of the joint distribution for image and feature representation. We decompose the above objective function into the following four components through mathematical analysis: Mutual information between image space and latent space of normal data, Entropy of normal data in latent space; Expectation of cross-entropy between normal and anomalous samples in latent space; Distribution distance between normal and anomalous samples in image space. The first two components can be calculated with normal data only. The fourth component is a constant once normal data is selected. Only optimizing the third term requires anomalous data. To optimize the objective function under the unsupervised setting, we investigate the condition to bypass the third term and get a lower bound on the objective function which can arXiv:2012.04837v1 [cs.CV] 9 Dec 2020 be considered as a trade-off between the mutual information and the entropy. To our best knowledge, this is the first end-to-end framework to optimize anomaly detection directly. We provide a specific method based on the framework and further show that the lower-bound objective function can be linked to several previous studies such as the reconstructionbased method and the classic one-class classification method SVDD <ref type="bibr" target="#b3">[4]</ref>. As most approaches focus on only one term (mutual information or entropy), the proposed objective function can not only fill the lack of theory for many of the existing anomaly detection method but also point out the potential direction of improvement. To our best knowledge, this is the first anomaly detection objective function that can be end-to-end optimized under the unsupervised setting.</p><p>To validate the effectiveness of our lower bound objective function, we conduct extensive experiments on several benchmark datasets, including MNIST <ref type="bibr" target="#b11">[12]</ref>, Fashion-MNIST <ref type="bibr" target="#b12">[13]</ref>, CIFAR-10 <ref type="bibr" target="#b13">[14]</ref>, CIFAR-100 <ref type="bibr" target="#b13">[14]</ref> and ImageNet <ref type="bibr" target="#b14">[15]</ref>. Our experimental results have shown that the proposed method outperforms several state-of-the-art methods in terms of model accuracy and model stability to a large extent. The main contributions of the paper are summarized as follows:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORKS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Anomaly Detection</head><p>For anomaly detection on images and videos, a large variety of methods have been developed in recent years <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b15">[16]</ref>- <ref type="bibr" target="#b22">[23]</ref>. As anomalous data is diverse and inexhaustible, anomaly detection is usually considered under the setting where the training dataset contains only "normal" data, i.e. the anomalous data is not available during training. The main challenges are two-fold, the first one is how to extract effective features, the second one is how to separate anomalous data in latent space.</p><p>All the previous approaches can be broadly classified into three categories, statistic based, surrogate based and one-class classification based approaches.</p><p>Statistic based approaches <ref type="bibr" target="#b23">[24]</ref>- <ref type="bibr" target="#b25">[26]</ref> assume that anomalous data will be mapped to different statistical representations that are far from the distribution of normal data. The features are typically extracted by some shallow encoders like Principal Component Analysis (PCA), kernel PCA, or Robust PCA <ref type="bibr" target="#b26">[27]</ref>.</p><p>Surrogate based approaches assume that the anomalous data will yield in different embedding from normal data and lead to poor performance which can be utilized as criteria to define anomaly. It manages to tackle the first challenge through unsupervised learning with an alternative objective function other than optimizing anomaly detection directly. Three main frameworks, different in the employed supervision, are typically adopted: reconstruction-based, self-labeling-based, and outlier exposure-based frameworks.</p><p>Reconstruction-based frameworks take input image as supervision and assume that anomalous data have larger reconstruction error. The advantage is that supervision can be easily obtained. The main challenge is to find a more effective loss function to replace the typically adopted pixel-wised MSE loss, which is indicated ineffective to force the model to extract discriminate features <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b28">[29]</ref>. Adversarial training is leveraged to optimize the pixel-wised MSE loss, through adding a discriminator after autoencoders to judge whether its original or reconstructed image <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>. Akcay et al. <ref type="bibr" target="#b6">[7]</ref> adds an extra encoder after autoencoders and enclosing the distance between the embedding. Perera et al. <ref type="bibr" target="#b7">[8]</ref> applied two adversarial discriminators and a classifier on a denoising autoencoder. By adding constraint and forcing each randomly drawn latent code to reconstruct examples like the normal data, it obtained high reconstruction errors for the anomalous data.</p><p>Self-label based frameworks, which take the artificial label as supervision and assume that the labels can not be predicted properly for anomalous data, has recently received significant attention. This framework, as decoder-free, can be a benefit in the advanced classification network which is proved to be more effective in extracting discriminate features. The main challenge is how to define meaningful labels. Golan et al. <ref type="bibr" target="#b8">[9]</ref> applied dozens of image geometric transforms and created a self-labeled dataset for transformation classification. Wang et al. <ref type="bibr" target="#b9">[10]</ref> introduced a more self-label method like patch re-arranging and irregular affine transformations.</p><p>Outlier exposure based frameworks take an auxiliary dataset entirely disjoint from test-time data as supervision and thus teach the network better representations for anomaly detection. Hendrycks et al. <ref type="bibr" target="#b29">[30]</ref> introduced extra data to build a multiclass classification task. The experiment revealed that even though the extra data was in limited quantities and weakly correlated to the normal data, the learned hyperplane was still effective in separating normal data.</p><p>Restoration based framework, a new framework introduced by Ye et al. <ref type="bibr" target="#b10">[11]</ref>, which assumed that through restoring the erased information the model will be effectively forced to learn what is erased and how to restore it. Thus feature embedding can be controlled by the corresponding information erasing.</p><p>One-class classification based approaches tackle the second challenge by making assumptions on the distribution of anomalous data, thus change the anomaly detection into a supervised binary classification problem. Explicitly, Scholkopf et al. <ref type="bibr" target="#b1">[2]</ref> and Oza et al. <ref type="bibr" target="#b2">[3]</ref> assumed the anomalous distribution to be the origin and the zero centered Gaussian distribution in latent space accordingly. Implicitly, Ruff et al. <ref type="bibr" target="#b3">[4]</ref> assumed that the anomalous distribution to be a uniform distribution in latent space. Despite these approaches <ref type="bibr" target="#b1">[2]</ref>- <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b30">[31]</ref> could directly optimize the anomaly detection based objective function, the disadvantage is also obvious: these approaches have to rely on a pre-defined or pre-trained feature extractor, as its objective function and simple assumption on anomalous distribution can not force the network to extract effective feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Unsupervised Learning by Maximizing Mutual Information</head><p>Mutual information, generally employed to measure the correlation between two random variables, has recently received extensive attention in unsupervised learning. Mutual information is notoriously difficult to compute, particularly in continuous and high-dimensional settings <ref type="bibr" target="#b31">[32]</ref>. To tackle this problem, Belghazi et al. <ref type="bibr" target="#b32">[33]</ref> employ deep neural networks to effectively compute the mutual information between high dimensional input/output pairs. Hjelm et al. <ref type="bibr" target="#b31">[32]</ref> utilize an 1x1 convolutional discriminator to compute the mutual information between a global summary feature vector and a collection of local feature vectors. Oord et al. <ref type="bibr" target="#b33">[34]</ref> introduce a new NCE based loss called InfoNCE to maximize mutual information. Chen et.al <ref type="bibr" target="#b34">[35]</ref> propose to maximize the agreement between two augmentation results from the same raw data and investigate properties of contrastive learning. Bachman et.al <ref type="bibr" target="#b35">[36]</ref> maximize mutual information between features extracted from multiple views of a shared context. He et al. <ref type="bibr" target="#b36">[37]</ref> utilize a dynamic dictionary to decouple the dictionary size from the mini-batch size, allowing the model to benefit from a large sampling size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. METHODS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Problem Formulation</head><p>Let X and Z be the domain of image data and representation data. Denote X n as the normal data and X a be the anomalous data, where X n = {x n : x n ? p n (x)}, X a = {x a : x a ? p a (x)}. Let the corresponding representation of X n and X a to be Z n and Z a accordingly, where p n (z) and p a (z) are the marginal distribution of the latent representations, p n (x, z) and p a (x, z) are the joint distribution between image space and the latent space.</p><p>To distinguish the normal data x n and anomalous data x a , due to the curse of dimensionality, anomaly detection in high-dimensional image space is not favorable in general cases. A common choice is to define a continuous and (almost everywhere) differentiable parametric function, E ? : X ? Z with parameters ? (e.g., a neural network) that encodes the data to the low-dimensional latent space Z, where the anomalous data can be detected more easily. Thus a straight-forward objective function may be maximizes the conditional distributions between normal and anomalous data in latent space. We take the commonly used KL divergence as measurement metric, and objective function can be formulate as:</p><formula xml:id="formula_0">max ? KL [p n (z|x) p a (z|x)] .<label>(1)</label></formula><p>In order to make the object function in Eq. 1 more complete, in which the distribution distance in image space is taken into consideration simultaneously, we introduce a novel anomaly detection based objective function, which maximizes the distance between normal and anomalous data in terms of the joint distribution for image and feature representation. The objective function can be formulate as:</p><formula xml:id="formula_1">max ? KL [p n (x, z) p a (x, z)] .<label>(2)</label></formula><p>When maximizing Eq. 2, all marginal distributions and all conditional distributions also match this maximization:</p><formula xml:id="formula_2">Remark 1. If KL [p n (x, z)||p a (x, z)] is maximized, then it is equivalent that KL [p n (x)||p a (x)] and KL [p n (z|x)||p a (z|x)] are maximized.</formula><p>Proof. The KL divergence for the joint distributions can be decomposed with chain rule <ref type="bibr" target="#b37">[38]</ref>:</p><formula xml:id="formula_3">KL [p n (x, z)||p a (x, z)] = E pn(x,z) log p n (x, z) p a (x, z) =E pn(x,z) log p n (x) p a (x) + log p n (z|x) p a (z|x) = KL [p n (x)||p a (x)] + E pn(x) [KL [p n (z|x)||p a (z|x)]] .<label>(3)</label></formula><p>To maximize the KL divergence for the joint distributions is equivalent to maximize the KL divergence for both marginal and conditional distributions <ref type="bibr" target="#b38">[39]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Objective Function Decomposition</head><p>Remark 1 shows the equivalence of our objective to the common knowledge of anomaly detection. In this section we present that this objective yields a lower bound which can be optimized without anomalous data. It is a great challenge to optimize the objective function in Eq. 2 directly, since p a (x, z) is not accessible. To tackle this challenge, firstly we decompose the objective function into four components, as introduced in the Proposition 1. Then, as shown in Proposition 2, we investigate the condition where we can bypass the component correlated with anomalous data and thus reformulated the the objective function in Eq. 2 into a lower-bound in Eq. 10 which can be optimized only with normal data. Finally, as shown in Corollary 2.1, the lower-bound can be optimized with a regularized Lagrange multiplier and get Eq. 13 as the final objective function. The Proposition 1 is introduced as follows:</p><formula xml:id="formula_4">Proposition 1. Let I n (x, z), H n (z), H(p n (z|x), p a (z|x)), KL [p n (x) || p a (x)</formula><p>] denote the mutual information between x and z for normal data, the entropy of z for normal data, the cross entropy between p n (z|x) and p a (z|x) and KL divergency between p n (x) and p a (x), respectively. Note that when the dataset is given, i.e. p n (x) and p a (x) are fixed (even though anomalous data is unknown). The objective function can be reformulated as:</p><formula xml:id="formula_5">max ? KL [p n (x, z)||p a (x, z)] = max ? {I n (x, z) ? H n (z) + E pn(x) [H(p n (z|x), p a (z|x))] + KL [p n (x)||p a (x)]}.<label>(4)</label></formula><p>Proof. The objective function in Eq. 2 can be reformulated as:</p><formula xml:id="formula_6">max ? KL [p n (x, z)||p a (x, z)] = max ? E pn(x,z) log p n (x, z) p a (x, z) = max ? E pn(x,z) log p n (z|x) ? p n (x) p a (z|x) ? p a (x) = max ? E pn(x,z) log p n (z|x) ? p n (x) ? p n (z) p a (z|x) ? p a (x) ? p n (z) = max ? E pn(x,z) log p n (z|x) p n (z) ? p n (z) ? 1 p a (z|x) ? p n (x) p a (x) .</formula><p>The above formula can be then decomposed into 4 components. The 1 st component refers to the mutual information between the data sample x and its representation z for normal data:</p><formula xml:id="formula_7">E pn(x,z) log p n (z|x) p n (z) = E pn(x,z) log p n (z|x) ? p n (x) p n (x) ? p n (z) =E pn(x,z) log p n (x, z) p n (x) ? p n (z) = I n (x, z) .<label>(5)</label></formula><p>The 2 nd component is the negative entropy of z w.r.t p n :</p><formula xml:id="formula_8">E pn(x,z) [log p n (z)] = ?E pn(z) log 1 p n (z) = ?H n (z). (6)</formula><p>The 3 rd component is the expected value of the cross entropy between the conditional distributions p a (z|x) and p n (z|x):</p><formula xml:id="formula_9">E pn(x,z) log 1 p a (z|x) = E pn(x) E pn(z|x) [? log p a (z|x)] =E pn(x) [H(p n (z|x), p a (z|x))] .<label>(7)</label></formula><p>With p n (x) and p a (x) fixed, the 4 th component is a constant:</p><formula xml:id="formula_10">E pn(x,z) log p n (x) p a (x) = KL [p n (x)||p a (x)] = C.<label>(8)</label></formula><p>Thus the objective function in Eq. 2 can be reformulated as:</p><formula xml:id="formula_11">max ? KL [p n (x, z)||p a (x, z)] = max ? {I n (x, z) ? H n (z) + E pn(x) [H(p n (z|x), p a (z|x))] + KL [p n (x)||p a (x)]}<label>(9)</label></formula><p>The decomposed objective function in Eq. 4 is an essential general formula for optimizing anomaly detection, which combines unsupervised learning (1 st and 2 nd components) and supervised learning (3 rd component).</p><p>As the 1 st and 2 nd components can be trained through an unsupervised fashion and force the encoder to extract effective features, the demand for anomalous data is greatly reduced.</p><p>To deal with unsupervised setting where anomalous data is complete absence during training, we seek to get rid of the 3 rd component, which partially relies on anomalous data. Proposition 2. If p n (x, z) and p a (x, z) have a certain distance such that for most samples x, z ? p n (x, z) the evaluated density p a (z|x) is small enough, such that p a (z|x) p n (z) and p a (z|x) 1 almost everywhere, then we can derive a lower bound of Objective funcition for Eq. 4:</p><formula xml:id="formula_12">max ? {I n (x, z) ? H n (z)}.<label>(10)</label></formula><p>Proof. With the assumption that the evaluated density p a (z|x) is small enough for most of the samples x, z ? p n (x, z). This ensures the non-negativity of E pn(x) [H(p n (z|x), p a (z|x)] with the following inequality:</p><formula xml:id="formula_13">inf E pn(x) [H(p n (z|x), p a (z|x)] = inf E pn(x,z) [? log p a (z|x)] E pn(x,z) [inf (? log p a (z|x))] 0.<label>(11)</label></formula><p>Moreover, the 4 th component in Eq. 4 is a constant greater than zero. Then we have a lower bound to Eq. 4:</p><formula xml:id="formula_14">KL [p n (x, z)||p a (x, z)] I n (x, z) ? H n (z).<label>(12)</label></formula><p>The objective function in Eq. 10 is vital as it reveals a general formula for optimizing anomaly detection in an unsupervised fashion. Note that the assumption in Proposition 2 is appropriate in the anomaly detection tasks. Since we often have access to data samples instead of the true data distribution, considering the empirical distribution p n (z) = 1</p><formula xml:id="formula_15">N N i=1 ? zi ; Z n = {z i } N i=1</formula><p>, we always have p n (z) 1 and we have the evaluated density p a (z i |x i ) 1. Moreover, with this assumption, we can futher ensure the objective can be optimized with a regularized Lagrange multiplier.</p><p>Corollary 2.1. With the assumption in proposition 2.1, the lower bound shown in Equation 10 yields an objective function to be optimized with a entropy-regularized Lagrange multiplier:</p><formula xml:id="formula_16">max ? {I (x, z) ? ? ? H(z)},<label>(13)</label></formula><p>where ? 0 is a positive coefficient for the weight of the entropy regularization.</p><p>Proof. To show Eq. (13) is a lower bound of Eq. (4), we only need to show the lower bound holds when ? = 0:</p><formula xml:id="formula_17">Eq. (4)?Eq. (13) = E pn(x,z) log p n (z) p a (z|x) +KL[p n (x)||p a (x)].</formula><p>E pn(x,z) log pn(z) pa(z|x) ? 0 as the assumption pn(z) pa(z|x) ? 1 in Proposition 2 while the second term is a positive constant , thus Eq. (4) ? Eq. (13) ? 0 and completes the proof.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Optimization</head><p>In this section, we extend our general lower-bound objective to concrete loss functions. Start from here, as all the terms in Eq. 10 and 13 refer to normal data only, we omit the subscript 'n' and 'a' to specify normal and anomalous. Moreover, we present the probabilistic expressions in the empirical distribution since we work with samples from the data distribution.</p><p>A challenge to maximize the objective function is that both mutual information and entropy are not always tractable. To maximize the mutual information between x and z, we apply the Contrastive Predictive Coding lower bound with Noise Contrastive Estimation <ref type="bibr" target="#b39">[40]</ref>:</p><formula xml:id="formula_18">I(x; z) E 1 K K i=1 log e f (xi,zi) 1 K K j=1 e f (xi,zj ) I NCE ,<label>(14)</label></formula><p>where f is the critic function that maps the inputs into a value in R, which can be modeled with various methods, such as a similarity function or a neural discriminator. Here, x i and</p><formula xml:id="formula_19">z i = E ? (x i ) are called positive pairs; while x i and z j = E ? (x j I [j =i] ), where I [j =i] ? {0, 1}</formula><p>is an indicator function evaluating to 1 iff j = i, are called negative pairs. Empirically, two independently randomly augmented versions of the same </p><formula xml:id="formula_20">5 x 2k?1 = t(x k ) 6 x 2k = t (x k ) 7 # Extract features 8 z 2k?1 = E ? ( x 2k?1 ) 9 z 2k = E ? ( x 2k ) 10 for all i ? {1, ...., 2N } and j ? {1, ...., 2N } do 11 # Similarity 12 s i,j = sim(z i , z j ) = z i ? z j 13 s i,j = c 2 ? tanh si,j c1?c2 14 define S = s i,j , i, j ? 2N , s max = max {S} 15 S shif t = S ? s max 16 define S shif t = {? i,j , i, j ? 2N } 17 define (i, j) = ? log exp(?i,j ) 2N k=1 I [k =i] exp(? i,k ) 18 L nce = 1 2N N k=1 [ (2k ? 1, 2k) + (2k, 2k ? 1)] 19 L entropy = 1 2N 2N k=1 z k q 20 L = L nce + ? ? L entropy 21</formula><p>update network E ? 22 return encoder network E ? sample, e.g. an image and its rotated view, are often used as positive pairs <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>.</p><p>To minimize the entropy, we seek the lower bound for the negative entropy as:</p><formula xml:id="formula_21">?H(z) = E p(x,z) [log p(z)] = E p(x,z) [log p(z) ? log r(z)] + E p(x,z) [log r(z)] = KL[p n (z)||r(z)] + E p(x,z) [log r(z)] E p(x,z) [log r(z)],<label>(15)</label></formula><p>where r(z) is a reference distribution and KL[p n (z)||r(z)] 0. One common choice is to let r(z) = N (0, I). Then, this lower bound is proportional to the L2 norm:</p><formula xml:id="formula_22">E p(x,z) [log r(z)] ? ? 1 N N i=1 z i 2 2 ,<label>(16)</label></formula><p>where ? 2 denotes the Frobenius norm when p = 2 and z i = E ? (x i ) denotes the latent feature of the i th normal sample. Eq. 16 also provides us with a geometrical interpretation in the latent space. In this view, we can also generalize the Frobenius case into other orders, such as p = 1: Another choice is thus to let r(z) as a standard Laplace distribution (r(z) = L(0, I)), similarly, this yields the mean of L1 norm:</p><formula xml:id="formula_23">E p(x,z) [log r(z)] ? ? 1 N N i=1 z i 1 .<label>(17)</label></formula><p>Based on Eq. 13, with Monte Carlo samples, our loss function is defined as:</p><formula xml:id="formula_24">L = ?I NCE (x, z) ? ? ? E p(x,z) [log r(z)] ? 1 N N i=1 ? log e f (xi,zi) 1 K K j=1 e f (xi,zj ) + ? ? z i p ,<label>(18)</label></formula><p>where p = 1 or p = 2 according to the choice of r. We will explain the difference of this choice in the experiment part.</p><p>In this paper, we apply f (</p><formula xml:id="formula_25">x i , z i ) = sim(E ? (x i ), E ? ( x i )) = sim(z i , z i ),</formula><p>where z i and z i are the latent representations of x i and its augmented view x i ; sim(u, v) ? u ? v denotes the similarity between two normalized vectors u and v. The loss function can be reformulated as:</p><formula xml:id="formula_26">L = 1 K K i=1 ? log exp (sim (z i , z i )) 1 K K j=1 exp(sim(z i , z j )) + ? z i p ,<label>(19)</label></formula><p>Note that in practice the NCE lower bound requires larger number of negative samples to ensure the good performance <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b40">[41]</ref>. Considering the efficiency of negative sampling in anomaly detection, we follow SimCLR <ref type="bibr" target="#b34">[35]</ref> and AMDIM <ref type="bibr" target="#b35">[36]</ref> for the augmentation strategy. The pseudocode of the training process for the base model is shown in Algorithm 1.</p><p>Local Deep Infomax (local DIM) <ref type="bibr" target="#b31">[32]</ref>, which maximizes the mutual information between a global feature vector depend on the full input and a collection of local feature vectors pulled from an intermediate layer in the encoder, has shown to be greatly effective in improving feature learning and maximizing mutual information in <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b35">[36]</ref>. To get the best performance, we introduce local DIM to our method as the extension model. With the augmentation strategy from <ref type="bibr" target="#b34">[35]</ref>, <ref type="bibr" target="#b35">[36]</ref>, the negative samples size is increased and L N CE (z i , z i ) becomes:</p><formula xml:id="formula_27">L N CE (z i , z i ) = ? log exp (sim (z i , z i )) 1 2K 2K j=1 I [j =i] exp(sim(z i , z j ))</formula><p>.</p><p>Thus the loss function, added local DIM, is formulated as:</p><formula xml:id="formula_29">L = 1 K K i=1 [L N CE (z gi , z gi ) + L N CE (z gi , z li ) + ? ? z gi p ] ,<label>(21)</label></formula><p>where z gi refers to the global features, produced by parametric function E ? , z li refers to the local features, produced by an intermediate layer in E ? .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Normal Score Measurement</head><p>Most surrogate supervision based approaches associate the anomaly score measurement with the loss function of surrogate task, which assume that anomalous data will result in relatively bigger loss. Following this mechanism, since the similarity between z i and z i is maximized in our method, a straight forward normal score measurement can be formulated as:</p><formula xml:id="formula_30">NormalScore = sim(z i , z i ),<label>(22)</label></formula><p>during z i and z i are the latent representations of the augmented view x i and x i of the same test data example x orii , in which augmented view is randomly selected. In this design, sample with high normal score is consider to be normal. However, it is time consuming to traverse all combinations of augmented view pair and random selected one combination yield in unstable result. As a solution, when testing we skip the augmentation terms and encode the original data x ori i directly. The corresponding output features is noted as z ori i . Thus we reformulated the normal score for base model as:</p><formula xml:id="formula_31">NormalScore = sim(z orii , z orii ).<label>(23)</label></formula><p>The normal score for extension model is then reformulated as:</p><formula xml:id="formula_32">NormalScore = sim(z gi , z gi ) + sim(z gi , z li ).<label>(24)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Relation to Other Algorithms</head><p>A successful theorem should not only be able to explain the implicit mechanisms in previous works but also be able to point out the potential improvement direction. We then take some classic methods to illustrate the interpretability of work.</p><p>AutoEncoder <ref type="bibr" target="#b41">[42]</ref>: Reconstruction based anomaly detection using Auto-encoder is a mainstream method. It assumes that by minimizing the reconstruction error, normal and anomalous samples could lead to significantly different embedding and thus the corresponding reconstruction errors can be leveraged to differentiate the two types of samples. Then we will see how our equation fits this work. First we reformulate the mutual information terms as:</p><formula xml:id="formula_33">I n (x, z) = H n (x) ? H n (x|z) =H n (x) + E x?pn(x) E z?pn(z|x) [log p n (x|z)] .<label>(25)</label></formula><p>With Eq. 25, the Eq. 10 is reformulated as:</p><formula xml:id="formula_34">max ? {I n (x, z) ? H n (z)} = max ? {H n (x) + E x?pn(x) E z?pn(z|x) [log p n (x|z)] ? H n (z)},<label>(26)</label></formula><p>where the first term is a constant, the second term is the reconstruction likelihood, the third term is the entropy of Z. This gives solid mathematical support to why anomaly detection can be benefited via maximizing reconstruction likelihood. Furthermore, it is indicated that adding entropy terms may further improve the method. SVDD <ref type="bibr" target="#b3">[4]</ref>: Deep one-class classification is the most classic method. Pre-trained by autoencoder network with reconstruction error, it then minimizes the volume of a data-enclosing hyper-sphere in latent space. It assumes that the normal examples of the data are closely mapped to center c, whereas anomalous examples are mapped further away from the center. SAD <ref type="bibr" target="#b30">[31]</ref> mathematically proved that the objective function in SVDD minimizes an upper bound on the entropy of latent space. Considering the pre-trained autoencoding objective implicitly maximizes the mutual information, SAD intuitively summarizes its objective function to have a positive correlation with mutual information and negative correlation with entropy, which is consistent with our objective function in Eq. 10. our method gives theoretical support to why anomaly detection can benefit from this objective function. Both SAD and SVDD used a two-stage optimization method, which maximizes the mutual information first and then minimizes the entropy.</p><p>This two-stage optimization can not guarantee the simultaneous optimization of the mutual information and the entropy. Moreover, to relief the hyper-sphere collapse, only networks without bias terms and bounded activation functions can be used <ref type="bibr" target="#b3">[4]</ref>.</p><p>Information bottleneck <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>: The Information Bottleneck (IB) methods define a good representation and learn it with the trade-off of a concise representation and a powerful prediction in downstream tasks <ref type="bibr" target="#b42">[43]</ref>, <ref type="bibr" target="#b43">[44]</ref>. Various studies, extend the IB methods into deep learning scenario with variational methods, such as Variational Information Bottleneck (VIB) <ref type="bibr" target="#b45">[45]</ref>, Information Confidence Penalty (ICP) <ref type="bibr" target="#b46">[46]</ref>, Variational Discriminator Bottleneck (VDB) <ref type="bibr" target="#b47">[47]</ref>, etc. Our regularizer shown in Eq. 10 is consistent with the one proposed in <ref type="bibr" target="#b46">[46]</ref>. We also show in Eq. 15 that the entropy is proportional to a KL divergence in terms of a reference distribution, which is consistent with the regularizer used in <ref type="bibr" target="#b45">[45]</ref>, <ref type="bibr" target="#b47">[47]</ref>.</p><p>Basic assumption for surrogate task based approaches in anomaly detection: As anomalous data is inaccessible during train process, most surrogate tasks based unsupervised anomaly detection methods are based on an assumption that data can be embedded into a lower-dimensional subspace where normal and anomalous samples appear significantly different <ref type="bibr" target="#b0">[1]</ref>. In our method, we are the first to reveal the theoretical rationality for this basic assumption. From Proposition 2, we can see the key to reformulate the objective function from semi-supervised fashion (objective function in Eq. 4) to unsupervised fashion (objective function in Eq. 10) is to ensures the non-negativity of E pn(x) [H(p n (z|x), p a (z|x)]. This is under the assumption, as introduced in Proposition 2, that p n (x, z) and p a (x, z) has certain distance such that for most samples x, z ? p n (x, z) the evaluated density log p a (z|x) 0, which is consistant with the assumption in <ref type="bibr" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. EXPERIMENTS</head><p>In this section, we present a comprehensive set of experiments to validate our anomaly detection algorithm under unsupervised settings, in which multiple commonly used benchmark datasets are involved. To further demonstrate the robustness of our method, following the setting of ARNet <ref type="bibr" target="#b10">[11]</ref>, a subset of ImageNet <ref type="bibr" target="#b14">[15]</ref> with higher resolution, richer texture and more complex background, is utilized.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Experimental Setups</head><p>Datasets. We experiment with the following five popular image datasets.</p><p>? MNIST <ref type="bibr" target="#b11">[12]</ref>: consists of 70,000 28 ? 28 handwritten grayscale digit images. ? Fashion-MNIST <ref type="bibr" target="#b12">[13]</ref>: a relatively new dataset comprising 28 ? 28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category.</p><p>? CIFAR-10 <ref type="bibr" target="#b13">[14]</ref>: consists of 60,000 32 ? 32 RGB images of 10 classes, with 6,000 images for per class. There are 50,000 training images and 10,000 test images, divided in a uniform proportion across all classes. ? CIFAR-100 <ref type="bibr" target="#b13">[14]</ref>: consists of 100 classes, each of which contains 600 RGB images. The 100 classes in the CIFAR-100 are grouped into 20 "superclasses" to make the experiment more concise and data volume of each selected "normal class" larger. ? ImageNet <ref type="bibr" target="#b14">[15]</ref>: Following ARNet <ref type="bibr" target="#b10">[11]</ref>, we group the data from the ILSVRC 2012 classification dataset <ref type="bibr" target="#b14">[15]</ref> into 10 superclasses by merging similar category labels using Latent Dirichlet Allocation (LDA) <ref type="bibr" target="#b48">[48]</ref>, a natural language processing method (see appendix for more details). We noted this dataset is more challenging due to its higher resolution richer contexture and more complex background. For all datasets, the training and test partitions remain as default. In addition, pixel values of all images are normalized to [?1, 1].</p><p>Evaluation protocols. For a dataset with C classes, we conduct a batch of C experiments respectively with each of the C classes set as the "normal" class once. We then evaluate performance on an independent test set, which contains samples from all classes, including normal and anomalous data. As all classes have equal volumes of samples in our selected datasets, the overall number proportion of normal and anomalous samples is 1 : C ? 1. The model performance is then quantified using the area under the Receiver Operating Characteristic (ROC) curve metric (AUROC). It is commonly adopted as performance measurement in anomaly detection tasks and eliminates the subjective decision of threshold value to divide the "normal" samples from the anomalous ones. The above evaluation protocols are generally accepted among most recent works on anomaly detection <ref type="bibr" target="#b5">[6]</ref>- <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b49">[49]</ref>- <ref type="bibr" target="#b52">[52]</ref>.</p><p>Model configuration. For all the datasets, the training epoch is set as 400, the learning rate is set as 2e-4. The corresponding pseudocode of base model can be found in Algorithm 1.</p><p>For all experiments, if not specified, the base model refers to the model with loss function in Eq. 13, normal scoring function in Eq. 23, pseudocode in Algorithm 1. The extensive model refers to the model with loss function in Eq. 21, normal scoring function in Eq. 24. In general, we use a base model to investigate the property of the objective function and use an extensive model to reach better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Investigation of Objective Function Properties</head><p>In this section, we look into the properties of our objective function with our base model. The objective function in Eq. 13 provides a lower bound for the maximization of the KL divergence in Eq. 2, which present a trade-off between the maximization of the mutual information I(x, z) and the constrain of the entropy H(z). CIFAR10 and CIFAR100. We report the average AUROC results of all classes with respect to ? <ref type="figure">( Fig. 1</ref>). We observe that the model yield a comparable good performance with ? in a relatively wide range from 0.5 to 40.0 in CIFAR10 and from 1 to 30.0 in CIFAR100, where the best performance is reached when ? = 20.0 on both datasets, suggesting that the model is not very sensitive to the change in ? as long as it in a certain range, which is vital in real-world cases where we can not utilize a testing dataset to select the super-parameter.</p><p>In contrast, the model results in poor performance when ? is either too small or too large. In this work, if not specified, we choose ? = 20.0 to conduct experiments on all datasets.</p><p>We also record the AUROC result every 5 epochs during the training process on CIFAR10 with different ? in B. The result of class 1 (car) is presented in <ref type="figure">Fig. 2</ref>. It is observed that the AUROC curve shows better convergence with ? in the range from 0.5 to 30.0, where the model from the last epoch reaches almost the best performance. This is a vital property in real-world cases, where we can not utilize testing results to choose the model with the best performance.</p><p>To be noted, as observed from the above two experiments, when ? = 0.0 the model can not converge properly, which indicates that without the entropy constrain the unsupervised learning framework based on maximizing mutual information only is not directly applicable to anomaly detection.</p><p>2) Digging out the essence of the trade-off: We experiment on CIFAR10 and CIFAR100 with our base model under the hyper-parameter ? in B. For each training class, we investigate the relation between the converged training loss (mutual information and entropy) and the corresponding AUROC. Then we look into the learned representation z i by calculating their distance from the center z i 2 of normal and anomalous data as ? increase. We report the results that trained with class 0 in <ref type="figure" target="#fig_1">Fig. 3</ref>. In the top panels of <ref type="figure" target="#fig_1">Fig. 3</ref>, we can observe that as ? increases, the loss corresponds to the mutual information converges to a larger value while the loss corresponds to the entropy converges to a smaller value. As ? increases, the model tends to ignore the mutual information, which matches our observation that the MI loss is getting larger and the entropy loss is getting smaller. It is remarkable that L N CE and L H become in similar scale when ? is in the range from 0.5 to 40.0 in CIFAR10 and from 10.0 to 30.0 in CIFAR100, in which model results in better performance as shown in the top panels in <ref type="figure" target="#fig_1">Fig. 3</ref>. This indicates that a proper ? for the trade-off should lead to similar converged scale for both L N CE and L H .</p><p>In the bottom panels of <ref type="figure" target="#fig_1">Fig. 3</ref>, we compare the mean z i 2 of all samples between normal and anomalous data in testing datasets. As ? increases, the mean z i 2 for both normal and anomalous data shows a declining tendency. More importantly, the z i 2 for the anomalous data decreases to a larger extent than that of the normal data. This results in a gap between normal and anomaly data. We observe that the model results in better performance when the mean z i 2 gap is larger, with ? in the range of 0.5 to 40.0 in CIFAR10 and 10.0 to 30.0 in CIFAR100. Especially, the biggest gap is attained when ? = 20.0 on CIFAR10 and ? = 10.0 on CIFAR100 dataset respectively, which correspond to their best performance as shown in the top panels of <ref type="figure" target="#fig_1">Fig. 3</ref>.</p><p>To analyze these experiments, we connect these results with the formulation. As shown in Eq. 15, the entropy regularizer is lower-bounded by the expected value of log r(z). As we choose r as a zero-centered reference distribution, whose density function is proportional to the p-norm z i p (p = 1 or p = 2), a geometric interpretation is also guaranteed: the model will regularize the Euclidian (resp. Manhattan) distance from the center z i 2 and encourage the representations z i to be centered. From <ref type="figure" target="#fig_1">Fig. 3</ref>, as increase the value of ?, we can observe that for anomaly data the mean z i 2 is getting close to zero rapidly, while for normal data which profits from the mutual information maximization the mean z i 2 is getting close to zero relatively slower. When ? is too large (e.g. ? 60.0), we can observe that the maximization of MI is over-regularized, thus the model cannot extract effective features for normal data, which results in a lower AUROC. These results enlighten the importance of the trade-off between mutual information and entropy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Ablation: Mutual Information and Entropy Estimators</head><p>The previous section discusses the importance of the information trade-off. A nice property of our formulation is that Eq. 13 is general enough and is able to plug in alternative estimators for the mutual information and entropy loss. In this section, we conduct the ablation experiments with the alternative mutual information and entropy estimator and justify the expressiveness of the estimators that we choose. 1) Learning with a different mutual information estimator: We apply the InfoNCE estimator <ref type="bibr" target="#b39">[40]</ref> for the calculation of the mutual information. Considering there are a wide range of approaches for the MI estimation, we also consider an alternative lower bound for MI estimation called Donsker-Varadahn (DV) bound <ref type="bibr" target="#b53">[53]</ref>.</p><formula xml:id="formula_35">I(x; z) E p(x,z) [f (x, z)] ? log E p(z) [e f (x,z) ] I DV (27)</formula><p>This bound is widely used in various algorithms such as Mutual Information Neural Estimator (MINE) <ref type="bibr" target="#b32">[33]</ref>. Deep InfoMax (DIM) <ref type="bibr" target="#b31">[32]</ref> continues to extend the critic in this bound with a Jensen-Shannon based formulation as: <ref type="formula" target="#formula_1">(28)</ref> where ?(z) = log (1 + e z ) denotes the Softplus function, and note that for DV bound and JSD bound the critic function f is usually modeled with a discriminator function f : X ? Z ? R. Moreover, according to existing studies like <ref type="bibr" target="#b31">[32]</ref>, the JSDbased estimator and the DV-based estimator behave similarly. Here, we apply the JSD-based MI estimator to represent the effect of DV bound.</p><formula xml:id="formula_36">I(x; z) E [?? (?f (x, z)) ? ? (f (x , z))] I JSD</formula><p>To compare the JSD-based and NCE-based MI estimator, on our base model, we utilize the JSD-based MI estimator and the InforNCE estimator. The experiments are conducted on CIFAR10 and CIFAR100 and the hyper-parameter is set as ? = 20.0. The results are shown in <ref type="table" target="#tab_1">Table I</ref>. Given the same entropy estimator, we can find the model with the JSD-based MI estimator underperforms than the NCE-based MI estimator.</p><p>To investigate the performance gap, we investigate the training process and illustrate the testing AUROC curve and the mutual information loss during the training process in <ref type="figure" target="#fig_2">Fig. 4</ref>, where the NCE-based and the JSD-based estimator is marked in red and blue respectively. Compared to the NCE-based estimator, both testing AUROC and the loss by JSD-based estimator show large perturbation during the training, which makes the model more difficult to converge.</p><p>One plausible explanation is that the mutual information estimation variance of the JSD estimator is much larger than the NCE estimator, which is the critical difference between these two MI estimators <ref type="bibr" target="#b40">[41]</ref>. This large variance caused by the JSD-based estimator makes the model more unstable during the training and the learned representations may be useless. In this way, the JSD-based methods need more fine-tuning to stabilize the training process of the model.</p><p>2) Learning with a different entropy estimator: We introduce two reference distributions in Eq. 16 and Eq. 17 to estimate the entropy, corresponding to the L2 norm and the L1 norm, respsectively. Similar to the previous experiments, CIFAR10 and CIFAR100 are used. With different entropy estimators, we test with both the NCE-based and the JSDbased mutual information estimator, and report the mean and standard deviation of the AUROC among all classes in <ref type="table" target="#tab_1">Table I</ref>. Given the same MI estimator, the L1 norm estimator yields   better performance. A case-by-case study is conducted and based on the hyper-parameter that we set, when the L1 norm used as the entropy regularizer, the representations are more inclined to shrink to the center. This results in a larger distance gap between normal and anomaly data than the L2 norm does and in order to have the same performance L2 norm may need more proper hyper-parameter tuning to balance the information trade-off. Based on our observation, the NCE-based estimator is more suitable and compatible with the proposed entropy estimator. In the following sections, we continue to refine the NCE-based estimator and apply the L1 entropy regularizer to present the effectiveness of our proposed method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Efficient Normal Scoring Mechanism</head><p>As shown in Eq. 22 the normal score is firstly designed to be the similarity of z i and z i , which are the latent representations of the randomly augmented view x i and x i of the same test data example x orii . However, the random augmentation yield in unstable result. An alternative solution is to utilized Monte Carlo samples, and the normal score is reformulated as:</p><formula xml:id="formula_37">NormalScore = H h=1 [sim(z (h) gi , z (h) gi )]<label>(29)</label></formula><p>Where the h refers to the h st sampling. Despite being more stable, it is time-consuming. We introduce a compromise as shown in Eq. 23, which skip the augmentation and directly input the original sample.  <ref type="bibr" target="#b3">[4]</ref> . Results of VAE, AnoGAN and ADGAN are from <ref type="bibr" target="#b5">[6]</ref>. Results of DAGMM, DSEBM and GeoTrans are from <ref type="bibr" target="#b8">[9]</ref>. Results of GANomaly and ARNet are from <ref type="bibr" target="#b10">[11]</ref>. With the base model, we conduct experiment on CIFAR10 and CIFAR100 to evaluate the three normal scoring mechanism based on Eq. 22, 23 and 29, which is noted as N ormalScore rand , N ormalScore ori and N ormalScore mc accordingly. To be noted that, in Eq. 29, H is set as 100. We repeat the testing process for 10 times for each normal scoring mechanism and record the average and standard deviation of the AUROC of all classes in CIFAR10. As illustrated in  <ref type="table" target="#tab_1">Table II</ref>, the normal scoring mechanisms base on Eq. 23 yield a comparable and stable result with only one inference. We take Eq. 23/Eq. 24 as our refined normal scoring mechanism for the base/extension model through in the following experiments to obtain the best performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Extensive Experiment on Extension Model</head><p>Table III provides results of our base model and extension model on MNIST, Fashion-MNIST, CIFAR-10, ImageNet and CIFAR-100. For grayscale datasets, such as MNIST and Fashion-MNIST, we convert the image into 3 channels through expanding. The performance of extension model is improved considerably over the base model both in average and standard deviation of the AUROC with Local DIM <ref type="bibr" target="#b35">[36]</ref>, indicating that a more effective module to optimize mutual information is beneficial. On all involved datasets, experiment results illustrate that the average AUROC or the standard deviation of our method outperforms all other methods to different extents. Furthermore, our method reveals greater advantage in more difficult datasets, from FashionMNIST which surpasses the SOTA by 3.2%, to 6% in CIFAR10, to 7.2% in CIFAR100 and to 8.3% in ImageNet Subset. This may be because our method is benefit from a decoder-free representation learning framework, where an advanced feature extracting model like RESNET can be utilized to handle pictures with higher resolution and more complex texture. More importantly, our method results in the lower standard deviation of AUROCs, which reflect the stability of the model when dealing with different kinds of anomalous data. This is vital especially in anomaly detection, where anomalous data can not be foreseen <ref type="bibr" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION AND FUTURE WORK</head><p>In this paper, we are the first to put forward an anomaly detection based objective function that can be optimized end-to-end in an unsupervised fashion. Many works can find mathematical support and further discover the potential optimization direction through our method. At last, based on the objective function we present a method that overperforms the state-of-the-arts, which illustrates the correctness of our objective function and rationality of the design of the loss function. Despite we restrict our method in an unsupervised anomaly detection setting, as can been seen in <ref type="bibr">Equation 4</ref>, this work can be extended to semi-supervised anomaly detection, which remains to be our future work. Notably, there are other loss functions in maximizing mutual information and minimizing entropy to explore. Furthermore, we can investigate the specific functions of each component in our lower bound objective function in Eq. 13. The function of mutual information seems obvious, as widely explored in unsupervised representation learning approaches <ref type="bibr" target="#b31">[32]</ref>, <ref type="bibr" target="#b33">[34]</ref>- <ref type="bibr" target="#b36">[37]</ref>, maximizing mutual information can effectively force the model to obtain better representation. Since the entropy forces z i 2 to be closed to zero, it may be indicated that the entropy regularizer limits the model representation ability. Thus this trade-off seems to force the network to represent normal data with limited representation ability. In another word, this trade-off force the network to generate features only to properly represent normal data, which is consistent with the insight in <ref type="bibr" target="#b7">[8]</ref>. As anomalous data is inaccessible during training, one feasible solution to enlarge the distribution of normal and anomalous data in latent space is to make anomalous data unable to be represented properly. Is this the essence of anomaly detection? We will explore this in our future work. .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>1 )Fig. 1 :Fig. 2 :</head><label>112</label><figDesc>Hyper parameter ? in adjusting the trade-off: To investigate the trade-off between the mutual information and the entropy, several experiments are conducted with a set of ? , noted as B = {0, 0.5, 1, 10, 20, 30, 40, 50, 60}, on datasets Average AUROC w.r.t. ? on CIFAR10 and CIFAR100. The testing AUROC w.r.t. ? during training.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 3 :</head><label>3</label><figDesc>The trade-off between MI and entropy. (Top) The AUROC curve (solid line in blue), the loss curve of NCE (dashed dot line in red) and the loss curve of entropy (dashed dot line in purple) w.r.t. ?. (Bottom) The mean value of z w.r.t. ? that corresponds to normal and anomalous data. (Best viewed in color)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 4 :</head><label>4</label><figDesc>The comparison of NCE-based and JSD-based mutual information estimator: conducted on dataset CIFAR10 where class 1 (car) is considered as normal data. (Top) The testing ROC curve during the training process by using NCE and JSD estimator for mutual information calculation. (Bottom) The estimated loss by using the NCE-based and JSD-based mutual information estimator during the training process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Algorithm 1 :</head><label>1</label><figDesc>Training Pseudocode for base model Input: batch size N, similarity function sim, structure of model E ? , entropy weight ?, constant c 1 represents the size of z i , constant c 2 is set to 20 for all experiment 1 for sampled minibatch {x k } for allk ? {1, ...., N } do</figDesc><table><row><cell></cell><cell>N k=1 do</cell></row><row><cell>3</cell><cell>randomly draw two augmentation functions</cell></row><row><cell></cell><cell>t, t ? T</cell></row></table><note>24 # Augmentation</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE I :</head><label>I</label><figDesc>Comparison of different MI and entropy estimators.</figDesc><table><row><cell>Loss function</cell><cell>CIFAR10</cell><cell>CIFAR100</cell></row><row><cell></cell><cell cols="2">AVG STD AVG STD</cell></row><row><cell cols="3">L N CE + ? ? L 2 Entropy 85.5 7.02 76.9 5.26</cell></row><row><cell cols="3">L N CE + ? ? L 1 Entropy 86.7 5.47 77.4 4.62</cell></row><row><cell>L JSD + ? ? L 2 Entropy</cell><cell cols="2">72.5 7.20 69.6 4.73</cell></row><row><cell>L JSD + ? ? L 1 Entropy</cell><cell cols="2">73.9 5.00 72.7 3.21</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE II :</head><label>II</label><figDesc>Efficient normal scoring mechanism.</figDesc><table><row><cell>Normal scoring function</cell><cell cols="2">CIFAR10</cell><cell cols="2">CIFAR100</cell></row><row><cell></cell><cell cols="4">AVG STD AVG STD</cell></row><row><cell>N ormalScore rand</cell><cell cols="4">86.4 1.04 75.6 1.26</cell></row><row><cell>N ormalScore mc</cell><cell cols="4">86.9 0.05 78.5 0.12</cell></row><row><cell>N ormalScore ori</cell><cell>86.7</cell><cell>?</cell><cell>77.4</cell><cell>?</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE III :</head><label>III</label><figDesc>Average area under the ROC curve (AUROC) in % of anomaly detection methods. For every dataset, each model is trained on the single class, and tested against all other classes. "SD" means standard deviation among classes. The best performing method is in bold. Results of Deep SVDD are borrowed from</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A MODEL STRUCTURE</head><p>The detailed structure of the model we used can be found in this section, where the model structure in <ref type="table">Table V</ref> is utilized for dataset ImageNet and model structure in <ref type="table">Table IV</ref> is utilized for other datasets. </p><p>#normal data has larger s i 10 return roc auc score(s i , label i )  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3: NCE Loss Pseudocode extension model</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Anomaly detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Chandola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acm Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Estimating the support of a high-dimensional distribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Williamson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1443" to="1471" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">One-class convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Oza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">M</forename><surname>Patel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Signal Processing Letters</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="277" to="281" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep one-class classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>G?rnitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Siddiqui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adversarially learned one-class classifier for novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sabokrou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khalooei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Adeli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Anomaly detection with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deecke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mandt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1809.04758</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Akcay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Atapour-Abarghouei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Breckon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Asian Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Ocgan: One-class novelty detection using gans with constrained latent representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Deep anomaly detection using geometric transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Golan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Effective end-to-end unsupervised outlier detection via inlier priority of discriminative network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5962" to="5975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Attribute restoration framework for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.10676v2</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">The mnist database of handwritten digits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<ptr target="http://yann.lecun.com/exdb/mnist/" />
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer, Tech. Rep</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Deep learning for anomaly detection: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">S</forename><surname>Chalapathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1901.03407</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Novelty detection: a review-part 1: statistical approaches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Markou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Novelty detection: a review-part 2: neural network based approaches</title>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A review of novelty detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A F</forename><surname>Pimentel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Clifton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Tarassenko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Signal Processing</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An overview of deep learning based methods for unsupervised and semi-supervised anomaly detection in videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">R</forename><surname>Kiran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Parakkal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Imaging</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sparse coding guided spatiotemporal feature learning for abnormal event detection in large videos</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="246" to="255" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Anomaly detection based on stacked sparse coding with intraframe classification strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1062" to="1074" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Video anomaly detection and localization based on an adaptive intra-frame classification network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Anomaly detection over noisy data using learned probability distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On-line unsupervised outlier detection using finite mixtures with discounting learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamanishi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Takeuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Milne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining &amp; Knowledge Discovery</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Coherence pursuit: Fast, simple, and robust principal component analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rahmani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">K</forename><surname>Atia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Signal Processing</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="6260" to="6275" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Robust pca via outlier pursuit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Caramanis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sanghavi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="3047" to="3064" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Autoencoding beyond pixels using a learned similarity metric</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B L</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>S?nderby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Winther</surname></persName>
		</author>
		<idno>PMLR</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1558" to="1566" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Generating images with perceptual similarity metrics based on deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="658" to="666" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deep anomaly detection with outlier exposure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deep semi-supervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Vandermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>G?rnitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-R</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning deep representations by mutual information estimation and maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fedorov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lavoie-Marchildon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Trischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Mutual information neural estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baratin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rajeshwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hjelm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="531" to="540" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Representation learning with contrastive predictive coding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">V</forename><surname>Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.03748</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.05709</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Buchwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="15" to="535" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m">series in Telecommunications and Signal Processing</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>Elements of information theory</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Adversarially learned inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Belghazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Mastropietro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Arjovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Noise-contrastive estimation: A new estimation principle for unnormalized statistical models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gutmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hyv?rinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</title>
		<meeting>the Thirteenth International Conference on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">On variational bounds of mutual information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Poole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ozair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Den Oord</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Extracting and composing robust features with denoising autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vincent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Manzagol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 25th international conference on Machine learning</title>
		<meeting>the 25th international conference on Machine learning</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="1096" to="1103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bialek</surname></persName>
		</author>
		<idno>physics/0004057</idno>
		<title level="m">The information bottleneck method</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Deep learning and the information bottleneck principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Tishby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zaslavsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Information Theory Workshop (ITW)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Deep variational information bottleneck</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Alemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Dillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Regularizing neural networks by penalizing confident output distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chorowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop Track in International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Variational discriminator bottleneck: Improving imitation learning, inverse rl, and gans by constraining information flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><forename type="middle">B</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Toyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="page" from="933" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Deep structured energy based models for anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Deep autoencoding gaussian mixture model for unsupervised anomaly detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lumezanu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unsupervised anomaly detection with generative adversarial networks to guide marker discovery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Schlegl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seeb?ck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Waldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schmidt-Erfurth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Langs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Information Processing in Medical Imaging</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Large deviations for markov processes and the asymptotic evaluation of certain markov process expectations for large times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Donsker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Varadhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Probabilistic Methods in Differential Equations</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1975" />
			<biblScope unit="page" from="82" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Small Encoder Architecture ReLU</title>
		<imprint/>
	</monogr>
	<note>Conv 2d(3, ndf, 3, 1, 0)</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">1, ndepth ) ? provides f local ResBlock (4 * ndf, 4 * ndf, 3, 1, ndepth ) ResBlock (4 * ndf, nrkhs , 3, 1, 1) ? provides f global ndf = 128, nrkhs = 1024, ndepth = 10 TABLE V: Big Encoder Architecture Big Encoder Architecture ReLU</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>ResBlock (4 * ndf, 4 * ndf. Conv 2d(3, ndf, 5, 2, 2)</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Relu</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Conv 2d(ndf, ndf, 3, 1, 0)</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">* ndf, 8 * ndf, 3, 1, ndepth ) ? provides f local ResBlock (8 * ndf, 8 * ndf, 3, 1, ndepth ) ResBlock (8 * ndf, nrkhs , 3, 1, 1) ? provides f global ndf = 192, nrkhs = 1536</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Resblock</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
