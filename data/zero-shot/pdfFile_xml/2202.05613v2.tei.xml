<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CMW-Net: Learning a Class-Aware Sample Weighting Mapping for Robust Deep Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020">AUGUST 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Journal Of L A T E X Class</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Files</surname></persName>
						</author>
						<title level="a" type="main">CMW-Net: Learning a Class-Aware Sample Weighting Mapping for Robust Deep Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<biblScope unit="volume">14</biblScope>
							<biblScope unit="issue">8</biblScope>
							<date type="published" when="2020">AUGUST 2020</date>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Meta Learning</term>
					<term>sample re-weighting</term>
					<term>noisy labels</term>
					<term>class imbalance</term>
					<term>semi-supervised learning</term>
					<term>partial-label learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Modern deep neural networks (DNNs) can easily overfit to biased training data containing corrupted labels or class imbalance. Sample re-weighting methods are popularly used to alleviate this data bias issue. Most current methods, however, require to manually pre-specify the weighting schemes as well as their additional hyper-parameters relying on the characteristics of the investigated problem and training data. This makes them fairly hard to be generally applied in practical scenarios, due to their significant complexities and inter-class variations of data bias situations. To address this issue, we propose a meta-model capable of adaptively learning an explicit weighting scheme directly from data. Specifically, by seeing each training class as a separate learning task, our method aims to extract an explicit weighting function with sample loss and task/class feature as input, and sample weight as output, expecting to impose adaptively varying weighting schemes to different sample classes based on their own intrinsic bias characteristics. Synthetic and real data experiments substantiate the capability of our method on achieving proper weighting schemes in various data bias cases, like the class imbalance, feature-independent and dependent label noise scenarios, and more complicated bias scenarios beyond conventional cases. Besides, the task-transferability of the learned weighting scheme is also substantiated, by readily deploying the weighting function learned on relatively smaller-scale CIFAR-10 dataset on much larger-scale full WebVision dataset. A performance gain can be readily achieved compared with previous state-of-the-art ones without additional hyper-parameter tuning and meta gradient descent step. The general availability of our method for multiple robust deep learning issues, including partial-label learning, semi-supervised learning and selective classification, has also been validated.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>D EEP neural networks (DNNs), equipped with highly parameterized structures for modeling complex input patterns, have recently obtained impressive performance on various applications, e.g., computer vision <ref type="bibr" target="#b0">[1]</ref>, natural language processing <ref type="bibr" target="#b1">[2]</ref>, speech processing <ref type="bibr" target="#b2">[3]</ref>, etc. These successes largely attribute to many large-scale paired samplelabel datasets expected to properly and sufficiently simulate the testing/evaluating environments. However, in most real applications, collecting such large-scale supervised datasets is notoriously costly, and always highly dependent on a rough crowdsourcing system or search engine. This often makes the training datasets error-prone, with unexpected data bias from the real testing distributions.</p><p>This distribution mismatch issue could have many different forms. For example, the collected training sets are often class imbalanced <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b4">[5]</ref>. Actually, real-world datasets are usually depicted as skewed distributions. Specifically, the frequency distribution of visual categories in our daily life is generally long-tailed, with a few common classes and many more rare ones. This often leads to a mismatch between collected datasets with long-tailed class distributions for training a machine learning model and our expectation on the model to perform well on all classes. Another popular data bias is the noisy label case <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b8">[9]</ref>. Even the most celebrated datasets collected from a crowdsourcing system with expert knowledge <ref type="bibr" target="#b9">[10]</ref>, like ImageNet, have been demonstrated to contain harmful examples with unreliable labels <ref type="bibr" target="#b10">[11]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>. To mitigate the high labeling cost, it has received increasing attention to collect web images by search engines <ref type="bibr" target="#b13">[14]</ref>. Though cheaper and easier to obtain training data, it often yields inevitable noisy labels due to the error-prone automatic tagging system <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b15">[16]</ref>.</p><p>The overparameterized DNNs tend to suffer significantly from overfitting on these biased training data, then conducting their poor performance in generalization. This robust deep learning issue has been theoretically illustrated in multiple literatures <ref type="bibr" target="#b16">[17]</ref>, <ref type="bibr" target="#b17">[18]</ref> and gradually attracted more attention in the field. Recently, various methods have been proposed to deal with such biased training data. Readers can refer to <ref type="bibr" target="#b18">[19]</ref>, <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref> for an overall review. In this paper, we focus on the sample re-weighting approach, which is a commonly used strategy against such data bias issue and has been widely investigated started at 1950s <ref type="bibr" target="#b24">[25]</ref>.</p><p>The sample re-weighting approach <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b25">[26]</ref> attempts to assign a weight to each example and minimize the corresponding weighted training loss to learn a classifier model. The example weights are typically calculated based on the training loss. More specifically, the learning methodology of sample re-weighting is to design a weighting function mapping from training loss to sample weight, and then iterates between calculating weights from current sample loss values and minimizing weighted training loss for classifier updating (that's why the method is called "re-weighting"). However, there exist two entirely contrary ideas for constructing such a loss-weight mapping. In class imbalanced problems, the function is generally set as monotonically increasing, aiming to enforce the learning to more emphasize samples with larger loss values since they are more like to be the minority class. Typical methods include Boosting and AdaBoost <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, hard negative mining <ref type="bibr" target="#b28">[29]</ref> and focal loss <ref type="bibr" target="#b29">[30]</ref>. But in noisy label problems, the function is more commonly set as monotonically decreasing, i.e., taking samples with smaller loss values as more important ones, since they are more likely to be high-confident ones with clean labels. Typical methods include self-paced learning (SPL) <ref type="bibr" target="#b30">[31]</ref>, iterative reweighting <ref type="bibr" target="#b31">[32]</ref> and multiple variants <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b33">[34]</ref>, <ref type="bibr" target="#b34">[35]</ref>. Although these pre-defined weighting schemes has substantiated to help improve the robustness of a learning algorithm on certain data bias scenarios, they still have evident deficiencies in practice. On the one hand, they need to manually preset a specific form of weighting function based on certain assumptions of training data. This, however, tends to be infeasible when we know insufficient knowledge underlying data or the label conditions are too complicated, like the case that the training set is both imbalanced and label-noisy. On the other hand, even when we properly specify certain weighting schemes, like focal loss <ref type="bibr" target="#b29">[30]</ref> or SPL <ref type="bibr" target="#b30">[31]</ref>, they inevitably involve hyper-parameters, like focusing parameter in the former and age parameter in the latter, to be manually preset or tuned by cross-validation. This tends to further raise their application difficulty in real problems.</p><p>To alleviate the above issues, our earlier work attempts to parameterize the weighting function as an MLP (multilayer perceptron) network with one hidden layer called MW-Net <ref type="bibr" target="#b8">[9]</ref>, as depicted in <ref type="figure" target="#fig_0">Fig. 1(a)</ref>, which is theoretically capable of dealing with such weighting function approximation problem <ref type="bibr" target="#b35">[36]</ref>. Instead of assuming a pre-defined weighting scheme, MW-Net can automatically learn a suitable weighting strategy from data for the training data at hand. Experiments on datasets with class imbalanced or noisy labels show that the automatically learned weighting schemes are consistent with the properly defined ones as traditional.</p><p>However, when encountered with complicated data bias scenarios, especially those with heterogeneous bias situations, MW-Net inclines to significantly lose efficacy in such more practical cases. This issue is mainly attributed to the fact that MW-Net assumes one unique weighting function shared by all classes of training data, implying that different classes should possess consistent bias. Unfortunately, this strong assumption is often invalid. As shown in <ref type="figure" target="#fig_1">Fig. 2(a)</ref>, we plot the empirical probability density function (pdf) of training loss 1 of each class for four kinds of common data bias types, including class imbalance, symmetric noise, asymmetric noise and more realistic feature-dependent noise <ref type="bibr" target="#b37">[38]</ref>. It can be seen that only in symmetric noise case, each <ref type="bibr" target="#b0">1</ref>. Since the loss values of all samples have been considered and validated to be important and beneficial information for exploring proper sample weight assignment principle, its distribution largely delivers the underlying bias configurations underlying data <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b36">[37]</ref>. class is with an approximately homoscedastic training loss distribution for all classes. Thus MW-Net can properly learn a suitable weighting scheme and naturally distinguish clean and noisy samples in this instance, as shown in <ref type="figure" target="#fig_1">Fig.2</ref>(b) (second column). While for all other cases, MW-Net can not finely adapt to the heteroscedastic loss distributions across classes. Particularly, for asymmetric and featuredependent noise cases, MW-Net easily learns a monotonically increasing weighting function for all classes and fails to entirely distinguish clean and noisy samples as shown in <ref type="figure" target="#fig_1">Fig.2(b) (third and fourth columns)</ref>. The real-world biased datatsets (like WebVision <ref type="bibr" target="#b13">[14]</ref>), however, always possess even more inter-class heterogenous bias configurations than these simulated biased ones. It is thus fairly insufficient and improper to employ only one single weighting function to deal with such complicated biased datasets.</p><p>This issue can be more intrinsically analyzed under the framework of meta-learning. From the task-distribution view, a meta-learning approach attempts to learn a task-agnostic learning algorithm from a family of training tasks, that is hopeful to be generalizable across tasks and enable new tasks to be learned better and more easily <ref type="bibr" target="#b38">[39]</ref>. By taking every class of training samples as a separate learning task, MW-Net can also be seen as a meta-learning strategy, aiming to learn how to properly impose an explicit weighting function from a set of training classes/tasks. The properness of using such meta-learning regime, however, is built on the premise that all training tasks approximately follow a similar task distribution <ref type="bibr" target="#b39">[40]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>. In complicated data bias scenarios, however, such premise is evidently hampered by the heterogeneous bias situations across different classes, making MW-Net hardly fit a concise weighting rule generally suitable for all classes.</p><p>The issue will be more prominent for practical large-scale datasets, especially for those containing large number of training classes but also possessing many rare ones. Then the inter-class heterogeneity will be more significant and the data bias situation more complicated. An easy amelioration is to separately learn a weighting function for each training task/class to obtain a better flexibility. This easy learning manner, however, is not only impractical due to its required large computation burden, but also easily leads to overfitting and thus hardly extracts available weight schemes from highly insufficient training task information for each class. More importantly, such learning manner is deviated from the original motivation of meta-learning, e.g., to learn a general weighting function imposing methodology generalizable and transferable to new biased datasets. The learned weighting scheme is even infeasible to be utilized in new problems with different class numbers and characteristics due to their mismatched input information to the meta-model.</p><p>Against the aforementioned issues, in this study, we substantially reform MW-Net to make it performable in practical scenarios with complicated data biases. The core idea is to extract certain feature representations from all training classes/tasks to deliver their specific heterogeneous bias characteristics for discriminating similar training classes (to accumulate them as a meta-class), and take this metaknowledge as the supplementary input information besides the sample loss into the weighting function. The purpose is to make such reformed MW-Net capable of distinguishing individual properties of different data classes, and adaptively ameliorating their imposed weighting function forms. We thus call this approach as the Class-aware Meta-Weight-Net, or CMW-Net for brevity.</p><p>By employing CMW-Net so proposed, the limitations of the MW-Net are expected to be essentially ameliorated. On the one hand, the involvement of the class feature makes CMW-Net capable of integrating similar training classes (i.e., a meta-class) to soundly train their shared weighting scheme while eliminating the unexpected interference from heterogeneouss classes. The method is thus hopeful to achieve better approximation capability to this specific meta-learning task even for datasets with complicated biases, as can be evidently observed <ref type="figure" target="#fig_0">Fig. 1</ref>(b) (more details are introduced in Sec. 4). On the other hand, this meta-class-knowledge embedded structure makes the learned weighting function possess consistent format across different training datasets, and thus enables the possibility of transferring the meta-learned weighting scheme to be readily used to new unseen biased datasets. The method is thus also with potentially stronger task-generalization capability. This is especially meaningful for those large-scale problems, since we can readily obtain the weighting-function-imposing methodology from relatively smaller-scale tasks, and then directly use it in larger-scale problems (corresponding to the meta-train and meta-test stages, respectively <ref type="bibr" target="#b42">[43]</ref>), avoiding the extra time-consuming weighting function tuning process.</p><p>In a nutshell, the main contribution of this paper can be summarized as follows.</p><p>1) Through simply taking the scale level of each sample class as input task information to represent its meta-class feature, we realize an easy form for CMW-Net meta-model. Albeit simple, this task information is validated to be effective and capable of assembling sample classes with similar homoscedastic loss distributions, as shown in <ref type="figure" target="#fig_1">Fig.2(a)</ref>, revealing the potential usefulness of such CMW-Net framework and possibility for further improving its performance.</p><p>2) The proposed CMW-Net is model-agnostic, and is substantiated to be performable in different complicated data bias cases, like class imbalance, symmetric, asymmetric and feature-dependent label noise ones, as shown in <ref type="figure" target="#fig_1">Fig.2(c)</ref>. It is also verified to obtain competitive results with state-ofthe-art (SOTA) methods on real-world biased datasets, like ANIMAL-10N <ref type="bibr" target="#b43">[44]</ref>, Webvision <ref type="bibr" target="#b13">[14]</ref> and WebFG-496 <ref type="bibr" target="#b44">[45]</ref>.</p><p>3) We further make soft-label amelioration for the proposed CMW-Net model by integrating sample pseudo-label knowledge estimated by model prediction, aiming to correct and reuse the suspected noisy samples into the model training. Attributed to the beneficial information contained among these samples, the performance of CWN-Net tends to be evidently improved, especially for noisy label cases. <ref type="bibr" target="#b3">4)</ref> We study the transferability of CMW-Net. The learned weighting scheme can be used in a plug-and-play manner, and can be directly deployed on unseen datasets, without extra hyperparameters required to be tuned. 5) We also evaluate easy generality of CMW-Net to other robust learning tasks, including partial-label learning <ref type="bibr" target="#b45">[46]</ref>, semi-supervised learning <ref type="bibr" target="#b46">[47]</ref> and selective classification <ref type="bibr" target="#b47">[48]</ref>.</p><p>The paper is organized as follows. Sec. 2 discusses related work. Sec. 3 presents the proposed CMW-Net method as well as its learning algorithm and convergence analysis. Simulated and real-world experiments are demonstrated in Sec. 4 and Sec. 5, respectively. Sec. 6 evaluates the transferability of CMW-Net. Sec. 7 introduces the evaluation of CMW-Net to several related applications. The conclusion is finally made.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>Conventional Sample Weighting Methods. The idea of re-weighting examples can be dated back to importance sampling <ref type="bibr" target="#b24">[25]</ref>, aiming to assign weights to samples in order to match one distribution to another. Besides, the early attempts of dataset resampling <ref type="bibr" target="#b48">[49]</ref>, <ref type="bibr" target="#b49">[50]</ref> or instance re-weight <ref type="bibr" target="#b50">[51]</ref> preevaluate the sample weights using certain prior knowledge on the task or data. To make sample weights fit data more flexibly, more recent researchers focus more on pre-designing an explicit weighting function mapping from training loss to sample weight, and dynamically ameliorate weights during training process. There are mainly two manners to design such weighting function. One is to make it monotonically increasing, which is specifically effective in class imbalance case. Typical methods along this line include the boosting algorithm <ref type="bibr" target="#b26">[27]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b51">[52]</ref>, hard example mining <ref type="bibr" target="#b28">[29]</ref> and focal loss <ref type="bibr" target="#b29">[30]</ref>, which impose larger weights to ones with larger loss values. On the contrary, another series of methods specify the weighting function as monotonically decreasing, more popularly used in noisy label cases. Typical examples include SPL <ref type="bibr" target="#b30">[31]</ref> and its extensions <ref type="bibr" target="#b32">[33]</ref>, <ref type="bibr" target="#b52">[53]</ref>, iterative reweighting <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b34">[35]</ref>, paying more emphasis on easy samples with smaller losses. The evident limitation of these methods is that they all need to manually pre-specify the form of weighting function as well as its hyper-parameters based on users' prior expert knowledge on the investigated data and learning problem, raising their difficulty to be readily used in real applications. Meanwhile, presetting a certain form of weighting function suffers from the limited flexibility to make the model adaptable to the complicated training data biases, like those with inter-class bias-heterogenous distributions.</p><p>Meta Learning Methods for Sample Weighting. Inspired by meta-learning developments <ref type="bibr" target="#b14">[15]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b42">[43]</ref>, recently some methods have been proposed to adaptively learn sample weights from data to make the learning more automatic and reliable. Typical methods along this line include FWL <ref type="bibr" target="#b53">[54]</ref>, learning to teach <ref type="bibr" target="#b54">[55]</ref>, MentorNet <ref type="bibr" target="#b36">[37]</ref>, L2RW <ref type="bibr" target="#b25">[26]</ref>, and MW-Net <ref type="bibr" target="#b8">[9]</ref>. Especially, MW-Net <ref type="bibr" target="#b8">[9]</ref> adopts an MLP net to learn an explicit weighting scheme instead of conventional pre-defined weighting scheme. It has been substantiated that weighting function automatically extracted from data comply with those proposed in the hand-designed studies for classimbalance or noisy labels <ref type="bibr" target="#b8">[9]</ref>. As analyzed in Sec. 1, the effectiveness of the method, however, is built on the premise assumption that all training classes are with approximately homogeneous biases. However, real-world biased dataset are always inter-class heteroscedastic, and thus it tends to lose efficacy in more practical applications.</p><p>Other Methods for Class Imbalance. Except for sample re-weighting methods, there exist other learning paradigms for handling class imbalance. Typically, <ref type="bibr" target="#b55">[56]</ref>, <ref type="bibr" target="#b56">[57]</ref> try to transfer the knowledge learned from major classes to minor ones. <ref type="bibr" target="#b57">[58]</ref> uses meta feature modulator to balance the contribution per class during the training phase. The metric learning based methods, e.g., triple-header loss <ref type="bibr" target="#b58">[59]</ref> and range loss <ref type="bibr" target="#b59">[60]</ref>, have also been developed to effectively exploit the tailed data to improve the generalization. Furthermore, <ref type="bibr" target="#b60">[61]</ref> applies domain adaptation on learning tail class representation.</p><p>Other Methods for Corrupted Labels. For handling noisy label issue, many methods have also been designed by making endeavor to correct noisy labels to their true ones to more sufficiently discover and reuse the beneficial knowledge underlying these corrupted data. The typical strategies include supplementing an extra label correction step <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b61">[62]</ref>, <ref type="bibr" target="#b62">[63]</ref>, <ref type="bibr" target="#b63">[64]</ref>, designing a robust loss function <ref type="bibr" target="#b5">[6]</ref>, <ref type="bibr" target="#b64">[65]</ref>, <ref type="bibr" target="#b65">[66]</ref>, <ref type="bibr" target="#b66">[67]</ref>, <ref type="bibr" target="#b67">[68]</ref>, <ref type="bibr" target="#b68">[69]</ref>, revising the loss function via loss correction <ref type="bibr" target="#b52">[53]</ref>, <ref type="bibr" target="#b69">[70]</ref>, <ref type="bibr" target="#b70">[71]</ref>, <ref type="bibr" target="#b71">[72]</ref>, and so on. Please refer to references <ref type="bibr" target="#b19">[20]</ref>, <ref type="bibr" target="#b20">[21]</ref>, <ref type="bibr" target="#b21">[22]</ref>, <ref type="bibr" target="#b22">[23]</ref>, <ref type="bibr" target="#b23">[24]</ref> for a more overall review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">CLASS-AWARE META-WEIGHT-NET</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sample Re-weighting Methodology</head><p>Consider a classification problem with biased training set</p><formula xml:id="formula_0">D tr = {x i , y i } N i=1</formula><p>, where x i denotes the i-th training sample, y i ? {0, 1} C is the one-hot encoding label corresponding to x i , and N is the number of the entire training data. f (x; w) denotes the classifier with w representing its model parameters. In current applications, f (x, w) is always set with a DNN architecture. We thus also adopt DNN as our prediction model, and call it a classifier network for convenience in the following. Generally, the optimal model parameter w * can be extracted by minimizing the following training loss calculated on the training set:</p><formula xml:id="formula_1">w * = arg min w 1 N N i=1 (f (x i ; w), y i ),<label>(1)</label></formula><p>where (f (x; w), y) denotes the training loss on training sample (x, y). In this study, we adopt the commonly adopted cross-entropy (CE) loss (f (x; w), y) = ?y T log(f (x; w)), where f (x; w) denotes the network output (especially, f (x; w) ? R c when using Sigmoid activation function in the end layer of the network). For notation convenience, we denote L tr i (w) = (f (x i ; w), y i ) in the following. In the presence of biased training data, sample reweighting methods aim to enhance the robustness of network training by imposing a weight v i ? [0, 1] on the i-th training sample loss. Then the optimal parameter w * is calculated by minimizing the following weighted loss function:</p><formula xml:id="formula_2">w * = arg min w N i=1 v i (f (x i ; w), y i ).<label>(2)</label></formula><p>To make sample weights fit data more flexibly, researchers mostly focused on pre-defining a weighting function mapping from training loss to sample weight, and dynamically ameliorate weights during training process <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b29">[30]</ref>, <ref type="bibr" target="#b30">[31]</ref>. More details can refer to literatures provided in related work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Meta-Weight-Net</head><p>As aforementioned, most conventional sample re-weighting studies need to manually pre-specify the form of weighting function as well as their hyper-parameters based on cetain expert knowledge for the investigated problem. This naturally raises their difficulty in readily using them in real applications. Meanwhile, such weighting function presetting manner suffers from the limited flexibility to adapt complicated data bias cases, like applications simultaneously containing class imbalance and noisy label abnormalities in their certain classes. To address above issues, MW-Net <ref type="bibr" target="#b8">[9]</ref> is proposed to use an MLP to deliver a suitable weighting function from data. The architecture of the MW-Net (see <ref type="figure" target="#fig_0">Fig. 1</ref>(a)), denoted as V ( ; ?), is naturally succeeded from the previous sample re-weighting approaches, by setting its input as training loss and output as sample weight, with ? as its network parameter. Just following standard MLP set, each hidden node is with ReLU activation function, and the output is with the Sigmoid activation function, to guarantee the output located in the interval of [0, 1]. This weight net is known with a strong fitting capability to represent a wide range of weighting function forms, like those monotonically increasing or decreasing ones as conventional manually specified ones <ref type="bibr" target="#b35">[36]</ref>. The MW-Net thus ideally includes many conventional sample weighting schemes as its special cases. The parameters contained in MW-Net can be optimized in a meta learning manner <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b42">[43]</ref>. Specifically, with a small amount of unbiased meta-data set D meta = {x</p><formula xml:id="formula_3">(meta) i , y (meta) i } M i=1 (i.e.</formula><p>, with clean labels and balanced data class distribution), representing the meta-knowledge of ground-truth sample-label distribution, where M is the number of meta-samples, the optimal parameter ? * of MW-Net can be obtained by minimizing the following bi-level optimization problem:</p><formula xml:id="formula_4">? * = arg min ? 1 M M i=1 L meta i (w * (?)), s.t. w * (?) = arg min w N i=1 V (L tr i (w); ?)L tr i (w),<label>(3)</label></formula><p>where L meta</p><formula xml:id="formula_5">i (w * (?)) = f (x (meta) i ; w * (?)), y (meta) i</formula><p>. Experimental results on datasets with inter-class homogeneous bias situations, like all classes with similar imbalance rate for class imbalance or similar noise rate for noisy labels case, have shown that the learned weighting schemes are consistent with empirical pre-defined ones as conventional methods <ref type="bibr" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Class-aware Meta-Weight-Net</head><p>The main limitation of MW-Net lies in its specification of only one unique weighting scheme to handle data biases over all training classes, which largely ignores the inter-class variation of bias situations in practical datasets, especially for those with large number of training classes. This problem can be easily observed in the asymmetric and feature-dependent noise cases as depicted in <ref type="figure" target="#fig_1">Fig.2(b)</ref>. It is evident that when the biased datasets are with inter-class heteroscedastic loss distributions, MW-Net tends to largely lose its efficacy. This motivates us to reform MW-Net to make it possess adaptability of specifying proper weighting schemes to different classes based on their own internal bias characteristics.</p><p>To this aim, we propose to integrate meta-class-feature knowledge into the input of the original MW-Net as a beneficial compensation besides the original sample loss input. The purpose is to enable the output weight of a sample correlated with its included training class/task, so as to make it possibly adaptable against class bias variations. We thus call the new weighting model as Class-aware Meta-Weight-Net (CMW-Net for brevity). Such amelioration is expected to accumulate training classes with approxmiately homogeneous bias types to extract a possible faithful sampleweighting scheme shared by them, while suppressing the unexpected interference by other heterogeneous ones.</p><p>In this study, we attempt to take the scale level of each training class to represent its meta-class feature. Albeit simple, such feature does be able to deliver helpful class/task pattern underlying its bias types. For instance, as demonstrated in <ref type="figure" target="#fig_1">Fig. 2</ref>(a) and 2(c) (especially, please see class imbalance, asymmetric noise and feature-dependent noisy label cases), for training classes with relatively small number of samples, the class imbalance bias tends to more possibly occur, and it is thus more rational to set the sample-weighting function as monotonically increasing to emphasize those informative marginal samples with larger loss values. Yet for those with relatively large number of training samples, the weighting function should be more rationally set as monotonically decreasing to take samples with smaller loss values as more important ones, since in this case we have sufficient training samples and should focus more on those high-confident ones with probable clean labels.</p><p>Specifically, we design the architecture of CMW-Net as the integration of two branches, as depicted in <ref type="figure" target="#fig_0">Fig. 1</ref> <ref type="bibr">(b)</ref>. Denote N i (i = 1,? ? ?, N ) as the number of samples contained in the training class to which the i-th sample x i belongs. Then one branch of CMW-Net can be expressed as C(N i ; ?) ? {0, 1} K , by taking N i as its input to represent the metaclass knowledge, and including a hidden layer containing K nodes, attached with K-levels of scales ? = {? k } K k=1 sorted in an ascending order (i.e., ? 1 &lt; ? 2 &lt; ? ? ? &lt; ? K ). The output of this branch is a K-dimensional one-hot vector (i.e., metaclass label), whose 1-element is located at its k-th dimension corresponding to the nearest ? k to the input N i .</p><p>The other branch can be represented as V(L tr i (w); ?) ? R K , built as an MLP architecture with the loss value of the i-th sample as its input, containing one hidden layer and a K-dimensional output 2 . Different from 1-dimensional weight output of MW-Net, this network contains K output weights, corresponding to its K different weighting schemes imposed on samples located in different meta-classes. The sharing hidden layer among these meta-classes extracts the 2. In all our experiments, we just simply set the hidden layer containing 100 nodes with ReLU activation function, and specify the output node with Sigmoid activation function, to guarantee the output of each meta-class located in the interval of [0, 1].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Step 6</head><p>Step 7</p><p>Step 8  correlation among weighting principles of different metaclasses, which helps reduce the risk of overfitting.</p><p>Then the CMW-Net weighting function is formulated as:</p><formula xml:id="formula_6">V(L tr i (w), N i ; ?, ?) = V(L tr i (w); ?) ? C(N i ; ?),<label>(4)</label></formula><p>where ? denotes the dot product between two vectors. Through the modulation of the meta-class information, CMW-Net is expected to learn a class-aware weighting function by accumulating classes with homogeneous bias situations, and allow different sample classes possessing different weighting schemes complying their own internal bias characteristics. Now, the objective function of CWM-Net can be written as the following bi-level optimization problem:</p><formula xml:id="formula_7">{? * , ? * } = arg min ?,? 1 M M i=1 L meta i (w * (?, ?)),<label>(5)</label></formula><formula xml:id="formula_8">w * (?, ?) = arg min w N i=1 V(L tr i (w), N i ; ?, ?)L tr i (w). (6)</formula><p>Note that CMW-Net is degenerated to the original MW-Net if we take K = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Learning Algorithm of CMW-Net</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Meta-training: learning CMW-Net from training data</head><p>There are two groups of hyper-parameters, including ? and ?, required to be optimized to attain the CMW-Net model. Therein, the optimization of the scale parameters ? corresponds to an integer programming problem and thus hard to design an efficient algorithm for getting its global optimum. We thus adopt a two-stage process to first predetermine a rational specification of ? * , and then focus the computation on optimizing other parameters in the problem. In specific, the standard K-means algorithm <ref type="bibr" target="#b72">[73]</ref> is employed on the sample numbers within all training classes (including C positive integers) to obtain cluster centers ? = {? k } K k=1 sorted in an ascending order. Throughout all our experiments, we simply set K = 3 to make our trained CMW-Net able to distinguish small, moderate, and largescale meta-classes for different datasets. All our experiments show consistently and stably fine performance under such simple setting. This also implies that there remains a large room for further performance enhancement of our model by utilizing more elegant optimization techniques and designing more comprehensive class features, which will be further investigated in our future research.</p><p>Then our aim is to solve the bi-level optimization of Eqs. <ref type="bibr" target="#b4">(5)</ref> and <ref type="bibr" target="#b5">(6)</ref> to obtain optimal ? * and w * . To make notation concise, we directly neglect ? in Eqs. <ref type="bibr" target="#b4">(5)</ref> and <ref type="bibr" target="#b5">(6)</ref> in the following. Note that exact solutions to Eqs. (5) and (6) require to solve the optimal w * whenever ? gets updated. This is both analytically infeasible and computationally expensive. Following previous works <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b25">[26]</ref>, we adopt one step of stochastic gradient descent (SGD) update for w to online approximate the optimal classifier for a given ?, which guarantees the efficiency of the algorithm.</p><p>Formulating learning manner of classifier network. To optimize Eq. (6), in each iteration a mini-batch of training samples {(x i , y i )} n i=1 is sampled, where n is the mini-batch size. Then the classifier parameter can be updated by moving the current w (t) along the descent direction of Eq. (6) on the mini-batch training data as the following expression:</p><formula xml:id="formula_9">w (t+1) (?) =w (t) ? ? n i=1 V(L tr i (w (t) ), N i ; ?)? w L tr i (w) w (t) ,<label>(7)</label></formula><p>where ? is the learning rate for the classifier network f . Updating parameters of CMW-Net: Based on the classifier updating formulation? (t+1) (?) from Eq. <ref type="formula" target="#formula_9">(7)</ref>, the parameter ? of the CMW-Net can then be readily updated guided by Eq.(5), i.e., moving the current parameter ? (t) along the objective gradient of Eq. <ref type="bibr" target="#b4">(5)</ref>. Similar to the updating step for w, the stochastic gradient descent (SGD) is also adopted. That is, the update is calculated on a sampled mini-batch of meta-data {(x meta i , y meta i )} m i=1 , expressed as</p><formula xml:id="formula_10">? (t+1) = ? (t) ? ? 1 m m i=1 ? ? L meta i (? (t+1) (?)) ? (t) ,<label>(8)</label></formula><p>where ? is the learning rate for CMW-Net. Notice that ? in? t+1 (?) here is a variable instead of a quantity, which makes the gradient in Eq. (8) able to be computed. Updating parameters of classifier network: Then, the updated ? (t+1) is employed to ameliorate the parameter w of the classifier network, i.e.,</p><formula xml:id="formula_11">w (t+1) =w (t) ? ? n i=1 V(L tr i (w (t) ), N i ; ? (t+1) )? w L tr i (w) w (t) .<label>(9)</label></formula><p>Note that we derive with plain SGD here. This, however, also holds for most variants of SGD, like Adam <ref type="bibr" target="#b73">[74]</ref>. The CMW-Net learning algorithm can then be summarized in Algorithm 1, and <ref type="figure" target="#fig_2">Fig.3</ref> illustrates its main implementation process (steps 6-8). All computations of gradients can be efficiently implemented by automatic differentiation techniques and generalized to any deep learning architectures of the classifier. The algorithm can be easily implemented using popular deep learning frameworks like PyTorch <ref type="bibr" target="#b74">[75]</ref>. It is easy to see that both the classifier and CMW-Net gradually ameliorate their parameters during the learning process based on their values calculated in the last step, and the weights thus tends to be updated in a stable manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 The CMW-Net Meta-training Algorithm</head><p>Input: Training dataset D tr , meta-data set D meta , batch size n, m, max iterations T . Output: Classifier parameter w ( * ) , CMW-Net parameter ? ( * ) 1: Apply K-means on the sample numbers of all training classes to obtain ? = {? k } K k=1 sorted in an ascending order. 2: Initialize classifier network parameter w (0) and CMW-Net parameter ? (0) . 3: for t = 0 to T ? 1 do <ref type="bibr">4:</ref> {x, y} ? SampleMiniBatch(D tr , n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>{x meta , y meta } ? SampleMiniBatch(D meta , m).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Formulate the learning manner of classifier network w (t+1) (?) by Eq. (7).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7:</head><p>Update parameter ? (t+1) of CMW-Net by Eq. (8). <ref type="bibr">8:</ref> Update parameter w (t+1) of classifier by Eq. (9). 9: end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Analysis on intrinsic learning mechanism of CMW-Net</head><p>The updating step of Eq. (8) can be equivalently rewritten as (derivations are presented in supplementary material):</p><formula xml:id="formula_12">? (t+1) = ? (t) + ?? n j=1 1 m m i=1 G ij ?V(L tr j (w (t) ), N j ; ?) ?? ? (t) ,<label>(10)</label></formula><p>where</p><formula xml:id="formula_13">G ij = ?L meta i (?) ?? T w (t+1) (?) ?L tr j (w) ?w w (t)</formula><p>. Neglecting</p><formula xml:id="formula_14">the coefficient 1 m m i=1 G ij ,</formula><p>it is easy to see that each term in the above sum orients to the ascend gradient of the weight function V(L tr j (w (t) ), N j ; ?). The coefficient imposed on the j-th gradient term, 1 m m i=1 G ij , represents the similarity between the gradient of the j-th training sample computed on the training loss and the average gradient of the minibatch meta data calculated on meta loss. This means that if the learning gradient of a training sample is similar to that of the meta samples, then it inclines to be considered as in-distribution and CMW-Net tends to produce a higher sample weight for it. Conversely, samples with gradient different from that of the meta set incline to be suppressed. This understanding is consistent with the intrinsic working mechanism underlying the well-known MAML <ref type="bibr" target="#b40">[41]</ref>, <ref type="bibr" target="#b75">[76]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Meta-test: transferring CMW-Net to unseen tasks</head><p>After the meta-training stage, the learned CMW-Net with parameter ? ( * ) can then be transferred to assign proper sample weights on unseen biased datasets. Specifically, for a query dataset D q = {x q i , y q i } N q i=1 , we first need to implement K-means on sample numbers of all classes to obtain its cluster centers ? q = {? q k } K k=1 as meta-class feature. Then the learned CMW-Net can be directly used to imposing sample weights to the classifier learning of the problem by solving:</p><formula xml:id="formula_15">u * = arg min u N q i=1 V(L q i (u), N q i ; ? * , ? q )L q i (u),<label>(11)</label></formula><p>where L q i (u) = (f (x q i ; u), y q i ), and N q i represents the number of samples contained in the class to which x q i belongs. Then we can directly solve Eq.(11) with the learned ? * to obtain classifier u * . The overall algorithm is summarized in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 The CMW-Net Meta-test Algorithm</head><p>Input: Training dataset D q , batch size n , max iterations T and meta-learned CMW-Net with parameter ? * . Output: Classifier parameter u * .</p><p>1: Apply K-means on sample numbers of all training classes to obtain ? q = {? q k } K k=1 sorted in an ascending order. 2: Initialize classifier network parameter u (0) . <ref type="bibr">3:</ref> for t = 0 to T ? 1 do <ref type="bibr">4:</ref> Update classifier u (t+1) by solving Eq. (11). 5: end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Convergence of the CMW-Net Learning Algorithm</head><p>Next we attempt to establish a convergence result of our method for calculating Eqs. <ref type="bibr" target="#b4">(5)</ref> and <ref type="bibr" target="#b5">(6)</ref> in a bi-level optimization manner. In particular, we theoretically show that our method converges to critical points of both the meta loss (Eq.(5)) and training loss (Eq.(6)) under some mild conditions in Theorem 1 and 2, respectively. The proofs are presented in the supplementary material (SM for brevity). Theorem 1. Suppose the loss function is Lipschitz smooth with constant L, and CMW-Net V(?, ?; ?) is differential with a ?-bounded gradient and twice differential with its Hessian bounded by B, and the loss function have ?-bounded gradients with respect to training/meta data. Let the learning rate ? t , ? t , 1 ? t ? T be monotonically decreasing sequences, and satisfy</p><formula xml:id="formula_16">? t = min{ 1 L , c1 ? T }, ? t = min{ 1 L , c2 ? T }, for some c 1 , c 2 &gt; 0, such that ? T c1 ? L, ? T c2 ? L. Meanwhile, they satisfy ? t=1 ? t = ?, ? t=1 ? 2 t &lt; ?, ? t=1 ? t = ?, ? t=1 ? 2 t &lt; ?. Then CMW-Net can then achieve E[ ?L meta (? (t) (? (t) )) 2 2 ] ? in O(1/ 2 ) steps. More specifically, min 0?t?T E ?L meta (? (t) (? (t) )) 2 2 ? O( C ? T ),</formula><p>where C is some constant independent of the convergence process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Theorem 2. Under the conditions of Theorem 1, CMW-Net can</head><formula xml:id="formula_17">achieve E[ ?L tr (w (t) ; ? (t) ) 2 2 ] ? in O(1/ 2 ) steps, where L tr (w; ?) = N i=1 V(L tr i (w), N i ; ?)L tr i (w). More specifically, min 0?t?T E ?L tr (w (t) ; ? (t) ) 2 2 ? O( C ? T ),</formula><p>where C is some constant independent of the convergence process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Enhancing CMW-Net with Soft Label Supervision</head><p>In the typical bias case that some training samples are with corrupted labels, the sample weighting strategy tends to largely neglect the function of these samples by imposing small or even zero weights on them. This manner, however, inclines to regrettably waste the beneficial information essentially contained in these samples. Some recent researches have thus been presented to possibly correct the noisy labels and reuse them in training. One popular option is to extract a pseudo soft label z on a sample x through the clue of the classifier's estimation during the training iterations, and then set the training loss as a convex weighting combination of loss terms computed with the suspected noisy label y and the pseudo-label z <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b7">[8]</ref>, <ref type="bibr" target="#b76">[77]</ref>, <ref type="bibr" target="#b77">[78]</ref>, i.e.,</p><p>where v ? [0, 1] denotes the sample weight. By setting the loss as the cross-entropy, the loss (12) can be rewritten as:</p><formula xml:id="formula_18">S (f (x; w), y) = ? (vy + (1 ? v)z) T log(f (x; w)). (13)</formula><p>It can then be understood as setting a corrected soft label vy+(1?v)z to ameliorate the original label y to make it more reliably reused and avoid roughly suppressing or throwing off the sample from training as conventional. We then shortly introduce the current research on how to set the sample weight v in the above <ref type="bibr" target="#b11">(12)</ref> or <ref type="bibr" target="#b12">(13)</ref>. The early attempts often adopted a manual manner for setting this hyper-parameter, e.g., the v is empirically set as v = 0.8 for all samples in <ref type="bibr" target="#b76">[77]</ref>. Evidently, such a fixed and constant weight specification could not sufficiently convey the variant knowledge of training samples with different contents of corruption and reliability. Afterwards, some methods try to dynamically assign individually weights for different samples. Typically, SELFIE <ref type="bibr" target="#b77">[78]</ref> iteratively selects clean samples by assigning weights v = 1 on them, and neglect doubtful noisy samples by setting their weights as v = 0 in (13). <ref type="bibr" target="#b6">[7]</ref> ameliorates this hard weighting manner as soft, by fitting a two-component mixture model per epoch to estimate the probability of a sample being clean or noisy, and then use this probability to assign a soft weight for the corresponding sample. Recently, DivideMix <ref type="bibr" target="#b7">[8]</ref> improves <ref type="bibr" target="#b6">[7]</ref> by adopting a Gaussian mixture model to estimate v on its per-sample loss distribution and using this clue to set a soft weight v.</p><p>However, all above methods require to exploit a separate early-learning stage <ref type="bibr" target="#b78">[79]</ref> to heuristically pre-determine the sample weights v, while certainly ignore the beneficial feedback from the classifier during the learning process. We thus can naturally introduce our CMW-Net method to automatically explore a weighting scheme by making it trained together with the classifier in a meta-learning manner. Specifically, we just need to easily revise the training objective of CMW-Net in Eq.(6) as (called CMW-Net-SL):</p><formula xml:id="formula_19">w * (?) = arg min w N i=1 [V(L tr i (w), N i ; ?)L tr i (w) + (1 ? V(L tr i (w), N i ; ?))L P se i (w)],<label>(14)</label></formula><p>where L P se</p><formula xml:id="formula_20">i (w) = (f (x i ; w), z i ).</formula><p>Taking a similar process as Sec. 3.4.2, we have</p><formula xml:id="formula_21">? (t+1) = ? (t) + ??? n j=1 1 m m i=1 (G ij ? G ij ) ?V(L tr j (w (t) ), N j ; ?) ?? ? (t) ,<label>(15)</label></formula><p>where</p><formula xml:id="formula_22">G ij = ?L meta i (?) ?? T w (t+1) (?) ?L P se j (w) ?w w (t)</formula><p>. Compared with CMW-Net, it is seen that CMW-Net-SL produces another term G ij to control the learning of the meta-learner.</p><formula xml:id="formula_23">Specifically, if 1 m m i=1 (G ij ? G ij ) &gt; 0,</formula><p>it means that the similarity between learning gradient of a training sample with original label and the meta samples is larger than that of a training sample with pseudo-label, and then it will be considered as a relatively clean label and CMW-Net tends to produce a higher sample weight to it. Otherwise, it inclines to be considered as a relatively noisy label and CMW-Net will suppress the influence of original labeled sample while produce more confidence on pseudo-labeled one. True label 96.9% 0.8% 1.1% 0.6% 0.1% 0.0% 0.0% 0.1% 0.3% 0.1%  In our experiments, we directly apply pseudo-label generating strategy in ELR <ref type="bibr" target="#b78">[79]</ref>, which has been verified to be effective in tasks like semi-supervised learning <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b79">[80]</ref> and robust learning <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b78">[79]</ref>, to produce pseudo-labels in our CMW-Net-SL algorithm. Note that the meta-train and metatest algorithms of CMW-Net-SL are similar to Algorithms 1 and 2 except that the training loss is revised from (5) to <ref type="bibr" target="#b13">(14)</ref>. More detailed algorithm description is provided in the SM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">LEARNING WITH SYNTHETIC BIASED DATA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Class Imbalance Experiments</head><p>Datasets. We use long-tailed versions of CIFAR-10 and CIFAR-100 datasets (CIFAR-10-LT and CIFAR-100-LT) as in <ref type="bibr" target="#b3">[4]</ref>. They contain the same categories as the original CIFAR dataset <ref type="bibr" target="#b81">[82]</ref>, but are created by reducing the number of training samples per class according to an exponential function n = n i ? i , where i denotes the class index, n i is the original number of training images and ? ? (0, 1). The imbalance factor of a dataset is defined as the number of training samples in the largest class divided by the smallest.</p><p>Baselines. The comparison methods include: 1) Empirical risk minimization (ERM): all examples have the same weights. By default, we use standard cross-entropy loss; 2) Focal loss <ref type="bibr" target="#b29">[30]</ref> and 3) CB loss <ref type="bibr" target="#b3">[4]</ref>: represent SOTA predefined sample re-weighting techniques; 4) LDAM loss <ref type="bibr" target="#b80">[81]</ref>: dynamically tune the margins between classes according to their degrees of dominance in the training set; 5) L2RW <ref type="bibr" target="#b25">[26]</ref>: adaptively assign sample weights by meta-learning; 6) MW-Net <ref type="bibr" target="#b8">[9]</ref>: learn an explicit weighting function by meta-learning; 7) MCW <ref type="bibr" target="#b60">[61]</ref>: also use a meta-learning framework, while consider an elegantly designed class-wise weighting scheme, validated to be specifically effective for class imbalance bias. More implementation details are specified in SM.</p><p>Results. <ref type="table">Table 1</ref> shows the test errors of all competing methods by taking ResNet-32 as the classifier model on CIFAR-10-LT and CIFAR-100-LT with different imbalance factors. It can be observed that: 1) Our algorithm outperforms other competing methods on the datasets, showing its robustness in such biased data; 2) CMW-Net evidently outperforms MW-Net in each experiment. Especially, the performance gain tends to be more evident under larger imbalanced factors. <ref type="figure" target="#fig_4">Fig. 4</ref> shows confusion matrices produced by the results of MW-Net and CMW-Net on CIFAR-10-LT with imbalance factor 200 3 . Compared with MW-Net, it is seen that CMW-Net improves the accuracies on tail classes and meanwhile maintains good performance on head classes. 3) Although <ref type="bibr" target="#b2">3</ref>. The confusion matrix is calculated by applying the trained classifier to the corresponding testing set included with the CIFAR-10 dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TABLE 1</head><p>Test top-1 error (%) comparison of different competing methods with ResNet-32 classifier on CIFAR-10-LT and CIFAR-100-LT under different imbalance settings. * indicates results reported in <ref type="bibr" target="#b60">[61]</ref>. <ref type="table" target="#tab_2">Imbalance factor  200  100  50  20  10  1  200  100  50  20</ref>  LDAM loss already has the capacity of mitigating the longtailed issue by penalizing hard examples, our method can further boost its performances. 4) Owing to its class-wise weighting scheme, MCW also attains good performance in these experiments. Yet CMW-Net still performs better in most cases. Considering its adaptive weighting-scheme-setting capability and general usability in wider range of biased issues, it should be rational to say that CMW-Net is effective. To understand the weighing scheme learned by CMW-Net, we also depict the weighting functions learned by the CMW-Net in <ref type="figure" target="#fig_1">Fig.2</ref>(c) (first column). It is seen that compared with MW-Net shown in <ref type="figure" target="#fig_1">Fig.2</ref>(b) (first column), CMW-Net produces three weighting functions corresponding to small, moderate and large-scale meta-classes. The overall tendency complies with conventional empirical setting for such classwise weight functions, like MCW <ref type="bibr" target="#b3">[4]</ref>, <ref type="bibr" target="#b60">[61]</ref>, i.e., assigning weights inversely related to the class sizes. Specifically, the learned weights of the tail classes are more prominent than those of the head ones, implying that samples in tail classes should be more emphasized in training to alleviate the class imbalanced bias issue. This also explains the consistently better performance of CMW-Net as compared with MW-Net.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Name CIFAR-10-LT CIFAR-100-LT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Feature-independent Label Noise Experiment</head><p>Datasets. We study two types of label noise following previous works <ref type="bibr" target="#b69">[70]</ref>, <ref type="bibr" target="#b70">[71]</ref>: 1) Symmetric noise: randomly replace sample labels for a percentage of the training data with all possible labels. 2) Asymmetric noise: try to mimic the structure of real-life label noise, where labels are only replaced by similar classes. Two benchmark datasets are employed: CIFAR-10 and CIFAR-100 <ref type="bibr" target="#b81">[82]</ref>.</p><p>Baselines. The comparison methods include: 1) ERM; 2) Forward <ref type="bibr" target="#b69">[70]</ref>: correct the prediction by the label transition matrix; 3) GCE <ref type="bibr" target="#b5">[6]</ref>: behave as a robust loss to handle the noisy labels; 4) M-correction <ref type="bibr" target="#b6">[7]</ref>; 5) DivideMix <ref type="bibr" target="#b7">[8]</ref>: represent the SOTA method for handling noisy label bias, by dividing training data into clean and noisy ones through a loss threshold and designing different label amelioration strategies on them through two diverged networks to co-train the classifier; 6) L2RW <ref type="bibr" target="#b25">[26]</ref> and 7) MW-Net <ref type="bibr" target="#b8">[9]</ref>: represent the sample reweighting methods by meta-learning. More experimental details are listed in SM.</p><p>Establishing Meta dataset. Motivated by <ref type="bibr" target="#b6">[7]</ref> and <ref type="bibr" target="#b7">[8]</ref>, we selected meta data at each epoch according to the training loss. Specifically, we explore to create the meta dataset based on the high-quality clean samples as well as its high-quality pseudo labels from the training set (with lowest losses) as an unbiased estimator of the clean data-label distribution. To make the meta dataset balanced, we selected 10 images per class in each epoch iteration. In this case, the performance of meta dataset can be served as an indicator to measure how much extent CMW-Net is trained to filter noisy samples and generalized to clean test distribution.</p><p>Such meta dataset may lack of diversity pattern to characterize the latent clean data-label distribution. To alleviate this issue, we further explore to utilize mixup technique <ref type="bibr" target="#b83">[84]</ref> to enrich the variety of the meta data distribution while possibly maintain its unbiasedness. The hyperparameter of convex combination in the technique is randomly sampled from a Beta distribution Beta(1, 1). Our extensive experiments have verified the effectiveness of using such generated meta True label 45.362% 5.598% 5.378% 5.818% 6.158% 6.397% 6.957% 6.218% 6.118% 5.998%</p><p>6.292% 45.335% 5.776% 6.431% 5.717% 6.431% 5.697% 5.994% 5.935% 6.391% 5.837% 6.215% 45.319% 5.797% 6.355% 5.637% 5.418% 6.355% 6.295% 6.773%</p><p>6.08% 5.863% 6.061% 46.187% 5.981% 5.605% 6.199% 6.12% 6.001% 5.902%</p><p>6.584% 6.098% 5.774% 5.794% 45.28% 6.605% 5.814% 6.605% 5.895% 5.551%</p><p>5.318% 6.888% 6.397% 5.907% 6.397% 45.428% 5.671% 5.985% 5.946% 6.064% 5.887% 6.047% 6.127% 5.527% 6.047% 5.947% 46.496% 6.588% 5.346% 5.987%</p><p>6.098% 5.838% 6.76% 6.319% 6.219% 5.717% 5.938% 45.537% 5.978% 5.597%</p><p>6.24% 6.1% 6.38% 5.879% 6.079% 5.598% 5.919% 5.257% 46.89% 5.658%  dataset from training data. Such property makes such metalearning strategy applicable to real-world biased dataset, since it is always not easy to collect an additional clean meta dataset in practice. We also use such meta-data-generation strategy in the following noisy labels experiments as well as the real-world biased dataset, where an expected clean meta-dataset is always unavailable. Results. <ref type="table" target="#tab_2">Table 2</ref> evaluates the performance of our method on CIFAR-10 and CIFAR-100 with different levels of symmetric and asymmetric label noise. We report the averaged test accuracy over the last 10 epochs. It is seen that CMW-Net evidently outperforms MW-Net in all cases. For symmetric noise, the training loss distribution is usually homoscedastic, as depicted in <ref type="figure" target="#fig_1">Fig.2</ref>(b) (second column), and thus CMW-Net learns three similar weighting schemes as that extracted by MW-Net, as shown in <ref type="figure" target="#fig_1">Fig.2(c)</ref>. For asymmetric noise, while MW-Net hardly adapts to the heterogeneous loss distribution across different classes, CMW-Net finely produces weighting schemes conditioned on different meta-classes. Specifically, as shown in <ref type="figure" target="#fig_1">Fig.2(c)</ref>, weighting functions of small and moderate-scale meta-classes tend to more emphasize those informative marginal samples since they don't contain replaced labels from other classes. While for large-scale meta-class, with many corrupted labeled data, CMW-Net tends to impose smaller weights on samples with relatively large losses to suppress the effect of these noisy labels. This shows that the learned weighting scheme by CMW-Net are adaptable to the internal bias patterns of different classes, and thus naturally leads to its superiority over MW-Net.</p><p>By introducing soft label amelioration, CMW-Net-SL can further enhance the performance of CMW-Net, as clearly shown in <ref type="table" target="#tab_2">Table 2</ref>. This is natural since CMW-Net-SL is able to adaptively refurbish noisy labeled samples rather than roughly trash them from training, and thus a more sufficient exploration on beneficial knowledge from training data could be obtained. <ref type="figure" target="#fig_5">Fig. 5</ref> shows the confusion matrices obtained by CMW-Net and CMW-Net-SL in 60% label noise rate case. It is seen that CMW-Net-SL evidently improves the prediction accuracy, especially for classes with heavy corrupted labels.</p><p>Note that by involving label amelioration through using pseudo-prediction information as our method, the DivideMix method also performs well in most symmetric noise experiments, especially, slightly better than CMW-Net-SL in 80% noise rate. However, the superiority of our method is still significant in all asymmetric label noise cases. This can be rationally explained by that DivideMix uses a consistent loss threshold for distinguishing clean and noisy samples, which, however, is certainly deviated from the insight of inter-class heteroscedastic loss distributions underlying this type of data bias. As can be observed in <ref type="figure" target="#fig_1">Fig.2</ref>(c), since clean training classes are simultaneously tail classes, the loss values of some training samples in these classes are possibly larger than those of head classes, especially for their contained noisy samples. Thus DivideMix tends to mistakenly recognize certain amount of clean/noisy samples, which then results in its performance degradation. Comparatively, the class-aware capability possessed by CMW-Net-SL enables the method more properly treat heteroscedastic loss distributions across different classes, and thus obtain more accurate weighting functions specifically suitable for them, which then naturally leads to its relatively superior performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Feature-dependent Label Noise Experiment</head><p>We then evaluate the capability of our method against the feature-dependent label noise, which is more approximate to the real-world bias scenarios <ref type="bibr" target="#b37">[38]</ref>, <ref type="bibr" target="#b82">[83]</ref>.</p><p>Datasets. We follow the PMD noise generation scheme proposed in <ref type="bibr" target="#b82">[83]</ref>. Let ? y1 (x) = P (y = y 1 |x) be the true posterior label distribution for the sample x. The noise label is generated by replacing the most confident label u x = arg max y ? y (x) of each training sample x to its second confident category s x with conditional probability   ? ux,sx = P (? = u x |y = s x , x). We use three types of ? ux,sx designed in <ref type="bibr" target="#b82">[83]</ref> as follows:</p><formula xml:id="formula_24">Type-I : ? ux,sx = ? 1 2 [? ux (x) ? ? sx (x)] 2 + 1 2 , Type-II : ? ux,sx =1 ? [? ux (x) ? ? sx (x)] 3 , Type-III : ? ux,sx =1 ? 1 3 [? ux (x) ? ? sx (x)] 3 + [? ux (x) ? ? sx (x)] 2 + [? ux (x) ? ? sx (x)] .</formula><p>Besides, we also consider the hybrid noise consisting of both feature-dependent noise and symmetric as well as asymmetric noise as in Sec. 4.2. We use CIFAR-10 and CIFAR-100 benchmarks with such simulated label noise. Baselines. Following the benchmark in <ref type="bibr" target="#b82">[83]</ref>, we compare the following baselines: 1) ERM; 2) LRT <ref type="bibr" target="#b62">[63]</ref>; 3) GCE [6]; 4) MW-Net <ref type="bibr" target="#b8">[9]</ref> and 5) PLC <ref type="bibr" target="#b82">[83]</ref>, which represents the SOTA method specifically designed for addressing heterogeneous feature-dependent label noise. All these methods are generic and handle label noise without assuming the noise structures.</p><p>Results. <ref type="table" target="#tab_3">Table 3</ref> lists the performance of different competing methods under three types of feature-dependent noise at noise levels 35% and 70%. It is seen that our method achieves the best performance on all cases. <ref type="table" target="#tab_5">Table 4 further</ref> shows the results on datasets corrupted with a combination of feature dependent and independent noises, where featureindependent noise is overlayed on the feature-dependent one and thus bias patterns are more complicated. The superiority of the proposed method can still be easily observed.</p><p>The generation mechanism of such feature-dependent noise results in noisy samples near the decision boundary <ref type="bibr" target="#b82">[83]</ref>, which are harder to distinguish and more likely to be mislabeled. As shown in <ref type="figure" target="#fig_1">Fig.2</ref>(a) (fourth column), the feature-dependent noisy samples tend to further deteriorate the loss distribution compared with only asymmetric noise independent to data. From <ref type="figure" target="#fig_1">Fig.2</ref>(c) (fourth column), it can be seen that the proposed method can still finely distinguish most of clean and noisy samples (some noisy samples are wrongly assigned to high weights due to they are samples near the decision boundary). As compared, from <ref type="figure" target="#fig_1">Fig.2</ref>(b) (fourth column), it can be observed that MW-Net totally fails to distinguish clean and noisy samples, and assigns high weights to all samples, naturally leading to its performance degeneration. Note that the PLC method <ref type="bibr" target="#b82">[83]</ref>, which is specifically designed for feature-dependent label noise data, also achieves fine results. The main idea of this method is to progressively correct noisy labels and refine the model for those relatively reliable samples with high confidence, measured by a dynamically specified threshold gradually deceased in iterations. Considering its general availability to wider range of data bias cases and relatively more concise meta-learning framework, it should be rational to say that the proposed method is effective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">LEARNING WITH REAL BIASED DATA</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Learning with Real-world Noisy Datasets</head><p>Datasets. We adopt two real-world datasets, ANIMAL-10N <ref type="bibr" target="#b43">[44]</ref> and WebVision <ref type="bibr" target="#b77">[78]</ref>. Animal-10N contains 55,000 human labeled online images for 10 confusing animal classes, all with approximately similar noisy label distributions (8% noisy samples). Following previous works <ref type="bibr" target="#b77">[78]</ref>, 50,000 images are exploited for training while the left for testing. For ease of comparison to previous works <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b86">[87]</ref>, we consider the mini WebVision dataset which contains the top 50 classes from the Google image subset of WebVision. The performance evaluation is implemented on both the validation sets of mini WebVision <ref type="bibr" target="#b13">[14]</ref> and the corresponding class samples of ImageNet <ref type="bibr" target="#b88">[89]</ref>. ResNet-50 is adopted as the classifier network. More implementation details are specified in SM.</p><p>Results. <ref type="table" target="#tab_6">Tables 5 and 6</ref>      <ref type="bibr" target="#b77">[78]</ref> and PLC <ref type="bibr" target="#b82">[83]</ref>. Figs. 6(a) and 6(b) visualize typical noisy examples selected by CMW-Net as well as its generated pseudo-labels. Though they are a pair of easily confused categories (cat, lynx), our method can still extract their wrong labels and correct them as the true ones. <ref type="figure">Fig. 7</ref>(a) further shows the weighting functions learned by CMW-Net, complying with the class balance and inter-class noise homogeneity property of this dataset. <ref type="table" target="#tab_7">Table 6</ref> also shows the superiority of CMW-Net compared to other competing methods without involving soft labels. By introducing soft labels, our CMW-Net-SL achieves superior performance to recent SOTA methods, DivideMix and ELR. Furthermore, by combining the self-supervised pretraining technique proposed in the C2D method <ref type="bibr" target="#b87">[88]</ref>, we further boost the performance. In <ref type="figure" target="#fig_6">Fig. 6</ref>, we show some typical noisy examples corrected by the proposed method, showing its capability of recovering of these easily confused samples. <ref type="figure">Fig. 7(b)</ref> plots the learned weighting functions by CMW-Net, revealing certain helpful data bias insight. For smallscale meta-class, the corresponding weighting function is with larger weights and shows increasing tendency. It is beneficial to more emphasize their contained rare samples especially those marginal informative ones for alleviating their possibly encountered class-imbalance bias issue. Yet for moderate and larger-scale meta-classes containing relatively abundant training data, the weighting functions are with monotonically decreasing shapes to suppress the negative effect brought by their contained noisy samples. Such more comprehensive and faithful exploration and encoding for data bias situations naturally leads to the better performance of CMW-Net than conventional sample weighting strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Webly Supervised Fine-Grained Recognition</head><p>We further run our method on a benchmark WebFG-496 dataset proposed in <ref type="bibr" target="#b44">[45]</ref>, consisting of three sub-datasets: Web-aircraft, Web-bird, Web-car, which contain 13,503 images with 100 types of airplanes, 18,388 images with 200 species of birds, and 21,448 images with 196 categories of cars, respectively. The aim is to use web images to train a finegrained recognition model. The data bias of this dataset is validated to be complicated, with both label noise and class imbalance patterns, as well as certain inter-class variance <ref type="bibr" target="#b44">[45]</ref>. Experimental results are shown in <ref type="table" target="#tab_9">Table 7</ref>. It is seen that CMW-Net-SL evidently improves other reported SOTA performance <ref type="bibr" target="#b44">[45]</ref>. This further validates the effectiveness of our method for such real dataset with complex data biases. More implementation details are given in SM. Long-tail recognition accuracy of different competing methods by using ResNet-10 as the classifier on ImageNet-LT <ref type="bibr" target="#b4">[5]</ref> . Results for baselines are copied from <ref type="bibr" target="#b4">[5]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">TRANSFERABILITY OF CMW-NET</head><p>As aforementioned, a potential usefulness of the metalearned weighing scheme by CMW-Net is that it is modelagnostic and hopefully equipped into other learning algorithms in a plug-and-play manner. To validate such transferable capability of CMW-Net, we attempt to transfer meta-learned CMW-Net on relatively smaller dataset to significantly larger-scale ones. In specific, we use CMW-Net trained on CIFAR-10 with feature-dependent label noise (i.e.,35% Type-I + 30% Asymmetric) as introduced in Sec. 4.3 since it finely simulates the real-world noise configuration. The extracted weighting function is depicted in <ref type="figure" target="#fig_1">Fig.2</ref>(c) (fourth column). We deploy it on two large-scale real-world biased dataset, ImageNet-LT <ref type="bibr" target="#b4">[5]</ref> and full WebVision <ref type="bibr" target="#b13">[14]</ref>. <ref type="table" target="#tab_10">Table 8</ref> shows the performance on ImageNet-LT. By readily equipping our learned CMW-Net upon the SOTA OLTR algorithm <ref type="bibr" target="#b4">[5]</ref> on this dataset, it can be seen that around 4% higher overall accuracy can be readily obtained. Besides, performance on full WebVision is compared in <ref type="table" target="#tab_12">Table 9</ref>. It is interesting to see that by directly integrating the learned CMW-Net into the simple ERM algorithm, the performance can be largely improved, even slightly superior to the SOTA HAR method on this data. This implies the potential usefulness of CMW-Net to more practical largescale problems with complicated data bias situations, by intrinsically reducing the labor and computation costs of specifying proper weighting scheme for a learning algorithm. More experimental details are presented in SM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">EXTENSIONAL APPLICATIONS</head><p>We then evaluate the generality of our proposed adaptive sample weighting strategy in more robust learning tasks, including partial-label learning and semi-supervised learning. The experiments on the selective classification task are introduced in SM due to page limitation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Partial-Label Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.1">Problem Formulation</head><p>Partial-label learning (PLL) <ref type="bibr" target="#b45">[46]</ref> aims to deal with the problem where each instance is provided with a set of candidate labels, only one of which is the correct label. Denote X ? R d as the input space, Y := {1, ? ? ? , C} as the label space, where C is the number of all training classes. Denote the partially labeled dataset as</p><formula xml:id="formula_25">D P LL = {(x i , Y i )} N i=1 , where Y i ? Y is the candidate label set of x i .</formula><p>The goal of PLL is to find latent ground-truth label y for each of x i s through observing their partial label sets. The basic definition of PLL is that true label y of an instance x must be in its candidate label set Y .  The PLL risk estimator is then defined over P (x, Y ) as:</p><formula xml:id="formula_26">R P LL (f ) = E P (x,Y ) [ P LL (f (x), Y )],<label>(16)</label></formula><p>where P LL (?, ?) is the loss function and f (?) is the classifier.</p><p>To estimate Eq. <ref type="formula" target="#formula_1">(16)</ref>, it usually treats all the candidate labels equally <ref type="bibr" target="#b45">[46]</ref></p><formula xml:id="formula_27">, i.e., P LL (f (x), Y ) = 1 |Y | y?Y (f (x), y).</formula><p>Considering that only the true label contributes to retrieving the classifier, PRODEN <ref type="bibr" target="#b93">[94]</ref> defines the PLL loss as the minimal loss over the candidate label set:</p><formula xml:id="formula_28">P LL (f (x), Y ) = min y?Y (f (x), y).</formula><p>They further relax the min operator of the above equality by the dynamic weights as follows:</p><formula xml:id="formula_29">P LL (f (x), Y ) = y?Y w y (f (x), y),</formula><p>where all w y s consist of a one-hot vector, expected to reflect the confidence of the label y ? Y being the true label.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.2">CMW-Net Amelioration and Experiments</head><p>PRODEN <ref type="bibr" target="#b93">[94]</ref> represents the recent SOTA method against such PLL task, through progressively identifying the true labels from the partial label sets, and refining them in turn to ameliorate the classifier. Then by taking the samples with predicted labels as training data, which still contain many wrong annotations, the CMW-Net method (i.e., Algorithm 1 by using meta-data establishing technique introduced in Sec. 4.2) can be readily employed to further improve the classifier.</p><p>Following PRODEN <ref type="bibr" target="#b93">[94]</ref>, two sets of partial label datasets are generated from CIFAR-10 and CIFAR-100, respectively, under different flipping probabilities. As shown in <ref type="figure" target="#fig_8">Fig. 8</ref>, it is seen that CMW-Net can significantly enhance the performance of the baseline method in both test cases, showing its potential usability in this PLL task. More experimental settings and results are presented in SM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Semi-Supervised Learning</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.1">Problem Formulation</head><p>To reduce the annotation cost for supervised learning, an alternative strategy is to train the classifier with small labeled set as well as a large amount of unlabeled samples. This constitutes the main aim of semi-supervised learning (SSL).</p><formula xml:id="formula_30">Let D = {D L , D U } denote the entire dataset, including a small labeled dataset D L = {(x i , y i )} L i=1</formula><p>and a large scale of CIFAR are copied from <ref type="bibr" target="#b46">[47]</ref>, and those of ImageNet are copied from <ref type="bibr" target="#b94">[95]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CIFAR</head><formula xml:id="formula_31">unlabeled dataset D U = {(x i )} U i=1</formula><p>, and L U . Formally, SSL aims to solve the following optimization problem <ref type="bibr" target="#b95">[96]</ref>:</p><formula xml:id="formula_32">min w (x l ,y l )?D L L S (x l , y l ; w) + ? xu?D U L U (x u ; w),</formula><p>where L S denotes the supervised loss, e.g., cross-entropy for classification, and L U denotes the unsupervised loss, e.g., consistency loss <ref type="bibr" target="#b96">[97]</ref> or a regularization term <ref type="bibr" target="#b97">[98]</ref>. w denotes the model parameters and ? &gt; 0 denotes the compromise parameter balancing two terms. Generally, different specifications of the unsupervised loss L U lead to different SSL algorithms. One commonly used strategy is the Pseudo Labeling approach <ref type="bibr" target="#b98">[99]</ref>, which aims to sufficiently use labelled data to predict the labels of the unlabeled data, and take these pseudo-labeled data as labeled ones in training (reflected in the term L U ). Recently, the SOTA SSL methods, like VAT <ref type="bibr" target="#b97">[98]</ref>, MixMatch <ref type="bibr" target="#b99">[100]</ref>, UDA <ref type="bibr" target="#b96">[97]</ref>, and FixMatch <ref type="bibr" target="#b46">[47]</ref> make good progress to enhance the pseudo labeling capability by using sample augmentation techniques, through encouraging consistency under different augmented data <ref type="bibr" target="#b96">[97]</ref>. We take the recent SOTA Fixmatch <ref type="bibr" target="#b46">[47]</ref> as a typical example. Denote ?(x l ) and A(x u ) as augmentation operators imposed on labeled and unlabeled samples, respectively. Then the FixMatch model can be written as:</p><formula xml:id="formula_33">min w (x l ,y l )?D L (f (?(x l ); w), y l ) + ? xu?D U 1(max(z u ? ? ) (f (A(x u ); w), y u ),<label>(17)</label></formula><p>where y u is the pseudo label on x u , calculated by y u = arg max j z uj , z u = f (?(x u ); w) in iteration. ? is a scalar hyperparameter denoting the threshold above which we retain a pseudo-label. Note that 1(max(z u ? ? ) corresponds to a hard weighting scheme with manually specified hyperparameter ? . Albeit attaining good performance, the above Fix-Match model is still with limitation that its hard-thresholding weighting scheme treats all unlabeled (augmented) samples equally, and its involved hyper-parameter ? is often not easily and adaptably specified against different tasks. The method thus still has room for further performance enhancement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2">CMW-Net Amelioration and Experiments</head><p>To better distinguish clean and noisy pseudo-labels, we can easily substitute the original hard weighting scheme as CMW-Net, to make sample weights capable of more sufficiently reflecting noise extents and adaptable to training data/task. Then the problem (17) can be ameliorated as:</p><formula xml:id="formula_34">min w (x l ,y l )?D L (f (?(x l ); w), y l ) + ? (xu)?D U V(L tr u (w), N i ; ?) (f (A(x u ); w), y u ).</formula><p>The algorithm can also be readily designed by integrating the updating step for the meta-parameter ? into the original algorithm of Fixmatch (the labeled data are naturally used as meta data), so as to make the weighting scheme iteratively extracted together with the classifier parameter w in an automatic and more likely intelligent manner.</p><p>We conduct experiments on several standard SSL image classification benchmarks, including CIFAR-10, CIFAR-100 <ref type="bibr" target="#b81">[82]</ref> and ImageNet dataset <ref type="bibr" target="#b88">[89]</ref>. Results are shown in <ref type="table" target="#tab_13">Table 10</ref>. It is evident that our CMW-Net consistently helps improve the performance of FixMatch, especially under smaller labeled data resources, showing its potential application prospects on this task. More experimental settings and results are presented in SM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">CONCLUSION AND DISCUSSION</head><p>In this study, we have proposed a novel meta-model, called CMW-Net, for adaptively extracting an explicit sample weighing scheme directly from training data. Compared with current sample weighing approaches, CMW-Net is validated to possess better flexibility against complicated data bias situations with inter-class heterogeneity. Assisted by additional soft pseudo-label information, the proposed method achieves competitive (mostly superior) performance under various data bias cases, including class imbalance, feature independent or dependent label noise, and more practical real-world data bias scenarios, beyond those SOTA methods specifically designed on these robust learning tasks. The extracted weighting schemes can always help faithfully reveal bias insights underlying training data, making the good effect of the method rational and interpretable. Two potential application prospects of CMW-Net are specifically illustrated and substantiated. One is its fine task-transferability of the learned weighting scheme, implying a possible efficiencyspeedup methodology for handling robust learning tasks under big data, through avoiding its time-consuming and laborsome weighting function tuning process. The other is its wide range of possible extensional applications for other robust learning tasks, e.g., partial-label learning, semisupervised learning and selective classification.</p><p>In our future investigation, we'll apply the proposed adaptive sample weighting strategies to more robust learning tasks to further validate its generality. Attributed to its relatively concise modeling manner, it is also hopeful to develop deeper and more comprehensive statistical learning understanding for revealing its intrinsic generalization capability across different tasks. Besides, we'll try to build more wider range of connections of our method to previous techniques on exploring data insights, like importance weighting <ref type="bibr" target="#b100">[101]</ref>. More sufficient and comprehensive meta-class representation will also be further investigated in our future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX A TECHNICAL DETAILS IN SECTION 3 A.1 Derivation of the Weighting Scheme in CMW-Net</head><p>We first derive the equivalent forms of the updating steps for CMW-Net and CMW-Net-SL parameters ?, as expressed in Eqs. <ref type="bibr" target="#b9">(10)</ref> and <ref type="bibr" target="#b14">(15)</ref>, in the main text, respectively.</p><p>Recall the update equation of the CWM-Net parameters as follows:</p><formula xml:id="formula_35">? (t+1) = ? (t) ? ? 1 m m i=1 ? ? L meta i (? (t+1) (?)) ? (t) .<label>(18)</label></formula><p>The gradient can be calculated by the following derivation:</p><formula xml:id="formula_36">1 m m i=1 ? ? L meta i (? (t+1) (?)) ? (t) = 1 m m i=1 ?L meta i (? (t+1) (?)) ?? (t+1) (?) ?? (t+1) (?) ?? ? (t) = 1 m m i=1 ?L meta i (? (t+1) (?)) ?? (t+1) (?) n j=1 ?? (t+1) (?) ?V(L tr j (w (t) ), N j ; ?) ?V(L tr j (w (t) ), N j ; ?) ?? ? (t) .<label>(19)</label></formula><p>Let</p><formula xml:id="formula_37">G ij = ?L meta i (?) ?? T w (t+1) (?) ?L tr j (w) ?w w (t) ,<label>(20)</label></formula><p>and by substituting Eqs. <ref type="bibr" target="#b19">(20)</ref> and <ref type="formula" target="#formula_1">(19)</ref> into Eq. <ref type="formula" target="#formula_1">(18)</ref>, we can get:</p><formula xml:id="formula_38">? (t+1) = ? (t) + ?? n j=1 1 m m i=1 G ij ?V(L tr j (w (t) ), N j ; ?) ?? ? (t) .<label>(21)</label></formula><p>This corresponds to Eq. (10) in the main text. 1) For the CMW-Net, since?</p><formula xml:id="formula_39">(t+1) (?) = w (t) ? ? n i=1 V(L tr i (w (t) ), N i ; ?)? w L tr i (w) w (t) ,<label>(22)</label></formula><p>thus we have</p><formula xml:id="formula_40">1 m m i=1 ? ? L meta i (? (t+1) (?)) ? (t) = ?? m m i=1 ?L meta i (?) ?? ? (t+1) (?) n j=1 ?L tr j (w) ?w w (t) ?V(L tr j (w (t) ), N j ; ?) ?? ? (t) = ? ? n j=1 1 m m i=1 ?L meta i (?) ?? T w (t+1) (?) ?L tr j (w) ?w w (t) ?V(L tr j (w (t) ), N j ; ?) ?? ? (t) .</formula><p>2) For the CMW-Net-SL, sinc?</p><formula xml:id="formula_41">w (t+1) (?) = w (t) ? ? n i=1 V(L tr i (w (t) ), N i ; ?)? w L tr i (w) w (t) + 1 ? V(L tr i (w (t) ), N i ; ?) ? w L Pse i (w) w (t) ,<label>(23)</label></formula><p>where L tr i (w) = (f (x i ; w), y i ), L Pse i (w) = (f (x i ; w), z i ), z i is the pseudo-label for example x i , we thus have</p><formula xml:id="formula_42">1 m m i=1 ? ? L meta i (? (t+1) (?)) ? (t)<label>(24)</label></formula><formula xml:id="formula_43">= ?? m m i=1 ?L meta i (?) ?? ? (t+1) (?) n j=1 ?L tr j (w) ?w w (t) ? ?L Pse j (w) ?w w (t) ?V(L tr j (w (t) ), N j ; ?) ?? ? (t)<label>(25)</label></formula><formula xml:id="formula_44">= ? ? n j=1 1 m m i=1 ?L meta i (?) ?? T w (t+1) (?) ?L tr j (w) ?w w (t) ? ?L Pse j (w) ?w w (t) ?V(L tr j (w (t) ), N j ; ?) ?? ? (t) .<label>(26)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 3 Learning Algorithm for CMW-Net-SL Model</head><p>Input: Training data D tr , meta data D meta , batch size n, temporal ensembling momentum ? ? [0, 1), weight averaging momentum ? ? [0, 1), mixup hyperparameter ? &gt; 0, Output: Classifier parameter w * 1: Initialize classifier network parameter w (0) . Initialize averaged predictions z (0) = 0 [N ?C] , and averaged weights (untrainable) w (0) W A = 0. 2: for t = 0 to T ? 1 do <ref type="bibr">3:</ref> {x, y} ? SampleMiniBatch(D tr , n).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>{x meta , y meta } ? SampleMiniBatch(D meta , m).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>Generate mixing coefficient ? ? Beta(?, ?), ? = max(?, 1 ? ?).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>6:</head><p>Calculate weight averaging: w (t+1)</p><formula xml:id="formula_45">W A = ?w (t) W A + (1 ? ?)w (t) . 7: Calculate temporal ensembling: z (t+1) = ?z (t) i + (1 ? ?)f (x; w (t+1) W A ).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8:</head><p>Generate new index sequence idx = torch.randperm(n). <ref type="bibr" target="#b8">9</ref>: <ref type="figure">; w)</ref>,?i). Calculate Ni and?i, representing the numbers of samples contained in the classes to which xi and x[idx]i belong, respectively.</p><formula xml:id="formula_46">Generatex = ? x + (1 ? ? )x[idx], and let? = y[idx],z (t+1) = z (t+1) [idx], i = (f (xi; w), yi),? i = (f (xi</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>10:</head><p>Formulate the learning manner of classifier network:</p><formula xml:id="formula_47">w (t+1) (?) = w (t) ? ? n i=1 {? V( i, Ni; ?)?w (f (xi; w), yi) w (t) + (1 ? V( i, Ni; ?))?w (f (xi; w), z (t+1) i ) w (t) + (1 ? ?) V(? i,?i; ?)?w (f (xi; w),?i) w (t) + (1 ? V(? i,?i; ?))?w (f (xi; w),z (t+1) i ) w (t) }.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>Update parameters of CMW-Net ? (t+1) by</p><formula xml:id="formula_48">? (t+1) = ? (t) ? ? 1 m m i=1 ?? f (x (meta) i ;? (t+1) (?)), y (meta) i ? (t) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>12:</head><p>Update parameters of classifier w (t+1) by</p><formula xml:id="formula_49">w (t+1) = w (t) ? ? n i=1 {? V( i, Ni; ? (t+1) )?w (f (xi; w), yi) w (t) + (1 ? V( i, Ni; ? (t+1) ))?w (f (xi; w), z (t+1) i ) w (t) + (1 ? ?) V(? i,?i; ? (t+1) )?w (f (xi; w),?i) w (t) + (1 ? V(? i,?i; ? (t+1) ))?w (f (xi; w),z (t+1) i ) w (t) }. 13: end for Let G ij = ?L meta i (?) ?? T w (t+1) (?) ?L tr j (w) ?w w (t) , G ij = ?L meta i (?) ?? T w (t+1) (?) ?L Pse j (w) ?w w (t) ,<label>(27)</label></formula><p>by substituting Eqs. <ref type="bibr" target="#b23">(24)</ref> and <ref type="formula" target="#formula_2">(27)</ref> into Eq. (18), we can get:</p><formula xml:id="formula_50">? (t+1) = ? (t) + ?? n j=1 1 m m i=1 (G ij ? G ij ) ?V(L tr j (w (t) ), N j ; ?) ?? ? (t) .<label>(28)</label></formula><p>This corresponds to Eq. (15) in the main text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Complete Learning Algorithm of CMW-Net-SL</head><p>Recently, some works are presented to extract pseudo soft labels on samples through the clue of the classifier's estimation during the training iterations, and then use such beneficial information to improve the robustness of classifier training especially in the presence of noisy labels. The utilized techniques include temporal ensembling <ref type="bibr" target="#b79">[80]</ref>, weight averaging, mixup <ref type="bibr" target="#b83">[84]</ref>, and others. In our experiments, we just directly apply the strategy utilized in ELR <ref type="bibr" target="#b78">[79]</ref> and DivideMix <ref type="bibr" target="#b7">[8]</ref>, which has been verified to be effective in tasks like semi-supervised learning <ref type="bibr" target="#b46">[47]</ref>, <ref type="bibr" target="#b79">[80]</ref> and robust learning <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b78">[79]</ref>, to produce pseudo-labels in our CMW-Net-SL algorithm. The complete algorithm is summarized in the above Algorithm 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.3 Convergence Proof of Proposed CMW-Net Learning Algorithm</head><p>This section provides the proofs of Theorems 1 and 2 in the paper. Suppose that we have a small amount of meta (validation) dataset with M samples {(x </p><formula xml:id="formula_51">L meta (w * (?)) = 1 M M i=1 L meta i (w * (?)),<label>(29)</label></formula><p>where w * is the parameter of the classifier network, and ? is the parameter of the CMW-Net. Let's suppose we have another N training data, {(x i , y i ), 1 ? i ? N }, where M N , and the overall training loss is,</p><formula xml:id="formula_52">L tr (w; ?) = N i=1 V(L tr i (w), N i ; ?)L tr i (w),<label>(30)</label></formula><p>where N i=1 V(L tr i (w), N i ; ?) = 1. Lemma 1. Suppose the meta loss function is Lipschitz smooth with constant L, and V(?, ?; ?) is differential with a ?-bounded gradient and twice differential with its Hessian bounded by B, and the loss function has ?-bounded gradient with respect to training/meta data. Then the gradient of ? with respect to the meta loss is Lipschitz continuous.</p><p>Proof. The gradient of ? with respect to the meta loss can be written as:</p><formula xml:id="formula_53">? ? L meta i (? (t+1) (?)) ? (t) = ?? n j=1 ?L meta i (?) ?? T w (t+1) (?) ?L tr j (w) ?w w (t) ?V(L tr j (w (t) ), N j ; ?) ?? ? (t) .<label>(31)</label></formula><p>Let V j (?) = V(L train j (w (t) ); ?) and G ij be defined in Eq. <ref type="bibr" target="#b19">(20)</ref>. Taking gradient of ? in both sides of Eq.(31), we have</p><formula xml:id="formula_54">? 2 ? 2 L meta i (? (t+1) (?)) ? (t) = ?? n j=1 ? ?? (G ij ) ? (t) ?V j (?) ?? ? (t) + (G ij ) ? 2 V j (?) ?? 2 ? (t) .</formula><p>For the first term in the right hand side, we have that</p><formula xml:id="formula_55">? ?? (G ij ) ? (t) ?V j (?) ?? ? (t) ?? ? ?? (G ij ) ? (t) = ? ? ?? ?L meta i (?) ?? ? (t) T w (t+1) (?) ?L tr j (w) ?w w (t) =? ? ?? ?L meta i (?) ?? ? (t+1) (?) (??) n k=1 ?L tr k (w) ?w w (t) ?V k (?) ?? ? (t) T w (t+1) (?) ?L tr j (w) ?w w (t) =? ? 2 L meta i (?) ?? 2 ? (t+1) (?) (??) n k=1 ?L tr k (w) ?w w (t) ?V k (?) ?? ? (t) T w (t+1) (?) ?L tr j (w) ?w w (t) ??nL? 2 ? 2 ,<label>(32)</label></formula><formula xml:id="formula_56">since ? 2 L meta i (?) ?? 2 ? (t+1) (?) ? L, ?L tr j (w) ?w w (t) ? ?, ?Vj (?) ?? ? (t) ? ?.</formula><p>And for the second term we have</p><formula xml:id="formula_57">(G ij ) ? 2 V j (?) ?? 2 ? (t) = ?L meta i (?) ?? T w (t+1) (?) ?L tr j (w) ?w w (t) ? 2 V j (?) ?? 2 ? (t) ? B? 2 ,<label>(33)</label></formula><formula xml:id="formula_58">since ?L meta i (?) ?? T w (t+1) (?) ??, ? 2 Vj (?) ?? 2 ? (t) ?B.</formula><p>Combining the above two inequalities Eqs. <ref type="bibr" target="#b31">(32)</ref> and <ref type="formula" target="#formula_4">(33)</ref>, we then have</p><formula xml:id="formula_59">? 2 ? 2 L meta i (? (t) (?)) ? (t) ? ?? 2 (n?L? 2 + B).<label>(34)</label></formula><p>Define L V = ?? 2 (n?L? 2 + B), and based on Lagrange mean value theorem, we have:</p><formula xml:id="formula_60">?L meta (? (t+1) (? 1 )) ? ?L meta (? (t+1) (? 2 )) ? L V ? 1 ? ? 2 , f or all ? 1 , ? 2 ,<label>(35)</label></formula><p>where ?L meta (? (t+1) (? 1 )) = ? ? L meta i (? (t+1) (?)) ?1 . Theorem 1. Suppose the loss function is Lipschitz smooth with constant L, and CMW-Net V(?, ?; ?) is differential with a ?-bounded gradient and twice differential with its Hessian bounded by B, and the loss function has ?-bounded gradient with respect to training/meta data. Let the learning rate ? t , ? t , 1 ? t ? T be monotonically descent sequences, and satisfy ? t = min{ 1</p><formula xml:id="formula_61">L , c1 ? T }, ? t = min{ 1 L , c2 ? T }, for some c 1 , c 2 &gt; 0, such that ? T c1 ? L, ? T c2 ? L. Meanwhile, they satisfy ? t=1 ? t = ?, ? t=1 ? 2 t &lt; ?, ? t=1 ? t = ?, ? t=1 ? 2 t &lt; ?. Then CMW-Net can achieve E[ ?L meta (? (t) (? (t) )) 2 2 ] ? in O(1/ 2 ) steps. More specifically, min 0?t?T E ?L meta (? (t) (? (t) )) 2 2 ? O( C ? T ),<label>(36)</label></formula><p>where C is some constant independent of the convergence process.</p><p>Proof. The update equation of ? in each iteration is as follows:</p><formula xml:id="formula_62">? (t+1) = ? (t) ? ? 1 m m i=1 ? ? L meta i (? (t+1) (?)) ? (t) .</formula><p>Under the sampled mini-batch ? t , the updating equation can be rewritten as:</p><formula xml:id="formula_63">? (t+1) = ? (t) ? ? t ?L meta (? (t+1) (? (t) )) ?t .</formula><p>Since the mini-batch is drawn uniformly from the entire data set, the above update equation can be written as:</p><formula xml:id="formula_64">? (t+1) = ? (t) ? ? t [?L meta (? (t+1) (? (t) )) + ? (t) ],</formula><p>where ? (t) = ?L meta (? (t+1) (? (t) )) ?t ? ?L meta (? (t+1) (? (t) )). Note that ? (t) are i.i.d random variable with finite variance, since ? t are drawn i.i.d with a finite number of samples. Furthermore, E[? (t) ] = 0, since samples are drawn uniformly at random. Observe that</p><formula xml:id="formula_65">L meta (? (t+1) (? (t+1) )) ? L meta (? (t) (? (t) )) = L meta (? (t+1) (? (t+1) )) ? L meta (? (t+1) (? (t) )) + L meta (? (t+1) (? (t) )) ? L meta (? (t) (? (t) )) .<label>(37)</label></formula><p>For the first term, by Lipschitz continuity of ? ? L meta (? (t+1) (?)) according to Lemma 1, we can deduce that:</p><formula xml:id="formula_66">L meta (? (t+1) (? (t+1) )) ? L meta (? (t+1) (? (t) )) ? ? ? L meta (? (t+1) (? (t) )), ? (t+1) ? ? (t) + L 2 ? (t+1) ? ? (t) 2 2 = ? ? L meta (? (t+1) (? (t) )), ?? t [? ? L meta (? (t+1) (? (t) )) + ? (t) ] + L? 2 t 2 ? ? L meta (? (t+1) (? (t) )) + ? (t) 2 2 = ? (? t ? L? 2 t 2 ) ? ? L meta (? (t+1) (? (t) )) 2 2 + L? 2 t 2 ? (t) 2 2 ? (? t ? L? 2 t ) ? ? L meta (? (t) (? (t) )), ? (t) .</formula><p>For the second term, by Lipschitz smoothness of the meta loss function L meta (? (t+1) (? (t+1) )), we have</p><formula xml:id="formula_67">L meta (? (t+1) (? (t) )) ? L meta (? (t) (? (t) )) ? ? w L meta (? (t) (? (t) )),? (t+1) (? (t) ) ?? (t) (? (t) ) + L 2 ? (t+1) (? (t) ) ?? (t) (? (t) ) 2 2 . Since? (t+1) (? (t) ) ?? (t) (? (t) ) = ?? t ?L tr (w (t) ; ? (t) )| ?t ,</formula><p>where ? t denotes the mini-batch drawn randomly from the training dataset in the t-th iteration, ?L train (w (t) ;</p><formula xml:id="formula_68">? (t) ) = n i=1 V(L tr i (w (t) ), N i ; ? (t) )? w (t) L tr i (w) w (t)</formula><p>, and n i=1 V(L tr i (w (t) ), N i ; ? (t+1) ) = 1. Since the mini-batch ? t is drawn uniformly at random, we can rewrite the update equation as:</p><formula xml:id="formula_69">w (t+1) (? (t) ) =? (t) (? (t) ) ? ? t [?L tr (w (t) ; ? (t) ) + ? (t) ],</formula><p>where ? (t) = ?L tr (w (t) ; ? (t) )| ?t ? ?L tr (w (t) ; ? (t) ). Note that ? (t) are i.i.d. random variables with finite variance, since ? t are drawn i.i.d. with a finite number of samples, and thus E[? <ref type="bibr">(t)</ref> </p><formula xml:id="formula_70">] = 0, E[ ? (t) 2 2 ] ? ? 2 . Thus we have L meta (? (t+1) (? (t) )) ? L meta (? (t) (? (t) )) ? ? w L meta (? (t) (? (t) )), ?? t [?L tr (w (t) ; ? (t) ) + ? (t) ] + L 2 ? t [?L tr (w (t) ; ? (t) ) + ? (t) ] 2 2 = L? 2 t 2 ?L tr (w (t) ; ? (t) ) 2 2 ? ? t ? w L meta (? (t) (? (t) )), ?L tr (w (t) ; ? (t) ) + L? 2 t 2 ? (t) 2 2 + L? 2 t ?L tr (w (t) ; ? (t) ), ? (t) ? ? t ? w L meta (? (t) (? (t) )), ? (t) ? L? 2 t ? 2 2 + ? t ? ?L tr (w (t) ; ? (t) ) 2 + L? 2 ? 2 t 2 + L? 2 t ?L tr (w (t) ; ? (t) ), ? (t) ? ? t ? w L meta (? (t) (? (t) )), ? (t) .</formula><p>The last inequality holds since ? w L meta (? (t) (? (t) )), ?L tr (w (t) ; ? (t) ) ? ?L meta (? (t) (? (t) )) <ref type="bibr" target="#b1">2</ref> ?L tr (w (t) ; ? (t) ) 2 . Thus Eq.(37) satifies</p><formula xml:id="formula_71">L meta (? (t+1) (? (t+1) )) ? L meta (? (t) (? (t) )) ? L? 2 t ? 2 2 + ? t ? ?L tr (w (t) ; ? (t) ) 2 + L? 2 ? 2 t 2 + L? 2 t ?L tr (w (t) ; ? (t) ), ? (t) ? ? t ? w L meta (? (t) (? (t) )), ? (t) ? (? t ? L? 2 t 2 ) ? ? L meta (? (t+1) (? (t) )) 2 2 + L? 2 t 2 ? (t) 2 2 ? (? t ? L? 2 t ) ? ? L meta (? (t) (? (t) )), ? (t) .</formula><p>Rearranging the terms, and taking expectations with respect to ? (t) and ? (t) on both sides, we can obtain</p><formula xml:id="formula_72">(? t ? L? 2 t 2 ) ? ? L meta (? (t+1) (? (t) )) 2 2 ? L? 2 t ? 2 2 + ? t ? ?L tr (w (t) ; ? (t) ) 2 + L? 2 ? 2 t 2 + L meta (? (t) (? (t) )) ? L meta (? (t+1) (? (t+1) )) + L? 2 t 2 ? 2 , since E[? (t) ] = 0, E[? (t) ] = 0 and E[ ? (t) 2 2 ] ? ? 2 .</formula><p>Summing up the above inequalities, we can obtain</p><formula xml:id="formula_73">T t=1 (? t ? L? 2 t 2 ) ? ? L meta (? (t+1) (? (t) )) 2 2 ?L meta (? (1) )(? (1) ) ? L meta (? (T +1) )(? (T +1) ) + L(? 2 + ? 2 ) 2 T t=1 ? 2 t + ? T t=1 ? t ?L tr (w (t) ; ? (t) ) 2 2 + L 2 T t=1 ? 2 t ? 2 ?L meta (? (1) )(? (1) ) + L(? 2 + ? 2 ) 2 T t=1 ? 2 t + ? T t=1 ? t ?L tr (w (t) ; ? (t) ) 2 2 + L 2 T t=1 ? 2 t ? 2 .</formula><p>Furthermore, we can deduce that</p><formula xml:id="formula_74">min t E ? ? L meta (? (t+1) (? (t) )) 2 2 ? T t=1 (? t ? L? 2 t 2 )E ? ? L meta (? (t+1) (? (t) )) 2 2 T t=1 ? t ? L? 2 t 2 ? 1 T t=1 (2? t ? L? 2 t ) L meta (? (1) )(? (1) ) + L(? 2 + ? 2 ) 2 T t=1 ? 2 t + ? T t=1 ? t ?L tr (w (t) ; ? (t) ) 2 2 + L 2 T t=1 ? 2 t ? 2 ? 1 T t=1 ? t 2L meta (? (1) )(? (1) ) + L(? 2 + ? 2 ) T t=1 ? 2 t + ? T t=1 ? t ?L tr (w (t) ; ? (t) ) 2 2 + L 2 ? 2 T t=1 ? 2 t ? 1 T ? T 2L meta (? (1) )(? (1) ) + L(? 2 + ? 2 ) T t=1 ? 2 t + ? T t=1 ? t ?L tr (w (t) ; ? (t) ) 2 2 + L 2 ? 2 T t=1 ? 2 t = 2L meta (? (1) )(? (1) ) + L(? 2 + ? 2 ) T t=1 ? 2 t + ? T t=1 ? t ?L tr (w (t) ; ? (t) ) 2 2 + L 2 ? 2 T t=1 ? 2 t T max{L, ? T c } =O( C ? T ).</formula><p>The third inequality holds since</p><formula xml:id="formula_75">T t=1 (2? t ? L? 2 t ) = T t=1 ? t (2 ? L? t ) ? T t=1 ? t ,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and the final equality holds since</head><formula xml:id="formula_76">lim T ?? T t=1 ? 2 t &lt; ?, lim T ?? T t=1 ? 2 t &lt; ?, lim T ?? T t=1 ? t ?L tr (w (t) ; ? (t) ) 2 2</formula><p>&lt; ?. Thus we can conclude that our algorithm can always achieve min 0?t?T E[ ?L meta (? (t) ) 2 2 ] ? O( C ? T ) in T steps, and this finishes our proof of Theorem 1.</p><p>Theorem 2. Suppose that the loss function is Lipschitz smooth with constant L, and CMW-Net V(?, ?; ?) is differential with a ?-bounded gradient and twice differential with its Hessian bounded by B, and the loss function has ?-bounded gradient with respect to training/meta data. Let the learning rate ? t , ? t , 1 ? t ? T be monotonically descent sequences, and satisfy</p><formula xml:id="formula_77">? t = min{ 1 L , c1 ? T }, ? t = min{ 1 L , c2 ? T }, for some c 1 , c 2 &gt; 0, such that ? T c1 ? L, ? T c2 ? L. Meanwhile, they satisfy ? t=1 ? t = ?, ? t=1 ? 2 t &lt; ?, ? t=1 ? t = ?, ? t=1 ? 2 t &lt; ?. Then CMW-Net can achieve E[ ?L tr (w (t) ; ? (t) ) 2 2 ] ? in O(1/ 2 ) steps. More specifically, min 0?t?T E ?L tr (w (t) ; ? (t) ) 2 2 ? O( C ? T ) (38)</formula><p>where C is some constant independent of the convergence process.</p><p>Proof. It is easy to conclude that ? t satisfy ? t=0 ? t = ?, ? t=0 ? 2 t &lt; ?. Recall the update equation of w in each iteration as follows:</p><formula xml:id="formula_78">w (t+1) = w (t) ? ? n i=1 V(L tr i (w), S yi ; ? (t+1) )? w L tr i (w) w (t) .</formula><p>Under the sampled mini-batch ? t from the training dataset, the updating equation can be rewritten as:</p><formula xml:id="formula_79">w (t+1) = w (t) ? ? t ?L tr (w (t) ; ? (t+1) )| ?t ,</formula><p>where ?L train (w (t) ; ? (t+1) ) = n i=1 V(L tr i (w (t) ), N i ; ? (t+1) )? w (t) L tr i (w)</p><formula xml:id="formula_80">w (t)</formula><p>, and n i=1 V(L tr i (w (t) ), N i ; ? (t+1) ) = 1. Since the mini-batch ? t is drawn uniformly at random, we can rewrite the update equation as:</p><formula xml:id="formula_81">w (t+1) = w (t) ? ? t [?L tr (w (t) ; ? (t+1) ) + ? (t) ],</formula><p>where ? (t) = ?L tr (w (t) ; ? (t+1) )| ?t ? ?L tr (w (t) ; ? (t+1) ). Note that ? (t) are i.i.d. random variables with finite variance, since ? t are drawn i.i.d. with a finite number of samples, and thus E[? (t) ] = 0, E[ ? (t) 2 2 ] ? ? 2 . The objective function L tr (w; ?) defined in Eq. (30) can be easily proved to be Lipschitz-smooth with constant L, and have ?-bounded gradient with respect to training data. Observe that</p><formula xml:id="formula_82">L tr (w (t+1) ; ? (t+1) ) ? L tr (w (t) ; ? (t) ) = L tr (w (t+1) ; ? (t+1) ) ? L tr (w (t+1) ; ? (t) ) + L tr (w (t+1) ; ? (t) ) ? L tr (w (t) ; ? (t) ) .<label>(39)</label></formula><p>For the first term, by Lipschitz smoothness of the training loss function L tr (? (t+1) (? (t+1) )), we have</p><formula xml:id="formula_83">L tr (w (t+1) ; ? (t) ) ? L tr (w (t) ; ? (t) ) ? ?L tr (w (t) ; ? (t) ), w (t+1) ? w (t) + L 2 w (t+1) ? w (t) 2 2 = ?L tr (w (t) ; ? (t) ), ?? t [?L tr (w (t) ; ? (t) ) + ? (t) ] + L? 2 t 2 ?L tr (w (t) ; ? (t) ) + ? (t) 2 2 = ? (? t ? L? 2 t 2 ) ?L tr (w (t) ; ? (t) ) 2 2 + L? 2 t 2 ? (t) 2 2 ? (? t ? L? 2 t ) ?L tr (w (t) ; ? (t) ), ? (t) .</formula><p>For the second term, we have</p><formula xml:id="formula_84">L tr (w (t+1) ; ? (t+1) ) ? L tr (w (t+1) ; ? (t) ) = 1 n n i=1 V(L tr i (w (t+1) ), N i ; ? (t+1) ) ? V(L tr i (w (t+1) ), N i ; ? (t) ) L train i (w (t+1) ) ? 1 n n i=1 ?V(L tr i (w (t+1) ), N i ; ?) ?? ? (t) , ? (t+1) ? ? (t) + ? 2 ? (t+1) ? ? (t) 2 2 L tr i (w (t+1) ) = 1 n n i=1 ?V(L tr i (w (t+1) ), N i ; ?) ?? ? (t) , ?? t [? ? L meta (? (t+1) (? (t) )) + ? (t) ] + ?? 2 t 2 ?L meta (? (t+1) (? (t) )) + ? (t) 2 2 L tr i (w (t+1) ) = 1 n n i=1 ?V(L tr i (w (t+1) ), N i ; ?) ?? ? (t) , ?? t [?L meta (? (t+1) (? (t) )) + ? (t) ] + ?? 2 t 2 ?L meta (? (t+1) (? (t) )) 2 2 + ? (t) 2 2 + 2 ?L meta (? (t+1) (? (t) )), ? (t) L tr i (w (t+1) ).</formula><p>Therefore, for Eq.(39), we have:</p><formula xml:id="formula_85">L tr (w (t+1) ; ? (t+1) ) ? L tr (w (t+1) ; ? (t) ) ? 1 n n i=1 ?V(L tr i (w (t+1) ), N i ; ?) ?? ? (t) , ?? t [?L meta (? (t+1) (? (t) )) + ? (t) ] + ?? 2 t 2 ?L meta (? (t+1) (? (t) )) 2 2 + ? (t) 2 2 + 2 ?L meta (? (t+1) (? (t) )), ? (t) L tr i (w (t+1) ) ? (? t ? L? 2 t 2 ) ?L tr (w (t) ; ? (t) ) 2 2 + L? 2 t 2 ? (t) 2 2 ? (? t ? L? 2 t ) ?L tr (w (t) ; ? (t) ), ? (t) .</formula><p>Taking expectation of the both sides of the above inequality and based on E[? (t) ] = 0, E[? (t) ] = 0, we have</p><formula xml:id="formula_86">E[L train (w (t+1) ; ? (t+1) )] ? E[L train (w (t) ; ? (t) )] ? E 1 n n i=1 ?V(L tr i (w (t+1) ), N i ; ?) ?? ? (t) , ?? t ?L meta (? (t+1) (? (t) )) + ?? 2 t 2 ?L meta (? (t+1) (? (t) )) 2 2 + ? (t) 2 2 L tr i (w (t+1) ) ? (? t ? L? 2 t 2 )E ?L tr (w (t) ; ? (t) ) 2 2 + L? 2 t 2 E[ ? (t) 2 2 ].</formula><p>Summing up the above inequalities over t = 1, ..., T in both sides and rearranging the terms, we obtain</p><formula xml:id="formula_87">T t=1 ? t ? L? 2 t 2 E ?L tr (w (t) ; ? (t) ) 2 2 ? T t=1 ? t E 1 n n i=1 L tr i (w (t+1) ) ?V(L tr i (w (t+1) ), N i ; ?) ?? ? (t) ?L meta (? (t+1) (? (t) )) + T t=1 L? 2 t 2 E[ ? (t) 2 2 ] + E[L train (w (1) ; ? (1) )] ? E[L tr (w (T +1) ; ? (T +1) )] + T t=1 ?? 2 t 2 1 n n i=1 L tr i (w (t+1) ) E ?L meta (? (t+1) (? (t) )) 2 2 + E ? (t) 2 2 ??M T t=1 ? t ?L meta (? (t+1) (? (t) )) + T t=1 L? 2 t 2 ? 2 +E[L tr (w (1) ; ? (1) )] + T t=1 ?? 2 t 2 M (? 2 + ? 2 ) &lt; ?.</formula><p>The last inequality holds since</p><formula xml:id="formula_88">? t=0 ? 2 t &lt; ?, ? t=0 ? 2 t &lt; ?, T t=1 ? t ?L meta (? (t+1) (? (t) )) &lt; ?, and 1 n n i=1 L train i (w (t) ) ? M , i.e.</formula><p>, the sum of limited number of samples' losses is bounded. Thus we have</p><formula xml:id="formula_89">min t E ?L tr (w (t) ; ? (t) ) 2 2 ? T t=1 ? t ? L? 2 t 2 E ? ? L meta (? (t+1) (? (t) )) 2 2 T t=1 ? t ? L? 2 t 2 ? ?M T t=1 ? t ?L meta (? (t+1) (? (t) )) + T t=1 L? 2 t 2 ? 2 +E[L tr (w (1) ; ? (1) )] + T t=1 ?? 2 t 2 M (? 2 + ? 2 ) T t=1 ? t ? L? 2 t 2 ? ?M T t=1 ? t ?L meta (? (t+1) (? (t) )) + T t=1 L? 2 t 2 ? 2 +E[L tr (w (1) ; ? (1) )] + T t=1 ?? 2 t 2 M (? 2 + ? 2 ) T t=1 ? t ? ?M T t=1 ? t ?L meta (? (t+1) (? (t) )) + T t=1 L? 2 t 2 ? 2 +E[L tr (w (1) ; ? (1) )] + T t=1 ?? 2 t 2 M (? 2 + ? 2 ) T ? t ? ?M T t=1 ? t ?L meta (? (t+1) (? (t) )) + T t=1 L? 2 t 2 ? 2 +E[L tr (w (1) ; ? (1) )] + T t=1 ?? 2 t 2 M (? 2 + ? 2 ) T max{L, ? T c } =O( C ? T ).</formula><p>The third inequality holds since</p><formula xml:id="formula_90">T t=1 (2? t ? L? 2 t ) = T t=1 ? t (2 ? L? t ) ? T t=1 ? t .</formula><p>Thus we can conclude that our algorithm can always achieve min 0?t?T E ?L tr (w (t) ; ? (t) ) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.4 Pytorch codes of our algorithm</head><p>The following is the Pytorch codes of our algorithm, which is essily completed based on the code of MW-Net. The main difference from MW-Net is to re-define the structure of meta-model (CMW-Net) and generate the meta-class labels in advance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX B MORE EXPERIMENTAL RESULTS AND EXPERIMENTAL SETTINGS IN SECTION 4 B.1 Class Imbalance Experiments</head><p>In this series of experiments, we use ResNet-32 <ref type="bibr" target="#b0">[1]</ref> as the classifier network with softmax cross-entropy loss by SGD with a momentum 0.9, a weight decay 5 ? 10 ?4 , an initial learning rate 0.1. The learning rate of ResNet-32 is divided by 100 after 160 and 180 epoch (for a total 200 epochs). The learning rate of CMW-Net is fixed as 10 ?4 , and the weight decay of CMW-Net is fixed as 10 ?5 . The batch size is set as 100 for all experiments. We randomly selected fixed images per class in every epoch from the training set as the meta-data set and the number of selected images for each class is the same as the number of the least class. <ref type="figure" target="#fig_12">Fig. 9</ref> shows the weighting schemes learned by CMW-Net on CIFAR-10-LT and CIFAR-100-LT, under different imbalance settings. It can be seen that our CMW-Net can adaptively learn proper weighting schemes according to different degrees of class imbalance. For example, when the dataset is balanced, CMW-Net tends to learn approximately similar weighting functions for all three meta-classes. When the degree of class imbalance becomes more significant, the weighting schemes extracted from different meta-classes tend to be more largely varied, showing their different internal bias characteristics.</p><p>In <ref type="figure" target="#fig_0">Fig. 10</ref>, we further plot the confusion matrices produced by the MW-Net and CMW-Net methods, respectively. As can be easily seen, CMW-Net consistently outperforms MW-Net, and CMW-Net more evidently improves the accuracies of MW-Net under larger class imbalance rate. Specifically, CMW-Net gets more prominent performance gain on tail classes, and meanwhile maintains the performance on head classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2 Feature-independent Label Noise Experiment</head><p>In this series of experiments, we adopted an 18-layer PreAct Resnet <ref type="bibr" target="#b101">[102]</ref> as our classifier network, with softmax cross-entropy loss by SGD with a momentum 0.9, a weight decay 5 ? 10 ?4 . For CMW-Net, we set the initial learning rate as 0.1 and the learning rate of classification network is divided by 10 after 80 and 100 epoch (for a total 120 epochs). For the CMW-Net-SL, we set the initial learning rate as 0.01 and the learning rate of classification network is divided by 10 after 150 epoch (for a total 300 epochs) following by Dividemix <ref type="bibr" target="#b7">[8]</ref>. The batch size is specified as 128 for all experiments. We adopt Adam optimizer to optimize CMW-Net and the learning rate of CMW-Net is fixed as 10 ?3 , and the weight decay of CMW-Net is fixed as 10 ?4 . We repeat the experiments with 3 random trials and report the mean value and standard deviation.</p><p>Motivated by M-correction <ref type="bibr" target="#b6">[7]</ref> and Dividemix <ref type="bibr" target="#b7">[8]</ref>, we selected the meta data at each epoch according to the training loss. Specifically, we explore to create the meta dataset dynamically along iteration, based on the high-quality clean samples as well as its high-quality pseudo labels from the training set (with lowest losses) as an unbiased estimator of the clean   data-label distribution in each iteration of our algorithm. To make the meta dataset balanced, we selected 10 images per class. In this case, the performance of meta dataset can be served as an indicator of whether CMW-Net is trained to filter noisy samples and generalize to clean test distribution.</p><p>Such meta dataset generation strategy may lack of diversity patterns to characterize the latent clean data-label distribution. To overcome this, we explore to utilize mixup technique <ref type="bibr" target="#b83">[84]</ref> to enrich the variety of our proposed meta dataset distribution while maintaining the unbiasedness in terms of clean test distribution. The hyperparameter of convex combination is randomly sampled from a Beta distribution Beta <ref type="bibr" target="#b0">(1,</ref><ref type="bibr" target="#b0">1)</ref>. Extensive experiments have verified the effectiveness of such created meta dataset from training dataset. Such property makes our meta-learning algorithm feasible to be applied to real-world biased datasets, where it is generally hard to collect an ideal high-quality extra clean meta dataset. We also use such meta dataset generation strategy all our noisy labels experiments as well as all real-world biased datasets.</p><p>Figs. 11 and 13 shows the empirical pdfs of cross-entropy loss for each class on CIFAR-10 dataset under symmetric and asymmetric noises with varying noise rates, respectively. The corresponding weighting functions and weight distributions over the training examples learned by MW-Net <ref type="bibr" target="#b8">[9]</ref> and the proposed CMW-Net are also depicted. It can be easily observed that compared with MW-Net, CMW-Net has better flexibility to deal with both training data bias cases, even for inter-class heterogenous data biases. Specifically, the proposed CMW-Net can adaptively adjust its weighting schemes to adapt variations of noise rates, and behaves consistently with the underlying data biased patterns, naturally leading to its better performance on distinguishing clean and noisy images. Note that even for high noise rate (e.g., 80%) scenarios, our method still shows fine capability of distinguishing clean and noisy images.</p><p>To further improve the learning effect of CMW-Net, we introduce additional soft label supervision to build the CMW-Net-SL strategy. <ref type="figure" target="#fig_0">Figs. 12 and 14</ref> show the confusion matrices learned by two methods, respectively. Specifically, the confusion matrices obtained by CMW-Net almost correspond to the noise transition matrices, and those calculated by CMW-Net-SL contain the refurbished labels by soft labels. Although the noise rate was in relatively high levels (e.g., 60% and 80%), most of the diagonal entries had probability larger than 0.95, implying the effectiveness of CMW-Net-SL on its fine label correction ability. This side information is thus validated to be able to compensate beneficially to the sample reweighting learning, and ameliorate both weighting scheme extracting and robust classifier learning in a stable way.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.3 Feature-dependent Label Noise Experiment</head><p>In this series of experiments, we use ResNet-34 <ref type="bibr" target="#b0">[1]</ref> as the classifier network, with softmax cross-entropy loss by SGD with a momentum 0.9, a weight decay 5 ? 10 ?4 and an initial learning rate 0.1. The learning rate of ResNet-34 is set as CosineAnnealingWarmRestarts <ref type="bibr" target="#b102">[103]</ref>. The learning rate of CWN-Net is fixed as 10 ?3 , and the weight decay of CMW-Net is fixed as 10 ?4 . The batch size is 128 for all experiments. We repeat the experiments with 3 random trials and report the mean value and standard deviation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.4 Additional Open-set Label Noise Experiment</head><p>Open-set noise experiments use training samples that do not belong to any of the original class in the dataset considered in the classification task. Following <ref type="bibr" target="#b103">[104]</ref>, we yield CIFAR-10 with open-set noise by randomly replacing 40% of its training images with images from CIFAR-100. We used wide ResNet-28-2 <ref type="bibr" target="#b104">[105]</ref> as the base classifier network with softmax cross-entropy loss by SGD with a momentum 0.9, a weight decay 5 ? 10 ?4 . We set the initial learning rate of classification network as 0.1 and the learning rate is divided by 10 after 80 and 100 epoch (for a total 120 epochs). The batch size is 128 for all experiments. We adopt Adam optimizer to learn CMW-Net, with a learning rate 10 ?3 , and a weight decay 10 ?4 . We repeat the experiments with 3 random trials and report the mean value and standard deviation. We adopt the meta-data generation strategy as introduced in Sec. 4.2 of the main text, by randomly selecting 10 images per class at every epoch from the training set as the meta-data set. We train the network 20 epochs with cross-entropy loss for a warm-up to get the meta dataset stably. The compared methods include: 1) ERM: use standard cross-entropy loss to train DNNs; 2) Forward <ref type="bibr" target="#b69">[70]</ref>: correct the prediction by the label transition matrix; 3) GCE <ref type="bibr" target="#b5">[6]</ref>: behave as a robust loss to handle the noisy labels; 4) M-correction <ref type="bibr" target="#b6">[7]</ref> and 5) DivideMix <ref type="bibr" target="#b7">[8]</ref>: use different label correction methods; 6) L2RW <ref type="bibr" target="#b25">[26]</ref> and 7) MW-Net <ref type="bibr" target="#b8">[9]</ref>: represent the typical sample reweighting methods by meta-learning.</p><p>The classification accuracy on CIFAR-10 noisy datasets with 40% open-set noise is reported in <ref type="table" target="#tab_18">Table 11</ref>. As can be seen, our method evidently outperforms all other competing methods, verifying that our model is capable of learning more  True label 45.362% 5.598% 5.378% 5.818% 6.158% 6.397% 6.957% 6.218% 6.118% 5.998%</p><p>6.292% 45.335% 5.776% 6.431% 5.717% 6.431% 5.697% 5.994% 5.935% 6.391% 5.837% 6.215% 45.319% 5.797% 6.355% 5.637% 5.418% 6.355% 6.295% 6.773%</p><p>6.08% 5.863% 6.061% 46.187% 5.981% 5.605% 6.199% 6.12% 6.001% 5.902%</p><p>6.584% 6.098% 5.774% 5.794% 45.28% 6.605% 5.814% 6.605% 5.895% 5.551%</p><p>5.318% 6.888% 6.397% 5.907% 6.397% 45.428% 5.671% 5.985% 5.946% 6.064% 5.887% 6.047% 6.127% 5.527% 6.047% 5.947% 46.496% 6.588% 5.346% 5.987%</p><p>6.098% 5.838% 6.76% 6.319% 6.219% 5.717% 5.938% 45.537% 5.978% 5.597%</p><p>6.24% 6.1% 6.38% 5.879% 6.079% 5.598% 5.919% 5.257% 46.89% 5.658% (d) Symmetry Noise (80%) <ref type="figure" target="#fig_0">Fig. 12</ref>. Confusion matrices obtained by CMW-Net without (left) or with (right) soft label amelioration on CIFAR-10 with symmetry noise with varying noise rates ranging from 20% to 80%.  <ref type="bibr" target="#b13">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.5 Ablation Study</head><p>We perform ablation study to verify the effectiveness of two important components involved in our method: 1) the number of meta-classes; 2) whether to use an extra clean meta-data or using the automatic meta-data-generation strategy as proposed in Sec. 4.2 of the main text. As shown in <ref type="figure" target="#fig_0">Fig. 15(a)</ref>, by setting the number of meta-class as three, our method can consistently adapt to inter-class heterogenous data bias. Actually, by setting K = 3, where the training classes/tasks are separated as small, moderate, large-scales, correspondingly, all our experiments can achieve a stably fine performance. Furthermore, by observing <ref type="figure" target="#fig_0">Fig. 15(b)</ref>, we can see that the utilized meta-data-generation strategy is practicable for dealing with real-world noisy datasets, in which an extra ideal clean meta data is always hard to be collected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX C MORE EXPERIMENTAL RESULTS AND EXPERIMENTAL SETTINGS IN SECTION 5 C.1 Learning with Real-world Noisy Datasets</head><p>Animal-10N. ANIMAL-10N <ref type="bibr" target="#b77">[78]</ref> contains 55,000 human-labeled online images for 10 animals with confusable appearance. The estimated label noise rate is 8%. Following previous works <ref type="bibr" target="#b77">[78]</ref>, <ref type="bibr" target="#b82">[83]</ref>, 50,000 images are exploited as the training set and the left for testing. Following SELFIE <ref type="bibr" target="#b77">[78]</ref>, we use VGG-19 <ref type="bibr" target="#b105">[106]</ref> with batch normalization as the classifier network. The SGD optimizer is employed to train the network with a momentum 0.9, a weight decay 1 ? 10 ?3 for 100 epochs. We use an initial learning rate of 0.1, which is divided by 5 at 50% and 75% of the total number of epochs. The batch size is 128. We repeat the experiments with 3 random trials and report the mean value and standard deviation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mini-WebVision.</head><p>As the full dataset of WebVision is very large, we follow <ref type="bibr" target="#b36">[37]</ref> to use a mini version, which contains the first 50 classes of the Google subset of the data for a total of about 61,000 images. Following the standard protocol <ref type="bibr" target="#b36">[37]</ref>, we test the trained model on the WebVision validation set and the ImageNet validation set. Following C2D <ref type="bibr" target="#b87">[88]</ref>, we used ResNet-50 architecture as the classifier network for training. For self-supervised pre-training, we directly use the pretrained self-supervised models released at https://github.com/ContrastToDivide/C2D, which is based on the SimCLR implementation. We trained the network with softmax cross-entropy loss by SGD with a momentum 0.9, a weight decay 5 ? 10 ?4 . We set the initial learning rate as 0.01 and the learning rate of classification network is divided by 10 after 50 epoch (for a total 90 epochs). The learning rate of CMW-Net is fixed as 10 ?4 , and the weight decay of CMW-Net is fixed as 10 ?5 .    Test Accuracy (\%) w/ clean meta data wo/ clean meta data (b) On whether to use extra clean meta data <ref type="figure" target="#fig_0">Fig. 15</ref>. Some ablation studies for parameter setting issues of our proposed method. The batch size is 64. We adopt the meta-data-generation strategy as introduced in Sec. 4.2 of the main text, to randomly select 10 images per class at every epoch from the training set as the meta-data set for the above two real-world biased datasets. More typical noisy examples corrected by the proposed method on Animal-10N and Mini-WebVision are shown in Figs. 16 and 17, respectively. This further demonstrates our method's capability of recovering these easily confusable samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Webly Supervised Fine-Grained Recognition</head><p>WebFG-496. This dataset consists of three sub-datasets: Web-aircraft, Web-bird, and Web-car. WebFG-496 reuses the category labels of three famous manually labeled fine-grained datasets, FGVC-Aircraft, CUB200-2011, and Stanford Cars, which contain 100 types of airplanes, 200 species of birds, and 196 categories of cars, respectively, by collecting images from the Internet. It contains 53,339 training images with total 496 classes. The testing data take the testing sets in the original FGVC-Aircraft, CUB200-2011, and Stanford Cars. We used Bilinear-CNN <ref type="bibr" target="#b106">[107]</ref> as the classifier network. The network is pre-trained on ImageNet, and then fine-tuned on three sub-datasets of WebFG496. Following <ref type="bibr" target="#b106">[107]</ref>, we adopt a two-stage training strategy. We firstly freeze the convolutional layer parameters and only optimize the last fully connected layers with the learning rate and batch size being 10 ?3 and 64 for total 200 epoch. Then we optimize the parameters of all layers in the fine-tuned model with learning rate and batch size being set as 10 ?4 and 32, respectively, for total 200 epoch. The learning rate of CMW-Net is fixed as 10 ?3 , and the weight decay of CMW-Net is fixed as 10 ?4 . We adopt the meta-data-generation strategy, as introduced in Sec. 4.2 of the main test, to randomly select 10 images per class at every epoch from the training set as the meta-data set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX D MORE EXPERIMENTAL RESULTS AND EXPERIMENTAL SETTINGS IN SECTION 6</head><p>ImageNet-LT. The dataset is constructed as a long-tailed version of the original ImageNet-2012 <ref type="bibr" target="#b88">[89]</ref> by sampling a subset following the Pareto distribution with the power value 6. It totally has 115.8K images from 1000 categories with maximally 1280 images per class and minimally 5 images per class. Following OLTR <ref type="bibr" target="#b4">[5]</ref>, besides the overall top-1 classification accuracy over all classes, we also calculate the accuracy of three disjoint subsets: many-shot classes (each with over training 100 samples), medium-shot classes (each with 20-100 training samples) and few-shot classes (each under 20 training samples). We adopt the two-stage training protocol following <ref type="bibr" target="#b4">[5]</ref>. We use a Resnet-10 model initialized from scratch (i.e., random initialization) as the classifier model. We train the model with softmax cross-entropy loss by SGD with a momentum 0.9, a weight decay 5 ? 10 ?4 , an initial learning rate 0.1 and a batch size of 128 for 30 epochs, and divide learning rate by 10 at 10 epoch. The transferred CMW-Net is used at the first stage to produce proper sample weights for robust training. And it follows training protocol in <ref type="bibr" target="#b4">[5]</ref> at the second stage.</p><p>WebVision. WebVision <ref type="bibr" target="#b13">[14]</ref> contains 2.4 million images crawled from Google and Flickr using 1,000 labels shared with the ImageNet dataset. Its training set is both heteroskedastic label noise and class imbalanced (more detailed statistics can be found in <ref type="bibr" target="#b13">[14]</ref>), and it is considered as a popular benchmark for robust learning in the presence of heavy label noises. We trained Inception-ResNet v2 <ref type="bibr" target="#b107">[108]</ref> with softmax cross-entropy loss by SGD with a momentum 0.9, a weight decay 10 ?4 , an initial learning rate 0.1 and a batch size of 256. The learning rate is divided by 10 after 30 and 40 epoch (for a total 50 epochs). The transferred CMW-Net is used at every iteration to produce proper sample weights for robust training. The test performance on full WebVision and ILSVRC12 dataset are presented in <ref type="table" target="#tab_2">Table 12</ref> tree frog tree frog bullfrog tree frog bullfrog bullfrog mud turtle axolotl (h) Samples selected from mini-WebVision <ref type="bibr" target="#b13">[14]</ref>. The original training label is tailed frog. <ref type="figure" target="#fig_0">Fig. 17</ref>. Examples of randomly selected samples with noisy labels corrected by our method on mini-WebVision <ref type="bibr" target="#b13">[14]</ref>. The original training labels and generated pseudo-labels by model are shown in red and blue, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>APPENDIX E MORE EXPERIMENTAL RESULTS AND EXPERIMENTAL SETTINGS IN SECTION 7 E.1 Partial-Label Learning</head><p>We adopted two training stages to solve the problem. At the first stage, we train the network using the recent SOTA method, PRODEN <ref type="bibr" target="#b93">[94]</ref>, for 100 epochs and then we can get the training data with single noisy labels by one-hot encoding of the model predictions. Now the partial-label learning problem becomes a conventional learning problem with all samples attached with single noisy labels. It is naturally to use the proposed method to further deal with such a problem. Thus at the second stage, we trained the network with obtained single noisy labeled data using the proposed CMW-Net method. We use a SGD optimizer with a momentum 0.9, a weight decay 5 ? 10 ?4 , an initial learning rate 0.1, a batch size 128. The learning rate is divided by 10 after 80 and 100 epoch (for a total 120 epochs). We adopt Adam optimizer to learn CMW-Net. The learning rate of CMW-Net is fixed as 10 ?3 , and the weight decay of CMW-Net is fixed as 10 ?4 . We repeat the experiments with 3 random trials and report the mean value and standard deviation. We adopt the meta-data-generation strategy as introduced in Sec. 4.2 of the main text, by randomly selecting 10 images per class at every epoch from the training set as the meta-data set.</p><p>Following PRODEN <ref type="bibr" target="#b93">[94]</ref>, we manually corrupt these datasets into partially labeled versions by a flipping probability q, where q = P (? = 1|y = 0) gives the probability that a false positive label? is flipped from a negative label y. We adopt a binomial flipping strategy: c ? 1 independent experiments are conducted on all training examples, each determining whether a negative label is flipped with probability q. Then for the examples that none of the negative labels are flipped, we additionally flip a random negative label to the candidate label set for ensuring all the training examples are partially labeled. We use five widely used benchmark datasets, including MNIST <ref type="bibr" target="#b108">[109]</ref>, Fashion-MNIST <ref type="bibr" target="#b109">[110]</ref>, Kuzushiji-MNIST <ref type="bibr" target="#b110">[111]</ref>, CIFAR-10 and CIFAR-100 <ref type="bibr" target="#b81">[82]</ref>. For MNIST, Fashion-MNIST, and Kuzushiji-MNIST datasets, we use 5-layer perceptron (MLP), and for CIFAR-10 and CIFAR-100 dataset, we use ResNet-32 <ref type="bibr" target="#b0">[1]</ref> as the classifier network. <ref type="table" target="#tab_3">Table 13</ref> reports the mean test accuracies with standard deviation on five benchmark datasets. It can be seen that our method can consistently outperform the baseline PRODEN method under both less-partial circumstances q = 0.1 and stronger-partial circumstances q = 0.7. Observing that PRODEN method behaves under strong-partial circumstances similarly as that under less-partial circumstances, which implies it tends to easily overfit to pseudo-labels estimated by model prediction. Considering that the obtained results are calculated on the basis of PRODEN method as single noisy labels dataset, our method can alleviate such pseudo-label issue and bring further performance improvement for such a partial label learning problem. Through introducing our method as a post-processing learning, we can obtain a more robust model based on the over-confident information. Particularly, our method can improve PRODEN method about 4-8 points on CIFAR-10 and 8-13 points on CIFAR-100 in classification accuracy. Applying our method to more partial-label learning method to obtain more robust result is thus potentially expected, and we leave this research for our future study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2 Semi-Supervised Learning</head><p>Following Fixmatch <ref type="bibr" target="#b46">[47]</ref>, we consider the settings by giving 4/25/400 labeled images for each class on CIFAR-10 and 4/25/100 labeled images for each class on CIFAR-100. We used WRN-28-2/WRN-28-8 for CIFAR-10/CIFAR-100 as the classifier network with an initial learning rate 0.03, a batch size 64 for label data and 448 for unlabel data. For ImageNet experiment, we use 10 % of the training data for each class as labeled and treat the rest as unlabeled examples. We used ResNet-50 as the classifier and the batch size for labeled (unlabeled) images is 64 (320) with initial learning rate 0.03. We adopt RandAugment <ref type="bibr" target="#b111">[112]</ref> as the strong augmentation for this experiment. We adopt Adam optimizer to learn CMW-Net. The learning rate of CMW-Net is fixed as 10 ?3 , and the weight decay of CMW-Net is fixed as 10 ?4 . <ref type="table" target="#tab_5">Table 14</ref> shows the classification error rates on CIFAR-10/100 and ImageNet. From the table, one can observe that our method improves Fixmatch method and achieves the best performance under all label conditions on all datasets. Specifically, our method achieves around 2 points improvement on ImageNet as compared with Fixmatch, showing that our method is capable of finely handling such large-scale sample weight learning issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3 Selective Classification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3.1 Problem Formulation</head><p>We consider the selective classification problem in DNNs (supervised learning with a rejection option), which allows the learned classifier to abstain whenever they are not sufficiently confident in their prediction, so as to finely detect and control statistical uncertainties of training cases <ref type="bibr" target="#b114">[115]</ref>. Specifically, let P (X, Y ) be the underlying joint distribution over X ? Y, where X , Y denote the sample and label spaces, respectively, and f : X ? Y be the prediction function (DNNs here). The expected risk is:  The selective classifier is then defined as a pair of functions (f, g), where g : X ? R is a selection function that reveals the underlying uncertainty of inputs. Specifically, given input x, (f, g) outputs:</p><formula xml:id="formula_91">R(f ) = E P (X,</formula><p>(f, g)(x) = f (x), if g(x) ? ? Abstain otherwise ,</p><p>i.e., the model abstains from making a prediction when selection function g(x) falls bellow a predetermined threshold ? . We call g(x) the uncertainty score of x, and different methods tend to use different g. The coverage is defined as the probability mass of the non-rejected region in X , expressed as:</p><formula xml:id="formula_92">?(g) = E P (X) [g(x)],</formula><p>and its empirical coverage is?</p><formula xml:id="formula_93">D tr (g) = 1 m N i=1 g(x i ).</formula><p>The selective risk of (f, g) is defined as</p><formula xml:id="formula_94">R(f, g) = E P (X,Y ) [ (f (x), y)g(x)] ?(g) ,</formula><p>and empirical version isR</p><formula xml:id="formula_95">D tr (f, g) = 1 N N i=1 (f (x i ), y i )g(x i ) ? D tr (g) .</formula><p>The SelectiveNet <ref type="bibr" target="#b114">[115]</ref> tries to optimize the objective</p><formula xml:id="formula_96">L = ?L D tr (f, g) + (1 ? ?)R D tr (h),</formula><p>where L D tr (f, g) =R D tr (f, g) + ? max(0, c ?? D tr (g)) 2 , c is the given coverage, and ?, ? control the relative importance of each term. As stated in <ref type="bibr" target="#b114">[115]</ref>, the auxiliary cross-entropy lossR D tr (h) exposes the main body block to all training samples throughout the training process to avoid SelectiveNet overfitting to the wrong subset of the training set.  It can be seen that the rationality of the auxiliary cross-entropy lossR D tr (h) still inclines to be negatively affected by the data biased issues, like commonly existed class imbalance and noisy label cases in practical datasets. It is thus natural to employ the proposed CMW-Net on the term for making the learned SelectiveNet with better robustness to training samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3.2 CMW-Net Amelioration and Experiments</head><p>We can then readily ameliorate the selective classification by embedding CMW-Net weighting schemes into its optimization problem. Specifically, provided a meta dataset as D meta = {x meta i , y meta i } M i=1 , the objective of the problem is then reformulated as the following bi-level problem:</p><formula xml:id="formula_97">? * = arg min ? L D meta (f * ? , g * ? ) {f * ? , g * ? } = arg min f,g ?L D tr (f, g) + (1 ? ?) N i=1 V( i , N i ; ?) (h(x i ), y i ).</formula><p>Through properly assigning sample weights to the loss terms for all training samples, it is expected to better eliminate the negative influence brought by complicated data biases. We use long-tailed versions of CIFAR-10 and CIFAR-100 datasets under different imbalance factors for performance evaluation. The generation strategy is similar to that introduced in Sec. 4.1 of the main text. The baseline method is the recent SOTA method for this task: SelectiveNet <ref type="bibr" target="#b114">[115]</ref>. We use the VGG-16 network <ref type="bibr" target="#b105">[106]</ref> with batch normalization <ref type="bibr" target="#b115">[116]</ref> and dropout <ref type="bibr" target="#b116">[117]</ref> as the classifier network in experiments. The network is optimized using SGD with initial learning rate of 0.1, momentum of 0.9, weight decay of 5 ? 10 ?4 , batch size of 128, and total training epoch of 300. The learning rate is decayed by 0.5 in every 25 epochs. As the meta-data-generation strategy as introduced in Sec. 4.2 of the main text, we randomly select 10 images per class at every epoch from the training set as the meta-data set.</p><p>The obtained experimental results are summarized in <ref type="table" target="#tab_6">Table 15</ref> and <ref type="figure" target="#fig_0">Fig. 18</ref>. Specifically, the figure compares the riskcoverage curves of SelectiveNet equipped with and without CMW-Net for weighting its sample loss. It is easy to see the performance gain brought to the method by CMW-Net. From the figure, one can more comprehensively observe that selective classification errors of SelectiveNet consistently grow as we increase the degree of class imbalance. Comparatively, under the assistance of CMW-Net, the errors can be consistently reduced in all cases. These results validate the usefulness of CMW-Net for this specific learning task under biased data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>The architectures of (a) MW-Net and (b) CMW-Net.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>(a) Empirical pdfs of cross-entropy loss of all 10 classes on CIFAR-10 dataset with different data bias cases. From left to right: Class imbalance (imbalanced factor 10), Symmetric noise (noise rate 40%), Asymmetric noise (noise rate 40%), Feature-dependent noise (Type-I + 30% Asymmetric). For each case, the classes are demonstrated in an ascending order of their contained sample numbers. (b) The weighting function extracted by MW-Net [9], alongside the histogram of all sample weights calculated by it, for each type of biased dataset in (a). (c) Three weighting functions extracted by CMW-Net (corresponding to three meta-classes with small, moderate, large data scales), alongside the histogram of all sample weights calculated by them, for each type of biased dataset in (a).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Main flowchart of the proposed CMW-Net meta-training algorithm (steps 6-8 in Algorithm 1).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Confusion matrices obtained by (left) MW-Net and (right) CMW-Net on CIFAR-10-LT (with imbalance factor 200).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Confusion matrices obtained by CMW-Net and CMW-Net-SL on CIFAR-10 with (a) Symmetry Noise 60% and (b) Asymmetry Noise 60%.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Fig. 6 .</head><label>6</label><figDesc>Examples of randomly selected samples with noisy labels corrected by our method. The original training labels and generated pseudo-labels by model are shown in red and blue, respectively. More comprehensive examples are depicted in the SM.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>moderate meta-class large meta-class (b) mini WebVision Fig. 7. Weighting schemes learned by CMW-Net on real biased datasets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Fig. 8 .</head><label>8</label><figDesc>Accuracy comparisons on PRODEN w/o CMW-Net strategy over (left) CIFAR-10 and (right) CIFAR100 under partial label learning setting.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>), 1</head><label>1</label><figDesc>? i ? M } with clean labels, and the overall meta loss is,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>T</head><label></label><figDesc>) in T steps, and this completes our proof of Theorem 2.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head></head><label></label><figDesc>def norm_func(v_lambda): norm_c = torch.sum(v_lambda) if norm_c != 0: v_lambda_norm = v_lambda / norm_c else: v_lambda_norm = v_lambda return v_lambda_norm class share(MetaModule): def __init__(self, input, hidden1, hidden2): super(share, self).__init__() self.layer = nn.Sequential( MetaLinear(input, hidden1), nn.ReLU(inplace=True) ) def forward(self, x): output = self.layer(x) return output class task(MetaModule): def __init__(self, hidden2, output, num_classes): super(task, self).__init__() self.layers = nn.ModuleList() for i in range(num_classes): self.layers.append(nn.Sequential( MetaLinear(hidden2, output), nn.Sigmoid() )) def forward(self, x, num, c): si = x.shape[0] output = torch.tensor([]).cuda() for i in range(si): output = torch.cat(( output, self.layers[c[num[i]]]( x[i].unsqueeze(0) ) ),0) return output # The structure of CMW-Net class VNet(MetaModule): def __init__(self, input, hidden1, hidden2, output, num_classes): super(VNet, self).__init__() self.feature = share(input, hidden1, hidden2) self.classfier = task(hidden2, output, num_classes) def forward(self, x, num, c): num = torch.argmax(num, -1) output = self.classfier( self.feature(x), num, c ) return output optimizer_a = torch.optim.SGD(model.params(), args.lr, momentum=args.momentum, nesterov=args.nesterov, weight_decay=args.weight_decay) optimizer_c = torch.optim.Adam(vnet.params(), 1e-3, weight_decay=1e-4) # Generating meta-class labels es = Kmeans(3) es.fit(train_loader.dataset.targets) c = es.labels_ for iters in range(num_iters): adjust_learning_rate(optimizer_a, iters + 1) model.train() data, target = next(iter(train_loader)) data, target = data.to(device), target.to(device) meta_model.load_state_dict(model.state_dict()) y_f_hat = meta_model(data) cost = F.cross_entropy(y_f_hat, target, reduce=False) cost_v = torch.reshape(cost, (len(cost), 1)) v_lambda = vnet(cost_v.data, target.data, c) v_lambda_norm = norm_func(v_lambda) l_f_meta = torch.sum(cost_v * v_lambda_norm) meta_model.zero_grad() grads = torch.autograd.grad(l_f_meta,(meta_model.params()),create_graph=True) meta_model.update_params(lr_inner=meta_lr,source_params=grads) data_meta,target_meta = next(iter(train_meta_loader)) data_meta,target_meta = data_meta.to(device),target_meta.to(device) y_g_hat = meta_model(data_meta) l_g_meta = F.cross_entropy(y_g_hat, target_meta) optimizer_c.zero_grad() l_g_meta.backward() optimizer_c.step() y_f = model(data) cost_w = F.cross_entropy(y_f, target, reduce=False) cost_v = torch.reshape(cost_w, (len(cost_w), 1)) with torch.no_grad(): w_new = vnet(cost_v,target, c) w_v = norm_func(w_new) l_f = torch.sum(cost_v * w_v) optimizer_a.zero_grad() l_f.backward() optimizer_a.step()</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Fig. 9 .</head><label>9</label><figDesc>Weighting schemes learned by CMW-Net on CIFAR-10-LT and CIFAR-100-LT with imbalance factors ranging from 1 to 200.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14"><head>Fig. 10 .</head><label>10</label><figDesc>Confusion matrices obtained by (left) MW-Net and (right) CMW-Net on CIFAR-10-LT with imbalance factors ranging from 1 to 200.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_15"><head></head><label></label><figDesc>Empirical pdf of cross-entropy loss for each class on CIFAR-10 dataset with varying noise rates under symmetric noise. Weighting functions and histograms of all sample weights over all training examples learned by MW-Net under symmetric noise. Weighting functions and histograms of all sample weights over all training examples learned by CMW-Net under symmetric noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_16"><head>Fig. 11 .</head><label>11</label><figDesc>(a) Empirical pdf of the cross-entropy loss calculated on all samples of each class on CIFAR-10 with varying noise rates (from left to right, the noise rates are 20%, 40%, 60%, 80%) under symmetric noise; (b)(c) The weighting functions and histograms of all sample weights over all training examples learned by MW-Net and CMW-Net.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_17"><head></head><label></label><figDesc>0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_18"><head></head><label></label><figDesc>Empirical pdf of cross-entropy loss for each class on CIFAR-10 dataset with varying noise rates under asymmetric noise. Weighting functions and histograms of all sample weights over all training examples learned by CMW-Net under asymmetric noise. Weighting functions and weight distributions over the training examples learned by our CMW-Net under asymmetric noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_19"><head>Fig. 13 .</head><label>13</label><figDesc>(a) Empirical pdf of the cross-entropy loss calculated on all samples of each class on CIFAR-10 with varying noise rates (from left to right, the noise rates are 20%, 40%, 60%, 80%) under asymmetric noise; (b)(c) The weighting functions and histograms of all sample weights over all training examples learned by MW-Net and CMW-Net.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_20"><head></head><label></label><figDesc>0</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_21"><head></head><label></label><figDesc>Y ) [ (f (x), y)], where : Y ? Y ? R + is the loss function. Given a dataset D tr = {(x i , y i )} N i=1 where all (x i , y i )s are i.i.d. drawn from X ? Y , the empirical risk is then specified asR D tr (f ) = 1 N N i=1 (f (x i ), y i ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_22"><head>Fig. 18 .</head><label>18</label><figDesc>Risk coverage curves of SelectiveNet w/o CMW-Net strategy on (left) CIFAR-10 and (right) CIFAR100 under imbalance factor 20.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>CMW-Net Update Classifier Update Loss Weight Meta-class label ... Meta- class feature</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>1.0% 98.6% 0.0% 0.1% 0.0% 0.0% 0.1% 0.0% 0.0% 0.2% 6.5% 0.2%<ref type="bibr" target="#b83">84</ref>.6% 4.2% 1.2% 1.6% 1.4% 0.3% 0.0% 0.0% 3.9% 0.9% 6.5% 78.7% 2.5% 4.8% 1.8% 0.8% 0.0% 0.1% 4.5% 0.3% 8.1% 7.6% 73.0% 2.3% 1.9% 2.3% 0.0% 0.0% 2.4% 0.1% 7.6% 28.7% 2.6% 55.3% 0.8% 2.3% 0.0% 0.2% 2.9% 1.2% 9.2% 12.4% 1.4% 1.4% 71.5% 0.0% 0.0% 0.0% 9.3% 0.2% 6.0% 13.8% 7.8% 4.9% 0.7% 57.3% 0.0% 0.0% 47.1% 11.2% 1.5% 1.8% 0.4% 0.3% 0.2% 0.0% 37.4% 0.1% 17.2% 44.6% 0.6% 2.0% 0.0% 0.0% 0.0% 0.1% 1.6% 33.9% 9% 1.0% 2.1% 1.4% 0.6% 0.0% 0.1% 0.1% 0.6% 0.2% 0.6% 98.6% 0.0% 0.2% 0.1% 0.0% 0.2% 0.0% 0.0% 0.3% 5.0% 0.1% 77.4% 7.8% 4.3% 2.5% 2.6% 0.3% 0.0% 0.0% 2.0% 0.6% 2.8% 83.9% 3.7% 4.3% 1.9% 0.7% 0.0% 0.1% 2.1% 0.2% 4.4% 7.9% 79.3% 2.1% 1.7% 2.3% 0.0% 0.0% 1.4% 0.2% 3.4% 31.5% 3.0% 57.0% 1.0% 2.3% 0.0% 0.2% 1.3% 1.2% 5.1% 14.0% 2.8% 1.2% 74.3% 0.0% 0.0% 0.1% 4.6% 0.2% 3.5% 17.3% 9.9% 5.4% 0.8% 58.3% 0.0% 0.0% 33.5% 9.3% 1.6% 3.2% 0.6% 0.3% 0.5% 0.0% 50.5% 0.5% 12.9% 35.5% 0.5% 4.0% 0.1% 0.0% 0.1% 0.1% 2.0% 44.8%</figDesc><table><row><cell>MW-Net</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>93.</cell></row><row><cell>80</cell><cell></cell><cell>1 2</cell></row><row><cell>40 60</cell><cell>True label</cell><cell>3 4 5 6</cell></row><row><cell>20</cell><cell></cell><cell>7 8</cell></row><row><cell>0</cell><cell></cell><cell>9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>55.25 49.73 43.06 39.41TABLE 2</head><label>2</label><figDesc>10 1 ERM 34.32 29.64 25.19 17.77 13.61 7.53 65.16 61.68 56.15 48.86 44.29 29.50 Focal loss [30] 34.71 29.62 23.29 17.24 13.34 6.97 64.38 61.59 55.68 48.05 44.22 28.85 CB loss [4] 31.11 27.63 21.95 15.64 13.23 7.53 64.44 61.23 55.21 48.06 42.43 29.37 30.81 MCW [61] with LDAM loss* 25.10 20.00 17.77 15.63 12.60 10.29 60.47 55.92 50.84 47.62 42.00 Performance comparison of different competing methods in test accuracy (%) on CIFAR-10 and CIFAR-100 with symmetric and asymmetric noise. The average accuracy and standard deviation over 3 trials are reported.</figDesc><table><row><cell>LDAM loss [81]*</cell><cell>-</cell><cell>26.65</cell><cell>-</cell><cell>-</cell><cell>13.04</cell><cell>-</cell><cell cols="2">60.40</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>43.09</cell><cell>-</cell></row><row><cell>L2RW [26]</cell><cell cols="3">33.49 25.84 21.07</cell><cell>16.90</cell><cell cols="9">14.81 10.75 66.62 59.77 55.56 48.36 46.27 35.89</cell></row><row><cell>MW-Net [9]</cell><cell cols="3">32.80 26.43 20.90</cell><cell>15.55</cell><cell>12.45</cell><cell>7.19</cell><cell cols="7">63.38 58.39 54.34 46.96 41.09 29.90</cell></row><row><cell>MCW [61] with CE loss*</cell><cell cols="3">29.34 23.59 19.49</cell><cell>13.54</cell><cell>11.15</cell><cell>7.21</cell><cell cols="6">60.69 56.65 51.47 44.38 40.42</cell><cell>-</cell></row><row><cell>CMW-Net with CE loss</cell><cell cols="3">27.80 21.15 17.26</cell><cell cols="2">12.45 10.97</cell><cell>8.30</cell><cell cols="7">60.85 -</cell></row><row><cell cols="8">CMW-Net with LDAM loss 59Datasets 25.57 19.95 17.66 13.08 11.42 7.04 Symmetric Noise Noise 0.2 0.4 0.6 0.8</cell><cell>0.2</cell><cell></cell><cell cols="3">Asymmetric Noise 0.4 0.6</cell><cell>0.8</cell></row><row><cell>CIFAR-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>.81 55.87 51.14 45.26 40.32 29.19</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 3</head><label>3</label><figDesc>Test accuracy (%) of all competing methods on CIFAR-10 and CIFAR-100 under different feature-dependent noise types and levels. The average accuracy and standard deviation over 3 trials are reported. 35%) 78.11 ? 0.74 80.98 ? 0.80 80.65 ? 0.39 82.20 ? 0.40 82.80 ? 0.27 82.27 ? 0.33 84.23 ? 0.17 Type-I (70%) 41.98 ? 1.96 41.52 ? 4.53 36.52 ? 1.62 38.85 ? 0.67 42.74 ? 2.14 42.23 ? 0.69 44.19 ? 0.69 Type-II (35%) 76.65 ? 0.57 80.74 ? 0.25 77.60 ? 0.88 81.28 ? 0.56 81.54 ? 0.47 81.69 ? 0.57 83.12 ? 0.40 Type-II (70%) 45.57 ? 1.12 81.08 ? 0.35 40.30 ? 1.46 42.15 ? 1.07 46.04 ? 2.20 46.30 ? 0.77 48.26 ? 0.88 Type-III (35%) 76.89 ? 0.79 76.89 ? 0.79 79.18 ? 0.61 81.57 ? 0.73 81.50 ? 0.50 81.52 ? 0.38 83.10 ? 0.34 Type-III (70%) 43.32 ? 1.00 44.47 ? 1.23 37.10 ? 0.59 42.43 ? 1.27 45.05 ? 1.13 43.76 ? 0.96 45.15 ? 0.91</figDesc><table><row><cell>Datasets</cell><cell>Noise</cell><cell>ERM</cell><cell>LRT [63]</cell><cell>GCE [6]</cell><cell>MW-Net [9]</cell><cell>PLC [83]</cell><cell>CMW-Net</cell><cell>CMW-Net-SL</cell></row><row><cell cols="2">CIFAR-10 Type-I (CIFAR-100 Type-I (35%) Type-I (70%) Type-II (35%) Type-II (70%)</cell><cell>57.68 ? 0.29 39.32 ? 0.43 57.83 ? 0.25 39.30 ? 0.32</cell><cell>56.74 ? 0.34 45.29 ? 0.43 57.25 ? 0.68 43.71 ? 0.51</cell><cell>58.37 ? 0.18 40.01 ? 0.71 58.11 ? 1.05 37.75 ? 0.46</cell><cell>62.10 ? 0.50 44.71 ? 0.49 63.78 ? 0.24 44.61 ? 0.41</cell><cell>60.01 ? 0.43 45.92 ? 0.61 63.68 ? 0.29 45.03 ? 0.50</cell><cell>62.43 ? 0.38 46.68 ? 0.64 64.08 ? 0.26 50.01 ? 0.51</cell><cell>64.01 ? 0.11 47.62 ? 0.44 64.13 ? 0.19 51.99 ? 0.35</cell></row><row><cell></cell><cell>Type-III (35%)</cell><cell>56.07 ? 0.79</cell><cell>56.57 ? 0.30</cell><cell>57.51 ? 1.16</cell><cell>62.53 ? 0.33</cell><cell>63.68 ? 0.29</cell><cell>63.21 ? 0.23</cell><cell>64.47 ? 0.15</cell></row><row><cell></cell><cell>Type-III (70%)</cell><cell>40.01 ? 0.18</cell><cell>44.41 ? 0.19</cell><cell>40.53 ? 0.60</cell><cell>45.17 ? 0.77</cell><cell>44.45 ? 0.62</cell><cell>47.38 ? 0.65</cell><cell>48.78 ? 0.62</cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">0 1 2 3 4 5 6 7 8 9 Corrupted label</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE 4</head><label>4</label><figDesc>Test accuracy (%) of all competing methods on CIFAR-10 and CIFAR-100 under different feature dependent (35%) and independent (30%) noise types and levels. The average accuracy and standard deviation over 3 trials are reported.Symmetric 75.26 ? 0.32 75.97 ? 0.27 78.08 ? 0.66 76.39 ? 0.42 79.04 ? 0.50 78.42 ? 0.47 82.00 ? 0.36 Type-I + Asymmetric 75.21 ? 0.64 76.96 ? 0.45 76.91 ? 0.56 76.54 ? 0.56 78.31 ? 0.41 77.14 ? 0.38 80.69 ? 0.47 Type-II + Symmetric 74.92 ? 0.63 75.94 ? 0.58 75.69 ? 0.21 76.57 ? 0.81 80.08 ? 0.37 76.77 ? 0.63 80.96 ? 0.23 Type-II + Asymmetric 74.28 ? 0.39 77.03 ? 0.62 75.30 ? 0.81 75.35 ? 0.40 77.63 ? 0.30 77.08 ? 0.52 80.94 ? 0.14 Type-III + Symmetric 74.00 ? 0.38 75.66 ? 0.57 77.00 ? 0.12 76.28 ? 0.82 80.06 ? 0.47 77.16 ? 0.30 81.58 ? 0.55 Type-III + Asymmetric 75.31 ? 0.34 77.19 ? 0.74 75.70 ? 0.91 75.82 ? 0.77 77.54 ? 0.70 76.49 ? 0.88 80.48 ? 0.48</figDesc><table><row><cell>Datasets</cell><cell>Noise</cell><cell>ERM</cell><cell>LRT [63]</cell><cell>GCE [6]</cell><cell>MW-Net [9]</cell><cell>PLC [83]</cell><cell>CMW-Net</cell><cell>CMW-Net-SL</cell></row><row><cell cols="2">CIFAR-10 Type-I + CIFAR-100 Type-I + Symmetric Type-I + Asymmetric Type-II + Symmetric Type-II + Asymmetric</cell><cell>48.86 ? 0.56 45.85 ? 0.93 49.32 ? 0.36 46.50 ? 0.95</cell><cell>45.66 ? 1.60 52.04 ? 0.15 43.86 ? 1.31 52.11 ? 0.46</cell><cell>52.90 ? 0.53 52.69 ? 1.14 53.61 ? 0.46 51.98 ? 0.37</cell><cell>57.70 ? 0.32 56.61 ? 0.71 54.08 ? 0.18 58.53 ? 0.45</cell><cell>60.09 ? 0.15 56.40 ? 0.34 60.01 ? 0.63 61.43 ? 0.33</cell><cell>59.17 ? 0.42 57.42 ? 0.81 59.16 ? 0.18 58.99 ? 0.91</cell><cell>60.87 ? 0.56 61.35 ? 0.52 61.00 ? 0.41 61.35 ? 0.57</cell></row><row><cell></cell><cell>Type-III + Symmetric</cell><cell>48.94 ? 0.61</cell><cell>42.79 ? 1.78</cell><cell>52.07 ? 0.35</cell><cell>55.29 ? 0.57</cell><cell>60.14 ? 0.97</cell><cell>58.48 ? 0.79</cell><cell>60.21 ? 0.48</cell></row><row><cell></cell><cell>Type-III + Asymmetric</cell><cell>45.70 ? 0.12</cell><cell>50.31 ? 0.39</cell><cell>50.87 ? 1.12</cell><cell>58.43 ? 0.60</cell><cell>54.56 ? 1.11</cell><cell>58.83 ? 0.57</cell><cell>60.52 ? 0.53</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>TABLE 5</head><label>5</label><figDesc>Comparison of different competing methods on Animal-10N dataset. Results for baseline methods are copied from<ref type="bibr" target="#b82">[83]</ref> </figDesc><table><row><cell>Method</cell><cell>Test Accuracy</cell><cell>Method</cell><cell>Test Accuracy</cell></row><row><cell>ERM</cell><cell>79.4 ? 0.14</cell><cell>ActiveBias [85]</cell><cell>80.5 ? 0.26</cell></row><row><cell>Co-teaching [86]</cell><cell>80.2 ? 0.13</cell><cell>SELFIE [78]</cell><cell>81.8 ? 0.09</cell></row><row><cell>PLC [83]</cell><cell>83.4 ? 0.43</cell><cell>MW-Net [9]</cell><cell>80.7 ? 0.52</cell></row><row><cell>CMW-Net</cell><cell>80.9 ? 0.48</cell><cell>CMW-Net-SL</cell><cell>84.7 ? 0.28</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>TABLE 6</head><label>6</label><figDesc>Comparison of different competing methods on mini WebVision dataset. Results for baseline methods are copied from<ref type="bibr" target="#b7">[8]</ref>. * denotes results trained with Inception-ResNet-v2.</figDesc><table><row><cell>Methods</cell><cell>WebVision top1 top5</cell><cell>ILSVRC12 top1 top5</cell></row><row><cell>Forward* [70]</cell><cell cols="2">61.12 82.68 57.36 82.36</cell></row><row><cell>MentorNet* [37]</cell><cell cols="2">63.00 81.40 57.80 79.92</cell></row><row><cell>Co-teaching* [86]</cell><cell cols="2">63.58 85.20 61.48 84.70</cell></row><row><cell>Interative-CV* [87]</cell><cell cols="2">65.24 85.34 61.60 84.98</cell></row><row><cell>MW-Net [9]</cell><cell cols="2">69.34 87.44 65.80 87.52</cell></row><row><cell>CMW-Net</cell><cell cols="2">70.56 88.76 66.44 87.68</cell></row><row><cell>DivideMix* [8]</cell><cell cols="2">77.32 91.64 75.20 90.84</cell></row><row><cell>ELR* [79]</cell><cell cols="2">77.78 91.68 70.29 89.76</cell></row><row><cell>DivideMix [8]</cell><cell cols="2">76.32 90.65 74.42 91.21</cell></row><row><cell>CMW-Net-SL</cell><cell cols="2">78.08 92.96 75.72 92.52</cell></row><row><cell cols="3">DivideMix with C2D [88] 79.42 92.32 78.57 93.04</cell></row><row><cell>CMW-Net-SL+C2D</cell><cell cols="2">80.44 93.36 77.36 93.48</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>compare the test performance of all competing methods trained on the Animal-10N and Typical noisy labeled samples corrected by our method from Animal-10N<ref type="bibr" target="#b77">[78]</ref>. The original training label is cat.</figDesc><table><row><cell>lynx</cell><cell>lynx</cell><cell>lynx</cell><cell>lynx</cell><cell>lynx</cell><cell>lynx</cell><cell>lynx</cell><cell>lynx</cell></row><row><cell>(a) cat</cell><cell>cat</cell><cell>cat</cell><cell>cat</cell><cell>cat</cell><cell>cat</cell><cell>cat</cell><cell>cat</cell></row><row><cell cols="7">(b) Typical noisy labeled samples corrected by our method from Animal-10N [78]. The original training label is lynx.</cell><cell></cell></row><row><cell>tree frog</cell><cell>tree frog</cell><cell>bullfrog</cell><cell>tree frog</cell><cell>bullfrog</cell><cell>bullfrog</cell><cell>mud turtle</cell><cell>axolotl</cell></row></table><note>(c) Typical noisy labeled samples corrected by our method from mini-WebVision [14]. The original training label is tailed frog.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>TABLE 7 performance77.41 76.48 79.70 77.86 mini</head><label>7</label><figDesc>comparison of classification accuracy (%) on WebFG-496. WebVision datasets, respectively. For the Animal-10N dataset, we compare 4 methods that have reported performance on this dataset. Compared with sample selection methods ActiveBias<ref type="bibr" target="#b84">[85]</ref> and Co-teaching<ref type="bibr" target="#b85">[86]</ref>, our CMW-Net attains better performance, showing its better screening capability for useful samples. Under soft-label amelioration, our method achieves a further performance gain over recent label correction methods SELFIE</figDesc><table><row><cell>Methods</cell><cell cols="4">Web-Bird Web-Aircraft Web-Car Average</cell></row><row><cell>ERM</cell><cell>66.56</cell><cell>64.33</cell><cell>67.42</cell><cell>66.10</cell></row><row><cell>Decoupling [90]</cell><cell>70.56</cell><cell>75.97</cell><cell>75.00</cell><cell>73.84</cell></row><row><cell>Co-teaching [86]</cell><cell>73.85</cell><cell>72.76</cell><cell>73.10</cell><cell>73.24</cell></row><row><cell>Peer-learning [45]</cell><cell>76.48</cell><cell>74.38</cell><cell>78.52</cell><cell>76.46</cell></row><row><cell>MW-Net</cell><cell>75.60</cell><cell>72.93</cell><cell>77.33</cell><cell>75.29</cell></row><row><cell>CMW-Net</cell><cell>75.72</cell><cell>73.72</cell><cell>77.42</cell><cell>75.62</cell></row><row><cell>CMW-Net-SL</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>TABLE 8</head><label>8</label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>TABLE 9</head><label>9</label><figDesc>Validation accuracy of different competing methods by using InceptionResNet-v2 as the classifier on full WebVision validation set.Results for baselines are copied from<ref type="bibr" target="#b91">[92]</ref>.</figDesc><table><row><cell></cell><cell cols="2">Methods</cell><cell cols="3">top1 top5</cell><cell>Methods</cell><cell>top1 top5</cell></row><row><cell></cell><cell></cell><cell>ERM</cell><cell>69.7</cell><cell cols="2">87.0</cell><cell>MentorMix [93]</cell><cell>74.3</cell><cell>90.5</cell></row><row><cell></cell><cell cols="2">MentorNet [37]</cell><cell>70.8</cell><cell cols="2">88.0</cell><cell>HAR [92]</cell><cell>75.0</cell><cell>90.6</cell></row><row><cell cols="3">Curriculumnet [16]</cell><cell>72.1</cell><cell cols="2">89.2</cell><cell>ERM + CMW-Net</cell><cell>75.4</cell><cell>91.5</cell></row><row><cell>Test accuracy (\%)</cell><cell>78 80 82 84 86 88 90</cell><cell cols="3">PRODEN PRODEN+CMW-Net</cell><cell>Test accuracy (\%)</cell><cell>48 50 52 54 56 58 60 62</cell><cell>PRODEN PRODEN+CMW-Net</cell></row><row><cell></cell><cell>76</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>46</cell></row><row><cell></cell><cell>0.1</cell><cell cols="2">0.3 Flipping probability 0.5</cell><cell>0.7</cell><cell></cell><cell>0.03</cell><cell>0.05 Flipping probability 0.07</cell><cell>0.10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>TABLE 10</head><label>10</label><figDesc>Performance comparison of Fixmatch w/o CMW-Net on CIFAR-10, CIFAR-100 and ImageNet datasets in test error over 3 trials. The baselines results</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>RA)<ref type="bibr" target="#b46">[47]</ref> 13.81 ? 3.<ref type="bibr" target="#b36">37</ref> 5.07 ? 0.65 4.26 ? 0.05 48.85 ? 1.<ref type="bibr" target="#b74">75</ref> 28.29 ? 0.11 22.60 ? 0.12</figDesc><table><row><cell></cell><cell></cell><cell>-10</cell><cell></cell><cell></cell><cell>CIFAR-100</cell><cell></cell><cell cols="2">ImageNet (10% labels)</cell></row><row><cell>Method</cell><cell>40 labels</cell><cell>250 labels</cell><cell>4000 labels</cell><cell>400 labels</cell><cell>2500 labels</cell><cell>10000 labels</cell><cell>top-1</cell><cell>top5</cell></row><row><cell cols="8">FixMatch (32.9</cell><cell>13.3</cell></row><row><cell>FixMatch (RA) + CMW-Net</cell><cell>9.60 ? 0.62</cell><cell>4.73</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>? 0.15 4.25 ? 0.03 47.70 ? 1.14 27.43 ? 0.12 22.55 ? 0.09 30.8 11.3</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>3% 96.7% 0.0% 0.1% 0.0% 0.0% 0.1% 0.0% 0.6% 2.2% 3.0% 0.0% 86.8% 2.5% 2.0% 1.7% 2.5% 1.0% 0.3% 0.2% 1.0% 0.1% 2.2% 82.7% 2.1% 8.3% 1.9% 0.9% 0.4% 0.4% 0.3% 0.1% 1.1% 1.7% 93.8% 1.1% 1.1% 0.7% 0.1% 0.0% 0.4% 0.0% 0.6% 9.6% 1.8% 85.4% 0.7% 1.3% 0.1% 0.1% 0.5% 0.1% 1.5% 1.7% 0.5% 0.6% 94.7% 0.2% 0.1% 0.1% 0.7% 0.0% 0.7% 1.2% 1.3% 1.7% 0.1% 94.3% 0.0% 0.0% 2.6% 0.8% 0.4% 0.5% 0.1% 0.0% 0.2% 0.0% 94.6% 0.8% 2% 97.4% 0.0% 0.1% 0.0% 0.0% 0.1% 0.0% 0.4% 1.8% 2.6% 0.0% 89.0% 1.7% 1.5% 1.6% 2.3% 1.0% 0.2% 0.1% 1.1% 0.1% 2.5% 80.9% 2.1% 9.2% 2.4% 0.9% 0.4% 0.4% 0.3% 0.2% 1.5% 1.7% 92.9% 1.1% 1.4% 0.7% 0.2% 0.0% 0.2% 0.1% 0.9% 8.5% 1.7% 86.7% 0.6% 1.1% 0.1% 0.1% 0.5% 0.1% 1.9% 1.4% 0.3% 0.7% 94.7% 0.2% 0.1% 0.1% 0.8% 0.0% 0.7% 1.2% 1.2% 1.8% 0.1% 94.2% 0.0% 0.0% 2.6% 0.8% 0.5% 0.5% 0.1% 0.0% 0.2% 0.0% 94.3% 1.0% 5% 98.3% 0.0% 0.1% 0.0% 0.0% 0.1% 0.0% 0.3% 0.7% 3.8% 0.2% 87.3% 2.0% 2.7% 1.2% 2.1% 0.4% 0.1% 0.2% 2.6% 0.1% 3.9% 80.8% 2.1% 6.5% 3.0% 0.6% 0.2% 0.2% 0.9% 0.1% 2.8% 3.5% 88.9% 0.8% 1.6% 1.4% 0.0% 0.0% 0.9% 0.1% 3.0% 13.0% 2.5% 78.3% 0.6% 1.5% 0.1% 0.0% 0.7% 0.4% 3.3% 4.1% 0.9% 0.4% 90.0% 0.1% 0.1% 0.0% 2.2% 0.0% 2.1% 3.8% 3.7% 2.9% 0.2% 84.8% 0.1% 0.2% 8.6% 2.6% 0.8% 0.9% 0.1% 0.1% 0.2% 0.0% 86.0% 0.7% 4% 95.2% 0.0% 0.4% 0.1% 0.1% 0.3% 0.0% 0.7% 2.8% 2.2% 0.0% 87.3% 1.7% 2.5% 2.2% 2.8% 0.9% 0.1% 0.3% 1.0% 0.0% 3.4% 76.0% 2.1% 10.9% 4.2% 1.3% 0.4% 0.7% 0.1% 0.1% 2.3% 2.5% 88.1% 2.1% 2.6% 2.1% 0.1% 0.0% 0.2% 0.1% 2.4% 6.8% 1.8% 85.8% 0.9% 1.9% 0.1% 0.0% 0.1% 0.1% 2.1% 2.2% 0.6% 0.8% 93.5% 0.4% 0.2% 0.0% 0.9% 0.0% 1.2% 2.3% 3.2% 4.0% 0.3% 87.6% 0.2% 0.3% 4.1% 1.3% 0.9% 0.9% 0.0% 0.2% 0.3% 0.1% 91.1% 1.1%</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>MW-Net</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ours</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MW-Net</cell><cell></cell><cell></cell><cell>Ours</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>94.5% 0.4% 1.3% 0.8% 0.1% 0.1% 0.3% 0.4% 1.4% 0.7%</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell>93.5% 0.6% 1.3% 0.8% 0.1% 0.1% 0.5% 0.4% 1.8% 0.9%</cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell>96.3% 0.7% 1.5% 0.3% 0.2% 0.0% 0.1% 0.1% 0.6% 0.2%</cell><cell></cell><cell></cell><cell>0</cell><cell>89.1% 0.5% 3.1% 1.1% 0.7% 0.4% 1.2% 0.5% 1.9% 1.5%</cell></row><row><cell cols="2">True label</cell><cell>1 2 3 4 5 6 7 8 9</cell><cell>1 2 3 4 5 6 7 8 9 Predicted label 0.1.2% 3.1% 0.2% 0.4% 0.0% 0.0% 0.0% 0.0% 1.1% 94.0%</cell><cell>0 20 40 60 80</cell><cell cols="2">True label</cell><cell>1 2 3 4 5 6 7 8 9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 0.0.9% 3.8% 0.2% 0.5% 0.0% 0.0% 0.0% 0.1% 1.1% 93.4%</cell><cell>0 20 40 60 80</cell><cell cols="2">True label</cell><cell>1 2 3 4 5 6 7 8 9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 0.2.6% 11.7% 0.2% 0.6% 0.0% 0.1% 0.1% 0.0% 1.7% 83.0%</cell><cell>0 20 40 60 80</cell><cell cols="2">True label</cell><cell>1 2 3 4 5 6 7 8 9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 0.1.0% 4.9% 0.2% 0.8% 0.0% 0.2% 0.3% 0.1% 1.6% 90.9%</cell><cell>0 20 40 60 80</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">(a) 1 for CIFAR-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(b) 10 for CIFAR-10</cell></row><row><cell></cell><cell></cell><cell></cell><cell>MW-Net</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ours</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MW-Net</cell><cell></cell><cell></cell><cell>Ours</cell></row><row><cell></cell><cell></cell><cell>0 1 2</cell><cell>96.7% 0.8% 0.9% 0.4% 0.2% 0.0% 0.0% 0.3% 0.6% 0.1% 0.6% 98.0% 0.0% 0.1% 0.1% 0.0% 0.0% 0.0% 0.1% 1.1% 4.6% 0.0% 86.5% 2.5% 2.8% 1.4% 1.8% 0.3% 0.1% 0.0%</cell><cell>80</cell><cell></cell><cell></cell><cell>0 1 2</cell><cell>90.1% 0.6% 2.8% 0.9% 0.4% 0.3% 0.7% 0.7% 2.7% 0.8% 0.7% 93.8% 0.0% 0.2% 0.1% 0.0% 0.3% 0.2% 0.9% 3.8% 2.7% 0.0% 86.8% 1.9% 2.1% 2.7% 2.9% 0.7% 0.1% 0.1%</cell><cell>80</cell><cell></cell><cell></cell><cell>0 1 2</cell><cell>97.0% 1.4% 0.8% 0.3% 0.1% 0.0% 0.0% 0.2% 0.1% 0.1% 0.9% 98.5% 0.0% 0.1% 0.0% 0.0% 0.0% 0.0% 0.1% 0.4% 5.8% 0.2% 85.3% 2.8% 2.0% 2.1% 1.4% 0.3% 0.0% 0.1%</cell><cell>80</cell><cell></cell><cell>0 2 1</cell><cell>92.6% 1.2% 0.8% 1.9% 0.6% 0.4% 0.2% 0.4% 1.3% 0.6% 4.6% 0.2% 76.3% 8.3% 3.3% 3.5% 3.1% 0.6% 0.1% 0.0% 0.6% 97.7% 0.0% 0.4% 0.0% 0.0% 0.0% 0.1% 0.4% 0.8%</cell><cell>80</cell></row><row><cell cols="2">True label</cell><cell>3 4 5 6</cell><cell>2.7% 0.5% 3.4% 80.6% 2.5% 6.8% 2.1% 1.0% 0.2% 0.2% 1.9% 0.1% 3.3% 3.7% 87.5% 1.2% 0.7% 1.5% 0.1% 0.0% 1.7% 0.3% 1.8% 14.8% 2.1% 77.5% 0.4% 1.2% 0.2% 0.0% 1.8% 0.5% 3.6% 5.2% 1.3% 0.8% 86.4% 0.2% 0.2% 0.0%</cell><cell>40 60</cell><cell cols="2">True label</cell><cell>3 4 5 6</cell><cell>1.2% 0.1% 3.3% 75.6% 2.2% 11.7% 3.6% 1.6% 0.3% 0.4% 0.6% 0.0% 4.4% 3.1% 83.7% 3.0% 2.3% 2.7% 0.2% 0.0% 0.9% 0.0% 1.2% 8.6% 1.6% 85.2% 0.7% 1.6% 0.2% 0.0% 0.4% 0.2% 2.3% 3.2% 0.4% 1.4% 91.7% 0.3% 0.1% 0.0%</cell><cell>40 60</cell><cell cols="2">True label</cell><cell>3 4 5 6</cell><cell>2.8% 0.8% 5.3% 77.8% 2.2% 7.9% 2.0% 0.8% 0.2% 0.2% 2.6% 0.2% 5.9% 5.5% 81.6% 1.9% 1.0% 1.3% 0.0% 0.0% 2.1% 0.2% 5.4% 17.9% 2.0% 70.2% 0.8% 1.3% 0.0% 0.1% 2.5% 1.2% 6.4% 6.1% 2.0% 1.3% 80.3% 0.0% 0.1% 0.1%</cell><cell>40 60</cell><cell cols="2">True label</cell><cell>3 4 5 6</cell><cell>1.1% 0.1% 2.7% 6.0% 84.2% 2.2% 1.9% 1.6% 0.2% 0.0% 0.5% 0.0% 1.2% 21.2% 2.1% 72.8% 1.0% 1.1% 0.0% 0.1% 1.0% 0.4% 2.1% 7.0% 2.1% 1.5% 85.6% 0.0% 0.2% 0.1% 1.0% 0.2% 1.5% 82.6% 2.4% 8.8% 2.2% 0.8% 0.3% 0.2%</cell><cell>40 60</cell></row><row><cell></cell><cell></cell><cell>7 8</cell><cell>4.2% 0.2% 1.4% 5.5% 4.3% 3.0% 0.1% 81.1% 0.1% 0.1% 16.6% 3.6% 0.7% 1.0% 0.1% 0.4% 0.1% 0.1% 76.8% 0.6%</cell><cell>20</cell><cell></cell><cell></cell><cell>7 8</cell><cell>1.0% 0.0% 1.6% 2.7% 2.5% 3.7% 0.3% 88.0% 0.1% 0.1% 4.2% 0.9% 0.9% 0.9% 0.0% 0.5% 0.2% 0.2% 91.3% 0.9%</cell><cell>20</cell><cell></cell><cell></cell><cell>7 8</cell><cell>4.7% 0.4% 2.8% 7.6% 5.1% 3.8% 0.2% 75.4% 0.0% 0.0% 25.4% 6.3% 1.2% 1.4% 0.2% 0.2% 0.0% 0.3% 64.3% 0.7%</cell><cell>20</cell><cell></cell><cell>7 8</cell><cell>1.4% 0.0% 1.0% 9.4% 5.7% 4.9% 0.2% 77.0% 0.1% 0.3% 9.6% 3.8% 0.8% 1.8% 0.4% 0.2% 0.1% 0.4% 82.0% 0.9%</cell><cell>20</cell></row><row><cell></cell><cell></cell><cell>9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 6.8% 12.8% 0.1% 1.1% 0.0% 0.1% 0.2% 0.2% 0.4% 78.3%</cell><cell>0</cell><cell></cell><cell></cell><cell>9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 2.3% 4.3% 0.4% 0.7% 0.0% 0.2% 0.3% 0.2% 2.3% 89.3%</cell><cell>0</cell><cell></cell><cell></cell><cell>9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 9.8% 21.8% 0.5% 1.1% 0.1% 0.2% 0.0% 0.1% 1.5% 64.9%</cell><cell>0</cell><cell></cell><cell>9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 4.4% 12.9% 0.1% 2.2% 0.1% 0.3% 0.3% 0.1% 3.0% 76.6%</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">(c) 20 for CIFAR-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(d) 50 for CIFAR-10</cell></row><row><cell></cell><cell></cell><cell></cell><cell>MW-Net</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ours</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MW-Net</cell><cell></cell><cell></cell><cell>Ours</cell></row><row><cell></cell><cell cols="2">0</cell><cell>97.7% 0.9% 0.6% 0.3% 0.1% 0.1% 0.1% 0.0% 0.2% 0.0%</cell><cell></cell><cell></cell><cell cols="2">0</cell><cell>94.0% 1.0% 1.2% 1.1% 0.5% 0.1% 0.4% 0.3% 1.0% 0.4%</cell><cell></cell><cell></cell><cell cols="2">0</cell><cell>97.9% 0.5% 0.8% 0.2% 0.2% 0.1% 0.0% 0.0% 0.2% 0.1%</cell><cell></cell><cell></cell><cell>0</cell><cell>93.3% 1.5% 1.7% 1.8% 0.3% 0.1% 0.2% 0.1% 0.6% 0.4%</cell></row><row><cell></cell><cell cols="2">1 2</cell><cell>1.2% 98.5% 0.0% 0.1% 0.0% 0.0% 0.0% 0.0% 0.0% 0.2% 6.2% 0.0% 85.6% 4.0% 1.7% 0.9% 1.2% 0.4% 0.0% 0.0%</cell><cell>80</cell><cell></cell><cell cols="2">1 2</cell><cell>0.7% 98.2% 0.0% 0.3% 0.1% 0.1% 0.1% 0.0% 0.0% 0.5% 4.6% 0.0% 79.8% 6.9% 3.5% 1.7% 2.8% 0.7% 0.0% 0.0%</cell><cell>80</cell><cell></cell><cell cols="2">1 2</cell><cell>1.0% 98.5% 0.0% 0.3% 0.0% 0.0% 0.2% 0.0% 0.0% 0.0% 8.6% 0.2% 83.7% 2.8% 2.2% 1.3% 0.9% 0.2% 0.1% 0.0%</cell><cell>80</cell><cell></cell><cell>1 2</cell><cell>5.3% 0.2% 77.3% 7.8% 4.0% 2.8% 1.9% 0.6% 0.1% 0.0% 0.3% 99.1% 0.0% 0.3% 0.0% 0.0% 0.2% 0.0% 0.1% 0.0%</cell><cell>80</cell></row><row><cell>True label</cell><cell cols="2">3 4 5 6</cell><cell>4.4% 0.9% 5.2% 80.1% 2.4% 5.2% 1.2% 0.3% 0.2% 0.1% 3.3% 0.0% 5.9% 5.6% 81.1% 1.1% 1.0% 2.0% 0.0% 0.0% 2.5% 0.1% 7.6% 24.3% 2.4% 60.9% 0.8% 1.4% 0.0% 0.0% 3.1% 1.0% 8.6% 9.2% 1.4% 1.7% 74.3% 0.4% 0.1% 0.2%</cell><cell>40 60</cell><cell>True label</cell><cell cols="2">3 4 5 6</cell><cell>2.1% 0.4% 2.4% 83.5% 3.0% 6.2% 1.4% 0.6% 0.2% 0.2% 1.5% 0.1% 3.1% 5.4% 85.7% 1.6% 1.0% 1.6% 0.0% 0.0% 0.6% 0.1% 2.9% 25.6% 2.6% 65.6% 0.8% 1.8% 0.0% 0.0% 1.6% 0.4% 4.1% 10.1% 2.2% 2.4% 78.1% 0.6% 0.1% 0.4%</cell><cell>40 60</cell><cell>True label</cell><cell cols="2">3 4 5 6</cell><cell>7.2% 0.8% 7.3% 76.1% 2.0% 5.2% 1.1% 0.2% 0.1% 0.0% 4.3% 0.2% 8.9% 5.6% 76.7% 2.0% 0.8% 1.5% 0.0% 0.0% 3.3% 0.4% 7.9% 26.9% 2.8% 56.7% 0.4% 1.6% 0.0% 0.0% 5.7% 0.6% 11.3% 8.8% 2.1% 1.5% 69.7% 0.2% 0.0% 0.1%</cell><cell>40 60</cell><cell>True label</cell><cell>3 4 5 6</cell><cell>1.7% 0.1% 2.8% 7.8% 80.5% 3.5% 1.3% 2.2% 0.1% 0.0% 0.8% 0.4% 2.0% 29.4% 2.8% 62.5% 0.6% 1.5% 0.0% 0.0% 1.8% 0.8% 4.7% 11.9% 2.6% 2.8% 74.8% 0.3% 0.1% 0.2% 1.7% 0.6% 2.5% 84.0% 2.3% 6.7% 1.6% 0.4% 0.2% 0.0%</cell><cell>40 60</cell></row><row><cell></cell><cell cols="2">7 8</cell><cell>7.1% 0.3% 3.9% 11.0% 8.5% 4.4% 0.0% 64.8% 0.0% 0.0% 35.2% 8.0% 1.2% 1.9% 0.2% 0.2% 0.1% 0.2% 52.7% 0.3%</cell><cell>20</cell><cell></cell><cell cols="2">7 8</cell><cell>2.7% 0.2% 1.3% 11.9% 8.3% 4.8% 0.0% 70.7% 0.0% 0.1% 18.2% 6.4% 1.0% 2.8% 0.7% 0.7% 0.3% 0.3% 68.8% 0.8%</cell><cell>20</cell><cell></cell><cell cols="2">7 8</cell><cell>10.6% 0.3% 7.2% 10.8% 9.7% 5.9% 0.3% 55.0% 0.1% 0.1% 51.8% 7.5% 1.5% 1.4% 0.3% 0.2% 0.1% 0.1% 37.0% 0.1%</cell><cell>20</cell><cell></cell><cell>7 8</cell><cell>3.5% 0.2% 3.5% 15.2% 10.1% 8.3% 0.3% 58.7% 0.1% 0.1% 29.2% 9.3% 1.3% 3.8% 0.7% 0.4% 0.3% 0.3% 54.1% 0.6%</cell><cell>20</cell></row><row><cell></cell><cell cols="2">9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 15.2% 36.1% 0.2% 1.7% 0.1% 0.0% 0.1% 0.1% 1.4% 45.1%</cell><cell>0</cell><cell></cell><cell cols="2">9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 6.5% 23.7% 0.2% 2.6% 0.1% 0.0% 0.2% 0.3% 2.3% 64.1%</cell><cell>0</cell><cell></cell><cell cols="2">9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 24.1% 45.8% 0.4% 1.7% 0.2% 0.3% 0.3% 0.3% 1.6% 25.3%</cell><cell>0</cell><cell></cell><cell>9</cell><cell>0 1 2 3 4 5 6 7 8 9 Predicted label 11.4% 44.9% 0.4% 3.4% 0.4% 0.7% 0.4% 0.5% 2.5% 35.4%</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">(e) 100 for CIFAR-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(f) 200 for CIFAR-10</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>224% 81.354% 1.827% 2.284% 2.204% 1.827% 1.847% 2.164% 2.025% 2.244% 1.819% 2.019% 82.371% 1.759% 2.319% 1.999% 1.699% 2.059% 1.879% 2.079% 1.988% 1.908% 2.008% 82.309% 2.209% 2.088% 1.787% 2.108% 1.847% 1.747% 2.086% 1.745% 1.685% 2.247% 81.906% 2.187% 2.006% 2.166% 1.825% 2.146% 2.181% 2.161% 2.062% 2.161% 2.121% 81.007% 2.28% 2.022% 1.963% 2.042% 2.038% 1.917% 2.32% 1.695% 1.877% 1.977% 82.97% 1.816% 1.634% 1.755% 2.116% 2.036% 1.996% 1.916% 1.876% 1.956% 2.056% 81.976% 1.816% 2.255% 1.915% 2.255% 1.536% 2.015% 1.915% 2.255% 1.895% 1.596% 82.821% 1.796% 08% 99.02% 0.0% 0.0% 0.0% 0.0% 0.04% 0.0% 0.18% 0.68% 0.245% 0.0% 97.92% 0.571% 0.306% 0.286% 0.408% 0.122% 0.082% 0.061% 0.139% 0.1% 0.697% 95.437% 0.299% 2.451% 0.299% 0.498% 0.04% 0.04% 0.079% 0.0% 0.337% 0.694% 97.739% 0.635% 0.159% 0.337% 0.0% 0.02% 0.02% 0.06% 0.503% 2.033% 0.201% 96.397% 0.161% 0.564% 0.02% 0.04% 0.06% 0.02% 0.479% 0.538% 0.199% 0.1% 98.504% 0.02% 0.0% 0.08% 0.04% 0.02% 0.1% 0.161% 0.281% 0.643% 0.04% 98.694% 0.0% 0.02% 0.28% 0.1% 0.08% 0.06% 0.04% 0.02% 0.06% 0.0% 99.14% 0.22% 205% 63.789% 3.862% 3.72% 3.882% 4.327% 4.266% 3.558% 3.922% 4.468% 3.899% 3.879% 63.627% 3.939% 4.239% 4.239% 3.979% 3.939% 3.899% 4.359% 3.789% 4.287% 3.968% 64.766% 3.888% 3.589% 3.789% 4.167% 3.789% 3.968% 4.505% 4.165% 3.744% 4.085% 63.556% 3.604% 3.744% 4.305% 4.245% 4.045% 3.915% 3.62% 4.249% 4.053% 4.053% 63.447% 3.856% 4.505% 3.895% 4.407% 3.888% 4.148% 4.566% 3.569% 3.908% 3.868% 64.865% 3.629% 3.629% 3.928% 3.966% 3.885% 4.573% 3.784% 4.411% 4.168% 3.521% 64.427% 3.662% 3.602% 3.767% 4.163% 3.925% 3.866% 3.886% 3.707% 4.441% 4.183% 64.75% 3.311% 1% 98.658% 0.0% 0.02% 0.0% 0.02% 0.0% 0.0% 0.2% 1.001% 0.452% 0.0% 96.219% 0.986% 0.637% 0.514% 0.616% 0.308% 0.185% 0.082% 0.218% 0.02% 1.01% 91.86% 0.871% 4.496% 0.574% 0.871% 0.04% 0.04% 0.059% 0.0% 0.674% 0.911% 96.097% 1.189% 0.198% 0.832% 0.02% 0.02% 0.123% 0.061% 0.716% 3.539% 0.43% 94.108% 0.307% 0.573% 0.082% 0.061%0.059% 0.079% 1.011% 0.852% 0.456% 0.198% 97.165% 0.059% 0.02% 0.099% 0.02% 0.02% 0.301% 0.321% 0.362% 1.346% 0.06% 97.51% 0.04% 0.02% 0.619% 0.18% 0.14% 0.08% 0.0% 0.02% 0.04% 0.06% 98.442% 0.419%</figDesc><table><row><cell></cell><cell>0</cell><cell>81.611% 2.119% 2.319% 1.899% 1.979% 1.959% 2.139% 1.919% 1.919% 2.139% wo/ soft labels</cell><cell>80</cell><cell></cell><cell>0</cell><cell>97.096% 0.177% 1.688% 0.157% 0.118% 0.059% 0.02% 0.177% 0.392% 0.118% w/ soft labels</cell><cell></cell><cell></cell><cell>0</cell><cell>63.723% 4.356% 3.719% 3.878% 4.336% 4.435% 3.679% 3.938% 3.779% 4.157% wo/ soft labels</cell><cell>60</cell><cell></cell><cell>0</cell><cell>95.117% 0.252% 2.306% 0.484% 0.233% 0.155% 0.174% 0.174% 0.62% 0.484% w/ soft labels</cell><cell></cell></row><row><cell>True label</cell><cell>1 2 3 4 5 6 7 8 9</cell><cell>1 2 3 4 5 6 7 8 9 Corrupted label 2.1.971% 1.911% 1.831% 2.032% 1.831% 2.052% 2.032% 2.012% 2.072% 82.257%</cell><cell>10 20 30 40 50 60 70</cell><cell>True label</cell><cell>1 2 3 4 5 6 7 8 9</cell><cell>0 1 2 3 4 5 6 7 8 9 Corrected label 0.0.1% 0.462% 0.06% 0.0% 0.0% 0.02% 0.02% 0.04% 0.1% 99.196%</cell><cell>0 20 40 60 80</cell><cell>True label</cell><cell>1 2 3 4 5 6 7 8 9</cell><cell>0 1 2 3 4 5 6 7 8 9 Corrupted label 4.4.015% 4.359% 3.751% 4.157% 3.913% 3.629% 3.67% 4.035% 3.893% 64.578%</cell><cell>10 20 30 40 50</cell><cell>True label</cell><cell>1 2 3 4 5 6 7 8 9</cell><cell>0 1 2 3 4 5 6 7 8 9 Corrected label 0.0.181% 0.866% 0.101% 0.121% 0.0% 0.02% 0.02% 0.02% 0.201% 98.469%</cell><cell>0 20 40 60 80</cell></row><row><cell></cell><cell></cell><cell cols="5">(a) Symmetry Noise (20%)</cell><cell></cell><cell></cell><cell></cell><cell cols="5">(b) Symmetry Noise (40%)</cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0 1 2 3 4 5 6 7 8 9 Corrupted label</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>TABLE 11</head><label>11</label><figDesc>Test accuracy (%) of all comparison methods under open-set noise on CIFAR-10. 17?0.80 84.63?0.80 85.96 ? 0.72 89.71 ? 0.53 90.16?0.40 83.60?0.24 84.78 ? 0.51 84.81 ? 0.51 92.12 ? 0.18 accurate representation directly from datasets with open-set noisy labels. Such capability supports that our method can be applied to learning from web-search data possibly containing such type of open-set noisy labels, e.g., WebVision</figDesc><table><row><cell>Methods</cell><cell>ERM</cell><cell>Forward [70] GCE [6] M-correction [7] DivideMix [8] L2RW [26] MW-Net [9] CMW-Net CMW-Net-SL</cell></row><row><cell cols="2">Accuracy 84.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head></head><label></label><figDesc>Fig. 14.Confusion matrices obtained by CMW-Net without (left) or with (right) soft label amelioration on CIFAR-10 with asymmetry noise with varying noise rates ranging from 20% to 80%.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>97</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>66</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>92.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>96</cell><cell></cell><cell></cell><cell>75</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Test Accuracy (\%)</cell><cell>90.5 91.0 91.5 92.0</cell><cell>1</cell><cell cols="2">2 The Number of Meta-Classes 3 4 5 CIFAR-10 10</cell><cell></cell><cell></cell><cell></cell><cell>Test Accuracy (\%)</cell><cell>58 60 62 64</cell><cell>1</cell><cell>2</cell><cell>3 The Number of Meta-Classes 4 5 CIFAR-100</cell><cell>10</cell><cell>100</cell><cell>Test Accuracy (\%)</cell><cell>91 92 93 94 95</cell><cell></cell><cell cols="2">20%</cell><cell>40% w/ clean meta data 60% Noise Rate wo/ clean meta data</cell><cell>80%</cell><cell>55 60 65 70</cell><cell>20%</cell><cell>40%</cell><cell>Noise Rate</cell><cell>60%</cell><cell>80%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="10">(a) On different numbers of meta-classes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0</cell><cell cols="4">83.264% 0.0% 16.736% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% wo/ soft labels</cell><cell>100</cell><cell></cell><cell></cell><cell>0</cell><cell cols="5">98.687% 0.08% 0.955% 0.08% 0.02% 0.06% 0.0% 0.06% 0.0% 0.06% w/ soft labels</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0</cell><cell>71.327% 0.0% 28.673% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% wo/ soft labels</cell><cell>100</cell><cell>0</cell><cell>97.435% 0.079% 1.854% 0.118% 0.099% 0.099% 0.0% 0.118% 0.0% 0.197% w/ soft labels</cell></row><row><cell></cell><cell></cell><cell>1 2</cell><cell cols="4">0.0% 83.056% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 16.944% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0%</cell><cell>80</cell><cell></cell><cell></cell><cell>1 2</cell><cell cols="5">0.059% 98.691% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 1.249% 0.182% 0.0% 99.151% 0.243% 0.101% 0.182% 0.0% 0.141% 0.0% 0.0%</cell><cell cols="2">80</cell><cell></cell><cell></cell><cell></cell><cell>1 2</cell><cell>0.0% 71.347% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 28.653% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0%</cell><cell>80</cell><cell>1 2</cell><cell>0.205% 0.02% 98.628% 0.41% 0.225% 0.307% 0.0% 0.184% 0.0% 0.02% 0.119% 98.143% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 1.738%</cell><cell>80</cell></row><row><cell cols="2">True label</cell><cell>3 4 5 6</cell><cell cols="4">0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 16.736% 0.0% 83.264% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0%</cell><cell>40 60</cell><cell cols="2">True label</cell><cell>3 4 5 6</cell><cell cols="5">0.102% 0.0% 0.287% 97.359% 0.143% 1.597% 0.0% 0.512% 0.0% 0.0% 0.0% 0.0% 0.12% 0.221% 99.017% 0.461% 0.0% 0.181% 0.0% 0.0% 0.02% 0.039% 0.274% 4.073% 0.117% 95.164% 0.0% 0.313% 0.0% 0.0% 0.02% 0.0% 0.199% 0.159% 0.04% 0.06% 99.463% 0.0% 0.0% 0.06%</cell><cell cols="2">40 60</cell><cell cols="3">True label</cell><cell>3 4 5 6</cell><cell>0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 28.377% 0.0% 71.623% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0%</cell><cell>40 60</cell><cell>True label</cell><cell>3 4 5 6</cell><cell>0.058% 0.039% 0.407% 6.526% 0.194% 92.332% 0.0% 0.426% 0.0% 0.019% 0.059% 0.0% 0.435% 0.356% 0.099% 0.099% 98.892% 0.0% 0.0% 0.059% 0.146% 0.0% 0.522% 95.825% 0.334% 2.38% 0.0% 0.772% 0.0% 0.021% 0.02% 0.0% 0.341% 0.421% 98.114% 0.843% 0.0% 0.261% 0.0% 0.0%</cell><cell>40 60</cell></row><row><cell></cell><cell></cell><cell>7 8</cell><cell cols="4">0.0% 0.0% 0.0% 0.0% 16.944% 0.0% 0.0% 83.056% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0%</cell><cell>20</cell><cell></cell><cell></cell><cell>7 8</cell><cell cols="5">0.02% 0.0% 0.02% 0.02% 0.839% 0.459% 0.0% 98.642% 0.0% 0.0% 0.259% 0.06% 0.02% 0.0% 0.0% 0.02% 0.0% 0.02% 99.542% 0.08%</cell><cell cols="2">20</cell><cell></cell><cell></cell><cell></cell><cell>7 8</cell><cell>0.0% 0.0% 0.0% 0.0% 28.967% 0.0% 0.0% 71.033% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0%</cell><cell>20</cell><cell>7 8</cell><cell>0.04% 0.0% 0.06% 0.08% 1.233% 0.994% 0.0% 97.594% 0.0% 0.0% 0.416% 0.139% 0.059% 0.02% 0.02% 0.02% 0.0% 0.04% 99.108% 0.178%</cell><cell>20</cell></row><row><cell></cell><cell></cell><cell>9</cell><cell cols="4">1 2 3 4 5 6 7 8 9 Corrupted label 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0%</cell><cell>0</cell><cell></cell><cell></cell><cell>9</cell><cell cols="5">0 1 2 3 4 5 6 7 8 9 Corrected label 0.162% 0.283% 0.0% 0.0% 0.0% 0.0% 0.0% 0.02% 0.0% 99.535%</cell><cell cols="2">0</cell><cell></cell><cell></cell><cell></cell><cell>9</cell><cell>0 1 2 3 4 5 6 7 8 9 Corrupted label 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0%</cell><cell>0</cell><cell>9</cell><cell>0 1 2 3 4 5 6 7 8 9 Corrected label 0.163% 0.346% 0.0% 0.061% 0.0% 0.0% 0.0% 0.061% 0.0% 99.37%</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="10">(a) Asymmetry Noise (20%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(b) Asymmetry Noise (40%)</cell></row><row><cell></cell><cell cols="2">0</cell><cell cols="4">62.453% 0.0% 37.547% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% wo/ soft labels</cell><cell>100</cell><cell></cell><cell cols="2">0</cell><cell cols="5">96.472% 0.197% 2.385% 0.237% 0.079% 0.138% 0.0% 0.138% 0.0% 0.355% w/ soft labels</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">0</cell><cell>55.568% 0.0% 44.432% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% wo/ soft labels</cell><cell>100</cell><cell>0</cell><cell>94.427% 0.214% 3.605% 0.448% 0.234% 0.175% 0.039% 0.273% 0.097% 0.487% w/ soft labels</cell></row><row><cell></cell><cell cols="2">1 2</cell><cell cols="4">0.0% 62.22% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 37.78% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0%</cell><cell>80</cell><cell></cell><cell cols="2">1 2</cell><cell cols="5">0.099% 97.78% 0.0% 0.0% 0.0% 0.02% 0.0% 0.0% 0.0% 2.101% 0.352% 0.0% 97.663% 0.662% 0.538% 0.476% 0.0% 0.269% 0.0% 0.041%</cell><cell cols="2">80</cell><cell></cell><cell></cell><cell cols="2">1 2</cell><cell>0.0% 55.673% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 44.327% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0%</cell><cell>80</cell><cell>1 2</cell><cell>0.584% 0.021% 96.347% 1.148% 0.522% 0.668% 0.209% 0.438% 0.0% 0.063% 0.138% 97.062% 0.0% 0.02% 0.0% 0.039% 0.0% 0.0% 0.079% 2.662%</cell><cell>80</cell></row><row><cell>True label</cell><cell cols="2">3 4 5 6</cell><cell cols="4">0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 37.107% 0.0% 62.893% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0%</cell><cell>40 60</cell><cell>True label</cell><cell cols="2">3 4 5 6</cell><cell cols="5">0.243% 0.081% 1.031% 91.975% 0.606% 4.973% 0.0% 1.031% 0.0% 0.061% 0.08% 0.0% 0.557% 0.676% 96.76% 1.371% 0.0% 0.537% 0.0% 0.02% 0.101% 0.061% 0.505% 6.498% 0.283% 91.907% 0.0% 0.626% 0.0% 0.02% 0.059% 0.02% 0.822% 0.685% 0.235% 0.215% 97.847% 0.039% 0.0% 0.078%</cell><cell cols="2">40 60</cell><cell cols="2">True label</cell><cell cols="2">3 4 5 6</cell><cell>0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 44.172% 0.0% 55.828% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0% 0.0% 0.0%</cell><cell>40 60</cell><cell>True label</cell><cell>3 4 5 6</cell><cell>0.141% 0.0% 0.503% 0.745% 96.457% 1.329% 0.06% 0.745% 0.0% 0.02% 0.16% 0.08% 0.701% 9.133% 0.621% 88.424% 0.04% 0.821% 0.0% 0.02% 0.097% 0.019% 1.11% 0.876% 0.584% 0.253% 96.885% 0.019% 0.0% 0.156% 0.164% 0.041% 1.309% 89.062% 1.022% 6.911% 0.102% 1.349% 0.0% 0.041%</cell><cell>40 60</cell></row><row><cell></cell><cell cols="2">7 8</cell><cell cols="4">0.0% 0.0% 0.0% 0.0% 37.826% 0.0% 0.0% 62.174% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0%</cell><cell>20</cell><cell></cell><cell cols="2">7 8</cell><cell cols="5">0.08% 0.0% 0.08% 0.16% 0.878% 1.736% 0.0% 97.066% 0.0% 0.0% 0.846% 0.197% 0.059% 0.059% 0.039% 0.039% 0.0% 0.039% 98.367% 0.354%</cell><cell cols="2">20</cell><cell></cell><cell></cell><cell cols="2">7 8</cell><cell>0.0% 0.0% 0.0% 0.0% 44.414% 0.0% 0.0% 55.586% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0% 0.0%</cell><cell>20</cell><cell>7 8</cell><cell>0.08% 0.02% 0.159% 0.318% 1.134% 2.447% 0.02% 95.803% 0.0% 0.02% 1.31% 0.313% 0.117% 0.117% 0.059% 0.02% 0.0% 0.039% 97.518% 0.508%</cell><cell>20</cell></row><row><cell></cell><cell cols="2">9</cell><cell cols="4">0 1 2 3 4 5 6 7 8 9 Corrupted label 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0%</cell><cell>0</cell><cell></cell><cell cols="2">9</cell><cell cols="5">0 1 2 3 4 5 6 7 8 9 Corrected label 0.265% 0.794% 0.081% 0.081% 0.0% 0.0% 0.0% 0.061% 0.0% 98.717%</cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell cols="2">9</cell><cell>0 1 2 3 4 5 6 7 8 9 Corrupted label 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% 100.0%</cell><cell>0</cell><cell>9</cell><cell>0 1 2 3 4 5 6 7 8 9 Corrected label 0.41% 0.841% 0.082% 0.103% 0.0% 0.021% 0.0% 0.041% 0.041% 98.461%</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="10">(c) Asymmetry Noise (60%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(d) Asymmetry Noise (80%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>TABLE 12</head><label>12</label><figDesc>Validation accuracy of InceptionResNet-v2 with transferable CMW-Net on full WebVision and ImageNet validation sets.</figDesc><table><row><cell>Methods</cell><cell cols="4">WebVision top1 top5 top1 top5 ILSVRC12</cell><cell>Methods</cell><cell cols="4">WebVision top1 top5 top1 top5 ILSVRC12</cell></row><row><cell>ERM</cell><cell>69.7</cell><cell>87.0</cell><cell>62.9</cell><cell>83.6</cell><cell>MentorMix [93]</cell><cell>74.3</cell><cell>90.5</cell><cell>67.5</cell><cell>87.2</cell></row><row><cell>MentorNet [37]</cell><cell>70.8</cell><cell>88.0</cell><cell>62.5</cell><cell>83.0</cell><cell>HAR [92]</cell><cell>75.0</cell><cell>90.6</cell><cell>67.1</cell><cell>86.7</cell></row><row><cell>Curriculumnet [16]</cell><cell>72.1</cell><cell>89.2</cell><cell>64.8</cell><cell>84.9</cell><cell>ERM + CMW-Net</cell><cell>75.4</cell><cell>91.5</cell><cell>67.8</cell><cell>87.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head></head><label></label><figDesc>Samples selected from Animal-10N<ref type="bibr" target="#b77">[78]</ref>. The original training label is cat. Samples selected from mini-WebVision<ref type="bibr" target="#b13">[14]</ref>. The original training labels are electric ray, crampfish, numbfish, torpedo. Samples selected from mini-WebVision<ref type="bibr" target="#b13">[14]</ref>. The original training labels are house finch, linnet, Carpodacus mexicanus. Samples selected from mini-WebVision<ref type="bibr" target="#b13">[14]</ref>.The original training labels are robin, American robin, Turdus migratorius. loggerhead turtle box turtle loggerhead turtle box turtle loggerhead turtle box turtle mud turtle mud turtle (d) Samples selected from mini-WebVision [14]. The original training labels are leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea. Samples selected from mini-WebVision [14]. The original training labels are common iguana, iguana, Iguana iguana. Samples selected from mini-WebVision [14]. The original training labels are American chameleon, anole, Anolis carolinensis. Gila monster common iguana Gila monster Gila monster common iguana Gila monster frilled lizard African crocodile (g) Samples selected from mini-WebVision [14]. The original training labels are Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis.</figDesc><table><row><cell>lynx great white shark</cell><cell>lynx carassius auratus</cell><cell>lynx tiger shark</cell><cell>lynx stingray</cell><cell>lynx indigo bunting</cell><cell cols="2">lynx African crocodile</cell><cell>lynx Tinca tinca</cell><cell>lynx tiger shark</cell></row><row><cell cols="5">(a) cat cat (a) goldfinch indigo bunting goldfinch indigo bunting goldfinch cat cat cat</cell><cell cols="2">cat goldfinch</cell><cell>cat goldfinch</cell><cell>cat goldfinch</cell></row><row><cell cols="8">(b) Samples selected from Animal-10N [78]. The original training label is lynx. coyote coyote coyote coyote (b) indigo bunting indigo bunting chickadee coyote coyote magpie goldfinch snowbird indigo bunting coyote</cell><cell>coyote magpie</cell></row><row><cell cols="8">(c) Samples selected from Animal-10N [78]. The original training label is wolf. wolf wolf wolf wolf (d) Samples selected from Animal-10N [78]. The original training label is coyote. cachimpanzeet wolf cachimpanzeet cachimpanzeet cachimpanzeet cachimpanzeet cachimpanzeet wolf (c) American chameleon Komodo dragon Anolis carolinensis wolf cachimpanzeet agama Anolis carolinensis whiptail lizard whiptail lizard</cell><cell>wolf cachimpanzeet mud turtle</cell></row><row><cell cols="8">(e) Samples selected from Animal-10N [78]. The original training label is chimpanzee. chimpanzee chimpanzee chimpanzee chimpanzee chimpanzee chimpanzee (e) African chameleon African chameleon common iguana chimpanzee agama African crocodile African chameleon bullfrog</cell><cell>chimpanzee common iguana</cell></row><row><cell>(f)</cell><cell cols="7">(f) Samples selected from Animal-10N [78]. The original training label is cachimpanzeet.</cell><cell></cell></row><row><cell>guinea pig</cell><cell>guinea pig</cell><cell>guinea pig</cell><cell>guinea pig</cell><cell>guinea pig</cell><cell cols="2">guinea pig</cell><cell>guinea pig</cell><cell>guinea pig</cell></row><row><cell></cell><cell cols="7">(g) Samples selected from Animal-10N [78]. The original training label is hamster.</cell><cell></cell></row><row><cell>hamster</cell><cell>hamster</cell><cell>hamster</cell><cell>hamster</cell><cell>hamster</cell><cell>.</cell><cell>hamster</cell><cell>hamster</cell><cell>hamster</cell></row></table><note>(h) Samples selected from Animal-10N [78]. The original training label is guinea pig. Fig. 16. Examples of randomly selected samples with noisy labels corrected by our method on Animal-10N dataset [78]. The original training labels and generated pseudo-labels by our model are shown in red and blue, respectively.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>TABLE 13 89.77 ? 0.36 88.01 ? 0.27 86.04 ? 0.32 80.57 ? 1.3361.22 ? 0.03 60.25 ? 0.17 59.17 ? 0.17 54.64 ? 0.15TABLE 14</head><label>1314</label><figDesc>Performance comparison of classification accuracy (%) on partially labeled benchmark datasets. MNIST PRODEN MLP 98.59 ? 0.01 98.07 ? 0.03 98.42 ? 0.03 98.09 ? 0.05 PRODEN+ Ours MLP 98.99 ? 0.01 98.83 ? 0.02 98.57 ? 0.04 98.33 ? 0.02 Fashion-MNIST PRODEN MLP 89.51 ? 0.07 88.79 ? 0.06 88.32 ? 0.07 87.21 ? 0.13 PRODEN+ Ours MLP 90.47 ? 0.02 90.07 ? 0.05 89.38 ? 0.12 87.84 ? 0.13 Kuzushiji-MNIST PRODEN MLP 91.07 ? 0.07 90.24 ? 0.12 88.31 ? 0.14 85.55 ? 0.58 PRODEN+ Ours MLP 93.07 ? 0.04 91.65 ? 0.03 88.86 ? 0.07 86.11 ? 0.17 CIFAR-10 PRODEN ResNet-32 82.09 ? 0.05 81.70 ? 0.58 80.72 ? 1.08 76.24 ? 1.35 PRODEN+ Ours ResNet-32 48.06 ? 0.95 47.07 ? 1.32 46.49 ? 1.73 46.30 ? 1.98 PRODEN+ Ours ResNet-32 Performance comparison of our method with SOTA methods trained on CIFAR-10, CIFAR-100 and ImageNet datasets in terms of test error over 3 trials.Results for all baselines are directly copied from<ref type="bibr" target="#b46">[47]</ref>.</figDesc><table><row><cell></cell><cell>Dataset</cell><cell>Methods</cell><cell>Classifier</cell><cell>q = 0.1</cell><cell cols="2">q = 0.3</cell><cell cols="2">q = 0.5</cell><cell>q = 0.7</cell></row><row><cell></cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>q = 0.03</cell><cell cols="2">q = 0.05</cell><cell cols="2">q = 0.07</cell><cell>q = 0.10</cell></row><row><cell></cell><cell>CIFAR-100</cell><cell cols="2">PRODEN ResNet-32 CIFAR-10</cell><cell></cell><cell></cell><cell cols="2">CIFAR-100</cell><cell>ImageNet</cell></row><row><cell>Method</cell><cell>40 labels</cell><cell>250 labels</cell><cell>4000 labels</cell><cell>400 labels</cell><cell></cell><cell cols="2">2500 labels</cell><cell>10000 labels</cell><cell>10% labels</cell></row><row><cell>?-Model [113]</cell><cell>-</cell><cell cols="2">54.26 ? 3.97 14.01 ? 0.38</cell><cell>-</cell><cell></cell><cell cols="2">57.25 ? 0.48</cell><cell>37.88 ? 0.11</cell><cell>-</cell></row><row><cell>Pseudo-Labeling [99]</cell><cell>-</cell><cell cols="2">49.78 ? 0.43 16.09 ? 0.28</cell><cell>-</cell><cell></cell><cell cols="2">57.38 ? 0.46</cell><cell>36.21 ? 0.19</cell><cell>-</cell></row><row><cell>Mean Teacher [114]</cell><cell>-</cell><cell>32.32 ? 2.30</cell><cell>9.19 ? 0.19</cell><cell>-</cell><cell></cell><cell cols="2">53.91 ? 0.57</cell><cell>35.83 ? 0.24</cell><cell>-</cell></row><row><cell>MixMatch [100]</cell><cell cols="2">47.54 ? 11.50 11.05 ? 0.86</cell><cell>6.42 ?0.10</cell><cell cols="2">67.61 ? 1.32</cell><cell cols="2">39.94 ? 0.37</cell><cell>28.31 ? 0.33</cell><cell>-</cell></row><row><cell>UDA [97]</cell><cell>29.05 ? 5.93</cell><cell>8.82 ? 1.08</cell><cell>4.88 ? 0.18</cell><cell cols="2">59.28 ? 0.88</cell><cell cols="2">33.13 ? 0.22</cell><cell>24.50 ? 0.25</cell><cell>-</cell></row><row><cell>FixMatch [47]</cell><cell>13.81 ? 3.37</cell><cell>5.07 ? 0.65</cell><cell>4.26 ? 0.05</cell><cell cols="2">48.85 ? 1.75</cell><cell cols="2">28.29 ? 0.11</cell><cell>22.60 ? 0.12</cell><cell>32.9 (top1), 13.3 (top5)</cell></row><row><cell>FixMatch + CMW-Net</cell><cell>9.6 ? 0.62</cell><cell>4.73 ? 0.15</cell><cell>4.25 ? 0.03</cell><cell>47.7</cell><cell></cell><cell></cell><cell></cell></row></table><note>? 1.14 27.43 ? 0.12 22.55 ? 0.09 30.8 (top1), 11.3 (top5)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>TABLE 15</head><label>15</label><figDesc>Selective classification error (%) on CIFAR-10, CIFAR-100 datasets for various coverage rates (%) for SelectiveNet (left in each panel) and SelectiveNet+CMW-Net (right in each panel). The better result in each case is highlighted in bold.</figDesc><table><row><cell>Dataset</cell><cell cols="2">Coverage</cell><cell>200 SelectiveNet</cell><cell>Ours</cell><cell cols="2">100 SelectiveNet</cell><cell>Ours</cell><cell>SelectiveNet</cell><cell>50</cell><cell>Ours</cell><cell cols="2">SelectiveNet</cell><cell>20</cell><cell>Ours</cell><cell>SelectiveNet</cell><cell>10</cell><cell>Ours</cell><cell>SelectiveNet</cell><cell>0</cell><cell>Ours</cell></row><row><cell>CIFAR-10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Selective risk (\%)</cell><cell>8 10 12 14 16 18</cell><cell cols="4">SelectiveNet SelectiveNet+CMW-Net</cell><cell></cell><cell></cell><cell></cell><cell>Selective risk (\%)</cell><cell>40 45 50 55</cell><cell cols="6">SelectiveNet SelectiveNet+CMW-Net</cell></row><row><cell></cell><cell></cell><cell>6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>35</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>0.70</cell><cell>0.75</cell><cell>0.80</cell><cell>0.85 Coverage</cell><cell>0.90</cell><cell>0.95</cell><cell>1.00</cell><cell></cell><cell></cell><cell>0.70</cell><cell cols="2">0.75</cell><cell>0.80</cell><cell cols="2">0.85 Coverage</cell><cell>0.90</cell><cell>0.95</cell><cell>1.00</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">S (f (x; w), y) = v (f (x; w), y)+(1 ? v) (f (x; w), z),<ref type="bibr" target="#b11">(12)</ref> </note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACL</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Convolutional neural networks for speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Hamid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Penn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE/ACM Transactions on audio, speech, and language processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1533" to="1545" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Class-balanced loss based on effective number of samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Large-scale long-tailed recognition in an open world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Dividemix: Learning with noisy labels as semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Meta-weight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Learning to predict from crowdsourced data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<pubPlace>UAI</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Shankar</surname></persName>
		</author>
		<title level="m">Do imagenet classifiers generalize to imagenet?&quot; in ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Pervasive label errors in test sets destabilize machine learning benchmarks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Northcutt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Athalye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mueller</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.14749</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Re-labeling imagenet: from single to multi-labels, from global to localized labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Webvision database: Visual learning and understanding from web data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agustsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.02862</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Small sample learning in big data era</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.04572</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Curriculumnet: Weakly supervised learning from large-scale web images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhuang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A closer look at memorization in deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Arpit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jastrz?bski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ballas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kanwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Maharaj</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Deep long-tailed learning: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hooi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.04596</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Classification in the presence of label noise: a survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fr?nay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verleysen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TNNLS</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Image classification with deep learning in the presence of noisy labels: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Algan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ulusoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">215</biblScope>
			<biblScope unit="page">106771</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Deep learning with noisy labels: Exploring techniques and remedies in medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Dou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Warfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gholipour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Image Analysis</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Learning from noisy labels with deep neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-G</forename><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.08199</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">A survey of label-noise representation learning: Past, present and future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">W</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2011.04406</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Methods of reducing sample size in monte carlo computations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of the Operations Research Society of America</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="263" to="278" />
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning to reweight examples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A decision-theoretic generalization of on-line learning and an application to boosting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of computer and system sciences</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="119" to="139" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The annals of statistics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Ensemble of exemplar-svms for object detection and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Malisiewicz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Efros</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Self-paced learning for latent variable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Packer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">A framework for robust subspace learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L T</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Mkchael</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note type="report_type">IJCV</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Easy samples first: Self-paced reranking for zero-example multimedia search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mitamura</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM MM</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Self-paced learning with diversity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-I</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hauptmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Robust probabilistic modeling with bayesian data reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kucukelbir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Approximation with artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Cs?ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Faculty of Sciences</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
		<respStmt>
			<orgName>Etvs Lornd University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Beyond class-conditional assumption: A primary attempt to combat instance-dependent label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P.-A</forename><surname>Heng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Meta-learning in neural networks: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hospedales</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Micaelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Storkey</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>TPAMI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A model of inductive bias learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Baxter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="149" to="198" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Model-agnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">The advantage of conditional meta-learning for biased regularization and fine tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Denevi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ciliberto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Learning an explicit hyperparameter prediction policy conditioned on tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2107.02378</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Webly supervised fine-grained recognition: Benchmark datasets and an approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-S</forename><forename type="middle">W Y Z F S J W J Z H T S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yazhou</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning with multiple labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Selective classification for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Geifman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Smote: synthetic minority over-sampling technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">V</forename><surname>Chawla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">W</forename><surname>Bowyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">O</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">P</forename><surname>Kegelmeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of artificial intelligence research</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="321" to="357" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Class rectification hard mining for imbalanced deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning and evaluating classifiers under sample selection bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zadrozny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Survey on deep learning with class imbalance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Meta transition adaptation for robust deep learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.05697</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Fidelity-weighted learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mehrjou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gouws</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sch?lkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Learning to teach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-Y.</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">in ICLR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Learning to model the tail</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Large scale fine-grained categorization and domain-specific transfer learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Meta feature modulator for long-tailed recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.03428</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Learning deep representation for imbalanced classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Range loss for deep face recognition with long-tailed training data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Rethinking class-balanced methods for long-tailed visual recognition from a domain adaptation perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Jamal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Self-adaptive training: beyond empirical risk minimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Error-bounded correction of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Learning to purify noisy labels via meta soft label corrector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sastry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Symmetric cross entropy for robust learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Robust bi-tempered logistic loss based on bregman divergences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Amid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Warmuth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Anil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Koren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Normalized loss functions for deep learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Learning adaptive loss for robust learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06482</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title level="m" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lukasik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<title level="m">Does label smoothing mitigate label noise?&quot; in ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Pattern recognition and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Pattern Recognition and Machine Learning</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Pytorch: An imperative style, high-performance deep learning library</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Killeen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gimelshein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Antiga</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Reptile: a scalable metalearning algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nichol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schulman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.02999</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Training deep neural networks on noisy labels with bootstrapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR workshop</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Selfie: Refurbishing unclean samples for robust deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-G</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5907" to="5915" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Early-learning regularization prevents memorization of noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Niles-Weed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Razavian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fernandez-Granda</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Temporal ensembling for semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Laine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Aila</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Learning imbalanced datasets with label-distribution-aware margin loss</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Learning with feature-dependent label noise: A progressive approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chen</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title level="m" type="main">Active bias: Training more accurate neural networks by emphasizing high variance samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Learned-Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title level="m" type="main">Co-teaching: robust training deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title level="m" type="main">Understanding and utilizing deep neural networks trained with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">B</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Contrast to divide: self-supervised pre-training for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Zheltonozhskii</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Baskin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mendelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Litany</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Decoupling&quot; when to update&quot; from&quot; how to update</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Malach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shalev-Shwartz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Deep metric learning via lifted structured feature embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jegelka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title level="m" type="main">Heteroskedastic and imbalanced deep learning with adaptive regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Arechiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gaidon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ma</surname></persName>
		</author>
		<editor>ICLR</editor>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Beyond synthetic noise: Deep learning on controlled noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Progressive identification of true labels for partial-label learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Exponential moving average normalization for self-supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Soatto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<monogr>
		<title level="m" type="main">A survey on deep semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2103.00550</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title level="m" type="main">Unsupervised data augmentation for consistency training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Virtual adversarial training: a regularization method for supervised and semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Miyato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Koyama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ishii</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">TPAMI</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshop : Challenges in Representation Learning</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Mixmatch: A holistic approach to semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Papernot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Classification with noisy labels by importance reweighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE TPAMI</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<analytic>
		<title level="a" type="main">Sgdr: Stochastic gradient descent with warm restarts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">H</forename><surname>Loshchilov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Iterative learning with open-set noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-T</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Wide residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Z</forename><surname>Simonyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<analytic>
		<title level="a" type="main">Bilinear cnn models for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aruni</forename><surname>Roychowdhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<monogr>
		<title level="m" type="main">Inception-v4, inception-resnet and the impact of residual connections on learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">V</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>AAAI</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">Gradient-based learning applied to document recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the IEEE</title>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<monogr>
		<title level="m" type="main">Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.07747</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b110">
	<monogr>
		<title level="m" type="main">Deep learning for classical japanese literature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Clanuwat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bober-Irizar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kitamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lamb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yamamoto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ha</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1812.01718</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b111">
	<analytic>
		<title level="a" type="main">Randaugment: Practical automated data augmentation with a reduced search space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR Workshops</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b112">
	<analytic>
		<title level="a" type="main">Semi-supervised learning with ladder networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rasmus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Berglund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Honkala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Raiko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b113">
	<monogr>
		<title level="m" type="main">Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tarvainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Valpola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b114">
	<analytic>
		<title level="a" type="main">Selectivenet: A deep neural network with an integrated reject option</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Geifman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>El-Yaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b115">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b116">
	<analytic>
		<title level="a" type="main">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
