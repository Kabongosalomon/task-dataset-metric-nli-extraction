<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Self-Attention Message Passing for Contrastive Few-Shot Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ojas</forename><surname>Kishorkumar Shirekar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Delft University of Technology (TU Delft)</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shell Global Solutions International B.V</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anuj</forename><surname>Singh</surname></persName>
							<email>a.r.singh@student.tudelft.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Delft University of Technology (TU Delft)</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shell Global Solutions International B.V</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadi</forename><surname>Jamali-Rad</surname></persName>
							<email>h.jamalirad@tudelft.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">Delft University of Technology (TU Delft)</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Shell Global Solutions International B.V</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Self-Attention Message Passing for Contrastive Few-Shot Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T09:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Humans have a unique ability to learn new representations from just a handful of examples with little to no supervision. Deep learning models, however, require an abundance of data and supervision to perform at a satisfactory level. Unsupervised few-shot learning (U-FSL) is the pursuit of bridging this gap between machines and humans. Inspired by the capacity of graph neural networks (GNNs) in discovering complex inter-sample relationships, we propose a novel self-attention based message passing contrastive learning approach (coined as SAMP-CLR) for U-FSL pre-training. We also propose an optimal transport (OT) based fine-tuning strategy (we call OpT-Tune) to efficiently induce task awareness into our novel end-to-end unsupervised few-shot classification framework (SAMPTransfer). Our extensive experimental results corroborate the efficacy of SAMPTransfer in a variety of downstream few-shot classification scenarios, setting a new state-of-the-art for U-FSL on both miniImageNet and tieredImageNet benchmarks, offering up to 7%+ and 5%+ improvements, respectively. Our further investigations also confirm that SAMPTransfer remains on-par with some supervised baselines on miniImageNet and outperforms all existing U-FSL baselines in a challenging cross-domain scenario. Our code can be found in our GitHub repository: https://github.com/ojss/SAMPTransfer/. 1</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Deep learning models have become increasingly large and data hungry to be able to guarantee acceptable downstream performance. Humans need neither a ton of data samples nor extensive forms of supervision to understand their surroundings and the semantics therein. Few-shot learning has garnered an upsurge of interest recently as it underscores this fundamental gap between humans' adaptive learning capacity compared to data-demanding deep learning methods. In this realm, few-shot classification is cast as the task of predicting class labels for a set of unlabeled data points (query set) given only a small set of labeled ones (support set). Typically, query and support data samples are drawn from the same distribution.</p><p>Few-shot classification methods usually consist of two sequential phases: (i) pre-training on a large dataset of base classes, regardless of this pre-training being supervised or unsupervised. This is followed by (ii) fine-tuning on an unseen dataset consisting of novel classes. Normally, the classes used in the pre-training and fine-tuning are mutually exclusive. In this paper, we focus on the self-supervised setting (also interchangeably called "unsupervised" in literature) where we have no access to the actual class labels of the "base" dataset. Our motivation to tackle unsupervised few-shot learning (U-FSL) is that it poses a more realistic challenge, closer to humans' learning process.</p><p>The body of work around U-FSL can be broadly classified into two different approaches. The first approach relies on the use of meta-learning and episodic pre-training that involves the creation of synthetic "tasks" to mimic the subsequent episodic fine-tuning phase <ref type="bibr">[1, 16, 23-25, 29, 56]</ref>. The second approach follows a transfer learning strategy, where the network is trained non-episodically to learn optimal representations in the pre-training phase from the abundance of unlabeled data and is then followed by an episodic finetuning phase <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b38">39]</ref>. To be more specific, a feature extractor is first pre-trained to capture the structure of unlabeled data (present in base classes) using some form of representation learning <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b38">39]</ref>. Next, a prediction layer (a linear layer, by convention) is fine-tuned in conjunction with the pre-trained feature extractor for a swift adaptation to the novel classes. The better the feature extractor models the distribution of the unlabeled data, the less the predictor requires training samples, and the faster it adapts itself to the unseen classes in the fine-tuning and eventual testing phases. Some recent studies <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b41">42]</ref> argue that transfer learning approaches outperform meta-learning counterparts in standard in-domain and cross-domain settings, where base and novel classes come from totally different distributions.</p><p>On the other side of the aisle, supervised FSL approaches that follow the episodic training paradigm may include a certain degree of task awareness. Such approaches exploit the information available in the query set during the training and testing phases <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b53">54,</ref><ref type="bibr" target="#b56">57]</ref> to alleviate the model's sample bias. As a result, the model learns to generate task-specific embeddings by better aligning the features of the support and query samples for optimal metric based label assignment. Some other supervised approaches do not rely purely on convolutional feature extractors. Instead, they use graph neural networks (GNN) to model instance-level and classlevel relationships <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b54">55,</ref><ref type="bibr" target="#b57">58]</ref>. This is owing to the fact that GNN's are capable of exploiting the manifold structure of the novel classes <ref type="bibr" target="#b51">[52]</ref>. However, looking at the recent literature, one can barely see any GNN based architectures being used in the unsupervised setting.</p><p>Recent unsupervised methods use a successful form of contrastive learning <ref type="bibr" target="#b5">[6]</ref> in their self-supervised pre-training phase. Contrastive learning methods typically treat each image in a batch as its own class. The only other images that share the class are the augmentations of the image in question. Such methods enforce similarity of representations between pairs of an image and its augmentations (positive pairs), while enforcing dissimilarity between all other pairs of images (negative pairs) through a contrastive loss. Although these methods work well, they overlook the possibility that within a randomly sampled batch of images there could be several images (apart from their augmentations) that in reality belong to the same class. By applying the contrastive loss, the network may inadvertently learn different representations for such images and classes.</p><p>To address this problem, recent methods such as SimCLR <ref type="bibr" target="#b5">[6]</ref> introduce larger batch sizes in the pre-training phase to maximize the number of negative samples. However, this approach faces two shortcomings: (i) increasingly larger batch sizes, mandate more costly training infrastructure, and (ii) it still does not ingrain intra-class dependencies into the network. Point (ii) still applies to even more recent approaches, such as ProtoCLR <ref type="bibr" target="#b31">[32]</ref>. A simple yet effective remedy of this problem proposed in C 3 LR <ref type="bibr" target="#b38">[39]</ref> where an intermediate clustering and re-ranking step is introduced, and the contrastive loss is accordingly adjusted to ingest a semblance of class-cognizance. However, the problem could be approached from a different perspective, where the network explores the structure of data samples per batch.</p><p>We propose a novel U-FSL approach (coined as SAMPTransfer) that marries the potential of GNNs in learning the global structure of data in the pre-training stage, and the efficiency of optimal transport (OT) for inducing task-awareness in the following fine-tuning phase. More concretely, with SAMPTransfer we introduce a novel selfattention message passing contrastive learning (SAMP-CLR) scheme that uses a form of graph attention allowing the network to learn refined representations by looking beyond single-image instances per batch. Furthermore, the proposed OT based fine-tuning strategy (we call OpT-Tune) aligns the distributions of the support and query samples to improve downstream adaptability of the pre-trained encoder, without requiring any additional parameters. Our contributions can be summarized as:</p><p>1. We propose SAMPTransfer, a novel U-FSL approach that introduces a self-attention message passing contrastive learning (SAMP-CLR) paradigm for unsupervised few-shot pre-training.</p><p>2. We propose applying an optimal transport (OT) based fine-tuning (OpT-Tune) strategy to efficiently induce task-awareness in both fine-tuning and inference stages.</p><p>3. We present a theoretical foundation for SAMPTransfer, as well as extensive experimental results corroborating the efficacy of SAMPTransfer, and setting a new state-of-the-art (to our best knowledge) in both miniImageNet and tieredImageNet benchmarks, we also report competitive performance on the challenging CDFSL benchmark <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Self-Supervised learning. Self-supervised learning (SSL) is a term used for a collection of unsupervised methods that obtain supervisory signals from within the data itself, typically by leveraging the underlying structure in the data. The general technique of self-supervised learning is to predict any unobserved (or property) of the input from any observed part. Several recent advances in the SSL space have made waves by eclipsing their fully supervised counterparts <ref type="bibr" target="#b17">[18]</ref>. Some examples of seminal works include SimCLR <ref type="bibr" target="#b5">[6]</ref>, BYOL <ref type="bibr" target="#b18">[19]</ref>, SWaV <ref type="bibr" target="#b4">[5]</ref>, MoCo <ref type="bibr" target="#b20">[21]</ref>, and SimSiam <ref type="bibr" target="#b6">[7]</ref>. Our pre-training method SAMP-CLR is inspired by SimCLR <ref type="bibr" target="#b5">[6]</ref>, ProtoTransfer <ref type="bibr" target="#b31">[32]</ref> and C 3 LR <ref type="bibr" target="#b38">[39]</ref>.</p><p>Metric learning. Metric learning aims to learn a representation function that maps the data to an embedding space. The distance between objects in the embedding space must preserve their similarity (or dissimilarity) -similar objects are closer, while dissimilar objects are farther. For example, unsupervised methods based on some form of contrastive loss, such as SimCLR <ref type="bibr" target="#b5">[6]</ref> or NNCLR <ref type="bibr" target="#b14">[15]</ref>, guide objects belonging to the same potential class to be mapped to the same point and those from different classes to be mapped to different points. Note that in an unsupervised setting, each image in a batch is its own class. This process generally involves taking two crops of the same image and encouraging the network to emit an identical representation for the two, while ensuring that the representations remain different from all other images in a given batch. Metric learning methods have been shown to work quite well for few-shot learning. AAL-ProtoNets <ref type="bibr" target="#b0">[1]</ref>, ProtoTransfer <ref type="bibr" target="#b31">[32]</ref>, UMTRA <ref type="bibr" target="#b24">[25]</ref>, and certain GNN methods <ref type="bibr" target="#b36">[37]</ref> are excellent examples that use metric learning for few-shot learning.</p><p>f ? = f ? ? f ? <ref type="figure">Figure 1</ref>: SAMP-CLR schematic view and pre-training procedure. In the figure, x i,a is an image sampled from the augmented set A. The p-message passing steps refine the features extracted using a CNN encoder.</p><p>f ? <ref type="figure">Figure 2</ref>: Features extracted from the pre-trained CNN are used to build a graph. The features are first refined using the pre-trained SAMP layer(s). Then OpT-Tune aligns support features with query features.</p><p>Graph Neural Networks for FSL. Since the first use of graphs for FSL in <ref type="bibr" target="#b36">[37]</ref>, there have been several advancements and continued interest in using graphs for supervised FSL. In <ref type="bibr" target="#b36">[37]</ref>, each node corresponds to one instance (labeled or unlabeled) and is represented as the concatenation of a feature embedding and a label embedding. The final layer of their model is a linear classifier layer that directly outputs the prediction scores for each unlabeled node. There has also been an increase in methods that use transduction. TPN <ref type="bibr" target="#b30">[31]</ref> is one of those methods that uses graphs to propagate labels <ref type="bibr" target="#b51">[52]</ref> from labeled samples to unlabeled samples. Although methods such as EGNN <ref type="bibr" target="#b25">[26]</ref> make use of edge and node features, earlier methods focused only on using node features. Graphs are attractive, as they can model intra-batch relations and can be extended for transduction, as used in <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b30">31]</ref>. In addition to transduction and relation modeling, graphs are highly potent as task adaptation modules. HGNN <ref type="bibr" target="#b57">[58]</ref> is an example in which a graph is used to refine and adapt feature embeddings. It must be noted that most graph-based methods have been applied in the supervised FSL setting. To the best of our knowledge, we are the first to use it in any form for U-FSL. More specifically, we use a message passing network as a part of our network architecture and pre-training scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method (SAMPTransfer)</head><p>In this section, we first describe our problem formulation. We then discuss the two subsequent phases of the proposed approach: (i) self-supervised pre-training (SAMP-CLR), and (ii) the optimal transport based episodic supervised fine-tuning (OpT-Tune). Together, these two phases constitute our overall approach, which we have coined as SAMPTransfer. The mechanics of the proposed pretraining and fine-tuning procedures are illustrated in Figs. 1 and 2, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preliminaries</head><p>Let us denote the training data of size D as</p><formula xml:id="formula_0">D tr = {(x i , y i )} D i=1 with (x i , y i )</formula><p>representing an image and its class label, respectively. In the pre-training phase, we sample L random images from D tr and augment each sample A times by randomly sampling augmentation functions ? a (.), ?a ? [A] from the set A. This results in a mini-batch of size B = (A + 1)L total samples. Note that in the unsupervised setting, we have no access to the data labels in the pre-training phase. Next, we fine-tune our model episodically <ref type="bibr" target="#b46">[47]</ref> on a set of randomly sampled tasks T i drawn from the test dataset</p><formula xml:id="formula_1">D tst = {(x i , y i )} D ? i=1 of size D ? . A task, T i ,</formula><p>is comprised of two parts: (i) the support set S from which the model learns, (ii) the query set Q on which the model is evaluated. The support set S = {x s i , y s i } N K i=1 is constructed by drawing K labeled random samples from N different classes, resulting in the so-called (N -way, K-shot) settings. The query set Q = {x q j } N Q j=1 then contains N Q unlabeled samples. By convention, we denote T i = S i ? Q i by (N, K).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Self-Attention Message Passing (SAMP)</head><p>Our network architecture consists of a convolutional (CNN) feature extractor f ? and a message passing network based on self-attention,</p><formula xml:id="formula_2">f ? . The CNN feature extractor f ? , parameterized by ?, is used to extract features V = f ? (X), where V ? R B?d is the set of B features each of size d and X ? R B?C?H?W is a batch of B images of size C ? H ? W .</formula><p>To help refine the features and use batch-level relationships, we create a graph G = Graph(V , e, ?) where V is treated as a set of initial node features, e is the pairwise distance between all nodes based on a given distance metric and ? is a threshold on the values in e that determines whether two nodes will be connected or not. Note that |G| = B, as we build the graph over the B samples in our batch. We use a self-attention message passing neural network (we call SAMP) f ? , parameterized by ?, to refine the initial feature vectors by exchanging and amalgamating information between all pairs of connected nodes. From now on, as can be seen in Figs. 1 and 2, we refer to the combination of the feature extractor f ? and the SAMP module f ? as f ? = f ? ? f ? where ? = {?, ?} is the collection of all parameters. The SAMP layers, f ? operate on the graph G.</p><p>To allow an effective exchange of information to refine initial node features V , we make use of graph attention in a slightly different manner than the standard graph attention defined in <ref type="bibr" target="#b45">[46]</ref>. The graph attention in <ref type="bibr" target="#b45">[46]</ref> uses a single weight matrix W that acts as a shared linear transformation for all nodes. Instead, we choose to use scaled dot-product self-attention as defined in <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b44">45]</ref>. The major benefit of this design choice is that it enhances the network with more expressivity, as shown in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b26">27]</ref>. Notably, the use of three separate representations (query, key, and value) instead of just a single weight matrix to linearly transform the data is key to modeling relationships between data points.</p><p>We apply p successive message passing steps similar to <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b45">46]</ref>. In each step, we pass messages between the connected nodes of G and obtain updated features in V p+1 , at step p + 1. Here, the i-th row of V p+1 is given by</p><formula xml:id="formula_3">V p+1 i = j?Ni ? p ij W p V p j ,</formula><p>where ? ij is the attention score between the nodes i and j, W p ? R d?d is the message passing weight matrix at step p, and N i denotes the set of neighboring nodes of node i. In this way, ? i,j allows our update mechanism to flexibly weight every sample w.r.t every other sample in the batch. We employ scaled dot-product self-attention to compute attention scores, lead- </p><formula xml:id="formula_4">ing to: ? p ij = softmax( W p q V p i (W p k V p j ) T / ? d) where W p k and W p q , both ? R d?d ,</formula><formula xml:id="formula_5">V p+1 i = ? ? j?Ni ? p,1 ij W p,1 V p j , . . . , j?Ni ? p,H ij W p,H V p j ? ? , note that V p+1 i still has the same dimension R d .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Self-Supervised Pre-Training (SAMP-CLR)</head><p>The fact that we do not have access to the true class labels of the training data underscores the need to use a self-supervised pre-training scheme. As briefly discussed in Section 1, we build on the idea of employing contrastive prototypical transfer learning with some inspiration from <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b38">39]</ref>. Standard contrastive learning enforces embeddings of augmented images to be close to the embeddings of their source images in the representation space. The key idea of SAMP-CLR is not only to perform contrastive learning (the "CLR" component) on the source and augmented image embeddings, but also to ensure that images in the mini-batch belonging to potentially the same class have similar embeddings. This is where the "SAMP" module comes to rescue, enabling the model to look beyond single instances and their augmentations. SAMP allows the model to extract richer semantic information across multiple images present in a mini-batch. Concretely speaking, we apply a contrastive loss on the SAMP refined features (generated by f ? ), and on the standard convolutional features (generated by f ? ). Let us walk you through the process in more detail.</p><p>Algorithm 1 begins with batch generation: each minibatch consists of L random samples {x i } L i=1 from D tr , where x i is treated as a 1-shot support sample for which we create A randomly augmented versionsx i,a as query samples (lines 2 to 3), leading to a batch size of B = (A + 1)L. Then the embeddings Z ? R L?d andZ ? R LA?d are generated (line 4) by passing the source images and augmented images through a feature extraction network f ? , respectively. We then construct G = Graph(V , e, ?) with V = [Z ? ,Z ? ] ? of size B ? d concatenating source and augmented image embeddings Z andZ (line 5-6), e is the vector of centered shift/scale-invariant cosine similarities d ? [.] (line 5) <ref type="bibr" target="#b43">[44]</ref>, and ? is defined earlier. The graph G is then passed through the SAMP layer(s) f ? resulting in a updated graph G ? with refined node features V ? (line 7). V ? is spliced into the updated source and augmented image</p><formula xml:id="formula_6">Algorithm 1: SAMP-CLR Require: A, f ? , f ? , ?, ?, ?, ?, d[.], d ? [.] 1 while not done do 2 Sample minibatch {xi} L i=1 ? Dtr 3</formula><p>Augment samples:xi,a = ?a(xi); ?a ? A.</p><formula xml:id="formula_7">4 Z,Z ? f ? {xi} L i=1 , f ? {xi, a} L,A i=1,a=1 5 V = [Z ? ,Z ? ] ? , e = {d ? [Vi, Vj], ?i, j ? [B]} 6 G ? Graph(V , e, ?) 7 G ? ? Graph(V ? , e ? , ?) = f ? (G) 8 Z ? ,Z ? ? V ? 1:L , V ? L+1:B 9 ?(i, a) = ? log exp(?d[Z (a?1)L+i ,Z i]) L k=1 exp(?d[Z (a?1)L+i ,Z k ]) 10 r(i, a) = ? log exp ?d Z? (a?1)L+i ,Z ? i L k=1 exp ?d Z? (a?1)L+i ,Z ? k 11 L1 = 1 /LA L i=1 A a=1 ?(i, a) 12 L2 = 1 /LA L i=1 A a=1 r(i, a) 13 L = ?L1 + L2 14 ? ? ? ? ???L 15 end embeddings (Z ? andZ ? )</formula><p>, respectively (lines 8). In lines 9 to 12, we then apply contrastive losses L 1 (between Z and Z) and L 2 (between Z ? andZ ? ). Here, L 1 encourages the feature extractor to cluster the embeddings of augmented query samplesZ around their prototypes (namely, source embeddings) Z, which in turn provides a good initial set of embeddings for the SAMP projector module to refine. L 2 enforces the same constraints as L 1 but for embeddings generated by the SAMP layer. Both loss terms use a Euclidean distance metric in the embedding space, denoted by d <ref type="bibr">[.]</ref>. Finally, the overall loss is given by L = ?L 1 + L 2 , which is optimized with mini-batch stochastic gradient descent w.r.t all the parameters in ? = {?, ?} where ? is a scaling factor, and ? the learning rate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Supervised Fine-tuning (OpT-Tune)</head><p>We propose a two-stage supervised fine-tuning consisting of (i) a transportation stage followed by (ii) a prototypical fine-tuning and classification stage. The transportation stage involves using optimal transport (OT) <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b33">34]</ref>. As sketched in <ref type="figure">Fig. 2</ref>, OT helps projecting embeddings of the support set, Z s = f ? ({x s i } N K i=1 ) ? R N K?d , so that they overlap better with the query set embeddings, Z q = f ? ({x q j } N Q j=1 ) ? R N Q?d upon transportation. This increases the spread of Z s in the query set's domain, which in turn creates more representative prototypes for each of the N classes in S. We show in Section 6 that this results in a significant boost in the downstream classification performance.</p><formula xml:id="formula_8">Algorithm 2: OpT-Tune Require: d[?], Z s , Z q 1 Mi,j = d[Z s i , Z q j ], ?i ? [N K], j ? [N Q] 2 ? ? ? Solving Eq. (1) using Sinkhorn-Knopp [10] 3? ? i,j ? ? ? i,j / j ? ? i,j , ?i ? [N K], j ? [N Q] 4 Solve Eq. (2)</formula><p>Return:? s OT based feature alignment. We provide a basic intuition for OT in the context of SAMPTransfer. Let r ? R N K and c ? R N Q be two probability simplexes defined over Z s i , ?i ? [N K] and Z q j , ?j ? [N Q], respectively. r denotes the distribution of the support embeddings, whereas c denotes the distribution of the query embeddings. Consider ?(r, c) to be a set of N K ?N Q doubly stochastic matrices where all rows sum up to r and all columns sum up to c as:</p><formula xml:id="formula_9">?(r, c) = ? ? R N K?N Q + | ?1 N Q = r, ? ? 1 N K = c .</formula><p>Intuitively, ?(r, c) is a collection of all transport "plans", where a transport plan is defined as a potential strategy specifying how much of each support embedding is allocated to every query embedding and vice-versa. Our goal here is to find the most optimal transport plan, out of all possible transport plans ?(r, c), that allocates N K support embeddings to N Q query embeddings with maximum overlap between their distributions.</p><p>Given a cost matrix M , the cost of mapping Z s to Z q using a transport plan ? can be quantified as ??, M ? F and the OT problem can then be stated as,</p><formula xml:id="formula_10">? ? = argmin ???(r,c) ??, M ? F ? ?H(?),<label>(1)</label></formula><p>where ? ? denotes the most optimal transportation plan, ??, ?? F is the Frobenius dot product, and ? is the weight on the entropic regularizer H. The cost matrix M quantifies the overlap between the two distributions by measuring the distance between each support and query embedding pair:</p><formula xml:id="formula_11">M i,j = d[Z s i , Z q j ].</formula><p>The entropic regularization promotes "smoother" transportation plans <ref type="bibr" target="#b9">[10]</ref>. Equation (1) is then solved using the time-efficient Sinkhorn-Knopp algorithm <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b39">40]</ref>. Notice that ? ? is also referred to as Wasserstein metric <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b33">34]</ref>. To adapt Z s to Z q with cost matrix M , we compute? s as the projected mapping of Z s , given by:</p><formula xml:id="formula_12">Z s =? ? Z q , ? ? i,j = ? ? i,j j ? ? i,j , ?i ? [N K], j ? [N Q],<label>(2)</label></formula><p>where ? ? is the normalized transport. The projected support embeddings? s are an estimation of Z s in the region occupied by the query embeddings Z q . Specifically, it is a barycentric mapping of the support features Z s . Algorithm 2 shows this process in a succinct manner. Prototypical classification. The projected support embeddings,? s , are used for prototype creation and classification of the query points. To this end, following <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b42">43]</ref> we concatenate f ? with a single layer nearest mean classifier f ? (resulting in an architecture similar to ProtoNet <ref type="bibr" target="#b40">[41]</ref>) and only fine-tune this last layer. In this stage, for each class k ? C in the support set, we compute the class prototype c k for class k using the projected support embeddings? s,k belonging to class k:</p><formula xml:id="formula_13">c k = 1 ?s,k ??? s,k? , for k ? C.</formula><p>Following <ref type="bibr" target="#b31">[32,</ref><ref type="bibr" target="#b42">43]</ref>, we initialize the classification layer f ? with weights set to W k = 2c k and biases set to b k = ??c k ? 2 . To finetune this layer, we sample a subset of supports from S and train f ? with a standard cross-entropy loss; more details are given in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Setup</head><p>Datasets. To benchmark the performance of our method SAMPTransfer, we conduct "in-domain" experimentation on two most commonly adopted few-shot learning datasets: miniImageNet <ref type="bibr" target="#b46">[47]</ref> and tieredImageNet <ref type="bibr" target="#b35">[36]</ref>. MiniImageNet contains 100 classes with 600 samples in each class. This equals a total of 60, 000 images that we resize to 84 ? 84 pixels. Out of the 100 classes, we use 64 classes for training, 16 for validation, and 20 for testing. TieredImageNet is a larger subset of ILSVRC-12 <ref type="bibr" target="#b12">[13]</ref> with 608 classes with a total of 779, 165 images of size 84 ? 84. We use 351 for training, 97 for validation, and 8 for testing, out of the 608 classes. The augmentation strategy follows the one proposed in <ref type="bibr" target="#b1">[2]</ref>. We also compare our method on a recent more challenging "cross-domain" few-shot learning (CDFSL) benchmark <ref type="bibr" target="#b19">[20]</ref>, which consists of several datasets. This benchmark has four datasets with increasing similarities to miniImageNet. In that order, we have grayscale chest X-ray images from ChestX <ref type="bibr" target="#b49">[50]</ref>, dermatological skin lesion images from ISIC2018 <ref type="bibr" target="#b7">[8]</ref>, aerial satellite images from Eu-roSAT <ref type="bibr" target="#b21">[22]</ref>, and crop disease images from CropDiseases <ref type="bibr" target="#b32">[33]</ref>. We also used the Caltech-UCSD Birds (CUB) dataset <ref type="bibr" target="#b47">[48]</ref> for further analysis of cross-domain performance. The CUB dataset is made up of 11, 788 images from 200 unique species of birds. We use 100 classes for training, 50 for both validation and testing.</p><p>Training strategy. In <ref type="figure">Fig. 1</ref>, as feature extractor, we use the standard Conv4 model following <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b46">47]</ref>. It is followed by a single SAMP layer with 4 attention heads. Note that we also use a slightly modified version of the Conv4 network which we call Conv4b, where we increase the number of filters from (64, 64, 64, 64) to (96, 128, 256, 512) <ref type="bibr" target="#b16">[17]</ref> and average pool the final feature map returning a smaller embedding dimension d = 512 instead of d = 1600. The networks are pre-trained using SAMP-CLR on the respective training splits of the datasets, with an initial learning rate of ? = 0.0005, annealed by a cosine scheduler via the Adam optimizer <ref type="bibr" target="#b27">[28]</ref> and L = 128. Experiments involving CDFSL benchmark follow <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b38">39]</ref>, where we pre-train a ResNet-10 encoder using SAMP-CLR on miniImageNet images of size 224 ? 224 for 400 epochs with the Adam optimizer and a constant learning rate of ? = 0.0001. Similar to the Conv4 encoder, the ResNet-10 uses the same SAMP configuration. During validation and testing, as defined in Section 3.4, we initialize and fine-tune f ? for 15 iterations where we sample a subset of examples from S in each iteration. For validation, we create 15 (N -way, K-shot) tasks using the validation split of the respective dataset.</p><p>Evaluation scenarios and baseline. Our testing scheme uses 600 test episodes, each with 15 query shots per class, on which the pre-trained encoder (SAMP-CLR) is fine-tuned using OpT-Tune and tested. All our results indicate 95% confidence intervals over 3 runs, each with 600 test episodes. Therefore, the standard deviation values are calculated according to the 3 runs to provide more concrete measures for comparison. For our in-domain benchmarks, we test on (5way, 1-shot) and (5-way, 5-shot) classification tasks, while our cross-domain testing is performed using (5-way, 5-shot) and (5-way, 20-shot) classification tasks following <ref type="bibr" target="#b19">[20]</ref>. We compare our performance with a suite of recent unsupervised few-shot baselines such as U-MlSo <ref type="bibr" target="#b59">[60]</ref>, C 3 LR [39], Meta-GMVAE <ref type="bibr" target="#b28">[29]</ref>, and Revisiting UML <ref type="bibr" target="#b55">[56]</ref> to name a few. Furthermore, we also compare with a set of supervised approaches (such as MetaQDA <ref type="bibr" target="#b60">[61]</ref> and TransductiveCNAPS <ref type="bibr" target="#b2">[3]</ref>), the best of which are expected to outperform ours and other unsupervised methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Performance Evaluation</head><p>In-domain experiments. <ref type="table" target="#tab_1">Table 1</ref> summarizes our performance evaluation results on the miniImageNet dataset for (N -way, K-shot) scenarios with N = 5 and K = 1, 5. The top section compares the performance of the proposed approach (SAMPTransfer) with the most recent unsupervised competitors. We outperform our closest competitors by approximately 7%+ and 2%+ in the (5-way, 1-shot) and (5-way, 5-shot) settings, respectively. More interestingly, our method matches or outperforms some of the supervised baselines (bottom section of the table), especially SimpleCNAPS which uses a much more powerful ResNet-18 backbone. Obviously, the state-of-the-art supervised few-shot learning approaches have the advantage of having access to the true labels. When it comes to tieredImageNet, our approach shows considerable gains over recent competitors such as C 3 LR [39] with a 3%+ improvement in the (5-way, 1-shot) setting and a 5%+ improvement in the (5-way,5 shot) setting. As such, SAMPTransfer sets a new state-of-the-art for both   <ref type="bibr" target="#b19">[20]</ref> to investigate the performance of SAMPTransfer in cross-domain scenarios. This outcome is summarize in <ref type="table" target="#tab_4">Table 3</ref>. Here, we pre-train on miniImageNet and fine-tune on ChestX <ref type="bibr" target="#b49">[50]</ref>, ISIC2018 <ref type="bibr" target="#b7">[8]</ref>, EuroSAT <ref type="bibr" target="#b21">[22]</ref>, and CropDiseases <ref type="bibr" target="#b32">[33]</ref>. We compare the performance against C 3 LR[39], ProtoTransfer <ref type="bibr" target="#b31">[32]</ref> along with its two variants using UMTRA <ref type="bibr" target="#b24">[25]</ref> (also proposed in <ref type="bibr" target="#b31">[32]</ref>), as well as Con-FeSS <ref type="bibr" target="#b10">[11]</ref> and ATA <ref type="bibr" target="#b48">[49]</ref> -two of the latest methods dedicated  to solving the cross-domain few-shot learning problem. Note that we also compare with a couple of related supervised approaches from <ref type="bibr" target="#b19">[20]</ref>, as a reference. Our method consistently keeps up with ConFeSS <ref type="bibr" target="#b10">[11]</ref>, but scores higher in 5 and 20 shot CropDiseases tasks by 2%+ and about 1%, respectively. Except for EuroSAT, our method is consistently competitive (? 1% difference) to the performance of ConFeSS in ChestX and ISIC. In ISIC, which is the second least similar dataset to miniImageNet, our method is better by 1%+ in the (5-way, 20-shot) setting. Note that SAMPTransfer outperforms another recent dedicated method ATA <ref type="bibr" target="#b48">[49]</ref> in all but one CDFSL benchmark settings, with the exception being the EuroSAT (5-way, 5-shot) setting. <ref type="table" target="#tab_5">Table 4</ref> investigates the performance of the proposed method against various choices of important hyperparameters. We use the (5-way, 5-shot) miniImageNet benchmark to analyze the robustness of our method and demonstrate the importance of our design choices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Ablation Study and Robustness Analysis</head><p>OpT-Tune is crucial. To illustrate the effect of using OpT-Tune on the classification performance, we perform experiments with OpT-Tune disabled. For a fair comparison, we use the same pre-trained models in the test runs with OpT-Tune enabled or disabled. The best performing model (a Conv4b) uses 1 SAMP layer with 4 attention heads and a batch size of 128, resulting in accuracy of 72.52% with OpT-Tune enabled. The same model, with OpT-Tune disabled, loses 9% accuracy. Even with OpT-Tune disabled, our method remains competitive with some of the latest methods in <ref type="table" target="#tab_1">Table 1</ref>. This observation suggests that the process described in Section 3.4 is an efficient technique to incorporate task awareness and improve the quality of prototypes. This is further corroborated in <ref type="figure" target="#fig_0">Fig. 3</ref> where a task with N = 2 is used to showcase the effect of OpT-Tune. We observe that the support embeddings are more evenly spread out over the distribution of the query embeddings. This is also backed by the DBI score <ref type="bibr" target="#b11">[12]</ref> which increases from 0.583 to 0.754 after OpT-Tune is applied.   SAMP layers and attention heads. In <ref type="table" target="#tab_5">Table 4</ref>, we also investigate the robustness of our method when the number of SAMP layers (p) and attention heads (H) vary. The best performance is achieved with a single SAMP layer with four attention heads. Increasing p leads to a significant decrease in performance; however, increasing H leads to a small performance degradation. Notably, the observations here are consistent with those reported in <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b45">46]</ref>.</p><p>Embedding dimension. We measure the performance of the model in relation to two commonly used (by a majority of the existing baselines) embedding dimensions: 512 and 1600. As can be seen in <ref type="table" target="#tab_5">Table 4</ref>, the network performs best with an embedding dimension of 512 (Conv4b). Performance is notably lower with an embedding dimension of 1600 (Conv4). We hypothesize that this behavior can be attributed to the lower number of channels in the final feature map of a Conv4 network, which is limited to 64.</p><p>Effect of loss scaling factor ? on L 1 . We observe that when ? = 0 the Conv4 based model suffers the most as it loses 15% accuracy compared to ? = 0.7, suggesting that training the CNN with a contrastive loss is crucial. However, the Conv4b model is not affected as strongly by the presence of this loss function. Regardless, we set ? = 0.7 for both models (Conv4 and Conv4b).</p><p>Cross-domain robustness. For the sake of completeness, and to further analyze the cross-domain performance of SAMPTransfer, in addition to <ref type="table" target="#tab_4">Table 3</ref>, we trained a Conv4 model on CUB and tested it on tasks derived from miniImageNet. CUB consists of 200 classes of only birds, while miniImageNet consists of 64 classes, of which only 3 training classes are birds. Thus, CUB has a diminished class diversity compared to miniImageNet. <ref type="table" target="#tab_6">Table 5</ref> demonstrates that when training classes are diversity constrained, our method offers a better cross-domain transfer accuracy compared to the only two other competing baselines that report experimental results on this setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Concluding Remarks</head><p>We introduced SAMP-CLR, a novel contrastive pretraining method for unsupervised few-shot classification. SAMP-CLR learns its representations by looking beyond single-image instances owing to a built-in self-attention message passing (SAMP) module. We also propose an optimal transport (OT) based fine-tuning strategy (OpT-Tune) which enables the creation of more representative prototypes by inducing task-awareness. Together, they construct our overall unsupervised FSL approach (coined as SAMPTransfer). We demonstrate that SAMPTransfer sets a new state-of-the-art for unsupervised FSL in both miniImageNet and tieredImageNet datasets, as well as offering competitive performance on the challenging CDFSL benchmark <ref type="bibr" target="#b19">[20]</ref>. As future work, we are investigating the idea of incorporating memory modules in SAMP-CLR pretraining to help better approximate the data distribution.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Before (left) and after applying OT (right). Prototypes (?), supports (?) and queries (?). OT helps better align the distribution of support and query samples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>are the weight matrices corresponding to the sending and receiving nodes, respectively. To allow the message-passing neural network to learn a diverse set of attention scores, we apply H scaled dot-product self-attention heads in every message-passing step and concatenate their results. To this end, instead of using single weight matrices W p q , W p k and W p , we use W</figDesc><table><row><cell>p,h q , W p,h k</cell><cell>and W p,h all</cell></row><row><cell>? R</cell><cell></cell></row></table><note>d /H?d for each attention head, resulting in:</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 :</head><label>1</label><figDesc>Accuracy (%? std.) for (N -way, K-shot) classification tasks. Style: best and second best.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">miniImageNet</cell></row><row><cell>Method(N, K)</cell><cell>Backbone</cell><cell>(5,1)</cell><cell>(5,5)</cell></row><row><cell>CACTUs-MAML [23]</cell><cell>Conv4</cell><cell cols="2">39.90 ? 0.74 53.97 ? 0.70</cell></row><row><cell>CACTUs-Proto [23]</cell><cell>Conv4</cell><cell cols="2">39.18 ? 0.71 53.36 ? 0.70</cell></row><row><cell>UMTRA [25]</cell><cell>Conv4</cell><cell>39.93</cell><cell>50.73</cell></row><row><cell>AAL-ProtoNet [1]</cell><cell>Conv4</cell><cell cols="2">37.67 ? 0.39 40.29 ? 0.68</cell></row><row><cell>AAL-MAML++ [1]</cell><cell>Conv4</cell><cell cols="2">34.57 ? 0.74 49.18? 0.47</cell></row><row><cell>UFLST [24]</cell><cell>Conv4</cell><cell cols="2">33.77 ? 0.70 45.03 ? 0.73</cell></row><row><cell>ULDA-ProtoNet [35]</cell><cell>Conv4</cell><cell cols="2">40.63 ? 0.61 55.41 ? 0.57</cell></row><row><cell>ULDA-MetaNet [35]</cell><cell>Conv4</cell><cell cols="2">40.71 ? 0.62 54.49 ? 0.58</cell></row><row><cell>U-SoSN+ArL [59]</cell><cell>Conv4</cell><cell cols="2">41.13 ? 0.84 55.39 ? 0.79</cell></row><row><cell>U-MlSo [60]</cell><cell>Conv4</cell><cell>41.09</cell><cell>55.38</cell></row><row><cell>ProtoTransfer [32]</cell><cell>Conv4</cell><cell cols="2">45.67 ? 0.79 62.99 ? 0.75</cell></row><row><cell>CUMCA [53]</cell><cell>Conv4</cell><cell>41.12</cell><cell>54.55</cell></row><row><cell>Meta-GMVAE [29]</cell><cell>Conv4</cell><cell>42.82</cell><cell>55.73</cell></row><row><cell>Revisiting UML [56]</cell><cell>Conv4</cell><cell cols="2">48.12 ? 0.19 65.33 ? 0.17</cell></row><row><cell>CSSL-FSL_Mini64 [30]</cell><cell>Conv4</cell><cell cols="2">48.53 ? 1.26 63.13 ? 0.87</cell></row><row><cell>C 3 LR [39]</cell><cell>Conv4</cell><cell>47.92 ? 1.2</cell><cell>64.81 ? 1.15</cell></row><row><cell>SAMPTransfer (ours)</cell><cell>Conv4</cell><cell cols="2">55.75 ? 0.77 68.33 ? 0.66</cell></row><row><cell>SAMPTransfer ? (ours)</cell><cell>Conv4b</cell><cell>61.02 ? 1.0</cell><cell>72.52 ? 0.68</cell></row><row><cell>Supervised Methods</cell><cell></cell><cell></cell><cell></cell></row><row><cell>MAML [16]</cell><cell>Conv4</cell><cell cols="2">46.81 ? 0.77 62.13? 0.72</cell></row><row><cell>ProtoNet [41]</cell><cell>Conv4</cell><cell>46.44? 0.78</cell><cell>66.33? 0.68</cell></row><row><cell>MMC [36]</cell><cell>Conv4</cell><cell cols="2">50.41 ? 0.31 64.39 ? 0.24</cell></row><row><cell>FEAT [57]</cell><cell>Conv4</cell><cell>55.15</cell><cell>71.61</cell></row><row><cell>SimpleShot [51]</cell><cell>Conv4</cell><cell cols="2">49.69 ? 0.19 66.92 ? 0.17</cell></row><row><cell>Simple CNAPS [3]</cell><cell>ResNet-18</cell><cell>53.2 ? 0.9</cell><cell>70.8 ? 0.7</cell></row><row><cell>Transductive CNAPS [3]</cell><cell>ResNet-18</cell><cell>55.6 ? 0.9</cell><cell>73.1 ? 0.7</cell></row><row><cell>MetaQDA [61]</cell><cell>Conv4</cell><cell cols="2">56.41 ? 0.80 72.64 ? 0.62</cell></row><row><cell>Pre+Linear [32]</cell><cell>Conv4</cell><cell cols="2">43.87 ? 0.69 63.01 ? 0.71</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Accuracy (%? std.) for (N -way, K-shot) classification tasks. Style: best and second best.</figDesc><table><row><cell></cell><cell></cell><cell cols="2">tieredImageNet</cell></row><row><cell>Method(N, K)</cell><cell>Backbone</cell><cell>(5,1)</cell><cell>(5,5)</cell></row><row><cell>C 3 LR [39]</cell><cell>Conv4</cell><cell cols="2">42.37 ? 0.77 61.77 ? 0.25</cell></row><row><cell>ULDA-ProtoNet [35]</cell><cell>Conv4</cell><cell cols="2">41.60 ?0.64 56.28 ? 0.62</cell></row><row><cell>ULDA-MetaOptNet [35]</cell><cell>Conv4</cell><cell cols="2">41.77 ? 0.65 56.78 ? 0.63</cell></row><row><cell>U-SoSN+ArL [59]</cell><cell>Conv4</cell><cell cols="2">43.68 ? 0.91 58.56 ? 0.74</cell></row><row><cell>U-MlSo [60]</cell><cell>Conv4</cell><cell cols="2">43.01 ? 0.91 57.53 ? 0.74</cell></row><row><cell>SAMPTransfer (ours)</cell><cell>Conv4</cell><cell cols="2">45.25 ? 0.89 59.75 ? 0.66</cell></row><row><cell>SAMPTransfer ? (ours)</cell><cell>Conv4b</cell><cell cols="2">49.10 ? 0.94 65.19 ? 0.82</cell></row><row><cell cols="3">tieredImageNet and miniImageNet datasets.</cell><cell></cell></row><row><cell cols="4">Cross-domain experiments. We focus on the recent</cell></row><row><cell>CDFSL benchmark</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>Accuracy (%? std.) of (N -way, K-shot) classification on the CDFSL benchmark. Style: best and second best. ProtoNet<ref type="bibr" target="#b31">[32]</ref> 24.94 ? 0.<ref type="bibr" target="#b42">43</ref> 28.04 ? 0.<ref type="bibr" target="#b43">44</ref> 39.21 ? 0.53 44.62 ? 0.49 74.91 ? 0.72 80.42 ? 0.66 79.81 ? 0.65 86.84 ? 0.50 UMTRA-ProtoTune [32] 25.00 ? 0.43 30.41 ? 0.44 38.47 ? 0.55 51.60 ? 0.54 68.11 ? 0.70 81.56 ? 0.54 82.67 ? 0.60 92.04 ? 0.43 ProtoTransfer [32] 26.71 ? 0.46 33.82 ? 0.48 45.19 ? 0.56 59.07 ? 0.55 75.62 ? 0.67 86.80 ? 0.42 86.53 ? 0.56 95.06 ? 0.32 C 3 LR [39] 26.00 ? 0.41 33.39 ? 0.47 45.93 ? 0.54 59.95 ? 0.53 80.32 ? 0.65 88.09 ? 0.45 87.90 ? 0.55 95.38 ? 0.31 SAMPTransfer (ours) 26.27 ? 0.44 34.15 ? 0.50 47.60 ? 0.59 61.28 ? 0.56 85.55 ? 0.60 88.52 ? 0.50 91.74 ? 0.55 96.36 ? 0.28 ? 1.01 28.21 ? 1.15 39.57 ? 0.57 49.50 ? 0.55 73.29 ? 0.71 82.27 ? 0.57 79.72 ? 0.67 88.15 ? 0.51 Pre+Mean-Cent. [20] (sup.) 26.31 ? 0.42 30.41 ? 0.46 47.16 ? 0.54 56.40 ? 0.53 82.21 ? 0.49 87.62 ? 0.34 87.61 ? 0.47 93.87 ? 0.68 Pre+Linear [20] (sup.) 25.97 ? 0.41 31.32 ? 0.45 48.11 ? 0.64 59.31 ? 0.48 79.08 ? 0.61 87.64 ? 0.47 89.25 ? 0.51 95.51 ? 0.31</figDesc><table><row><cell>Method(N, K)</cell><cell>(5,5)</cell><cell>(5,20)</cell><cell>(5,5)</cell><cell>(5,20)</cell><cell>(5,5)</cell><cell>(5,20)</cell><cell>(5,5)</cell><cell>(5,20)</cell></row><row><cell></cell><cell>ChestX</cell><cell></cell><cell>ISIC</cell><cell></cell><cell cols="2">EuroSAT</cell><cell cols="2">CropDiseases</cell></row><row><cell>UMTRA-ConFeSS [11] (dedicated)</cell><cell>27.09</cell><cell>33.57</cell><cell>48.85</cell><cell>60.10</cell><cell>84.65</cell><cell>90.40</cell><cell>88.88</cell><cell>95.34</cell></row><row><cell>ATA [49] (dedicated)</cell><cell>24.43 ? 0.2</cell><cell>-</cell><cell>45.83 ? 0.3</cell><cell>-</cell><cell>83.75 ? 0.4</cell><cell>-</cell><cell>90.59 ? 0.3</cell><cell>-</cell></row><row><cell>ProtoNet [20] (sup.)</cell><cell>24.05</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 :</head><label>4</label><figDesc>Ablation study of various parameters on accuracy.</figDesc><table><row><cell>Backbone</cell><cell>p</cell><cell>H</cell><cell>L</cell><cell>?</cell><cell cols="2">OT Accuracy</cell></row><row><cell>Conv4b</cell><cell>1</cell><cell>4</cell><cell>64</cell><cell>1.0</cell><cell>?</cell><cell>71.42 ? 0.73</cell></row><row><cell>Conv4b</cell><cell>1</cell><cell>4</cell><cell>64</cell><cell>0.7</cell><cell>?</cell><cell>71.41 ? 0.71</cell></row><row><cell>Conv4b</cell><cell>1</cell><cell>8</cell><cell>64</cell><cell>1.0</cell><cell>?</cell><cell>71.27 ? 0.75</cell></row><row><cell>Conv4b</cell><cell>1</cell><cell>8</cell><cell>64</cell><cell>0.7</cell><cell>?</cell><cell>69.87 ? 0.72</cell></row><row><cell>Conv4b</cell><cell>2</cell><cell>1</cell><cell>64</cell><cell>0.7</cell><cell>?</cell><cell>68.99 ? 0.71</cell></row><row><cell>Conv4b</cell><cell>2</cell><cell>4</cell><cell>64</cell><cell>0.7</cell><cell>?</cell><cell>67.01 ? 0.69</cell></row><row><cell>Conv4</cell><cell>1</cell><cell>4</cell><cell>64</cell><cell>0.7</cell><cell>?</cell><cell>69.61 ? 0.71</cell></row><row><cell>Conv4</cell><cell>1</cell><cell>4</cell><cell>64</cell><cell>1.0</cell><cell>?</cell><cell>67.60 ? 0.62</cell></row><row><cell>Conv4</cell><cell>1</cell><cell>8</cell><cell>64</cell><cell>1.0</cell><cell>?</cell><cell>63.59 ? 0.68</cell></row><row><cell>Conv4b</cell><cell>1</cell><cell>4</cell><cell>128</cell><cell>0.7</cell><cell>?</cell><cell>72.52 ? 0.72</cell></row><row><cell>Conv4</cell><cell>1</cell><cell>4</cell><cell>128</cell><cell>0.7</cell><cell>?</cell><cell>68.33 ? 0.71</cell></row><row><cell>Conv4</cell><cell>1</cell><cell>4</cell><cell>128</cell><cell>0.0</cell><cell>?</cell><cell>52.81 ? 0.66</cell></row><row><cell>Conv4b</cell><cell>1</cell><cell>4</cell><cell>128</cell><cell>0.0</cell><cell>?</cell><cell>72.44 ? 0.69</cell></row><row><cell>Conv4b</cell><cell>1</cell><cell>4</cell><cell>64</cell><cell>0.7</cell><cell>?</cell><cell>64.29 ? 0.63</cell></row><row><cell>Conv4b</cell><cell>1</cell><cell>4</cell><cell>128</cell><cell>0.7</cell><cell>?</cell><cell>63.47 ? 0.64</cell></row><row><cell>Conv4</cell><cell>1</cell><cell>4</cell><cell>64</cell><cell>0.7</cell><cell>?</cell><cell>66.73 ? 0.65</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 :</head><label>5</label><figDesc>Accuracy (%? std.) for (N -way, K-shot) classification on miniImageNet with pre-training on CUB. LR [39] ProtoTune 39.61 ? 1.11 55.53 ? 1.42 SAMPTransfer (ours) OpT-Tune 49.32 ? 0.75 56.10 ? 0.60</figDesc><table><row><cell>Training</cell><cell>Testing</cell><cell>(5,1)</cell><cell>(5,5)</cell></row><row><cell>ProtoTransfer [32]</cell><cell>ProtoTune</cell><cell>35.37 ? 0.63</cell><cell>52.38 ? 0.66</cell></row><row><cell>C 3</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">This paper is accepted to appear in the proceedings of WACV 2023.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Assume, augment and learn: Unsupervised few-shot meta-learning via random labels and data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antreas</forename><surname>Antoniou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amos</forename><surname>Storkey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09884</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning representations by maximizing mutual information across views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devon</forename><surname>Hjelm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William</forename><surname>Buchwalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Enhancing few-shot image classification with unlabelled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peyman</forename><surname>Bateni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jarred</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan-Willem</forename><surname>Van De Meent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="2796" to="2805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">How attentive are graph attention networks?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaked</forename><surname>Brody</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Uri</forename><surname>Alon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eran</forename><surname>Yahav</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.14491</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Unsupervised learning of visual features by contrasting cluster assignments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="9912" to="9924" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Exploring simple siamese representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinlei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="15750" to="15758" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Skin lesion analysis toward melanoma detection 2018: A challenge hosted by the international skin imaging collaboration (isic)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noel</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Veronica</forename><surname>Rotemberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emre</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Dusza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Gutman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Helba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aadi</forename><surname>Kalloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Konstantinos</forename><surname>Liopyris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Marchetti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.03368</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Parameterless transductive feature re-representation for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wentao</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhong</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="2212" to="2221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sinkhorn distances: Lightspeed computation of optimal transport</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">26</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">ConfeSS: A framework for single source cross-domain few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debasmit</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungrack</forename><surname>Yun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A cluster separation measure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">W</forename><surname>Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bouldin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="224" to="227" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li-Jia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<publisher>Ieee</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">A baseline for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pratik</forename><surname>Guneet S Dhillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avinash</forename><surname>Chaudhari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Soatto</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.02729</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">With a little help from my friends: Nearest-neighbor contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debidatta</forename><surname>Dwibedi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yusuf</forename><surname>Aytar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Tompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9588" to="9597" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modelagnostic meta-learning for fast adaptation of deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1126" to="1135" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Boosting few-shot visual learning with self-supervision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Spyros</forename><surname>Gidaris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrei</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Cord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF international conference on computer vision</title>
		<meeting>the IEEE/CVF international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8059" to="8068" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Selfsupervised pretraining of visual features in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathilde</forename><surname>Caron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Lefaudeux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Min</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengchao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vivek</forename><surname>Pai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mannat</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vitaliy</forename><surname>Liptchinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Armand</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Bojanowski</surname></persName>
		</author>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent-a new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Bastien</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florent</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corentin</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Elena</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernardo</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="21271" to="21284" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhui</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Karlinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.07200</idno>
		<title level="m">Tajana Rosing, and Rogerio Feris. A New Benchmark for Evaluation of Cross-Domain Few-Shot Learning</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Momentum contrast for unsupervised visual representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqi</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saining</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="9729" to="9738" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Eurosat: A novel dataset and deep learning benchmark for land use and land cover classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Helber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Bischke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Dengel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damian</forename><surname>Borth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Unsupervised learning via meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyle</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chelsea</forename><surname>Finn</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.02334</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Unsupervised few-shot learning via self-supervised training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilong</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiejun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Wu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.12178</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Unsupervised meta-learning for few-shot image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Siavash</forename><surname>Khodadadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ladislau</forename><surname>Boloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mubarak</forename><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Edge-labeling graph neural network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongmin</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taesup</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungwoong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chang D</forename><surname>Yoo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Pure transformers are powerful graph learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinwoo</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tien</forename><forename type="middle">Dat</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seonwoo</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sungjun</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Moontae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honglak</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seunghoon</forename><surname>Hong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2207.02505</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Meta-gmvae: Mixture of gaussian vae for unsupervised meta-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongchan</forename><surname>Dong Bok Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seanie</forename><surname>Min</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Few-shot image classification via contrastive self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianyi</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guizhong</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.09942</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Learning to propagate labels: Transductive propagation network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanbin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juho</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Minseop</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saehoon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eunho</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sung</forename><forename type="middle">Ju</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.10002</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Self-supervised prototypical transfer learning for few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Medina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnout</forename><surname>Devos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Grossglauser</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.11325</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Using Deep Learning for Image-Based Plant Disease Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sharada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mohanty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcel</forename><surname>Hughes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Salath?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Plant Science</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">1419</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Computational optimal transport: With applications to data science. Foundations and Trends? in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Peyr?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marco</forename><surname>Cuturi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="355" to="607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Diversity helps: Unsupervised few-shot learning via distribution shift-based data augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tiexin</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenbin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Gao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05805</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Meta-learning for semi-supervised few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengye</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sachin</forename><surname>Ravi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.00676</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Few-shot learning with graph neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Garcia</forename><surname>Victor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joan</forename><forename type="middle">Bruna</forename><surname>Satorras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Estrach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning intra-batch connections for deep metric learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenny</forename><forename type="middle">Denise</forename><surname>Seidenschwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ismail</forename><surname>Elezi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laura</forename><surname>Leal-Taix?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<publisher>PMLR</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9410" to="9421" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Self-supervised class-cognizant few-shot classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kishore</forename><surname>Ojas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hadi</forename><surname>Shirekar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jamali-Rad</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2202.08149</idno>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Concerning nonnegative matrices and doubly stochastic matrices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Sinkhorn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Knopp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pacific Journal of Mathematics</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="343" to="348" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Prototypical networks for few-shot learning. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Rethinking few-shot image classification: a good embedding is all you need?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dilip</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="266" to="282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eleni</forename><surname>Triantafillou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tyler</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Dumoulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Lamblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Utku</forename><surname>Evci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kelvin</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Goroshin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carles</forename><surname>Gelada</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre-Antoine</forename><surname>Manzagol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1903.03096</idno>
		<title level="m">Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Metric distances derived from cosine similarity and pearson and spearman correlations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stijn</forename><surname>Van Dongen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anton</forename><forename type="middle">J</forename><surname>Enright</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1208.3145</idno>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Attention is all you need. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Graph attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Petar</forename><surname>Veli?kovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillem</forename><surname>Cucurull</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arantxa</forename><surname>Casanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adriana</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Li?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">The Caltech-UCSD Birds-200-2011 Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Branson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Welinder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<idno>- port CNS-TR-2011-001</idno>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
		<respStmt>
			<orgName>California Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Re</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Cross-domain few-shot classification via adversarial task augmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi-Hong</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21</title>
		<editor>Zhi-Hua Zhou</editor>
		<meeting>the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21</meeting>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">2021</biblScope>
		</imprint>
	</monogr>
	<note>Main Track</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Chestx-ray8: Hospital-scale chest x-ray database and benchmarks on weakly-supervised classification and localization of common thorax diseases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaosong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammadhadi</forename><surname>Bagheri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ronald M</forename><surname>Summers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2097" to="2106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Simpleshot: Revisiting nearestneighbor classification for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04623</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">Learning from labeled and unlabeled data with label propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhu</forename><surname>Xiaojin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ghahramani</forename><surname>Zoubin</surname></persName>
		</author>
		<idno>CMU-CALD-02-107</idno>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Unsupervised meta-learning for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deqiang</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Shao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page">107951</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Attentional constellation nets for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weijian</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yifan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huaijin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuowen</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Dpgn: Distribution propagation graph network for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liangliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zilun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyu</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erjin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</title>
		<meeting>the IEEE/CVF conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13390" to="13399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Revisiting Unsupervised Meta-Learning via the Characteristics of Few-Shot Tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han-Jia</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De-Chuan</forename><surname>Zhan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Few-shot learning via embedding adaptation with set-to-set functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexiang</forename><surname>Han-Jia Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>De-Chuan Zhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="8808" to="8817" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Hybrid graph neural networks for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyuan</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi-Zhe</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Xiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="3179" to="3187" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Rethinking class relations: Absoluterelative supervised and unsupervised few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songlei</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="9432" to="9441" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Multilevel second-order few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongdong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Koniusz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Multimedia</title>
		<imprint>
			<biblScope unit="page" from="1" to="1" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Shallow bayesian meta learning for real-world few-shot recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xueting</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Debin</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henry</forename><surname>Gouk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">M</forename><surname>Hospedales</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2021-10" />
			<biblScope unit="page" from="651" to="660" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
