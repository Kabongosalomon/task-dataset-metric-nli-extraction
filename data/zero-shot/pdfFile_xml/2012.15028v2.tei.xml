<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">NBNet: Noise Basis Learning for Image Denoising with Subspace Projection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shen</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Megvii Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuzhi</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Megvii Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Huang</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Kuaishou Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donghao</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Megvii Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoqiang</forename><surname>Fan</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Megvii Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuaicheng</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Megvii Technology</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Electronic Science and Technology of China</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">NBNet: Noise Basis Learning for Image Denoising with Subspace Projection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we introduce NBNet, a novel framework for image denoising. Unlike previous works, we propose to tackle this challenging problem from a new perspective: noise reduction by image-adaptive projection. Specifically, we propose to train a network that can separate signal and noise by learning a set of reconstruction basis in the feature space. Subsequently, image denosing can be achieved by selecting corresponding basis of the signal subspace and projecting the input into such space. Our key insight is that projection can naturally maintain the local structure of input signal, especially for areas with low light or weak textures. Towards this end, we propose SSA, a non-local attention module we design to explicitly learn the basis generation as well as subspace projection. We further incorporate SSA with NBNet, a UNet structured network designed for end-to-end image denosing based. We conduct evaluations on benchmarks, including SIDD and DND, and NBNet achieves state-of-the-art performance on PSNR and SSIM with significantly less computational cost.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image denoising is a fundamental and long lasting task in image processing and computer vision. The main challenging is to recover a clean signal x from the noisy observation y, with the additive noise n, namely:</p><formula xml:id="formula_0">y = x + n<label>(1)</label></formula><p>This problem is ill-posed as both the image term x and the noise term n are unknown and can hardly be separated. Towards this end, many denoising methods utilize image prior and a noise model to estimate either image or noise from the noisy observation. For example, traditional methods such as NLM <ref type="bibr" target="#b8">[9]</ref> and BM3D <ref type="bibr" target="#b13">[14]</ref> use the local similarity of image Computational Cost (GFlops) Denoising Performance (PSNR) <ref type="bibr" target="#b7">8</ref> 16 32 <ref type="figure">Figure 1</ref>: PSNRs at different computational cost and parameter amount of our method and previous methods in SIDD <ref type="bibr" target="#b0">[1]</ref>. The proposed NBNet achieves SOTA performance with a balanced computational requirement. and the independence of noise, and wavelet denoising <ref type="bibr" target="#b33">[34]</ref> utilizes the sparsity of image in transformed domain. Recent deep neural networks (DNN) based denoising methods <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b41">42]</ref> usually implicitly utilize image prior and noise distribution learned from a large set of paired training data.</p><p>Although previous CNN-based methods have achieved tremendous success, it is still challenging to recover high quality images in hard scenes such as weak textures or highfrequency details. Our key observation is that convolutional networks usually depend on local filter response to separate noise and signal. While in hard scenes with low signalnoise-ratio (SNR), local response can easily get confused without additional global structure information.</p><p>In this paper, we utilize non-local image information by projection. The basic concept of image projection is illustrated in <ref type="figure">Fig. 2</ref>, where a set of image basis vectors are generated from the input image, then we reconstruct the image inside the subspace spanned by these basis vectors. As natural images usually lie in a low-rank signal subspace, by properly learning and generating the basis vectors, the reconstructed image can keep most original information and arXiv:2012.15028v2 [cs.CV] 11 May 2021</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basis Generation</head><p>Basis Set Projection Reconstruction Input <ref type="figure">Figure 2</ref>: Denoising via subspace projection: Our NBNet learns to generate a set of basis for the signal subspace and by projecting the input into this space, signal can be enhanced after reconstruction for easy separation from noise. suppress noise which is irrelevant to the generated basis set. Based on this idea, we propose NBNet, depicted in <ref type="figure" target="#fig_0">Fig. 3</ref>. The overall architecture of NBNet is a commonlyused UNet <ref type="bibr" target="#b35">[36]</ref>, except for the crucial ingredient subspace attention (SSA) module which learns the subspace basis and image projection in an end-to-end fashion. Our experiments on popular benchmark datasets such as SIDD <ref type="bibr" target="#b0">[1]</ref> and DnD <ref type="bibr" target="#b32">[33]</ref> demonstrate that the proposed SSA module brings a significant performance boost in both PSNR and SSIM with much smaller computational cost than adding convolutional blocks. As depicted in <ref type="figure">Fig. 1</ref>, the whole architecture of NBNet achieves the state-of-the-art performance while only a smaller additional computational cost is added. To summarize, our contributions include:</p><p>? We analyze the image denoising problem from a new perspective of subspace projection. We further design a simple and efficient SSA module to learn subspace projection which can be plugged into normal CNNs.</p><p>? We propose NBNet, a UNet with SSA module for projection based image denoising.</p><p>? NBNet acheives state-of-the-art performance in PSNR and SSIM on many popular benchmarks ? We provide in-depth analysis of projection based image denoising, demonstrating it is a promising direction to explore.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Works</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Traditional Methods</head><p>Image noise reduction is a fundamental component in image processing problem and has been studied for decades.</p><p>Early works usually rely on image priors, including nonlocal means (NLM) <ref type="bibr" target="#b8">[9]</ref>, sparse coding <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b1">2]</ref>, 3D transform-domain filtering (BM3D) <ref type="bibr" target="#b13">[14]</ref>, and others <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b33">34]</ref>. Although these classical approaches like BM3D, can generate reasonable desnoising results with certain accuracy and robustness, their algorithmic complexity is usually high and with limited generalization. With the recent development of convolutional neural networks (CNNs), end-toend trained denoising CNNs has gained considerable attention with great success in this field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Network architecture</head><p>One main stream of CNNs based desnoising is to design novel network architecture to tackle this problem. Earlier work <ref type="bibr" target="#b9">[10]</ref> proposed to apply multi-layer perceptron (MLP) to denoising task and achieved comparable results with BM3D. Since then more advanced network architectures are introduced. Chen et al. <ref type="bibr" target="#b11">[12]</ref> proposed a trainable nonlinear reaction diffusion (TNRD) model for Gaussian noise removal at different level. DnCNN <ref type="bibr" target="#b49">[50]</ref> demonstrated the effectiveness of residual learning and batch normalization for denoising network using deep CNNs. Later on, More network structures were proposed to either enlarge the receptive field or balance the efficiency, like dilated convolution <ref type="bibr" target="#b50">[51]</ref>, autoencoder with skip connection <ref type="bibr" target="#b29">[30]</ref>, ResNet <ref type="bibr" target="#b34">[35]</ref>, recursively branched deconvolutional network (RBDN) <ref type="bibr" target="#b37">[38]</ref>. Recently some interests are put into involving high-level vision semantics like classification and segmentation with image denoising. Works <ref type="bibr" target="#b25">[26,</ref><ref type="bibr" target="#b31">32]</ref> applied segmentation to enhance the denoising performance on different regions. <ref type="bibr" target="#b51">[52]</ref> recently proposed FFDNet, a non-blind denoising by concatenating the noise level as a map to the noisy image and demonstrated a spatial-invariant denoising on realistic noises with over-smoothed detail. MIRNet <ref type="bibr" target="#b48">[49]</ref> proposed a general network architecture for image enhancement such as denoising and super-resolution with many noval build blocks which can extract, exchange and utilize multi-scale feature information.</p><p>In this work, we adapt a UNet style architecture with a novel subspace attention module. Unlike <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b40">41]</ref> use attention module for region or feature selection, SSA is designed to learn the subspace basis and image projection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Noise distribution</head><p>To train the deep networks mentioned above, it requires high quality real datasets with a huge amount of clean and noisy image pairs, which is hard and tedious to construct in practice. Hence, the problem of synthesizing realistic image noise has also been extensively studied. To approximate real noise, multiple types of synthetic noise are explored in previous work, such as Gaussian-Poisson <ref type="bibr" target="#b17">[18,</ref><ref type="bibr" target="#b26">27]</ref>, in-camera process simulation <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b38">39]</ref>, Gaussian Mixture Model (GMM) <ref type="bibr" target="#b53">[54]</ref> and GAN-generated noises <ref type="bibr" target="#b10">[11]</ref> and so  on. It has been shown that networks properly trained from the synthetic data can generalize well to real data <ref type="bibr" target="#b52">[53,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b42">43]</ref>. Different from all the aforementioned works that focus on noise modeling , our method study subspace basis generation and improve noise reduction by projection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Subspace Projection with Neural Network</head><p>As shown in <ref type="figure">Fig. 2</ref>, the projection contains two main steps: a) Basis generation: generating subspace basis vectors from image feature maps; b) Projection: transforming feature maps into the signal subspace. We denote X 1 , X 2 ? R H?W ?C as two feature maps from a single image. They are the intermediate activations of a CNN and can be in different layers but with the same size. We first estimate K basis vectors [v 1 , v 2 , ? ? ? , v K ] based on X 1 and X 2 , and each v i ? R N is a basis vector of the signal subspace, where N = HW . Then we transform X 1 into the subspace spanned by {v}.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1.">Basis Generation</head><p>Let f ? : (R H?W ?C , R H?W ?C ) ? R N ?K be a function parameterized by ?, basis generation can be written as:</p><formula xml:id="formula_1">V = f ? (X 1 , X 2 ),<label>(2)</label></formula><p>where X 1 and X 2 are image feature maps and V = [v 1 , v 2 , ? ? ? , v K ] is a matrix composed of basis vectors. We implement the function f ? with a small convolutional network. We first concatenate X 1 and X 2 along the channel axis as X ? R H?W ?2C , then feed it into a shallow residual-convolutional block with K output channels ( <ref type="figure" target="#fig_0">Fig. 3(b)</ref>), whose output can then be reshaped to HW ?K.</p><p>The weights and biases of the basis generation blocks are updated during the training in an end-to-end fashion.  <ref type="figure">Figure 5</ref>: Denoising examples from DND <ref type="bibr" target="#b32">[33]</ref>. Our results preserve the textures and sharpness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Projection</head><p>Given the aforementioned matrix V ? R N ?K whose columns are basis vectors of a K-dimensional signal subspace V ? R N , we can project the image feature map X 1 onto V by orthogonal linear projection.</p><p>Let P : R N ? V be the orthogonal projection matrix to signal subspace, P can calculated from V [31], given by   where the normalization term (V V ) ?1 is required since the basis generation process does not ensure the basis vectors are orthogonal to each other. Finally, the image feature map X 1 can be reconstructed in the signal subspace by as Y , given by</p><formula xml:id="formula_2">P = V (V V ) ?1 V ,<label>(3)</label></formula><formula xml:id="formula_3">Y = P X 1 .<label>(4)</label></formula><p>The operations in projection are purely linear matrix manipulations with some proper reshaping, which is fully differentiable and can be easily implemented in modern neural network frameworks.</p><p>Combining basis generation and subspace projection, we construct the structure of the proposed SSA module, illustrated in <ref type="figure" target="#fig_0">Fig. 3</ref>(c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">NBNet Architecture and Loss Function</head><p>The architecture of NBNet is illustrated in <ref type="figure" target="#fig_0">Fig. 3(a)</ref>. The overall structure is based on a typical UNet <ref type="bibr" target="#b35">[36]</ref> architecture. NBNet has 4 encoder stages and 4 corresponding decoder stages, where feature maps are downsampled to <ref type="bibr" target="#b0">1</ref> 2 ? scale with a 4?4-stride-2 convolution at the end of each encoder stage, and upsampled to 2? scale with a 2 ? 2 deconvolution before each decoder stage. Skip connections pass large-scale low-level feature maps from each encoder stage to its corresponding decoder stage. The basic convolution building blocks in encoder, decoder and skip connections follow the same residual-convolution structure depicted in <ref type="figure" target="#fig_0">Fig. 3(b)</ref>. We use LeakyReLU as activation functions for each convolutional layer.</p><p>The proposed SSA modules are placed in each skipconnection. As feature maps from low levels contain more detailed raw image information, we take the low-level feature maps as X 1 and high-level features as X 2 and feed them into an SSA module. In other words, low-level feature maps from skip-connections are projected into the signal subspace guided by the upsampled high-level features. The projected features are then fused with the original high-level feature before outputing to the next decoder stage.</p><p>Compared with conventional UNet-like architectures, which directly fuse low-level and high-level feature maps in each decoder stage, the major difference in NBNet is lowlevel features are projected by SSA modules before fusion.</p><p>Finally, the output of the last decoder pass a linear 3 ? 3 convolutional layer as the global residual to the noisy input and outputs the denoising result.</p><p>The network is trained with pairs of clean and noisy images, and we use simple 1 distance between clean images and the denoising result as the loss function, written as:</p><formula xml:id="formula_4">L(G, x, y) = x ? G(y) 1 ,<label>(5)</label></formula><p>where x, y and G(?) represent clean image, noisy image and NBNet, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation and Experiments</head><p>We evaluate the performance of our method on synthetic and real datasets and compare it with previous methods. Next, we describe the implementation details. Then we report results on five real image datasets. Finally, we perform ablation studies to verify the superiority of the proposed method.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Training Settings</head><p>The proposed architecture requires no pre-training and it can be trained through an end-to-end strategy. The number of subspace K is set by experience to 16 for all modules.</p><p>In the training stage, the weights of the whole network are initialized according to <ref type="bibr" target="#b19">[20]</ref>. We use Adam <ref type="bibr" target="#b22">[23]</ref> optimizer with momentum terms (0.9, 0.999). The initial learning rate is set to 2 ? 10 ?4 and the strategy of decreasing the learning rate is cosine annealing. The training process takes 700, 000 minibatch iterations.</p><p>During training, 128 ? 128-sized patches are cropped from each training pair as an instance, and 32 instances stack a mini-batch. We apply random rotation, cropping and flipping to the images to augment the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results on Synthetic Gaussian Noise</head><p>We first evaluate our approach on synthetic noisy dataset. We follow the experiment scheme described in VDN <ref type="bibr" target="#b46">[47]</ref>. The training dataset includes 432 images from BSD <ref type="bibr" target="#b5">[6]</ref>, 400 images from the validation set of ImageNet <ref type="bibr" target="#b14">[15]</ref> and 4744 images from the Waterloo Exploration Database <ref type="bibr" target="#b27">[28]</ref>. The evaluation test dataset are generated from Set5 <ref type="bibr" target="#b21">[22]</ref>, LIVE1 <ref type="bibr" target="#b21">[22]</ref> and BSD68 <ref type="bibr" target="#b6">[7]</ref>.</p><p>In order to achieve a fair comparison, we use the same noise generation algorithm as <ref type="bibr" target="#b46">[47]</ref>, where non-i.i.d. Gaussian noise is generated by:</p><formula xml:id="formula_5">n = n 1 M , n 1 ij ? N (0, 1),<label>(6)</label></formula><p>where M is a spatially variant mask. Four types of masks are generated, one for training and three for testing. By this way, the generalization ability of the noise reduction model can be well tested. <ref type="table" target="#tab_5">Table 3</ref> lists the PSNR performance results of different methods on non-i.i.d Gaussian noise, where our NBNet method outperform the baseline VDN method on every test case, although VDN has an automatic noise level prediction while our method is purely blind noise reduction. More results on additive Gaussian white noise (AWGN) with various noise levels (? = 15, 25, 50) also indicates our method surpasses VDN by an average margin of ? 0.3 dB in PSNR.</p><p>Our noise reduction method does not explicitly rely on a prior distribution of noise data, but it still achieve the best results in our evaluation. This shows the effectiveness of the proposed projection method which helps separating signal and noise in feature space by utilizing image prior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results on SIDD Benchmark</head><p>The Smartphone Image Denoising Dataset (SIDD) <ref type="bibr" target="#b0">[1]</ref> , are about 30,000 noisy images from 10 scenes under different lighting conditions using five representative smartphone cameras and generated their ground truth images through a systematic procedure. SIDD can be used to benchmark denoising performance for smartphone cameras. As a benchmark, SIDD splits 1,280 color images for the validation.</p><p>In this section, we use SIDD benchmark <ref type="bibr" target="#b0">[1]</ref> to verify the performance of our method on a real-world noise reduction task. We compare with the previous methods, including VDN, DANet, and MIRNet. <ref type="table">Table 1</ref> illustrates a quantitative comparison between previous methods and ours in <ref type="figure" target="#fig_1">Fig 6.</ref> We also provide visualization of noise reduction results from different models. The number of parameters and computational cost of each model are shown in <ref type="figure">Fig 1.</ref> Compared to MIRNet, we provide 39.75 PSNR compared to MIRNet's 39.72 by only taking 11.2% of its computational cost and 41.82% of its number of parameters. In the SSIM metric, we have a performant rise over MIRNet, boosting from 0.959 to ours 0.969. This growth explains that our model concentrates further on regional textures and local features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Results on DND Benchmark</head><p>The Darmstadt Noise Dataset (DND) <ref type="bibr" target="#b32">[33]</ref> consists of 50 pairs of real noisy images and corresponding ground truth images that were captured with consumer-grade cameras of Noisy FFDNet <ref type="bibr" target="#b51">[52]</ref> VDN <ref type="bibr" target="#b46">[47]</ref> Ours Reference   <ref type="table">Table 5</ref>: Ablation study on SSA and other modules differing sensor sizes. For every pair, a source image is taken with the base ISO level while the noisy image is taken with higher ISO and appropriately adjusted exposure time.</p><p>The reference image undergoes careful post-processing involving small camera shift adjustment, linear intensity scaling, and removal of low-frequency bias. The post-processed image serves as ground truth for the DND benchmark. We evaluate the performance of our method on the DND dataset which contains 50 images for testing. It provides bounding boxes for extracting 20 patches from each image, resulting in 1000 patches in total. Note that the DND dataset does not provide any training data, so we employ a training strategy by combining the dataset of SIDD and Renoir <ref type="bibr" target="#b2">[3]</ref>. Results are submitted to the DND benchmark by utilizing the same model that provides the best validation performance on the SIDD benchmark.</p><p>Follow to MIRNet, we only use SIDD training set and the same augmentation strategy to train our NBNet. <ref type="table" target="#tab_4">Table 2</ref> shows the results of various methods, we can notice that NBNet can provide a better PSNR compared to MIRNet's 39.88 dB with just a fractional of both computational cost and the number of parameters of MIRNet mentioned in section 4.3. Visual results compared to other methods on DND are also provided in <ref type="figure">Fig 5.</ref> Our method can provide a clean output image while preserving the textures and sharpness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Ablation Study</head><p>We examine three major determinants of our model: a) SSA module for another network, and b) the dimension of the signal subspace, i.e. the number of basis vectors K. c)  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1.">Integrated into DnCNN</head><p>For evaluating the effectiveness of our proposed SSA module, we consider another classical architecture DnCNN as a baseline. In order to use X 1 and X 2 shown in Equation 2, we regarded the feature of the first convolution as X 1 and the feature before the last convolution as X 2 . The results are shown in <ref type="table" target="#tab_12">Table 7</ref>. DnCNN + Concat achieves about 0.2dB higher than DnCNN by simply concatenating X 1 and X 2 to utilizing the different level features, while the DnCNN + SSA with our SSA module achieves about 0.5dB higher than DnCNN. <ref type="table" target="#tab_10">Table 6</ref> provides the results on SIDD with different K values. When the number of basis vectors K is set to 32, our model does not converge. In this setting, as the number of channels in the first stage is also 32, the SSA module does cannot work effectively as subspace projection since K equals to the full dimension size. On the other hand, the higher dimension of the subspace may increase the difficulty of model fitting, hence cause instability of training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2.">Influence about Different k Values</head><p>The rest experiments shows that the best choice of K is 16. If K equals 1, the information kept in the subspace is insufficient and cause significant information loss in the skip-connection. Setting K to 8 and 16 leads to comparable performance, and the SSA module might create a lowdimensional, compact, or classifiable subspace. Therefore, we can see that the subspace dimension K is a robust hyperparameter in a reasonable range.  </p><formula xml:id="formula_6">1 P roj(X 1 , X 1 ) - 2 P roj(X 1 , X 2 ) 39.02 3 P roj(X 2 , X 2 ) 38.48 4 P roj(X 2 , X 1 ) - 5 P roj(X 2 , X 1 &amp;X 2 )</formula><p>39.68 6 P roj(X 1 , X 1 &amp;X 2 ) 39.75 <ref type="table">Table 8</ref>: Ablation study on projections and '-' denotes nonconvergence</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3.">Options about Projection</head><p>In <ref type="table">Table 8</ref>, we evaluate different options about projection: how to generate basis vectors and how to select feature maps for projection. Let's denote P roj(a, b) as a projection operation where a is projected to the basis generated based on b. As shown in first and second rows in <ref type="table">Table 8</ref>, basis generation based only on X 1 makes training unstable, resulting in non-convergence. On the contrary, compare third and forth rows, basis generation based on only X 2 enables the network to be trainable, but get unsatisfactory results. The best results are shown in the last two rows. The network achieves better performance by considering both X 1 and X 2 . Therefore, projecting X 1 on the basis generated by X 1 and X 2 obtains the best PSNR, which is 39.75 dB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Basis Visualization and Discussion</head><p>To gain insight about how the learned subspace projection works , we pick a sample image and inspect the subspace generated by the SSA module. <ref type="figure" target="#fig_1">Fig 7 plots the 16</ref> basis vectors together with the prediction with and without the SSA module. It can be seen that when SSA is enabled, the dotted texture in the dark region is recovered in a way consistent with other part of the patch. This is different when SSA is disabled: the network simply blurs the upper area. Same phenomenon is also observed in <ref type="figure" target="#fig_1">Fig 6</ref> where NBNet outperforms other methods in weak-textured regions.</p><p>Not surprisingly, this phenomenon finds its root in the projection basis vectors. As shown in the left side of <ref type="figure">Fig 7,</ref> many of the 16 channels contain the dots pattern that evenly span the whole image patch. We can thus reasonably surmise that this improvement should be attributed to the nonlocal correlation created by the SSA module: the weak textures on the upper part are supported by the similar occur-UNet (31.81 dB) Visualization of basis SSA (32.15 dB) <ref type="figure">Figure 7</ref>: Left: the basis vectors that span the projection subspace. It can be seen that the dotted pattern is captured in the channels. Right: denoising results with and without the SSA module. When SSA is used, the weak texture in the upper part is recovered better and appear more consistent with other parts of the image.</p><p>rence in other parts of the image, and the projection reconstructs the texture by combining the basis with globally determined coefficients. A conventional convolutional neural network, on the contrary, rely on responses of fixed-valued local filters and coarse information from downsampled features. When the filter response is insignificant and coarse information is blurry, e.g. in the weak texture areas, nonlocal information can hardly improve local responses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this study, we revisit the problem of image denoising and provide a new prospective of subpsace projection. Instead of relying on complicate network architecture or accurate image noise modeling, the proposed subspace basis generation and projection operation can naturally introduce global structure information into denoising process and achieve better local detail preserving. We further demonstrate such basis generation and projection can be learned with SSA in end-to-end fashion and yield better efficiency than adding convolutional blocks. We believe subspace learning is a promising direction for image denoising as well as other low-level vision tasks, and it is worth further exploration.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 3 :</head><label>3</label><figDesc>Overall architecture of NBNet and structure of key building blocks. NBNet is based on UNet architecture with a depth of 5 and our SSA module is used to project features of skip-connection from the encoder.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 6 :</head><label>6</label><figDesc>Results of Gaussian noise reduction. Our method obtains better visual results in the flower area.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>23.66 24.71 25.58 25.65 25.78 26.76 26.88 27.11 30.78 38.71 39.28 39.47 39.72 39.75 SSIM ? 0.583 0.641 0.792 0.685 0.809 0.699 0.842 0.870 0.754 0.914 0.909 0.918 0.959 0.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>NBNet</cell></row><row><cell>[50]</cell><cell>[10] [37] [13]</cell><cell>[19]</cell><cell>[9]</cell><cell>[2]</cell><cell>[55]</cell><cell>[39]</cell><cell>[4]</cell><cell>[47] [48]</cell><cell>[49]</cell><cell>ours</cell></row><row><cell>PSNR ?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>Method DnCNN MLP FoE BM3D WNNM NLM KSVD EPLL CBDNet RIDNet VDN DANet MIRNet973 Table 1: Denoising comparisons on the SIDD [1] dataset .</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>34.51 36.49 37.38 37.61 37.94 38.06 39.26 39.38 39.59 39.88 39.89 SSIM ? 0.851 0.898 0.929 0.942 0.940 0.942 0.953 0.952 0.955 0.956 0.955</figDesc><table><row><cell cols="10">Method BM3D KSVD MCWNNM FFDNet+ TWSC CBDNet RIDNet VDN DANet MIRNet NBNet</cell></row><row><cell>[13]</cell><cell>[2]</cell><cell>[46]</cell><cell>[52]</cell><cell>[45]</cell><cell>[39]</cell><cell>[4]</cell><cell>[47] [48]</cell><cell>[49]</cell><cell>ours</cell></row><row><cell>PSNR ?</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 :</head><label>2</label><figDesc>Denoising comparisons on the DND<ref type="bibr" target="#b32">[33]</ref> dataset.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Methods</cell><cell></cell></row><row><cell cols="2">Cases Datasets</cell><cell cols="7">CBM3D WNNM NCSR MLP DnCNN-B MemNet FFDNet FFDNet v UDNet VDN Ours</cell></row><row><cell></cell><cell></cell><cell>[39]</cell><cell>[19]</cell><cell>[16] [10]</cell><cell>[50]</cell><cell>[40]</cell><cell>[52]</cell><cell>[52]</cell><cell>[24] [47]</cell></row><row><cell></cell><cell>Set5</cell><cell>27.76</cell><cell cols="2">26.53 26.62 27.26</cell><cell>29.85</cell><cell>30.10</cell><cell>30.16</cell><cell>30.15</cell><cell>28.13 30.39 30.59</cell></row><row><cell>Case 1</cell><cell cols="2">LIVE1 26.58</cell><cell cols="2">25.27 24.96 25.71</cell><cell>28.81</cell><cell>28.96</cell><cell>28.99</cell><cell>28.96</cell><cell>27.19 29.22 29.40</cell></row><row><cell></cell><cell cols="2">BSD68 26.51</cell><cell cols="2">25.13 24.96 25.58</cell><cell>28.73</cell><cell>28.74</cell><cell>28.78</cell><cell>28.77</cell><cell>27.13 29.02 29.16</cell></row><row><cell></cell><cell>Set5</cell><cell>26.34</cell><cell cols="2">24.61 25.76 25.73</cell><cell>29.04</cell><cell>29.55</cell><cell>29.60</cell><cell>29.56</cell><cell>26.01 29.80 29.88</cell></row><row><cell>Case 2</cell><cell cols="2">LIVE1 25.18</cell><cell cols="2">23.52 24.08 24.31</cell><cell>28.18</cell><cell>28.56</cell><cell>28.58</cell><cell>28.56</cell><cell>25.25 28.82 29.01</cell></row><row><cell></cell><cell cols="2">BSD68 25.28</cell><cell cols="2">23.52 24.27 24.30</cell><cell>28.15</cell><cell>28.36</cell><cell>28.43</cell><cell>28.42</cell><cell>25.13 28.67 28.76</cell></row><row><cell></cell><cell>Set5</cell><cell>27.88</cell><cell cols="2">26.07 26.84 26.88</cell><cell>29.13</cell><cell>29.51</cell><cell>29.54</cell><cell>29.49</cell><cell>27.54 29.74 29.89</cell></row><row><cell>Case 3</cell><cell cols="2">LIVE1 26.50</cell><cell cols="2">24.67 24.96 25.26</cell><cell>28.17</cell><cell>28.37</cell><cell>28.39</cell><cell>28.38</cell><cell>26.48 28.65 28.82</cell></row><row><cell></cell><cell cols="2">BSD68 26.44</cell><cell cols="2">24.60 24.95 25.10</cell><cell>28.11</cell><cell>28.20</cell><cell>28.22</cell><cell>28.20</cell><cell>26.44 28.46 28.59</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>The PSNR (dB) results of all competing methods on the three groups of test datasets. The best and second best results are highlighted in bold and Italic, respectively.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4 :</head><label>4</label><figDesc>The PSNR(dB) results of all competing methods on AWGN noise cases of three test datasets.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc>Effects of subspace dimensionality K on SIDD.</figDesc><table><row><cell>Our model does not converge when K=32</cell></row><row><cell>the options about projection.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>Ablation study on DnCNN architecture</figDesc><table><row><cell>Method</cell><cell>PSNR(dB)</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A high-quality denoising dataset for smartphone cameras</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Abdelhamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael S</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1692" to="1700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">K-svd: An algorithm for designing overcomplete dictionaries for sparse representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Aharon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alfred</forename><surname>Bruckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Renoir-a dataset for real low-light image noise reduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josue</forename><surname>Anaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Barbu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.8230</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Real image denoising with feature attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Barnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Identity enhanced image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Saeed</forename><surname>Anwar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cong</forename><forename type="middle">P</forename><surname>Huynh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatih</forename><surname>Porikli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPRW</title>
		<meeting>CVPRW</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="520" to="521" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="898" to="916" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Contour detection and hierarchical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Arbelaez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charless</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="898" to="916" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Unprocessing images for learned raw denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Brooks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Mildenhall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfan</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dillon</forename><surname>Sharlet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><forename type="middle">T</forename><surname>Barron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11036" to="11045" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartomeu</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Image denoising: Can plain neural networks compete with bm3d?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Harold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Burger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Christian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="1256" to="1272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Image blind denoising with generative adversarial network based noise modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwen</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongyang</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3155" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Trainable nonlinear reaction diffusion: A flexible framework for fast and effective image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Pock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1256" to="1272" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image denoising with blockmatching and 3d filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Image Processing: Algorithms and Systems, Neural Networks, and Machine Learning</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">6064</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-d transform-domain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scalable multi-label annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGCHI</title>
		<meeting>SIGCHI</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="3099" to="3102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Nonlocally centralized sparse representation for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weisheng</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangming</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Image denoising via sparse and redundant representations over learned dictionaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Elad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michal</forename><surname>Aharon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3736" to="3745" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Practical poissonian-gaussian noise modeling and fitting for single-image raw-data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mejdi</forename><surname>Trimeche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1737" to="1754" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Weighted nuclear norm minimization with application to image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangchu</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1026" to="1034" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Natural image denoising with convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Viren</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="769" to="776" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Accurate image super-resolution using very deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiwon</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jung</forename><forename type="middle">Kwon</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1646" to="1654" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Universal denoising networks: a novel cnn architecture for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stamatios</forename><surname>Lefkimmiatis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Automatic estimation and removal of noise from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Szeliski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Sing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="299" to="314" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">When image denoising meets high-level vision tasks: A deep learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bihan</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhangyang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas S</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.04284</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Practical signal-dependent noise parameter estimation from a single noisy image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinhao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masayuki</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Masatoshi</forename><surname>Okutomi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4361" to="4371" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Waterloo exploration database: New challenges for image quality assessment models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kede</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengfang</forename><surname>Duanmu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingbo</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhou</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongliang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1004" to="1016" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Non-local sparse models for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julien</forename><surname>Mairal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Ponce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Sapiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="54" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Image restoration using very deep convolutional encoderdecoder networks with symmetric skip connections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaojiao</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Bin</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2810" to="2818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Matrix Analysis and Applied Linear Algebra. Society for Industrial and Applied Mathematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><forename type="middle">D</forename><surname>Meyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Class-specific poisson denoising by patch-based importance sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Milad</forename><surname>Niknejad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jos?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bioucas-Dias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>M?rio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Figueiredo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02867</idno>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Benchmarking denoising algorithms with real photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Pl?tz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Image denoising using scale mixtures of gaussians in the wavelet domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Portilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasily</forename><surname>Strela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eero P</forename><surname>Wainwright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Simoncelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1338" to="1351" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Dn-resnet: Efficient deep residual network for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Haoyu Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungwon</forename><surname>El-Khamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lee</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.06766</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">U-net: Convolutional networks for biomedical image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. MICCAI</title>
		<meeting>MICCAI</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Nonlinear total variation based noise removal algorithms. Physica D: nonlinear phenomena</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stanley</forename><surname>Leonid I Rudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Emad</forename><surname>Osher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fatemi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Generalized deep image to image regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venkataraman</forename><surname>Santhanam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vlad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry S</forename><surname>Morariu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5609" to="5619" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Toward convolutional blind denoising of real photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guo</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Zifei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Kai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuo</forename><surname>Wangmeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhang</forename><surname>Lei</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.04686</idno>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note type="report_type">In arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Memnet: A persistent memory network for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Tai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoming</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="4539" to="4547" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Attention-guided cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunwei</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuoyong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lunke</forename><surname>Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hong</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Networks</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="177" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep image prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmitry</forename><surname>Ulyanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="9446" to="9454" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Practical deep raw image denoising on mobile devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Yuzhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaming</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ECCV</title>
		<meeting>ECCV</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Image denoising and inpainting with deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junyuan</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linli</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Enhong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="341" to="349" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">A trilateral weighted sparse coding scheme for real-world image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1807.04364</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Multi-channel weighted nuclear norm minimization for real color image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangchu</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Variational denoising network: Toward blind noise modeling and removal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongsheng</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongwei</forename><surname>Yong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. NeurIPS</title>
		<meeting>NeurIPS</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1690" to="1701" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Dual adversarial network: Toward real-world noise removal and noise generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zongsheng</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qian</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.05946</idno>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Learning enriched features for real image restoration and enhancement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Syed Waqas Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Munawar</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Hayat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ling</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shao</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.06792</idno>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunjin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deyu</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning deep cnn denoiser prior for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuhang</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3929" to="3938" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Ffdnet: Toward a fast and flexible solution for cnn-based image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wangmeng</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. on Image Processing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">When awgn-based denoiser meets real noises</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbo</forename><surname>Jiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Huang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03485</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">From noise modeling to blind image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fengyuan</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangyong</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pheng-Ann</forename><surname>Heng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. CVPR</title>
		<meeting>CVPR</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="420" to="429" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">From learning models of natural image patches to whole image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Zoran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yair</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="479" to="486" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
