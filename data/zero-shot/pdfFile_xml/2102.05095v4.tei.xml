<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Is Space-Time Attention All You Need for Video Understanding?</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gedas</forename><surname>Bertasius</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Wang</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Torresani</surname></persName>
						</author>
						<title level="a" type="main">Is Space-Time Attention All You Need for Video Understanding?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T19:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a convolution-free approach to video classification built exclusively on self-attention over space and time. Our method, named "TimeSformer," adapts the standard Transformer architecture to video by enabling spatiotemporal feature learning directly from a sequence of framelevel patches. Our experimental study compares different self-attention schemes and suggests that "divided attention," where temporal attention and spatial attention are separately applied within each block, leads to the best video classification accuracy among the design choices considered. Despite the radically new design, TimeSformer achieves state-of-the-art results on several action recognition benchmarks, including the best reported accuracy on Kinetics-400 and Kinetics-600. Finally, compared to 3D convolutional networks, our model is faster to train, it can achieve dramatically higher test efficiency (at a small drop in accuracy), and it can also be applied to much longer video clips (over one minute long). Code and models are available at: https://github.com/ facebookresearch/TimeSformer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Over the last few years, the field of natural language processing (NLP) has been revolutionized by the emergence of methods based on self-attention <ref type="bibr" target="#b55">(Vaswani et al., 2017a)</ref>. Because of their excellent capabilities at capturing long-range dependencies among words as well as their training scalability, self-attention architectures, such as the Transformer model, represent the current state-of-the-art across a wide range of language tasks, including machine translation <ref type="bibr" target="#b40">(Ott et al., 2018;</ref><ref type="bibr" target="#b9">Chen et al., 2018a)</ref>, question answering <ref type="bibr" target="#b17">(Devlin et al., 2019;</ref><ref type="bibr" target="#b14">Dai et al., 2019)</ref>, and autoregressive word generation <ref type="bibr">Brown et al., 2020)</ref>.</p><p>Video understanding shares several high-level similarities with NLP. First of all, videos and sentences are both sequential. Furthermore, precisely as the meaning of a word can often be understood only by relating it to the other words in the sentence, it may be argued that atomic actions in shortterm segments need to be contextualized with the rest of the video in order to be fully disambiguated. Thus, one would expect the long-range self-attention models from NLP to be highly effective for video modeling as well. However, in the video domain, 2D or 3D convolutions still represent the core operators for spatiotemporal feature learning across different video tasks <ref type="bibr">(Feichtenhofer et al., 2019a;</ref><ref type="bibr" target="#b52">Teed &amp; Deng, 2020;</ref><ref type="bibr" target="#b4">Bertasius &amp; Torresani, 2020)</ref>. While self-attention has shown benefits when applied on top of convolutional layers <ref type="bibr" target="#b59">(Wang et al., 2018a)</ref>, to the best of our knowledge, no attempt to use self-attention as the exclusive building block for video recognition models has been reported.</p><p>In this work we pose the question of whether it may be possible to build a performant convolution-free video architecture by replacing altogether the convolution operator with self-attention. We argue that such a design has the potential to overcome a few inherent limitations of convolutional models for video analysis. First, while their strong inductive biases (e.g., local connectivity and translation equivariance) are undoubtedly beneficial on small training sets, they may excessively limit the expressivity of the model in settings where there is ample availability of data and "all" can be learned from examples. Compared to CNNs, Transformers impose less restrictive inductive biases. This broadens the family of functions they can represent <ref type="bibr" target="#b13">(Cordonnier et al., 2020;</ref><ref type="bibr" target="#b66">Zhao et al., 2020)</ref>, and renders them better suited to modern big-data regimes where there is less need for strong inductive priors. Second, while convolutional kernels are specifically designed to capture short-range spatiotemporal information, they cannot model dependencies that extend beyond the receptive field. While deep stacks of convolutions <ref type="bibr" target="#b47">(Simonyan &amp; Zisserman, 2015;</ref><ref type="bibr" target="#b51">Szegedy et al., 2015;</ref><ref type="bibr" target="#b7">Carreira &amp; Zisserman, 2017)</ref> naturally extend the receptive field, these strategies are inherently limited in capturing long-range dependencies by means of aggregation of shorter-range information. Conversely, the self-attention mechanism can be applied to capture both local as well as global long-range dependencies by directly comparing feature activations at all space-time locations, much beyond the receptive field of traditional convolutional filters. Finally, despite the advances in GPU hardware acceleration, training deep CNNs remains very costly, especially when applied to high-resolution and long videos. Recent work in the stillimage domain <ref type="bibr" target="#b18">(Dosovitskiy et al., 2020;</ref><ref type="bibr">Carion et al., 2020;</ref><ref type="bibr" target="#b66">Zhao et al., 2020)</ref> has demonstrated that Transformers enjoy faster training and inference compared to CNNs, making it possible to construct models with larger learning capacity for the same computational budget.</p><p>Motivated by these observations, we propose a video architecture built exclusively on self-attention. We adapt the image model "Vision Transformer" (ViT) <ref type="bibr" target="#b18">(Dosovitskiy et al., 2020)</ref> to video by extending the self-attention mechanism from the image space to the space-time 3D volume. Our proposed model, named "TimeSformer" (from Time-Space Transformer), views the video as a sequence of patches extracted from the individual frames. As in ViT, each patch is linearly mapped into an embedding and augmented with positional information. This makes it possible to interpret the resulting sequence of vectors as token embeddings which can be fed to a Transformer encoder, analogously to the token features computed from words in NLP.</p><p>One downside of self-attention in standard Transformer is that it requires computing a similarity measure for all pairs of tokens. In our setting, this is computationally costly due to the large number of patches in the video. To address these challenges, we propose several scalable self-attention designs over the space-time volume and empirically evaluate them over large-scale action classification datasets. Among the proposed schemes, we found that the best design is represented by a "divided attention" architecture which separately applies temporal attention and spatial attention within each block of the network. Compared to the established paradigm of convolution-based video architecture, TimeSformer follows a radically different design. Yet, it achieves accuracy comparable, and in some cases superior, to the state-of-theart in this field. We also show that our model can be used for long-range modeling of videos spanning many minutes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Our approach is influenced by recent works that use selfattention for image classification, either in combination with the convolution operator or even as a full replacement for it. Within the former class, Non-Local Networks <ref type="bibr" target="#b60">(Wang et al., 2018b</ref>) employ a non-local mean that effectively generalizes the self-attention function of Transformers <ref type="bibr" target="#b56">(Vaswani et al., 2017b)</ref>. <ref type="bibr" target="#b2">Bello et al. (Bello et al., 2019)</ref> propose a 2D selfattention mechanism that is competitive as a replacement of 2D convolution but gives even stronger results when used to augment convolutional features with self-attention features. Beyond image categorization, Relation Networks <ref type="bibr" target="#b30">(Hu et al., 2018)</ref> and DETR <ref type="bibr">(Carion et al., 2020)</ref> use self-attention on top of convolutional feature maps for object detection.</p><p>Our method is more closely related to image networks leveraging self-attention as a substitute for convolution <ref type="bibr" target="#b41">(Parmar et al., 2018;</ref><ref type="bibr" target="#b45">Ramachandran et al., 2019;</ref><ref type="bibr" target="#b13">Cordonnier et al., 2020;</ref><ref type="bibr" target="#b66">Zhao et al., 2020)</ref>. Since these works use individual pixels as queries, in order to maintain a manageable computational cost and a small memory consumption, they must restrict the scope of self-attention to local neighborhoods or use global self-attention on heavily downsized versions of the image. Alternative strategies for scalability to full images include sparse key-value sampling  or constraining the self-attention to be calculated along the spatial axes <ref type="bibr" target="#b29">(Ho et al., 2019;</ref><ref type="bibr" target="#b31">Huang et al., 2019;</ref><ref type="bibr" target="#b58">Wang et al., 2020b)</ref>. A few of the self-attention operators considered in our experiments adopt similar sparse and axial computation, although generalized to the spatiotemporal volume. However, the efficiency of our approach stems mainly from decomposing the video into a sequence of frame-level patches and then feeding linear embeddings of these patches as input token embeddings to a Transformer. This strategy was recently introduced in Vision Transformers (ViT) <ref type="bibr" target="#b18">(Dosovitskiy et al., 2020)</ref> which were shown to deliver impressive performance on image categorization. In this work, we build on the ViT design, and extend it to video by proposing and empirically comparing several scalable schemes for space-time self-attention over videos.</p><p>While Transformers have been recently used for video generation , we are not aware of prior video recognition architectures using self-attention as the exclusive building block. However, we note that Transformers have been adopted on top of convolutional feature maps for action localization and recognition <ref type="bibr" target="#b26">(Girdhar et al., 2019)</ref>, video classification <ref type="bibr" target="#b60">(Wang et al., 2018b;</ref><ref type="bibr" target="#b10">Chen et al., 2018b)</ref>, and group activity recognition <ref type="bibr" target="#b25">(Gavrilyuk et al., 2020)</ref>. We also note that there is a wide literature based on the use of text Transformers combined with video CNNs to address various video-language tasks, such as captioning <ref type="bibr" target="#b67">(Zhou et al., 2018)</ref>, question-answering <ref type="bibr" target="#b65">(Yang et al., 2020)</ref> and dialog . Finally, multimodal video-text transformers <ref type="bibr" target="#b50">(Sun et al., 2019;</ref><ref type="bibr" target="#b35">Li et al., 2020a)</ref> have also been trained or pretrained in unsupervised fashion by adopting masked-token pretext tasks adapted from the language domain <ref type="bibr" target="#b16">(Devlin et al., 2018;</ref><ref type="bibr" target="#b43">Radford et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The TimeSformer Model</head><p>Input clip. The TimeSformer takes as input a clip X ? R H?W ?3?F consisting of F RGB frames of size H ? W sampled from the original video.</p><p>Decomposition into patches. Following the ViT <ref type="bibr" target="#b18">(Dosovitskiy et al., 2020)</ref>, we decompose each frame into N non-overlapping patches, each of size P ? P , such that the N patches span the entire frame, i.e., N = HW/P 2 . We flatten these patches into vectors x (p,t) ? R 3P 2 with     <ref type="figure">Figure 1</ref>. The video self-attention blocks that we investigate in this work. Each attention layer implements self-attention <ref type="bibr" target="#b56">(Vaswani et al., 2017b</ref>) on a specified spatiotemporal neighborhood of frame-level patches (see <ref type="figure">Figure 2</ref> for a visualization of the neighborhoods). We use residual connections to aggregate information from different attention layers within each block. A 1-hidden-layer MLP is applied at the end of each block. The final model is constructed by repeatedly stacking these blocks on top of each other. p = 1, . . . , N denoting spatial locations and t = 1, . . . , F depicting an index over frames.</p><formula xml:id="formula_0">G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v</formula><formula xml:id="formula_1">G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v</formula><formula xml:id="formula_2">G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v</formula><p>Linear embedding. We linearly map each patch x (p,t) into an embedding vector z </p><p>where e pos (p,t) ? R D represents a learnable positional embedding added to encode the spatiotemporal position of each patch. The resulting sequence of embedding vectors z (0) (p,t) for p = 1, . . . , N , and t = 1, . . . , F represents the input to the Transformer, and plays a role similar to the sequences of embedded words that are fed to text Transformers in NLP. As in the original BERT Transformer <ref type="bibr" target="#b16">(Devlin et al., 2018)</ref>, we add in the first position of the sequence a special learnable vector z (0) (0,0) ? R D representing the embedding of the classification token.</p><p>Query-Key-Value computation. Our Transformer consists of L encoding blocks. At each block , a query/key/value vector is computed for each patch from the representation z ( ?1) (p,t) encoded by the preceding block:</p><formula xml:id="formula_4">q ( ,a) (p,t) = W ( ,a) Q LN z ( ?1) (p,t) ? R D h (2) k ( ,a) (p,t) = W ( ,a) K LN z ( ?1) (p,t) ? R D h (3) v ( ,a) (p,t) = W ( ,a) V LN z ( ?1) (p,t) ? R D h<label>(4)</label></formula><p>where LN() denotes LayerNorm <ref type="bibr" target="#b1">(Ba et al., 2016)</ref>, a = 1, . . . , A is an index over multiple attention heads and A denotes the total number of attention heads. The latent dimensionality for each attention head is set to D h = D/A.</p><p>Self-attention computation. Self-attention weights are computed via dot-product. The self-attention weights ? ? ? ( ,a) (p,t) ? R N F +1 for query patch (p, t) are given by:</p><formula xml:id="formula_5">? ? ? ( ,a) (p,t) = SM ? ? q ( ,a) (p,t) ? D h ? k ( ,a) (0,0) k ( ,a) (p ,t ) p =1,...,N t =1,...,F ? ?<label>(5)</label></formula><p>where SM denotes the softmax activation function. Note that when attention is computed over one dimension only (e.g., spatial-only or temporal-only), the computation is significantly reduced. For example, in the case of spatial attention, only N + 1 query-key comparisons are made, using exclusively keys from the same frame as the query:</p><formula xml:id="formula_6">? ? ? ( ,a)space (p,t) = SM ? ? q ( ,a) (p,t) ? D h ? k ( ,a) (0,0) k ( ,a) (p ,t) p =1,...,N ? ? .<label>(6)</label></formula><p>Encoding. The encoding z ( ) (p,t) at block is obtained by first computing the weighted sum of value vectors using self-attention coefficients from each attention head:  <ref type="figure">Figure 2</ref>. Visualization of the five space-time self-attention schemes studied in this work. Each video clip is viewed as a sequence of frame-level patches with a size of 16 ? 16 pixels. For illustration, we denote in blue the query patch and show in non-blue colors its self-attention space-time neighborhood under each scheme. Patches without color are not used for the self-attention computation of the blue patch. Multiple colors within a scheme denote attentions separately applied along different dimensions (e.g., space and time for (T+S)) or over different neighborhoods (e.g., for (L+G)). Note that self-attention is computed for every single patch in the video clip, i.e., every patch serves as a query. We also note that although the attention pattern is shown for only two adjacent frames, it extends in the same fashion to all frames of the clip.</p><formula xml:id="formula_7">s ( ,a) (p,t) = ? ( ,a) (p,t),(0,0) v ( ,a) (0,0) + N p =1 F t =1 ? ( ,a) (p,t),(p ,t ) v ( ,a) (p ,t ) .<label>(7)</label></formula><p>Then, the concatenation of these vectors from all heads is projected and passed through an MLP, using residual connections after each operation:</p><formula xml:id="formula_8">z ( ) (p,t) = W O ? ? ? ? s ( ,1) (p,t) . . . s ( ,A) (p,t) ? ? ? ? + z ( ?1) (p,t) (8) z ( ) (p,t) = MLP LN z ( ) (p,t) + z ( ) (p,t) .<label>(9)</label></formula><p>Classification embedding. The final clip embedding is obtained from the final block for the classification token:</p><formula xml:id="formula_9">y = LN z (L) (0,0) ? R D .<label>(10)</label></formula><p>On top of this representation we append a 1-hidden-layer MLP, which is used to predict the final video classes.</p><p>Space-Time Self-Attention Models. We can reduce the computational cost by replacing the spatiotemporal attention of Eq. 5 with spatial attention within each frame only (Eq. 6). However, such a model neglects to capture temporal dependencies across frames. As shown in our experiments, this approach leads to degraded classification accuracy compared to full spatiotemporal attention, especially on benchmarks where strong temporal modeling is necessary.</p><p>We propose a more efficient architecture for spatiotemporal attention, named "Divided Space-Time Attention" (denoted with T+S), where temporal attention and spatial attention are separately applied one after the other. This architecture is compared to that of Space and Joint Space-Time attention in <ref type="figure">Fig. 1</ref>. A visualization of the different attention models on a video example is given in <ref type="figure">Fig. 2</ref>. For Divided Attention, within each block , we first compute temporal attention by comparing each patch (p, t) with all the patches at the same spatial location in the other frames:</p><formula xml:id="formula_10">? ? ? ( ,a)time (p,t) = SM ? ? q ( ,a) (p,t) ? D h ? k ( ,a) (0,0) k ( ,a) (p,t ) t =1,...,F ? ? .<label>(11)</label></formula><p>The encoding z ( )time <ref type="bibr">(p,t)</ref> resulting from the application of Eq. 8 using temporal attention is then fed back for spatial attention computation instead of being passed to the MLP. In other words, new key/query/value vectors are obtained from z ( )time <ref type="bibr">(p,t)</ref> and spatial attention is then computed using Eq. 6. Finally, the resulting vector z ( )space <ref type="bibr">(p,t)</ref> is passed to the MLP of Eq. 9 to compute the final encoding z  V space } over the time and space dimensions. Note that compared to the (N F + 1) comparisons per patch needed by the joint spatiotemporal attention model of Eq. 5, Divided Attention performs only (N +F +2) comparisons per patch. Our experiments demonstrate that this space-time factorization is not only more efficient but it also leads to improved classification accuracy.</p><p>We have also experimented with a "Sparse Local Global" (L+G) and an "Axial" (T+W+H) attention models. Their architectures are illustrated in <ref type="figure">Fig. 1, while Fig. 2</ref> shows the patches considered for attention by these models. For each patch (p, t), (L+G) first computes a local attention by considering the neighboring F ? H/2 ? W/2 patches and then calculates a sparse global attention over the entire clip using a stride of 2 patches along the temporal dimension and also the two spatial dimensions. Thus, it can be viewed as a faster approximation of full spatiotemporal attention using a local-global decomposition and a sparsity pattern, similar to that used in . Finally, "Axial" attention decomposes the attention computation in three distinct steps: over time, width and height. A decomposed attention over the two spatial axes of the image was proposed in <ref type="bibr" target="#b29">(Ho et al., 2019;</ref><ref type="bibr" target="#b31">Huang et al., 2019;</ref><ref type="bibr" target="#b58">Wang et al., 2020b)</ref> and our (T+W+H) adds a third dimension (time) for the case of video. All these models are implemented by learning distinct query/key/value matrices for each attention step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>We evaluate TimeSformer on four popular action recognition datasets: Kinetics-400 <ref type="bibr" target="#b7">(Carreira &amp; Zisserman, 2017)</ref>, Kinetics-600 <ref type="bibr" target="#b8">(Carreira et al., 2018)</ref>, Something-Something-V2 <ref type="bibr" target="#b28">(Goyal et al., 2017b)</ref>, and Diving-48 <ref type="bibr" target="#b36">(Li et al., 2018)</ref>. We adopt the "Base" ViT architecture <ref type="bibr" target="#b18">(Dosovitskiy et al., 2020)</ref> pretrained on either ImageNet-1K or ImageNet-21K <ref type="bibr" target="#b15">(Deng et al., 2009)</ref>, as specified for each experiment. Unless differently indicated, we use clips of size 8 ? 224 ? 224, with frames sampled at a rate of 1/32. The patch size is 16 ? 16 pixels. During inference, unless otherwise noted, we sample a single temporal clip in the middle of the video. We use 3 spatial crops <ref type="bibr">(top-left, center, bottom-right)</ref> from the temporal clip and obtain the final prediction by averaging the scores for these 3 crops. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Analysis of Self-Attention Schemes</head><p>For this first set of experiments we start from a ViT pretrained on ImageNet-21K. In <ref type="table">Table 1</ref>, we present the results obtained with TimeSformer for the five proposed space-time attention schemes on Kinetics-400 (K400) and Something-Something-V2 (SSv2). First, we note that TimeSformer with space-only attention (S) performs well on K400. This is an interesting finding. Indeed, prior work <ref type="bibr" target="#b46">(Sevilla-Lara et al., 2021)</ref> has shown that on K400, spatial cues are more important than temporal information in order to achieve strong accuracy. Here, we show that it is possible to obtain solid accuracy on K400 without any temporal modeling. Note, however, that space-only attention performs poorly on SSv2. This stresses the importance of temporal modeling on this latter dataset.</p><p>Furthermore, we observe that divided space-time attention achieves the best accuracy on both K400 and SSv2. This makes sense because compared to joint space-time attention, divided space-time attention has a larger learning capacity (see <ref type="table">Table 1</ref>) as it contains distinct learning parameters for temporal attention and spatial attention.</p><p>In <ref type="figure" target="#fig_7">Figure 3</ref>, we also compare the computational cost of joint space-time versus divided space-time attention when using higher spatial resolution (left) and longer (right) videos. We note that the scheme of divided space-time scales gracefully under both of these settings. In contrast, the scheme of joint space-time attention leads to a dramatically higher cost when resolution or video length is increased. In practice, joint space-time attention causes a GPU memory overflow once the spatial frame resolution reaches 448 pixels, or once the number of frames is increased to 32 and thus it is effectively not applicable to large frames or long videos. Thus, despite a larger number of parameters, divided space-time attention is more efficient than joint space-time attention when operating on higher spatial resolution, or longer videos. Thus, for all subsequent experiments we use a TimeSformer constructed with divided space-time self-attention blocks.  <ref type="table" target="#tab_2">Table 2</ref>. Comparing TimeSformer to SlowFast and I3D. We observe that TimeSformer has lower inference cost despite having a larger number of parameters. Furthermore, the cost of training TimeSformer on video data is much lower compared to SlowFast and I3D, even when all models are pretrained on ImageNet-1K.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Comparison to 3D CNNs</head><p>In this subsection we perform an empirical study aimed at understanding the distinguishing properties of TimeSformer compared to 3D convolutional architectures, which have been the prominent approach to video understanding in recent years. We focus our comparison on two 3D CNN models: 1) SlowFast <ref type="bibr" target="#b24">(Feichtenhofer et al., 2019b)</ref>, which is the state-of-the-art in video classification, and 2) I3D (Carreira &amp; Zisserman, 2017), which has been shown to benefit from image-based pretraining, similarly to our own model. We present quantitative comparisons to these two networks in <ref type="table" target="#tab_2">Table 2</ref> and highlight key observations below.</p><p>Model Capacity. From  (i.e., 448 GPU hours), its accuracy drops to 70.0%. Similarly, training I3D using a similar computational budget (i.e., 444 GPU hours) leads to a lower accuracy of 71.0%. This highlights the fact that some of the latest 3D CNNs <ref type="bibr" target="#b24">(Feichtenhofer et al., 2019b;</ref><ref type="bibr" target="#b21">Feichtenhofer, 2020</ref>) require a very long optimization schedule to achieve good performance (even when using ImageNet pretraining). In contrast, TimeSformer provides a more efficient alternative to labs that do not have access to hundreds of GPUs.</p><p>The Importance of Pretraining. Due to a large number of parameters, training our model from scratch is difficult. Thus, before training TimeSformer on video data, we initialize it with weights learned from ImageNet. In contrast, SlowFast can be learned on video data from scratch although at the expense of a very high training cost (see <ref type="table" target="#tab_2">Table 2</ref>). We also attempted to train TimeSformer on Kinetics-400 directly, without any ImageNet pretraining. By using a longer training schedule and more data augmentations, we found it possible to train the model from scratch, albeit to a much lower video level accuracy of 64.8%. Thus, based on these results, for all subsequent studies we continued to use Ima-geNet for pretraining <ref type="bibr" target="#b15">(Deng et al., 2009)</ref> In The Impact of Video-Data Scale. To understand the effects of video-data scale on performance, we trained TimeSformer on different subsets of K400 and SSv2: {25%, 50%, 75%, 100%} of the full datasets. We show these results in <ref type="figure">Figure 4</ref>, where we also compare our method with SlowFast R50 <ref type="bibr" target="#b24">(Feichtenhofer et al., 2019b)</ref>, and I3D R50 <ref type="bibr" target="#b7">(Carreira &amp; Zisserman, 2017</ref>) trained on the same subsets and using the same pretraining. Since we do not have access to a ResNet pretrained on ImageNet-21K, we use ImageNet-1K pretraining for all 3 architectures.</p><p>The results of <ref type="figure">Figure 4</ref> show that, on K400, TimeSformer outperforms the other models for all training subsets. However, we observe a different trend on SSv2, where TimeSformer is the strongest model only when trained on 75% or 100% of the full data. This may be explained by the fact that compared to K400, SSv2 requires learning more complex temporal patterns, and thus more examples are needed by TimeSformer to learn effectively those patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Varying the Number of Tokens</head><p>The scalability of our model allows it to operate at higher spatial resolution and on longer videos compared to most 3D CNNs. We note that both of these aspects affect the length of the sequence of tokens fed to the Transformer. Specifically, increasing the spatial resolution results in a higher number of patches (N ) per frame. The number of input tokens is also increased when using more frames. To investigate the benefits, we conduct an empirical study where we separately increase the number of tokens along each of these two axes.</p><p>We report the findings in <ref type="figure">Figure 5</ref>. We see that increasing the spatial resolution (up to a certain point) leads to a boost in performance. Similarly, we observe that increasing the length of the input clip leads to consistent accuracy gains. Due to GPU memory constraints, we are not able to test our model on clips longer than 96 frames. Still, we would like to point out that using clips of 96 frames is a significant departure from current convolutional models, which are typically limited to processing inputs of 8 ? 32 frames.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">The Importance of Positional Embeddings</head><p>To investigate the importance of our learned spatiotemporal positional embeddings, we also conduct experiments with a few variants of TimeSformer that use: (1) no positional embedding, (2) space-only positional embedding, and (3) space-time positional embedding. We report these results in <ref type="table" target="#tab_6">Table 4</ref>. Based on these results, we observe that the variant of our model that uses space-time positional embeddings produces the best accuracy on both Kinetics-400, and Something-Something-V2. Interestingly, we also observe that using space-only positional embeddings leads to solid results on Kinetics-400, but much worse results on Something-Something-V2. This makes sense as Kinetics-400 is more spatially biased, whereas Something-Something-V2 requires complex temporal reasoning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Comparison to the State-of-the-Art</head><p>Kinetics-400 &amp; Kinetics-600. In <ref type="table">Table 5</ref> we present our results on the validation set of K400. For these experiments, we use TimeSformer pretrained on ImageNet-21K. In addition to the accuracy metrics, we also include inference cost, given in TFLOPs. We note that whereas most previous Method Top-1 Top-5 TFLOPs R(2+1)D  72.0 90.0 17.5 bLVNet  73.5 91.2 0.84 TSM <ref type="bibr" target="#b38">(Lin et al., 2019)</ref> 74.7 N/A N/A S3D-G <ref type="bibr" target="#b64">(Xie et al., 2018)</ref> 74.7 93.4 N/A Oct-I3D+NL  75.7 N/A 0.84 D3D <ref type="bibr" target="#b49">(Stroud et al., 2020)</ref> 75.9 N/A N/A I3D+NL <ref type="bibr" target="#b60">(Wang et al., 2018b)</ref> 77.7 93.3 10.8 ip-CSN-152 <ref type="bibr" target="#b54">(Tran et al., 2019)</ref> 77.8 92.8 3.2 CorrNet <ref type="bibr" target="#b57">(Wang et al., 2020a)</ref> 79.2 N/A 6.7 LGD-3D-101 <ref type="bibr" target="#b42">(Qiu et al., 2019)</ref> 79.4 94.4 N/A SlowFast <ref type="bibr">(Feichtenhofer et al., 2019b) 79.8 93.9</ref> 7.0 X3D-XXL <ref type="bibr" target="#b21">(Feichtenhofer, 2020)</ref> 80  <ref type="table">Table 5</ref>. Video-level accuracy on Kinetics-400.</p><p>Is Space-Time Attention All You Need for Video Understanding?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Top-1 Top-5 I3D-R50+Cell <ref type="bibr" target="#b61">(Wang et al., 2020c)</ref> 79.8 94.4 LGD-3D-101 <ref type="bibr" target="#b42">(Qiu et al., 2019)</ref> 81.5 95.6 SlowFast <ref type="bibr" target="#b24">(Feichtenhofer et al., 2019b)</ref> 81.8 95.1 X3D-XL <ref type="bibr" target="#b21">(Feichtenhofer, 2020)</ref> 81  <ref type="figure">Figure 6</ref>. Video-level accuracy on Kinetics-400 vs the number of temporal clips used during inference. TimeSformer-L achieves excellent accuracy using a small number of clips, which leads to strong performance at low inference cost. methods use 10 temporal clips with 3 spatial crops (for a total of 30 space-time views) during inference, TimeSformer achieves solid accuracy with only 3 views (3 spatial crops), which reduces the inference cost. Our long-range variant, TimeSformer-L achieves a top-1 accuracy of 80.7%. Furthermore, our default TimeSformer has the lowest inference cost among recent state-of-the-art models. Yet, it still provides a solid accuracy of 78.0%, outperforming many more costly models.</p><p>We also measured the actual inference runtime on 20K validation videos of Kinetics-400 (using 8 Tesla V100 GPUs). Whereas SlowFast takes 14.88 hours to complete the inference, TimeSformer, TimeSformer-HR, and TimeSformer-L take 36 minutes, 1.06 hours and 2.6 hours, respectively. Thus, even though SlowFast and TimeSformer-L have comparable cost in terms of TFLOPs, in practice the runtimes of all our versions of TimeSformer are much lower.</p><p>In <ref type="table">Table 6</ref>, we also present our results on Kinetics-600. Just like on Kinetics-400, we observe that TimeSformer performs well on this benchmark, outperforming all prior methods.</p><p>Finally, in <ref type="figure">Figure 6</ref>, we study the effect of using multiple temporal clips during inference (each with a single spatial crop). We plot accuracy using K ? {1, 3, 5, 10} temporal clips for testing. We compare our model against X3D <ref type="bibr" target="#b21">(Feichtenhofer, 2020)</ref>, and SlowFast <ref type="bibr" target="#b24">(Feichtenhofer et al., 2019b)</ref>. X3D and SlowFast require multiple (? 5) clips to approach their top accuracy. Conversely, our longrange variant, TimeSformer-L, does not require multiple clips to achieve its best performance, since it is able to span Method SSv2 Diving-48 * * SlowFast <ref type="bibr" target="#b24">(Feichtenhofer et al., 2019b)</ref> 61.7 77.6 TSM <ref type="bibr" target="#b38">(Lin et al., 2019)</ref> 63.4 N/A STM <ref type="bibr" target="#b32">(Jiang et al., 2019)</ref> 64.2 N/A MSNet <ref type="bibr" target="#b33">(Kwon et al., 2020)</ref> 64.7 N/A TEA <ref type="bibr" target="#b37">(Li et al., 2020b)</ref> 65.1 N/A bLVNet  65. about 12 seconds of a Kinetics video with a single clip.</p><p>Something-Something-V2 &amp; Diving-48. In <ref type="table">Table 7</ref>, we also validate our model on SSv2 and Diving-48. Since ImageNet-21K pretraining does not improve accuracy on SSv2 (see <ref type="table" target="#tab_3">Table 3</ref>), in this case, we use TimeSformer pretrained on ImageNet-1K. This also allows us to apply the same pretraining to all other models in this comparison, using a ResNet pretrained on ImageNet-1K. Our results suggest that TimeSformer achieves lower accuracy than the best models on this dataset. However, considering that our model uses a completely different design, we take these results as suggesting that TimesSformer is a promising approach even for challenging temporally-heavy datasets, such as SSv2.</p><p>In <ref type="table">Table 7</ref>, we also present our method on another "temporally-heavy" dataset, Diving-48. Due to a recently discovered issue with a previous version of Diving-48 labels, here, we only compare our method with a reproduced Slow-Fast 16?8 R101 model. Our results show that TimeSformer outperforms SlowFast by a substantial margin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6.">Long-Term Video Modeling</head><p>Lastly, we evaluate TimeSformer on the task of long-term video modeling using HowTo100M <ref type="bibr" target="#b39">(Miech et al., 2019)</ref>. HowTo100M is an instructional video dataset that contains around 1M instructional Web videos showing humans performing over 23K different tasks, such as cooking, repairing, making arts, etc. The average duration of these videos is around 7 minutes, which is orders of magnitude longer than the duration of videos in standard action recognition benchmarks. Each HowTo100M video has a label indicating the task demonstrated in the video (one out of the 23K classes), which can be used for supervised training. Thus, it is a good benchmark to assess the ability of a model to recognize activities exhibited over very long temporal extents.</p><p>For this evaluation, we consider only categories that have at least 100 video examples. This gives a subset of HowTo100M corresponding to 120K videos spanning 1059 task categories. We randomly partition this collection into 85K training videos and 35K testing videos. Table 8. Long-term task classification on HowTo100M. Given a video spanning several minutes, the goal is to predict the long-term task demonstrated in the video (e.g., cooking breakfast, cleaning house, etc). We evaluate a few variants of SlowFast and TimeSformer on this task. "Single Clip Coverage" denotes the number of seconds spanned by a single clip. "# Test Clips" is the average number of clips needed to cover the entire video during inference. All models in this comparison are pretrained on Kinetics-400.</p><p>We present our results in <ref type="table">Table 8</ref>. As our baselines, we use four variants of SlowFast R101, all operating on video clips sampled at a frame rate of 1/32 but having varying number of frames: 8, 32, 64 and 96. We use the same four configurations for TimeSformer, starting from a ViT pretrained on ImageNet-21K. All models in this comparison are pretrained on Kinetics-400 before finetuning on HowTo100M.</p><p>During inference, for each method, we sample as many non-overlapping temporal clips as needed to cover the full temporal extent of a video, e.g., if a single clip spans 8.5 seconds, we would sample 48 test clips to cover a video of 410 seconds. Video-level classification is done by averaging the clip predictions.</p><p>From the results in <ref type="table">Table 8</ref> we first note that, for the same single clip coverage, TimeSformer outperforms the corresponding SlowFast by a large margin of 8 ? 11%. We also observe that longer-range TimeSformers do better, i.e., our longest-range variant achieves the best video-level classification accuracy. These results suggest that our model is highly suitable for tasks that require long-term video modeling.</p><p>We also experimented with finetuning TimeSformer directly from a ViT pretrained on ImageNet-1K and ImageNet-21K (skipping the Kinetics-400 training). We report that when pretrained only on ImageNet-1K, our model achieves top-1 accuracies of 52.8, 58.4, 59.2, 59.4 for 8, 32, 64, 96 frame inputs, respectively. When considering ImagNet-21K pretraining, TimeSformer produces top-1 accuracies of 56.0, 59.2, 60.2, 62.1 for 8, 32, 64, 96 frame inputs, respectively. These results demonstrate that our model can effectively exploit long-range temporal dependencies regardless of the pretraining dataset that we use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7.">Additional Ablations</head><p>Smaller &amp; Larger Transformers. In addition to the "Base" ViT model <ref type="bibr" target="#b18">(Dosovitskiy et al., 2020)</ref>, we also experimented with the "Large" ViT. We report that this yielded results 1% worse on both Kinetics-400, and Something-Something-V2. Given that our "Base" model already has 121M parameters, we suspect that the current datasets are not big enough to justify a further increase in model capacity. We also tried the "Small" ViT variant, which produced accuracies about 5% worse than our default "Base" ViT model.</p><p>Larger Patch Size. We also experimented with a different patch size, i.e., P = 32. We report that this variant of our model produced results about 3% worse than our default variant using P = 16. We conjecture that the performance decrease with P = 32 is due to the reduced spatial granularity. We did not train any models with P values lower than 16 as those models have a much higher computational cost.</p><p>The Order of Space and Time Self-Attention. Our proposed "Divided Space-Time Attention" scheme applies temporal attention and spatial attention one after the other. Here, we investigate whether reversing the order of time-space attention (i.e., applying spatial attention first, then temporal) has an impact on our results. We report that applying spatial attention first, followed by temporal attention leads to a 0.5% drop in accuracy on both Kinetics-400, and Something-Something-V2. We also tried a parallel spacetime self-attention. We report that it produces 0.4% lower accuracy compared to our adopted "Divided Space-Time Attention" scheme.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8.">Qualitative Results</head><p>Visualizing Learned Space-Time Attention. In <ref type="figure">Figure 7</ref>, we present space-time attention visualizations obtained by applying TimeSformer on Something-Something-V2 videos. To visualize the learned attention, we use the Attention Rollout scheme presented in <ref type="bibr" target="#b0">(Abnar &amp; Zuidema, 2020)</ref>. Our results suggest that TimeSformer learns to attend to the relevant regions in the video in order to perform complex spatiotemporal reasoning. For example, we can observe that the model focuses on the configuration of the hand when visible and the object-only when not visible.</p><p>Visualizing Learned Feature Embeddings. In <ref type="figure">Figure 8</ref>, we also visualize the features learned by TimeSformer on Something-Something-V2. The visualization is done using t-SNE (van der <ref type="bibr" target="#b54">Maaten &amp; Hinton, 2008)</ref> where each point represents a single video, and different colors depict different action categories. Based on this illustration, we observe that TimeSformer with divided space-time attention learns semantically more separable features than the TimeSformer with space-only attention or ViT <ref type="bibr" target="#b18">(Dosovitskiy et al., 2020)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we introduced TimeSformer, a fundamentally different approach to video modeling compared to the established paradigm of convolution-based video networks. We showed that it is possible to design an effective, and scalable video architecture built exclusively on space-time self-attention. Our method (1) is conceptually simple, (2) achieves state-of-the-art results on major action recognition benchmarks, (3) has low training and inference cost, and (4) can be applied to clips of over one minute, thus enabling long-term video modeling. In the future, we plan to extend our method to other video analysis tasks such as action localization, video captioning and question-answering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Implementation Details</head><p>Our TimeSformer implementation is built using PySlow-Fast <ref type="bibr">(Fan et al., 2020)</ref> and pytorch-image-models (Wightman, 2019) packages. Below, we describe specific implementation details regarding the training and inference procedures of our model.</p><p>Training. We train our model for 15 epochs with an initial learning rate of 0.005, which is divided by 10 at epochs 11, and 14. During training, we first resize the shorter side of the video to a random value in <ref type="bibr">[256,</ref><ref type="bibr">320]</ref>. We then randomly sample a 224 ? 224 crop from the resized video. For our high-resolution model, TimeSformer-HR, we resize the shorter side of the video to a random value in <ref type="bibr">[448,</ref><ref type="bibr">512]</ref>, and then randomly sample a 448 ? 448 crop. We randomly sample clips from the full-length videos with a frame rate of 1/32. The batch size is set to 16. We train all our models using synchronized SGD across 32 GPUs. The momentum is set to 0.9, while the weight decay is set to 0.0001.</p><p>Unless otherwise noted, in our experiments we use the "Base" ViT model <ref type="bibr" target="#b18">(Dosovitskiy et al., 2020)</ref>. Temporal and spatial attention layers in each block are initialized with the same weights, which are obtained from the corresponding attention layer in ViT.</p><p>Inference. As discussed in the main draft, during inference we sample a single temporal clip in the middle of the video. We scale the shorter spatial side of a video to 224 pixels (or 448 for TimeSformer-HR) and take 3 crops of size 224?224 (448 ? 448 for TimeSformer-HR) to cover a larger spatial extent within the clip. The final prediction is obtained by averaging the softmax scores of these 3 predictions.</p><p>Other models in our comparison. To train I3D <ref type="bibr" target="#b7">(Carreira &amp; Zisserman, 2017)</ref>, and SlowFast <ref type="bibr" target="#b24">(Feichtenhofer et al., 2019b)</ref>, we use the training protocols that were used in the original papers. For I3D, we initialize it with a 2D ImageNet CNN, and then train it for 118 epochs with a base learning rate of 0.01, which is divided by 10 at epochs 44 and 88. We use synchronized SGD across 32 GPUs following the linear scaling recipe of <ref type="bibr" target="#b27">Goyal et al. (2017a)</ref>. We set the momentum to 0.9, and weight decay to 0.0001. The batch size is set to 64. For the SlowFast model, when initialized from ImageNet weights, we use this same exact training protocol. When training SlowFast from scratch, we use the training protocol described by the authors <ref type="bibr" target="#b24">(Feichtenhofer et al., 2019b)</ref>. More specifically, in that case, the training is done for 196 epochs with a cosine learning rate schedule, and the initial learning rate is set to 0.1. We use a linear warm-up for the first 34 epochs starting with a learning rate of 0.01. A dropout of 0.5 is used before the final classification layer. The momentum is set to 0.9, the weight decay is 0.0001, and the batch size is set to 64. Just as before, we adopt the linear scaling recipe <ref type="bibr" target="#b27">(Goyal et al., 2017a)</ref>.</p><p>Datasets. Kinetics-400 (Carreira &amp; Zisserman, 2017) consists of 240K training videos and 20K validation videos that span 400 human action categories. Kinetics-600 (Carreira et al., 2018) has 392K training videos and 30K validation videos spanning 600 action categories. Something-Something-V2 <ref type="bibr" target="#b28">(Goyal et al., 2017b)</ref> contains 170K training videos and 25K validation videos that span 174 action categories. Lastly, Diving-48 <ref type="bibr" target="#b36">(Li et al., 2018)</ref> has 16K training videos and 3K testing videos spanning 48 fine-grained diving categories. For all of these datasets, we use standard classification accuracy as our main performance metric.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>&lt;</head><label></label><figDesc>l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; Time Att. Space Att. &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j qK I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; MLP &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; Space Att. MLP &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; Joint Space-Time Att. &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; Time Att. Width Att. &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; MLP &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; Height Att. &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " N 4 z t u 7 r A 6 G c W P A 6 n A D Z 8 t M O c v q E = " &gt; A A A B 7 X i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y K o M e g F 4 8 R z A O S J c x O Z p M x s z P L T K 8 Q Q v 7 B i w d F v P o / 3 v w b J 8 k e N L G g o a j q p r s r S q W w 6 P v f X m F t f W N z q 7 h d 2 t n d 2 z 8 o H x 4 1 r c 4 M 4 w 2 m p T b t i F o u h e I N F C h 5 O z W c J p H k r W h 0 O / N b T 9 x Y o d U D j l M e J n S g R C w Y R S c 1 u z q V m e 2 V K 3 7 V n 4 O s k i A n F c h R 7 5 W / u n 3 N s o Q r Z J J a 2 w n 8 F M M J N S i Y 5 N N S N 7 M 8 p W x E B 7 z j q K I J t + F k f u 2 U n D m l T 2 J t X C k k c / X 3 x I Q m 1 o 6 T y H U m F I d 2 2 Z u J / 3 m d D O P r c C J U m i F X b L E o z i R B T W a v k 7 4 w n K E c O 0 K Z E e 5 W w o b U U I Y u o J I L I V h + e Z U 0 L 6 q B X w 3 u L y u 1 m z y O I p z A K Z x D A F d Q g z u o Q w M Y P M I z v M K b p 7 0 X 7 9 3 7 W L Q W v H z m G P 7 A + / w B z / 6 P R Q = = &lt; / l a t e x i t &gt; t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; z (` 1) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0= " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 OK i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M Ww t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A AA B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 OK i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M Ww t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A AA B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 OK i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M Ww t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A AA B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 OK i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; z (`)&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = "&gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l at e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g= " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l at e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g= " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l at e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g= " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; z (`)&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; z (`) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; z (`) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " v r 9 M 2 7 h w k m J n 9 H y e w c y B F v y r m C g = " &gt; A A A B + X i c b V B N S 8 N A E N 3 U r 1 q / o h 6 9 L B a h X k o i g h 6 L X j x W s B / Q x L L Z T t q l m 0 3 Y 3 R R q y D / x 4 k E R r / 4 T b / 4 b t 2 0 O 2 v p g 4 P H e D D P z g o Q z p R 3 n 2 y q t r W 9 s b p W 3 K z u 7 e / s H 9 u F R W 8 W p p N C i M Y 9 l N y A K O B P Q 0 k x z 6 C Y S S B R w 6 A T j 2 5 n f m Y B U L B Y P e p q A H 5 G h Y C G j R B u p b 9 u Z F 4 T 4 K X / M a h 5 w f p 7 3 7 a p T d + b A q 8 Q t S B U V a P b t L 2 8 Q 0 z Q C o S k n S v V c J 9 F + R q R m l E N e 8 V I F C a F j M o S e o Y J E o P x s f n m O z 4 w y w G E s T Q m N 5 + r v i Y x E S k 2 j w H R G R I / U s j c T / / N 6 q Q 6 v / Y y J J N U g 6 G J R m H K s Y z y L A Q + Y B K r 5 1 B B C J T O 3 Y j o i k l B t w q q Y E N z l l 1 d J + 6 L u O n X 3 / r L a u C n i K K M T d I p q y E V X q I H u U B O 1 E E U T 9 I x e 0 Z u V W S / W u / W x a C 1 Z x c w x + g P r 8 w c J U Z N B &lt; / l a t e x i t &gt; z (` 1) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; z (` 1) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; z (` 1) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; z (` 1) &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " P q F O k q 3 4 I v z y o S m k 0 / r j I Y a / L b 0 = " &gt; A A A B + 3 i c b V B N S 8 N A E N 3 U r 1 q / Y j 1 6 W S x C P V g S E f R Y 9 O K x g v 2 A N p b N d t I u 3 W z C 7 k a s I X / F i w d F v P p H v P l v 3 L Y 5 a O u D g c d 7 M 8 z M 8 2 P O l H a c b 6 u w s r q 2 v l H c L G 1 t 7 + z u 2 f v l l o o S S a F J I x 7 J j k 8 U c C a g q Z n m 0 I k l k N D n 0 P b H 1 1 O / / Q B S s U j c 6 U k M X k i G g g W M E m 2 k v l 1 O e 3 6 A n 7 L 7 t N o D z k / d k 6 x v V 5 y a M w N e J m 5 O K i h H o 2 9 / 9 Q Y R T U I Q m n K i V N d 1 Y u 2 l R G p G O W S l X q I g J n R M h t A 1 V J A Q l J f O b s / w s V E G O I i k K a H x T P 0 9 k Z J Q q U n o m 8 6 Q 6 J F a 9 K b i f 1 4 3 0 c G l l z I R J x o E n S 8 K E o 5 1 h K d B 4 A G T Q D W f G E K o Z O Z W T E d E E q p N X C U T g r v 4 8 j J p n d V c p + b e n l f q V 3 k c R X S I j l A V u e g C 1 d E N a q A m o u g R P a N X 9 G Z l 1 o v 1 b n 3 M W w t W P n O A / s D 6 / A H t l p O z &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>t) ? R D by means of a learnable matrix E ? R D?3P 2 : t) = Ex (p,t) + e pos (p,t)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>&lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A U / v q + D A g M m 1 x 9 R h U c 2 0 a A 7 B J w Y = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c K 9 g P a U D a b T b t 2 k w 2 7 E 6 G E / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 j c o 0 4 y 2 m p N L d g B o u R c J b K F D y b q o 5 j Q P J O 8 H 4 d u Z 3 n r g 2 Q i U P O E m 5 H 9 N h I i L B K F q p 3 Q + 5 R D q o 1 t y 6 O w d Z J V 5 B a l C g O a h + 9 U P F s p g n y C Q 1 p u e 5 K f o 5 1 S i Y 5 N N K P z M 8 p W x M h 7 x n a U J j b v x 8 f u 2 U n F k l J J H S t h I k c / X 3 R E 5 j Y y Z x Y D t j i i O z 7 M 3 E / 7 x e h t G 1 n 4 s k z Z A n b L E o y i R B R W a v k 1 B o z l B O L K F M C 3 s r Y S O q K U M b U M W G 4 C 2 / v E r a F 3 X P r X v 3 l 7 X G T R F H G U 7 g F M 7 B g y t o w B 0 0 o Q U M H u E Z X u H N U c 6 L 8 + 5 8 L F p L T j F z D H / g f P 4 A k Y y P H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A U / v q + D A g M m 1 x 9 R h U c 2 0 a A 7 B J w Y = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c K 9 g P a U D a b T b t 2 k w 2 7 E 6 G E / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 j c o 0 4 y 2 m p N L d g B o u R c J b K F D y b q o 5 j Q P J O 8 H 4 d u Z 3 n r g 2 Q i U P O E m 5 H 9 N h I i L B K F q p 3 Q + 5 R D q o 1 t y 6 O w d Z J V 5 B a l C g O a h + 9 U P F s p g n y C Q 1 p u e 5 K f o 5 1 S i Y 5 N N K P z M 8 p W x M h 7 x n a U J j b v x 8 f u 2 U n F k l J J H S t h I k c / X 3 R E 5 j Y y Z x Y D t j i i O z 7 M 3 E / 7 x e h t G 1 n 4 s k z Z A n b L E o y i R B R W a v k 1 B o z l B O L K F M C 3 s r Y S O q K U M b U M W G 4 C 2 / v E r a F 3 X P r X v 3 l 7 X G T R F H G U 7 g F M 7 B g y t o w B 0 0 o Q U M H u E Z X u H N U c 6 L 8 + 5 8 L F p L T j F z D H / g f P 4 A k Y y P H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A U / v q + D A g M m 1 x 9 R h U c 2 0 a A 7 B J w Y = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c K 9 g P a U D a b T b t 2 k w 2 7 E 6 G E / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 j c o 0 4 y 2 m p N L d g B o u R c J b K F D y b q o 5 j Q P J O 8 H 4 d u Z 3 n r g 2 Q i U P O E m 5 H 9 N h I i L B K F q p 3 Q + 5 R D q o 1 t y 6 O w d Z J V 5 B a l C g O a h + 9 U P F s p g n y C Q 1 p u e 5 K f o 5 1 S i Y 5 N N K P z M 8 p W x M h 7 x n a U J j b v x 8 f u 2 U n F k l J J H S t h I k c / X 3 R E 5 j Y y Z x Y D t j i i O z 7 M 3 E / 7 x e h t G 1 n 4 s k z Z A n b L E o y i R B R W a v k 1 B o z l B O L K F M C 3 s r Y S O q K U M b U M W G 4 C 2 / v E r a F 3 X P r X v 3 l 7 X G T R F H G U 7 g F M 7 B g y t o w B 0 0 o Q U M H u E Z X u H N U c 6 L 8 + 5 8 L F p L T j F z D H / g f P 4 A k Y y P H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A U / v q + D A g M m 1 x 9 R h U c 2 0 a A 7 B J w Y = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c K 9 g P a U D a b T b t 2 k w 2 7 E 6 G E / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 j c o 0 4 y 2 m p N L d g B o u R c J b K F D y b q o 5 j Q P J O 8 H 4 d u Z 3 n r g 2 Q i U P O E m 5 H 9 N h I i L B K F q p 3 Q + 5 R D q o 1 t y 6 O w d Z J V 5 B a l C g O a h + 9 U P F s p g n y C Q 1 p u e 5 K f o 5 1 S i Y 5 N N K P z M 8 p W x M h 7 x n a U J j b v x 8 f u 2 U n F k l J J H S t h I k c / X 3 R E 5 j Y y Z x Y D t j i i O z 7 M 3 E / 7 x e h t G 1 n 4 s k z Z A n b L E o y i R B R W a v k 1 B o z l B O L K F M C 3 s r Y S O q K U M b U M W G 4 C 2 / v E r a F 3 X P r X v 3 l 7 X G T R F H G U 7 g F M 7 B g y t o w B 0 0 o Q U M H u E Z X u H N U c 6 L 8 + 5 8 L F p L T j F z D H / g f P 4 A k Y y P H A = = &lt; / l a t e x i t &gt; frame t + &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A U / v q + D A g M m 1 x 9 R h U c 2 0 a A 7 B J w Y = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c K 9 g P a U D a b T b t 2 k w 2 7 E 6 G E / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 j c o 0 4 y 2 m p N L d g B o u R c J b K F D y b q o 5 j Q P J O 8 H 4 d u Z 3 n r g 2 Q i U P O E m 5 H 9 N h I i L B K F q p 3 Q + 5 R D q o 1 t y 6 O w d Z J V 5 B a l C g O a h + 9 U P F s p g n y C Q 1 p u e 5 K f o 5 1 S i Y 5 N N K P z M 8 p W x M h 7 x n a U J j b v x 8 f u 2 U n F k l J J H S t h I k c / X 3 R E 5 j Y y Z x Y D t j i i O z 7 M 3 E / 7 x e h t G 1 n 4 s k z Z A n b L E o y i R B R W a v k 1 B o z l B O L K F M C 3 s r Y S O q K U M b U M W G 4 C 2 / v E r a F 3 X P r X v 3 l 7 X G T R F H G U 7 g F M 7 B g y t o w B 0 0 o Q U M H u E Z X u H N U c 6 L 8 + 5 8 L F p L T j F z D H / g f P 4 A k Y y P H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A U / v q + D A g M m 1 x 9 R h U c 2 0 a A 7 B J w Y = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c K 9 g P a U D a b T b t 2 k w 2 7 E 6 G E / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 j c o 0 4 y 2 m p N L d g B o u R c J b K F D y b q o 5 j Q P J O 8 H 4 d u Z 3 n r g 2 Q i U P O E m 5 H 9 N h I i L B K F q p 3 Q + 5 R D q o 1 t y 6 O w d Z J V 5 B a l C g O a h + 9 U P F s p g n y C Q 1 p u e 5 K f o 5 1 S i Y 5 N N K P z M 8 p W x M h 7 x n a U J j b v x 8 f u 2 U n F k l J J H S t h I k c / X 3 R E 5 j Y y Z x Y D t j i i O z 7 M 3 E / 7 x e h t G 1 n 4 s k z Z A n b L E o y i R B R W a v k 1 B o z l B O L K F M C 3 s r Y S O q K U M b U M W G 4 C 2 / v E r a F 3 X P r X v 3 l 7 X G T R F H G U 7 g F M 7 B g y t o w B 0 0 o Q U M H u E Z X u H N U c 6 L 8 + 5 8 L F p L T j F z D H / g f P 4 A k Y y P H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A U / v q + D A g M m 1 x 9 R h U c 2 0 a A 7 B J w Y = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c K 9 g P a U D a b T b t 2 k w 2 7 E 6 G E / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 j c o 0 4 y 2 m p N L d g B o u R c J b K F D y b q o 5 j Q P J O 8 H 4 d u Z 3 n r g 2 Q i U P O E m 5 H 9 N h I i L B K F q p 3 Q + 5 R D q o 1 t y 6 O w d Z J V 5 B a l C g O a h + 9 U P F s p g n y C Q 1 p u e 5 K f o 5 1 S i Y 5 N N K P z M 8 p W x M h 7 x n a U J j b v x 8 f u 2 U n F k l J J H S t h I k c / X 3 R E 5 j Y y Z x Y D t j i i O z 7 M 3 E / 7 x e h t G 1 n 4 s k z Z A n b L E o y i R B R W a v k 1 B o z l B O L K F M C 3 s r Y S O q K U M b U M W G 4 C 2 / v E r a F 3 X P r X v 3 l 7 X G T R F H G U 7 g F M 7 B g y t o w B 0 0 o Q U M H u E Z X u H N U c 6 L 8 + 5 8 L F p L T j F z D H / g f P 4 A k Y y P H A = = &lt; / l a t e x i t &gt; &lt; l a t e x i t s h a 1 _ b a s e 6 4 = " A U / v q + D A g M m 1 x 9 R h U c 2 0 a A 7 B J w Y = " &gt; A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c K 9 g P a U D a b T b t 2 k w 2 7 E 6 G E / g c v H h T x 6 v / x 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S K U w 6 L r f T m l t f W N z q 7 x d 2 d n d 2 z + o H h 6 1 j c o 0 4 y 2 m p N L d g B o u R c J b K F D y b q o 5 j Q P J O 8 H 4 d u Z 3 n r g 2 Q i U P O E m 5 H 9 N h I i L B K F q p 3 Q + 5 R D q o 1 t y 6 O w d Z J V 5 B a l C g O a h + 9 U P F s p g n y C Q 1 p u e 5 K f o 5 1 S i Y 5 N N K P z M 8 p W x M h 7 x n a U J j b v x 8 f u 2 U n F k l J J H S t h I k c / X 3 R E 5 j Y y Z x Y D t j i i O z 7 M 3 E / 7 x e h t G 1 n 4 s k z Z A n b L E o y i R B R W a v k 1 B o z l B O L K F M C 3 s r Y S O q K U M b U M W G 4 C 2 / v E r a F 3 X P r X v 3 l 7 X G T R F H G U 7 g F M 7 B g y t o w B 0 0 o Q U M H u E Z X u H N U c 6 L 8 + 5 8 L F p L T j F z D H / g f P 4 A k Y y P H A = = &lt; / l a t e x i t &gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>t) of the patch at block . For the model of divided attention, we learn distinct query/key/value matrices {W ( ,a) Q time , W ( ,a) K time , W ( ,a) V time }</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 3 .</head><label>3</label><figDesc>We compare the video classification cost (in TFLOPs) of Joint Space-Time versus Divided Space-Time attention. We plot the number of TFLOPs as a function of spatial crop size in pixels (left), and the number of input frames (right). As we increase the spatial resolution (left), or the video length (right), our proposed divided space-time attention leads to dramatic computational savings compared to the scheme of joint space-time attention.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .Figure 8 .</head><label>78</label><figDesc>Visualization of space-time attention from the output token to the input space on Something-Something-V2. Our model learns to focus on the relevant parts in the video in order to perform spatiotemporal reasoning. Feature visualization with t-SNE (van der Maaten &amp; Hinton, 2008) on Something-Something-V2. Each video is visualized as a point. Videos belonging to the same action category have the same color. The TimeSformer with divided space-time attention learns semantically more separable features than the TimeSformer with space-only attention or ViT<ref type="bibr" target="#b18">(Dosovitskiy et al., 2020)</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>, we first observe that al-</cell></row><row><cell>though TimeSformer has a large learning capacity (the num-</cell></row><row><cell>ber of parameters is 121.4M ), it has low inference cost</cell></row><row><cell>(0.59 in TFLOPs). In contrast, SlowFast 8x8 R50 has a</cell></row><row><cell>larger inference cost (1.97 TFLOPs) despite containing only</cell></row><row><cell>34.6M parameters. Similarly, I3D 8x8 R50 also has a larger</cell></row><row><cell>inference cost (1.11 TFLOPs) despite containing fewer pa-</cell></row><row><cell>rameters (28.0M ). This suggests that TimeSformer is better</cell></row><row><cell>suited for settings that involve large-scale learning. In con-</cell></row><row><cell>trast, the large computational cost of modern 3D CNNs</cell></row><row><cell>makes it difficult to further increase their model capacity</cell></row><row><cell>while also maintaining efficiency.</cell></row><row><cell>Video Training Time. One significant advantage of Ima-</cell></row><row><cell>geNet pretraining is that it enables very efficient training of</cell></row><row><cell>TimeSformer on video data. Conversely, state-of-the-art 3D</cell></row><row><cell>CNNs are much more expensive to train even if pretrained</cell></row><row><cell>on image datasets. In Table 2, we compare the video train-</cell></row><row><cell>ing time on Kinetics-400 (in Tesla V100 GPU hours) of</cell></row><row><cell>TimeSformer to that of SlowFast and I3D. Starting from a</cell></row><row><cell>ResNet50 pretrained on ImageNet-1K, SlowFast 8 ? 8 R50 requires 3 840 Tesla V100 GPU hours in order to reach an</cell></row><row><cell>accuracy of 75.6% on Kinetics-400. Training I3D, under</cell></row><row><cell>similar settings, requires 1 440 Tesla V100 GPU hours for a</cell></row><row><cell>73.4% accuracy. In contrast, TimeSformer, also pretrained</cell></row><row><cell>on ImageNet-1K, only requires 416 Tesla V100 GPU hours</cell></row><row><cell>to achieve a higher 75.8% accuracy (see Table 2). Fur-</cell></row><row><cell>thermore, if we constrain SlowFast to be trained under a</cell></row><row><cell>somewhat similar computational budget as TimeSformer</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 .</head><label>3</label><figDesc>Comparing</figDesc><table><row><cell>the effectiveness of ImageNet-1K and</cell></row><row><cell>ImageNet-21K pretraining on Kinetics-400 (K400) and Something-</cell></row><row><cell>Something-V2 (SSv2). On K400, ImageNet-21K pretraining leads</cell></row><row><cell>consistently to a better performance compared to ImageNet-1K pre-</cell></row><row><cell>training. On SSv2, ImageNet-1K and ImageNet-21K pretrainings</cell></row><row><cell>lead to similar accuracy.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc>we study the benefits of ImageNet-1K vs ImageNet-21K pretraining on K400 and SSv2. For these experiments, we use three variants of our model: (1) TimeSformer, which is the default version of our model operating on 8 ? 224 ? 224 video clips, (2) TimeSformer-HR, a high spatial resolution variant that operates on 16 ? 448 ? 448 video clips, and lastly (3) TimeSformer-L, a long-range configuration of our model that operates on 96 ? 224 ? 224 video clips with frames sampled at a rate of 1/4. This makes sense as SSv2 requires complex spatiotemporal reasoning, whereas K400 is biased more towards spatial scene information, and thus, it benefits more from the features learned on the larger pretraining dataset.</figDesc><table><row><cell>Based on the results in Table 3, we observe that ImageNet-</cell></row><row><cell>21K pretraining is beneficial for K400, where it leads to</cell></row><row><cell>a consistently higher accuracy compared to ImageNet-1K</cell></row><row><cell>pretraining. On the other hand, on SSv2, we observe that</cell></row><row><cell>ImageNet-1K and ImageNet-21K pretrainings lead to simi-</cell></row><row><cell>lar accuracy.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Clip-level accuracy on Kinetics-400 as a function of spatial crop size in pixels (left), and the number of input frames (right).</figDesc><table><row><cell></cell><cell>80</cell><cell></cell><cell></cell><cell></cell><cell>80</cell><cell></cell><cell></cell></row><row><cell>Clip Accuracy</cell><cell>65 70 75</cell><cell></cell><cell></cell><cell>Clip Accuracy</cell><cell>65 70 75</cell><cell></cell><cell></cell></row><row><cell></cell><cell>224</cell><cell>336</cell><cell>448</cell><cell>560</cell><cell>8</cell><cell>32</cell><cell>64</cell><cell>96</cell></row><row><cell></cell><cell cols="4">Spatial Crop Side (Px)</cell><cell cols="3">Number of Input Frames</cell></row><row><cell cols="5">Figure 5. Positional Embedding</cell><cell>K400</cell><cell>SSv2</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>None</cell><cell></cell><cell>75.4</cell><cell>45.8</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Space-only</cell><cell>77.8</cell><cell>52.5</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Space-Time</cell><cell>78.0</cell><cell>59.5</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Ablation on positional embeddings. The version of TimeSformer using space-time positional embeddings yields the highest accuracy on both Kinetics-400 and SSv2.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Table 7. Video-level accuracy on Something-Something-V2 and Diving-48. * * Due to an issue with Diving-48 labels used in previously published results, we only compare our method with a reproduced SlowFast 16 ? 8 R101 model. All models are pretained on ImageNet-1K.</figDesc><table><row><cell></cell><cell>2</cell><cell>N/A</cell></row><row><cell>TimeSformer</cell><cell>59.5</cell><cell>74.9</cell></row><row><cell>TimeSformer-HR</cell><cell>62.2</cell><cell>78.0</cell></row><row><cell>TimeSformer-L</cell><cell>62.4</cell><cell>81.0</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Facebook AI 2 Dartmouth College. Correspondence to: Gedas Bertasius &lt;gberta@seas.upenn.edu&gt;.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Quantifying attention flow in transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Abnar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zuidema</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Ba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Layer normalization. CoRR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Attention augmented convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<title level="m">IEEE/CVF International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Classifying, segmenting, and tracking object instances in video with mask propagation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bertasius</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Ryder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Subbiah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kaplan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dhariwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Neelakantan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shyam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Askell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herbert-Voss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Henighan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ramesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Winter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hesse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sigler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Litwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mccandlish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amodei</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>Language models are few-shot learners. 2020</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">End-to-end object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference Computer Vision (ECCV)</title>
		<imprint>
			<biblScope unit="page">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Quo vadis, action recognition? A new model and the kinetics dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2017 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Honolulu, HI, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-07-21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">A short note about kinetics-600</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Noland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Banki-Horvath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hillier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The best of both worlds: Combining recent advances in neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Firat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bapna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A?2-nets: Double attention networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 31</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Drop an octave: Reducing spatial redundancy in convolutional neural networks with octave convolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Generating long sequences with sparse transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">On the relationship between self-attention and convolutional layers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cordonnier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Loukas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jaggi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Transformer-XL: Attentive language models beyond a fixed-length context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2009.5206848</idno>
	</analytic>
	<monogr>
		<title level="m">2009 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bert</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">An image is worth 16x16 words: Transformers for image recognition at scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kolesnikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Minderer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Heigold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Houlsby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-Y</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pyslowfast</surname></persName>
		</author>
		<ptr target="https://github.com/facebookresearch/slowfast,2020" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">More is less: Learning efficient video representations by big-little network and depthwise temporal aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-F</forename><forename type="middle">R</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kuehne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pistoia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Expanding architectures for efficient video recognition. CVPR</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>X3d</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="200" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Slowfast networks for video recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the</title>
		<meeting>the</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
				<title level="m">IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Slowfast networks for video recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feichtenhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 IEEE/CVF International Conference on Computer Vision, ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Actor-transformers for group activity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gavrilyuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sanford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Javan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Video action transformer network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girdhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tulloch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Accurate</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">The &quot;something something&quot; video database for learning and evaluating visual common sense</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Michalski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Materzynska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Westphal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Haenel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fr?nd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Yianilos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mueller-Freitag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Thurau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Memisevic</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Axial attention in multidimensional transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kalchbrenner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Relation networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Ccnet: Criss-cross attention for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Spatiotemporal and motion encoding for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2019-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Motionsqueeze: Neural motion feature learning for video understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Multimodal transformer networks for end-to-end video-grounded dialogue systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sahoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hero</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00200</idno>
		<title level="m">Hierarchical encoder for video+ language omni-representation pre-training</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Towards action recognition without representation bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Resound</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Tea: Temporal excitation and aggregation for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Temporal shift module for efficient video understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Tsm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miech</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhukov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Alayrac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tapaswi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laptev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Howto100m</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Scaling neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Auli</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation: Research Papers</title>
		<meeting>the Third Conference on Machine Translation: Research Papers</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Image transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tran</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning, ICML</title>
		<editor>Dy, J. G. and Krause, A.</editor>
		<meeting>the 35th International Conference on Machine Learning, ICML</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning spatio-temporal representation with local and global diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Ngo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Improving language understanding by generative pretraining</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Stand-alone self-attention in vision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="68" to="80" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Only time can tell: Discovering temporal data for temporal modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Sevilla-Lara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feiszli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</meeting>
		<imprint>
			<date type="published" when="2021-01" />
			<biblScope unit="page" from="535" to="544" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Is Space-Time Attention All You Need for Video Understanding?</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Distilled 3d networks for video action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stroud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>D3d</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</meeting>
		<imprint>
			<date type="published" when="2020-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Videobert: A joint model for video and language representation learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vondrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">RAFT: recurrent all-pairs field transforms for optical flow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Teed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 -16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A closer look at spatiotemporal convolutions for action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Salt Lake City, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Video classification with channel-separated convolutional networks. ICCV</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feiszli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<ptr target="http://www.jmlr.org/papers/v9/vandermaaten08a.html" />
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>Visualizing data using t-SNE</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 30</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Video modeling with correlation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Torresani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feiszli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2020-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Axial-deeplab: Stand-alone axial-attention for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 -16th European Conference</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2018-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Salt Lake City, UT, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06-18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Attentionnas: Spatiotemporal attention cell search for video classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Piergiovanni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Ryoo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Angelova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2020 -16th European Conference</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>Proceedings, Part VIII</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Scaling autoregressive video models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>T?ckstr?m</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations, ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">Pytorch image models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wightman</surname></persName>
		</author>
		<ptr target="https://github.com/rwightman/pytorch-image-models" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Rethinking spatiotemporal feature learning: Speedaccuracy trade-offs in video classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-01267-0_19</idno>
		<idno>doi: 10.1007/ 978-3-030-01267-0\_19</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-01267-0_19" />
	</analytic>
	<monogr>
		<title level="m">Computer Vision -ECCV 2018 -15th European Conference</title>
		<meeting><address><addrLine>Munich, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="318" to="335" />
		</imprint>
	</monogr>
	<note>Proceedings, Part XV</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Bert representations for video question answering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Otani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Nakashima</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Takemura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Winter Conference on Applications of Computer Vision</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Exploring self-attention for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Koltun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">End-to-end dense video captioning with masked transformer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Corso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
