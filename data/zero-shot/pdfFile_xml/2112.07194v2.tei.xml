<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue Evaluation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Zhang</surname></persName>
							<email>chenzhang@u.nus.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Robert Bosch (SEA)</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luis</forename><surname>Fernando D&amp;apos;haro</surname></persName>
							<email>luisfernando.dharo@upm.es</email>
							<affiliation key="aff3">
								<orgName type="institution">Universidad Polit?cnica de Madrid</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Friedrichs</surname></persName>
							<email>thomas.friedrichs@sg.bosch.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Robert Bosch (SEA)</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Li</surname></persName>
							<email>haizhou.li@u.nus.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Kriston AI Lab</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">The Chinese University of Hong Kong (Shenzhen)</orgName>
								<address>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">MDD-Eval: Self-Training on Augmented Data for Multi-Domain Dialogue Evaluation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T17:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Chatbots are designed to carry out human-like conversations across different domains, such as general chit-chat, knowledge exchange, and persona-grounded conversations.</p><p>To measure the quality of such conversational agents, a dialogue evaluator is expected to conduct assessment across domains as well. However, most of the state-of-the-art automatic dialogue evaluation metrics (ADMs) are not designed for multi-domain evaluation. We are motivated to design a general and robust framework, MDD-Eval, to address the problem. Specifically, we first train a teacher evaluator with human-annotated data to acquire a rating skill to tell good dialogue responses from bad ones in a particular domain and then, adopt a self-training strategy to train a new evaluator with teacher-annotated multi-domain data, that helps the new evaluator to generalize across multiple domains. MDD-Eval is extensively assessed on six dialogue evaluation benchmarks. Empirical results show that the MDD-Eval framework achieves a strong performance with an absolute improvement of 7% over the state-of-the-art ADMs in terms of mean Spearman correlation scores across all the evaluation benchmarks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Recent years have witnessed growing interests in opendomain dialogue systems <ref type="bibr" target="#b0">(Adiwardana et al. 2020;</ref><ref type="bibr" target="#b44">Zhang et al. 2020;</ref><ref type="bibr" target="#b27">Roller et al. 2021)</ref>. With the increasing availability of high-quality dialogue corpora <ref type="bibr" target="#b14">(Li et al. 2017;</ref><ref type="bibr" target="#b43">Zhang et al. 2018</ref>) and advancement of neural architectures <ref type="bibr" target="#b3">(Devlin et al. 2019;</ref><ref type="bibr" target="#b24">Radford et al. 2019)</ref>, learning-based dialogue systems are becoming possible. The applications call for dialogue technology capable of generating appropriate responses to users' prompts in a diverse range of scenarios, such as general chit-chat <ref type="bibr" target="#b14">(Li et al. 2017</ref>), knowledge exchange <ref type="bibr" target="#b8">(Gopalakrishnan et al. 2019</ref>), persona-based chat <ref type="bibr" target="#b43">(Zhang et al. 2018)</ref>, and emotion disclosure <ref type="bibr" target="#b25">(Rashkin et al. 2019)</ref>.</p><p>However, the dialogue research heavily relies on the ability to evaluate system performance with automatic dialogue evaluation metrics (ADMs). Common natural language generation (NLG) metrics used in the dialogue system literature, such as BLEU <ref type="bibr" target="#b21">(Papineni et al. 2002)</ref> and ROUGE <ref type="bibr" target="#b15">(Lin 2004)</ref>, are unsuitable for the multi-domain dialogue evaluation task as they are shown to correlate poorly with human Copyright ? 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metric</head><p>DailyDialog-Eval Topical-Eval DEB 0.486 0.116 GRADE 0.533 0.217 USR 0.367 0.423 <ref type="table">Table 1</ref>: Spearman correlation scores of three state-of-theart model-based metrics on two dialogue evaluation benchmarks.</p><p>judgements <ref type="bibr" target="#b16">(Liu et al. 2016</ref>) due to the one-to-many contextresponse mapping in dialogues <ref type="bibr" target="#b46">(Zhao, Zhao, and Eskenazi 2017)</ref> as well as the multi-faceted nature of dialogue evaluation <ref type="bibr" target="#b20">(Mehri and Eskenazi 2020b</ref>). An alternative solution is to design model-based ADMs that explicitly learn to discriminate dialogue responses of varying quality. Lately, many model-based ADMs leveraging self-supervised learning are proposed to address the weaknesses of the standard NLG metrics <ref type="bibr" target="#b28">(Sai et al. 2020;</ref><ref type="bibr" target="#b7">Ghazarian et al. 2019;</ref><ref type="bibr" target="#b20">Mehri and Eskenazi 2020b;</ref><ref type="bibr" target="#b11">Huang et al. 2020;</ref><ref type="bibr" target="#b40">Zhang et al. 2021c)</ref>. While these ADMs have demonstrated strong correlations with human judgements, they lack a generalized skill to evaluate dialogues across multiple domains. For example, in <ref type="table">Table 1</ref>, DEB <ref type="bibr" target="#b28">(Sai et al. 2020)</ref> and <ref type="bibr">GRADE (Huang et al. 2020</ref>) are pretrained on the DailyDialog dataset <ref type="bibr" target="#b14">(Li et al. 2017)</ref>. They perform well on the DailyDialog-Eval <ref type="bibr" target="#b45">(Zhao, Lala, and Kawahara 2020)</ref> benchmark that contains responses from dialogue systems trained on chit-chat content. However, their performance significantly drops when assessed on the Topical-Eval <ref type="bibr" target="#b20">(Mehri and Eskenazi 2020b)</ref> benchmark, which is close in domain with TopicalChat <ref type="bibr" target="#b8">(Gopalakrishnan et al. 2019)</ref> and contains dialogue responses from knowledge-grounded conversations. The reverse is true for USR <ref type="bibr" target="#b20">(Mehri and Eskenazi 2020b)</ref>, which is pretrained on the TopicalChat dataset.</p><p>To design robust ADMs for the multi-domain dialogue evaluation task, we consider two research questions. (1) How to equip the ADM with a rating skill to discriminate responses of varying quality? In other words, the ability to assign a high score to relevant responses and a low score otherwise. (2) How can an ADM learn the general knowledge across dialogue domains so as to generalize the evaluation skill? For the first question, the most direct and ef-fective way is to learn from humans, i.e., the ADM can be trained with human-annotated dialogue data. As for the second question, the general knowledge can be learned on a large-scale multi-domain dialogue dataset. Ideally, If human annotations are available, an oracle multi-domain dialogue evaluator can be learned. However, performing large-scale human annotations is extremely expensive. Thus, we are motivated to explore semi-supervised learning for our task.</p><p>More specifically, we propose a multi-domain dialogue evaluation (MDD-Eval) framework under the self-training paradigm <ref type="bibr" target="#b29">(Scudder 1965;</ref><ref type="bibr">Yarowsky 1995)</ref> where a teacher model, trained on human-annotated dialogue evaluation data, creates pseudo labels for unlabeled dialogue data. Then, the synthetically-labeled data are used to train a student model. To obtain the large-scale multi-domain unlabeled dialogue data, we leverage the dialogue data augmentation techniques that have been successfully applied in the self-supervised learning of ADMs, such as random utterance selection <ref type="bibr" target="#b33">(Tao et al. 2018;</ref><ref type="bibr" target="#b40">Zhang et al. 2021c)</ref>, mask-andfill <ref type="bibr" target="#b5">(Donahue, Lee, and Liang 2020;</ref><ref type="bibr" target="#b9">Gupta, Tsvetkov, and Bigham 2021)</ref> and back-translation <ref type="bibr" target="#b6">(Edunov et al. 2018;</ref><ref type="bibr" target="#b30">Sinha et al. 2020)</ref>. In this way, we expect that the student model carries the rating skill of the teacher model, and it can generalize across domains after being adapted on a largescale multi-domain dataset with pseudo labels.</p><p>Overall, we make the following contributions:</p><p>? A model-based framework, named MDD-Eval, is proposed with a self-training scheme on augmented data. Its rating skill is trained on human-annotated data, and its cross-domain general knowledge is trained on machineannotated data. ? We release a large-scale multi-domain dialogue dataset with machine annotations that facilitate ADM training. We name the dataset, MDD-Data. ? MDD-Eval attains an absolute improvement of 7% over the state-of-the-art ADMs in terms of mean Spearman correlation over six dialogue evaluation benchmarks. ? MDD-Data, MDD-Eval implementation, and pretrained checkpoints will be released to the public 1 . This allows practitioners and researchers to use and adapt MDD-Eval for automatic evaluation of their dialogue systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Dialogue Evaluation Metrics</head><p>Human evaluation reflects the perceived quality of dialogue systems. However, it is expensive and time-consuming. For system development, we rely on ADMs for model design, hyperparameter tuning and system benchmarking <ref type="bibr" target="#b37">(Yeh, Eskenazi, and Mehri 2021)</ref>. The current trend of opendomain ADMs is shifting from the reference-based approach towards the model-based approach that is referencefree <ref type="bibr" target="#b19">(Mehri and Eskenazi 2020a;</ref><ref type="bibr" target="#b38">Zhang et al. 2021a</ref>). In many ADM solutions, we predict the relatedness between a dialogue context and the generated responses by training a discriminative network to distinguish the original response from negative samples in a self-supervised fashion. Typical examples include RUBER <ref type="bibr" target="#b33">(Tao et al. 2018)</ref>, BERT-RUBER <ref type="bibr" target="#b7">(Ghazarian et al. 2019)</ref>, USR <ref type="bibr" target="#b20">(Mehri and Eskenazi 2020b)</ref>, <ref type="bibr">GRADE (Huang et al. 2020)</ref>, MaUdE <ref type="bibr" target="#b30">(Sinha et al. 2020</ref>) and D-score <ref type="bibr" target="#b40">(Zhang et al. 2021c)</ref>.</p><p>A problem with the metrics learned with self-supervised learning is that the random negative-sampling strategy is likely to produce false-negative or over-simplistic candidates, thus introducing unwanted biases to the ADMs. One idea is to introduce adversarial irrelevant responses to increase the ADMs' discrimination capability <ref type="bibr" target="#b28">(Sai et al. 2020;</ref><ref type="bibr" target="#b9">Gupta, Tsvetkov, and Bigham 2021;</ref><ref type="bibr" target="#b22">Park et al. 2021)</ref>. In this way, the evaluation model will greatly benefit from a dataset of multiple relevant and adversarial irrelevant responses from diverse dialogue context. The existing methods are focused very much on how to design such a dataset. Along this line of thought, this work presents a novel strategy to learn the rating skill from one dataset first, then generalize the skill across multiple domains.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Self-Training</head><p>Self-training is a simple and effective semi-supervised approach, which incorporates a model's prediction on unlabeled data to obtain additional information. It has been shown effective in many tasks, such as image recognition <ref type="bibr" target="#b36">(Yalniz et al. 2019</ref>), text generation <ref type="bibr" target="#b10">(He et al. 2020</ref>), automatic speech recognition <ref type="bibr" target="#b12">(Kahn, Lee, and Hannun 2020)</ref>, and parsing <ref type="bibr" target="#b18">(McClosky, Charniak, and Johnson 2006)</ref>. There are two key ideas that contribute to the success of selftraining: pseudo-labeling and consistency regularization.</p><p>Pseudo-labeling refers to the process of converting model predictions to hard labels <ref type="bibr" target="#b13">(Lee et al. 2013)</ref>. Usually, a confidence-based threshold is imposed to retain unlabeled examples only when the classifier is sufficiently confident . In MDD-Eval, we apply pseudolabeling together with the confidence-based threshold to bootstrap high-quality adversarial and random negative samples from the unlabeled data.</p><p>Consistency regularization was first proposed by (Bachman, Alsharif, and Precup 2014). It means that the prediction made by the classification model remains consistent even when the input or the model function is perturbed by a small amount of noise. Recently, the use of consistency regularization to modulate the self-training process has been shown to boost model performance on many image and text classification tasks <ref type="bibr" target="#b34">(Xie et al. 2020a;</ref><ref type="bibr" target="#b2">Berthelot et al. 2020)</ref>. We are motivated to incorporate consistency regularization into the learning of our dialogue evaluator, which is essentially learned with a text classification task. <ref type="bibr" target="#b35">Xie et al. (2020b)</ref> proposes Noisy Student and <ref type="bibr" target="#b31">Sohn et al. (2020)</ref> proposes FixMatch frameworks. Both incorporate pseudo-labeling and consistency regularization into a unified framework. Noisy Student and FixMatch have demonstrated remarkable performance on image classification tasks, that motivates us to unify the pseudo-labeling and consistency regularization ideas in open-domain ADM training for the first time.</p><p>In this section, we first define the multi-domain dialogue evaluation task (Section 3.1), then formulate MDD-Eval framework in three steps: (a) We pretrain a teacher model (Section 3.2) from a human-annotated dataset, to learn the rating skill to distinguish relevant responses from irrelevant ones. (b) We augment a large-scale multi-domain dataset for MDD-Eval self-training (Section 3.3). (c) We generalize the pretrained teacher model with the augmented data to derive a student model, which carries a generalized rating skill learned from the augmented data. (Section 3.4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problem Formulation</head><p>Formally, a dialogue context and the corresponding dialogue response can be denoted as c j i and r j i respectively. c j i and r j i are the i th data pair drawn from the j th dialogue evaluation benchmark D j , where j ? {1, ..., J}, and D j ? D J and i ? {1, ..., I}. There are J domains, each of which has I data pairs. Our goal is to learn a metric, M : (c j i , r j i ) ? s j i where s j i is the metric score that indicates the quality of (c j i , r j i ) as perceived by M . In addition, each (c j i , r j i ) is annotated by several human judges and each human judge will provide a quality score based on the Likert scale 2 to indicate his or her perception of the quality of (c j i , r j i ). We denote the mean human score given to (c j i , r j i ) as q j i . Due to the multi-faceted nature of dialogue evaluation, the quality can refer to language fluency, coherence, topic relevance, logical consistency etc. Since the focus of our work is multi-domain dialogue evaluation instead of multi-dimensional evaluation, we fix the quality as response appropriateness here.</p><p>To assess the performance of M on D j , the correlation score between S = {s j i , . . . , s j I } and Q = {q j i , . . . , q j I } are calculated. We use ? j to represent the correlation score on D j . Higher ? j indicates better performance of the metric on D j . In the multi-domain dialogue evaluation task, an effective M should achieve good correlation scores across all J domains. In other words, the desired M should obtain a good average correlation? = 1 J J j=1 ? j .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Teacher Model</head><p>We first pretrain a model on human-annotated data in one particular domain, i.e., the teacher model, M teacher , defined by the parameters ? teacher . Given a dialogue contextresponse pair, M teacher should accurately determine the degree of relevance between the context and the corresponding response. To equip the teacher model with a solid rating skill, we rely on a high-quality human-annotated base dataset D b ? D J . Note that D b is from a single-domain, and of much smaller size than the data we would like to augment.</p><p>In dataset D b , there are three categories of responses for a given context: random, adversarial and relevant. The relevant and adversarial responses are generated by human an-2 In the evaluation benchmarks used in our experiments, the Likert scale is from 1 to 5. The higher the better. notators. M teacher is trained on D b to classify a contextresponse pair into one of the three categories:</p><formula xml:id="formula_0">y b i = f ? teacher ([c b i ? r b i ])<label>(1)</label></formula><p>with the objective function:</p><formula xml:id="formula_1">min ? teacher 1 |D b | (c b i ,r b i ,y b i )?D b L CE (? b i , y b i ) (2) where ? denotes the concatenation operation.? b i is the pre- dicted class, y b i is the gold label for (c b i , r b i )</formula><p>and L CE is the cross entropy loss.</p><p>M teacher plays three key roles: (1) providing pseudo labels to unlabeled context-response pairs, (c * i , r * i ) 3 , which are obtained with different dialogue data augmentation techniques.</p><p>(2) facilitating the data selection process whereby false negatives and adversarial or random samples with low confidence scores as determined by M teacher are removed.</p><p>(3) serving as a baseline in the evaluation task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Dialogue Data Augmentation</head><p>To generalize the teacher model across domains, we collect a multi-domain dataset, denoted as D * , that contains a large amount of unlabeled context-response pairs. The unlabeled pairs will be automatically annotated in the same way as D b by M teacher . An example of a dialogue context with three candidate responses for annotation is presented in <ref type="figure" target="#fig_0">Figure 1</ref>. To construct such a dataset, we leverage the following dialogue data augmentation techniques:</p><p>Syntactic Perturbation Motivated by <ref type="bibr" target="#b30">(Sinha et al. 2020)</ref>, we have considered three variants of perturbations at the syntax level: (1) word-drop (a random portion of tokens in the response is dropped). (2) word-shuffle (the ordering of tokens in the response is randomly shuffled). (3) word-repeat (a random portion of tokens in the response is repeated multiple times). The syntactic perturbations are intended to simulate erroneous behaviours of some generative models in generating unnatural dialogue responses.</p><p>Back-Translation Back-translation <ref type="bibr" target="#b6">(Edunov et al. 2018</ref>) augments a response by generating its syntactic variants. In practice, we adopt the pretrained WMT'19 English-German and German-English ensemble model to perform backtranslation.</p><p>Generative Model Output State-of-the-art dialogue generators, such as DialoGPT  and BlenderBot <ref type="bibr" target="#b27">(Roller et al. 2021)</ref>, have been pretrained on a large amount of conversation data and are demonstrating strong capability in generating fluent and on-topic responses. They help generate semantic variants of a response conditioned on the respective dialogue contexts.</p><p>Random Utterance Selection The random utterance selection is a simple and effective strategy that has been widely adopted in the self-supervised learning of dialogue evaluation metrics <ref type="bibr" target="#b20">(Mehri and Eskenazi 2020b;</ref><ref type="bibr" target="#b11">Huang et al. 2020;</ref><ref type="bibr" target="#b28">Sai et al. 2020)</ref> to introduce irrelevant responses w.r.t. a dialogue context. Given a dialogue context, three variants of random utterance selection are adopted: (1) randomly sample a response from a different dialogue. (2) randomly sample a response from the entire pool of responses produced by the generative models. (3) randomly sample a response from the entire pool of responses obtained via back-translation.</p><p>Mask-and-fill Above-mentioned techniques tend to produce response candidates for the relevant and random class. The mask-and-fill strategy is adopted to automatically construct candidates for the adversarial class. Specifically, we adopt the Infilling by Language Modeling (ILM) framework <ref type="bibr" target="#b5">(Donahue, Lee, and Liang 2020)</ref> to perform the mask-and-fill response augmentation. The process is as follows: given a context-response pair extracted from a natural human-human dialogue, one or a few contiguous tokens in the response are randomly replaced by the [blank] placeholder. The modified response is input into the pretrained ILM model, which then generate tokens in an autoregressive manner. Subsequently, the [blank] placeholder is substituted with the generated tokens to obtain a reconstructed view of the original response. The reconstructed response serves as an adversarial sample w.r.t. the dialogue context.</p><p>After obtaining the large number of context-response pairs, we apply the pretrained M teacher to provide soft pseudo labels to all the pairs. The soft pseudo label is a probability distribution over the three classes (random, adversarial and relevant). Then, a filtering process is implemented to improve the quality of pseudo-labeled D * . A confidence threshold of 70% is applied to exclude pairs classified by M teacher with low confidence. Emprical evidence suggests that the 70% threshold provides a good balance between the quality and quantity of augmented data. Within D * , the relevant </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Student Model</head><p>Once D * is ready, we can learn a student model, M student parameterized by ? student , on D * by performing the following classification task: <ref type="figure" target="#fig_1">Figure 2</ref> is a graphical illustration of the training objective of M student and the equation is as follows:</p><formula xml:id="formula_2">x * i = f ? student ([c * i ? r * i ])<label>(3)</label></formula><formula xml:id="formula_3">min ? student 1 |D * | (c * i ,r * i ,? * i )?D * L CE (x * i ,? * i )+ L KL (x * i ,x * i ) + L M LM ([c * i ? r * i ])<label>(4)</label></formula><p>where L CE is the cross-entropy loss, L KL is the KL divergence and L M LM is the self-supervised masked language modeling (MLM) loss. x * i and? * i are the logits output from M student and the pseudo label generated by the pretrained M teacher respectively given the input pair (c * i , r * i ). L KL is introduced to enforce consistency regularization, with which M student is less sensitive to noise and hence smoother w.r.t. perturbations in the input space <ref type="bibr" target="#b34">(Xie et al. 2020a)</ref>. We denote the noisy version of r * i after noise injection asr * i . In the practical implementation, we follow <ref type="bibr" target="#b10">(He et al. 2020)</ref> to generater * i based on r * i .x * i is the corresponding logits from M student after inputting (c * i ,r * i ). The KL divergence between the respective post-softmax probability distributions of x * i andx * i is minimized during training. The last term, L M LM , is intended to help M student extract additional domain-specific knowledge so as to better adapt to the multi-domain synthetic dataset. The MLM implementation follows the standard BERT <ref type="bibr" target="#b3">(Devlin et al. 2019)</ref> practice whereby a random portion of tokens in the concatenated sequence, [c * i ? r * i ], are masked. M student is expected to make predictions on the masked tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Run-time Scoring Process</head><p>The learned student model serves as the backbone of MDD-Eval for performing the multi-domain dialogue evaluation task, that derives the metric score s j i for a given contextresponse pair (c j i , r j i ) ? D j as mentioned in Section 3.1. We formulate the scoring process by M student as follows:</p><formula xml:id="formula_4">s j i = P (? j i = relevance|(c j i , r j i ))<label>(5)</label></formula><p>which is the post-softmax probability w.r.t. the relevant class output by M student given the input, (c j i , r j i ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment Setup</head><p>We first discuss the dialogue corpora (Section 4.1) used in the experiments. Then, the evaluation benchmarks used for assessing the performance of MDD-Eval are discussed in Section 4.2. Next, Section 4.3 is about the architecture choice for both the teacher and the student model. Finally, the choices of baselines are outlined in Section 4.4. The detailed statistics of the four dialogue corpora are presented in <ref type="table" target="#tab_2">Table 2</ref>. We only use the training and validation sets of the dialogue corpora since some dialogue contexts in the evaluation benchmarks are sampled from their test sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Dialogue Corpora</head><p>To extract context-response pairs from the human-human dialogues, we take the dialogue history and current response as an original context-response pair. The number of utterances per context is kept between one and four. For each original context-response pair, we sample ten different augmented pairs per augmentation technique. After the filtering process, we end up with a class-balanced and multidomain synthetic dataset of around 2.6 million contextresponse pairs. We name this synthetic dataset, MDD-Data. In our experiment, for quick turn-around, we sub-sample 600K context-response pairs from MDD-Data to train the final student model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation Datasets</head><p>Guided by <ref type="bibr" target="#b37">(Yeh, Eskenazi, and Mehri 2021)</ref>, we use publicly-available dialogue evaluation datasets to assess the performance of the ADMs. Additionally, we propose a few criteria for the selection of high-quality dialogue evaluation datasets. First, we select the ones that cover as many domains as possible. Second, the size of the datasets should be sufficiently large to provide statistically significant analysis. Third, most of the state-of-the-art metrics should have achieved relatively good correlation results on the datasets. This is to avoid inclusion of any biased evaluation dataset. Next, the inter-annotator agreement should be relatively good (?0.6). Lastly, the evaluation datasets should cover responses of a wide quality spectrum. In total, we have adopted six different publicly-available dialogue evaluation datasets with each accounting for a dialogue domain for assessing MDD-Eval 4 : DailyDialog-Eval <ref type="bibr" target="#b45">(Zhao, Lala, and Kawahara 2020)</ref>, Persona-Eval <ref type="bibr" target="#b45">(Zhao, Lala, and Kawahara 2020)</ref>, Topical-Eval (Mehri and Eskenazi 2020b), Movie-Eval <ref type="bibr" target="#b21">(Merdivan et al. 2020</ref><ref type="bibr">), Empathetic-Eval (Huang et al. 2020</ref> and Twitter-Eval <ref type="bibr" target="#b11">(Hori and Hori 2017)</ref>. Detailed statistics of each evaluation dataset is listed in <ref type="table">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Model Architecture Choice</head><p>We choose RoBERTa-Large <ref type="bibr" target="#b17">(Liu et al. 2019)</ref> for both the teacher and the student model in MDD-Eval. There are two reasons. First, RoBERTa has been pretrained on more than 160GB of uncompressed text covering multiple domains including news, stories, books and web text. Therefore, it equips the prediction model with general knowledge of the text with which the prediction model can easily adapt to the downstream dialogue evaluation tasks. Second, it has been proven as a powerful text encoder that are beneficial for the automatic dialogue evaluation task in prior works <ref type="bibr" target="#b45">(Zhao, Lala, and Kawahara 2020;</ref><ref type="bibr" target="#b20">Mehri and Eskenazi 2020b;</ref><ref type="bibr">Zhang et al. 2021c,b)</ref>.   <ref type="table">Table 3</ref>: Summary of the evaluation datasets. Some information are obtained from <ref type="bibr" target="#b37">(Yeh, Eskenazi, and Mehri 2021)</ref> and <ref type="bibr" target="#b42">(Zhang et al. 2021d)</ref>. #criteria is the number of response qualities that have been annotated, such as appropriateness, naturalness, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Baselines</head><p>We compare MDD-Eval against state-of-the-art referencefree dialogue metrics, including DEB <ref type="bibr" target="#b28">(Sai et al. 2020)</ref>, USL-H (Phy, Zhao, and Aizawa 2020), GRADE (Huang et al. 2020), USR (Mehri and Eskenazi 2020b), unreferenced BERT-RUBER (uBERT-R) <ref type="bibr" target="#b7">(Ghazarian et al. 2019)</ref>, and Dscore <ref type="bibr" target="#b40">(Zhang et al. 2021c</ref>). The selection of baselines is guided by a recent comprehensive survey on ADMs <ref type="bibr" target="#b37">(Yeh, Eskenazi, and Mehri 2021)</ref>, which has showcased the strong performance of the above-mentioned metrics. In fact, each selected metric is one of the top-ranking metrics on one or more public dialogue evaluation benchmarks. As in the previous work, we use the publicly-available checkpoints of the selected evaluation metrics for our evaluation tasks. <ref type="table" target="#tab_4">Table 4</ref> summarizes the training details of the model-based evaluation metrics including the teacher (MDD-T) and student models (MDD-S) in MDD-Eval as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results &amp; Analysis</head><p>Main Correlation Results <ref type="table">Table 5</ref> presents the Spearman correlation scores of baseline evaluation metrics, the proposed MDD-Eval metric, and its ablation versions, across six dialogue evaluation benchmarks. For each MDD-Eval variant, we train the model five times with different random seeds and report the average results across the five runs. It can be observed that the full student model, MDD-S, performs generally well across all the evaluation benchmarks with an average Spearman correlation score of 0.476. MDD-S outperforms all the state-of-the-art model-based evaluation metrics. Remarkably, it outperforms the best baseline, DEB, by roughly 7% in absolute terms. This confirms that MDD-Eval is a robust framework for the multi-domain dialogue evaluation task.</p><p>Ablation Study To better understand the influence of each component of MDD-S. The results w.r.t three ablation versions, MDD-T, MDD-C, and MDD-CM, are presented in <ref type="table">Table 5</ref>. MDD-T is the teacher model, which is trained only on the single-domain human-annotated dataset, Dai-lyDialog++. It performs well on the DailyDialog-Eval and Empathetic-Eval benchmarks, which are close in domain w.r.t its training data source, compared to the baselines. This confirms our statement in Section 1 that learning from humans is an effective approach to equip ADMs with a rating skill to discriminate responses of varying quality. MDD-C brings significant performance improvement over MDD-T (7.1% Spearman correlation score). Note that MDD-C is learned with the vanilla self-training setup without consistency regularization and domain adaptation. The performance improvement showcases that the student model can generalize the rating skill of the teacher through the MDD-Data alone without any additional inductive bias.</p><p>MDD-CM brings a further improvement of 2.4% Spearman correlation score. This confirms the usefulness of the self-supervised MLM objective in helping the student model to extract additional domain-specific knowledge.</p><p>Finally, the full model MDD-S achieves the highest average Spearman correlation score of 0.476. This showcases the effectiveness of consistency regularization in our selftraining setup.</p><p>MDD-Eval vs uBERT-R Unreferenced BERT-RUBER (uBERT-R) can be considered the fundamental representative of the recent family of ADMs based on self-supervised   <ref type="table">Table 5</ref>: Spearman correlation scores of state-of-the-art ADMs and MDD-Eval variants on the six dialogue evaluation benchmarks. Scores with p-values larger than 0.05 are underlined (indicating statistical insignificance). The best score for each benchmark is highlighted in bold. The ablation metrics include MDD-T, MDD-C and MDD-CM, which refer to the teacher model, the student model optimized with only L CE , and the student model optimized with both L M LM and L CE respectively. MDD-S is the full student model optimized with all three losses.</p><p>learning and pretrained language models. It can be observed that uBERT-R performs much worse than the MDD-Eval variants. There are two major reasons. First, uBERT-R acquires the rating skill to discriminate varying-quality responses in a self-supervised manner. The random sampling strategy adopted by uBERT-R is prone to introduction of false-negative and over-simplistic samples that can negatively impact the evaluation performance. The better performance of MDD-T than uBERT-R indicates that the humandesigned sampling strategy is much more useful than the automatic random sampling scheme for equipping ADMs with the rating skill. Second, MDD-S generalizes the rating skill to multiple domains with a self-training framework in which additional inductive biases are incorporated, including mask language modeling and consistency regularization. The much better performance of MDD-S than uBERT-R showcases that semi-supervised learning is a promising option in improving dialogue evaluation performance compared to purely unsupervised learning.</p><p>MDD-Eval vs DEB DEB and MDD-Eval variants are learned with the same classification task and their backbone model architectures are also similar. The only difference between MDD-T and DEB is that DEB is equipped with the general knowledge about dialogues across multiple domains through pretraining on 727M Reddit conversations with the MLM objective. As a result, DEB outperforms MDD-T by 3.5% in terms of the average Spearman correlation score.</p><p>This shows that pretraining on large-scale conversations is useful for the multi-domain dialogue evaluation task. However, DEB performs worse than MDD-S, which is trained only on 600K context-response pairs. The key difference between MDD-S and DEB is the generalization strategy. DEB adopts the pretrain-and-finetune paradigm whereas MDD-S adopts self-training. The more superior performance of MDD-S confirms that the self-training strategy is more effective and data-efficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MDD-Eval vs Other Metrics</head><p>Even though GRADE, USL-H, USR, and D-score, have different training configurations, each of them have its unique strengths. Unlike uBERT-R, the four metrics have additional knowledge to generalize their evaluation skill. GRADE leverages Conceptnet Numberbatch <ref type="bibr" target="#b32">(Speer, Chin, and Havasi 2017)</ref>, which provides additional commonsense knowledge and topic information, to aid the self-supervised learning process. USR, USL-H and D-score consist of multiple model-based sub-metrics, and hence, they leverage more inductive biases for the task. It can be observed that MDD-S significantly outperforms the four state-of-the-art-metrics, confirming the effectiveness of the proposed self-training strategy for evaluation skill generalization. Since none of the current state-of-the-art metrics is explicitly designed to target the multi-domain dialogue evaluation problem, MDD-Eval helps bridge this gap.  may be concern that some state-of-the-art metrics are trained on much less data or fewer dialogue domains compared to MDD-S. We presents the results w.r.t USL-H, USR, and GRADE in <ref type="table" target="#tab_6">Table 6</ref>. These three metrics are trained on a combined dataset, which contains the training data of all four dialogue corpora used to construct MDD-Data. We didn't include DEB (the best performing baseline) here, because DEB has already been pre-trained on large-scale Reddit conversations (?767M), and then finetuned on the highquality DailyDialog++ dataset. We hypothesize that further finetuning DEB an mixed data will suffer from catastrophic forgetting. In addition, it can be observed that our MDD-C approach, which has similar model architecture and objective function as DEB, outperforms DEB on average, but performs worse compared to the final MDD-S metric. It can be observed that simply combining dialogue data from different domains and training ADMs on the combined data in a self-supervised fashion don't bring robust performance for multi-domain dialogue evaluation. Hence, we need mechanism to filter undesirable data while keeping the ones useful to the evaluation task in order to construct a high-quality multi-domain dataset. MDD-Eval offers a simple, yet effective way to realize that.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of Combining Data of Different Domains</head><p>Error Analysis We can observe in <ref type="table">Table 5</ref> that DEB outperforms MDD-S on Movie-Eval by a large margin. Similarly, D-score also outperforms MDD-S on Twitter-Eval by a large margin. We hypothesize this is because DEB has been pre-trained on 767M Reddit conversations (that could con-tain information about movies). In addition, we directly use a D-score checkpoint, which is trained on Twitter dialogues, for evaluating D-score's performance on Twitter-Eval. However, for MDD-S, the data distributions of Movie-Eval and Twitter-Eval are very different from its training datasets. This problem can be easily addressed by extend the MDDdata to both the movie, and the twitter domains.</p><p>To further analyze the limitations of MDD-Eval, we select a dialogue context and four candidate responses from the DailyDialog-Eval, and then, perform a case study on how MDD-S score the responses. The case study is presented in <ref type="figure">Figure 3</ref>. Firstly, it can be observed that MDD-S provides a high score to a generic response, "I do n't know" while human annotators deem it inappropriate. Future work on MDD-Eval needs to consider modeling specificity.</p><p>In addition, the metric focuses more on the neighbouring context, and struggles to capture key information in the longer context. For example, it doesn't recognize that the conversation is about "bus pass", which has little association with "book store" in candidate B. However, candidate B is somehow directive w.r.t its previous utterance (making a suggestion). Hence, MDD-S assigns a high score to candidate B. Future work may consider explicit modeling of speaker dependency, utterance dependency <ref type="bibr" target="#b38">(Zhang et al. 2021a)</ref>, and the entity transition pattern within the dialogues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We target the multi-domain dialogue evaluation problem and approach the problem with two research questions: (1) How can an ADM learn the rating skill to discriminate responses of varying quality? (2) How can the ADM acquire the general knowledge across different dialogue domains so as to generalize the evaluation skill? We propose MDD-Eval to address the two research questions. Specifically, a teacher evaluator is trained with human-annotated data to acquire the skill to distinguish good context-respons pairs from bad ones in a particular domain. Then, a new evaluator is trained with the teacher-annotated multi-domain data so as to generalizes the evaluation skill across multiple domains. Empirical results demonstrate that MDD-Eval is effective and robust for the multi-domain dialogue evaluation task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>An example of a dialogue context with three candidate responses. M teacher is expected to annotate the contextresponse pairs as either relevant, adversarial or random.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The training process of M student . L T otal is the sum of three components: (1) The cross entropy loss L CE , which is computed between? * i generated by M teacher and the prediction by M student for an input pair (c * i , r * i ) .(2) The self-supervised MLM loss L M LM , for domain adaptation.(3) The KL Loss L KL , for consistency regularization. set consists of filtered pairs obtained with back-translation and generative models in addition to the original contextresponse pairs extracted from dialogues of different dialogue corpora. The adversarial set mainly include filtered pairs that are constructed via syntactic perturbation and mask-and-fill strategy. For the random set, the context-response pairs are mainly obtained with random utterance selection.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Human-Human Dialogue Corpora Statistics</figDesc><table><row><cell>Name</cell><cell cols="3">#Instances Avg.#Utts. Avg.#Ctx/Hyp Words</cell><cell>Type</cell><cell cols="3">#Criteria #Annotations Used NLG models</cell></row><row><cell>Persona-Eval (2020)</cell><cell>900</cell><cell>5.1</cell><cell>48.8 / 11.5</cell><cell>Turn-level</cell><cell>1</cell><cell>3,600</cell><cell>LSTM Seq2Seq, Random sampling, and GPT-2</cell></row><row><cell>DailyDialog-Eval (2020)</cell><cell>900</cell><cell>4.7</cell><cell>47.5 / 11.0</cell><cell>Turn-level</cell><cell>4</cell><cell>14,400</cell><cell>LSTM Seq2Seq, Random sampling, and GPT-2</cell></row><row><cell>Topical-Eval (2020b)</cell><cell>360</cell><cell>11.2</cell><cell>236.3 / 22.4</cell><cell>Turn-level</cell><cell>6</cell><cell>6,480</cell><cell>Transformers</cell></row><row><cell>Empathetic-Eval (2020)</cell><cell>300</cell><cell>3.0</cell><cell>29.0 / 15.6</cell><cell>Turn-level</cell><cell>1</cell><cell>3,000</cell><cell>Transformer Seq2Seq, Transformer Ranker</cell></row><row><cell>Twitter-Eval (2017)</cell><cell>9,990</cell><cell>3.5</cell><cell>35.3 / 11.2</cell><cell>Turn-level</cell><cell>3</cell><cell>29,700</cell><cell>RNN, LSTM Seq2Seq</cell></row><row><cell>Movie-Eval (2020)</cell><cell>9,500</cell><cell>3.9</cell><cell>17.0 / 6.1</cell><cell>Turn-level</cell><cell>2</cell><cell>57,000</cell><cell>Random sampling</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 4 :</head><label>4</label><figDesc>Training details of model-based metrics. 'Training Dataset' and 'Size' indicate the training dialogue corpora and training data size in terms of the number of context-response pairs respectively. 'Pretrained Model' and 'Objective' refer to the backbone pretrained language model and the loss function used by the metrics accordingly. 'External Knowledge' means whether the training process leverages additional knowledge sources. 'Single' denotes that whether a metric is a single evaluation model or a combination of multiple evaluation models. 'Unknown' means that information is not publicly available.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Baselines</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Ablation Metrics</cell><cell>Final</cell></row><row><cell>Benchmarks</cell><cell cols="10">DEB USL-H GRADE USR uBERT-R D-score MDD-T MDD-C MDD-CM MDD-S</cell></row><row><cell cols="2">DailyDialog-Eval 0.486</cell><cell>0.391</cell><cell>0.533</cell><cell>0.367</cell><cell>0.285</cell><cell>0.426</cell><cell>0.501</cell><cell>0.482</cell><cell>0.546</cell><cell>0.579</cell></row><row><cell>Persona-Eval</cell><cell>0.579</cell><cell>0.407</cell><cell>0.583</cell><cell>0.571</cell><cell>0.384</cell><cell>0.511</cell><cell>0.528</cell><cell>0.580</cell><cell>0.594</cell><cell>0.621</cell></row><row><cell>Topical-Eval</cell><cell>0.116</cell><cell>0.340</cell><cell>0.217</cell><cell>0.423</cell><cell>0.348</cell><cell>0.233</cell><cell>0.218</cell><cell>0.373</cell><cell>0.484</cell><cell>0.520</cell></row><row><cell>Empathetic-Eval</cell><cell>0.395</cell><cell>0.235</cell><cell>0.297</cell><cell>0.255</cell><cell>0.148</cell><cell>0.087</cell><cell>0.345</cell><cell>0.404</cell><cell>0.404</cell><cell>0.374</cell></row><row><cell>Movie-Eval</cell><cell>0.649</cell><cell>0.531</cell><cell>0.612</cell><cell>0.366</cell><cell>0.388</cell><cell>0.340</cell><cell>0.383</cell><cell>0.556</cell><cell>0.524</cell><cell>0.537</cell></row><row><cell>Twitter-Eval</cell><cell>0.214</cell><cell>0.179</cell><cell>0.122</cell><cell>0.166</cell><cell>0.217</cell><cell>0.301</cell><cell>0.249</cell><cell>0.258</cell><cell>0.241</cell><cell>0.227</cell></row><row><cell>Average</cell><cell>0.407</cell><cell>0.347</cell><cell>0.394</cell><cell>0.358</cell><cell>0.295</cell><cell>0.316</cell><cell>0.371</cell><cell>0.442</cell><cell>0.466</cell><cell>0.476</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 6 :</head><label>6</label><figDesc>Spearman correlation scores of USR, USL-H, and GRADE trained on the combined dataset.</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">https://github.com/e0397123/MDD-Eval</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">* means that the context-response pair can be drawn from dialogue corpora of any domain.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The names of the datasets are unified in our paper to better distinguish their respective domains.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We would like to thank all the reviewers for their constructive comments. This work is supported by Science and Engineering Research Council, Agency of Science, Technology and Research (A*STAR), Singapore, through the National Robotics Program under Human-Robot Interaction Phase 1 (Grant No. 192   <ref type="formula">25 00054)</ref>; Human Robot Collaborative AI under its AME Programmatic Funding Scheme (Project No. A18A2b0046); Robert Bosch (SEA) Pte Ltd under EDB's Industrial Postgraduate Programme -II (EDB-IPP), project title: Applied Natural Language Processing; The work leading to these results is also part of the project GOMINOLA (PID2020-118112RB-C22) funded by MCIN/AEI/10.13039/501100011033 and project AMIC-PoC (PDC2021-120846-C42) funded by MCIN/AEI/10.13039/501100011033 and by "the European Union "NextGenerationEU/PRTR".</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Adiwardana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Fiedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Thoppilan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kulshreshtha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Nemade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2001.09977</idno>
		<title level="m">Towards a human-like open-domain chatbot</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning with pseudo-ensembles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Bachman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Alsharif</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Precup</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="3365" to="3373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">ReMixMatch: Semi-Supervised Learning with Distribution Matching and Augmentation Anchoring</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The second conversational intelligence challenge (convai2)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Malykh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Shuster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The NeurIPS&apos;18 Competition</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="187" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Enabling Language Models to Fill in the Blanks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Donahue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="2492" to="2501" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Understanding Back-Translation at Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="489" to="500" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Better Automatic Evaluation of Open-Domain Dialogue Systems with Contextualized Embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghazarian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Workshop on Methods for Optimizing and Evaluating Neural Language Generation</title>
		<meeting>the Workshop on Methods for Optimizing and Evaluating Neural Language Generation</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gopalakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hedayatnia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gottardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kwatra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Venkatesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Gabriel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hakkani-T?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename></persName>
		</author>
		<editor>IN-TERSPEECH</editor>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1891" to="1895" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Synthesizing Adversarial Negative Responses for Robust Response Ranking and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Tsvetkov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bigham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="3867" to="3883" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Revisiting Self-Training for Neural Sequence Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ranzato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Liang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.07440</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<publisher>EMNLP</publisher>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>End-to-end conversation modeling track in DSTC6</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Self-training for end-to-end speech recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hannun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="7084" to="7088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on challenges in representation learning, ICML</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">896</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">DailyDialog: A Manually Labelled Multi-turn Dialogue Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Niu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the eight International Joint Conference on Natural Language Processing</title>
		<meeting>the eight International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="986" to="995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">ROUGE: A Package for Automatic Evaluation of Summaries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Text Summarization Branches Out</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Serban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Noseworthy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Charlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2016 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m">RoBERTa: A Robustly Optimized BERT Pretraining Approach</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Effective Self-Training for Parsing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johnson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Human Language Technology Conference of the NAACL, Main Conference</title>
		<meeting>the Human Language Technology Conference of the NAACL, Main Conference</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Unsupervised Evaluation of Interactive Dialog with DialoGPT</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</title>
		<meeting>the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="225" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">USR: An Unsupervised and Reference Free Evaluation Metric for Dialog Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Human Annotated Dialogues Dataset for Natural Conversational Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Merdivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hanke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kropf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Holzinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Geist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ward</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W.-J</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 40th annual meeting of the Association for Computational Linguistics</title>
		<meeting>the 40th annual meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="311" to="318" />
		</imprint>
	</monogr>
	<note>Bleu: a method for automatic evaluation of machine translation</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Generating Negative Samples by Manipulating Golden Responses for Unsupervised Learning of a Response Evaluation Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="1525" to="1534" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Deconstruct to Reconstruct a Configurable Evaluation Metric for Open-Domain Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Phy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 28th International Conference on Computational Linguistics</title>
		<meeting>the 28th International Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4164" to="4178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Language models are unsupervised multitask learners</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>OpenAI blog</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rashkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 57th</title>
		<meeting>the 57th</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<title level="m">Annual Meeting of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="page" from="5370" to="5381" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Recipes for Building an Open-Domain Chatbot</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Williamson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-L</forename><surname>Boureau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 16th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="300" to="325" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Improving Dialog Evaluation with a Multireference Adversarial Dataset and Large Scale Pretraining. Transactions of the Association for Computational Linguistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">B</forename><surname>Sai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">K</forename><surname>Mohankumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Probability of error of some adaptive pattern-recognition machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Scudder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="363" to="371" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Learning an Unreferenced Metric for Online Dialogue Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Parthasarathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">L</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pineau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Raffel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">ConceptNet 5.5: An Open Multilingual Graph of General Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Speer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Havasi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="4444" to="4451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Ruber: An unsupervised method for automatic evaluation of open-domain dialog systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Unsupervised Data Augmentation for Consistency Training</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page">33</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Selftraining with noisy student improves imagenet classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-T</forename><surname>Luong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<biblScope unit="page" from="10687" to="10698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Yarowsky, D. 1995. Unsupervised word sense disambiguation rivaling supervised methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">Z</forename><surname>Yalniz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>J?gou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Mahajan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.00546</idno>
	</analytic>
	<monogr>
		<title level="m">33rd annual meeting of the association for computational linguistics</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
	<note>Billion-scale semi-supervised learning for image classification</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">A Comprehensive Assessment of Dialog Evaluation Metrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-T</forename><surname>Yeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mehri</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.03706</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">DynaEval: Unifying Turn and Dialogue Level Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Friedrichs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="5676" to="5689" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Friedrichs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.01895</idno>
		<title level="m">Investigating the Impact of Pre-trained Language Models on Dialog Evaluation</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">D-Score: Holistic Dialogue Evaluation Without Reference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
			</analytic>
	<monogr>
		<title level="m">Speech, and Language Processing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="2502" to="2516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Automatic Evaluation and Moderation of Open-domain Dialogue Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sedoc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">F</forename><surname>Haro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Banchs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rudnicky</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.02110</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Personalizing Dialogue Agents: I have a dog, do you have pets too?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Dinan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Urbanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Szlam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2204" to="2213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Brockett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="270" to="278" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Designing Precise and Robust Dialogue Response Evaluators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kawahara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="26" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Learning Discourse-level Diversity for Neural Dialog Models using Conditional Variational Autoencoders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Eskenazi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 55th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
