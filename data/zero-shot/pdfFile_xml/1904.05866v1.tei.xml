<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Expressive Body Capture: 3D Hands, Face, and Body from a Single Image</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
							<email>gpavlakos@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<region>DE</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vasileios</forename><surname>Choutas</surname></persName>
							<email>vchoutas@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<region>DE</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
							<email>nghorbani@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<region>DE</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
							<email>tbolkart@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<region>DE</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ahmed</forename><forename type="middle">A A</forename><surname>Osman</surname></persName>
							<email>aosman@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<region>DE</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
							<email>dtzionas@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<region>DE</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
							<email>black@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="institution">MPI for Intelligent Systems</orgName>
								<address>
									<settlement>T?bingen</settlement>
									<region>DE</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Expressive Body Capture: 3D Hands, Face, and Body from a Single Image</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>To facilitate the analysis of human actions, interactions and emotions, we compute a 3D model of human body pose, hand pose, and facial expression from a single monocular image. To achieve this, we use thousands of 3D scans to train a new, unified, 3D model of the human body, SMPL-X, that extends SMPL with fully articulated hands and an expressive face. Learning to regress the parameters of SMPL-X directly from images is challenging without paired images and 3D ground truth. Consequently, we follow the approach of SMPLify, which estimates 2D features and then optimizes model parameters to fit the features. We improve on SMPLify in several significant ways: (1) we detect 2D features corresponding to the face, hands, and feet and fit the full SMPL-X model to these; (2) we train a new neural network pose prior using a large MoCap dataset; (3) we define a new interpenetration penalty that is both fast and accurate; (4) we automatically detect gender and the appropriate body models (male, female, or neutral); (5) our PyTorch implementation achieves a speedup of more than 8? over Chumpy. We use the new method, SMPLify-X, to fit SMPL-X to both controlled images and images in the wild. We evaluate 3D accuracy on a new curated dataset comprising 100 images with pseudo ground-truth. This is a step towards automatic expressive human capture from monocular RGB data. The models, code, and data are available for research purposes at https://smpl-x.is.tue.mpg.de.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Humans are often a central element in images and videos. Understanding their posture, the social cues they communicate, and their interactions with the world is critical for holistic scene understanding. Recent methods have shown rapid progress on estimating the major body joints, hand joints and facial features in 2D <ref type="bibr">[15,</ref><ref type="bibr" target="#b29">31,</ref><ref type="bibr" target="#b67">69]</ref>. Our interactions with the world, however, are fundamentally 3D and recent work has also made progress on the 3D estimation * equal contribution <ref type="figure" target="#fig_3">Figure 1</ref>: Communication and gesture rely on the body pose, hand pose, and facial expression, all together. The major joints of the body are not sufficient to represent this and current 3D models are not expressive enough. In contrast to prior work, our approach estimates a more detailed and expressive 3D model from a single image. From left to right: RGB image, major joints, skeleton, SMPL (female), SMPL-X (female). The hands and face in SMPL-X enable more holistic and expressive body capture. of the major joints and rough 3D pose directly from single images <ref type="bibr">[10,</ref><ref type="bibr" target="#b35">37,</ref><ref type="bibr" target="#b56">58,</ref><ref type="bibr" target="#b59">61]</ref>.</p><p>To understand human behavior, however, we have to capture more than the major joints of the body -we need the full 3D surface of the body, hands and the face. There is no system that can do this today due to several major challenges including the lack of appropriate 3D models and rich 3D training data. <ref type="figure" target="#fig_3">Figure 1</ref> illustrates the problem. The interpretation of expressive and communicative images is difficult using only sparse 2D information or 3D representations that lack hand and face detail. To address this problem, we need two things. First, we need a 3D model of the body that is able to represent the complexity of human faces, hands, and body pose. Second, we need a method to extract such a model from a single image.</p><p>Advances in neural networks and large datasets of manually labeled images have resulted in rapid progress in 2D human "pose" estimation. By "pose", the field often means the major joints of the body. This is not sufficient to understand human behavior as illustrated in <ref type="figure" target="#fig_3">Fig. 1</ref>. OpenPose <ref type="bibr">[15,</ref><ref type="bibr" target="#b57">59,</ref><ref type="bibr" target="#b67">69]</ref> expands this to include the 2D hand joints and 2D facial features. While this captures much more about the communicative intent, it does not support reasoning about surfaces and human interactions with the 3D world.</p><p>Models of the 3D body have focused on capturing the overall shape and pose of the body, excluding the hands and face <ref type="bibr">[2,</ref><ref type="bibr">3,</ref><ref type="bibr">6,</ref><ref type="bibr">26,</ref><ref type="bibr" target="#b46">48]</ref>. There is also an extensive literature on modelling hands <ref type="bibr" target="#b37">[39,</ref><ref type="bibr" target="#b50">52,</ref><ref type="bibr" target="#b54">56,</ref><ref type="bibr" target="#b55">57,</ref><ref type="bibr" target="#b65">67,</ref><ref type="bibr" target="#b66">68,</ref><ref type="bibr" target="#b68">70,</ref><ref type="bibr" target="#b71">73,</ref><ref type="bibr" target="#b72">74]</ref> and faces <ref type="bibr">[4,</ref><ref type="bibr">9,</ref><ref type="bibr">11,</ref><ref type="bibr">13,</ref><ref type="bibr">14,</ref><ref type="bibr" target="#b41">43,</ref><ref type="bibr" target="#b60">62,</ref><ref type="bibr" target="#b73">75,</ref><ref type="bibr" target="#b76">78]</ref> in 3D but in isolation from the rest of the body. Only recently has the field begun modeling the body together with hands <ref type="bibr" target="#b65">[67]</ref>, or together with the hands and face <ref type="bibr" target="#b34">[36]</ref>. The Frank model <ref type="bibr" target="#b34">[36]</ref>, for example, combines a simplified version of the SMPL body model <ref type="bibr" target="#b46">[48]</ref>, with an artist-designed hand rig, and the FaceWarehouse <ref type="bibr">[14]</ref> face model. These disparate models are stitched together, resulting in a model that is not fully realistic.</p><p>Here we learn a new, holistic, body model with face and hands from a large corpus of 3D scans. The new SMPL-X model (SMPL eXpressive) is based on SMPL and retains the benefits of that model: compatibility with graphics software, simple parametrization, small size, efficient, differentiable, etc. We combine SMPL with the FLAME head model <ref type="bibr" target="#b41">[43]</ref> and the MANO hand model <ref type="bibr" target="#b65">[67]</ref> and then register this combined model to 5586 3D scans that we curate for quality. By learning the model from data, we capture the natural correlations between the shape of bodies, faces and hands and the resulting model is free of the artifacts seen with Frank. The expressivity of the model can be seen in <ref type="figure" target="#fig_0">Fig. 2</ref> where we fit SMPL-X to expressive RGB images, as well as in <ref type="figure">Fig. 4</ref> where we fit SMPL-X to images of the public LSP dataset <ref type="bibr" target="#b31">[33]</ref>. SMPL-X is freely available for research purposes.</p><p>Several methods use deep learning to regress the parameters of SMPL from a single image <ref type="bibr" target="#b35">[37,</ref><ref type="bibr" target="#b56">58,</ref><ref type="bibr" target="#b59">61]</ref>. To estimate a 3D body with the hands and face though, there exists no suitable training dataset. To address this, we follow the approach of SMPLify. First, we estimate 2D image features "bottom up" using OpenPose <ref type="bibr">[15,</ref><ref type="bibr" target="#b67">69,</ref><ref type="bibr" target="#b74">76]</ref>, which detects the joints of the body, hands, feet, and face features. We then fit the SMPL-X model to these 2D features "top down", with our method called SMPLify-X. To do so, we make several significant improvements over SMPLify. Specifically, we learn a new, and better performing, pose prior from a large dataset of motion capture data <ref type="bibr" target="#b45">[47,</ref><ref type="bibr" target="#b48">50]</ref> using a variational auto-encoder. This prior is critical because the mapping from 2D features to 3D pose is ambiguous. We also define a new (self-) interpenetration penalty term that is significantly more accurate and efficient than the approximate method in SMPLify; it remains differentiable. We train a gender detector and use this to automatically determine what body model to use, either male, female or gender neutral. Finally, one motivation for training direct regression methods to estimate SMPL parameters is that SMPLify is slow. Here we address this with a PyTorch implementation that is at least 8 times faster than the corresponding Chumpy implementation, by leveraging the computing power of modern GPUs. Examples of this SMPLify-X method are shown in <ref type="figure" target="#fig_0">Fig. 2</ref>.</p><p>To evaluate the accuracy, we need new data with fullbody RGB images and corresponding 3D ground truth bodies. To that end, we curate a new evaluation dataset containing images of a subject performing a wide variety of poses, gestures and expressions. We capture 3D body shape using a scanning system and we fit the SMPL-X model to the scans. This form of pseudo ground-truth is accurate enough to enable quantitative evaluations for models of body, hands and faces together. We find that our model and method performs significantly better than related and less powerful models, resulting in natural and expressive results.</p><p>We believe that this work is a significant step towards expressive capture of bodies, hands and faces together from a single RGB image. We make available for research purposes the SMPL-X model, SMPLify-X code, trained networks, model fits, and the evaluation dataset at https://smpl-x.is.tue.mpg.de.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work 2.1. Modeling the body</head><p>Bodies, Faces and Hands. The problem of modeling the 3D body has previously been tackled by breaking the body into parts and modeling these parts separately. We focus on methods that learn statistical shape models from 3D scans.</p><p>Blanz and Vetter <ref type="bibr">[9]</ref> pioneered this direction with their 3D morphable face model. Numerous methods since then have learned 3D face shape and expression from scan data; see <ref type="bibr">[13,</ref><ref type="bibr" target="#b78">80]</ref> for recent reviews. A key feature of such models is that they can represent different face shapes and a wide range of expressions, typically using blend shapes inspired by FACS <ref type="bibr">[21]</ref>. Most approaches focus only on the face region and not the whole head. FLAME <ref type="bibr" target="#b41">[43]</ref>, in contrast, models the whole head, captures 3D head rotations, and also models the neck region; we find this critical for connecting the head and the body. None of these methods, model correlations in face shape and body shape.</p><p>The availability of 3D body scanners enabled learning of body shape from scans. In particular the CAESAR dataset <ref type="bibr" target="#b64">[66]</ref> opened up the learning of shape <ref type="bibr">[2]</ref>. Most early work focuses on body shape using scans of people in roughly the same pose. Anguelov et al. <ref type="bibr">[6]</ref> combined shape with scans of one subject in many poses to learn a factored model of body shape and pose based on triangle deformations. Many models followed this, either using triangle deformations <ref type="bibr">[16,</ref><ref type="bibr">23,</ref><ref type="bibr">26,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b61">63]</ref> or vertex-based displacements <ref type="bibr">[3,</ref><ref type="bibr">27,</ref><ref type="bibr" target="#b46">48]</ref>, however they all focus on modeling body shape and pose without the hands or face. These methods assume that the hand is either in a fist or an open pose and that the face is in a neutral expression.</p><p>Similarly, hand modeling approaches typically ignore the body. Additionally, 3D hand models are typically not learned but either are artist designed <ref type="bibr" target="#b68">[70]</ref>, based on shape primitives <ref type="bibr" target="#b50">[52,</ref><ref type="bibr" target="#b55">57,</ref><ref type="bibr" target="#b66">68]</ref>, reconstructed with multiview stereo and have fixed shape <ref type="bibr">[8,</ref><ref type="bibr" target="#b72">74]</ref>, use non-learned per-part scaling parameters <ref type="bibr">[19]</ref>, or use simple shape spaces <ref type="bibr" target="#b71">[73]</ref>. Only recently <ref type="bibr" target="#b37">[39,</ref><ref type="bibr" target="#b65">67]</ref> have learned hand models appeared in the literature. Khamis et al. <ref type="bibr" target="#b37">[39]</ref> collect partial depth maps of 50 people to learn a model of shape variation, however they do not capture a pose space. Romero et al. <ref type="bibr" target="#b65">[67]</ref> on the other side learn a parametric hand model (MANO) with both a rich shape and pose space using 3D scans of 31 subjects in up to 51 poses, following the SMPL <ref type="bibr" target="#b46">[48]</ref> formulation.</p><p>Unified Models. The most similar models to ours are Frank <ref type="bibr" target="#b34">[36]</ref> and SMPL+H <ref type="bibr" target="#b65">[67]</ref>. Frank stitches together three different models: SMPL (with no pose blend shapes) for the body, an artist-created rig for the hands, and the FaceWarehouse model <ref type="bibr">[14]</ref> for the face. The resulting model is not fully realistic. SMPL+H combines the SMPL body with a 3D hand model that is learned from 3D scans. The shape variation of the hand comes from full body scans, while the pose dependent deformations are learned from a dataset of hand scans. SMPL+H does not contain a deformable face.</p><p>We start from the publicly-available SMPL+H <ref type="bibr" target="#b49">[51]</ref> and add the publicly-available FLAME head model <ref type="bibr">[22]</ref> to it. Unlike Frank, however, we do not simply graft this onto the body. Instead we take the full model and fit it to 5586 3D scans and learn the shape and pose-dependent blend shapes. This results in a natural looking model with a consistent parameterization. Being based on SMPL, it is differentiable and easy to swap into applications that already use SMPL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Inferring the body</head><p>There are many methods that estimate 3D faces from images or RGB-D <ref type="bibr" target="#b78">[80]</ref> as well as methods that estimate hands from such data <ref type="bibr" target="#b77">[79]</ref>. While there are numerous methods that estimate the location of 3D joints from a single image, here we focus on methods that extract a full 3D body mesh.</p><p>Several methods estimate the SMPL model from a single image <ref type="bibr" target="#b35">[37,</ref><ref type="bibr" target="#b39">41,</ref><ref type="bibr" target="#b56">58,</ref><ref type="bibr" target="#b59">61]</ref>. This is not trivial due to a paucity of training images with paired 3D model parameters. To address this, SMPLify <ref type="bibr">[10]</ref> detects 2D image features "bottom up" and then fits the SMPL model to these "top down" in an optimization framework. In <ref type="bibr" target="#b39">[41]</ref> these SMPLify fits are used to iteratively curate a training set of paired data to train a direct regression method. HMR <ref type="bibr" target="#b35">[37]</ref> trains a model without paired data by using 2D keypoints and an adversary that knows about 3D bodies. Like SMPLify, NBF <ref type="bibr" target="#b56">[58]</ref> uses an intermediate 2D representation (body part segmentation) and infers 3D pose from this intermediate representation.</p><p>MonoPerfCap <ref type="bibr" target="#b75">[77]</ref> infers 3D pose while also refining surface geometry to capture clothing. These methods estimate only the 3D pose of the body without the hands or face.</p><p>There are also many multi-camera setups for capturing 3D pose, 3D meshes (performance capture), or parametric 3D models <ref type="bibr" target="#b6">[7,</ref><ref type="bibr">20,</ref><ref type="bibr">24,</ref><ref type="bibr" target="#b28">30,</ref><ref type="bibr" target="#b33">35,</ref><ref type="bibr" target="#b44">46,</ref><ref type="bibr" target="#b51">53,</ref><ref type="bibr" target="#b63">65,</ref><ref type="bibr" target="#b69">71]</ref>. Most relevant is the Panoptic studio <ref type="bibr" target="#b33">[35]</ref> which shares our goal of capturing rich, expressive, human interactions. In <ref type="bibr" target="#b34">[36]</ref>, the Frank model parameters are estimated from multi-camera data by fitting the model to 3D keypoints and 3D point clouds. The capture environment is complex, using 140 VGA cameras for the body, 480 VGA cameras for the feet, and 31 HD cameras for the face and hand keypoints. We aim for a similar level of expressive detail but from a single RGB image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Technical approach</head><p>In the following we describe SMPL-X (Section 3.1), and our approach (Section 3.2) for fitting SMPL-X to single RGB images. Compared to SMPLify <ref type="bibr">[10]</ref>, SMPLify-X uses a better pose prior (Section 3.3), a more detailed collision penalty (Section 3.4), gender detection (Section 3.5), and a faster PyTorch implementation (Section 3.6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Unified model: SMPL-X</head><p>We create a unified model, called SMPL-X, for SMPL eXpressive, with shape parameters trained jointly for the face, hands and body. SMPL-X uses standard vertexbased linear blend skinning with learned corrective blend shapes, has N = 10, 475 vertices and K = 54 joints, which includes joints for the neck, jaw, eyeballs and fingers. SMPL-X is defined by a function M (?, ?, ?) : R |?|?|?|?|?| ? R 3N , parameterized by the pose ? ? R 3(K+1) where K is the number of body joints in addition to a joint for global rotation. We decompose the pose parameters ? into: ? f for the jaw joint, ? h for the finger joints, and ? b for the remaining body joints. The joint body, face and hands shape parameters are noted by ? ? R |?| and the facial expression parameters by ? ? R |?| . More formally:</p><formula xml:id="formula_0">M (?, ?, ?) = W (T p (?, ?, ?) , J (?) , ?, W)<label>(1)</label></formula><formula xml:id="formula_1">T P (?, ?, ?) =T + B S (?; S) + B E (?; E) + B P (?; P)<label>(2)</label></formula><p>where B S (?; S) = |?| n=1 ? n S n is the shape blend shape function, ? are linear shape coefficients, |?| is their number, S n ? R 3N are orthonormal principle components of vertex displacements capturing shape variations due to different person identity, and S = S 1 , . . . , S |?| ? R 3N ?|?| is a matrix of all such displacements. B P (?; P) : R |?| ? R 3N is the pose blend shape function, which adds corrective vertex displacements to the template meshT as in SMPL <ref type="bibr" target="#b45">[47]</ref>:</p><formula xml:id="formula_2">B P (?; P) = 9K n=1 (R n (?) ? R n (? * ))P n ,<label>(3)</label></formula><p>where R : R |?| ? R 9K is a function mapping the pose vector ? to a vector of concatenated part-relative rotation matrices, computed with the Rodrigues formula <ref type="bibr">[12,</ref><ref type="bibr" target="#b52">54,</ref><ref type="bibr" target="#b62">64]</ref> and R n (?) is the n th element of R(?), ? * is the pose vector of the rest pose, P n ? R 3N are again orthonormal principle components of vertex displacements, and P = [P 1 , . . . , P 9K ] ? R 3N ?9K is a matrix of all pose blend shapes. B E (?; E) = |?| n=1 ? n E is the expression blend shape function, where E are principle components capturing variations due to facial expressions and ? are PCA coefficients. Since 3D joint locations J vary between bodies of different shapes, they are a function of body shape J(?) = J T + B S (?; S) , where J is a sparse linear regressor that regresses 3D joint locations from mesh vertices. A standard linear blend skinning function W (.) <ref type="bibr" target="#b40">[42]</ref> rotates the vertices in T p (.) around the estimated joints J(?) smoothed by blend weights W ? R N ?K .</p><p>We start with an artist designed 3D template, whose face and hands match the templates of FLAME <ref type="bibr" target="#b41">[43]</ref> and MANO <ref type="bibr" target="#b65">[67]</ref>. We fit the template to four datasets of 3D human scans to get 3D alignments as training data for SMPL-X. The shape space parameters, {S}, are trained on 3800 alignments in an A-pose capturing variations across identities <ref type="bibr" target="#b64">[66]</ref>. The body pose space parameters, {W, P, J }, are trained on 1786 alignments in diverse poses. Since the full body scans have limited resolution for the hands and face, we leverage the parameters of MANO <ref type="bibr" target="#b65">[67]</ref> and FLAME <ref type="bibr" target="#b41">[43]</ref>, learned from 1500 hand and 3800 head high resolution scans respectively. More specifically, we use the pose space and pose corrective blendshapes of MANO for the hands and the expression space E of FLAME.</p><p>The fingers have 30 joints, which correspond to 90 pose parameters (3 DoF per joint as axis-angle rotations). SMPL-X uses a lower dimensional PCA pose space for the hands such that ? h = |m h | n=1 m hn M, where M are principle components capturing the finger pose variations and m h are the corresponding PCA coefficients. As noted above, we use the PCA pose space of MANO, that is trained on a large dataset of 3D articulated human hands. The total number of model parameters in SMPL-X is 119: 75 for the global body rotation and { body, eyes , jaw } joints, 24 parameters for the lower dimensional hand pose PCA space, 10 for subject shape and 10 for the facial expressions. Additionally there are separate male and female models, which are used when the gender is known, and a shape space constructed from both genders for when gender is unknown. SMPL-X is realistic, expressive, differentiable and easy to fit to data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">SMPLify-X: SMPL-X from a single image</head><p>To fit SMPL-X to single RGB images (SMPLify-X), we follow SMPLify <ref type="bibr">[10]</ref> but improve every aspect of it. We formulate fitting SMPL-X to the image as an optimization problem, where we seek to minimize the objective function</p><formula xml:id="formula_3">E(?, ?, ?) = E J + ? ? b E ? b + ? ? f E ? f + ? m h E m h + ? ? E ? + ? ? E ? + ? E E E + ? C E C<label>(4)</label></formula><p>where ? b , ? f and m h are the pose vectors for the body, face and the two hands respectively, and ? is the full set of optimizable pose parameters. The body pose parameters are a function ? b (Z), where Z ? R 32 is a lower-dimensional pose space described in Section 3.3.</p><formula xml:id="formula_4">E J (?, ?, K, J est ) is the data term as described below, while the terms E m h (m h ), E ? f (? f ), E ? (?)</formula><p>and E E (?) are simple L 2 priors for the hand pose, facial pose, body shape and facial expressions, penalizing deviation from the neutral state. Since the shape space of SMPL-X is scaled for unit variance, similarly to <ref type="bibr" target="#b65">[67]</ref>, E ? (?) = ? 2 describes the Mahalanobis distance between the shape parameters being optimized and the shape distribution in the training dataset of SMPL-X. E ? (? b ) = i?(elbows,knees) exp(? i ) follows <ref type="bibr">[10]</ref> and is a simple prior penalizing extreme bending only for elbows and knees. We further employ</p><formula xml:id="formula_5">E ? b (? b ) that is a VAE-based body pose prior (Section 3.3), while E C (? b,h,f , ?)</formula><p>is an interpenetration penalty (Section 3.4). Finally, ? denotes weights that steer the influence of each term in Eq. 4. We empirically find that an annealing scheme for ? helps optimization (Section 3.6).</p><p>For the data term we use a re-projection loss to minimize the weighted robust distance between estimated 2D joints J est and the 2D projection of the corresponding posed 3D</p><formula xml:id="formula_6">joints R ? (J(?)) i of SMPL-X for each joint i, where R ? (?)</formula><p>is a function that transforms the joints along the kinematic tree according to the pose ?. Following the notation of <ref type="bibr">[10]</ref>, the data term is</p><formula xml:id="formula_7">E J (?, ?, K, J est ) = joint i ? i ? i ?(? K (R ? (J(?)) i ) ? J est,i )<label>(5)</label></formula><p>where ? K denotes the 3D to 2D projection with intrinsic camera parameters K. For the 2D detections we rely on the OpenPose library <ref type="bibr">[15,</ref><ref type="bibr" target="#b67">69,</ref><ref type="bibr" target="#b74">76]</ref>, which provides body, hands, face and feet keypoints jointly for each person in an image. To account for noise in the detections, the contribution of each joint in the data term is weighted by the detection confidence score ? i , while ? i are per-joint weights for annealed optimization, as described in Section 3.6. Finally, ? denotes a robust Geman-McClure error function <ref type="bibr">[25]</ref> for down weighting noisy detections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Variational Human Body Pose Prior</head><p>We seek a prior over body pose that penalizes impossible poses while allowing possible ones. SMPLify uses an approximation to the negative log of a Gaussian mixture model trained on MoCap data. While effective, we find that the SMPLify prior is not sufficiently strong. Consequently, we train our body pose prior, VPoser, using a variational autoencoder <ref type="bibr" target="#b38">[40]</ref>, which learns a latent representation of human pose and regularizes the distribution of the latent code to be a normal distribution. To train our prior, we use <ref type="bibr" target="#b45">[47,</ref><ref type="bibr" target="#b48">50]</ref> to recover body pose parameters from three publicly available human motion capture datasets: CMU <ref type="bibr" target="#b94">[17]</ref>, training set of Human3.6M <ref type="bibr" target="#b30">[32]</ref>, and the PosePrior dataset <ref type="bibr">[1]</ref>. Our training and test data respectively consist of roughly 1M, and 65k poses, in rotation matrix representation. Details on the data preparation procedure is given in Sup. Mat.</p><p>The training loss of the VAE is formulated as:</p><formula xml:id="formula_8">L total = c 1 L KL + c 2 L rec + c 3 L orth + c 4 L det1 + c 5 L reg (6) L KL = KL(q(Z|R)||N (0, I))<label>(7)</label></formula><p>L rec = ||R ?R|| 2 2 (8)</p><formula xml:id="formula_9">L orth = ||RR ? I|| 2 2 (9) L det1 = |det(R) ? 1| (10) L reg = ||?|| 2 2 ,<label>(11)</label></formula><p>where Z ? R 32 is the latent space of the autoencoder, R ? SO(3) are 3 ? 3 rotation matrices for each joint as the network input andR is a similarly shaped matrix representing the output. The Kullback-Leibler term in Eq. <ref type="formula" target="#formula_8">(7)</ref>, and the reconstruction term in Eq. <ref type="formula">(8)</ref> follow the VAE formulation in <ref type="bibr" target="#b38">[40]</ref>, while their role is to encourage a normal distribution on the latent space, and to make an efficient code to reconstruct the input with high fidelity. Eq. <ref type="formula">(9)</ref> and <ref type="formula" target="#formula_0">(10)</ref> encourage the latent space to encode valid rotation matrices. Finally, Eq. (11) helps prevent over-fitting by encouraging smaller network weights ?. Implementation details can be found in Sup. Mat. To employ VPoser in the optimization, rather than to optimize over ? b directly in Eq. 4, we optimize the parameters of a 32 dimensional latent space with a quadratic penalty on Z and transform this back into joint angles ? b in axis-angle representation. This is analogous to how hands are treated except that the hand pose ? h is projected into a linear PCA space and the penalty is on the linear coefficients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Collision penalizer</head><p>When fitting a model to observations, there are often self-collisions and penetrations of several body parts that are physically impossible. Our approach is inspired by SMPLify, that penalizes penetrations with an underlying collision model based on shape primitives, i.e. an ensemble of capsules. Although this model is computationally efficient, it is only a rough approximation of the human body.</p><p>For models like SMPL-X, that also model the fingers and facial details, a more accurate collision model in needed. To that end, we employ the detailed collision-based model for meshes from <ref type="bibr">[8,</ref><ref type="bibr" target="#b72">74]</ref>. We first detect a list of colliding triangles C by employing Bounding Volume Hierarchies (BVH) <ref type="bibr" target="#b70">[72]</ref> and compute local conic 3D distance fields ? defined by the triangles C and their normals n. Penetrations are then penalized by the depth of intrusion, efficiently computed by the position in the distance field. For two colliding triangles f s and f t , intrusion is bi-directional; the vertices v t of f t are the intruders in the distance field ? fs of the receiver triangle f s and are penalized by ? fs (v t ), and vice-versa. Thus, the collision term E C in the objective (Eq. 4) is defined as</p><formula xml:id="formula_10">E C (?) = (fs(?),ft(?))?C vs?fs ? ? ft (v s )n s 2 + vt?ft ? ? fs (v t )n t 2 .<label>(12)</label></formula><p>For technical details about ?, as well as details about handling collisions for parts with permanent or frequent selfcontact we redirect the reader to <ref type="bibr">[8,</ref><ref type="bibr" target="#b72">74]</ref> and Sup. Mat.. For computational efficiency, we use a highly parallelized implementation of BVH following <ref type="bibr" target="#b36">[38]</ref> with a custom CUDA kernel wrapped around a custom PyTorch operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Deep Gender Classifier</head><p>Men and women have different proportions and shapes. Consequently, using the appropriate body model to fit 2D data means that we should apply the appropriate shape space. We know of no previous method that automatically takes gender into account in fitting 3D human pose. In this work, we train a gender classifier that takes as input an image containing the full body and the OpenPose joints, and assigns a gender label to the detected person. To this end, we first annotate through Amazon Mechanical Turk a large dataset of images from LSP <ref type="bibr" target="#b31">[33]</ref>, LSP-extended <ref type="bibr" target="#b32">[34]</ref>, MPII <ref type="bibr">[5]</ref>, MS-COCO <ref type="bibr" target="#b43">[45]</ref>, and LIP datset <ref type="bibr" target="#b42">[44]</ref>, while following their official splits for train and test sets. The final dataset includes 50216 training examples and 16170 test samples (see Sup. Mat.). We use this dataset to fine tune a pretrained ResNet18 <ref type="bibr">[28]</ref> for binary gender classification. Moreover, we threshold the computed class probabilities, by using a class-equalized validation set, to obtain a good trade-off between discarded, correct, and incorrect predictions. We choose a threshold of 0.9 for accepting a predicted class, which yields 62.38% correct predictions, and 7.54% incorrect predictions on the validation set. At test time, we run the detector and fit the appropriate gendered model. When the detected class probability is below the threshold, we fit the gender-neutral body model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Optimization</head><p>SMPLify employs Chumpy and OpenDR <ref type="bibr" target="#b47">[49]</ref> which makes the optimization slow. To keep optimization of Eq. 4 tractable, we use PyTorch and the Limited-memory BFGS optimizer (L-BFGS) <ref type="bibr" target="#b53">[55]</ref> with strong Wolfe line search. Implementation details can be found in Sup. Mat.</p><p>We optimize Eq. 4 with a multistage approach, similar to <ref type="bibr">[10]</ref>. We assume that we know the exact or an approximate value for the focal length of the camera. Then we first estimate the unknown camera translation and global body orientation (see <ref type="bibr">[10]</ref>). We then fix the camera parameters and optimize body shape, ?, and pose, ?. Empirically, we found that an annealing scheme for the weights ? in the data term E J (Eq. 5) helps optimization of the objective (Eq. 4) to deal with ambiguities and local optima. This is mainly motivated by the fact that small body parts like the hands and face have many keypoints relative to their size, and can dominate in Eq. 4, throwing optimization in a local optimum when the initial estimate is away from the solution.</p><p>In the following, we denote by ? b the weights corresponding to the main body keypoints, ? h the ones for hands and ? f the ones for facial keypoints. We then follow three steps, starting with high regularization to mainly refine the global body pose, and gradually increase the influence of hand keypoints to refine the pose of the arms. After converging to a better pose estimate, we increase the influence of both hands and facial keypoints to capture expressivity. Throughout the above steps the weights ? ? , ? ? , ? E in Eq.4 start with high regularization that gradually lowers to allow for better fitting, The only exception is ? C that gradually increases while the influence of hands gets stronger in E J and more collisions are expected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Evaluation datasets</head><p>Despite the recent interest in more expressive models <ref type="bibr" target="#b34">[36,</ref><ref type="bibr" target="#b65">67]</ref> there exists no dataset containing images with ground-truth shape for bodies, hands and faces together. Consequently, we create a dataset for evaluation from currently available data through fitting and careful curation.</p><p>Expressive hands and faces dataset (EHF). We begin with the SMPL+H dataset <ref type="bibr" target="#b49">[51]</ref>, obtaining one full body RGB image per frame. We then align SMPL-X to the 4D scans following <ref type="bibr" target="#b65">[67]</ref>. An expert annotator manually curated the dataset to select 100 frames that can be confidently considered pseudo ground-truth, according to alignment quality and interesting hand poses and facial expressions. The pseudo ground-truth meshes allow to use a stricter vertexto-vertex (v2v) error metric <ref type="bibr" target="#b46">[48,</ref><ref type="bibr" target="#b59">61]</ref>, in contrast to the common paradigm of reporting 3D joint error, which does not capture surface errors and rotations along the bones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Qualitative &amp; Quantitative evaluations</head><p>To test the effectiveness of SMPL-X and SMPLify-X, we perform comparisons to the most related models, namely SMPL <ref type="bibr" target="#b46">[48]</ref>, SMPL+H <ref type="bibr" target="#b65">[67]</ref>, and Frank <ref type="bibr" target="#b34">[36]</ref>. In this direction we fit SMPL-X to the EHF images to evaluate both qualitatively and quantitatively. Note that we use only 1 image and 2D joints as input, while previous methods use much more information; i.e. 3D point clouds <ref type="bibr" target="#b34">[36,</ref><ref type="bibr" target="#b65">67]</ref> and joints <ref type="bibr" target="#b34">[36]</ref>. Specifically <ref type="bibr" target="#b46">[48,</ref><ref type="bibr" target="#b65">67]</ref>   projectors, while <ref type="bibr" target="#b34">[36]</ref> employ more than 500 cameras. We first compare to SMPL, SMPL+H and SMPL-X on the EHF dataset and report results in <ref type="table" target="#tab_4">Table 1</ref>. The table reports mean vertex-to-vertex (v2v) error and mean 3D body joint error after Procrustes alignment with the ground-truth 3D meshes and body (only) joints respectively. To ease numeric evaluation, for this table only we "simulate" SMPL and SMPL+H with a SMPL-X variation with locked degrees of freedom, noted as "SMPL" and "SMPL+H" respectively. As expected, the errors show that the standard mean 3D joint error fails to capture accurately the difference in model expressivity. On the other hand, the much stricter v2v metric shows that enriching the body with finger and face modeling results in lower errors. We also fit SMPL with additional features for parts that are not properly modeled, e.g. finger features. The additional features result in an increasing error, pointing to the importance of richer and more expressive models. We report similar qualitative comparisons in Sup. Mat.</p><p>We then perform an ablative study, summarized in Table 2, where we report the mean vertex-to-vertex (v2v) error. SMPLify-X with a gender-specific model achieves 52.9 mm error. The gender neutral model is easier to use, as it does not need gender detection, but comes with a small compromise in terms of accuracy. Replacing VPoser with the GMM of SMPLify <ref type="bibr">[10]</ref> increases the error to 56.4 mm, showing the effectiveness of VPoser. Finally, removing the collision term increases the error as well, to 53.5 mm, while also allowing for non physically plausible pose estimates.  To fit Frank, <ref type="bibr" target="#b34">[36]</ref> employ both 3D joints and point cloud, i.e. more than 500 cameras. In contrast, our method produces a realistic and expressive reconstruction using only 2D joints. We show results using the 3D joints of <ref type="bibr" target="#b34">[36]</ref> projected in 1 camera view (third column), as well as using joints estimated from only 1 image (last column), to show the influence of noise in 2D joint detection. Compared to Frank, our SMPL-X does not have skinning artifacts around the joints, e.g. elbows.</p><p>The closest comparable model to SMPL-X is Frank <ref type="bibr" target="#b34">[36]</ref>. Since Frank is not available to date, nor are the fittings to <ref type="bibr">[18]</ref>, we show images of results found online. <ref type="figure" target="#fig_1">Figure 3</ref> shows Frank fittings to 3D joints and point clouds, i.e. using more than 500 cameras. Compare this with SMPL-X fitting that is done with SMPLify-X using only 1 RGB image with 2D joints. For a more direct comparison here, we fit SMPL-X to 2D projections of the 3D joints that <ref type="bibr" target="#b34">[36]</ref> used for Frank. Although we use much less data, SMPL-X shows at least similar expressivity to Frank for both the face and hands. Since Frank does not use pose blend shapes, it suffers from skinning artifacts around the joints, e.g. elbows, as clearly seen in <ref type="figure" target="#fig_1">Figure 3</ref>. SMPL-X by contrast, is trained to include pose blend shapes and does not suffer from this. As a result it looks more natural and realistic. <ref type="figure">Figure 4</ref>: Qualitative results of SMPL-X for the in-the-wild images of the LSP dataset <ref type="bibr" target="#b31">[33]</ref>. A strong holistic model like SMPL-X results in natural and expressive reconstruction of bodies, hands and faces. Gray color depicts the gender-specific model for confident gender detections. Blue is the gender-neutral model that is used when the gender classifier is uncertain. To further show the value of a holistic model of the body, face and hands, in <ref type="figure" target="#fig_2">Fig. 5</ref> we compare SMPL-X and SMPLify-X to the hands-only approach of [60]. Both approaches employ OpenPose for 2D joint detection, while [60] further depends on a hand detector. As seen in <ref type="figure" target="#fig_2">Fig. 5</ref>, in case of good detections both approaches perform nicely, though in case of noisy detections, SMPL-X shows increased robustness due to the context of the body. We further perform quantitative comparison after aligning the resulting fittings to EHF. Due to different mesh topology, for simplicity we use hand joints as pseudo ground-truth, and perform Procrustes analysis of each hand independently, ignoring the body. Panteleris et al.</p><p>[60] achieve a mean 3D joint error of 26.5 mm, while SMPL-X has 19.8 mm.</p><p>Finally, we fit SMPL-X with SMPLify-X to some in-thewild datasets, namely the LSP <ref type="bibr" target="#b31">[33]</ref>, LSP-extended <ref type="bibr" target="#b32">[34]</ref> and MPII datasets <ref type="bibr">[5]</ref>. <ref type="figure">Figure 4</ref> shows some qualitative results for the LSP dataset <ref type="bibr" target="#b31">[33]</ref>; see Sup. Mat. for more examples and failure cases. The images show that a strong holistic model like SMPL-X can effectively give natural and expressive reconstruction from everyday images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work we present SMPL-X, a new model that jointly captures the body together with face and hands. We additionally present SMPLify-X, an approach to fit SMPL-X to a single RGB image and 2D OpenPose joint detections. We regularize fitting under ambiguities with a new powerful body pose prior and a fast and accurate method for detecting and penalizing penetrations. We present a wide range of qualitative results using images in-the-wild, showing the expressivity of SMPL-X and effectiveness of SMPLify-X. We introduce a curated dataset with pseudo ground-truth to perform quantitative evaluation, that shows the importance of more expressive models. In future work we will curate a dataset of in-the-wild SMPL-X fits and learn a regressor to directly regress SMPL-X parameters directly from RGB images. We believe that this work is an important step towards expressive capture of bodies, hands and faces together from an RGB image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Qualitative results</head><p>Comparison of SMPL, SMPL+H &amp; SMPL-X: In Section 4.2 of the main paper, in <ref type="table" target="#tab_4">Table 1</ref> we present a quantitative comparison between different models with different modeling capacities. In <ref type="figure" target="#fig_3">Fig. A.1</ref> we present a similar comparison for SMPL (left), SMPL+H (middle) and SMPL-X (right) for an image of the EHB dataset. For fair comparison we fit all models with a variation of SMPLify-X to a single RGB image. The figure reflects the same findings as <ref type="table" target="#tab_4">Table 1</ref> of the paper, but qualitatively; there is a clear increase in expressiveness from left to right, as model gets richer from body-only (SMPL) to include hands (SMPL+H) or hands and face (SMPL-X).</p><p>Holistic vs part models: In Section 4.2 and <ref type="figure" target="#fig_2">Fig. 5</ref> of the main paper we compare our holistic SMPL-X model to the hand-only approach of <ref type="bibr">[24]</ref> on EHB. <ref type="figure" target="#fig_0">Figure A.2</ref> shows a similar qualitative comparison, this time on the data of <ref type="bibr">[24]</ref>. To further explore the benefit of holistic reasoning, we also focus on the head and we compare SMPL-X fitting to a head-only method by fitting FLAME <ref type="bibr">[16]</ref> to 2D keypoints similar to our method. The context of the full body stabilizes head estimation for occlusions or non-frontal views (see <ref type="figure" target="#fig_1">Fig. A.3)</ref>. This benefit is also quantitative, where the holistic SMPL-X improves over the head-only fitting by 17% in our EHF dataset in terms of vertex-to-vertex error.</p><p>Failure cases: <ref type="figure">Figure A.4</ref> shows some representative failure cases; depth ambiguities can cause wrong estimation of torso pose or wrong ordinal depth estimation of body parts due to the simple 2D re-projection data term. Furthermore, occluded joints leave certain body parts unconstrained, which currently leads to failures. We plan to address this in future work, by employing a visibility term in the objective.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Collision Penalizer</head><p>In Section 3.4 of the paper we describe the collision penalizer. For technical details and visualizations the reader is redirected to <ref type="bibr">[4,</ref><ref type="bibr">28]</ref>, but for the sake of completion we include the mathematical formulation also here.</p><p>We first detect a list of colliding triangles C by employing Bounding Volume Hierarchies (BVH) <ref type="bibr">[27]</ref> and compute local conic 3D distance fields ? : R 3 ? R + defined by the triangles C and their normals n ? R 3 . Penetrations are then penalized by the depth of intrusion, efficiently computed by the position in the distance field. For two colliding triangles f s and f t intrusion is bi-directional; the vertices v t ? R 3 of f t are the intruders in the distance field ? fs of the receiver triangle f s and are penalized by ? fs (v t ), and vice-versa. Thus, the collision term E C is defined as Both approaches depend on OpenPose <ref type="bibr">[23]</ref>. In case of good 2D detections both perform well (left group). In case of noisy detections (right group) fitting a holistic model is more robust. For the case where f t is the intruder and f s is the receiver (similarly for the opposite case) the cone for the distance <ref type="figure">Figure A.4</ref>. Failure cases for SMPLify-X with the female SMPL-X for expressive RGB images similar to the ones of <ref type="figure" target="#fig_0">Figures 1 and 2</ref> of the main paper. In the left case, 2D keypoints are reasonable, but due to depth ambiguities the torso pose is wrong, while the head shape is under-estimated. In the right case, the arms and hands are occluded and due to lack of constraints the arm and hand pose is wrong. The ordinal depth for feet is estimated wrongly, while similarly to the left case the torso pose and head shape are not estimated correctly. Left: Input RGB image. Middle : Intermediate 2D keypoints from OpenPose. Right: SMPL-X fittings overlaid on the RGB image.</p><formula xml:id="formula_11">E C (?) = ? (fs(?),ft(?))?C ? ? vs?fs ? ? ? ft (v s )n s ? 2 + ? vt?ft ? ? ? fs (v t )n t ? 2 ? .<label>(1)</label></formula><p>field ? fs is defined as</p><formula xml:id="formula_12">? fs (v t ) = ? |(1 ? ?(v t ))?(n fs ? (v t ? o fs ))| 2 ?(v t ) &lt; 1 0 ?(v t ) ? 1 (2) where o fs ? R 3</formula><p>is the circumcenter and r fs ? R &gt;0 the radius of the circumcircle for the receiver triangle. The term</p><formula xml:id="formula_13">?(v t ) = ?(v t ? o fs ) ? (n fs ? (v t ? o fs ))n fs ? ? r fs ? (n fs ? (v t ? o fs )) + r fs<label>(3)</label></formula><p>projects the vertex v t onto the axis of the cone defined by the triangle normal n fs and going through the circumcenter o fs . It then measures the distance to it, scaled by the radius of the cone at this point. If ?(v) &lt; 1 the vertex is inside the cone and if ?(v) = 0 the vertex is on the axis. The term</p><formula xml:id="formula_14">?(x) = ? ? ? ? ? ?x + 1 ? ? x ? ?? ? 1?2? 4? 2 x 2 ? 1 2? x + 1 4 (3 ? 2?) x ? (??, +?) 0</formula><p>x ? +? (4) measures how far the projected point is from the circumcenter to define the intensity of penalization. For ?(x) &lt; 0 the projected point is behind the triangle. For x ? (??, +?) the penalizer is quadratic, while for x &gt; |?| it becomes linear. The parameter ? also defines the field of view of the cone. In contrast to <ref type="bibr">[4,</ref><ref type="bibr">28]</ref> that use mm unit and ? = 0.5, we use m unit and ? = 0.0001. For the resolution of our meshes, we empirically find that this value allows for both penalizing penetrations, as well as for not over-penalizing in case of self-contact, e.g. arm resting on knee.</p><p>As seen in <ref type="figure" target="#fig_2">Fig. A.5</ref>, for certain parts of the body, like the eyes, toes, armpits and crotch, as well as neighboring parts <ref type="figure">Figure A</ref>.5. For certain parts of the body, like the eyes, toes, armpits and crotch, as well as neighboring parts in the kinematic chain, there is either always or frequently self-contact. The triangles for which collisions are detected are highlighted with red (left, middle). Since the model does not model deformations due to contact, for simplicity we just ignore collisions for these areas (right).</p><p>in the kinematic chain, there is either always or frequently self-contact. For simplicity, since the model does not model deformations due to contact, we simply ignore collisions for neighboring parts in these areas. Our empirical observations suggest that collision detection for the other parts resolves most penetrations and helps prevent physically implausible poses. <ref type="figure" target="#fig_6">Figure A.6</ref> shows the effect of the collision penalizer, by including or excluding it from optimization, and depicts representative success and failure cases.</p><p>For computational efficiency, we developed a custom PyTorch wrapper operator for our CUDA kernel based on the highly parallelized implementation of BVH <ref type="bibr">[14]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Optimization</head><p>In Section 3.6 of the paper we present the main information about optimizing our objective function, while in the following we present omitted details.</p><p>To keep optimization tractable, we use a PyTorch implementation and the Limited-memory BFGS optimizer (L-BFGS) <ref type="bibr">[22]</ref> with strong Wolfe line search. We use a learning rate of 1.0 and 30 maximum iterations. For the annealing scheme presented in Section 3.6 we take the following three steps. We start with high regularization to mainly refine the global body pose, (? b = 1, ? h = 0, ? f = 0) and gradually increase the influence of hand keypoints to refine the pose of the arms (? b = 1, ? h = 0.1, ? f = 0). After converging to a better pose estimate, we increase the influence of both hands and facial keypoints to capture expressivity (? b = 1, ? h = 2, ? f = 2). Throughout the above steps the weights ? ? , ? ? , ? E in the objective function E start with high regularization that progressively lowers to allow for better fitting. The only exception is ? C that progressively increases while the influence of hands and facial keypoints gets stronger in E J , thus bigger pose changes and more collisions are expected.</p><p>Regarding the weights of the optimization, they are set empirically and the exact parameters for each stage of the optimization will be released with our code. For more intuition we performed sensitivity analysis by perturbing each weight ? separately by up to ?25%. This resulted to relative changes smaller than 6% in the vertex-to-vertex error metric, meaning that our approach is robust for significant weight ranges and not sensitive to fine-tuning. The detailed results are presented in <ref type="figure">Fig. A.7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Quantitative evaluation on "Total Capture"</head><p>In the main paper we present a curated dataset called Expressive hands and faces dataset (EHF) with ground-truth shape for bodies, hands and faces together.</p><p>Since the most relevant model is Frank <ref type="bibr">[13]</ref>, we also use the "Total Capture" dataset <ref type="bibr">[8]</ref> of the authors, focusing on the "PtCloudDB" part that includes pseudo ground-truth for <ref type="figure">Figure A.7</ref>. Sensitivity of the weights for the different terms of the optimization. Each weight ? is perturbed separately up to ?25%. The relative changes in the vertex-to-vertex error are smaller than 6%, indicating that our approach is robust for significant weight ranges and not sensitive to fine-tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SMPLify-X using</head><p>Error Joints Alignment Joints GT 2D pred 2D  Quantitative results on the selected frames from CMU Panoptic Studio, using SMPLify-X on the 2D re-projection of the ground-truth 3D joints, and the 2D joints detected by OpenPose respectively. The numbers are mean 3D joint errors after Procrustes alignment. First, we evaluate the error on the body-only keypoints after Procrustes alignment with the ground-truth bodyonly keypoints (row 1). Then, we consider the same alignment using body-only keypoints, but we evaluate the joint error across all the body+hands+face keypoints (row 2). Finally, we align the prediction using all body+hands+face keypoints and we report the mean error across all of them (row 3).</p><p>all body, face and hands. This pseudo ground-truth is created with triangulated 3D joint detection from multi-view with OpenPose <ref type="bibr">[23]</ref>. We curate and pick 200 images, according to the degree of visibility of the body in the image, interesting hand poses and facial expressions. In the following, we refer to this data as "total hands and faces" (THF) dataset. <ref type="figure" target="#fig_7">Figure A.8</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Quantitative evaluation on Human3.6M</head><p>In the main manuscript <ref type="table" target="#tab_4">(Table 1)</ref>, we demonstrated that evaluating the reconstruction accuracy using 3D body joints is not representative of the accuracy and the detail of a Method Mean (mm) Median (mm) SMPLify <ref type="bibr">[5]</ref> 82.3 69.3 SMPLify-X 75.9 60.8 method's reconstruction. However, many approaches do evaluate quantitatively based on 3D body joints metrics, so here we compare our results with SMPLify <ref type="bibr">[5]</ref> to demonstrate that our approach is not only more natural, expressive and detailed, but the results are also more accurate in the common metrics. In <ref type="table" target="#tab_4">Table A</ref>.2 we present our results using the Human3.6M <ref type="bibr">[10]</ref> dataset. We follow the same protocol as <ref type="bibr">[5]</ref> and we report results after Procrustes alignment with the ground-truth 3D pose. Even though there are several factors that improve our approach over SMPLify and this experiment does not say which is more important (we direct the reader to the ablative study in <ref type="table" target="#tab_1">Table 2</ref> of the main manuscript for this), we still outperform the original SMPLify using this crude metric based on 3D joints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Qualitative evaluation on MPII</head><p>In <ref type="figure">Fig. A</ref>.14 we present qualitative results on the MPII dataset <ref type="bibr">[3]</ref>. For this dataset we also include some cases with low resolution, heavily occluded or cropped people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Model</head><p>In Section 3.1 of the main manuscript we describe the SMPL-X model. The model shape space is trained on the CAESAR database <ref type="bibr">[26]</ref>. In <ref type="figure" target="#fig_8">Fig. A.9</ref> we present the percentage of explained variance as a function of the number of PCA components used. All models explain more than 95% of the variance with 10 principle components.</p><p>We further evaluate the model on a held out set of 180 alignments of male and female subjects in different poses. The male model is evaluated on the male alignments, the female model is evaluated on the female alignments, while the gender neutral is evaluated on both male and female alignments. We report the model alignment vertex-to-vertex (v2v) mean absolute error as a function of the number of principle components used, shown in <ref type="figure" target="#fig_3">Fig. A.10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">VPoser</head><p>In Section 3.3 of the main manuscript we introduce a new parametrization of the human pose and a prior on this parameterization, also referred to as VPoser. In this Section we present further details on the data preparation and implementation. Qualitative results on some of the data of the "total capture" dataset <ref type="bibr">[8]</ref>, focusing on the "PtCloudDB" part that includes pseudo ground-truth for all body, face and hands. We curate and pick 200 images, according to degree of body coverage in the image and interesting hand poses and facial expressions. We refer to this data as "total hands and faces" dataset (THF). Top row: Reference RGB image. Middle row: SMPLify-X results using pseudo ground-truth OpenPose keypoints (3D keypoints of <ref type="bibr">[8]</ref> estimated from multiview and projected on 2D). Bottom row: SMPLify-X results using 2D OpenPose keypoints estimated with <ref type="bibr">[23]</ref>. Gray color depicts the gender-specific model for confident gender detections. Blue is the gender-neutral model that is used when the gender classifier is uncertain.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.">Data preparation</head><p>We use SMPL body pose parameters extracted with <ref type="bibr">[19,</ref><ref type="bibr">21]</ref> from human motion sequences of CMU <ref type="bibr" target="#b6">[7]</ref>, Hu-man3.6M <ref type="bibr">[10]</ref>, and PosePrior <ref type="bibr">[2]</ref> as our dataset. Subsequently, we hold out parameters for Subjects 9 and 11 of Human3.6M as our test set. We randomly select 5% of the training set as our validation set and use that to make snapshots of the model with minimum validation loss. We choose matrix rotations for our pose parameterization.  <ref type="figure">Figure A</ref>.11. VPoser model in different modes. For training the network consists of an encoder and a decoder. For testing we use the latent code instead of the body pose parameters, i.e. ? b , of SMPL-X, which are described in Section 3.1 of the main paper. By "inverse Rodrigues" we note the conversion from a rotation matrix to an axis-angle representation for posing SMPL-X. <ref type="figure">Figure A.</ref>12. Gender classifier results on the test set. From left to right column: Successful predictions, predictions discarded due to low confidence(&lt; 0.9), failure cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.">Implementation details</head><p>For implementation we use TensorFlow <ref type="bibr">[1]</ref> and later port the trained model and weights to PyTorch <ref type="bibr">[25]</ref>. <ref type="figure" target="#fig_3">Figure A.11</ref> shows the network architecture during training and test time. We use only fully-connected layers, with LReLU <ref type="bibr">[20]</ref> non-linearity and keep the encoder and decoder symmet-ric. The encoder has two dense layers with 512 units each, and then one dense layer for mean and another for variance of the VAE's posterior Normal distribution. The decoder weights have the same shape as the encoder, only in reverse order. We use the ADAM solver <ref type="bibr">[15]</ref>, and update the weights of the network to minimize the loss defined in Eq. 5 of the main manuscript. We empirically choose the values for loss weights as: c 1 = 0.005, c 2 = 1.0 ? c 2 , c 3 = 1.0, c 4 = 1.0, c 5 = 0.0005. We train for 60 epochs for each of the following learning rates: [5e?4, 1e?4, 5e?5].</p><p>After training, the latent space describes a manifold of physically plausible human body poses, that can be used for efficient 2D-to-3D lifting. <ref type="figure" target="#fig_1">Figure A.13</ref> shows a number of random samples drawn from the latent space of the model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Gender lassifier</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.1.">Training data</head><p>For training data we employ the LSP <ref type="bibr">[11]</ref>, LSPextended <ref type="bibr">[12]</ref>, MPII <ref type="bibr">[3]</ref>, MS-COCO <ref type="bibr">[18]</ref>, LIP <ref type="bibr" target="#b94">[17]</ref> datasets, respecting their original train and test splits. To curate our data for gender annotations we collect tight crops around persons and keep only the ones for which there is at least one visible joint with high confidence for the head, torso and for each limb. We further reject crops with size smaller than 200 ? 200 pixels. The gathered samples are annotated with gender labels using Amazon Mechanical Turk. Each image is annotated by two Turkers and we keep only the ones with consistent labels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.">Implementation details</head><p>For implementation we use Keras <ref type="bibr">[6]</ref> with Tensor-Flow <ref type="bibr">[1]</ref> backend. We use a pretrained ResNet18 <ref type="bibr">[9]</ref> for feature extraction and append fully-connected layers for our classifier. We employ a cross entropy loss, augmented with an L2 norm on the weights. Each data sample is resized to 224 ? 224 pixels to be compatible with the ResNet18 <ref type="bibr">[9]</ref> architecture. We start by training the final fully-connected layers for two epochs with each of the following learning rate values [1e?3, 1e?4, 1e?5, 1e?6]. Afterwards, the entire network is finetuned end-to-end for two epochs using these learning rates [5e?5, 1e?5, 1e?6, 1e?7]. Optimization is performed using Adam <ref type="bibr">[15]</ref>.  Qualitative results of SMPLify-X with SMPL-X on the MPII dataset <ref type="bibr">[3]</ref>. In this figure we also include images with some heavily occluded or cropped bodies. Gray color depicts the gender-specific model for confident gender detections. Blue is the genderneutral model that is used when the gender classifier is uncertain or when cropping does not agree with the filtering criterion described in ubsection 9.1. <ref type="figure" target="#fig_2">Figure A.15</ref>. Results of SMPLify-X fitting for the LSP dataset. For each group of images we compare two body priors; the top row shows a reference RGB image, the bottom row shows results of SMPLify with VPoser, while the middle row shows results for which VPoser is replaced with the GMM body pose prior of SMPLify <ref type="bibr">[5]</ref>. To eliminate factors of variation, for this comparison we use the gender neutral SMPL-X model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>We learn a new 3D model of the human body called SMPL-X that jointly models the human body, face and hands. We fit the female SMPL-X model with SMPLify-X to single RGB images and show that it captures a rich variety of natural and expressive 3D human poses, gestures and facial expressions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Qualitative comparison of our gender neutral model (top, bottom rows) or gender specific model (middle) against Frank [36] on some of their data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 :</head><label>5</label><figDesc>Comparison of the hands-only approach of [60] (middle) against our approach with the male model (right). Both approaches depend on OpenPose. In case of good detections both perform well (top). In case of noisy 2D detections (bottom) our holistic model shows increased robustness. (images cropped at the bottom in the interest of space)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure A. 1 .</head><label>1</label><figDesc>Comparison of SMPL (left), SMPL+H (middle) and SMPL-X (right) on the EHB dataset, using the male models. For fair comparison we fit all models with a variation of SMPLify-X to a single RGB image. The results show a clear increase in expressiveness from let to right, as model gets richer from body-only (SMPL) to include hands (SMPL+H) or hands and face (SMPL-X).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure A. 2 .</head><label>2</label><figDesc>Comparison of the hands-only approach of [24] (middle row) against SMPLify-X with the male SMPL-X (bottom row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure A. 3 .</head><label>3</label><figDesc>Fitting SMPL-X (right) versus FLAME (middle). For minimal occlusions and frontal views (top) both methods perform well. For moderate (middle) or extreme (bottom) occlusions the body provides crucial context and improves fitting (bottom: missing FLAME model indicates a complete fitting failure).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure A. 6 .</head><label>6</label><figDesc>Effect of the collision penalizer. The colliding triangles are highlighted to show penetrations at the end of optimization with SMPLify-X without (middle) and with (right) the collision term in the objective function. The top row shows a successful case, were optimization resolves most collisions and converges in a physically plausible pose that reflects the input image. The bottom row shows a failure case, for which arm crossing causes a lot of collisions due to self-touch. The final pose (right) is still physically plausible, but optimization gets trapped in a local minima and the pose does not reflect the input image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure A. 8 .</head><label>8</label><figDesc>Figure A.8. Qualitative results on some of the data of the "total capture" dataset [8], focusing on the "PtCloudDB" part that includes pseudo ground-truth for all body, face and hands. We curate and pick 200 images, according to degree of body coverage in the image and interesting hand poses and facial expressions. We refer to this data as "total hands and faces" dataset (THF). Top row: Reference RGB image. Middle row: SMPLify-X results using pseudo ground-truth OpenPose keypoints (3D keypoints of [8] estimated from multiview and projected on 2D). Bottom row: SMPLify-X results using 2D OpenPose keypoints estimated with [23]. Gray color depicts the gender-specific model for confident gender detections. Blue is the gender-neutral model that is used when the gender classifier is uncertain.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure A. 9 .</head><label>9</label><figDesc>Cumulative relative variance of the CAESAR dataset explained as a function of the number of shape coefficients for three SMPL-X models: male, female, gender neutral model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure A. 10 .</head><label>10</label><figDesc>Evaluating SMPL-X generalization on a held out test set of male and female 3D alignments.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure A. 12</head><label>12</label><figDesc>shows some qualitative results of the gender classifier on the test set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure A. 13 .</head><label>13</label><figDesc>Random pose samples from the latent space of VPoser. We sample from a 32 dimensional normal distribution and feed the value to the decoder of VPoser; shown inFigure A.11b. SMPL is then posed with the decoder output, after conversion to an axis-angle representation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure A. 14</head><label>14</label><figDesc>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>employ 66 cameras and 34</figDesc><table><row><cell>Model</cell><cell>Keypoints</cell><cell cols="2">v2v error Joint error</cell></row><row><cell cols="3">"SMPL" "SMPL" Body+Hands+Face 64.5 57.6 Body "SMPL+H" 54.2 Body+Hands SMPL-X Body+Hands+Face 52.9</cell><cell>63.5 71.7 63.9 62.6</cell></row><row><cell cols="4">Table 1: Quantitative comparison of "SMPL", "SMPL+H" and SMPL-X, as described in Section 4.2, fitted with SMPLify-X on the EHF dataset. We report the mean vertex-to-vertex (v2v) and the standard mean 3D body (only) joint error in mm. The table shows that richer modeling power results in lower errors.</cell></row><row><cell>Version</cell><cell></cell><cell cols="2">v2v error</cell></row><row><cell cols="3">SMPLify-X gender neutral model replace Vposer with GMM no collision term</cell><cell>52.9 58.0 56.4 53.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table /><note>Ablative study for SMPLify-X on the EHF dataset. The numbers reflect the contribution of each component in overall accuracy.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table A</head><label>A</label><figDesc></figDesc><table /><note>.1.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>shows qualitative results on part of THF. For each group of images the top row shows a reference RGB image, the middle row shows SMPLify-X results using pseudo ground-truth OpenPose keypoints (projected on 2D for use by our method), while the bottom row shows SMPLify-X results using 2D OpenPose keypoints estimated with[23]. Quantitative results for this dataset are reported inTable A.1.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Table A.2. Quantitative results on the Human3.6M dataset[10]. The numbers are mean 3D joint errors after Procrustes alignment. We use the evaluation protocol of[5].</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>? N (0, I) ? R 32 Dense -32 ? 512 LReLU -0.2 Dropout -0.25</figDesc><table><row><cell cols="2">R ? [?1, 1] 207</cell><cell></cell></row><row><cell cols="2">Dense -207 ? 512 LReLU -0.2</cell><cell></cell></row><row><cell cols="2">Dropout -0.25</cell><cell></cell></row><row><cell cols="2">Dense -512 ? 512 LReLU -0.2</cell><cell></cell></row><row><cell>?(R)</cell><cell>?(R)</cell><cell>Dense -512 ? 512 LReLU -0.2</cell></row><row><cell>Dense -512 ? 32</cell><cell>Dense -512 ? 32</cell><cell></cell></row><row><cell cols="2">Z ? N (?(R), ?(R))</cell><cell>Dense -512 ? 207 tan?</cell></row><row><cell cols="2">Dense -32 ? 512 LReLU -0.2</cell><cell>R ? [?1, 1] 207</cell></row><row><cell cols="2">Dropout -0.25</cell><cell></cell></row><row><cell></cell><cell></cell><cell>inv. Rodrigues</cell></row><row><cell cols="2">Dense -512 ? 512 LReLU -0.2</cell><cell></cell></row><row><cell></cell><cell></cell><cell>R axis angle ? R 69</cell></row><row><cell cols="2">Dense -512 ? 207 tan?</cell><cell></cell></row><row><cell cols="2">R ? [?1, 1] 207</cell><cell></cell></row><row><cell cols="2">(a) Train mode.</cell><cell></cell></row></table><note>ZSMPLHF (b) Test mode.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Georgios Pavlakos *1,2 , Vasileios Choutas *1 , Nima Ghorbani 1 , Timo Bolkart 1 , Ahmed A. A. Osman 1 , Dimitrios Tzionas 1 , and Michael J. Black 1 1 MPI for Intelligent Systems, T?bingen, DE , 2 University of Pennsylvania, PA, USA {gpavlakos, vchoutas, nghorbani, tbolkart, aosman, dtzionas, black}@tuebingen.mpg.de</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr" target="#b34">[36]</ref><p>.</p><p>Disclosure: MJB has received research gift funds from Intel, Nvidia, Adobe, Facebook, and Amazon. While MJB is a part-time employee of Amazon, his research was performed solely at, and funded solely by, MPI. MJB has financial interests in Amazon and Meshcapade GmbH.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pose-conditioned joint angle limits for 3D human pose reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ijaz</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The space of human body shapes: Reconstruction and parameterization from range scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brett</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoran</forename><surname>Popovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH)</title>
		<meeting>SIGGRAPH)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning a correlated model of identity and posedependent body shape variation for real-time synthesis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brett</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Curless</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zoran</forename><surname>Popovi?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Hertzmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM SIGGRAPH/Eurographics Symposium on Computer Animation, SCA &apos;06</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Expression invariant 3D face recognition with a morphable model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Amberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Knothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Automatic Face Gesture Recognition</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">2D human pose estimation: New benchmark and state of the art analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">SCAPE: Shape Completion and Animation of PEople</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Praveen</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daphne</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastian</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jim</forename><surname>Rodgers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Davis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH)</title>
		<meeting>SIGGRAPH)</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Marker-less motion capture of skinned models in a four camera set-up using optical flow and silhouettes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guido</forename><forename type="middle">Maria</forename><surname>Cortelazzo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Symposium on 3D Data Processing, Visualization and Transmission (3DPVT)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Motion capture of hands in action using discriminative salient points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aparna</forename><surname>Taneja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A morphable model for the synthesis of 3D faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Blanz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIGGRAPH</title>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Large scale 3D morphable models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Booth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasios</forename><surname>Roussos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Allan</forename><surname>Ponniah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Dunaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">2-4</biblScope>
			<biblScope unit="page" from="233" to="254" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Twist based acquisition and tracking of animal and human kinematics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Bregler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Katherine</forename><surname>Pullen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="179" to="194" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Review of statistical shape spaces for 3D data with comparative analysis for human faces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Brunton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Augusto</forename><surname>Salazar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanie</forename><surname>Wuhrer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">0</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Facewarehouse: A 3D facial expression database for visual computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanlin</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shun</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiying</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kun</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Realtime multi-person 2D pose estimation using part affinity fields</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-En</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Tensorbased human body modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zicheng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhengyou</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Total Capture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dataset</surname></persName>
		</author>
		<ptr target="http://domedb.perception.cs.cmu.edu.7" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Model-based 3D hand pose estimation from monocular video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">La</forename><surname>Gorce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">J</forename><surname>Fleet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Paragios</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1793" to="1805" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">3D articulated models and multiview tracking with physical forces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quentin</forename><surname>Delamarre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olivier</forename><forename type="middle">D</forename><surname>Faugeras</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="328" to="357" />
		</imprint>
		<respStmt>
			<orgName>CVIU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Facial Action Coding System: A Technique for the Measurement of Facial Movement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Friesen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
			<publisher>Consulting Psychologists Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<ptr target="http://flame.is.tue.mpg.de.3" />
		<title level="m">models FLAME website: dataset and code</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Lie bodies: A manifold representation of 3D human shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oren</forename><surname>Freifeld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Motion capture using joint skeleton tracking and surface estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Stoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edilson</forename><forename type="middle">De</forename><surname>Aguiar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Statistical methods for tomographic image reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stuart</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><forename type="middle">E</forename><surname>Mcclure</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 46th Session of the International Statistical Institute, Bulletin of the ISI</title>
		<meeting>the 46th Session of the International Statistical Institute, Bulletin of the ISI</meeting>
		<imprint>
			<date type="published" when="1987" />
			<biblScope unit="volume">52</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A statistical model of human pose and body shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Stoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Sunkel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning skeletons for shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nils</forename><surname>Hasler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thorsten</forename><surname>Thorm?hlen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D &apos;10</title>
		<meeting>the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games, I3D &apos;10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="23" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Coregistration: Simultaneous alignment and modeling of articulated 3D shape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">A</forename><surname>Hirshberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Rachlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Towards accurate marker-less human shape and pose estimation over time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinghao</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ijaz</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Deepercut: A deeper, stronger, and faster multi-person pose estimation model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eldar</forename><surname>Insafutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bjoern</forename><surname>Andres</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">6M: Large scale datasets and predictive methods for 3D human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Human3</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1325" to="1339" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Clustered pose and nonlinear appearance models for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning effective human pose estimation from inaccurate annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Panoptic studio: A massively multiview system for social motion capture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lin</forename><surname>Gui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bart</forename><surname>Nabbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shohei</forename><surname>Nobuhara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Total capture: A 3D deformation model for tracking faces, hands, and bodies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">End-to-end recovery of human shape and pose</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jitendra</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Maximizing parallelism in the construction of BVHs, Octrees, and K-d trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics</title>
		<meeting>the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="33" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Learning an efficient model of hand shape variation from depth images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameh</forename><surname>Khamis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jamie</forename><surname>Shotton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note>Cem Keskin, Shahram Izadi, and Andrew Fitzgibbon</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Auto-encoding variational bayes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unite the people: Closing the loop between 3D and 2D human representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Kiefel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><forename type="middle">V</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gehler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Pose space deformation: A unified approach to shape interpolation and skeleton-driven deformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">P</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Cordner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nickson</forename><surname>Fong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ACM Transactions on Graphics</title>
		<imprint>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="165" to="172" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning a model of facial shape and expression from 4D scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Romero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Human parsing with contextualized convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Markerless motion capture of multiple characters using multiview image segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yebin</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carsten</forename><surname>Stoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qionghai</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>PAMI</publisher>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="2720" to="2735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">MoSh: Motion and shape capture from sparse markers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">SMPL: A skinned multiperson linear model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<idno>248:1-248:16</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. SIGGRAPH Asia)</title>
		<meeting>SIGGRAPH Asia)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">OpenDR: An approximate differentiable renderer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">AMASS: Archive of motion capture as surface shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nikolaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Troje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03278</idno>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<ptr target="http://mano.is.tue.mpg.de.3" />
		<title level="m">MANO, models SMPL+H website: dataset, and code</title>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Dynamics based 3D skeletal hand tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stan</forename><surname>Melax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Keselman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sterling</forename><surname>Orsten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Graphics Interface</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A survey of advances in vision-based human motion capture and analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">B</forename><surname>Moeslund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Hilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Volker</forename><surname>Kr?ger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVIU</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="90" to="126" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">A Mathematical Introduction to Robotic Manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">M</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zexiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shankar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sastry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>CRC press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wright</surname></persName>
		</author>
		<title level="m">Nonlinear Equations</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Training a feedback loop for hand pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Markus</forename><surname>Oberweger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Wohlhart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Lepetit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Argyros. Efficient model-based 3D tracking of hand articulations using Kinect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iason</forename><surname>Oikonomidis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Kyriazis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antonis</forename><forename type="middle">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Neural body fitting: Unifying deep learning and model-based human pose and shape estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohamed</forename><surname>Omran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Openpose</surname></persName>
		</author>
		<ptr target="https://github.com/CMU-Perceptual-Computing-Lab/openpose" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Iason Oikonomidis, and Antonis Argyros. Using a single RGB frame for real time 3D hand pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paschalis</forename><surname>Panteleris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In WACV</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning to estimate 3D human pose and shape from a single color image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgios</forename><surname>Pavlakos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luyang</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">A 3D face model for pose and illumination invariant face recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Paysan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinhard</forename><surname>Knothe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brian</forename><surname>Amberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sami</forename><surname>Romdhani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Vetter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sixth IEEE International Conference on Advanced Video and Signal Based Surveillance</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="296" to="301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Dyna: A model of dynamic human shape in motion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
		<idno>120:1-120:14</idno>
	</analytic>
	<monogr>
		<title level="m">Proc. SIG-GRAPH)</title>
		<meeting>SIG-GRAPH)</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">34</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Model-Based Pose Estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Pons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><surname>Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bodo</forename><surname>Rosenhahn</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="139" to="170" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Learning monocular 3D human pose estimation from multi-view images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rg</forename><surname>Sp?rri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isinsu</forename><surname>Katircioglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fr?d?ric</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erich</forename><surname>M?ller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mathieu</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Fua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Civilian American and European Surface Anthropometry Resource (CAESAR) final report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">M</forename><surname>Robinette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherri</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hein</forename><surname>Daanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Boehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hoeferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Burnsides</surname></persName>
		</author>
		<idno>AFRL-HE-WP-TR-2002-0169</idno>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
		<respStmt>
			<orgName>US Air Force Research Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Embodied hands: Modeling and capturing hands and bodies together</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">DART: Dense articulated real-time tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tanner</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Newcombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dieter</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">RSS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Hand keypoint detection in single images using multiview bootstrapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Matthews</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Interactive markerless articulated hand motion tracking using RGB and depth data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Srinath</forename><surname>Sridhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antti</forename><surname>Oulasvirta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Surface capture for performance-based animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Starck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Hilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE computer graphics and applications</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Collision detection for deformable objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Teschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Kimmerle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Heidelberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Zachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laks</forename><surname>Raghupathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnulph</forename><surname>Fuhrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Paule</forename><surname>Cani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Faure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><surname>Magnenat-Thalmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Strasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Volino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Sphere-meshes for real-time hand modeling and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anastasia</forename><surname>Tkach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Pauly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Tagliasacchi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Capturing hands in action using discriminative salient points and physics simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhilash</forename><surname>Srikantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Aponte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Face transfer with multilinear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Vlasic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Brand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanspeter</forename><surname>Pfister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jovan</forename><surname>Popovi?</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM transactions on graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="426" to="433" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Convolutional pose machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shih-En</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Takeo</forename><surname>Ramakrishna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Kanade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Monoperfcap: Human performance capture from monocular video</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weipeng</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Avishek</forename><surname>Chatterjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zollh?fer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helge</forename><surname>Rhodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dushyant</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans-Peter</forename><surname>Seidel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">27</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Expression flow for 3D-aware face component transfer</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jue</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eli</forename><surname>Shechtman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubomir</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitri</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">60</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Depthbased 3D hand pose estimation: From current achievements to future goals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shanxin</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillermo</forename><surname>Garcia-Hernando</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bj?rn</forename><surname>Stenger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gyeongsik</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Ju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pavlo</forename><surname>Kyoung Mu Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jan</forename><surname>Molchanov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sina</forename><surname>Kautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liuhao</forename><surname>Honari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In CVPR</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">State of the art on monocular 3D face reconstruction, tracking, and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Zollh?fer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Justus</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Derek</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thabo</forename><surname>Beeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>P?rez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Stamminger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Nie?ner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Theobalt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="523" to="550" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Tensorflow: A system for large-scale machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mart?n</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Barham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianmin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhifeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andy</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Dean</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthieu</forename><surname>Devin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjay</forename><surname>Ghemawat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Isard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">OSDI</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Pose-conditioned joint angle limits for 3D human pose reconstruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ijaz</forename><surname>Akhter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">2D human pose estimation: New benchmark and state of the art analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mykhaylo</forename><surname>Andriluka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonid</forename><surname>Pishchulin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernt</forename><surname>Schiele</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Motion capture of hands in action using discriminative salient points</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aparna</forename><surname>Taneja</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Federica</forename><surname>Bogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angjoo</forename><surname>Kanazawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Lassner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Gehler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Total Capture</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dataset</surname></persName>
		</author>
		<ptr target="http://domedb.perception.cs.cmu.edu.3" />
		<imprint>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">6M: Large scale datasets and predictive methods for 3D human sensing in natural environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Catalin</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragos</forename><surname>Papava</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vlad</forename><surname>Olaru</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Human3</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
		<title level="a" type="main">Clustered pose and nonlinear appearance models for human pose estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">BMVC</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Learning effective human pose estimation from inaccurate annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Everingham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title level="a" type="main">Total capture: A 3D deformation model for tracking faces, hands, and bodies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanbyul</forename><surname>Joo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaser</forename><surname>Sheikh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Maximizing parallelism in the construction of BVHs, Octrees, and K-d trees</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tero</forename><surname>Karras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics</title>
		<meeting>the Fourth ACM SIGGRAPH / Eurographics Conference on High-Performance Graphics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="33" to="37" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">Learning a model of facial shape and expression from 4D scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianye</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timo</forename><surname>Bolkart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Black</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Javier</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Romero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">194</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Human parsing with contextualized convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaodan</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaohui</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianchao</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Si</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinhui</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuicheng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In ICCV</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Microsoft COCO: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">MoSh: Motion and shape capture from sparse markers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael J</forename><surname>Black</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Graphics (TOG)</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">220</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<analytic>
		<title level="a" type="main">Rectifier nonlinearities improve neural network acoustic models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Andrew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Maas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Awni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew Y</forename><surname>Hannun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML Workshops</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<monogr>
		<title level="m" type="main">AMASS: Archive of motion capture as surface shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Naureen</forename><surname>Mahmood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nima</forename><surname>Ghorbani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Nikolaus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerard</forename><surname>Troje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">J</forename><surname>Pons-Moll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Black</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.03278</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title level="m" type="main">Numerical Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Nocedal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b100">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Openpose</surname></persName>
		</author>
		<ptr target="https://github.com/CMU-Perceptual-Computing-Lab/openpose.2" />
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<analytic>
		<title level="a" type="main">Iason Oikonomidis, and Antonis Argyros. Using a single RGB frame for real time 3D hand pose estimation in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paschalis</forename><surname>Panteleris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WACV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">Automatic differentiation in pyTorch</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Soumith</forename><surname>Chintala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Chanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Edward</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zachary</forename><surname>Devito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeming</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alban</forename><surname>Desmaison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Antiga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Lerer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<monogr>
		<title level="m" type="main">Civilian American and European Surface Anthropometry Resource (CAESAR) final report</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kathleen</forename><forename type="middle">M</forename><surname>Robinette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sherri</forename><surname>Blackwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hein</forename><surname>Daanen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Boehmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tina</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Hoeferlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis</forename><surname>Burnsides</surname></persName>
		</author>
		<idno>AFRL-HE-WP-TR-2002-0169</idno>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
		<respStmt>
			<orgName>US Air Force Research Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Collision detection for deformable objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Teschner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefan</forename><surname>Kimmerle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruno</forename><surname>Heidelberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Zachmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laks</forename><surname>Raghupathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnulph</forename><surname>Fuhrmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marie-Paule</forename><surname>Cani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Faure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nadia</forename><surname>Magnenat-Thalmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfgang</forename><surname>Strasser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pascal</forename><surname>Volino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Eurographics</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<analytic>
		<title level="a" type="main">Capturing hands in action using discriminative salient points and physics simulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dimitrios</forename><surname>Tzionas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Ballan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhilash</forename><surname>Srikantha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pablo</forename><surname>Aponte</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marc</forename><surname>Pollefeys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Juergen</forename><surname>Gall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="172" to="193" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
