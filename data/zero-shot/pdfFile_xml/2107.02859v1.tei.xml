<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Poly-NL: Linear Complexity Non-local Layers with Polynomials</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Babiloni</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Marras</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Huawei Noah&apos;s Ark Lab</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Filippos</forename><surname>Kokkinos</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">University College London 4? cole Polytechnique F?d?rale de Lausanne</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Deng</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Grigorios</forename><surname>Chrysos</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Imperial College London</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Poly-NL: Linear Complexity Non-local Layers with Polynomials</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T04:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Spatial self-attention layers, in the form of Non-Local blocks, introduce long-range dependencies in Convolutional Neural Networks by computing pairwise similarities among all possible positions. Such pairwise functions underpin the effectiveness of non-local layers, but also determine a complexity that scales quadratically with respect to the input size both in space and time. This is a severely limiting factor that practically hinders the applicability of non-local blocks to even moderately sized inputs. Previous works focused on reducing the complexity by modifying the underlying matrix operations, however in this work we aim to retain full expressiveness of non-local layers while keeping complexity linear. We overcome the efficiency limitation of non-local blocks by framing them as special cases of 3rd order polynomial functions. This fact enables us to formulate novel fast Non-Local blocks, capable of reducing the complexity from quadratic to linear with no loss in performance, by replacing any direct computation of pairwise similarities with element-wise multiplications. The proposed method, which we dub as "Poly-NL", is competitive with state-of-the-art performance across image recognition, instance segmentation, and face detection tasks, while having considerably less computational overhead.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Convolutional Neural Networks (CNNs) have led to a revolution in machine learning, and, specifically, are currently the undisputed state of the art in computer vision on various tasks. Nonetheless, CNNs, even if composed by a deep stack of convolutional operators, have a limited receptive field <ref type="bibr" target="#b31">[32]</ref>, which makes the crucial long-range dependencies hard to capture.</p><p>Recent work on spatial self-attention ameliorated this issue with a novel set of modules for neural networks <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b45">45]</ref>. These blocks extract non-local interactions among all spa-tial positions of the input and weight them with a set of learnable parameters. Passing through a Non-local block, each input position takes into account the contribution of all the others, scaled by their similarity with a given reference. These blocks introduce the possibility to reason about the whole space in one glance and make non-local behavior easier to be captured by the network. Inserting Non-local blocks in neural architectures has been proven very effective <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b49">49,</ref><ref type="bibr" target="#b36">37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b35">36]</ref>, but the computation of a similarity score for each pair of points scales quadratically with the number of spatial positions. As such, the expensive computational and storage complexity makes non-local blocks impractical to compute even upon moderately sized input.</p><p>Recent works tackle such limitation via an efficient computation of the similarity matrix <ref type="bibr" target="#b56">[56,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b42">42]</ref> but miss to provide a theoretical overview of the Non-local block formulation. In this work, we build upon the aforementioned line of research, and revisit Non-local layers under the lens of polynomials, framing them as special cases of 3 rd order polynomials. Powered by this intuition, we derive an efficient version of Non-local neural networks, Poly-NL which takes into account long-range dependencies without the need to compute explicitly any pairwise similarity. Poly-NL layers perform computations using the same set of interactions as the Non-local block of <ref type="bibr" target="#b50">[50]</ref>, and at the same time reduce the overall complexity drastically from O(N 2 ) to O(N ) with no loss in performance.</p><p>In this work, we link polynomials and the Non-Local layer. Our goal is to efficiently extract high-order interactions from the input while capturing long-range spatial dependencies. Thus, our contribution can be summarized as follows:</p><p>? We bridge the formulations between high-order polynomials and non-local attention. In particular, we prove that self-attention (in the form of Non-local blocks) can be seen as a particular case of general 3 rd order polynomials.</p><p>? We propose "Poly-NL" a novel building block for neural networks, which can be seen as polynomials of the input matrix. In particular, we propose an alternative Non-local block that reduce complexity from quadratic to linear with respect to the spatial dimensions.</p><p>? We showcase the efficiency and the effectiveness of our method across a range of tasks: image recognition, instance segmentation, and face detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Multiplicative interactions <ref type="bibr" target="#b20">[21]</ref> can be found at the core of various machine learning models such as Bilinear layers, LSTM, and Higher-order Boltzmann machines. In LSTM <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24]</ref>, element-wise products are used to fuse representations. In Bilinear layers <ref type="bibr" target="#b44">[44,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b53">53]</ref> feature maps of different networks get bilinearly combined together to capture pairwise interactions. In k th -order Boltzmann machines <ref type="bibr" target="#b33">[34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b39">40]</ref> k th order multiplicative interactions are used to define the energy function. These high order interactions capture the many possible ways in which the output can depend on the input. More recently, ??nets <ref type="bibr" target="#b11">[12]</ref> use polynomial expansions as a function approximator, replacing traditional activation functions with polynomials of the input vectors and use tensor decompositions <ref type="bibr" target="#b22">[23]</ref> to reduce the number of learnable parameters.</p><p>Multiplicative interactions are also crucial in the context of self-attention. Self-attention methods have been proposed as mechanisms to self-recalibrate feature maps and have been used either as replacement or addition to traditional residual blocks <ref type="bibr" target="#b17">[18]</ref>. Complementary to our work, some of these methods accumulate contextual information into lightweight global-descriptors, either extrapolating a single scalar for each spatial position <ref type="bibr" target="#b46">[46]</ref>, channel <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b3">4]</ref>, channel and position <ref type="bibr" target="#b51">[51]</ref> or region of space <ref type="bibr" target="#b25">[26]</ref>.</p><p>Closer to our work, it is the idea of modeling non-local long-range dependencies among spatial positions. While this is not new in computer vision <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b12">13]</ref> it is relatively recent in the context of neural networks architecture, in the form of "Non-local" attention modules, capable to attend at the same time every element of the input <ref type="bibr" target="#b50">[50,</ref><ref type="bibr" target="#b45">45]</ref>. Examples of successful use of these modules can be found in natural language processing as well as in computer vision, where some form of self-attention has been used to achieve state-of-the-art performance in various problems as translation <ref type="bibr" target="#b36">[37]</ref>, question answering <ref type="bibr" target="#b35">[36]</ref>, classification <ref type="bibr" target="#b37">[38,</ref><ref type="bibr" target="#b1">2]</ref>, segmentation <ref type="bibr" target="#b47">[47,</ref><ref type="bibr" target="#b4">5]</ref>, and video processing <ref type="bibr" target="#b49">[49]</ref>, among others. While some works focused on extending the scope of Non-local blocks, by capturing channels' correlations <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b14">15]</ref> or considering multiple resolutions of the image <ref type="bibr" target="#b32">[33,</ref><ref type="bibr" target="#b13">14]</ref>, recent work has sparked a discussion on the scalability of these modules, and on how to overcome their intrinsic efficiency limitations <ref type="bibr" target="#b43">[43]</ref>.</p><p>Existing solutions focus on increasing the efficiency of the similarity operator, for example by reducing the number of positions attended <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b55">55]</ref> or using low dimensional latent spaces <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b56">56,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b48">48]</ref> or on the computation order of the matrix-formula <ref type="bibr" target="#b42">[42,</ref><ref type="bibr" target="#b21">22]</ref>. In this work, we propose an alternative solution to this problem. We introduce a faster reformulation of the Non-Local block by framing non-local dependencies as 3 rd order interactions. Our method can extract non-local dependencies using no matrix multiplication computed along the spatial dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Non-locality and high-order interactions</head><p>We start by introducing notation and background, then proceed in formalizing the concept of 3 rd order interactions. Our goal is to accelerate Non-local blocks in a principled manner without losing the rich, long-range interactions that have proven successful in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Background</head><p>Notation. We follow the notation of Kolda et al. as in <ref type="bibr" target="#b22">[23]</ref>. Vectors are denoted as lower-case bold letters (e.g. x) and matrices as upper-case bold letters (e.g X). The element (i, j) of a matrix X can be indicated as x (i,j) . Tensors are identified with bold Euler script letters (e.g. X ). The order of a tensor is the number of dimensions, also known as way or mode. Hadamard products are indicated using the symbol " ". Given two tensors, we define their double-dot product as the tensor contraction with respect to the last two indices of the first one and the first two indices of the second one, identified with the bullet "?" symbol. In the case of a tensor W ? R I1?I2????I N -1 ?I N and a matrix X ? R I N -1 ?I N their double-dot product is a tensor of order N -2, i.e. Y = W ? X of dimension I 1 ? I 2 ? ? ? ? I N -2 . Specifically, in element-wise form, such double-dot product reads</p><formula xml:id="formula_0">y (i1,...,i N -2 ) = I N in=1 I N -1 in-1=1 w (i1,...,i N -2 ,in-1,in) x (in-1,in) .</formula><p>Non-local Block. A generic self-attention block for neural networks highlights relevant interactions in a feature map using a function g, designed to manipulate the input, and a function f , in charge of extracting similarities from it. In <ref type="bibr" target="#b50">[50]</ref>, the authors introduce the "Non-local block", a self-attention block used to highlight non-local long-range dependencies in the input. It operates on a folded feature map X ? R N ?C of N spatial positions and C channels and outputs a matrix Z of the same dimensionality</p><formula xml:id="formula_1">Z = Y + X = f (X)g(X) + X<label>(1)</label></formula><p>where f : R N ?C ? R N ?N is a pairwise function that calculates similarity for each pair of spatial positions, and </p><formula xml:id="formula_2">Poly-NL ? R N ?C?N ?C?N ?C?N ?C weight each triplet x (c,d) x (e,f ) x (g,h) by its importance w (a,b,c,d,e,f,g,h)</formula><p>. This is depicted in the second box as a line of colored dots. The output element y (a,b) is the weighted summation of every triplet.</p><p>g : R N ?C ? R N ?C , which has the form of a unary function computing a new representation for the input. In the case where g(X) is a linear embedding and f (X) is an embedded dot-product, the contribution of the self-attention to the output can be written as</p><formula xml:id="formula_3">Y N L = (XW ? W ? X )(XW g ) = XW f X XW g (2)</formula><p>where W ? , W ? , W g are matrices of learnable parameters of dimension C ? C. To produce the output Y, the Nonlocal block computes the dot-product between a similarity matrix (XW f X ) ? R N ?N and an embedding of the input (XW g ) ? R N ?C . This matrix multiplication recalibrates the features of the n th position via aggregating information from all the others. The pairwise function provides the similarity weights for the contribution of each position and uses a matrix multiplication along the N dimension. Such matrix multiplication on the N dimension is at the core of the non-local processing but introduces a quadratic term in computation that makes the complexity of this module equal to O(N 2 ).</p><p>Polynomials for Neural Networks. Recently in <ref type="bibr" target="#b11">[12]</ref>, the authors adopted polynomials as layers of neural networks. We follow their formulation of a polynomial function P : R N ?C ? R N ?C such that Y = P (X), in which each element of the output matrix is expressed as a polynomial of all the input elements x (i,j) . The output of the layer is formed as</p><formula xml:id="formula_4">Y = P (X) = D d=1 W [d] d j=1 ?X + W [0]<label>(3)</label></formula><p>where D is the order of the polynomial, W <ref type="bibr">[d]</ref> is the tensor of learnable parameters associated with a specific order d, and W [0] is a bias matrix of learnable parameters. The order of the tensor W [d] increases exponentially for higherorder polynomial terms, i.e.</p><formula xml:id="formula_5">W [d] ? R N ?C? d j=1 (N ?C) .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">3 rd order interactions</head><p>To present our method, we start by describing 3 rd order interactions terms for a feature map X ? R H?W ?C . We consider its folding X ? R N ?C , where the spatial dimensions have been grouped together N = H ? W . To capture all potential 3 rd order dependencies between X's elements, we consider their linear combination weighted with a set of learnable parameters. In other words, we isolate the 3 rd order term (D = 3) of Eq. (3) by assuming</p><formula xml:id="formula_6">W [0] = 0, W [1] = 0, W [2] = 0. Under the aforemen- tioned assumptions, Eq. (3) becomes Y = (((W [3] ? X) ? X) ? X)<label>(4)</label></formula><p>where W <ref type="bibr" target="#b2">[3]</ref> is a tensor of order 8 and dimension R N ?C?N ?C?N ?C?N ?C . We can find all possible 3 rd order interactions, i.e. the multiplication of all possible triplets of the input's elements summed together, clearly highlighted in its element-wise formula</p><formula xml:id="formula_7">y (a,b) = N c,e,g C d,f,h w 3 (a,b,c,d,e,f,g,h) x (c,d) x (e,f ) x (g,h) (5)</formula><p>As depicted in Eq. (5), in a 3 rd order polynomial each element of the output matrix, y (a,b) , benefits from the contributions of every possible triplet x <ref type="bibr">(c,d)</ref> x (e,f ) x (g,h) , each weighted by its unique importance w 3 (a,b,c,d,e,f,g,h) . The use of W <ref type="bibr" target="#b2">[3]</ref> in its most general form would allow taking into account every possible pattern in the input but, at the same time, it would increase the number of parameters exponentially. A well-known problem in higher-order models <ref type="bibr" target="#b39">[40,</ref><ref type="bibr" target="#b11">12]</ref> is the number of parameters considered, which tends to be the most expensive part of their implementation. The number of the parameters to determine in Eq. <ref type="formula" target="#formula_4">(3)</ref> depends on the order of the polynomial and, even without considering orders lower than D, the parameters required are (N C) D (for instance, the use of D = 3 on an input 1024 ? 196 will introduce nearly extra 10 21 parameters). Different approaches can be considered for reducing the number of parameters, for example by taking into account prior knowledge about the task or the nature of the input data <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b34">35]</ref>. One approach to reduce the complexity is by selecting only a limited subsets of all the possible combinations x <ref type="bibr">(c,d)</ref> x (e,f ) x (g,h) exploiting a particular structure of the tensor W <ref type="bibr" target="#b2">[3]</ref> . For example, assigning the same weight to a group of triplets will guarantee the same contribution for each of them, or imposing some zero-weights on one subsets of triplet will cancel their impact on the output y (a,b) . These choices can be expressed in a formal way, which makes the format of the W <ref type="bibr" target="#b2">[3]</ref> tensor sparse, because some of the dimensions are constrained to be diagonal, or low-rank, since repeated values are used along some dimensions. The central idea of this paper is to factor the interaction tensor W <ref type="bibr" target="#b2">[3]</ref> in a particular way, to extract only a minimal subset of 3 rd order interactions from the input data. In other words, the choice of such tensor allows its replacement with matrices of smaller size, implemented using only pre-existing building blocks for neural networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Method</head><p>In this section, we characterize the set of 3 rd order interactions associated with non-local dependencies and propose a method that accesses them without the expensive computation of a similarity matrix. The proposed method "Poly-NL" is a novel non-local block, capable of selecting the same interactions as a Non-local layer at a fraction of its original computational cost in both space and time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Poly-NL layer</head><p>As described in Section 3.1, a major drawback of the Non-local block is its complexity, which depends on the number of spatial positions as O(N 2 ). To address this drawback we propose Poly-NL, a non-local spatial selfattention module that avoids any matrix multiplications along dimension N. Poly-NL takes in input a matrix X ? R N ?C and outputs a matrix of the same dimensionality Z, that can be computed as Z = ?X + ?Y Poly-NL , with ? and ? are learnable scalars. The matrix Y Poly-NL is the core of the Poly-NL layer and can be written as follows</p><formula xml:id="formula_8">Y Poly-NL = (?(XW 1 XW 2 ) X)W 3 ,<label>(6)</label></formula><p>where ? : R N ?C ? R N ?C is an average pooling on spatial positions followed by an expand function, W 1 , W 2 , W 3 ? R C?C are matrices of learnable parameters and indicates element-wise multiplication. A visual depiction of the module is presented in <ref type="figure" target="#fig_0">Figure 1</ref>, Poly-NL is a layer that scales linearly with the dimension N (i.e. has a complexity of O(N )).</p><p>Noteworthily, Poly-NL extracts the same set of dependencies as the Non-local block but learns a different set of weights to process them. In order to connect the two formulations, we describe the set of interactions captured by these two blocks. The set of spatial interactions associated with Poly-NL is clearly highlighted in its element-wise formula</p><formula xml:id="formula_9">y Poly-NL (a,b) = C d,f,h N e 1 N w 1 (h,d) w 2 (f,d) w 3 (d,b) x (a,d) x (e,f ) x (e,h)<label>(7)</label></formula><p>In Poly-NL, each element y Poly-NL (a,b) of the output matrix is computed using the contribution of a set of triplets x <ref type="bibr">(a,d)</ref> x (e,f ) x (e,h) , weighted using the learnable parameters</p><formula xml:id="formula_10">w 1 (h,d) w 2 (f,d) w 3 (d,b) .</formula><p>Analogously, we highlight the set of interaction captured by the non-local module of Eq. (2), by writing its elementwise formulation</p><formula xml:id="formula_11">y NL (a,b) = C d,f,h N e w f (d,f ) w g (h,b) x (a,d) x (e,f ) x (e,h) .<label>(8)</label></formula><p>In the Non-local block, each element of the output matrix y NL (a,b) is computed using the contribution of a set of triplets x <ref type="bibr">(a,d)</ref> x (e,f ) x (e,h) , weighted using the learnable parameters w f (d,f ) w g (h,b) . As visible from the comparison between the two formulas, Poly-NL and Non-Local block modules are closely connected. They both access the same set of triplets and optimize through backpropagation a set of learnable weights. Nevertheless, the two modules differ considerably in terms of computational efficiency. Poly-NL does not need to explicitly compute any pairwise-function and can be therefore viewed as a linear complexity alternative to the Non-Local blocks.  Interestingly, both of these blocks are also special cases of 3 rd order polynomials of Eq. (4). The outputs of these blocks Y NL and Y Poly-NL , can be equivalently computed using Eq. (4), in which W <ref type="bibr" target="#b2">[3]</ref> NL and W <ref type="bibr" target="#b2">[3]</ref> Poly-NL are block-sparse, low-rank, and can be decomposed through smaller matrices (i.e. W g W f and W 1 W 2 W 3 , respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Relation with other Non-local blocks</head><p>The idea of decomposing higher-order tensors in smaller matrices is not new <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b34">35]</ref>, but can be used to cast a new light on a series of popular self-attention models. Besides Non-local block and Poly-NL, other popular non-local variants can be framed as special cases of 3 rd order polynomials <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b56">56,</ref><ref type="bibr" target="#b42">42]</ref>. We compare Poly-NL to these methods and discuss the advantages of our formulation in terms of computational efficiency. <ref type="figure" target="#fig_1">Figure 2</ref> depicts the complexity overhead of various spatial Non-local blocks for different sizes of the input matrix X. In the visualization, we examine both the number of spatial positions <ref type="figure" target="#fig_1">(Figures 2b and 2c</ref>) and the number of channels (as in <ref type="figure" target="#fig_1">Figure 2a</ref>). The charts examine the performance of five different methods (TESA <ref type="bibr" target="#b0">[1]</ref>, NL <ref type="bibr" target="#b50">[50]</ref>, L-GNN <ref type="bibr" target="#b56">[56]</ref>, E-NL <ref type="bibr" target="#b42">[42]</ref> and Poly-NL) and a showcase how the proposed solution is able to process inputs size otherwise unmanageable by other formulations. We report computational time on CPU <ref type="figure" target="#fig_1">(Figure 2a</ref>) and GPU <ref type="figure" target="#fig_1">(Figure 2b</ref>) as measure of time complexity and peak memory usage on GPU as indi-cator of space complexity <ref type="figure" target="#fig_1">(Figure 2c</ref>). To ease comparisons among methods, we include as baseline a regular convolution layer (CONV), where no attention mechanism is used. All benchmarks were executed considering a single layer of each method on identical hardware, under comparable implementations, and hyper-parameters (please check additional material for full-nets run-times and implementation details). For each method, the values shown in the charts are the median of 20 runs.</p><p>The TESA block of <ref type="bibr" target="#b0">[1]</ref> proposes to integrate spatial correlations together with channels' dependencies by computing six matrix multiplications on the three different matricizations of the input tensor X . This procedure increments the patterns captured by the self-attention but it is burdened by a very high computational complexity of O(N 2 ). The Latent-GNN block of <ref type="bibr" target="#b56">[56]</ref>, given the input matrix X ? R N ?C , proposes to use a latent representation N ? d to extract long-range dependencies with O(N d 2 ) complexity. The block uses matrix multiplications to compute a lowrank matrix d ? d, which captures latent space interactions, and a matrix d ? C, which captures its relation with the input channels. This method has a computational complexity that is linear with respect to the number of spatial positions N but depends on the choice of the hyperparameter d and a sequence of matrix dot-product multiplications to compute the output. Lastly, the "Efficient Non-local block" <ref type="bibr" target="#b42">[42]</ref> proposes to compute the original formula of Eq. <ref type="formula">(2)</ref>    to left. This procedure avoids the computation of pairwisespatial similarities and makes the complexity linear with respect to N , but it still requires computing a sequence of two matrix dot-products multiplications to extract the output. As displayed in <ref type="figure" target="#fig_1">Figures 2b and 2c</ref>, increasing the number of spatial positions greatly impacts efficiency. Run times of TESA and NL, which both depend quadratically on N , quickly become impractical, even in cases where the input dimension is small. Efficient methods (E-NL, L-GNN, Poly-NL) scale better with increasing spatial positions. Nonetheless, our method holds a competitive advantage across all figures, due to its lack of any matrix dot-product multiplication on the spatial dimension N . As shown in <ref type="figure" target="#fig_1">Figure 2a</ref>, the number of channels impact linearly the runtime performance of most methods, with the notable exception of TESA. Even in this case, our proposed method is performing significantly better than competing methods especially when the number of channels becomes significant.</p><p>As visible on the figures, Poly-NL consistently outperforms existing competitors, and has an efficiency on par with a regular convolution layer (CONV) since by design it avoids the explicit computation of any attention matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Experiments</head><p>We evaluate the proposed method on three different tasks: object detection and instance segmentation on COCO <ref type="bibr" target="#b28">[29]</ref>, image classification on ImageNet <ref type="bibr" target="#b38">[39]</ref>, and face detection on the WIDER FACE dataset <ref type="bibr" target="#b52">[52]</ref>. We provide empirical evidence that Poly-NL outperforms previously proposed Non-local neural networks while maintaining an optimal trade-off between efficiency and performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Instance Segmentation on MS COCO</head><p>We tested our method on object detection and instance segmentation, where the network processes an image and produces a pixel-pixel mask that identifies both the category and the instance for each object. We use the MS-COCO 2017 dataset <ref type="bibr" target="#b28">[29]</ref>, composed by 118k images as training set, 5k as validation set and 20k as test set, and the Mask R-CNN baseline of <ref type="bibr" target="#b16">[17]</ref>. For all the experiments, we report the standard metrics of Average Precision AP , AP 50 , and AP 75 for both bounding boxes and segmentation masks. The Mask R-CNN architecture is composed of a ResNet-FPN backbone for feature extraction followed by a stage that predicts class and box offsets. We trained with 8 Tesla V-100 GPUs and 2 images per GPU (effective batch size 16) using random horizontal flip as augmentation during training. We use an SGD solver with weight decay of 0.0001, momentum of 0.90, and an initial learning rate of 0.02. All models are trained for 26 epochs with learning rate steps are executed at epoch 16 and 22 with gamma 0.1. We used as backbones ResNet-50 <ref type="bibr" target="#b17">[18]</ref> architectures pre-trained on Imagenet.</p><p>Following prior work, we modify the Mask R-CNN backbone by adding one non-local layer right before the last residual block of Res4. This procedure highlights the capacity of the self-attention to boost features' representation and improve the quality of the candidate object bounding boxes. We compare our method against four different spatial selfattention layers, the original Non-local block of <ref type="bibr" target="#b50">[50]</ref>, the efficient Latent-GNN variant of <ref type="bibr" target="#b56">[56]</ref>, the Efficient-NL of <ref type="bibr" target="#b42">[42]</ref> and the recently proposed TESA <ref type="bibr" target="#b0">[1]</ref>. For fair comparison, we report the results from our training, achieved using public available source codes and hyperparameters as provided by the respective authors.</p><p>Quantitative results are summarized in <ref type="table" target="#tab_0">Table 1</ref>. When compared to the best performing method, TESA <ref type="bibr" target="#b0">[1]</ref>, Poly-NL exhibits identical performance in AP mask and slightly lower accuracy for AP box . However, we note that our proposed method is nearly ?10 faster to compute than TESA at the given resolution. Moreover, compared to the Non-local layer <ref type="bibr" target="#b50">[50]</ref> and its efficient variants Latent-GNN <ref type="bibr" target="#b56">[56]</ref> and Efficient-Net, our method improves performance by 0.3% ? in AP box while keeping linear computational complexity.</p><p>We ablate the location we insert the proposed layer in MaskR-CNN and present our findings in <ref type="table" target="#tab_2">Table 2</ref>. We find that employing self-attention on any block of the ResNet backbone improves considerably the performance in both detection and segmentation. It appears that Res4 is the optimal block to insert Poly-NL into, since the numerical improvement across all metrics is consistent. At the same time, <ref type="table" target="#tab_2">Table 2</ref> shows that a combination of all ResNet blocks leads to the best performance (at most 1.2% ? in AP box and 1.5% ? in AP mask ). Although having a self-attention block at Res4 is preferable, the contribution of attention on multiple blocks outperforms the usage on a single module. These results suggest how complementary attention patterns can be captured at different network stages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Face Detection on WIDER FACE</head><p>We also apply our model to the task of face detection on the WIDER FACE dataset <ref type="bibr" target="#b52">[52]</ref>, which consists of 32, 203 images and 393, 703 face bounding boxes (40% training, 10% validation, and 50% testing) with a high degree of variability in scale, pose, expression, occlusion, and illumination. Compared to COCO <ref type="bibr" target="#b28">[29]</ref>, WIDER FACE <ref type="bibr" target="#b52">[52]</ref> contains more tiny and dense detection objects (i.e. faces). 51% of objects from COCO <ref type="bibr" target="#b28">[29]</ref> have the relative scale to the image below 0.11, while for a similar proportion, 55% of faces in WIDER FACE are less than 0.02. In addition, 1% of images in COCO have more than 30 objects, while there are 8% images contains more than 30 faces in WIDER FACE and many images even include more than 150 faces. Based on the detection rate of EdgeBox <ref type="bibr" target="#b58">[58]</ref>, three levels of difficulty (i.e. Easy, Medium, and Hard) are defined by incrementally incorporating hard samples. By using the evaluation metric of IoU 0.5, we compare the Average Precision (AP) of the proposed method and other baselines on Easy, Medium and Hard subsets, respectively.</p><p>Our experiments are implemented with PyTorch based on open source mmdetection <ref type="bibr" target="#b6">[7]</ref>. Inspired by RetinaNet <ref type="bibr" target="#b27">[28]</ref>, we choose ResNet-50 <ref type="bibr" target="#b17">[18]</ref> as backbone and Feature Pyramid Network (FPN) <ref type="bibr" target="#b26">[27]</ref> as neck to construct the feature extractor. The losses of classification and regression branches are focal loss <ref type="bibr" target="#b27">[28]</ref> and DIoU loss <ref type="bibr" target="#b57">[57]</ref>, respectively. Following <ref type="bibr" target="#b50">[50]</ref>, we insert one Poly-NL block right before the last residual block of c4. To detect tiny faces, we tile three scales of anchors over each level of the FPN. The aspect ratio is set as 1.3 and the IoU threshold for positive sampling matching is 0.35. For augmentation during training, square patches are cropped and resized to 640 ? 640 from the original image with a random scale. Then, photometric distortion and random horizontal flip with the probability of 0.5 are applied. We train the model by using SGD optimizer (momentum 0.9, weight decay 5e-4) with a batch size of 8?8 on 8 Tesla V100 GPUs. The initial learning rate is set to 0.001, linearly warms up for the first 3 epochs, and decays by a factor of 10 at 250-th epoch and 350-th epoch. All the models are trained with 400 epochs from scratch without any pre-training. During testing, we only employ single scale inference with the short and long edge of image bounded by 1100 and 1650, respectively. As shown in <ref type="table" target="#tab_3">Table 3b</ref>, all attention modules can significantly improve the performance of face detection on WIDER FACE, indicating the effectiveness of context modeling (i.e. capturing long-range dependencies among pixels). Besides, the proposed Poly-NL module consistently outperforms all other non-local layers across the three levels of difficulty, achieving the mAP of 92.76% on the hard subset while being considerably faster than all competing methods.</p><formula xml:id="formula_12">X Y Z = X + Y X Y Z = X + Y</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Classification on Imagenet</head><p>We evaluated our method on the task of large-scale image classification, using Imagenet dataset <ref type="bibr" target="#b38">[39]</ref>, counting 1.28M training images of 1000 classes. For all the experiments, we modify a ResNet-50 architecture <ref type="bibr" target="#b17">[18]</ref> by inserting a self-attention module and then train from scratch with 8 GPUs for 90 epochs, using a batch size of 256 and an SGD optimizer with an initial learning rate of 0.1 and weightdecay as described in <ref type="bibr" target="#b15">[16]</ref>. Quantitative results are reported in table (3a) and show the Top-1 and the Top-5 accuracy for the evaluated methods. It is apparent that also in the classification task, where the goal is to provide a summary of the input, reasoning about spatial dependencies benefits greatly the accuracy. Poly-NL achieves the best performance on Top-5 accuracy, and on Top-1, outperforms significantly all other Non-Local neural networks with the exception of TESA <ref type="bibr" target="#b0">[1]</ref>, which is very computationally demanding.</p><p>Beyond quantitative results, <ref type="figure" target="#fig_2">Fig. 3</ref> illustrates qualitative differences between different non-local variants. The visualization is produced with Gradient-weighted Class Activation Mapping (Grad-CAM) <ref type="bibr" target="#b40">[41]</ref>, a technique that highlights areas of high importance for image classification tasks. Our proposed method more accurately captures global context and salient features when compared to other Non-Local methods. <ref type="figure" target="#fig_3">Fig. 4</ref> visualize the contribution of Poly-NL to the input's representation. The figure overlays the norm of different features on top of the input image. We report the input's feature map X, the contribution of attention module Y and their summation Z, i.e. output of the Poly-NL module. It is apparent that Poly-NL learns to contextualize the visual clues of the input with non-local dependencies. Our selfattention module can effectively recognize patterns that are complementary to those captured in the input and makes the features map aware of long-range dependencies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this work, we cast the recently proposed Non-local block as a 3rd order polynomial in the form of multiplicative interactions between spatial locations on a grid. Based on this fact, we propose a novel and fast embodiment of Nonlocal layers named Poly-NL that can capture long-range dependencies with a complexity that scales linearly with the size of the input in both space and time. Poly-NL consistently outperforms other non-local networks on image recognition, instance segmentation, and face detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Two views of the Poly-NL block. a) Poly-NL as a non-local self-attention block for neural networks. The symbol denotes Hadamard products. Gray boxes represent convolutions of kernel size 1 and an averaging function over the rows. The output of the average pooling undergoes an expansion before the Hadamard multiplication. b) Poly-NL as a 3 rd order polynomial module for neural networks. In the first box the space of 3 rd order interactions is represented as a line of (N C) 3 white dots, containing all possible triplets. The learnable parameters of W<ref type="bibr" target="#b2">[3]</ref> </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Runtime and Peak memory consumption performance comparison between Poly-NL and other non-local methods executed on a CPU Intel(R) Core(TM) i9-9900X CPU (a) and a RTX2080 GPU (b,c). Poly-NL exhibits lower computational overhead than competing methods, which is of importance with an increasing number of spatial positions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Class saliency maps of different methods. Grad-Cam<ref type="bibr" target="#b40">[41]</ref> evaluates regions of the image which correspond to the class of interest. The use of non-local blocks helps to discriminate classes' characteristics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Non-local dependencies captured by Poly-NL. The norm of the extracted features per spatial location is visualized over the input image. The attention contribution Y learns patterns complementary to those captured by the input X. The summation of the aforementioned quantities merges together the contribution of short and long-range spatial dependencies.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>MethodAP box AP box50 AP box75 AP mask AP mask50 AP mask75</figDesc><table><row><cell>MaskR-CNN</cell><cell>37.9</cell><cell>59.2</cell><cell>41.0</cell><cell>34.6</cell><cell>56.0</cell><cell>36.9</cell></row><row><cell>+ Non-local</cell><cell>38.8</cell><cell>60.6</cell><cell>42.0</cell><cell>35.4</cell><cell>57.3</cell><cell>37.7</cell></row><row><cell>+ TESA</cell><cell>39.5</cell><cell>60.9</cell><cell>43.1</cell><cell>35.4</cell><cell>57.2</cell><cell>37.5</cell></row><row><cell>+ Latent-GNN</cell><cell>38.9</cell><cell>60.4</cell><cell>42.4</cell><cell>35.3</cell><cell>57.3</cell><cell>37.4</cell></row><row><cell>+ Efficient-NL</cell><cell>38.9</cell><cell>60.3</cell><cell>42.2</cell><cell>35.4</cell><cell>57.2</cell><cell>37.7</cell></row><row><cell>+ Poly-NL</cell><cell>39.2</cell><cell>60.8</cell><cell>42.2</cell><cell>35.4</cell><cell>57.4</cell><cell>37.6</cell></row></table><note>Results of Poly-NL and other Non-Local methods on Instance Segmentation-COCO.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>from right Method AP box AP box50 AP box75 AP mask AP mask50 AP mask75</figDesc><table><row><cell>MaskR-CNN</cell><cell>37.9</cell><cell>59.2</cell><cell>41.0</cell><cell>34.6</cell><cell>56.0</cell><cell>36.9</cell></row><row><cell>w/ Poly-NL</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>+ on Res3</cell><cell>38.6</cell><cell>60.1</cell><cell>41.5</cell><cell>35.2</cell><cell>56.9</cell><cell>37.4</cell></row><row><cell>+ on Res4</cell><cell>39.2</cell><cell>60.8</cell><cell>42.2</cell><cell>35.4</cell><cell>57.4</cell><cell>37.6</cell></row><row><cell>+ on Res5</cell><cell>38.7</cell><cell>60.6</cell><cell>41.9</cell><cell>35.2</cell><cell>57.2</cell><cell>37.3</cell></row><row><cell>+ on Res345</cell><cell>39.8</cell><cell>61.7</cell><cell>43.2</cell><cell>36.0</cell><cell>58.4</cell><cell>38.3</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 :</head><label>2</label><figDesc>Ablation study of Poly-NL placement in MaskR-CNN for Instance Segmentation. Adding Poly-NL on different ResNet blocks yields changes in performance. An application of Poly-NL on all ResNet blocks provides the best results when compared to a sole application on a single block.</figDesc><table><row><cell>Method</cell><cell>Top-1 Top-5</cell><cell>Method</cell><cell>Easy</cell><cell cols="2">M edium Hard</cell></row><row><cell>ResNet-50</cell><cell>75.62 92.68</cell><cell>ResNet-50</cell><cell>95.49</cell><cell>94.85</cell><cell>89.87</cell></row><row><cell>+ Non-local</cell><cell>76.09 93.00</cell><cell>+ Non-local</cell><cell>95.88</cell><cell>95.14</cell><cell>91.94</cell></row><row><cell>+ TESA</cell><cell>76.49 93.05</cell><cell>+ TESA</cell><cell>96.22</cell><cell>95.61</cell><cell>92.58</cell></row><row><cell cols="2">+ Latent-GNN 75.28 92.33</cell><cell>+ Latent-GNN</cell><cell>96.00</cell><cell>95.31</cell><cell>92.49</cell></row><row><cell cols="2">+ Efficient-NL 75.86 93.02</cell><cell>+ Efficient-NL</cell><cell>96.06</cell><cell>95.42</cell><cell>92.55</cell></row><row><cell>+ Poly-NL</cell><cell>76.30 93.06</cell><cell>+ Poly-NL</cell><cell>96.37</cell><cell>95.71</cell><cell>92.76</cell></row><row><cell cols="2">(a) Imagenet</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>(b) Face Detection</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table /><note>Results of Non-Local variants for image classification on ImageNet and face detection on WIDER FACE.</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Tesa: Tensor element self-attention via matricization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francesca</forename><surname>Babiloni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ioannis</forename><surname>Marras</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gregory</forename><surname>Slabaugh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="13945" to="13954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Attention augmented convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision (ICCV)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A non-local algorithm for image denoising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><surname>Buades</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bartomeu</forename><surname>Coll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J-M</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;05)</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Gcnet: Non-local networks meet squeeze-excitation networks and beyond</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyun</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">End-toend object detection with transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Carion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Francisco</forename><surname>Massa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Synnaeve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicolas</forename><surname>Usunier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Kirillov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="213" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Semantic segmentation with second-order pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Caseiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jorge</forename><surname>Batista</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cristian</forename><surname>Sminchisescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="430" to="443" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaqi</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiangmiao</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuhang</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoxiao</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuyang</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wansen</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiarui</forename><surname>Xu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07155</idno>
		<title level="m">Open mmlab detection toolbox and benchmark</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Graph-based global reasoning networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunpeng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marcus</forename><surname>Rohrbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhicheng</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Shuicheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiashi</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Kalantidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="433" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">On tensors, sparsity, and nonnegative factorizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamara</forename><forename type="middle">G</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Journal on Matrix Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1272" to="1299" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Generating long sequences with sparse transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rewon</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alec</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ilya</forename><surname>Sutskever</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.10509</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rethinking attention with performers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Valerii</forename><surname>Krzysztof Marcin Choromanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Likhosherstov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyou</forename><surname>Dohan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreea</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tamas</forename><surname>Gane</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Sarlos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jared</forename><forename type="middle">Quincy</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Afroz</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Mohiuddin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">Benjamin</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucy</forename><forename type="middle">J</forename><surname>Belanger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adrian</forename><surname>Colwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">P-nets: Deep polynomial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stylianos</forename><surname>Grigorios G Chrysos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giorgos</forename><surname>Moschoglou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yannis</forename><surname>Bouritsas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiankang</forename><surname>Panagakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefanos</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zafeiriou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Image denoising by sparse 3-d transformdomain collaborative filtering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostadin</forename><surname>Dabov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alessandro</forename><surname>Foi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vladimir</forename><surname>Katkovnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Egiazarian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on image processing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2080" to="2095" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Second-order attention network for single image super-resolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tao</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianrui</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbing</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu-Tao</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lei</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="11065" to="11074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dual attention network for scene segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jing</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haijie</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongjun</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3146" to="3154" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pieter</forename><surname>Noordhuis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Wesolowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aapo</forename><surname>Kyrola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Tulloch</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.02677</idno>
		<title level="m">Yangqing Jia, and Kaiming He. Accurate, large minibatch sgd: Training imagenet in 1 hour</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Piotr Doll?r, and Ross Girshick. Mask r-cnn</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Georgia</forename><surname>Gkioxari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Long short-term memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sepp</forename><surname>Hochreiter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1735" to="1780" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Squeeze-and-excitation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jie</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7132" to="7141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Multiplicative interactions and where to find them</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Siddhant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wojciech</forename><forename type="middle">M</forename><surname>Jayakumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Menick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Rae</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yee</forename><forename type="middle">Whye</forename><surname>Osindero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Teh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Razvan</forename><surname>Harley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pascanu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transformers are rnns: Fast autoregressive transformers with linear attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Angelos</forename><surname>Katharopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Apoorv</forename><surname>Vyas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikolaos</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Fleuret</surname></persName>
		</author>
		<idno>PMLR, 2020. 2</idno>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<biblScope unit="page" from="5156" to="5165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Tensor decompositions and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Tamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kolda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Brett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">SIAM review</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Multiplicative lstm for sequence modelling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iain</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steve</forename><surname>Renals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.07959</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighteenth International Conference on Machine Learning</title>
		<meeting>the Eighteenth International Conference on Machine Learning</meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Spatial group-wise enhance: Improving semantic feature learning in convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1905.09646</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Kaiming He, Bharath Hariharan, and Serge Belongie. Feature pyramid networks for object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Bilinear cnn models for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yu</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aruni</forename><surname>Roychowdhury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhransu</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1449" to="1457" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Spatially and temporally efficient non-local attention network for video-based person re-identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Ting</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chih-Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chiang Frank</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shao-Yi</forename><surname>Chien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Understanding the effective receptive field in deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Zemel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, and R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">29</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Pyramid attention networks for image restoration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yiqun</forename><surname>Mei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulun</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiahui</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuqian</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ding</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yun</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honghui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shi</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.13824</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Unsupervised learning of image transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>IEEE</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Learning to represent spatial transformations with factored higher-order boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roland</forename><surname>Memisevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Mohamed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dmytro</forename><surname>Okhonko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.11660</idno>
		<title level="m">Transformers with convolutional context for asr</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Scaling neural machine translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myle</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Auli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Conference on Machine Translation (WMT)</title>
		<meeting>the Third Conference on Machine Translation (WMT)</meeting>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Stand-alone selfattention in vision models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prajit</forename><surname>Ramachandran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Irwan</forename><surname>Bello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anselm</forename><surname>Levskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>H. Wallach, H. Larochelle, A. Beygelzimer, F. d&apos;Alch?-Buc, E. Fox, and R. Garnett, editors</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Higher-order boltzmann machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Terrence</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sejnowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AIP Conference Proceedings</title>
		<imprint>
			<publisher>American Institute of Physics</publisher>
			<date type="published" when="1986" />
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ramprasaath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Selvaraju</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhishek</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramakrishna</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Batra</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Visual explanations from deep networks via gradient-based localization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Grad-Cam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="618" to="626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Efficient attention: Attention with linear complexities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhuoran</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mingyuan</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haiyu</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuai</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision</title>
		<meeting>the IEEE/CVF Winter Conference on Applications of Computer Vision</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="3531" to="3539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Tay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mostafa</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dara</forename><surname>Bahri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.06732</idno>
		<title level="m">Efficient transformers: A survey</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Separating style and content with bilinear models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Joshua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">William T</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1247" to="1283" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1706.03762</idno>
		<title level="m">Attention is all you need</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Residual attention network for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mengqing</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Honggang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="3156" to="3164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Axial-deeplab: Standalone axial-attention for panoptic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huiyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukun</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bradley</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hartwig</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang-Chieh</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="108" to="126" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Linformer: Self-attention with linear complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sinong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Belinda</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madian</forename><surname>Khabsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Ma</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.04768</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Edvr: Video restoration with enhanced deformable convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xintao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Kelvin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ke</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chao</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen Change</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Loy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="0" to="0" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Joon-Young Lee, and In So Kweon. Cbam: Convolutional block attention module</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanghyun</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jongchan</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Wider face: A face detection benchmark</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen-Change</forename><surname>Loy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Hierarchical bilinear pooling for fine-grained visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaojian</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinyi</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xinge</forename><surname>You</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="574" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Compact generalized non-local network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiyu</forename><surname>Yue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuchen</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Feng</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Errui</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuxin</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NeurIPS</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="6511" to="6520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Dynamic graph message passing networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anurag</forename><surname>Arnab</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="3726" to="3735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Latentgnn: Learning efficient non-local relations for visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Songyang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shipeng</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="7374" to="7383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Distance-iou loss: Faster and better learning for bounding box regression</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhaohui</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ping</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinze</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongguang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongwei</forename><surname>Ren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Edge boxes: Locating object proposals from edges</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
