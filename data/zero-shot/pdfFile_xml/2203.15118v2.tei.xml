<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">LiDAR Snowfall Simulation for Robust 3D Object Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Hahner</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>3 MPI for Informatics 4 KU</addrLine>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sakaridis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>3 MPI for Informatics 4 KU</addrLine>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Bijelic</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>3 MPI for Informatics 4 KU</addrLine>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Heide</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>3 MPI for Informatics 4 KU</addrLine>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>3 MPI for Informatics 4 KU</addrLine>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>3 MPI for Informatics 4 KU</addrLine>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>3 MPI for Informatics 4 KU</addrLine>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eth</forename><surname>Z?rich</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Princeton University</orgName>
								<address>
									<addrLine>3 MPI for Informatics 4 KU</addrLine>
									<settlement>Leuven</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">LiDAR Snowfall Simulation for Robust 3D Object Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T07:39+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>3D object detection is a central task for applications such as autonomous driving, in which the system needs to localize and classify surrounding traffic agents, even in the presence of adverse weather. In this paper, we address the problem of LiDAR-based 3D object detection under snowfall. Due to the difficulty of collecting and annotating training data in this setting, we propose a physically based method to simulate the effect of snowfall on real clearweather LiDAR point clouds. Our method samples snow particles in 2D space for each LiDAR line and uses the induced geometry to modify the measurement for each LiDAR beam accordingly. Moreover, as snowfall often causes wetness on the ground, we also simulate ground wetness on LiDAR point clouds. We use our simulation to generate partially synthetic snowy LiDAR data and leverage these data for training 3D object detection models that are robust to snowfall. We conduct an extensive evaluation using several state-of-the-art 3D object detection methods and show that our simulation consistently yields significant performance gains on the real snowy STF dataset compared to clearweather baselines and competing simulation approaches, while not sacrificing performance in clear weather. Our code is available at github.com/SysCV/LiDAR snow sim.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A light detection and ranging (LiDAR) sensor is an active range sensor useful for several applications <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b27">27,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b61">61]</ref>. Its high-quality 3D output renders LiDAR the modality of choice for several tasks that require 3D reasoning, such as 3D object detection <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b59">59]</ref>. As LiDAR sensors are becoming increasingly cheaper <ref type="bibr" target="#b53">[53]</ref>, their integration into autonomous cars becomes increasingly feasible as well.</p><p>Nonetheless, previous sensor tests have revealed that such active pulsed systems are vulnerable in scattering media, leading to decreases of perception distances in various weather conditions such as rain <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b52">52]</ref>, fog <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b52">52]</ref>, and snow <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b28">28]</ref>, as shown in <ref type="figure" target="#fig_0">Fig. 1</ref>. In these conditions, the optical medium contains particles of water or snow which interact with the laser beam and absorb, reflect or refract its photons. This results in two effects: (i) attenuation of the received power that corresponds to the target at the line of sight, and (ii) backscattering from particles leading to spurious maxima in the received power and thus to spurious returns at ranges different from the true range of the target. Consequently, there is a severe degradation of measurement quality due to intense noise, a large domain shift relative to point clouds captured in clear weather, and hence a detrimental effect on performance of high-level tasks such as 3D object detection <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b15">16]</ref>. Yet, achieving robust perception in adverse weather is a desirable goal as fatality rates for human drivers are notably higher in adverse weather, as reported by the US Department of Transportation <ref type="bibr" target="#b49">[49]</ref> and the European Commission <ref type="bibr" target="#b7">[8]</ref>.</p><p>Since adverse-weather data are hard to collect <ref type="bibr" target="#b0">[1]</ref>, previous works have investigated simulation methods to close the domain gap for camera data in fog <ref type="bibr" target="#b36">[36]</ref> and rain <ref type="bibr" target="#b48">[48]</ref>.</p><p>More recently, simulation methods for LiDAR sensors in fog <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b15">16]</ref> and rain <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b21">22]</ref> have also been proposed. Motivated by this line of work, we introduce a physically based method to simulate snowfall on real clear-weather LiDAR point clouds. In particular, we use the linear system introduced in <ref type="bibr" target="#b33">[33]</ref> to model the transmission of LiDAR pulses and the associated received power at the sensor. We simulate snowfall by explicitly sampling snow particles and modeling them as opaque spheres, the size of which is controlled by the snowfall rate <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">32]</ref>. In our sampling, we obey the exclusion principle that no two particles intersect with each other. Given the sample of snow particles, we compute for each LiDAR beam the set of particles that intersect with it and derive the angle of the beam cross-section that is reflected by each particle, taking potential occlusions into account. This derivation directly delivers the modified impulse response of the linear system in the presence of snowfall, which allows the analytical calculation of the received power at the sensor.</p><p>Another condition associated with snowfall is wetness on the ground. This emerging thin water layer increases the specular component of reflection by the ground surface <ref type="bibr" target="#b44">[44]</ref>. To model the ground reflection, we introduce an optical model using the Fresnel equations and the reflection on thin surfaces, which provides adapted reflectance values for wet surfaces.</p><p>The generated partially synthetic point clouds with our snowfall and wet ground simulation are used as training data for optimizing state-of-the-art 3D object detection methods, so that the learned models are more robust under snowfall. The hope is that our physically based simulation is realistic enough to relieve us from the need for real snowy training samples. We benchmark the models trained in this regime on the challenging real snowy subset of the STF dataset <ref type="bibr" target="#b0">[1]</ref> and find that the models trained on our simulated snow consistently achieve significant performance gains over baseline models trained only on clear weather and competing simulation methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>Adverse weather research can be subdivided in meteorological publications providing fundamental knowledge for computer vision approaches <ref type="bibr" target="#b14">[15,</ref><ref type="bibr" target="#b32">32,</ref><ref type="bibr" target="#b33">33,</ref><ref type="bibr" target="#b38">38]</ref>, phenomenological reasoning of introduced disturbance patterns of different weather conditions <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b23">24]</ref> and the application of computer vision algorithms to such challenging conditions <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b48">48]</ref>. In <ref type="bibr" target="#b33">[33]</ref> a general theoretical framework predicting the influence of various weather types on LiDAR has been studied, including rain, fog and snow. The authors study these weather effects following the statistical distribution of the scattering particles, which are introduced e.g. for snow in <ref type="bibr" target="#b14">[15]</ref> and <ref type="bibr" target="#b38">[38]</ref>. Further implications on visibility in snowfall are presented in <ref type="bibr" target="#b32">[32]</ref>.</p><p>Those resulting disturbance patterns and their strength are phenomenologically investigated for rain in <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b52">52]</ref>, fog in <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b52">52]</ref>, snow in <ref type="bibr" target="#b18">[19,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b28">28]</ref> and wet surfaces in <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b44">44,</ref><ref type="bibr" target="#b56">56]</ref>. Algorithmically, authors have tried to tackle those conditions by robust fusion algorithms <ref type="bibr" target="#b0">[1]</ref>, developed simulation techniques as data augmentation for camera data in <ref type="bibr" target="#b36">[36,</ref><ref type="bibr" target="#b48">48]</ref> and LiDAR data in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b21">22]</ref>. Authors also investigated enhancement technologies to remove adverse weather effects in <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b43">43]</ref> or applied domain adaptation methods adjusting clear-weather algorithms to adverse weather in <ref type="bibr" target="#b37">[37]</ref>. Underlying deep learning data sets containing adverse weather samples were introduced in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b29">29,</ref><ref type="bibr" target="#b37">37,</ref><ref type="bibr" target="#b46">46</ref>]. Yet classical data loop approaches are difficult to apply as adverse weather samples are rare and well underrepresented <ref type="bibr" target="#b0">[1]</ref>.</p><p>Simulation of adverse weather allows to mitigate the rarity of adverse weather effects and difficulties in data collection campaigns as for example shown in <ref type="bibr" target="#b35">[35,</ref><ref type="bibr" target="#b36">36,</ref><ref type="bibr" target="#b48">48]</ref> through data synthesis. Additionally, it enables to generate reproducible conditions with clear ground truth necessary to learn image enhancement techniques in <ref type="bibr" target="#b16">[17,</ref><ref type="bibr" target="#b43">43]</ref> or to investigate adverse weather noise-dependent performance decrease reproducible for different weather effects in <ref type="bibr" target="#b48">[48]</ref>. LiDAR simulation methods were explicitly studied in <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b21">22]</ref>. Developments started in <ref type="bibr" target="#b0">[1]</ref> with a data driven approach in fog which was extended by <ref type="bibr" target="#b15">[16]</ref>, introducing a physically based model and achieving higher 3D object detection performances. A simulation method for rain is introduced in <ref type="bibr" target="#b13">[14]</ref> and a general approach for snow, rain and fog in <ref type="bibr" target="#b21">[22]</ref>. Contrary to <ref type="bibr" target="#b21">[22]</ref>, our snowfall simulation involves a continuous formulation in the power signal domain, which allows us to superimpose reflections by different particles and to reason about occlusions between particles and the target, thereby adhering better to the physics of the laser transmission. Additionally, we take into account the effects of wet roads, allowing us to estimate laser hardware parameters as noise floor and sent intensity from the dry road intensities in a data-driven way.</p><p>3D object detection has seen tremendous progress in recent years. Several methods have been presented for RGB camera <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b54">54,</ref><ref type="bibr" target="#b60">60]</ref>, LiDAR <ref type="bibr" target="#b24">[25,</ref><ref type="bibr" target="#b31">31,</ref><ref type="bibr" target="#b39">[39]</ref><ref type="bibr" target="#b40">[40]</ref><ref type="bibr" target="#b41">[41]</ref><ref type="bibr" target="#b42">[42]</ref><ref type="bibr" target="#b62">62]</ref>, gated imagers <ref type="bibr" target="#b19">[20]</ref> or the fusion of multiple modalities in <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b51">51]</ref>. Across many dataset leaderboards, however, the top performance positions are typically all sorted out among LiDAR based methods <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b46">46]</ref>. In our work, we utilize the methods PV-RCCN <ref type="bibr" target="#b39">[39]</ref>, VoxelRCNN-Car <ref type="bibr" target="#b8">[9]</ref>, CenterPoint <ref type="bibr" target="#b59">[59]</ref>, Part-A? <ref type="bibr" target="#b42">[42]</ref>, PointRCNN <ref type="bibr" target="#b41">[41]</ref>, SECOND <ref type="bibr" target="#b57">[57]</ref>, and Point-Pillars <ref type="bibr" target="#b24">[25]</ref>. The methods differ in point cloud representations, the used feature extraction backbones and the number of detection stages. As input modalities, point clouds are treated e.g. in voxel space <ref type="bibr" target="#b39">[39,</ref><ref type="bibr" target="#b40">40,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b57">57,</ref><ref type="bibr" target="#b62">62]</ref>, inferring the raw point clouds <ref type="bibr" target="#b31">[31,</ref><ref type="bibr" target="#b41">41]</ref> or using abstract representations such as pillars in <ref type="bibr" target="#b24">[25]</ref>. The number of detection stages is most often classified into single <ref type="bibr" target="#b24">[25]</ref> and two-stage approaches <ref type="bibr">[39-41, 57, 59, 62]</ref>, where single-stage approaches directly discretize the input space and predict objects for each individual cell following <ref type="bibr" target="#b25">[26]</ref>. Two-stage approaches first predict proposals and refine them in a subsequent pooled feature space following the general idea of <ref type="bibr" target="#b34">[34]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Snowfall Simulation on LiDAR Point Clouds</head><p>Pulse propagation in free space can be modeled with geometrical optics for cost-effective LiDAR systems. Such systems apply an array of synchronized near-field infrared pulse emitters Tx and avalanche photodiodes (APDs) as receivers Rx depicted in <ref type="figure" target="#fig_1">Fig. 2</ref> and described in <ref type="bibr" target="#b55">[55]</ref>. The sent-out laser pulse P 0 is reflected by a solid scene object, often referred to as target, with reflectivity ? 0 , and it is captured by the receiver, providing the time delay ? of the captured echo and its corresponding power P R . The object distance R is calculated by applying R = c? , where c is the speed of light. The 3D position [x, y, z] of the object is obtained by using the direction in which the pulse was emitted. For extended objects, geometric optics <ref type="bibr" target="#b10">[11]</ref> can be applied to model the received power P R following</p><formula xml:id="formula_0">PR(R) = CAP0?0 cos (?in) R 2 ,<label>(1)</label></formula><p>which holds for objects with a diameter larger than the beam diameter at distance R and requires additional information about (i) the incident angle ? in and (ii) the system constant C A independent of range and time. However, the received laser power is typically corrected <ref type="bibr" target="#b10">[11]</ref>, as C A differs for each scanning layer due to different optics and beam divergences. Four different levels of intensity calibration can be reported according to <ref type="bibr" target="#b20">[21]</ref>. For the Velodyne HDL-S3D sensor used in our experiments, a beam divergence correction is applied following the sensor manual [50]. This correction is defined as</p><formula xml:id="formula_1">i = PR + fs fo ? 1 ? R Rmax 2 ,<label>(2)</label></formula><p>where f s is the focal slope and f o is the focal offset. The parameters for each laser are retrieved from the factory side calibration. Before applying the proposed simulation methods, we first retrieve the raw intensities by inverting this intensity calibration. In snowfall, the optical medium contains particles which are smaller than the beam diameter, so Mie scattering and the exact spatial distribution of the particles must be taken into account <ref type="bibr" target="#b33">[33]</ref>.</p><p>Pulse propagation in the presence of scattering particles is described by a linear model introduced in <ref type="bibr" target="#b33">[33]</ref>, which is valid for non-elastic scattering. This model expresses the range-dependent received power P R as a time-wise convolution between the time-dependent transmitted signal power P T and the impulse response H of the optical system:</p><formula xml:id="formula_2">PR(R) = CA 2R/c 0 PT (t) H R ? ct 2 dt,<label>(3)</label></formula><p>with the time signature of the transmitted pulse given by</p><formula xml:id="formula_3">PT (t) = P0 sin 2 ? 2 ? H t , 0 ? t ? 2 ?H , 0 otherwise.<label>(4)</label></formula><p>? H is the half-power pulse width, set to 10 ns for the Velodyne HDL-S3D sensor. The impulse response H can be factored into the impulse responses of the optical channel, H C , and the target, H T :</p><formula xml:id="formula_4">H(R) = H C (R) H T (R).<label>(5)</label></formula><p>H C depends on the beam divergence, the overlap of transmitter and receiver described by ?(R) as well as the transmittance T (R) of the medium through</p><formula xml:id="formula_5">H C (R) = T 2 (R) R 2 ?(R).<label>(6)</label></formula><p>The transmittance T (R) is equal to 1 in the part of the medium that is not occupied by snow particles, assuming absence of other scatterers. The overlap ?(R) can be geometrically derived from <ref type="figure" target="#fig_1">Fig. 2</ref> as</p><formula xml:id="formula_6">?(R) = ? ? ? 0, R ? R1 R?R 1 R 2 ?R 1 , R1 &lt; R &lt; R2 1, R2 ? R.<label>(7)</label></formula><p>The impulse response of the target, H T , allows us to model snow particles as we detail in the following. Scene reflection defines the particle interaction with the laser pulse through H T . For an extended solid target object we can write</p><formula xml:id="formula_7">HT (R) = ?0? (R ? R0) ,<label>(8)</label></formula><p>with ? 0 being the reflectivity of the object and ? the Dirac delta function. However, in snowfall, apart from the solid target object, the laser beam is also partially reflected by snow particles.  We model snow particle j as a spherical object with reflectivity ? s , diameter D j following the distribution introduced in <ref type="bibr" target="#b14">[15]</ref> and distance R j from the sensor, placed uniformly at random around the sensor so that it does not intersect with any other particle. The number of particles is chosen according to the snowfall rate, typically ranging in 0-2.5 mm/h (see supplementary materials for more details). Particles can occlude each other and the target object, as illustrated in <ref type="figure" target="#fig_3">Fig. 4 (top)</ref>. Thus, each particle j reflects only a fraction ? j /? of the opening angle ? of the beam, also letting a fraction ? 0 /? of the beam reach the target. Details on calculating the ratios ? j /? are given in the supplementary materials as well.</p><p>Assuming D j ? c? H for all j, we can write</p><formula xml:id="formula_8">HT (R) = 1 ? ?0 ?0?(R ? R0) + ?s n j=1 ?j?(R ? Rj) ,<label>(9)</label></formula><p>with ? = ? 0 + n j=1 ? j . Plugging (4), (5), <ref type="bibr" target="#b5">(6)</ref> and <ref type="formula" target="#formula_8">(9)</ref> into (3), the received power in snowfall is</p><formula xml:id="formula_9">PR,snow(R) = P 0 R,snow (R) + n j=1 P j R,snow (R),<label>(10)</label></formula><p>where P j R,snow (R)</p><formula xml:id="formula_10">= C A P0?s?j ?(Rj ) ?Rj 2 2? H 0 sin 2 ? 2? H t ?(R ? ct 2 ? R0)dt = C A P 0 ?s ? j ?(R j ) ?R j 2 sin 2 ?(R?R j ) c? H , Rj ? R ? Rj + c? H 0 otherwise.<label>(11)</label></formula><p>P 0 R,snow (R) can be derived by substituting (? j , R j , ? s ) with (? 0 , R 0 , ? 0 ) on the right-hand side of <ref type="bibr" target="#b10">(11)</ref>.</p><p>The received power is thus a superposition of multiple echoes, each associated with an object (snow particle or target object), as depicted in <ref type="figure" target="#fig_3">Fig. 4 (bottom)</ref>. Crucially, the magnitude of each echo depends on the angle ? j and the inverse square of the distance R j of the respective object from the sensor. In this work, we retrieve the maximum peak of the received power as the LiDAR return. Thus, if a peak owing to snow particles is higher than the peak associated to the target object, the true echo is missed and a cluttered point is added to the simulated point cloud at the range of the former peak. s ? SAMPLE SNOWFLAKES(Rmax, rs) ? in 2D <ref type="bibr" target="#b14">[15]</ref> 7:</p><p>for p in pc l do ? for each point in layer l 8:</p><p>x, y, z, i ? p 9:</p><p>R0 ? ?p? if R = R0 then ? original target 15: Otherwise the target object intensity is attenuated according to its occlusion percentage. Our complete snowfall simulation is presented in Algorithm 1. In <ref type="figure" target="#fig_2">Fig. 3</ref> we show a winterly example scene, once augmented with our snowfall simulation and once with the one proposed in LISA <ref type="bibr" target="#b21">[22]</ref>.  from wet ground leading to significantly attenuated laser echoes depending on the water height <ref type="bibr" target="#b4">[5]</ref>. Analysing the road wetness statistics of STF <ref type="bibr" target="#b0">[1]</ref> (given in the supplementary materials), it becomes apparent that wet roads occur together with adverse weather such as snowfall and are the main cause for lost points on road surfaces (see <ref type="figure">Fig. 5</ref>).</p><formula xml:id="formula_11">PR ? i ? fs fo ? 1 ? R Rmax 2 16: CAP0 ? P R ? 0 R0 2 ?</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Wet Ground Model</head><p>To model the attenuation caused by road wetness, we apply geometric optics modeling single rays and their refraction on a thin layer of water illustrated in <ref type="figure" target="#fig_7">Fig. 6</ref>. A qualitative example is shown in <ref type="figure">Fig. 5 (bottom)</ref>. We use the refractive indices (n in , n out ) and angles (? in , ? out ) at the transition point. The angle ? out can be calculated based on Snell's law:</p><formula xml:id="formula_12">sin (?out) = n in nout sin (? in ) .<label>(12)</label></formula><p>The change in pulse amplitude is modeled by the Fresnel equations described by the perpendicular and parallel transmissions t ? , t = and reflections r ? , r = with respect to the ground, respectively (details in the supplementary materials). Going from amplitude to transmitted power, we can deduce the power reflection R p k and transmission T p k :</p><formula xml:id="formula_13">R p k = (r p k ) 2 ,<label>(13)</label></formula><formula xml:id="formula_14">T p k = n in cos (? in ) n out cos (? out ) (t p k ) 2 ,<label>(14)</label></formula><p>where p ? (?, =) refers to the polarization. We sum up all individual light rays which traverse back to the sensor, as shown in <ref type="figure" target="#fig_7">Fig. 6</ref>, leading to the geometric series</p><formula xml:id="formula_15">T p total = T p air ?0T p water ? k=0 (?0R p water ) k ,<label>(15)</label></formula><p>which can be simplified for (? 0 R water ) &lt; 1 to</p><formula xml:id="formula_16">T p total = T p air ?0T p water /(1 ? ?0R p water ).<label>(16)</label></formula><p>As the actual polarization is proprietary, we assume that the manufacturer optimized the polarization depending on the distance for best possible performance, implying</p><formula xml:id="formula_17">T total = max T = total , T ? total .<label>(17)</label></formula><p>Algorithm 2 LiDAR wet ground simulation <ref type="bibr">1:</ref> procedure WET GROUND(p, i, w, h, ?g, dw, dp, PT , in) <ref type="bibr">2:</ref> if |p ? w ? h| &lt; ?g then 3:</p><p>R0 ? ?p?2 <ref type="bibr">4:</ref> ?in ? arccos <ref type="formula" target="#formula_0">18)</ref> 6: ? = min (max (dw/dp, 0) , 1) ? see Eq. <ref type="bibr" target="#b18">(19)</ref> 7:</p><formula xml:id="formula_18">p?w R 0 ?w? 2 5: ?0 ? i cos(? in )P (R 0 ) ? see Eq. (</formula><p>?w ? (1 ? ?) ? ?0 + ? ? Ttotal/ cos (?in) ? see Eq. <ref type="bibr" target="#b19">(20)</ref> 8:</p><p>i ? ?w cos (?in) PT (R0) <ref type="bibr">9:</ref> if i &gt; in (R0) then Based on this formulation, we design Algorithm 2. A pre-processing step involves estimation of the ground plane normal w and intercept h with RANSAC <ref type="bibr" target="#b11">[12]</ref> as detailed in the supplementary materials. These parameters allow to identify all points belonging to the ground as well as the beam incident angle ? in . Then the modified intensity can be reconstructed from the measured "dry" intensity, taking into account that the beam divergence ? has been corrected by a factory side calibration leading to i ? ? 0 P T (R) cos (? in ). Normalizing i with the incident angle i(R)/ cos (? in ) returns a linear correspondence between the measured intensities i and the range R, such that we can approximate the power P T (R) and noise floor i n (R) linearly from the known given echoes. Then we can obtain the reflectivity ? 0 for each point p:</p><formula xml:id="formula_19">?0 = i/ (cos (?in) P (R0)) .<label>(18)</label></formula><p>These corrected reflectivities are augmented by weighing dry and wet reflections, assuming a road thread profile of depth d p filled with water of depth d w , which yields</p><formula xml:id="formula_20">? (d w , d p ) = min (max (d w /d p , 0) , 1) ,<label>(19)</label></formula><formula xml:id="formula_21">? w (?) = (1 ? ?) ? ? + ? ? T total / cos (? in ) . (20)</formula><p>Finally, the measured intensity i is updated based on the modified reflectivity ? w and the resulting point p is only kept if its intensity i is greater than the noise floor i n .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Dataset. Our experiments are carried out on the STF dataset <ref type="bibr" target="#b0">[1]</ref>. It provides 12997 annotated samples with accurate 3D bounding boxes for object detection of cars, pedestrians, and cyclists in various weather conditions including light fog, dense fog and snow. Without denying the importance of the pedestrian and cyclist classes, in the main paper, we focus on the most dominant class, i.e. cars. In the supplementary materials we provide additional results. In total, 3469 frames in clear conditions can be used for training and 3916 frames in snowy conditions are provided. We split the 3916 samples in the snow test set based on the intensity of snowfall into two different subsets, termed light snowfall and heavy snowfall, with 2512 and 1404 samples respectively. Inspired by <ref type="bibr" target="#b29">[29]</ref>, we perform this split by leveraging the DROR algorithm <ref type="bibr" target="#b5">[6]</ref>. The light snowfall split contains frames where DROR <ref type="bibr" target="#b5">[6]</ref> would filter 10-79 points from a 10?2?2m box in front of the ego vehicle, while the heavy snowfall contains at least 80 of such points within this box (further details in the supplementary materials). Evaluation setting. For evaluation, we use the 3D object detection metrics defined in the KITTI evaluation framework <ref type="bibr" target="#b12">[13]</ref> and in <ref type="bibr" target="#b58">[58]</ref>. Specifically, <ref type="bibr" target="#b58">[58]</ref> introduces an extension to the KITTI metrics by reporting the results with respect to the object distance. Since the weather effects detailed in Sec. 3 are distance-dependent, we opt for following their extension and report results in the intervals as in <ref type="bibr" target="#b19">[20]</ref>. Additionally, we follow <ref type="bibr" target="#b45">[45]</ref> and report average precision (AP) at 40 recall positions to provide a fair comparison. Other than that we use the typical overlap thresholds defined in <ref type="bibr" target="#b12">[13]</ref>. To mitigate potential statistical fluctuations, we report for each experiment the average performance over three independent training runs. Baseline methods. In total, we investigate the effectiveness of our snowfall simulation scheme for seven well-known 3D object detection methods <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b39">39,</ref><ref type="bibr" target="#b41">41,</ref><ref type="bibr" target="#b42">42,</ref><ref type="bibr" target="#b57">57,</ref><ref type="bibr" target="#b59">59]</ref>. We compare our approach to a clear-weather baseline and two competing adverse weather simulation methods, one for fog <ref type="bibr" target="#b15">[16]</ref> and one for snowfall <ref type="bibr" target="#b21">[22]</ref>. Additionally, we compare to denoising the point clouds using DROR <ref type="bibr" target="#b5">[6]</ref>. To train the detection models, we use OpenPCDet <ref type="bibr" target="#b47">[47]</ref> and follow the default training configurations for each method. All methods are trained from scratch. Data augmentation. We choose to apply our simulation(s) to every 10-th training sample, for which the snowfall rate is sampled from [0, 0.5, ..., 2.5]mm/h, and set the sensor constants ? H = 10 ns, R max = 120 m, ? = 0.003 rad, ? s = 0.9 and ? 0 = 1?10 ?6 ? . The exact same settings are used for <ref type="bibr" target="#b21">[22]</ref>. For the wet ground simulation we use an exponential distribution and sample d w from the interval 0.1-1.2 mm, while fixing d p to 1.2 mm and setting ? g to 0.5m.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Quantitative Results</head><p>We present the quantitative results in <ref type="table">Table 1</ref>. In reading <ref type="table">Table 1</ref>, the reader should first focus on the columns showing AP across the entire evaluation range of 0-80 m. The main experimental finding from <ref type="table">Table 1</ref> is that our full simulation including both the snowfall and the wet ground  <ref type="table">Table 1</ref>. Comparison of simulation methods for 3D object detection in snowfall on STF <ref type="bibr" target="#b0">[1]</ref>. We report 3D average precision (AP) of moderate cars on three STF splits: the heavy snowfall test split with 1404 samples, the light snowfall test split with 2512 samples and the clear-weather test split with 1816 samples. "Ours-wet": our wet ground simulation, "Ours-snow": our snowfall simulation, "Ours-snow+wet": cascaded application of our snowfall and wet ground simulation. model (Ours-snow+wet) consistently improves the performance on the most challenging test case, i.e. heavy snowfall, for all methods by a significant margin compared to both the baseline approach as well as all competing simulation <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b21">22]</ref> and denoising <ref type="bibr" target="#b5">[6]</ref> methods. This improvement on heavy snowfall is particularly pronounced for the best-performing detection method, i.e. PV-RCNN <ref type="bibr" target="#b39">[39]</ref>, for which our full simulation beats the clear-weather baseline by a notable 2.1% in AP.</p><p>For PV-RCNN <ref type="bibr" target="#b39">[39]</ref>, CenterPoint <ref type="bibr" target="#b59">[59]</ref> and Part-A? <ref type="bibr" target="#b42">[42]</ref>, our full simulation also delivers the best performance among all methods on light snowfall, showing that the benefit of our simulation extends to all snowfall intensities. Moreover, on the clear-weather test split, our snowfall simulation without wet ground modeling demonstrates the best performance among all competing approaches for six out of the seven detection methods, consistently improving upon the clear-weather baseline. This finding shows that using <ref type="bibr">Figure 7</ref>. Qualitative comparison of PV-RCNN <ref type="bibr" target="#b39">[39]</ref> on samples from STF <ref type="bibr" target="#b0">[1]</ref> containing heavy snowfall. The leftmost column shows the corresponding RGB images. The rest of the columns show the LiDAR point clouds with ground-truth boxes and predictions using the clear-weather baseline ("no augmentation"), DROR <ref type="bibr" target="#b5">[6]</ref>, LISA <ref type="bibr" target="#b21">[22]</ref>, and our fully-fledged simulation ("our snow+wet augmentation"). our snowfall simulation for training increases detection performance on severe snowy conditions, while not sacrificing but rather improving performance on clear weather as well.</p><p>Using simulation methods designed for different adverse conditions, such as the fog simulation in <ref type="bibr" target="#b15">[16]</ref>, does not transfer well to snowfall as the respective physical models differ; performance of <ref type="bibr" target="#b15">[16]</ref> is slightly lower than the clearweather baseline on both snowfall splits for most detection methods. The application of DROR <ref type="bibr" target="#b5">[6]</ref> as an enhancement step removing clutter points achieves among the lowest results, because it also removes several valid points, which do not belong to the snowfall clutter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Qualitative Results</head><p>Qualitative results showing the proposed data augmentation scheme are presented in <ref type="figure">Fig. 7</ref>. Here, PV-RCNN <ref type="bibr" target="#b39">[39]</ref> is compared to the clear-weather baseline with no augmentation, DROR <ref type="bibr" target="#b5">[6]</ref> and LISA <ref type="bibr" target="#b21">[22]</ref>. In the first row, we see that the pedestrian inside the snowfall clutter can only be detected when our proposed data augmentation is applied during training. In the second row, additional false positives appear for all competing approaches. The bottom row shows a difficult highway scene with whirled-up snow dust. Our data augmentation approach generalizes well to this example, being the only method that detects the lead vehicle. Note also that in such a scenario with whirled-up snow dust, DROR <ref type="bibr" target="#b5">[6]</ref> cannot remove the clutter completely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>In this work, we have introduced a novel method for realistic synthesis of winter scenes from clear LiDAR captures modeling snowfall and wet surfaces in a physically accurate way. Further, we have proven the effectiveness of the proposed algorithm, testing the augmentation with seven different 3D object detection methods and achieving consistent improvements of up to 2.1% in AP in heavy snowfall. As future work, we envision the exploration of temporal cues for robust LiDAR-based 3D object detection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>3D object detection results in heavy snowfall with prior training on the proposed data augmentation scheme (top right) in comparison to no augmentation (top left). The bottom row shows the RGB image as reference.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Sketch of a LiDAR sensor where the transmitter Tx and the receiver Rx do not have coaxial optics, but have parallel axes (called a bistatic beam configuration).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Simulated snowfall corresponding to a snowfall rate of rs = 2.5 mm/h. The left block shows the clear undisturbed input. The right block shows our snowfall simulation (top) and the snowfall simulation in LISA<ref type="bibr" target="#b21">[22]</ref> (bottom). Note that we simulate the scattering realistically and only attenuate points which are affected by individual snowflakes instead of attenuating all points based on their distance.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Snow particles interfering a single LiDAR beam (top). Schematic plot of corresponding received power echoes (bottom). Note how the received power of individual targets can overlap with each other (c?H ? 3 m with ?H = 10 ns).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .Algorithm 1 2 : 3 : 2 ?</head><label>51232</label><figDesc>A real-world capture on a dry highway (top), a realworld capture with a water height of dw = 0.53 mm (middle) and the synthesized road wetness from the clear reference (bottom). LiDAR snowfall simulation 1: procedure SNOWFALL(pc, n l , ?H , Rmax, ?, rs, ?s, ?0) for l in n l do ? for each layer l pc l ? pc.SELECT(layer = l) 4: f d , fs, imax ? LOAD CALIB(l) 5: fo ? ( 1?f d 13100 ) focal offset [50]6:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>PR,snow ? 0 ? initialize with zeros 13 :</head><label>013</label><figDesc>? GET PARTICLES IN BEAM(s, x, y, R0, ?) ? in 2D 11:if len(t t t) &gt; 1 then ? otherwise no interference12:    for i, R, ? in t t t do ? for each target 14:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>LiDAR readings are affected by the wetness of surrounding surfaces. Emitted light pulses are reflected specularly</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Visualization showing the geometrical optical model which describes the reflection on a wet road surface.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>None 39.69 65.05 36.14 8.03 41.13 69.24 39.72 11.68 45.36 72.34 42.48 10.53 Fog [16] 38.19 64.72 33.38 7.49 39.82 68.41 38.68 9.65 43.37 71.05 40.03 9.90 DROR [6] 38.57 64.27 35.40 8.07 39.33 66.73 38.14 10.51 41.44 67.76 38.48 9.44 PV-RCNN [39] LISA [22] 39.21 64.21 35.34 8.64 41.60 69.15 41.08 11.15 45.30 71.06 42.86 11.45 Ours-wet 40.03 65.34 35.82 9.31 41.07 68.49 40.03 11.02 44.81 71.60 42.71 10.63 Ours-snow 41.61 67.44 37.47 8.84 41.20 68.79 40.20 11.13 45.61 72.14 43.40 11.21 Ours-snow+wet 41.79 68.39 37.14 8.85 41.79 70.30 41.01 11.28 45.71 71.88 43.31 11.69 None 39.47 65.14 36.29 6.83 41.25 69.12 39.86 11.81 45.19 72.33 43.20 10.69 Fog [16] 40.06 65.58 36.78 7.33 41.10 68.93 39.25 10.98 44.46 71.67 41.78 10.</figDesc><table><row><cell>Detection</cell><cell>Simulation</cell><cell></cell><cell cols="2">heavy snowfall ?</cell><cell></cell><cell></cell><cell cols="2">light snowfall ?</cell><cell></cell><cell></cell><cell cols="2">clear weather ?</cell><cell></cell></row><row><cell>method</cell><cell>method</cell><cell>0-80m</cell><cell>0-30m</cell><cell>30-50m</cell><cell>50-80m</cell><cell>0-80m</cell><cell>0-30m</cell><cell>30-50m</cell><cell>50-80m</cell><cell>0-80m</cell><cell>0-30m</cell><cell>30-50m</cell><cell>50-80m</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>84</cell></row><row><cell></cell><cell>DROR [6]</cell><cell cols="3">38.16 64.97 33.23</cell><cell cols="4">6.83 38.48 66.93 35.68</cell><cell cols="4">9.97 40.65 67.94 36.85</cell><cell>8.45</cell></row><row><cell cols="2">VoxelRCNN-Car [9] LISA [22]</cell><cell cols="3">39.06 66.61 33.56</cell><cell cols="9">6.93 40.68 68.80 38.78 10.75 45.03 72.05 41.96 10.59</cell></row><row><cell>(single class method)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Acknowledgements. This work is funded by Toyota Motor Europe via the research project TRACE-Z?rich. The work also received funding by the AI-SEE project with national funding from the Austrian Research Promotion Agency (FFG), Business Finland, Federal Ministry of Education and Research (BMBF) and National Research Council of Canada Industrial Research Assistance Program (NRC-IRAP). We also thank the Federal Ministry for Economic Affairs and Energy for support within "VVM-Verification and Validation Methods for Automated Vehicles Level 4 and 5", a PEGASUS family project. Felix Heide was supported by an NSF CAREER Award (2047359), a Sony Young Faculty Award, and a Project X Innovation Award. We thank Emmanouil Sakaridis for verifying our derivation of occlusion angles in our snowfall simulation.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Seeing through fog without seeing fog: Deep multimodal sensor fusion in unseen adverse weather</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Bijelic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahim</forename><surname>Mannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Dietmayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Heide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A benchmark for LiDAR sensors in fog: Is detection breaking down?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Bijelic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Ritter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">nuScenes: A multimodal dataset for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varun</forename><surname>Bankiti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourabh</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Venice</forename><forename type="middle">Erin</forename><surname>Liong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anush</forename><surname>Krishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Giancarlo</forename><surname>Baldan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Beijbom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">LIBRE: The multiple 3D LiDAR dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Carballo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abraham</forename><forename type="middle">Monrroy</forename><surname>Cano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">Robert</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patiphon</forename><surname>Narksri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuki</forename><surname>Kitsukawa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eijiro</forename><surname>Takeuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shinpei</forename><surname>Kato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Takeda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Angular spectral response from covered asphalt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Johan</forename><surname>Casselgren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mikael</forename><surname>Sj?dahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Leblanc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Optics</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">De-noising of LiDAR point clouds corrupted by snowfall</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Charron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Waslander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Computer and Robot Vision (CRV)</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Multi-view 3D object detection network for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaozhi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huimin</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tian</forename><surname>Xia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Road safety in the European Union</title>
		<idno type="DOI">10.2832/169706</idno>
		<idno>2018. Ac- cessed: 15</idno>
		<ptr target="https://doi.org/10.2832/169706" />
		<imprint>
			<date type="published" when="2021-11" />
		</imprint>
	</monogr>
	<note>European Commission</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Voxel R-CNN: Towards high performance voxel-based 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peiwei</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wengang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanyong</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houqiang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Motion-based detection and tracking in 3D LiDAR scans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ayush</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tim</forename><surname>Caselitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gian</forename><forename type="middle">Diego</forename><surname>Tipaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wolfram</forename><surname>Burgard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Combination of overlap-driven adjustment and phong model for LiDAR intensity correction. Photogrammetry and Remote Sensing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiong</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bruce</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yanxiong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guoxiang</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="40" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Fischler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Bolles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="381" to="395" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Are we ready for autonomous driving? the KITTI vision benchmark suite</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andreas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Lenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Predicting the influence of rain on LiDAR in ADAS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Goodin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Carruth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Doude</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Hudson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The distribution with size of aggregate snowflakes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Gunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Marshall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmospheric Sciences</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="1958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Fog simulation on real LiDAR point clouds for 3D object detection in adverse weather</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Hahner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Philipp Schindler, and Wilhelm Stork. CNN-based LiDAR point cloud de-noising in adverse weather</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Heinzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Florian</forename><surname>Piewak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="issue">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Weather influence and classification with automotive LiDAR sensors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robin</forename><surname>Heinzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Schindler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J?rgen</forename><surname>Seekircher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilhelm</forename><surname>Stork</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Testing and validation of automotive point-cloud sensors in adverse weather conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Jokela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Kutila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasi</forename><surname>Pyyk?nen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Gated3D: Monocular 3D object detection from temporal illumination cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Frank</forename><surname>Julca-Aguilar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Bijelic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahim</forename><surname>Mannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Heide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A review of LiDAR radiometric processing: From ad hoc intensity correction to rigorous radiometric calibration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alireza</forename><surname>Kashani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Olsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Parrish</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas</forename><surname>Wilson</surname></persName>
		</author>
		<idno>2015. 3</idno>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">LiDAR light scattering augmentation (LISA): physics-based simulation of adverse weather conditions for 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Velat</forename><surname>Kilic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deepti</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishwanath</forename><surname>Sindagi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vishal</forename><surname>Patel</surname></persName>
		</author>
		<idno>2107.07004</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Joint 3D proposal generation and object detection from view aggregation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Melissa</forename><surname>Mozifian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungwook</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename><surname>Harakeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Waslander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Benchmarking automotive LiDAR performance in arctic conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matti</forename><surname>Kutila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pasi</forename><surname>Pyyk?nen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maria</forename><surname>Jokela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tobias</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Bijelic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Ritter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Intelligent Transportation Systems (ITSC)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">PointPillars: Fast encoders for object detection from point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourabh</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Holger</forename><surname>Caesar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lubing</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Beijbom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<imprint>
			<pubPlace>Scott Reed; Alexander C</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Single shot multibox detector</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Berg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ssd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">L3-Net: Towards learning based LiDAR localization for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weixin</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guowei</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shenhua</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Towards characterizing the behavior of LiDARs in snowy conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sebastien</forename><surname>Michaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Fran?ois</forename><surname>Lalonde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Gigu?re</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Planning, Perception and Navigation for Intelligent Vehicles, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Canadian adverse driving conditions dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Pitropov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danson</forename><forename type="middle">Evan</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Rebello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Smart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krzysztof</forename><surname>Czarnecki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Waslander</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Frustum PointNets for 3D object detection from RGB-D data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenxia</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">PointNet: Deep learning on point sets for 3D classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaichun</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leonidas</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The estimation of snowfall rate using visibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roy</forename><surname>Rasmussen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jothiram</forename><surname>Vivekanandan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Barry</forename><surname>Myers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Masters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Meteorology</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1542" to="1563" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Influences of weather phenomena on automotive laser radar systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Rasshofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Spies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hans</forename><surname>Spies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Radio Science</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">3</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Faster R-CNN: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural Information Processing Systems (NeurIPS)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Model adaptation with synthetic and real data for semantic dense foggy scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Hecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Semantic foggy scene understanding with synthetic data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="973" to="992" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">ACDC: The Adverse Conditions Dataset with Correspondences for semantic driving scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christos</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dengxin</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<biblScope unit="volume">2021</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Snow size spectra and radar reflectivity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sekhon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Srivastava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Atmospheric Sciences</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="299" to="307" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">PV-RCNN: Point-voxel feature set abstraction for 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoxu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">PV-RCNN++: point-voxel feature set abstraction with local vector representation for 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiajun</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chaoxu</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
		<idno>2102.00463</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">PointR-CNN: 3D object proposal generation and detection from point cloud</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">From points to parts: 3D object detection from point cloud with part-aware and part-aggregation network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoshuai</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhe</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianping</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaogang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hongsheng</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Zeroscatter: Domain transfer for long distance imaging and vision through scattering media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Tseng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Bijelic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Werner</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Felix</forename><surname>Heide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Characteristics of laser backscattering intensity to detect frozen and wet surfaces on roads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jungil</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hyunsuk</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taejung</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Disentangling monocular 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Simonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Samuel</forename><forename type="middle">Rota</forename><surname>Bulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lorenzo</forename><surname>Porzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manuel</forename><surname>Lopez-Antequera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Kontschieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Jonathon Shlens, Zhifeng Chen, and Dragomir Anguelov. Scalability in perception for autonomous driving: Waymo open dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pei</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Kretzschmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xerxes</forename><surname>Dotiwalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aurelien</forename><surname>Chouard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijaysai</forename><surname>Patnaik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Tsui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuning</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><surname>Caine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiquan</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hang</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksei</forename><surname>Timofeev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxim</forename><surname>Krivokon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amy</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">OpenPCDet: An opensource toolbox for 3D object detection from point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Openpcdet</forename><surname>Development Team</surname></persName>
		</author>
		<ptr target="https://github.com/open-mmlab/OpenPCDet,2020" />
		<imprint>
			<date type="published" when="2021-11-15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Rain rendering for evaluating and improving robustness to bad weather</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maxime</forename><surname>Tremblay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shirsendu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raoul</forename><surname>Halder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jean-Fran?ois</forename><surname>De Charette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lalonde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Department of Transportation: Federal Highway Administration. How do weather events impact roads?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">S</forename></persName>
		</author>
		<ptr target="https://ops.fhwa.dot.gov/weather/q1_roadimpact.htm" />
		<imprint>
			<date type="published" when="2019-11" />
			<biblScope unit="page">15</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Hdl-64e user&apos;s manual</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Velodyne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">PointPainting: Sequential fusion for 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sourabh</forename><surname>Vora</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alex</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bassam</forename><surname>Helou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oscar</forename><surname>Beijbom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Full waveform LiDAR for adverse weather conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Wallace</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abderrahim</forename><surname>Halimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerald</forename><surname>Buller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Vehicular Technology</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">MEMS mirrors for LiDAR: A review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dingkang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connor</forename><surname>Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huikai</forename><surname>Xie</surname></persName>
		</author>
		<idno>2020. 1</idno>
		<imprint>
			<publisher>Micromachines</publisher>
			<biblScope unit="volume">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Bharath Hariharan, Mark Campbell, and Kilian Weinberger. Pseudo-LiDAR from visual depth estimation: Bridging the gap in 3D object detection for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divyansh</forename><surname>Garg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Optimization of eyesafe avalanche photodiode LiDAR for automobile safety and autonomous navigation systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">George</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Comparison of 905 nm and 1550 nm semiconductor laser rangefinders&apos; performance deterioration due to adverse environmental conditions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacek</forename><surname>Wojtanowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marek</forename><surname>Zygmunt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miros?awa</forename><surname>Kaszczuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zygmunt</forename><surname>Mierczyk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?</forename><surname>Muzal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Opto-Electronics Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">SECOND: Sparsely embedded convolutional detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxing</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sensors</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Pixor: Realtime 3D object detection from point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjie</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raquel</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Centerbased 3D object detection and tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianwei</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xingyi</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Krahenbuhl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Pseudo-LiDAR++: Accurate depth for 3D object detection in autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yurong</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Divyansh</forename><surname>Garg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoff</forename><surname>Pleiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bharath</forename><surname>Hariharan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kilian Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">LOAM : LiDAR odometry and mapping in real-time</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ji</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjiv</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems Conference (RSS)</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">VoxelNet: End-to-end learning for point cloud based 3D object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oncel</forename><surname>Tuzel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
