<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">STMTrack: Template-free Visual Tracking with Space-time Memory Networks</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihong</forename><surname>Fu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qingjie</forename><surname>Liu</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zehua</forename><surname>Fu</surname></persName>
							<email>zehuafu@163.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yunhong</forename><surname>Wang</surname></persName>
							<email>yhwang@buaa.edu.cn</email>
						</author>
						<title level="a" type="main">STMTrack: Template-free Visual Tracking with Space-time Memory Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T10:36+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Boosting performance of the offline trained siamese trackers is getting harder nowadays since the fixed information of the template cropped from the first frame has been almost thoroughly mined, but they are poorly capable of resisting target appearance changes. Existing trackers with template updating mechanisms rely on time-consuming numerical optimization and complex hand-designed strategies to achieve competitive performance, hindering them from real-time tracking and practical applications. In this paper, we propose a novel tracking framework built on top of a space-time memory network that is competent to make full use of historical information related to the target for better adapting to appearance variations during tracking. Specifically, a novel memory mechanism is introduced, which stores the historical information of the target to guide the tracker to focus on the most informative regions in the current frame. Furthermore, the pixel-level similarity computation of the memory network enables our tracker to generate much more accurate bounding boxes of the target. Extensive experiments and comparisons with many competitive trackers on challenging large-scale benchmarks, OTB-2015, TrackingNet, GOT-10k, LaSOT, UAV123, and VOT2018, show that, without bells and whistles, our tracker outperforms all previous state-of-the-art real-time methods while running at 37 FPS. The code is available at https: //github.com/fzh0917/STMTrack.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Visual object tracking is an essential task in computer vision with applications in various fields such as humancomputer interactions <ref type="bibr" target="#b28">[29]</ref>, video surveillance <ref type="bibr" target="#b53">[54]</ref>, and autonomous driving <ref type="bibr" target="#b21">[22]</ref>. Significant efforts have been devoted to address this problem, yet there is still a great gap to the practical applications due to the challenging factors such as occlusions, fast motions, and non-rigid deformations <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b52">53,</ref><ref type="bibr" target="#b19">20]</ref>, which urge us to develop trackers with strong adaptiveness and robustness. <ref type="bibr">*</ref>   <ref type="figure">Figure 1</ref>: Visualized comparisons of our method with representative trackers SiamFC++ <ref type="bibr" target="#b55">[56]</ref> and DiMP-50 <ref type="bibr" target="#b1">[2]</ref>. Our method can estimate more accurate target state when targets suffer from partial occlusions and non-rigid deformations.</p><p>The goal of visual tracking is to locate an object in the subsequent frames of a video given its initial annotation in the first frame. In recent years, with the advancements of deep learning techniques, deep trackers have dominated the tracking field, among which two methodologies are widely studied, and one popular methodology addresses object tracking as a similarity matching problem between the target template and the search frames in an embedding space offline trained. The representative template-matching methods are siamese trackers <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b14">15]</ref>. These methods usually do not update the template and thus are hard to adapt to appearance changes caused by occlusions, non-rigid deformations, etc.</p><p>To solve this problem, some trackers <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b10">11]</ref> are equipped with sophisticated template updating mechanisms and thus show stronger robustness than siamese trackers. However, online template updating requires much more computational resources, which impends trackers from real-time tracking. Furthermore, these customized updating strategies <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b57">58,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b58">59,</ref><ref type="bibr" target="#b6">7]</ref> introduce hyper-parameters that require tricky tuning.</p><p>Note that when tracking moving objects humans remember their identities in visual working memory to maintain temporal continuity in a constantly changing environment <ref type="bibr" target="#b32">[33]</ref>. This inspires us to develop a memory-based tracking model to take advantage of rich historical information of the object. In contrast to previous works that strive to design template updating mechanisms to capture appearance variations of the object, our model predicts the state of the object from its historical information stored in the memory network, thus avoiding of using the template and updating it. Thus we call our model a template-free method. Furthermore, our tracker computes pixel-level similarities to locate the target, making it more robust to partial occlusions and non-rigid deformations than those using featuremap-level cross correlation. <ref type="figure">Fig. 1</ref> depicts this advantage of our tracker (Refer to the section 1.1 of the supplemental material for quantitative comparisons).</p><p>The proposed method is evaluated on six benchmarks: OTB-2015, TrackingNet, LaSOT, GOT-10k, UAV123, and VOT2018 and surpasses all state-of-the-art real-time approaches while running at 37 FPS. Notably, it achieves 80.3 success (AUC) on the challenging TrackingNet dataset, outperforming the previous best real-time method by 4.5%. It also sets new state-of-the-art performance on the performance-saturated OTB-2015 dataset.</p><p>Summarily, the main contributions of this work are fourfold.</p><p>? We propose a novel end-to-end memory-based tracking framework, which not only is as simple and efficient as the offline trained siamese networks, but also has strong adaptiveness ability as the sophisticated template updating strategies. ? The proposed tracking framework deviates from the original evolving path of template-based tracking, and it could inspire more space-time-memory-based trackers to be developed in the future. ? A novel memory mechanism based on pixel-level similarity computation is introduced for visual tracking, which enables our tracker to have stronger robustness and to generate much more accurate target bounding boxes than many previous high-performance methods that use feature-map-level cross correlation. ? Our proposed tracker outperforms all state-of-the-art real-time approaches on OTB-2015, TrackingNet, La-SOT, and GOT-10k, while running in real-time at 37 FPS, which demonstrates the superiority of the framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Siamese Trackers</head><p>Siamese networks <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b59">60,</ref><ref type="bibr" target="#b7">8]</ref> have attracted significant attention in recent years and been very popular in the tracking community <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b64">65,</ref><ref type="bibr" target="#b60">61,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b55">56,</ref><ref type="bibr" target="#b14">15]</ref> . Siamese trackers treat the visual object tracking task as a matching problem. During inference, a template is cropped from the first frame and matched to the search regions in the current frame to achieve tracking. They have excellent performance and real-time tracking speed when running in many routine tracking scenarios. However, their vulnerability becomes evident when the targets suffer from drastic appearance changes, non-rigid deformations, and partial occlusions. Unlike these approaches, our proposed work makes full use of historical multiple-frame information in the tracking process, which can greatly improve the robustness of the model in those challenging scenarios.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Template Updates</head><p>To cope with challenging factors in tracking processing, updating the template is critical to adapt the tracker to target variations.</p><p>DSiam <ref type="bibr" target="#b15">[16]</ref> proposes a dynamic siamese network with a fast transformation learning model to enable effective template updating and cluttered background suppression. In <ref type="bibr" target="#b64">[65]</ref>, a distractor-aware module is designed to transfer the general embedding in siamese networks to the specific target domain of the current video. Observing that the absolute values of gradients at locations where objects are occluded or distracted from similar objects are prone to be higher, GradNet <ref type="bibr" target="#b24">[25]</ref> integrates backward gradients into the initial template for augmenting the discriminative ability of the template. These methods explicitly select informative frames and use customized strategies to update the template. Different from these explicit template updating strategies, we propose to store the historical information of the target in memory networks and retrieve them as needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Memory Networks</head><p>Memory networks were first proposed to solve document Q&amp;A <ref type="bibr" target="#b51">[52,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b20">21]</ref> in the Natural Language Processing field. They are common neural networks equipped with external memory components to read and write historical information. Recently, memory networks have shown significant performance improvement in few shot learning <ref type="bibr" target="#b38">[39,</ref><ref type="bibr" target="#b29">30]</ref>, video object segmentation <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b29">30]</ref>, etc.</p><p>Memory networks have been also introduced into visual tracking, a typical one is MemTrack <ref type="bibr" target="#b57">[58]</ref>. It uses a memory network to read a residual template during tracking and then combines it with the initial template to yield a synthetic template that is used as an updated representation of the target. Although MemTrack <ref type="bibr" target="#b57">[58]</ref> uses a large amount of historical information in the tracking process, the memory reading operation controlled by a LSTM may lose useful information. The overall performance of the tracker is greatly affected by the learning quality of the LSTM controller.</p><p>In our work, the retrieval of historical information is determined by the current frame itself, therefore it can obtain all it needs, adaptively. Foreground-background Label Map <ref type="figure">Figure 2</ref>: The architecture of our proposed method. The left part is the feature extraction network that consists of a memory branch (displayed in light green) and a query branch (displayed in light blue). The memory branch takes both memory frames and corresponding foreground-background label maps as inputs. "concat." denotes the concatenation operation along the temporal dimension. The middle part is the space-time memory network that retrieves the target information from multiple memory frames for the target localization in the query frame. The right side is the head network for the foregroundbackground classification and the target bounding box regression of the query frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Proposed Method</head><p>In this section, we will describe the proposed tracking framework in detail. First, we will introduce an overview of the framework in Sec. 3.1. Then, we will give an account of each module of the whole framework one by one from Sec. 3.2 to Sec. 3.4. Last, we will present the online tracking process of the framework in Sec. 3.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Architecture</head><p>As shown in <ref type="figure">Fig. 2</ref>, the framework can be divided into three parts, a feature extraction network, a space-time memory network, and a head network. The feature extraction network consists of a memory branch (in light green) and a query branch (in light blue). The memory branch takes both memory frames and corresponding foreground-background label maps (will be explained in the next section) as inputs, while the input of the query branch is only a single query frame. In this work, the memory frames are multiple historical frames, and the query frame is the current frame in a tracking sequence. After the feature extraction, the spacetime memory network retrieves information related to the target from features of all memory frames, generating a synthetic feature map to classify the target from backgrounds and to predict the target bounding box for the query frame.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Feature Extraction Network</head><p>Here we describe the feature extraction procedures of the memory branch and the query branch, respectively.</p><p>Memory Feature Extraction. The inputs of the memory branch are T memory frames m (each frame is m i ) and T foreground-background label maps c (each label map is c i ), where c is to ensure that the memory backbone ? m learns the consistency of the real target characteristics rather than distractors and cluttered background information. Specifically, we label each pixel with 1 within the corresponding ground truth bounding box and 0 elsewhere for each memory frame m i . Then, we adopt the first convolutional layer of ? m (represented by ? m 0 ) and an extra convolutional layer g to map m and c to a same embedding space, respectively. After that, we add ? m 0 (m) and g(c) element-wise, then input the sum to the latter layers of ? m to generate T memory feature maps (denoted as f m , each memory feature map is f m i ). The feature dimensionality of f m is then reduced to 512 by a non-linear convolutional layer (denoted as h m ):</p><formula xml:id="formula_0">f m i = h m (? m ? (? m 0 (m i ) ? g(c i )))<label>(1)</label></formula><p>where f m i ? R C?H?W , ? m ? represents all layers of ? m except the first layer, and "?" is element-wise addition.</p><p>Query Feature Extraction. Different from the memory branch, the query branch takes a query frame q as input and produces a feature map ? q (q). Similar to the memory branch, the feature dimensionality of ? q (q) is also reduced to 512 by a non-linear convolutional layer (denoted as h q ):</p><formula xml:id="formula_1">f q = h q (? q (q))<label>(2)</label></formula><p>where f q ? R C?H?W . Note that the two backbones ? m and ? q share the same network architecture but have different parameters. An ablation study on whether sharing one backbone can be seen in Sec. 4.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Space-time Memory Network</head><p>As illustrated in <ref type="figure" target="#fig_1">Fig. 3</ref>, we first compute the similarities between every pixel of f m and every pixel of f q to obtain a similarity matrix w ? R T HW ?HW . Inspired by <ref type="bibr" target="#b50">[51]</ref>, we expect the similarity computation to apply the gaussian function. Thus, we normalize w with a softmax function. Taking one element w ij for example, we can formally denote w ij as:</p><formula xml:id="formula_2">w ij = exp f m i? f q ?j /s ?k exp f m k? f q ?j /s<label>(3)</label></formula><p>where i is the index of each pixel on f m ? R T HW ?C , j is the index of each pixel on f q ? R C?HW , and the binary operator denotes vector dot-product. Here s is a scaling factor to prevent the exp function from overflowing numerically. Following <ref type="bibr" target="#b44">[45]</ref>, we set s to</p><formula xml:id="formula_3">? C, where C is the feature dimensionality of f m .</formula><p>Then, treating w as a soft weight map, we multiply f m by w. Because f m stores all historical memory information related to the target, according to the needs of the query frame itself, the target information stored in f m is adaptively retrieved. Obviously, the readout information is a feature map as the same size as f q . Therefore, we concatenate the readout information and the query feature map f q along the channel dimension to generate the final synthetic feature map y. Formally, for the i-th element of y, the space-time memory read operation can be denoted as:</p><formula xml:id="formula_4">y i = concat f q i , (f m ) T i ? w<label>(4)</label></formula><p>where (f m ) T ? R C?T HW is the transpose of f m , and the concat(?, ?) function represents the concatenation operation. At a first glance, the working mechanism of the memory read operation is similar to the non-local self-attention <ref type="bibr" target="#b50">[51]</ref>. A representative example of deploying the non-local self-attention <ref type="bibr" target="#b50">[51]</ref> in visual tracking is AlphaRefine <ref type="bibr" target="#b56">[57]</ref>, the winner of the real-time tracking challenge VOT-RT2020 <ref type="bibr" target="#b18">[19]</ref>, that uses a non-local block to augment the response map generated by a pixel-wise correlation since the longerrange dependencies can produce more precise target boundary decision information. Differently, the purpose of designing the space-time memory reader in our proposed framework, however, is to retrieve the target information from multiple memory frames by taking the similarity matrix as soft weights, instead of computing the non-local selfattention for each pixel pair in a feature map. Particularly, different from STMVOS <ref type="bibr" target="#b33">[34]</ref> and Gragh-MemVOS <ref type="bibr" target="#b36">[37]</ref> in video object segmentation, our method does not divide the features extracted by ? m and ? q into keys and values, but directly uses f m and f q to locate the target. The motivation is that, f m itself happens to provide adequate target information to find the exposed parts of the target when it suffers from partial occlusions in the query frame. This difference makes the space-time memory network more suitable for the single object tracking task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Head Network</head><p>Inspired by the phenomenon that the one-stage anchorfree detector <ref type="bibr" target="#b43">[44]</ref> has achieved better performance and has fewer parameters than the one-stage anchor-based method <ref type="bibr" target="#b26">[27]</ref> in object detection, we design an anchor-free head network that contains a classification branch to classify the tar-get from backgrounds and an anchor-free regression branch to directly estimate the target bounding box.</p><p>To be specific, first, we encode y with a lightweight classification convolutional network ? cls to integrate f q and the retrieved information from f m to adapt to the classification task. Then, a linear convolutional layer with 1 ? 1 kernel is used to reduce the dimensionality of the output of ? cls to 1, producing the final classification response map R cls ? R 1?H?W .</p><p>Moreover, we observe that the positive samples near the target boundary tend to predict low-quality target bounding boxes. Therefore, a sub-branch is forked after ? cls to generate a center-ness response map R ctr ? R 1?H?W , as illustrated in the right part of <ref type="figure">Fig. 2</ref>. During inference, R cls is multiplied by R ctr to suppress the classification confidence scores of pixels away from the target center.</p><p>In the regression branch, we pass y to another lightweight regression convolutional network ? reg and then reduce the dimensionality of the outputted features to 4 to generate a regression response map R reg ? R 4?H?W for the target bounding box estimation.</p><p>We recommend readers to refer to <ref type="bibr" target="#b55">[56]</ref> for more details about the encodings and the training objectives of R cls , R ctr , and R reg .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Inference Phase</head><p>Our space-time memory network is flexible so that the number of used memory frames (i.e. the memory size) during inference is independent of the number of memory frames during training (See Sec. 4.3 for the impact of different number of memory frames on performance in the two phases). In this work, for the current frame F t , we select N memory frames from all historical frames (i.e. frame F 1 to frame F t?1 ) as memory frames for rich appearance information and strong generalization ability. From the perspective of existing works <ref type="bibr" target="#b45">[46,</ref><ref type="bibr" target="#b36">37]</ref>, experiences, and intuitions, target information from the first frame and the previous frame plays an important role for the target localization in the current frame. Specifically, the target from the first frame provides the most reliable information, while the tracked target from the previous frame has the most similar appearance to the target in the current frame. Therefore, for the current frame F t , the memory frames hold the first frame F 1 , the previous frame F t?1 and other N ? 2 frames F ?1 , F ?2 , ? ? ? , F ? (N ?2) sampled following the methodology: splitting all historical frames into N ? 2 segments, and choosing one representative frame from each segment for the best balance between the target domain adaptation, underfitting, and the time cost. Formally, the sampling method can de described as:</p><formula xml:id="formula_5">? i = t ? 1 N ? 2 ? (i + ? i )<label>(5)</label></formula><p>Here, i ? {1, 2, ? ? ? , N ? 2}, and ? i ? [0, 1) is the offset of the representative frame in the i-th segment. For the first N frames, we set all historical frames (i.e. F 1 , F 2 , ? ? ? , F N ?1 ) as memory frames. In our experiments, N is set to 6, and we simply set ? i = 1 2 |1 ? i ? N ? 2 . For each frame in the whole tracking process, after obtaining R cls , R ctr , and R reg , the postprocessing is the same as <ref type="bibr" target="#b55">[56]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments</head><p>Our tracker is implemented in Python using PyTorch framework, which runs at 37 1 FPS on an NVIDIA Tesla V100 GPU. We evaluate our tracker on benchmarks: OTB-2015 <ref type="bibr" target="#b52">[53]</ref>, TrackingNet <ref type="bibr" target="#b35">[36]</ref>, GOT-10k <ref type="bibr" target="#b16">[17]</ref>, LaSOT <ref type="bibr" target="#b12">[13]</ref>, UAV123 <ref type="bibr" target="#b34">[35]</ref>, and VOT2018 <ref type="bibr" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Training Dataset</head><p>We adopt TrackingNet <ref type="bibr" target="#b35">[36]</ref>, the training set of La-SOT <ref type="bibr" target="#b12">[13]</ref> and GOT-10k <ref type="bibr" target="#b16">[17]</ref>, ILSVRC VID <ref type="bibr" target="#b37">[38]</ref>, ILSVRC DET <ref type="bibr" target="#b37">[38]</ref>, and COCO <ref type="bibr" target="#b27">[28]</ref> as our training dataset except the GOT-10k benchmark. We sample T (T = 3 in this paper) frames within the maximum frame index gap 100 and adopt random affine transformations to increase data diversity for training video sequences. To be specific, the translation is randomly performed from ?0.2S to 0.2S and the resizing scale varies between 1 1+r and 1 + r with r = 0.3. Here S is the cropping size, and we set S to the scale of 4 times the target bounding box for mining as much contextual information as possible and enhancing the discriminative ability of the model. We apply the above data augmentation strategy with different parameter settings to generate a synthetic video sample for ILSVRC DET <ref type="bibr" target="#b37">[38]</ref> and COCO <ref type="bibr" target="#b27">[28]</ref>. Note that, different from siamese trackers, our method does not have to keep the same target scale for a training sample. For each frame in a training sample, taking the target center as the center, we crop a square image patch with side length S from the original frame and resize the cropped image patch to 289 ? 289 to be the input of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Implementation Details</head><p>Model Settings. We adopt GoogLeNet <ref type="bibr" target="#b42">[43]</ref> as our backbone ? m and ? q . The classification convolutional network ? cls and the regression convolutional network ? reg are both comprised of seven convolutional layers. Each convolutional layer in ? cls and ? reg is followed by a ReLU activation function.</p><p>Optimization and Training Strategies. Our tracker is trained with SGD optimizer for 20 epochs. There are 300,000 samples per epoch, and the mini-batch size is set to 64. The whole training phase takes about 27 hours to converge with four NVIDIA Tesla V100 GPUs. For the GOT-10k benchmark, we set the number of samples per epoch to 150,000 and the mini-batch size to 32. The momentum and the weight decay rate are set to 0.9 and 1 ? 10 ?4 , respectively. We freeze all convolutional layers of ? m and ? q in the first 10 epochs and unfreeze all convolutional layers of stage 3 and 4 <ref type="bibr" target="#b42">[43]</ref> of ? m and ? q for the other epochs. The learning rate increases from 1 ? 10 ?2 to 8 ? 10 ?2 with a warmup technology at the first epoch and decreases from 8 ? 10 ?2 to 1 ? 10 ?6 with a cosine annealing learning rate schedule for the other epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Ablation Study</head><p>In this section, we conduct a comprehensive ablation study for the proposed tracker.</p><p>Should the Tracker Share one Backbone? First, we analyze whether the tracker should share one backbone between the memory branch and the query branch like most siamese networks. As shown in Tab. 1, from the top two rows, we observe that sharing one backbone can improve the average overlap (AO) by 2.3% if we do not use foreground-background label maps. However, the comparison of the bottom two rows in Tab. 1 and comparisons on other benchmarks in Tab. 2 show that the performance of using different backbones is more superior than sharing one.</p><p>Should the Tracker Use Foreground-background Label Maps in the Input of the Memory Branch? Second, we discuss the necessity to use foreground-background label maps in the input of the memory branch. By comparing the first row with the third row and comparing the second row with the last row in Tab. 1, we notice that the performance will be improved by 2.9% and 7.4% with the same backbone and different backbones, respectively. It indicates that foreground-background label maps are crucial to the memory mechanism in this framework.</p><p>What is the Best Number of Reference Frames in the Memory? Last but not least, the number of reference frames in the memory (i.e. the memory size) is a key factor for memory networks. During training, the number of reference frames affects the learning qualities of two backbones. The more reference frames, the more target patterns can be trained, but the more frames are similar to the current frame. In that case, the network tends to compare the most similar image pairs, rather than learning to compute the similarities between the current frame and frames with clutter backgrounds or partially occluded targets. We verify the impact in training with different memory size settings on the GOT-10k benchmark. Tab. 3 shows that using 3 reference frames in a training sample brings the best performance in terms of average overlap (AO) metric.</p><p>During inference, the memory size not only affects the performance, but also significantly determines the running speed. We conduct a group of experiments on TrackingNet to analyze the impact of the memory size on the perfor- <ref type="table">Table 1</ref>: Ablation study on the GOT-10k benchmark. Here the variable "share" denotes whether the network should share the backbone between the memory and the query branch, and the variable "fb label" represents whether the network should use foreground-background label maps in the memory branch input.    mance and the speed. As listed in Tab. 4, the most suitable memory size is 6 for this work. Besides, the more reference frames does not produce the better performance. We speculate that there are two main reasons: the one is overfitting, and the another one is too many low-quality memory frames affect tracking results that further products more inferior memory frames.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparison with the state-of-the-art</head><p>OTB-2015. OTB-2015 <ref type="bibr" target="#b52">[53]</ref> is a classical benchmark in visual object tracking, containing 100 short-term videos with 590 frames per video on average. We report the results on OTB-2015. It is known to have tended to saturation over recent years. Still, as shown in Tab. 5, our approach surpasses the previous best performance trackers by 0.4% in terms of success (AUC) metric, setting a new state-of-theart performance on this dataset.</p><p>TrackingNet. TrackingNet <ref type="bibr" target="#b35">[36]</ref> is a large-scale short-  <ref type="bibr" target="#b63">[64]</ref> 0.715 KYS <ref type="bibr" target="#b2">[3]</ref> 0.695 RPT <ref type="bibr" target="#b31">[32]</ref> 0.715 MCCT <ref type="bibr" target="#b48">[49]</ref> 0.695 CGACD <ref type="bibr" target="#b11">[12]</ref> 0.713 GFS-DCF <ref type="bibr" target="#b54">[55]</ref> 0.693 SiamAttn <ref type="bibr" target="#b58">[59]</ref> 0.712 ASRCF <ref type="bibr" target="#b8">[9]</ref> 0.692 DCFST <ref type="bibr" target="#b62">[63]</ref> 0.709 PGNet <ref type="bibr" target="#b25">[26]</ref> 0.691 UPDT <ref type="bibr" target="#b3">[4]</ref> 0.702 RPCF <ref type="bibr" target="#b41">[42]</ref> 0.690 DRT <ref type="bibr" target="#b40">[41]</ref> 0.699 SPM <ref type="bibr" target="#b47">[48]</ref> 0.687 SiamCAR <ref type="bibr" target="#b14">[15]</ref> 0.697 DiMP-50 <ref type="bibr" target="#b1">[2]</ref> 0.684 PrDiMP-50 <ref type="bibr" target="#b10">[11]</ref> 0.696 Ocean <ref type="bibr" target="#b61">[62]</ref> 0.684 SiamBAN <ref type="bibr" target="#b5">[6]</ref> 0.696 SiamFC++ <ref type="bibr" target="#b55">[56]</ref> 0.683 term tracking dataset that provides a large amount of videos in the wild for training and testing. The testing set contains 511 videos without publicly released ground truths. We evaluate our tracker on the testing set and obtain results from the dedicated evaluation server. As shown in Tab. 6, our tracker outperforms all previous state-of-the-art real-time approaches by a large margin and strongly sets leading performance. It is noteworthy that this dataset has a wide variety in terms of classes and scenarios in the wild; therefore, the significant performance improvement of our approach illustrates its strong generalization ability to realworld tracking videos. GOT-10k. GOT-10k <ref type="bibr" target="#b16">[17]</ref> is a recently released largescale generic object tracking benchmark, containing 10,000 videos totally, in which the testing set has 180 videos. Similar to TrackingNet, the ground truths of the testing set are also withheld so that all tracking results must be evaluated in a specific evaluation server. Different from others, GOT-10k benchmark restricts trackers to use only the training set for training. In this work, we follow this protocol for training our tracker and testing it on the testing set. All settings are unchanged except for the training data. Tab. 7 lists a comparison of our tracker with other state-of-the-art trackers in terms of average overlap (AO) and success rates (SR) at threshold 0.5 and 0.75. Benefit from the pixel-level similarity computation in the space-time memory reader, our method outperforms the second place tracker PrDiMP-50 <ref type="bibr" target="#b10">[11]</ref> by 3.2% for the SR 0.75 metric (The percentage of successfully tracked frames where the overlaps exceed 0.75).</p><p>LaSOT. LaSOT <ref type="bibr" target="#b12">[13]</ref> is also a large-scale single object tracking dataset with high-quality annotations. Its testing set consists of 280 long videos, with an average of 2500 frames per video. Thus, the robustness of trackers is crucial against complicated scenarios, such as occlusions, out-ofview, etc. We report the results on the testing set. As shown in <ref type="figure" target="#fig_3">Fig. 4, comparing</ref>     <ref type="table">Table 9</ref>: A comparison of our tracker with state-of-the-art trackers on VOT2018. The best results are highlighted in red, blue, and green, respectively. Trackers are ranked from top to bottom according the EAO scores. The arrows after the metrics mean that the bigger(?) or the smaller(?) is the better.</p><p>Tracker EAO? A? R? Ours 0.447 0.590 0.159 D3S <ref type="bibr" target="#b30">[31]</ref> 0.489 0.640 0.150 Ocean <ref type="bibr" target="#b61">[62]</ref> 0.489 0.592 0.117 SiamAttn <ref type="bibr" target="#b58">[59]</ref> 0.470 0.630 0.160 KYS <ref type="bibr" target="#b2">[3]</ref> 0.462 0.609 0.143 SiamBAN <ref type="bibr" target="#b5">[6]</ref> 0.452 0.597 0.178 PGNet <ref type="bibr" target="#b25">[26]</ref> 0.447 0.618 0.192 PrDiMP-50 <ref type="bibr" target="#b10">[11]</ref> 0.442 0.618 0.165 DiMP-50 <ref type="bibr" target="#b1">[2]</ref> 0.440 0.597 0.153 Siam R-CNN <ref type="bibr" target="#b45">[46]</ref> 0.408 0.609 0.220 SiamFC++ <ref type="bibr" target="#b55">[56]</ref> 0.426 0.587 0.183 SiamRPN++ <ref type="bibr" target="#b22">[23]</ref> 0.414 0.600 0.234 FCOS-MAML <ref type="bibr" target="#b46">[47]</ref> 0.392 0.635 0.220 characteristics of UAV, this dataset has numerous scenarios with partial and full occlusions, out-of-view, and small objects. Thus, many objects have quite low resolutions. As shown in Tab. 8, however, our tracker obtains a success (AUC) score of 0.647, which still significantly outperforms recent competitive siamese trackers SiamBAN <ref type="bibr" target="#b5">[6]</ref>, Siam-CAR <ref type="bibr" target="#b14">[15]</ref>, and SiamRPN++ <ref type="bibr" target="#b22">[23]</ref>, while running at a realtime speed.</p><p>VOT2018. The 2018 version of the visual object tracking (VOT) challenge <ref type="bibr" target="#b19">[20]</ref> contains 60 videos. Following the evaluation protocol of the VOT2018 dataset, we report the results of our tracker in terms of expected average overlap (EAO), accuracy (A), and robustness (R) and compare it with state-of-the-art trackers. As shown in Tab. 9, the robustness of our tracker is similar to D3S <ref type="bibr" target="#b30">[31]</ref> and Sia-mAttn <ref type="bibr" target="#b58">[59]</ref>. However, the accuracy is worse than them since the ground truths in the VOT evaluation system are rotated bounding boxes, the estimated bounding boxes in our tracker are axis-aligned instead.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions</head><p>This work proposes a novel tracking framework based on space-time memory networks. The framework abandons the traditional template-based tracking mechanism, using multiple memory frames and foreground-background label maps to locate the target in the query frame. In the space-time memory networks, the target information stored in multiple memory frames is adaptively retrieved by the query frame, so that the tracker has a strong adaptive ability to the target variations. Extensive experiments demonstrates that, without bells and whistles, the proposed tracker achieves better performance than current state-ofthe-art real-time methods, while running at 37 FPS. The experiments also shows its generalizability, extendibility, and applicability.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>The space-time memory reader. Here f m ? R T ?C?H?W and f q ? R C?H?W , where T is the number of memory frames, C, H and W represent the feature dimensionality, the height, and the width of the feature map, respectively. For the convenience of matrix multiplication in math, we reshape f m from T ?C ?H ?W to T HW ?C, and reshape f q from C ? H ? W to C ? HW , thus here T HW = T ? H ? W and HW = H ? W . the operator "?" denotes matrix multiplication, and "concat." denotes the concatenation operation along the channel dimension.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 :</head><label>4</label><figDesc>Plots show comparisons of our tracker with other competitive trackers on the testing set of LaSOT. Trackers are evaluated by the success, precision, and normalized precision metrics.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Corresponding author.</figDesc><table><row><cell>#229</cell><cell>#815</cell><cell>#836</cell><cell></cell></row><row><cell>#214</cell><cell>#247</cell><cell>#519</cell><cell></cell></row><row><cell>#419</cell><cell>#568</cell><cell cols="2">#1312</cell></row><row><cell>Ours</cell><cell>SiamFC++</cell><cell>DiMP-50</cell><cell>Ground Truth</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell cols="4">The same ablation study as Tab. 1 on OTB-2015,</cell></row><row><cell cols="4">TrackingNet, and LaSOT. The tracker is evaluated by suc-</cell></row><row><cell>cess (AUC) metric.</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">share fb label OTB-2015 TrackingNet LaSOT</cell></row><row><cell></cell><cell>0.702</cell><cell>79.7</cell><cell>0.593</cell></row><row><cell>-</cell><cell>0.719</cell><cell>80.3</cell><cell>0.606</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>The performance on GOT-10k with different number of reference frames in training. Here AO is the average overlap metric.</figDesc><table><row><cell>#</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell></row><row><cell cols="5">AO 0.629 0.624 0.642 0.627</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>The performance in terms of success (AUC) metric on TrackingNet with different number of reference frames in the inference phase.</figDesc><table><row><cell>#</cell><cell>1</cell><cell>2</cell><cell>4</cell><cell>6</cell><cell>8</cell><cell>ALL</cell></row><row><cell cols="7">Success 79.1 79.3 80.2 80.3 80.2 79.8</cell></row><row><cell>FPS</cell><cell cols="5">43.0 26.6 29.3 28.6 22.7</cell><cell>6.5</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 :</head><label>5</label><figDesc>A success (AUC) performance list on OTB-2015 for a comprehensive comparison of our tracker with competitive trackers published in recent years. The best three results are highlighted in red, blue, and green, respectively. Trackers are ranked from top to bottom and left to right according the Success values.</figDesc><table><row><cell>Tracker</cell><cell>Success</cell><cell>Tracker</cell><cell>Success</cell></row><row><cell>Ours</cell><cell>0.719</cell><cell>SiamRPN++ [23]</cell><cell>0.696</cell></row><row><cell>DROL</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 :</head><label>6</label><figDesc>A performance comparison of our tracker with other competitive approaches on the test split of Track-ingNet. Trackers are ranked from top to bottom according the "Suc." values. "Suc.", "Prec.", and "Norm. Prec." are abbreviations for success (AUC), precision, and normalized precision, respectively. The best three results are highlighted in red, blue, and green, respectively.</figDesc><table><row><cell>Tracker</cell><cell cols="3">Suc. Prec. Norm. Prec.</cell></row><row><cell>Ours</cell><cell cols="2">80.3 76.7</cell><cell>85.1</cell></row><row><cell>PrDiMP-50 [11]</cell><cell cols="2">75.8 70.4</cell><cell>81.6</cell></row><row><cell cols="2">FCOS-MAML [47] 75.7</cell><cell>-</cell><cell>82.2</cell></row><row><cell>SiamFC++ [56]</cell><cell cols="2">75.4 70.5</cell><cell>80.0</cell></row><row><cell>SiamAttn [59]</cell><cell>75.2</cell><cell>-</cell><cell>81.7</cell></row><row><cell>DCFST-50 [63]</cell><cell cols="2">75.2 70.0</cell><cell>80.9</cell></row><row><cell>DROL [64]</cell><cell cols="2">74.6 70.8</cell><cell>81.7</cell></row><row><cell>KYS [3]</cell><cell cols="2">74.0 68.8</cell><cell>80.0</cell></row><row><cell>DiMP-50 [2]</cell><cell cols="2">74.0 68.7</cell><cell>80.1</cell></row><row><cell>SiamRPN++ [23]</cell><cell cols="2">73.3 69.4</cell><cell>80.0</cell></row><row><cell>D3S [31]</cell><cell cols="2">72.8 66.4</cell><cell>76.8</cell></row><row><cell>CGACD [12]</cell><cell cols="2">71.1 69.3</cell><cell>80.0</cell></row><row><cell>GlobalTrack [18]</cell><cell cols="2">70.4 65.6</cell><cell>75.4</cell></row><row><cell>ATOM [10]</cell><cell cols="2">70.3 64.8</cell><cell>77.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 7 :</head><label>7</label><figDesc>A performance comparison of our tracker with other competitive approaches on the test split of GOT-10k in terms of average overlap (AO) and success rates (SR) at threshold 0.5 and 0.75. The best three results are highlighted in red, blue, and green, respectively. Trackers are ranked from top to bottom according the AO values.</figDesc><table><row><cell>Tracker</cell><cell>AO</cell><cell cols="3">SR 0.5 SR 0.75 FPS</cell></row><row><cell>Ours</cell><cell cols="2">0.642 0.737</cell><cell>0.575</cell><cell>37</cell></row><row><cell>KYS [3]</cell><cell cols="2">0.636 0.751</cell><cell>0.515</cell><cell>20</cell></row><row><cell cols="3">PrDiMP-50 [11] 0.634 0.738</cell><cell>0.543</cell><cell>30</cell></row><row><cell>RPT [32]</cell><cell cols="2">0.624 0.730</cell><cell>0.504</cell><cell>20</cell></row><row><cell>Ocean [62]</cell><cell cols="2">0.611 0.721</cell><cell>-</cell><cell>58</cell></row><row><cell>DiMP-50 [2]</cell><cell cols="2">0.611 0.717</cell><cell>0.492</cell><cell>43</cell></row><row><cell>D3S [31]</cell><cell cols="2">0.597 0.676</cell><cell>0.462</cell><cell>25</cell></row><row><cell>SiamFC++ [56]</cell><cell cols="2">0.595 0.695</cell><cell>0.479</cell><cell>90</cell></row><row><cell>SiamCAR [15]</cell><cell cols="2">0.569 0.670</cell><cell>0.415</cell><cell>52</cell></row><row><cell>ATOM [10]</cell><cell cols="2">0.556 0.634</cell><cell>0.402</cell><cell>30</cell></row><row><cell cols="3">SiamRPN++ [23] 0.517 0.616</cell><cell>0.325</cell><cell>35</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>with twelve comparable trackers, our tracker sets top performance in terms of success, precision, and normalized precision.UAV123. UAV123<ref type="bibr" target="#b34">[35]</ref> is designed to evaluate trackers in UAV applications, including 123 low altitude aerial videos, with an average of 915 frames per video. Due to the</figDesc><table><row><cell></cell><cell>0.9</cell><cell></cell><cell cols="4">Success plots of OPE on LaSOT Testing Set</cell><cell></cell><cell>0.8</cell><cell></cell><cell cols="4">Precision plots of OPE on LaSOT Testing Set</cell><cell></cell><cell>0.8</cell><cell></cell><cell cols="4">Normalized Precision plots of OPE on LaSOT Testing Set</cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Success rate</cell><cell>0.3 0.4 0.5 0.6</cell><cell></cell><cell>[0.606] Ours [0.570] LTMU [0.565] DiMP-50 [0.560] Ocean [0.543] SiamFC++ [0.521] GlobalTrack [0.516] SiamCAR</cell><cell></cell><cell></cell><cell></cell><cell>Precision</cell><cell>0.4 0.5 0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[0.633] Ours [0.566] LTMU [0.566] Ocean [0.563] DiMP-50 [0.547] SiamFC++ [0.529] GlobalTrack [0.524] SiamCAR</cell><cell>Precision</cell><cell>0.4 0.5 0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">[0.693] Ours [0.653] LTMU [0.651] Ocean [0.646] DiMP-50 [0.623] SiamFC++ [0.610] SiamCAR [0.599] GlobalTrack</cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell>[0.514] ATOM [0.514] SiamBAN [0.496] SiamRPN++</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">[0.521] SiamBAN [0.505] ATOM [0.491] SiamRPN++</cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">[0.598] SiamBAN [0.577] ATOM [0.569] SiamRPN++</cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell>[0.475] UpdateNet [0.447] ROAM++</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[0.459] UpdateNet [0.445] ROAM++</cell><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[0.564] UpdateNet [0.543] ROAM++</cell></row><row><cell></cell><cell></cell><cell></cell><cell>[0.390] VITAL</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[0.360] VITAL</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>[0.453] VITAL</cell></row><row><cell></cell><cell>0</cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell><cell>0</cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Overlap threshold</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Location error threshold</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Location error threshold</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">(a) Success Plot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(b) Precision Plot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">(c) Normalized Precision Plot</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 8 :</head><label>8</label><figDesc>A comparison of our tracker with other competitive approaches on UAV123 in terms of success (AUC) metric. The best three results are highlighted in red, blue, and green, respectively.OursDiMP-50 [2] ATOM [10] SiamBAN [6] SiamCAR [15] SiamRPN++ [23] UPDT [4]</figDesc><table><row><cell>Success 0.647</cell><cell>0.654</cell><cell>0.643</cell><cell>0.631</cell><cell>0.614</cell><cell>0.613</cell><cell>0.545</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The running speed is calculated by the GOT-10k evaluation server.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Fully-convolutional siamese networks for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jack</forename><surname>Valmadre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joao</forename><forename type="middle">F</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="850" to="865" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Learning discriminative model prediction for tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6182" to="6191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Know your surroundings: Exploiting scene information for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="205" to="221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unveiling the power of deep tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joakim</forename><surname>Johnander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="483" to="498" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Signature verification using a &quot;siamese&quot; time delay neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jane</forename><surname>Bromley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L?on</forename><surname>Bentz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Isabelle</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Cliff</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Moore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roopak</forename><surname>S?ckinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Siamese box adaptive network for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zedu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bineng</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guorong</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengping</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rongrong</forename><surname>Ji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6668" to="6677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deep meta learning for real-time target-aware visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Janghoon</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junseok</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyoung Mu</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="911" to="920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning a similarity metric discriminatively, with application to face verification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="539" to="546" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Visual tracking via adaptive spatially-regularized correlation filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenan</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianhua</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="4670" to="4679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Atom: Accurate tracking by overlap maximization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fahad</forename><surname>Shahbaz Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Felsberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="4660" to="4669" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Probabilistic regression for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luc</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Radu</forename><surname>Timofte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="7183" to="7192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Correlation-guided attention for corner detection based visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fei</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xianglong</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6836" to="6845" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Lasot: A high-quality benchmark for large-scale single object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liting</forename><surname>Heng Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fan</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ge</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sijia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hexin</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="5374" to="5383" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Siamese cascaded region proposal networks for real-time visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Heng</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haibin</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7952" to="7961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Siamcar: Siamese fully convolutional classification and regression for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dongyan</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ying</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhenhua</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shengyong</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6269" to="6277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning dynamic siamese network for visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qing</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ce</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liang</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1763" to="1771" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Got-10k: A large high-diversity benchmark for generic object tracking in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianghua</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Globaltrack: A simple and strong baseline for long-term tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lianghua</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xin</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiqi</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="11037" to="11044" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The eighth visual object tracking vot2020 challenge results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ales</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Pflugfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joni-Kristian</forename><surname>Kamarainen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Luka? Ehovin Zajc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Danelljan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ondrej</forename><surname>Lukezic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linbo</forename><surname>Drbohlav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yushan</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Song</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinyu</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fernandez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The sixth visual object tracking vot2018 challenge results</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Kristan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ales</forename><surname>Leonardis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Felsberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roman</forename><surname>Pfugfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luka?ehovin</forename><surname>Zajc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomas</forename><surname>Vojir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Goutam</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lukezic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelrahman</forename><surname>Eldesokey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gustavo</forename><surname>Fernandez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Ask me anything: Dynamic memory networks for natural language processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ankit</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ozan</forename><surname>Irsoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peter</forename><surname>Ondruska</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bradbury</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishaan</forename><surname>Gulrajani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Victor</forename><surname>Zhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Romain</forename><surname>Paulus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Socher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1378" to="1387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">On-road pedestrian tracking across multiple driving recorders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hui</forename><surname>Kuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jenq-Neng</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Hwang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TMM</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1429" to="1438" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Siamrpn++: Evolution of siamese visual tracking with very deep networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fangyi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junliang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="4282" to="4291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">High performance visual tracking with siamese region proposal network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolin</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="8971" to="8980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Gradnet: Gradient-guided network for visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peixia</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Boyu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanli</forename><surname>Ouyang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="6162" to="6171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Pg-net: Pixel to global matching network for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bingyan</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chenye</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yayun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaonong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Kaiming He, and Piotr Doll?r. Focal loss for dense object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Priya</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Microsoft coco: Common objects in context</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tsung-Yi</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Deva</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Doll?r</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C Lawrence</forename><surname>Zitnick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="740" to="755" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hand posture recognition using finger geometric feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Liwei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junliang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haizhou</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiang</forename><surname>Ruan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="565" to="568" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Video object segmentation with episodic graph memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiankai</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenguan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danelljan</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianfei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianbing</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Luc</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">D3s-a discriminative single shot segmentation tracker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alan</forename><surname>Lukezic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matej</forename><surname>Kristan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="7133" to="7142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Rpt: Learning point set representation for siamese visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziang</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linyuan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jun</forename><surname>Yin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.03467</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The role of visual working memory in attentive tracking of unique objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tal</forename><surname>Makovski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Yuhong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Human Perception and Performance</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1687</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Key-value memory networks for directly reading documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Fisch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Amir-Hossein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weston</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.03126</idno>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A benchmark and simulator for uav tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Neil</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Trackingnet: A large-scale dataset and benchmark for object tracking in the wild</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adel</forename><surname>Bibi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Giancola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Salman</forename><surname>Alsubaihi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernard</forename><surname>Ghanem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Video object segmentation using space-time memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joon-Young</forename><surname>Seoung Wug Oh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Seon Joo</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Imagenet large scale visual recognition challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IJCV</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Meta-learning with memory-augmented neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Endto-end memory networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sainbayar</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2440" to="2448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Correlation tracking via joint discrimination and reliability learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsuan</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="489" to="497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Roi pooled correlation filters for visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuxuan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">You</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5783" to="5791" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yangqing</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pierre</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dragomir</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Rabinovich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Fcos: Fully convolutional one-stage object detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunhua</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tong</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9627" to="9636" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Attention is all you need</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ashish</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Noam</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Niki</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jakob</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Llion</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aidan</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?ukasz</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Illia</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Siam r-cnn: Visual tracking by re-detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Paul</forename><surname>Voigtlaender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonathon</forename><surname>Luiten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">S</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bastian</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Leibe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="6578" to="6588" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Tracking by instance detection: A metalearning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyan</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="6288" to="6297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Spm-tracker: Series-parallel matching for real-time visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangting</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chong</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiwei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wenjun</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="3643" to="3652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Multi-cue correlation filters for robust visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wengang</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qi</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richang</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Meng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houqiang</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="4844" to="4853" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Fast online object tracking and segmentation: A unifying approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luca</forename><surname>Bertinetto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip Hs</forename><surname>Torr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1328" to="1338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Non-local neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaolong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abhinav</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="7794" to="7803" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoine</forename><surname>Bordes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1410.3916</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">Memory networks. arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<title level="m">Object tracking benchmark. TPAMI</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1834" to="1848" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Multiple human tracking based on multi-view upper-body detection and discriminative learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junliang</forename><surname>Xing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ai</forename><surname>Haizhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shihong</forename><surname>Lao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICPR</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Joint group feature selection and discriminative filter learning for robust visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen-Hua</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao-Jun</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Josef</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICCV</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7950" to="7960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Siamfc++: Towards robust and accurate visual tracking with target estimation guidelines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinda</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zeyu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zuoxin</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ye</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gang</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="12549" to="12556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">Alpha-refine: Boosting tracking performance by precise bounding box estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bin</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dong</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Huchuan</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoyun</forename><surname>Yang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2007.02024,2020.4</idno>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Learning dynamic memory networks for object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tianyu</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Antoni</forename><forename type="middle">B</forename><surname>Chan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="152" to="167" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Deformable siamese attention networks for visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuechen</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yilei</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weilin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthew R</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="6728" to="6737" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Learning to compare image patches via convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Zagoruyko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="4353" to="4361" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Deeper and wider siamese networks for real-time visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houwen</forename><surname>Peng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4591" to="4600" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Ocean: Object-aware anchor-free tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhipeng</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Houwen</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianlong</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bing</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Learning feature embeddings for discriminant model based tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linyu</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yingying</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinqiao</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hanqing</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV, 2020</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Discriminative and robust online learning for siamese visual tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jinghao</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Peng</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoyang</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13017" to="13024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Distractor-aware siamese networks for visual object tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zheng</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Junjie</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weiming</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="101" to="117" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
