<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Auto-Tuning Spectral Clustering for Speaker Diarization Using Normalized Maximum Eigengap</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jin</forename><surname>Tae</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Kyu</forename><forename type="middle">J</forename><surname>Park</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Member, IEEE</roleName><forename type="first">Manoj</forename><surname>Han</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shrikanth</forename><surname>Kumar</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><roleName>Fellow, IEEE</roleName><surname>Narayanan</surname></persName>
						</author>
						<title level="a" type="main">Auto-Tuning Spectral Clustering for Speaker Diarization Using Normalized Maximum Eigengap</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note>1</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T10:50+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Index Terms-Auto-Tuning</term>
					<term>Spectral Clustering</term>
					<term>Eigengap Heuristic</term>
					<term>Speaker Diarization githubcom/tango4j/Auto-Tuning-Spectral-Clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We propose a new spectral clustering framework that can auto-tune the parameters of the clustering algorithm in the context of speaker diarization. The proposed framework uses normalized maximum eigengap (NME) values to estimate the number of clusters as well as the parameters for the threshold of the elements of each row in an affinity matrix during spectral clustering, without any parameter tuning on a development set. Even with this hands-off approach, we achieve comparable or better performance across various evaluation sets than with the traditional clustering methods that use careful parameter tuning and development data. The relative improvement of 17% in terms of speaker error rate in the well-known CALLHOME evaluation set shows the effectiveness of our proposed auto-tuning spectral clustering.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Auto-Tuning Spectral Clustering for Speaker Diarization Using Normalized Maximum Eigengap</head><p>Tae Jin Park, Member, IEEE, Kyu J. Han Member, IEEE, Manoj Kumar and Shrikanth Narayanan, Fellow, IEEE Abstract-We propose a new spectral clustering framework that can auto-tune the parameters of the clustering algorithm in the context of speaker diarization. The proposed framework uses normalized maximum eigengap (NME) values to estimate the number of clusters as well as the parameters for the threshold of the elements of each row in an affinity matrix during spectral clustering, without any parameter tuning on a development set. Even with this hands-off approach, we achieve comparable or better performance across various evaluation sets than with the traditional clustering methods that use careful parameter tuning and development data. The relative improvement of 17% in terms of speaker error rate in the well-known CALLHOME evaluation set shows the effectiveness of our proposed auto-tuning spectral clustering.</p><p>Index Terms-Auto-Tuning, Spectral Clustering, Eigengap Heuristic, Speaker Diarization github.com/tango4j/Auto-Tuning-Spectral-Clustering</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>S PEAKER diarization is the problem of identifying "who spoke when" and assigning speaker identity labels in a given audio stream. In general, speaker diarization systems are comprised of three major parts: Speech segmentation module, speaker embedding extractor, and clustering module. speech segmentation module removes non-speech parts from the audio stream and breaks the speech parts into segments that are supposedly homogeneous in terms of speaker identity. Speaker embedding extractor captures and embeds speaker characteristics in the given segment into a speaker embedding, which is a vector of learned low dimensional representation. Finally, clustering module groups the speaker embeddings from the same speakers into the same clusters.</p><p>Spectral clustering has been widely adopted in numerous speaker diarization studies [1]- <ref type="bibr" target="#b5">[6]</ref>. Spectral clustering is a graph-based clustering technique that uses an affinity matrix, each element of which is the distance between a pair of speaker embeddings. Throughout the Laplacian matrix computations, the affinity matrix is converted to spectral embeddings, which are clustered by the k-means algorithm <ref type="bibr" target="#b6">[7]</ref>. Despite its popularity, spectral clustering has a limitation that its performance is sensitive to the quality of the affinity matrix. Due to the noisy nature of speaker embeddings and distance metrics, it is highly likely for some elements of the affinity matrix to possess noisy signals that could degenerate the clustering process. To address this issue, the spectral clustering algorithms in recent studies employ either a scaling parameter [1]- <ref type="bibr" target="#b2">[3]</ref> or a rowwise thresholding parameter <ref type="bibr" target="#b4">[5]</ref> to put different weights across the elements in the affinity matrix. The downside of these approaches is that those parameters for either scaling or thresholding need to be optimized on a development set to obtain the maximum benefit. The burden of such hyper-parameter tuning in spectral clustering would make the generalization of the clustering algorithm harder in unseen testing environments.</p><p>In this paper, we propose a new spectral clustering framework to self-tune the parameters of clustering so that there would be no need for any hyper-parameter tuning with a development dataset. More specifically, our proposed framework estimates both the threshold p for row-wise binarization of a given affinity matrix and the number of clusters k. To estimate these parameters without the help of a development set, we use the normalized maximum eigengap (NME) value, g p , which is dependent on p and can be obtained by the eigengap heuristic <ref type="bibr" target="#b16">[16]</ref>. We hypothesize that there exists a piecewise linear relationship between p and g p and the ratio of p/g p is a good proxy for diarization error rate (DER). Using this ratio, we can select p, where DER would be presumably the lowest.</p><p>To show the experimental evidence, we compare the proposed clustering method with the widely used clustering methods, which need to be optimized on a development set. Our proposed method is compared with the well-known spectral clustering approach <ref type="bibr" target="#b7">[8]</ref> appeared in a number of speaker diarization studies <ref type="bibr" target="#b0">[1]</ref>- <ref type="bibr" target="#b2">[3]</ref>, and the agglomerative hierarchical clustering (AHC) approach coupled with probabilistic linear discriminant analysis (PLDA) <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b9">[10]</ref>, which has also appeared in recent studies <ref type="bibr" target="#b10">[11]</ref>- <ref type="bibr" target="#b13">[13]</ref>. In addition, the performance of the development-set-optimized version of our proposed spectral clustering method is also tested to verify the benefit of our NME-based auto-tuning approach. The experimental results reveal that p/g p is a good proxy for DER, and the proposed auto-tuning approach can show comparable or even better performance than widely used development-setoptimized clustering algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. TRADITIONAL SPECTRAL CLUSTERING ALGORITHM A. Ng-Jordan-Weiss (NJW) Algorithm</head><p>Spectral clustering is a graph-based clustering technique based on an affinity matrix and its eigenvalues. The affinity matrix is a similarity matrix for a given set of data points, and each element is determined by the distance between a pair of data points in the given input. This algorithm is widely used in diverse fields, such as image segmentation <ref type="bibr" target="#b14">[14]</ref>, multitype relational data <ref type="bibr" target="#b15">[15]</ref>, and speaker diarization [1]- <ref type="bibr" target="#b5">[6]</ref>, due to its simple implementation and decent performance. Among many variants of spectral clustering algorithms, the Ng-Jordan-Weiss (NJW) algorithm <ref type="bibr" target="#b7">[8]</ref> has been the most widely used for speaker diarization tasks. The NJW algorithm consists of three main steps: creation of the affinity matrix, Laplacian matrix computations, and k-means clustering <ref type="bibr" target="#b6">[7]</ref>. To form an affinity matrix, the NJW algorithm employs a kernel method. The similarity measure, which we refer to as d(w i , w j ), between two speaker embeddings from two speech segments is obtained by the cosine similarity measure:</p><formula xml:id="formula_0">d(w i , w j ) = w i ? w j w i w j .<label>(1)</label></formula><p>Each entry in the affinity matrix A is defined as follows:</p><formula xml:id="formula_1">a ij = exp (?d(wi,wj ) 2 ? 2 if i = j 0 if i = j,<label>(2)</label></formula><p>where ? is a scaling factor that needs to be tuned. A can be considered as an undirected graph G = (V, E), where V represents vertices and E represents undirected edges. In the NJW algorithm, this affinity matrix A is normalized with the diagonal matrix D as follows:</p><formula xml:id="formula_2">L = D ? 1 2 AD ? 1 2 ,<label>(3)</label></formula><formula xml:id="formula_3">where D = diag{d 1 , d 2 , ..., d M } and N is the dimension of A.</formula><p>The noramlized matrix L is used to find the eigenvectors, among which the k largest eigenvectors form a spectral embedding matrix with the size N ? k. Each row in this spectral embedding matrix is clustered into one of the k clusters using the k-means clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Limitations of the Traditional Spectral Clustering</head><p>Despite its success, the NJW algorithm has inherent limitations in the context of speaker diarization.</p><p>1) Sensitivity to the Quality of an Affinity Matrix: The similarity values we obtain from distance measures, for example, cosine similarity in (1), for an affinity matrix are merely estimated as well as dependent on how representative the speaker embeddings would be in terms of speaker characteristics. It is likely for some entries in the affinity matrix to have noisy signals that could degenerate the clustering process down the road. Thus, without having a proper scheme to mitigate the effect of such inaccurate information from the affinity matrix, noisy similarity values could lead to a poor clustering result.</p><p>2) Adaptivity to the Variability in Data: Due to the above issue, there have been a number of schemes proposed in the literature to put different weights across the elements in the affinity matrix. In the previous studies, <ref type="bibr" target="#b4">[5]</ref> chose only the entries in each row of the affinity matrix within p-percentile, and <ref type="bibr" target="#b0">[1]</ref>, <ref type="bibr" target="#b2">[3]</ref> used scaling factors to control the weights of each element of the affinity matrix. The downside of these approaches is that the parameters for either thresholding or scaling need to be tuned using a development dataset. This could lead to the dependency of the clustering performance upon how to select the development data. Requiring such hyper-parameter tuning would become a burden in generalizing the clustering algorithm in unseen testing conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. NORMALIZED MAXIMUM EIGENGAP ANALYSIS</head><p>In this section, we present the details of our proposed spectral clustering framework using the NME analysis. The procedure is described in Algorithm 1 1 . The following is the itemized description: 1 https://github.com/tango4j/Auto-Tuning-Spectral-Clustering Algorithm 1 NME-SC algorithm Input: Affinity Matrix A Output: Cluster vector C procedure NME-SC(A)</p><formula xml:id="formula_4">for p ? 1 to P do Ap ? binarize(A, p) Ap ? (Ap + A T p )/2 Lp ? Laplacian(?p) Up, ?p, V T p ? SVD(Lp) ep ? eigengap(?p) gp ? max(ep)/max(?p) r[p] ? p/gp end for p ? argmin(r) k ? argmax(ep) S ? Up[1, N ; 1, k] T C ? k-means(S, k) return C end procedure A.</formula><p>Steps of the Proposed Clustering Method 1) Affinity Matrix: Unlike the NJW algorithm, the affinity matrix A in our proposed framework is formed with raw cosine similarity values in (1) without a kernel or a scaling parameter. From all N speech segments in the given input utterance, we get N 2 similarity values as below:</p><formula xml:id="formula_5">a ij = d(w i , w j ),<label>(4)</label></formula><p>where i and j are indexes of the speech segments.</p><p>2) p-Neighbor Binarization: The cosine similarity values in the affinity matrix A are binarized to either 0 or 1 to mitigate the effect of unreliable similarity values. This can be done by converting the p largest similarity values in each row to 1 while zeroing out the rest of the values. p is an integer, and is determined by the NME analysis described later.</p><formula xml:id="formula_6">A p = binarize(A, p)<label>(5)</label></formula><p>3) Symmetrization: To transform the affinity matrix A p into an undirected adjacency matrix in a graph theory perspective, we perform symmetrization by taking an average of the original and the transposed version of A p as follows:</p><formula xml:id="formula_7">A p = 1 2 (A p + A T p ).<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4) Laplacian:</head><p>We use the unnormalized matrix for the Laplacian matrix computations <ref type="bibr" target="#b16">[16]</ref> in the following:</p><formula xml:id="formula_8">d i = N k=1 a ik D p = diag{d 1 , d 2 , ..., d N } L p = D p ?? p ,<label>(7)</label></formula><p>where N is the size of the matrix? p ? R N ?N in (6).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5) Singular Value Decomposition (SVD):</head><p>Perform SVD to obtain eigenvalues for the Laplacian matrix L p :</p><formula xml:id="formula_9">L p = U p ? p V T p .<label>(8)</label></formula><p>6) Eigengap Vector: Create an eigengap vector e p as follows, using the eigenvalues from ? p in <ref type="formula" target="#formula_9">(8):</ref> e p = [? p,2 ? ? p,1 , ? p,3 ? ? p,2 , ? ? ? , ? p,N ? ? p,N ?1 ], <ref type="bibr" target="#b8">(9)</ref> where ? p,i is the i-th sorted eigenvalue in ascending order, given p for the binarization process in step 2). 7) Normalized Maximum Eigengap (NME): The NME analysis is most critical for the auto-tuning part of the proposed spectral clustering algorithm, as we compare the NME values across every p and determine the proper p where DER is presumably minimized. We will discuss this in more detail in Section IV. The NME value g p for given p is defined as below:</p><p>g p = max(e p ) ? p,N + ,</p><p>where ? p,N = max(? p ) and is a very small value ( = 1 ? 10 ?10 ). We obtain the ratio r(p) between the pruning threshold p for the row-wise binarization and the NME value</p><formula xml:id="formula_11">g p : r(p) = p g p .<label>(11)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>8) Estimation of p,p:</head><p>The value r p is calculated throughout every p ? N ? [1, P ] and stored in the list r as below:</p><formula xml:id="formula_12">r = [r(1), r(2), ? ? ? , r(P )].<label>(12)</label></formula><p>Based on our observation, which we will discuss in Section IV as well, r(p) is a very good proxy for DER. Thus, we find the valuep which makes the minimum value of r. Consequently, the parameterp attempts to minimize DER: p = argmin(r).</p><p>With thisp, we estimate the number of clusters k:</p><formula xml:id="formula_14">k = argmax(ep).<label>(14)</label></formula><p>9) Spectral Embedding: We take the smallest k eigenvalues and their corresponding eigenvectors to obtain the matrix of k-dimensional spectral embeddings S ? R k?N :</p><formula xml:id="formula_15">S = Up[1, N ; 1, k] T = [s 1 , s 2 , ..., s N ].<label>(15)</label></formula><p>10) k-means Clustering: We use the k-means clustering algorithm <ref type="bibr" target="#b6">[7]</ref> to obtain k clusters from S.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IV. VALIDATION OF NME ANALYSIS</head><p>Since our approach of pruning the graph connections of the affinity matrix based on the p-neighbor binarization scheme is heavily dependent on the value of p, an in-depth analysis is needed for the relationship between the NME value g p and the pruning parameter p.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Eigengap and the Purity of Clusters</head><p>It has been known that the size of the eigengap can be used as a quality criterion for spectral clustering <ref type="bibr" target="#b16">[16]</ref>. The relation of the size of the eigengap to the purity of clusters has been investigated in <ref type="bibr" target="#b16">[16]</ref>, <ref type="bibr" target="#b17">[17]</ref> using the perturbation theory, more specifically the Davis-Kahan theorem. In this work, we use the NME value g p to gauge the purity of the clusters, as the purity is directly linked to speaker diarization performance. In doing so, we search the most probable k and the most adequate p altogether using the eigenvalues. <ref type="figure">Fig. 1</ref>. An example plot that shows the relationship between the NME value gp and the binarization parameter p. The plot of ratio between p and gp in (b) is reflecting the trend of the DER plot in (c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. p Versus g p</head><p>Having a higher p value in an affinity matrix A generally leads to a larger g p value with the higher purity measure of the clusters, since the graph gets more connections within each cluster. However, since all the connections have the equal weight of 1, an excessive amount of connections (i.e., high p value) gives rise to a poor estimation of the number of clusters followed by a poor diarization result, although it gives a high g p value. This can be easily understood by thinking of an affinity matrix whose elements are all equal to 1, which would always yield only one cluster regardless of the actual number of clusters. As depicted in <ref type="figure">Fig.1(a)</ref>, we see a gradual increase of g p as p increases while this tendency stops around at p = 50 in <ref type="figure">Fig.1(a)</ref>. As we increase p even more from p = 50, the estimated number of clusters drops and g p increases again, meaning that we get a higher g p value with a smaller estimated number of clusters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. r(p) = p/g p as a Good Proxy for DER</head><p>Since the excessive amount of connections leads to poor clustering results, p value should be minimized to get an accurate number of clusters, while the g p value should be maximized to get the higher purity of clusters. Thus, we calculate the ratio r(p) = p/g p to find the best p value by getting a size of the p value in proportion to g p . It is clearly shown in <ref type="figure">Fig.1(b)</ref> and <ref type="figure">Fig.1(c)</ref> that the ratio of p to g p , r(p) is a very good proxy for DER. As described in <ref type="bibr" target="#b10">(11)</ref>, r(p) indicates the slope in the p versus g p plot. The lowest r(p) value means that the resulting clusters have the highest purity measure g p in proportion to p. In <ref type="figure">Fig.1</ref>, the solid vertical lines show the estimated point of the lowest DER, while the dotted vertical lines indicate where the actual DER is the lowest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. EXPERIMENTAL RESULTS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Test Setup</head><p>To test the performance of the contribution of the clustering algorithms, we used the same speaker embedding extractor proposed in <ref type="bibr" target="#b13">[13]</ref>, <ref type="bibr" target="#b18">[18]</ref> for all the experiments in this work. The evaluation method and metrics followed <ref type="bibr" target="#b19">[19]</ref>. The estimated number of speakers was limited to a maximum of eight speakers for all the experiments. We tested the following five different clustering algorithms: 1) COS+NJW-SC: This is the NJW algorithm in <ref type="bibr" target="#b7">[8]</ref> which incorporates the cosine similarity measure. The number of clusters are estimated by the method in <ref type="bibr" target="#b0">[1]</ref>.</p><p>2) COS+AHC: This setup is identical to <ref type="bibr" target="#b13">[13]</ref>, <ref type="bibr" target="#b18">[18]</ref>, using the AHC algorithm, except we use cosine similarity instead of PLDA.</p><p>3) PLDA+AHC: This setup, identical to <ref type="bibr" target="#b13">[13]</ref>, <ref type="bibr" target="#b18">[18]</ref>, is AHC coupled with PLDA. The PLDA model is adapted with each development set. 4) COS+B-SC: This is our proposed spectral clustering framework with the p-neighbor binarization scheme only, without the NME based auto-tuning approach. i.e., p is optimized on each development set instead of usingp from <ref type="bibr" target="#b13">(13)</ref>.</p><p>5) COS+NME-SC: This is our proposed NME-based clustering algorithm, which includes the proposed auto-tuning approach. No hyper-parameter tuning or optimization is done. The p value is searched in the range of <ref type="bibr">[1, N 4</ref> ] for each utterance, where N is the number of total segments in a given input utterance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Datasets</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>1) NIST SRE 2000 (LDC2001S97):</head><p>This dataset is the most widely used for speaker diarization in recent literature, which is referred to as CALLHOME. CALLHOME contains two to seven speakers for each utterance. For the CALLHOME dataset, twofold cross validation is conducted to match the test conditions with <ref type="bibr" target="#b13">[13]</ref>, <ref type="bibr" target="#b18">[18]</ref> for all the experiments.</p><p>2) CALLHOME American English Speech (CHAES) (LDC97S42): This is a corpus that only contains English speech data with two to four speakers per each utterance. CHAES is divided into a train, dev, and eval set, and we report the results on the eval set. Both the train set and the dev set are used for parameter turning. The subset of CHAES that only contains two speakers is referred to as CH109 in the literature, and the CH109 dataset is tested by providing the number of speakers ahead to all the tested systems (i.e., no estimation of the number of speakers involved in CH109). The rest of the utterances in CHAES are used as a dev set for CH109.</p><p>3) RT03 (LDC2007S10): RT03 is an English dataset and contains utterances with two to four speakers. We use the split provided by the authors in <ref type="bibr" target="#b4">[5]</ref> using only Switchboard utterances. C. Experiments 1) Oracle SAD: <ref type="table" target="#tab_0">Table I</ref> shows the experimental results with the oracle SAD. Note that, except for RT03 dataset, NME-SC shows very competitive performances with no parameter tuning at all. The DER of NME-SC is impressive, especially for the CALLHOME dataset, where each utterance has the varying number of speakers, and our proposed auto-tuning approach gains many advantages.</p><p>2) System SAD: <ref type="table" target="#tab_0">Table II</ref> shows the experimental results for the system SAD. We used the ASpIRE SAD model <ref type="bibr" target="#b20">[20]</ref> that is publicly available. With the system SAD setting, which is closer to scenarios in the wild, NME-SC outperforms all the other methods except for RT03, where NME-SC shows very close performance to dev-set-optimized COS+B-SC method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Discussions</head><p>The performance gain from NJW-SC to B-SC indicates that the p-neighbor binarization scheme with the unnormalized Laplacian approach can be effective, as it shows very distinctive performance difference. More importantly, the performance gain from B-SC to NME-SC shows that the value of p can be effectively auto-tuned even without optimizing on a development set. We also see the performance improvement of NME-SC over PLDA+AHC, hinting that our proposed clustering scheme can still get a competitive speaker diarization result without employing PLDA as a distance measure. These all validate the effectiveness of the proposed auto-tuning spectral clustering framework with the NME analysis.</p><p>VI. CONCLUSIONS In this paper, a new framework of auto-tuning spectral clustering was introduced. The experimental results show that our proposed NME-based spectral clustering method is competitive in performance while not requiring any hyperparameter tuning. It is promising that the proposed method outperformed the widely used AHC method with PLDA. Further work will include a way to theoretically analyze the reason that the ratio of the tuning parameter p to the NME value g p is a proxy for DER and how it could be generalized in various data on real production systems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I EXPERIMENTAL</head><label>I</label><figDesc>Oracle SAD Spk. Err. (DER) Spk. Err. (DER) Spk. Err. (DER) Spk. Err. (DER) Spk. Err.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">RESULTS WITH THE ORACLE SAD</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">COS+NJW-SC</cell><cell cols="2">COS+AHC</cell><cell cols="2">PLDA+AHC</cell><cell cols="2">COS+B-SC</cell><cell cols="2">COS+NME-SC</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">(DER)</cell></row><row><cell cols="2">CALLHOME</cell><cell>24.05</cell><cell></cell><cell>21.13</cell><cell></cell><cell>8.39</cell><cell>8.78</cell><cell></cell><cell>7.29</cell><cell></cell></row><row><cell cols="2">CHAES-eval</cell><cell>30.31</cell><cell></cell><cell>31.99</cell><cell></cell><cell>24.27</cell><cell>4.4</cell><cell></cell><cell>2.48</cell><cell></cell></row><row><cell cols="2">CH109</cell><cell>13.06</cell><cell></cell><cell>29.8</cell><cell></cell><cell>9.72</cell><cell>2.25</cell><cell></cell><cell>2.63</cell><cell></cell></row><row><cell cols="2">RT03</cell><cell>6.56</cell><cell></cell><cell>5.66</cell><cell></cell><cell>1.73</cell><cell>0.88</cell><cell></cell><cell>2.21</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">TABLE II</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">EXPERIMENTAL RESULTS WITH THE SYSTEM SAD</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">COS+NJW-SC</cell><cell cols="2">COS+AHC</cell><cell cols="2">PLDA+AHC</cell><cell cols="2">COS+B-SC</cell><cell cols="2">COS+NME-SC</cell></row><row><cell>System SAD</cell><cell cols="2">DER Spk. Err.</cell><cell cols="2">DER Spk. Err.</cell><cell cols="2">DER Spk. Err.</cell><cell cols="2">DER Spk. Err.</cell><cell cols="2">DER Spk. Err.</cell></row><row><cell cols="2">CALLHOME 26.99</cell><cell>20.67</cell><cell>20.14</cell><cell>13.82</cell><cell>12.96</cell><cell>6.64</cell><cell>13.23</cell><cell>6.91</cell><cell>11.73</cell><cell>5.41</cell></row><row><cell cols="2">CHAES-eval 12.04</cell><cell>7.73</cell><cell>9.96</cell><cell>5.85</cell><cell>5.52</cell><cell>1.45</cell><cell>5.07</cell><cell>1.00</cell><cell>5.04</cell><cell>0.97</cell></row><row><cell>CH109</cell><cell>5.85</cell><cell>1.56</cell><cell>28.92</cell><cell>24.63</cell><cell>6.89</cell><cell>2.6</cell><cell>5.75</cell><cell>1.46</cell><cell>5.61</cell><cell>1.32</cell></row><row><cell>RT03</cell><cell>6.42</cell><cell>3.88</cell><cell>6.24</cell><cell>4.7</cell><cell>3.53</cell><cell>0.99</cell><cell>3.1</cell><cell>0.56</cell><cell>3.13</cell><cell>0.59</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A spectral clustering approach to speaker diarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 9th Int. Conf. Spoken Lang. Process</title>
		<meeting>9th Int. Conf. Spoken Lang. ess</meeting>
		<imprint>
			<date type="published" when="2006-09" />
			<biblScope unit="page" from="2178" to="2181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On the use of agglomerative and spectral clustering in speaker diarization of meetings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hernando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Odyssey: The Speaker and Lang. Recognit. Workshop</title>
		<meeting>Odyssey: The Speaker and Lang. Recognit. Workshop</meeting>
		<imprint>
			<date type="published" when="2012-06" />
			<biblScope unit="page" from="130" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the use of spectral and iterative methods for speaker diarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Annual Conf. Int. Speech Commun. Association</title>
		<meeting>13th Annual Conf. Int. Speech Commun. Association</meeting>
		<imprint>
			<date type="published" when="2012-09" />
			<biblScope unit="page" from="482" to="485" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Unsupervised methods for speaker diarization: An integrated and iterative approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Shum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Glass</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Audio, Speech, Lang. Process</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2015" to="2028" />
			<date type="published" when="2013-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Speaker diarization with LSTM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Downey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Mansfield</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">L</forename><surname>Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust., Speech, Signal Process</title>
		<meeting>IEEE Int. Conf. Acoust., Speech, Signal ess</meeting>
		<imprint>
			<date type="published" when="2018-04" />
			<biblScope unit="page" from="5239" to="5243" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">LSTM based similarity measurement with spectral clustering for speaker diarization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bredin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2019-09" />
			<biblScope unit="page" from="366" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Least squares quantization in PCM</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lloyd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inf. Theory</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="137" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On spectral clustering: Analysis and an algorithm</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint>
			<date type="published" when="2002-12" />
			<biblScope unit="page" from="849" to="856" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Probabilistic linear discriminant analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eur. Conf. Comput. Vision</title>
		<meeting>Eur. Conf. Comput. Vision</meeting>
		<imprint>
			<date type="published" when="2006-05" />
			<biblScope unit="page" from="531" to="542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Probabilistic linear discriminant analysis for inferences about identity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Prince</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Elder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE 11th Int. Conf. Comput. Vision</title>
		<meeting>IEEE 11th Int. Conf. Comput. Vision</meeting>
		<imprint>
			<date type="published" when="2007-10" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Speaker diarization using deep neural network embeddings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Garcia-Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccree</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc</title>
		<meeting>null</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">IEEE Int. Conf. Acoust., Speech, Signal Process</title>
		<imprint>
			<biblScope unit="page" from="4930" to="4934" />
			<date type="published" when="2017-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Diarization is hard: Some experiences and lessons learned for the JHU team in the inaugural DIHARD challenge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mccree</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Garcia-Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Villalba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maciejewski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Manohar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dehak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. INTERSPEECH</title>
		<meeting>INTERSPEECH</meeting>
		<imprint>
			<date type="published" when="2018-09" />
			<biblScope unit="page" from="2808" to="2812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Callhome diarization recipe using x-vectors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Snyder</surname></persName>
		</author>
		<ptr target="https://david-ryan-snyder.github.io/2018/05/04/modelcallhomediarizationv2.html" />
	</analytic>
	<monogr>
		<title level="j">Github</title>
		<imprint>
			<date type="published" when="2018-05-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Self-tuning spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zelnik-Manor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Adv. Neural Inf. Process. Syst</title>
		<meeting>Adv. Neural Inf. ess. Syst</meeting>
		<imprint>
			<date type="published" when="2005-12" />
			<biblScope unit="page" from="1601" to="1608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Spectral clustering for multi-type relational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd Int. Conf. Mach. Learn</title>
		<meeting>23rd Int. Conf. Mach. Learn</meeting>
		<imprint>
			<date type="published" when="2006-06" />
			<biblScope unit="page" from="585" to="592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A tutorial on spectral clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Von</forename><surname>Luxburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. and Comput</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="395" to="416" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Matrix Perturbation Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Academic Press</publisher>
			<pubPlace>Boston, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">X-vectors: Robust DNN embeddings for speaker recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Snyder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Garcia-Romero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khudanpur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Int. Conf. Acoust., Speech, Signal Process</title>
		<meeting>IEEE Int. Conf. Acoust., Speech, Signal ess</meeting>
		<imprint>
			<date type="published" when="2018-04" />
			<biblScope unit="page" from="5329" to="5333" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The rich transcription 2006 spring meeting recognition evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Fiscus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ajot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Garofolo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Int. Workshop Mach. Learn. Multimodal Interaction</title>
		<meeting>Int. Workshop Mach. Learn. Multimodal Interaction</meeting>
		<imprint>
			<date type="published" when="2006-05" />
			<biblScope unit="page" from="309" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The Kaldi speech recognition toolkit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Povey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghoshal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Boulianne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Burget</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Glembek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hannemann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Motlicek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Workshop Autom. speech Recognit. and Underst</title>
		<meeting>IEEE Workshop Autom. speech Recognit. and Underst</meeting>
		<imprint>
			<date type="published" when="2011-12" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
