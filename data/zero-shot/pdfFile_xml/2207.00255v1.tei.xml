<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Trajectory Forecasting on Temporal Graphs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G?rkay</forename><surname>Aydemir</surname></persName>
							<email>gorkay.aydemir@metu.edu.trkakan20</email>
							<affiliation key="aff0">
								<orgName type="institution">Middle East Technical University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adil</forename><surname>Kaan Akan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">KUIS AI Center</orgName>
								<orgName type="institution">Ko? University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fatma</forename><surname>G?ney</surname></persName>
							<email>fguney@ku.edu.tr</email>
							<affiliation key="aff1">
								<orgName type="department">KUIS AI Center</orgName>
								<orgName type="institution">Ko? University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Trajectory Forecasting on Temporal Graphs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T21:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Predicting future locations of agents in the scene is an important problem in self-driving. In recent years, there has been a significant progress in representing the scene and the agents in it. The interactions of agents with the scene and with each other are typically modeled with a Graph Neural Network. However, the graph structure is mostly static and fails to represent the temporal changes in highly dynamic scenes. In this work, we propose a temporal graph representation to better capture the dynamics in traffic scenes. We complement our representation with two types of memory modules; one focusing on the agent of interest and the other on the entire scene. This allows us to learn temporally-aware representations that can achieve good results even with simple regression of multiple futures. When combined with goal-conditioned prediction, we show better results that can reach the state-of-the-art performance on the Argoverse benchmark. * Work done during an internship at KUIS AI Center. arXiv:2207.00255v1 [cs.CV] 1 Jul 2022</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Self-driving is a complex task, therefore the standard approach is to divide it into separate modules. A typical modular pipeline consists of several modules focusing on different aspects of the problem such as perception, prediction, planning, and control. In this work, we assume that the perceptual input including the detections, the tracks, and the map information is provided in a bird's eye view representation, and focus on prediction by proposing a motion forecasting algorithm. Motion forecasting is the problem of predicting the future location of traffic agents for safe navigation. This requires understanding the scene by representing the map information as well as the interactions of agents with the scene and with each other. Furthermore, there are multiple plausible future scenarios which need to be considered by the following planner module in the stack.</p><p>Previous work on motion forecasting mostly focuses on learning representations of the scene, specifically the map and the agent history, i.e. the previous locations of agents. While early attempts <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b2">3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b8">9]</ref> create a rasterized representation that can easily be processed with a 2D Convolutional Neural Network (CNN), recent work mostly focuses on the spatial aspect with a lane graph <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref> or vector representations <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b14">15]</ref>. An explicit representation of the topology and interactions with a Graph Neural Network (GNN) leads to better representations of the surrounding environment as well as the agent interactions. In this work, we adapt the vectorized representation for the spatial aspect of the scene and then focus on the temporal aspect.</p><p>The temporal aspect is mostly ignored in motion forecasting by simply dividing the time into two: the present with the information up to now and the future to be predicted. Typically, the history of each agent is independently encoded with a recurrent neural network <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref> or simply with a 1D CNN <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12]</ref>. This approach fails to represent the evolving interactions between the agents and their relation with the scene elements through time. We claim that learning temporal dynamics plays a crucial role in prediction. Consider a scenario where two vehicles approach an intersection, their speed history changing together decides their future locations, for example one of them slowing down and letting the other vehicle continue with the turn at its current speed. Our results show improvements in these scenarios where the temporal dynamics are crucial for future prediction. Ye et al. <ref type="bibr" target="#b23">[24]</ref> recently proposed to model the temporal aspect by focusing on the dynamics of the agent of interest only. While this improves the results, it overlooks the dynamics in the other parts of the scene that might still be relevant for predicting the next location of the agent of interest. We propose to learn a temporal graph representation that is aware of the entire scene dynamics.  <ref type="figure">Figure 1</ref>: Temporal Graph Learning for Motion Forecasting. We learn a dynamic scene representation where each timestamp is encoded as a temporal graph. We keep track of changes to the agent of interest with a sequential memory and to the entire scene with a scene memory. We generate goal proposals by using both the scene memory and the motion information related to the agent of interest. Finally, we predict the full trajectories conditioned on the refined goal locations.</p><p>We construct a temporal graph representing the dynamic scene with agents moving and interacting with the scene and with each other. We dynamically update the features of each scene element in a way informed by the other scene elements such as the other agents in the scene and nearby road segments. While these interactions are modelled with a static GNN in previous work, we model the interactions on the graph temporally by considering the time axis in the updates. In addition, we introduce two memory modules; one specific to the agent of interest and another to the entire scene. Our experiments show the importance of dynamic updates and the two types of memory modules.</p><p>Another aspect in motion forecasting is the multi-modality which can be addressed by predicting multiple futures. While there are various approaches that predict a heatmap <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b24">25]</ref> or learn a distribution <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b1">2,</ref><ref type="bibr" target="#b26">27,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b27">28]</ref> to sample from, we follow a simpler approach that is commonly used in the literature by generating a set of predictions and applying the loss only on the closest one during training. Common metrics used in motion forecasting evaluate both the quality and the diversity of endpoint predictions. As shown in recent work <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b22">23]</ref>, addressing these two aspects together is challenging. While one option is to develop separate objectives optimizing each metric, we instead focus on learning representations that are good at predicting accurate endpoint distributions without sacrificing diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Context Representation: Representing the context, i.e. the surrounding environment is an important aspect of motion forecasting. Typically, the context consists of a map in 2D bird's eye view (BEV) representation as well as the past trajectories of agents on the map. There are two types of approaches to context representation: rasterized and vectorized. In rasterized representation, the context is rastered and encoded with a 2D CNN. Despite the convenience of CNNs especially when predicting a heatmap <ref type="bibr" target="#b22">[23]</ref>, 2D raster image cannot explicitly represent the complex topology of the map such as long range connectivity and hierarchy between the scene elements due to the limited receptive field size. Vector representations initially proposed in VectorNet <ref type="bibr" target="#b12">[13]</ref> can capture the complex topology of the road networks as well as the spatial locality of semantic entities with a hierarchical representation. Several followup work including ours <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b28">29]</ref> build on VectorNet to represent the context. Differently, we also learn a temporal representation of the scene.</p><p>Temporal Encoding: Rossi et al. propose to learn changes on a massive graph, e.g. Wikipedia, Twitter, with a temporal graph neural network <ref type="bibr" target="#b29">[30]</ref>. We also propose to learn a temporal graph representation but for multiple, smaller graphs representing scenes observed through limited time intervals. The number of time steps are smaller but the changes are more dynamic through interactions between agents. Recent work called TPCN <ref type="bibr" target="#b23">[24]</ref> shows the importance of learning temporal relations in motion forecasting. Similar to us, in TPCN, there is a spatial module for a global representation and a temporal module for learning dynamics. Differently, multi-interval learning for temporal representation is specialized to the agent of interest in TPCN, whereas in our case, we learn temporal relations between all the entities. This way, learned dynamics can still help even when the interactions of the agent of interest is limited but there are other moving agents in the scene. Besides, predictions should be informed by the scene dynamics occurring in spatially further regions than the agent.</p><p>Goal-Conditioned Prediction: Earlier methods <ref type="bibr" target="#b9">[10,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b31">32]</ref> directly predict K full trajectories based on the features of the agent of interest. However, this approach may fail to cover diverse future locations on the map since it only focuses on the agent of interest. Some methods <ref type="bibr" target="#b20">[21]</ref> follow an auto-regressive approach which may lead to drift due to accumulating error in consecutive timestamps. Another line of work <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b32">33]</ref> first predicts the endpoint of future trajectory and then conditioned on the predicted endpoint, the whole trajectory is predicted. We also follow this target-based approach because predicting trajectory is mostly straightforward once the target endpoint is identified. The target-based methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b14">15]</ref> typically follow a two-stage approach. First, a distribution over target locations is predicted, either to find the closest lane to the endpoint <ref type="bibr" target="#b13">[14]</ref> or densely over all possible locations on a grid <ref type="bibr" target="#b14">[15]</ref>. Finding the closest lane is typically not accurate enough to locate the target point, therefore an offset is also predicted with respect to the lane <ref type="bibr" target="#b13">[14]</ref>. In this work, we show that our learned temporal representation is capable of directly regressing the target locations without scoring lanes or dense grid locations. Another option is to predict a heatmap representing the probability distribution of the target location <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b10">11]</ref>. In heatmap-based approaches, the sampling strategy becomes very important. While it can be optimized for very low miss rates, it is difficult to optimize it together with the endpoint accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>Given the past states of agents in the scene and an HD map of the environment, our goal is to predict the future locations of the agent of interest. Our approach illustrated in <ref type="figure">Fig. 1</ref> is based on the following observation: traffic scenes consist of a dynamic part with agents moving through time and a static context which remains unchanged except for the interactions with the dynamic part. We first build a holistic representation of the static part and then model the dynamics as a temporal graph on top of it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Scene Encoding</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Temporal Graph Representation</head><p>We construct a dynamic graph to represent the state of the scene at time t as a graph G t = {V t , E t } where V t and E t denote the set of vertices and undirected edges on the graph. Each vertex v i t ? V t corresponds to a lane segment or an agent i at time t. Due to the cost of a fully connected graph at each time step, we selectively build two types of edges between different types of nodes. We first connect each agent to the lane segments in their vicinity based on a threshold. The undirected edge between an agent and the surrounding lane segments allows to represent the current location of an agent on the map as well as the occupancy of map locations through time. We also connect the agent of interest to all the other agents at that timestamp to model dynamic interactions between agents.</p><p>Let F t denote the feature matrix at time t where each row corresponds to a vertex v i t and d k denote the length of key features. We perform dynamic updates on the features through time using self attention <ref type="bibr" target="#b33">[34]</ref> between the connected nodes:</p><formula xml:id="formula_0">F t = softmax F Q t?1 F K t?1 T ? d k F V t?1<label>(1)</label></formula><p>where F Q t?1 , F K t?1 and F V t?1 are linear transformations of the feature matrix from the previous timestamp. After initializing the node features from VectorNet, we accumulate temporal information to learn the dynamics. We explicitly encode the time information to form the final feature matrix F t :</p><formula xml:id="formula_1">f i t = g 1 f i t + ? time (t) (2)</formula><p>where f i t denotes the features of the agent i at time t, ? time (?) is a time encoder as proposed in <ref type="bibr" target="#b29">[30]</ref> and g 1 is simply a two-layer MLP.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Memory Modules</head><p>An important aspect of learning dynamics is building a memory to remember necessary information from past steps. In Temporal Graph Networks <ref type="bibr" target="#b29">[30]</ref>, Rossi et al. propose to keep track of changes with a memory for every node and edge on the graph. While it is shown to be crucial for node or edge addition or removal tasks in case of TGN, such a fine-grained memory module is not only infeasible in our case but also excessive for predicting the trajectory of a single agent of interest. On the other hand, to predict future reliably, the agent of interest needs to remember the changes in its representation as well as the changes to the whole scene through time. Therefore, we consider two types of memory modules in our temporal graph representation: one for the agent of interest and another for the whole scene.</p><p>Given the temporal features of the agent of interest f t at time t, we keep track of changes to its representation sequentially with a GRU:</p><formula xml:id="formula_2">h seq t = GRU f t , h seq t?1<label>(3)</label></formula><p>where h t refers the hidden state of the GRU. Note that we drop the superscript on the node features as we build the sequential memory model only for the agent of interest.</p><p>We introduce another memory module for the whole scene: scene memory. We initialize the scene memory at time t by applying a linear layer to the feature matrix at that time step:</p><formula xml:id="formula_3">M (0) t = g 0 (F t )</formula><p>. We then build the scene memory module as layers of self attention operations (4) followed by layer normalization at each layer l (5).</p><formula xml:id="formula_4">M (l) t = softmax ? ? ? M (l?1),Q t M (l?1),K t T ? d k ? ? ? M (l?1),V t (4) M (l) t = ? norm M (l) t<label>(5)</label></formula><p>After the last layer L, we aggregate all the node features with a max pool operation (6) to summarize the relevant scene features in m (L) t and then relate them across time with a GRU <ref type="bibr" target="#b6">(7)</ref>.</p><formula xml:id="formula_5">m (L) t = ? pool M (L) t (6) h mem t = GRU(m (L) t , h mem t?1 )<label>(7)</label></formula><p>In addition to the memory modules, we use cross attention between the temporally updated features of the agent of interest and the context elements including the lanes and the other agents following <ref type="bibr" target="#b14">[15]</ref>. The final representation for the agent of interest contains the lane and agent features as the result of cross attention and the temporal features (2) including their initialization for learning the change as well as the memory modules for the agent (3) and the whole scene <ref type="bibr" target="#b6">(7)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Goal-Conditioned Trajectory Prediction</head><p>Several previous work <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b14">15]</ref> address multi-modality by predicting K number of trajectories for a scene. The loss is calculated based on the prediction that has the closest endpoint to the ground truth endpoint. A recent line of work <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b28">29]</ref> first predicts the endpoints as the target locations, and then, conditioned on the targets, predicts the full trajectory. We follow a similar goal-conditioned approach but in a more focused way on target locations. While the common approach in this line of work is to score a large number of map elements first, in some cases even densely <ref type="bibr" target="#b14">[15]</ref>, and then refine them, it distributes the focus evenly to relevant target locations and irrelevant, distant locations on the map. Therefore, we first regress K number of goal locations, and then focus on refinement and scoring.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Goal Prediction</head><p>We initially predict K number of goal locations. As indicated by the failure cases of the previous work <ref type="bibr" target="#b23">[24]</ref>, goal locations need to be constrained by both the motion and the map information. We obtain the motion information from the features of the agent of interest as explained at the end of Section 3.1.2. Although the agent of interest interacts with the scene, its features do not directly correspond to the scene elements. Therefore, for map constrained goal locations, we construct a map feature f map by max-pooling the feature of the lane nodes in the scene graph, L, and concatenating them with the updated scene memory from <ref type="formula" target="#formula_5">(7)</ref>:</p><formula xml:id="formula_6">f map T = g 2 (? pool (L T ) , ? agg (h mem T ))<label>(8)</label></formula><p>where T is the last observed time step before prediction and g 2 (?) is a 2-layer MLP. We generate half of the proposals from the features of the agent of interest and the other half from the map features.</p><p>Once the proposals are created, we refine and score them in a way informed by the scene features. Our goal is to assign high scores to the proposals that are consistent with dynamic scene features. We first encode the proposals that are 2D coordinates and then apply cross attention with scene features F T to place it in our map representation before refinement and scoring. Our objective is to minimize the distance between the predicted goal location that is the closest to the ground truth with a smooth-L ? loss and also to increase its score with respect to the other proposals with a cross entropy loss.</p><p>We predict the full trajectory conditioned on K goal locations and apply a smooth-L ? loss to minimize the distance between the ground truth and the predicted trajectory for the best goal prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>Dataset: We use Argoverse motion forecasting dataset <ref type="bibr" target="#b34">[35]</ref> which has more than 300K sequences with the map information and the agent trajectories. Each sequence or a scene is 5 seconds long sampled at 10 Hz, corresponding to 50 time steps. Given the map information and the agent history in the first 2 seconds (20 frames), the goal is to predict the trajectory of the agent of interest for the next 3 seconds, (30 frames). We follow the original training, validation, and test splits.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics:</head><p>We use four different metrics to evaluate our work. (i) Minimum Average Displacement Error (min-ADE) is the average displacement error between the ground truth trajectories and the predicted trajectory that has the closest final step to the ground truth endpoint over all time steps. (ii) Minimum Final Displacement Error (min-FDE) is the displacement error between the best final step prediction and the ground truth final step. minADE K and minFDE K refers to the minimum over K predictions. (iii) Miss Rate (MR) is the percentage of the scenes where none of the predicted trajectory endpoints are not within a threshold (2 meters) to the ground truth endpoint. (iv) Brier-minFDE (b ? minFDE) is the official metric of the challenge by also considering the probability distribution p of a trajectory. Specifically, b ? minFDE is calculated by adding a probability score, (1 ? p) 2 to the minFDE value. We report the values for K = 6.</p><p>Training Details: We construct the graph by including the lanes that are closer than 50 meters to the agent of interest in terms of Manhattan distance. We normalize and rotate the scene with respect to the position and the orientation of the agent of interest. We create an edge between a lane segment and an agent if the distance between them is less than 2 meters. We train our models with a batch size of 64 for 36 epochs. We use Adam optimizer <ref type="bibr" target="#b35">[36]</ref> with an initial learning rate of 1 ? 10 ?4 and divide it by 5 at the end of 24 th and 30 th epochs. We randomly scale the scene by using a scale factor in the range of [0.75, 1.25] and also apply random translations to the polylines for data augmentation. We initialize the global context encoder of our model from a pre-trained VectorNet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ablation Study</head><p>What is the contribution of each component proposed? We perform an ablation study to measure the effect of each component on the performance in  <ref type="table" target="#tab_0">Table 1</ref>: Ablation Study. We evaluate the contribution of each component proposed including the temporal graph (TG), the sequential memory (Seq), the scene memory (Scene), and the goal conditioning (Goal Pred.) with also an additional loss on the best endpoint prediction (Goal Loss).</p><p>initialization in the first row. This shows the importance of learning temporal dynamics in the scene. On top of the temporal graph, we measure the effect of two types of memory modules (Section 3.1.2).</p><p>The scene memory provides temporal information about the overall scene and the sequential memory about temporal dynamics related to the agent of interest such as speed changes. The sequential memory for the agent of interest only (Seq) degrades the performance slightly but the scene memory (Scene) improves it, and using them together results in the best performance. This shows the importance of propagating information from past time steps together with scene information.  <ref type="table">Table 2</ref>: Performance based on Feature Representation. We compare the performance of different methods by simply regressing multiple outputs without any target sampling or goal conditioning to highlight the importance of learned representations. Temporal representation learning methods, i.e. TPCN and ours, outperform the others, showing the importance of learning temporal dynamics. How useful is the learned temporal representation? In order to measure the effect of learning a temporal representation, in <ref type="table">Table 2</ref>, we compare our method to the other methods by discarding the effect of goal conditioning in target-based methods <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref> and target sampling in a heatmap-based method <ref type="bibr" target="#b22">[23]</ref>. Following the previous work on representation learning <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38]</ref> where an MLP is trained on top of a frozen backbone to measure the quality of a learned representation, we train an MLP on top of our backbone to directly regress K trajectories. The more informative the features extracted by the backbones are, the better the predicted trajectories will be. As can be seen from <ref type="table">Table 2</ref>, the two methods, TPCN <ref type="bibr" target="#b23">[24]</ref> and ours, which learn temporal representations outperform the other methods. This shows the importance of learning dynamics independent of other factors.</p><p>What is the role of goal prediction? In the upper part of <ref type="table" target="#tab_0">Table 1</ref>, we basically regress K trajectories directly. In the bottom part, we measure the importance of goal prediction by first predicting K goal locations and then predicting the full trajectories conditioned them. Goal conditioning improves the performance in terms of both minFDE and b-minFDE. Predicting the endpoint accurately is crucial since we condition on it to predict the trajectory next. Therefore, we apply an additional goal loss on the best endpoint directly which results in the best performance in all metrics. We also ablate the source, i.e. which features to use, for goal prediction (Supplementary) and find that using both the map and the motion information improves the results in terms of MR and b-minFDE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Comparison to Previous Work</head><p>We compare our method's performance with the other published methods on both the validation set <ref type="table">(Table 4</ref>) and the leaderboard (   <ref type="table">Table 4</ref>: Results on Argoverse Validation Set. Our method is among the top-performing methods, the second in minADE 6 , minFDE 6 , top-3 in MR 6 . ? reproduced results using the official implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Qualitative Results</head><p>We visualize the effectiveness of our temporal graph representation in <ref type="figure">Fig. 2</ref> where we compare our model (Temporal) to a basic version without temporal graph (Naive) which is similar to vanilla VectorNet <ref type="bibr" target="#b12">[13]</ref> for global context encoding. Learning a temporal representation allows our model to generate more admissible trajectories respecting the borders of the map as shown in (2a) and (2b) and also to better capture the changes in speed as shown in (2c). In general (see Supplementary for more examples), the improvements are more pronounced at the intersections where the map information is crucial and there are typically significant alterations to the speed of the agents.</p><p>In (2d), we compare our goal conditioned prediction to simple regression without any goal conditioning by visualizing all the K trajectories predicted in orange. Even though simple regression performs well quantitatively <ref type="table" target="#tab_0">(Table 1)</ref>, we can cover more modes with goal conditioning. The simple regression misses the left turn. With goal conditioning, we can not only predict the left turn but also the possibility of a right turn as well as going straight, all in agreement with the map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion, Limitations, and Future Work</head><p>We propose a temporal graph representation for motion forecasting with two types of memory modules. Our method is among the top-performing methods on Argoverse, especially in terms of the official metric b-minFDE which measures the quality of the distributions. We address diversity with a simple goal conditioning, therefore our method is not among the top-performing methods in terms Ground-Truth Naive Best Temporal Best <ref type="bibr">(a)</ref> Ground-Truth Naive Best Temporal Best</p><formula xml:id="formula_7">(b)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ground-Truth Naive Best Temporal Best</head><p>(c)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Regression</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Goal Conditioned</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Comparison Ground-Truth Regression Best Goal-Cond. Best (d) <ref type="figure">Figure 2</ref>: Temporal Graph Representation with Goal Conditioning. We visualize the effect of learning temporal dynamics with our model (Temporal) to a basic version without temporal graph (Naive). Learning temporal dynamics leads to more admissible predictions agreeing with the map (a, b) and better capturing the changes to the velocity (c). We also show that goal conditioning results in better distributions by covering more modes compared to simple regression (d).</p><p>of MR. In future, we plan to focus on diversity by extending our temporal graph to a probabilistic formulation. Contemporary work <ref type="bibr" target="#b39">[40]</ref> shows the importance of learning a holistic representation for the scene rather than focusing on a single agent. In this work, we still focus on a single agent in prediction but we consider temporal relations for the whole scene. An interesting future work can build on our temporal representation to improve predictions for all the agents in the scene. In motion forecasting, algorithms rely on map info and perception input which may not be available in real life.</p><p>In this material which is the supplementary of the paper Trajectory Forecasting on Temporal Graphs, we explain our implementation and training settings in detail, provide quantitative results related to goal conditioning mentioned in the paper and comprehensive qualitative results including component comparison and fail cases with reasons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Implementation Details</head><p>In this section, we provide the details of our model for reproducibility. We will also publish our code when this work is published.</p><p>Scene Representation: In scene representation, we converted lanes and agent trajectories in vector form as in original VectorNet paper <ref type="bibr" target="#b12">[13]</ref>. We included all lanes that are closer than 50 meters to any agent in any past timestamp to make lane-agent interaction possible during temporal encoding. We kept the the feature vector size as 128.</p><p>Encoders: Both MLP inputs and outputs are vectors of size 128 except enhanced agent of interest feature. As explained in the paper, we used cross attention between all nodes and and lane nodes and concatenated them form the final enhanced agent of interest feature of size 384. We extracted features of 2D points to vectors of size 128 with point subgraph of DenseTNT <ref type="bibr" target="#b14">[15]</ref> which is 3 linear layers taking inputs of a 2D point and agent feature. We followed cross attention mechanism of DenseTNT <ref type="bibr" target="#b14">[15]</ref> to get final point features.</p><p>Graph Networks: We set layer number to 3 in subgraphs of VectorNet backbone and Scene Memory Encoder GNN where each layer is 2 layer MLP. We L 2 normalized Subgraph outputs and did not use map completion loss. Global graphs of VectorNet backbone and Temporal Graph is implemented as a single head self attention. If there is no edge between nodes in temporal graph, we set probability of node inclusion to 0 by using adjacency matrix of a timestamp as the mask before softmax operation as proposed in original transformer <ref type="bibr" target="#b33">[34]</ref>.</p><p>Goal Conditioned Prediction: We conditionally predicted the full trajectory with 2 layer MLP whose input is concatenation of the agent of interest feature and endpoint feature. To Similarly, we predicted endpoints by giving point features to 2 layer MLP.</p><p>Data Augmentations: Since we normalized the scene according to agent of interest, to scale the scene, we just multiplied the coordinate points with a value between [0.75, 1.25]. We added noise sampled from N (0, 0.2) to polyline locations as perturbation.</p><p>Training Details: As mentioned in the paper, we trained our models with a batch size of 64 for 36 epochs corresponding to 115848 iterations in 4 Tesla T4 GPUs in a distributed manner. We used Adam optimizer <ref type="bibr" target="#b35">[36]</ref> with an initial learning rate of 1 ? 10 ?4 and divide it by 5 at the end of 24 th and 30 th epochs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Quantitative Results</head><p>Does it matter which features we use for goal prediction? As explained in the methodology  <ref type="table" target="#tab_5">Table 5</ref>: Comparing Features for Goal Prediction. We compare the sources for goal prediction, including the map information (Context), the motion information of the agent of interest (Agent), and both where the half of the proposals come from the context and the other half from the agent.</p><p>of the paper, we propose to use both the map information and the motion information about the agent of interest for predicting goal locations. In <ref type="table" target="#tab_5">Table 5</ref>, we ablate this decision by comparing the performance using the map information only (Context), the motion information only (Agent), and using both as proposed. As can be seen from  <ref type="figure">Fig. 3</ref> and <ref type="figure">Fig. 4</ref>. Furthermore, we provide some fail cases with the reasons which are mode missing in <ref type="figure">Fig. 5</ref>, lane change in <ref type="figure" target="#fig_2">Fig. 6</ref>, inaccurate prediction with true prediction of future mode in <ref type="figure">Fig. 7</ref> and data defects in past input or future output sequence being also pointed out by other works <ref type="bibr" target="#b23">[24,</ref><ref type="bibr" target="#b31">32]</ref> in <ref type="figure">Fig. 8</ref> Naive</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Temporal (Reg.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Temporal (Goal Cond.)   Temporal (Reg.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Temporal (Goal Cond.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Comparison Naive Best Temporal (Reg.) Best Temporal (Goal Cond.) Best Ground-Truth <ref type="figure">Figure 7</ref>: Fail cases caused by inaccurate prediction despite true mode prediction. Although our model predicted the intention of agent of interest such as turns, it could not generate endpoints and trajectories close enough to ground truth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Naive</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Temporal (Reg.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Temporal (Goal Cond.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Comparison Naive Best Temporal (Reg.) Best Temporal (Goal Cond.) Best Ground-Truth</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Naive</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Temporal (Reg.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Temporal (Goal Cond.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Comparison Naive Best Temporal (Reg.) Best Temporal (Goal Cond.) Best Ground-Truth</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Naive</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Temporal (Reg.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Temporal (Goal Cond.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Prediction</head><p>Comparison Naive Best Temporal (Reg.) Best Temporal (Goal Cond.) Best Ground-Truth <ref type="figure">Figure 8</ref>: Fail cases caused by data defects. There are some faulty or uninformative input sequences as well as inconsistent ground truth sequences in the dataset resulting illogical trajectory predictions or high reported errors despite admissible predictions respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :Figure 4 :Figure 5 :</head><label>345</label><figDesc>Component Comparison (a) Component Comparison (b) Fail cases caused by mode missing. In some cases, our model could not catch the future intention of agent of interest vehicle such as left turn and U-turn.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 6 :</head><label>6</label><figDesc>Fail cases caused by lane change. In some cases, lane changes of agent of interest caused the fail. Since there is no sign about lane change on input sequences, lane changes remain hard to predict cases.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell>Temporal Encoding TG Seq Scene Goal Pred. Goal Loss Goal</cell><cell>minADE6</cell><cell>minFDE6</cell><cell>MR6</cell><cell>b-minFDE6</cell></row><row><cell></cell><cell>0.81</cell><cell>1.32</cell><cell>0.15</cell><cell>1.94</cell></row><row><cell></cell><cell>0.75</cell><cell>1.18</cell><cell>0.12</cell><cell>1.81</cell></row><row><cell></cell><cell>0.76</cell><cell>1.19</cell><cell>0.13</cell><cell>1.82</cell></row><row><cell></cell><cell>0.75</cell><cell>1.15</cell><cell>0.12</cell><cell>1.78</cell></row><row><cell></cell><cell>0.74</cell><cell>1.14</cell><cell>0.12</cell><cell>1.77</cell></row><row><cell></cell><cell>0.74</cell><cell>1.12</cell><cell>0.12</cell><cell>1.73</cell></row><row><cell></cell><cell>0.73</cell><cell>1.08</cell><cell>0.10</cell><cell>1.68</cell></row></table><note>. Adding the temporal graph (TG; Section 3.1.1) significantly improves the performance in each metric compared to the VectorNet</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3</head><label>3</label><figDesc>Note minADE 6 minFDE 6 MR 6 b-minFDE 6</figDesc><table><row><cell>HOME [23]</cell><cell>0.94</cell><cell>1.45</cell><cell>0.10</cell><cell>-</cell></row><row><cell>Autobot [39]</cell><cell>0.89</cell><cell>1.41</cell><cell>0.16</cell><cell>-</cell></row><row><cell>TPCN [24]</cell><cell>0.87</cell><cell>1.38</cell><cell>0.16</cell><cell>-</cell></row><row><cell>LaneRCNN [12]</cell><cell>0.90</cell><cell>1.45</cell><cell>0.12</cell><cell>2.15</cell></row><row><cell>Jean [19]</cell><cell>1.00</cell><cell>1.41</cell><cell>0.13</cell><cell>2.12</cell></row><row><cell>PRIME [32]</cell><cell>1.22</cell><cell>1.56</cell><cell>0.12</cell><cell>2.10</cell></row><row><cell>LaneGCN [10]</cell><cell>0.87</cell><cell>1.36</cell><cell>0.16</cell><cell>2.05</cell></row><row><cell>mmTransformer [29]</cell><cell>0.84</cell><cell>1.34</cell><cell>0.15</cell><cell>2.03</cell></row><row><cell>DenseTNT [15]</cell><cell>0.88</cell><cell>1.28</cell><cell>0.13</cell><cell>1.98</cell></row><row><cell>THOMAS [25]</cell><cell>0.94</cell><cell>1.44</cell><cell>0.10</cell><cell>1.97</cell></row><row><cell>Scene Transformer [40]</cell><cell>0.80</cell><cell>1.23</cell><cell>0.13</cell><cell>1.89</cell></row><row><cell>Ours</cell><cell>0.86</cell><cell>1.31</cell><cell>0.15</cell><cell>1.93</cell></row></table><note>). Our method is among the top-performing methods, top-3 in minADE and minFDE on both the validation and test, which shows the endpoint prediction and trajectory completion accuracy, and the second best in the official ranking metric b-minFDE.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Results on Argoverse Leaderboard (Test Set). Our method is among the top-performing methods, the second in main ranking metric b-minFDE 6 , and top-3 in minADE 6 , minFDE 6 .</figDesc><table><row><cell></cell><cell cols="3">minADE 6 minFDE 6 MR 6</cell></row><row><cell>HOME [23]</cell><cell>-</cell><cell>1.28</cell><cell>0.07</cell></row><row><cell>TPCN [24]</cell><cell>0.73</cell><cell>1.15</cell><cell>0.11</cell></row><row><cell>LaneRCNN [12]</cell><cell>0.77</cell><cell>1.19</cell><cell>0.08</cell></row><row><cell>PRIME [32]</cell><cell>-</cell><cell>-</cell><cell>0.08</cell></row><row><cell>LaneGCN [10]</cell><cell>0.71</cell><cell>1.08</cell><cell>-</cell></row><row><cell>mmTransformer [29]</cell><cell>0.71</cell><cell>1.15</cell><cell>0.11</cell></row><row><cell>DenseTNT-MR  ? [15]</cell><cell>0.82</cell><cell>1.28</cell><cell>0.07</cell></row><row><cell>DenseTNT-minFDE  ? [15]</cell><cell>0.76</cell><cell>1.05</cell><cell>0.10</cell></row><row><cell>Ours</cell><cell>0.73</cell><cell>1.08</cell><cell>0.10</cell></row></table><note>that our method can obtain competitive performance in all metrics without optimizing for any metric specifically. Without targeting the MR specifically, our method can reach 10% on the validation set which is the third best. This is because our method can predict a good endpoint distribution as shown by the second best b-minFDE on the test set.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc>, using both improves the results in terms of MR and b-minFDE.In this section, we first provide some qualitative results of the same scene from regressive model without temporal encoding [Naive], regressive model with temporal encoding [Temporal (Reg.)] and goal conditioned model with temporal encoding [Temporal (Goal Cond.)] in</figDesc><table><row><cell>C Qualitative Results</cell></row><row><cell>C.1 Component Comparison</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Multiple futures prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="15424" to="15434" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Desire: Distant future prediction in dynamic scenes with interacting agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Vernaza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Choy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Torr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chandraker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="336" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Multipath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.05449</idno>
		<title level="m">Multiple probabilistic anchor trajectory hypotheses for behavior prediction</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Multimodal trajectory predictions for autonomous driving using deep convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Radosavljevic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F.-C</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T.-K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Djuric</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2019 International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2090" to="2096" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Covernet: Multimodal behavior prediction using trajectory sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Phan-Minh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Grigore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Boulton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Beijbom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Wolff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="14074" to="14083" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Precog: Prediction conditioned on goals in visual multi-agent settings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rhinehart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mcallister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="2821" to="2830" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Intentnet: Learning to predict intention from raw sensor data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<idno>PMLR</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="947" to="956" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Rules of the road: Predicting driving behavior with a convolutional model of semantic interactions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8454" to="8462" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Prank: motion prediction based on ranking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Biktairov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Stebelev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rudenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Shliazhko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yangel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="2553" to="2563" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Learning lane graph representations for motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="541" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Gohome: Graph-oriented heatmap output for future motion estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sabatini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsishkou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stanciulescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moutarde</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.01827</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lanercnn: Distributed representations for graphcentric motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Vectornet: Encoding hd maps and agent dynamics from vectorized representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">TNT: Target-driven trajectory prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Sapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
	<note>PMLR, 2021. 1, 2, 3, 4</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">DenseTNT: End-to-end trajectory prediction from dense goal sets</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Social LSTM: Human trajectory prediction in crowded spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Ramanathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="961" to="971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Social GAN: Socially acceptable trajectories with generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Savarese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Alahi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2255" to="2264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">What-if motion prediction for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hartnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.10587</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Multi-head attention for multi-modal joint vehicle motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mercat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">El</forename><surname>Zoghby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sandou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Beauvois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Gil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2020 IEEE International Conference on Robotics and Automation (ICRA)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="9638" to="9644" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Plop: Probabilistic polynomial objects trajectory planning for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Buhet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wirbel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bursuc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Perrotton</surname></persName>
		</author>
		<idno>PMLR, 2020. 1</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Diverse and admissible trajectory forecasting through multimodal context understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Jadhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-P</forename><surname>Morency</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneous data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Salzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ivanovic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pavone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020" />
			<biblScope unit="page" from="683" to="700" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Home: Heatmap output for future motion estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sabatini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsishkou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stanciulescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moutarde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2021 IEEE International Intelligent Transportation Systems Conference (ITSC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="500" to="507" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Tpcn: Temporal point cloud networks for motion forecasting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gilles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sabatini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tsishkou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Stanciulescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Moutarde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thomas</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.06607</idno>
		<title level="m">Trajectory heatmap output with learned multi-agent sampling</title>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">DiversityGAN: Diversity-aware vehicle motion prediction via latent semantic sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Mcgill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Decastro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Leonard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">C</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Rosman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics and Automation Letters</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="5089" to="5096" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kitani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.04967</idno>
		<title level="m">Diverse trajectory forecasting with determinantal point processes</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Multi-modal trajectory prediction of surrounding vehicles with maneuver based lstms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Deo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Intelligent Vehicles Symposium (IV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1179" to="1184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multimodal motion prediction with stacked transformers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="7577" to="7586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Frasca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eynard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bronstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.10637</idno>
		<title level="m">Temporal graph networks for deep learning on dynamic graphs</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Multi-modal motion prediction with transformer-based neural network for autonomous driving</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lv</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2109.06446</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning to predict vehicle trajectories with model-based planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<idno>PMLR, 2021. 3</idno>
	</analytic>
	<monogr>
		<title level="m">Conference on Robot Learning</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Trajectory prediction with graph-based dual-scale context fusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2111.01592</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Attention is all you need. Advances in neural information processing systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Argoverse: 3d tracking and forecasting with rich maps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sangkloy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hartnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Carr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lucey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="8748" to="8757" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<idno>PMLR, 2020. 6</idno>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<biblScope unit="page" from="1597" to="1607" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Bootstrap your own latent-a new approach to self-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-B</forename><surname>Grill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Strub</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Altch?</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tallec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Richemond</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Buchatskaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Avila Pires</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Gheshlaghi</forename><surname>Azar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="21271" to="21284" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Girgis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Golemo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Codevilla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Kahou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Heide</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Autobots</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2104.00563</idno>
		<title level="m">Latent variable sequential set transformers</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Scene transformer: A unified architecture for predicting multiple agent trajectories</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ngiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Caine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-T</forename><forename type="middle">L</forename><surname>Chiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Roelofs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bewley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Venugopal</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.08417</idno>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
