<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">CONTAINER: Few-Shot Named Entity Recognition via Contrastive Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarkar</forename><surname>Snigdha</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sarathi</forename><surname>Das</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rebecca</forename><forename type="middle">J</forename><surname>Passonneau</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rui</forename><surname>Zhang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Pennsylvania State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">CONTAINER: Few-Shot Named Entity Recognition via Contrastive Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T20:53+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Named Entity Recognition (NER) in Few-Shot setting is imperative for entity tagging in low resource domains. Existing approaches only learn class-specific semantic features and intermediate representations from source domains. This affects generalizability to unseen target domains, resulting in suboptimal performances. To this end, we present CON-TAINER, a novel contrastive learning technique that optimizes the inter-token distribution distance for Few-Shot NER. Instead of optimizing class-specific attributes, CON-TAINER optimizes a generalized objective of differentiating between token categories based on their Gaussian-distributed embeddings.</p><p>This effectively alleviates overfitting issues originating from training domains. Our experiments in several traditional test domains (OntoNotes, CoNLL'03, WNUT '17, GUM) and a new large scale Few-Shot NER dataset (Few-NERD) demonstrate that, on average, CONTAINER outperforms previous methods by 3%-13% absolute F1 points while showing consistent performance trends, even in challenging scenarios where previous approaches could not achieve appreciable performance. The source code of CONTAINER will be available at:</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named Entity Recognition (NER) is a fundamental NLU task that recognizes mention spans in unstructured text and categorizes them into a predefined set of entity classes. In spite of its challenging nature, recent deep-learning based approaches <ref type="bibr" target="#b18">(Huang et al., 2015;</ref><ref type="bibr" target="#b23">Ma and Hovy, 2016;</ref><ref type="bibr" target="#b22">Lample et al., 2016;</ref><ref type="bibr" target="#b26">Peters et al., 2018;</ref><ref type="bibr" target="#b6">Devlin et al., 2018)</ref> have achieved impressive performance. As these supervised NER models require large-scale human-annotated datasets, few-shot techniques that can effectively perform NER in resource constraint settings have recently garnered a lot of attention. <ref type="figure">Figure 1</ref>: Contrastive learning dynamics of a token (Islands) with all other tokens in an example sentence from GUM <ref type="bibr" target="#b40">(Zeldes, 2017)</ref>. CONTAINER decreases the embedding distance between tokens of the same category (PLACE) while increasing the distance between different categories ( QTY. and O).</p><p>Few-shot learning involves learning unseen classes from very few labeled examples <ref type="bibr" target="#b10">(Fei-Fei et al., 2006;</ref><ref type="bibr" target="#b21">Lake et al., 2011;</ref><ref type="bibr" target="#b1">Bao et al., 2020)</ref>. To avoid overfitting with the limited available data, meta-learning has been introduced to focus on how to learn <ref type="bibr" target="#b32">(Vinyals et al., 2016;</ref><ref type="bibr" target="#b1">Bao et al., 2020)</ref>. <ref type="bibr" target="#b29">Snell et al. (2017)</ref> proposed Prototypical Networks to learn a metric space where the examples of a specific unknown class cluster around a single prototype. Although it was primarily deployed in computer vision, <ref type="bibr" target="#b11">Fritzler et al. (2019)</ref> and <ref type="bibr" target="#b16">Hou et al. (2020)</ref> also used Prototypical Networks for fewshot NER. <ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref>, on the other hand, proposed a supervised NER model that learns class-specific features and extends the intermediate representations to unseen domains. Additionally, they employed a Viterbi decoding variant of their model as "StructShot".</p><p>Few-shot NER poses some unique challenges that make it significantly more difficult than other few-shot learning tasks. First, as a sequence labeling task, NER requires label assignment according to the concordant context as well as the dependencies within the labels <ref type="bibr" target="#b22">(Lample et al., 2016;</ref><ref type="bibr" target="#b38">Yang and Katiyar, 2020)</ref>. Second, in NER, tokens that do not refer to any defined set of entities are labeled as Outside (O). Consequently, a token that is labeled as O in training entity set may correspond to a valid target entity in test set. For prototypical networks, this challenges the notion of entity exam-ples being clustered around a single prototype. As for Nearest Neighbor based methods such as <ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref>, they are initially "pretrained" with the objective of source class-specific supervision. As a result, the trained weights will be closely tied to the source classes and the network will project training set O-tokens so that they get clustered in embedding space. This will force the embeddings to drop a lot of useful features pertaining to its true target entity in the test set. Third, in few-shot setting, there are not enough samples from which we can select a validation set. This reduces the capability of hyperparameter tuning, which particularly affects template based methods where prompt selection is crucial for good performance <ref type="bibr" target="#b4">(Cui et al., 2021)</ref>. In fact, the absence of held-out validation set puts a lot of earlier few-shot works into question whether their strategy is truly "Few-Shot" <ref type="bibr" target="#b25">(Perez et al., 2021)</ref>.</p><p>To deal with these challenges, we present a novel approach , CONTAINER that harnesses the power of contrastive learning to solve Few-Shot NER. CONTAINER tries to decrease the distance of token embeddings of similar entities while increasing it for dissimilar ones <ref type="figure">(Figure 1</ref>). This enables CONTAINER to better capture the label dependencies. Also, since CONTAINER is trained with a generalized objective, it can effectively avoid the pitfalls of O-tokens that the prior methods struggle with. Lastly, CONTAINER does not require any dataset specific prompt or hyperparameter tuning. Standard settings used in prior works <ref type="bibr" target="#b38">(Yang and Katiyar, 2020)</ref> works well across different domains in different evaluation settings.</p><p>Unlike traditional contrastive learners <ref type="bibr">Khosla et al., 2020)</ref> that optimize similarity objective between point embeddings, CON-TAINER optimizes distributional divergence effectively modeling Gaussian Embeddings. While point embedding simply optimizes sample distances, Gaussian Embedding faces an additional constraint of maintaining class distribution through the variance estimation. Thus Gaussian Embedding explicitly models entity class distributions which not only promotes generalized feature representation but also helps in few-sample target domain adaptation. Previous works in Gaussian Embedding has also shown that mapping to a density captures representation uncertainties <ref type="bibr" target="#b31">(Vilnis and McCallum, 2014)</ref> and expresses natural asymmetries <ref type="bibr" target="#b27">(Qian et al., 2021)</ref> while showing better gen-eralization requiring less data to achieve optimal performance <ref type="bibr" target="#b2">(Bojchevski and G?nnemann, 2017)</ref>. Inspired by these unique qualities of Gaussian Embedding, in this work we leverage Gaussian Embedding in contrastive learning for Few-Shot NER.</p><p>A nearest neighbor classification scheme during evaluation reveals that on average, CON-TAINER significantly outperforms previous SOTA approaches in a wide range of tests by up to 13% absolute F1-points. In particular, we extensively test our model in both in-domain and out-of-domain experiments as proposed in <ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref> in various datasets <ref type="bibr">(CoNLL '03,</ref><ref type="bibr">OntoNotes 5.0,</ref><ref type="bibr">WNUT '17,</ref><ref type="bibr">I2B2)</ref>. We also test our model in a large dataset recently proposed for Few-Shot NER -Few-NERD <ref type="bibr" target="#b7">(Ding et al., 2021)</ref> where CON-TAINER outperforms all other SOTA approaches setting a new benchmark result in the leaderboard.</p><p>In summary, our contributions are as follows: (1) We propose a novel Few-Shot NER approach CONTAINER that leverages contrastive learning to infer distributional distance of their Gaussian Embeddings. To the best of our knowledge we are the first to leverage Gaussian Embedding in contrastive learning for Named Entity Recognition.</p><p>(2) We demonstrate that CONTAINER representations are better suited for adaptation to unseen novel classes, even with a low number of support samples. <ref type="formula" target="#formula_2">(3)</ref> We extensively test CONTAINER in a wide range of experiments using several datasets and evaluation schemes. In almost every case, our model largely outperforms present SOTAs establishing new benchmark results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Formulation</head><p>Given a sequence of n tokens {x 1 , x 2 , . . . x n }, NER aims to assign each token x i to its corresponding tag label y i .</p><p>Few-shot Setting For Few-shot NER, a model is trained in a source domain with a tag-set {C s (i) } and tested in a data-scarce target domain with a tag-set</p><formula xml:id="formula_0">{C d (j) } where i, j are index of different tags. Since {C s (i) } ? {C d (j) } = ?,</formula><p>it is very challenging for models to generalize to unseen test tags. In an N-way K-shot setting, there are N tags in the target domain |{C d (j) }| = N , and each tag is associated with a support set with K examples.</p><p>Tagging Scheme For fair comparison of CON-TAINER against previous SOTA models, we follow an IO tagging scheme where I-type repre- sents that all of the tokens are inside an entity, and O-type denotes all the other tokens <ref type="bibr" target="#b38">(Yang and Katiyar, 2020;</ref><ref type="bibr" target="#b7">Ding et al., 2021)</ref>.</p><p>Evaluation Scheme To compare with SOTA models in Few-NERD leaderboard <ref type="bibr" target="#b7">(Ding et al., 2021)</ref>, we adpot episode evaluation as done by the authors. Here, a model is assessed by calculating the micro-F1 score over multiple number of test episodes. Each episode consists of a K-shot support set and a K-shot unlabeled query (test) set to make predictions. While Few-NERD is explicitly designed for episode evaluation, traditional NER datasets (e.g., OntoNotes, CoNLL'03, WNUT '17, GUM) have their distinctive tag-set distributions. Thus, sampling test episodes from the actual test data perturbs the true distribution that may not represent the actual performance. Consequently, <ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref> proposed to sample multiple support sets from the original development set and use them for prediction in the original test set. We also use this evaluation strategy for these traditional NER datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>CONTAINER utilizes contrastive learning to optimize distributional divergence between different token entity representations. Instead of focusing on label specific attributes, this contradistinction explicitly trains the model to distinguish between different categories of tokens. Furthermore, modeling Gaussian Embedding instead of traditional point representation effectively lets CONTAINER model the entity class distribution, which incites generalized representation of tokens. Finally, it lets us carefully finetune our model even with a small number of samples without overfitting which is imperative for domain adaptation.</p><p>As demonstrated in <ref type="figure">Figure 2</ref>, we first train our model in source domains. Next, we finetune model representations using few-sample support sets to adapt it to target domains. The training and finetuning of CONTAINER is illustrated in Algorithm 1. Finally, we use an instance level nearest neighbor classifier for inference in test sets. <ref type="figure">Figure 2</ref> shows the key components of our model. To generate contextualized representation of sentence tokens, CONTAINER incorporates a pretrained language model encoder PLM. For proper comparison against existing approaches, we use BERT <ref type="bibr" target="#b6">(Devlin et al., 2018)</ref> as our PLM encoder. Thus given a sequence of n tokens [x 1 , x 2 , . . . , x n ], we take the final hidden layer output of the PLM as the intermediate representations h i ? R l .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model</head><p>[h 1 , h 2 , . . . , h n ] = PLM([x 1 , x 2 , . . . , x n ]) (1) These intermediate representations are then channeled through simple projection layer for generating the embedding. Unlike SimCLR  that uses projected point embedding for contrastive learning, we assume that token embeddings follow Gaussian distributions. Specifically, we employ projection network f ? and f ? for producing Gaussian distribution parameters:</p><formula xml:id="formula_1">? i = f ? (h i ), ? i = ELU (f ? (h i ))+(1+ ) (2)</formula><p>where ? i ? R l , ? i ? R l?l represents mean and diagonal covariance (with nonzero elements only along the diagonal of the matrix) of the Gaussian Embedding respectively; f ? and f ? are implemented as ReLU followed by single layer networks; ELU for exponential linear unit; and ? e ?14 for numerical stability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training in Source Domain</head><p>For calculating the contrastive loss, we consider the KL-divergence between all valid token pairs in the sampled batch. Two tokens x p and x q are considered as positive examples if they have the same label y p = y q . Given their Gaussian Embeddings N (? p , ? p ) and N (? q , ? q ), we can calculate their KL-divergence as following:</p><formula xml:id="formula_2">D KL [N q ||N p ] = D KL [N (? q , ? q )||N (? p , ? p )] = 1 2 Tr(? ?1 p ? q ) + (? p ? ? q ) T ? ?1 p (? p ? ? q ) ? l + log |? p | |? q |<label>(3)</label></formula><p>Both directions of the KL-divergence are calculated since it is not symmetric.</p><formula xml:id="formula_3">d(p, q) = 1 2 (D KL [N q ||N p ] + D KL [N p ||N q ])<label>(4)</label></formula><p>We first train our model in resource rich source domain having training data X tr . At each training step, we randomly sample a batch of sequences (without replacement) X ? X tr from the training set having batch size of b. For each (x i , y i ) ? X , we obtain its Gaussian Embedding N (? i , ? i ) by channeling the corresponding token sequence through the model (Algorithm 1: Line 3-6). We find in-batch positive samples X p for sample p and subsequently calculate the Gaussian embedding loss of x p with respect to that of all other valid tokens in the batch: X p = {(x q , y q ) ? X | y p = y q , p = q} (5)</p><formula xml:id="formula_4">(p) = ? log (xq,yq)?Xp exp(?d(p, q))/|X p | (xq,yq)?X ,p =q exp(?d(p, q))<label>(6)</label></formula><p>In this way we can calculate the distributional divergence of all the token pairs in the batch (Algorithm 1: Line 7-10 ). We do not scale the contrastive loss by any normalization factor as proposed by Chen et al. (2020) since we did not find it to be beneficial for optimization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Finetuning to Target Domain using Support Set</head><p>After training in source domains, we finetune our model using a small number of target domain support samples following a similar procedure as in the training stage. As we have only a few samples for finetuning, we take them in a single batch. When multiple few-shot samples (e.g., 5-shot) are available for the target classes, the model can effectively adapt to the new domain by optimizing KLdivergence of Gaussian Embeddings as in Eq. 4. In contrast, for 1-shot case, it turns out challenging for models to adapt to the target class distribution.</p><p>If the model has no prior knowledge about target classes (either from direct training or indirectly from source domain training where the target class entities are marked as O-type), a single example might not be sufficient to deduce the variance of the target class distribution. Thus, for 1-shot scenario, we optimize d (p, q) = ||? p ? ? q || 2 2 , the squared euclidean distance between mean of the embedding distributions. When the model has direct/indirect prior knowledge about the target classes involved, we still optimize the KL-divergence of the distributions similar to the 5-shot scenario.</p><p>We demonstrate in <ref type="table" target="#tab_12">Table 7</ref> that optimizing with squared euclidean distance gives us slightly better performance in 1-shot scenario. Nevertheless, in all cases with 5-shot support set, optimizing the KL-divergence between the Gaussian Embeddings gives us the best result.</p><p>Early Stopping Finetuning with a small support set runs the risk of overfitting and without access to a held out validation set due to data scarcity in the target domain, we cannot keep tabs on the saturation point where we need to stop finetuning. To alleviate this, we rely on the calculated contrastive loss and use it as our early stopping criteria with a patience of 1. (Algorithm 1: Line 16-17, 24 )</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Training and Finetuning of CON-TAINER</head><p>Require: Training data Xtr, Support Data Xsup, Train loss function dtr, Finetune loss function d f t , f?, f?, PLM 1: // training in source domain 2: for sampled (w/o replacement) minibatch X ? Xtr do 3:</p><formula xml:id="formula_5">for all i ? (xi, yi) ? X do 4: ?i = f?(PLM(xi)) //[Eq. 1] 5: ?i = ELU (f?(PLM(xi))) + (1 + ) //[Eq. 2] 6: end for 7:</formula><p>for all i ? (xi, yi) ? X do 8:</p><p>Calculate (i) as in Eq. 5 and 6 9: end for 10:</p><formula xml:id="formula_6">Ltr = 1 |X | i?X (i)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11:</head><p>update f?, f?, PLM by backpropagation to reduce Ltr 12: end for 13: // finetuning to target domain 14:</p><formula xml:id="formula_7">Lprev = ? 15: L f t = Lprev ? 1 //Stable Initialization 16: while L f t &lt; Lprev do 17: Lprev = L f t 18:</formula><p>for all i ? (xi, yi) ? Xsup do 19:</p><p>Calculate ?i and ?i using Eq. 1, 2 //Line 4,5 20: end for 21:</p><p>for all i ? (xi, yi) ? Xsup do 22:</p><p>Calculate (i) as in Eq. 5 and 6 23:</p><p>end for 24:</p><formula xml:id="formula_8">L f t = 1 |Xsup| i?Xsup (i)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>25:</head><p>update f?, f?, PLM by backpropagation to reduce L f t 26: end while 27: return PLM and discard f?, f?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Instance Level Nearest Neighbor Inference</head><p>After training and finetuning the network with train and support data respectively, we extract the pretrained language model encoder PLM for inference. Similar to SimCLR , we found that representations before the projection layers actually contain more information than the final output representation which contributes to better performance, so f ? and f ? projection heads are not used for inference. We thus calculate the representations of the test data from PLM and find nearest neighbor support set representation for inference <ref type="bibr" target="#b33">(Wang et al., 2019;</ref><ref type="bibr" target="#b38">Yang and Katiyar, 2020</ref>  30.5 ? 12.3 28.8 ? 11.2 20.8 ? 9.9 26.7 47.5 ? 4.0 53.0 ? 7.9 48.7 ? 2.7 49.8 CONTaiNER 32.2 ? 5.3 30.9 ? 11.6 32.9 ? 12.7 32.0 51.2 ? 5.9 55.9 ? 6.2 61.5 ? 2.7 56.2 + Viterbi 32.4 ? 5.1 30.9 ? 11.6 33.0 ? 12.8 32.1 51.2 ? 6.0 56.0 ? 6.2 61.5 ? 2.7 56.2  Baselines We compare the performance of CON-TAINER with state-of-the-art Few-Shot NER models on different datasets across several settings. We first measure the model performance in traditional NER datasets in tag-set extension and domain transfer tasks as proposed in <ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref>.</p><p>We then evaluate our model in Few-NERD <ref type="bibr" target="#b7">(Ding et al., 2021)</ref> dataset that is explicitly designed for Few-Shot NER, and compare it against the Few-NERD leaderboard baselines. Similar to <ref type="bibr" target="#b7">Ding et al. (2021)</ref>, we take Prototypical Network based Pro-toBERT <ref type="bibr" target="#b29">(Snell et al., 2017;</ref><ref type="bibr" target="#b11">Fritzler et al., 2019;</ref><ref type="bibr" target="#b16">Hou et al., 2020)</ref>, nearest neighbor based metric method NNShot that leverages the locality of inclass samples in embedding space, and additional Viterbi decoding based Structshot <ref type="bibr" target="#b38">(Yang and Katiyar, 2020)</ref> as the main SOTA baselines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Tag-set Extension Setting</head><p>A common use-case of Few-Shot NER is that new entity types may appear in the same existing text domain. Thus <ref type="bibr" target="#b38">(Yang and Katiyar, 2020)</ref> proposed to experiment tag-set extension capability using OntoNotes <ref type="bibr" target="#b35">(Weischedel et al., 2013)</ref> dataset. The eighteen existing entity classes are split in three groups: A, B, and C, each having six classes. Models are tested in each of these groups having few sample support set while being trained in the remaining two groups. During training, all test group entities are replaced with O-tag. Since the source and destination domains are the same, the training phase will induce some indirect information about unseen target entities. So, during finetuning of CONTAINER, we optimize the KL-divergence between ouptut embeddings as in Eq. 4. We use the same entity class splits as used by <ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref> and used bert-base-cased as the backbone encoder for all models. Since they could not share the sampled support set for licensing reasons, we sampled five sets of support samples for each group and averaged the results, as done by the authors. We show these results in <ref type="table" target="#tab_0">Table 2</ref>. We see that in different entity groups, CONTAINER outperforms present SOTAs by upto 12.75 absolute F1 points, a substantial improvement in performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Domain Transfer Setting</head><p>In this experiment a model trained on a source domain is deployed to a previously unseen novel text domain. Here we take OntoNotes (General) as our source text domain, and evaluate the Few-Shot performance in I2B2 (Medical), CoNLL (News), WNUT (Social) domains as in <ref type="bibr" target="#b38">(Yang and Katiyar, 2020)</ref>. We also evaluate the performance in GUM <ref type="bibr" target="#b40">(Zeldes, 2017)</ref> dataset due to its particularly challenging nature. We show these results in <ref type="table" target="#tab_4">Table 3</ref>. While all the other domains have almost no intersection with OntoNotes, target entities in CoNLL are fully contained within OntoNotes entities, that makes it comparable to supervised learning.    . We evaluate our model performance using these provided dataset splits and compare the performance in Few-NERD leaderboard. All models use bert-base-uncased as the backbone encoder. As shown in <ref type="table" target="#tab_6">Table 4</ref> and <ref type="table" target="#tab_7">Table 5</ref>, CON-TAINER establishes new benchmark results in the leaderboard in both of these tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Few-NERD Setting</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Analysis</head><p>We prudently analyze different components of our model and justify the design choices made in the scheming of CONTAINER. We also examine the results discussed in Section 4 that gives some intuitions about few-shot NER in general.  <ref type="table" target="#tab_6">(Table 4</ref>) is a challenging scenario where the coarse grained entity types corresponding to train and test sets do not overlap. As a result, other baseline approaches face a substantial performance hit, whereas CON-TAINER still performs well. In tag-set extension <ref type="table" target="#tab_0">(Table 2)</ref>, we see a similar performance trend -CONTAINER performs consistently well across the board. Likewise, in domain transfer to a very challenging unseen text domain like GUM <ref type="bibr" target="#b40">(Zeldes, 2017)</ref>, baseline models performs miserably; yet CONTAINER manages to perform consistently outperforming SOTA models by a significant margin. Analyzing these results more closely, we notice that while CONTAINER surpasses other baselines in almost every tests, more prominently in 5-shot cases. Evidently, CONTAINER is able to make better use of multiple few-shot samples thanks to distribution modeling via contrastive Gaussian Embedding optimization. In this context, note that StructShot actually got marginally higher F1-score in 1-shot CoNLL domain adaptation and 1?2 shot FEW-NERD (INTER) cases. In CoNLL, the target classes are subsets of training classes, so supervised learning based feature extractors are expected to get an advantage in prediction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Overall Results</head><p>On the other hand, <ref type="bibr" target="#b7">Ding et al. (2021)</ref> carefully tuned the hyperparameters for baselines like Struct-Shot for best performance. We could also improve performance in a similar manner, however for uniformity of model across different few-shot settings, we use the same model architecture in every test. Nevertheless, CONTAINER shows comparable performance even in these cases while significantly outperforming in every other test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Training Objective</head><p>Traditional contrastive learners usually optimize cosine similarity of point embeddings . While this has proven to work well in image data, in more challenging NLU tasks like Few-Shot NER, it gives subpar performance. We compare the performance of point embeddings with euclidean distance and cosine similarity to that of CONTAINER using Gaussian Embedding and KLdivergence in OntoNotes tag-set extension. We report these performance in <ref type="table" target="#tab_14">Table 8</ref> in Appendix. Basically, Gaussian Embedding leads to learning generalized representation during training, which is more suitable for finetuning to few sample target domain. In Appendix C, we examine this aspect by comparing the t-SNE representations from point embedding and Gaussian Embedding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Effect of Model Fine-tuning</head><p>Being a contrastive learner, CONTAINER can take advantage of extremely small support set to refine its representations through fine-tuning.</p><p>To closely examine the effects of fine-tuning, we conduct a case study with OntoNotes tagextension task using PERSON, DATE, MONEY, LOC, FAC, PRODUCT target entities.  As shown in <ref type="table" target="#tab_10">Table 6</ref>, we see that finetuning indeed improves few-shot performance. Besides, the effect of finetuning is even more marked in 5-shot prediction indicating that CONTAINER finetuning process can make the best use of few-samples available in target domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Modeling Label Dependencies</head><p>Analyzing the results, we observe that domain transfer <ref type="table" target="#tab_4">(Table 3</ref>) sees some good gains in performance from using Viterbi decoding. In contrast, tag-set extension ( <ref type="table" target="#tab_0">Table 2)</ref> and FEW-NERD <ref type="table" target="#tab_6">(Table  4</ref>,5) gets almost no improvement from using Viterbi decoding. This indicates an interesting property of CONTAINER. During domain transfer the text domains have no overlap in train and test set. So, an extra Viterbi decoding actually provides additional information regarding the label dependencies, giving us some nice improvement. Otherwise, the train and target domain have substantial overlap in both tagset extension and FEW-NERD. Thus the model can indirectly learn the label dependencies through in-batch contrastive learning. Consequently, unless there is a marked shift in the target text domain, we can achieve the best performance even without employing additional Viterbi decoding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Related Works</head><p>Meta Learning The idea of Few-shot learning was popularized in computer vision through Matching Networks <ref type="bibr" target="#b32">(Vinyals et al., 2016)</ref>. Subsequently, Prototypical Network <ref type="bibr" target="#b29">(Snell et al., 2017)</ref> was proposed where class prototypical representations were learned. Test samples are given labels according to the nearest prototype. Later this technique was proven successful in other domains as well. <ref type="bibr" target="#b33">Wang et al. (2019)</ref>, on the other hand found simple feature transformations to be quite effective in few shot image recognition These metric learning based approaches have also been deployed in different NLP tasks <ref type="bibr">(Geng et al., 2019;</ref><ref type="bibr" target="#b1">Bao et al., 2020;</ref><ref type="bibr" target="#b15">Han et al., 2018;</ref><ref type="bibr" target="#b11">Fritzler et al., 2019)</ref>.</p><p>Contrastive Learning Early progress was made by contrasting positive against negative samples <ref type="bibr" target="#b14">(Hadsell et al., 2006;</ref><ref type="bibr" target="#b9">Dosovitskiy et al., 2014;</ref><ref type="bibr" target="#b37">Wu et al., 2018)</ref>.  proposed SimCLR by refining the idea of contrastive learning with the help of modern image augmentation techniques to learn robust sets of features. <ref type="bibr">Khosla et al. (2020)</ref> leveraged this to boost supervised learning performance as well. In-batch negative sampling has also been explored for learning representation <ref type="bibr" target="#b8">(Doersch and Zisserman, 2017;</ref><ref type="bibr" target="#b39">Ye et al., 2019)</ref>. Storing instance class representation vectors is another popular direction <ref type="bibr" target="#b37">(Wu et al., 2018;</ref><ref type="bibr">Zhuang et al., 2019;</ref><ref type="bibr" target="#b24">Misra and Maaten, 2020)</ref>.</p><p>Gaussian Embedding <ref type="bibr" target="#b31">Vilnis and McCallum (2014)</ref> first explored the idea of learning word embeddings as Gaussian Distributions. Although the authors used RANK-SVM based learning objective instead of modern deep contextual modeling, they found that embedding densities in a Gaussian space enables natural represenation of uncertainty through variances. Later, <ref type="bibr" target="#b2">Bojchevski and G?nnemann (2017)</ref> leveraged Gaussian Embedding in Graph representation. Besides state-of-the-art performance, they found Gaussian Embedding to be surprisingly effective in inductive learning, generalizing to unseen nodes with few training data. Moreover, KL-divergence between Gaussian Embeddings allows explicit consideration of asymmetric distance which better represents inclusion, similarity or entailment <ref type="bibr" target="#b27">(Qian et al., 2021)</ref> and preserve the hierarchical structures among words <ref type="bibr" target="#b0">(Athiwaratkun and Wilson, 2018)</ref>.</p><p>Few-Shot NER Established few-shot learning approaches have also been applied in Named Entity Recognition. <ref type="bibr" target="#b11">Fritzler et al. (2019)</ref> leveraged prototypical network <ref type="bibr" target="#b29">(Snell et al., 2017)</ref> for few shot NER. Inspired by the potency of simple feature extractors and nearest neighbor inference <ref type="bibr" target="#b33">(Wang et al., 2019;</ref><ref type="bibr" target="#b36">Wiseman and Stratos, 2019)</ref> in few-Shot learning, <ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref> used super-vised learner based feature extractors for Few-Shot NER. Pairing it with abstract transition tag Viterbi decoding, they achieved current SOTA result in Few-Shot NER tasks. <ref type="bibr" target="#b17">Huang et al. (2020)</ref> proposed noisy supervised pre-training for Few-Shot NER. However, this method requires access to a large scale noisy NER dataset such as WiNER <ref type="bibr" target="#b13">(Ghaddar and Langlais, 2017)</ref> for the supervised pretraining. Acknowledging the shortcomings and evaluation scheme disparity in Few-Shot NER, <ref type="bibr" target="#b7">Ding et al. (2021)</ref> proposed a large scale dataset specifically designed for this task. <ref type="bibr" target="#b7">Wang et al. (2021)</ref> explored model distillation for Few-Shot NER. However, this requires access to a large unlabelled dataset for good performance. Very recently, prompt based techniques have also surfaced in this domain <ref type="bibr" target="#b4">(Cui et al., 2021)</ref>. However, the performance of these methods rely heavily on the chosen prompt. As denoted by the author, the performance delta can be massive (upto 19% absolute F1 points) depending on the prompt. Thus, in the absence of a large validation set, their applicability becomes limited in true few-shot learning <ref type="bibr" target="#b25">(Perez et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We propose a contrastive learning based framework CONTAINER that models Gaussian embedding and optimizes inter token distribution distance. This generalized objective helps us model a class agnostic feature extractor that avoids the pitfalls of prior Few-Shot NER methods. CONTAINER can also take advantage of few-sample support data to adapt to new target domains. Extensive evaluations in multiple traditional and recent few-shot NER datasets reveal that, CONTAINER consistently outperforms prior SOTAs, even in challenging scenarios. While we investigate the efficacy of distribution optimization based contrastive learning in Few-Shot NER, it will be of particular interest to investigate its potency in other domains as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Implementation Details</head><p>For all of our experiments in CONTAINER. we chose the same hyperparameters as in <ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref>. Across all our tests, we kept Gaussian Embedding dimension fixed to l = 128. In order to guarantee proper comparison against prior competitive approaches, we use the same backbone encoder for all methods in same tests, i.e. bert-base-cased was used for all methods in Tag-Set Extension and Domain Transfer tasks while bert-base-uncased was used for Few-NERD following the respective evaluation strategies. Finally, to observe the effect of Viterbi decoding on CONTAINER output, we set the renormalizing temperature ? from [0.01, 0.05, 0.1].</p><p>Using an RTX A6000, we trained the network on OntoNotes dataset for 30 minutes. The finetuning stage requires less than a minute due to the small number of samples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Fine-tuning Objective</head><p>During finetuning, if a model does not have any prior knowledge about the target classes, directly or indirectly, a 1-shot example may not give sufficient information about the target class distribution (i.e. the variance of the distribution). Consequently during finetuning, for 1-shot adaptation to new classes, optimizing euclidean distance of the mean embedding gives better performance. Nevertheless, for 5-shot cases, KL-divergence of the Gaussian Embedding always gives better performance indicating that it takes better advantage of multiple samples. We show this behavior in the best result of domain transfer task with WNUT in <ref type="table" target="#tab_12">Table 7</ref>. Since this domain transfer task gives no prior information about target embeddings during training, optimizing KL-divergence in 1-shot fineutuning actually hurts performance a bit compared to euclidean finetuning. However, in 5-shot, KL-finetuning again gives superior performance as it can now adapt better to the novel target class distributions.   In <ref type="figure" target="#fig_1">Figure 3</ref> (a) we can see that point embedding paired with Euclidean distance metric has suboptimal clustering pattern in both support and test sets. In fact, the support examples in different classes are intermixed implying poor generalization. When the point embedding model is finetuned with the support set ( <ref type="figure" target="#fig_1">Figure 3 (c)</ref>), Euclidean distance aggressively optimizes them and tries to force the same class support examples to collapse into essentially a single point representation. In other words, the model quickly overfits the small support data which in fact hurts model performance. In comparsion, Gaussian Embedding offers a better t-SNE representation prior to and after finetuning. <ref type="figure" target="#fig_1">Figure  3 (b)</ref> shows the representation of support and test sets prior to finetuning with Gaussian Embedding paired with KL-divergence. In both support and test sets, we observe different class samples mostly clustered together. This indicates that even before finetuning it shows good generalization to unseen classes. While finetuning, the KL-divergence optimization objective maintains the class distribution letting the model generate separate support clusters <ref type="figure" target="#fig_1">(Figure 3(d)</ref>). After finetuning, the clusters get cleaner offering even better separation between different class clusters, which is also reflected in the performance uplift of the model. <ref type="table" target="#tab_14">Table 8</ref> compares the performance of Gaussian Embedding (KL-divergence) with that of point embedding (Euclidean distance of cosine similarity) in OntoNotes tag extension task. Since Gaussian Embedding utilizes l dimensional mean and l dimensional diagonal covariance matrix, for a fair comaparison we show the results for 2l dimensional point embedding. As discussed in Section   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C t-SNE Visualization: Point Embedding vs. Gaussian Embedding</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Comparison of Different Training Objectives</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Embedding Quality: Before vs. After Projection</head><p>As explained in Section 3.4, the representation before the projection layer contains more information than that of after. In <ref type="table">Table 9</ref>, we compare the performance of representations before and after the Gaussian projection layer. From the results it is evident that, representation before the projection Before Projection After Projection 1-shot 32.17 29.21 5-shot 51.19 49.78 <ref type="table">Table 9</ref>: Comparison of F1-Scores on OntoNotes Group A before and after the projection layer of CON-TAINER indeed achieves higher performance, which also supports the findings of . This is because the representation after the projection head is directly adjacent to the contrastive objec-tive, which causes information loss in this layer. Consequently, the representation before projection achieves better performance. Wang Shin -hwanP ER notes that traditional bacterial and viral cultures take seven to ten days to prepare , and even with the newer molecular biology testing techniques it takes three daysDAT E to get a result .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F NER Prediction Examples</head><p>Wang ShinP ER -hwan notes that traditional bacterial and viral cultures take seven to ten daysDAT E to prepare , and even with the newer molecular biology testing techniques it takes three daysDAT E to get a result .</p><p>Wang Shin -hwan notes that traditional bacterial and viral cultures take seven to ten daysDAT E to prepare , and even with the newer molecular biology testing techniques it takes three daysDAT E to get a result .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research</head><p>program director Pan Chao -chiP ER states that at present they are actively developing a " fever chip " with a wide range of applications .</p><p>Research program director PanP ER Chao -chi states that at presentDAT E they are actively developing a " fever chip " with a wide range of applications .</p><p>Research program director PanP ER Chao -chi states that at present they are actively developing a " fever chip " with a wide range of applications .</p><p>Pan explains that in clinical practice , the causes of fever are difficult to quickly diagnose .</p><p>PanP ER explains that in clinical practice , the causes of fever are difficult to quickly diagnose .</p><p>Pan explains that in clinical practice , the causes of fever are difficult to quickly diagnose .</p><p>Jerry HuangP ER, executive vice president of U -Vision Biotech , reveals that U -Vision , which was set up in September 1999DAT E , has signed a contract with the US company Zen -Bio to jointly develop human adipocyte cDNA microarray chips . Jerry HuangP ER, executive vice president of U -Vision Biotech , reveals that U -Vision , which was set up in September 1999DAT E , has signed a contract with the US company Zen -Bio to jointly develop human adipocyte cDNA microarray chips . Jerry Huang , executive vice president of U -Vision Biotech , reveals that U -Vision , which was set up in September 1999 , has signed a contract with the US company Zen -Bio to jointly develop human adipocyte cDNA microarray chips.</p><p>HuangP ER states that research in recent yearsDAT E has revealed that adipocytes -LR fat cells -RR are active regulators of the energy balance in the body , and play an important role in disorders such as obesity , diabetes , osteoporosis and cardiovascular disease .</p><p>HuangP ER states that research in recent yearsDAT E has revealed that adipocytes -LR fat cells -RR are active regulators of the energy balance in the body , and play an important role in disorders such as obesity , diabetes , osteoporosis and cardiovascular disease .</p><p>Huang states that research in recent years has revealed that adipocytes -LR fat cells -RR are active regulators of the energy balance in the body , and play an important role in disorders such as obesity , diabetes , osteoporosis and cardiovascular disease . Russian and Norwegian divers searched the fourth compartment of the wrecked submarine KurskP RODU CT , SundayDAT E , but they found too much damage to proceed with the task of recovering bodies .</p><p>Russian and Norwegian divers searched the fourth compartment of the wrecked submarine KurskP RODU CT , SundayDAT E , but they found too much damage to proceed with the task of recovering bodies .</p><p>Russian and Norwegian divers searched the fourth compartment of the wrecked submarine Kursk, SundayDAT E , but they found too much damage to proceed with the task of recovering bodies .</p><p>ZinniP ER testifying after the attack on the "USS Cole"P RODU CT -Aden never had a specific terrorist threat .</p><p>ZinniP ER testifying after the attack on the "USS Cole"P RODU CT -Aden never had a specific terrorist threat .</p><p>Zinni testifying after the attack on the "USS Cole"P RODU CT -Aden never had a specific terrorist threat .</p><p>Today , the enterovirus chip is in the testing phase , and DR. Chip is collaborating with Taipei Veterans General Hospital to obtain samples with which to establish the accuracy of the chip .</p><p>TodayDAT E , the enterovirus chip is in the testing phase, and DR. ChipP RODU CT is collaborating with Taipei Veterans General HospitalF AC to obtain samples with which to establish the accuracy of the chip .</p><p>TodayDAT E , the enterovirus chip is in the testing phase, and DR. ChipP RODU CT is collaborating with Taipei Veterans General Hospital to obtain samples with which to establish the accuracy of the chip .</p><p>And I think perhaps no one more surprised than some of the people running those firms on Wall StreetF AC .</p><p>I think perhaps no one more surprised than some of the people running those firms on Wall StreetF AC .</p><p>I think perhaps no one more surprised than some of the people running those firms on Wall Street.</p><p>We're all getting , this news in from the speech that the Homeland Security Secretary Tom RidgeP ER is expected to be delivering at the international press club around 1:00 Eastern at the top of the hour .</p><p>We're all getting , this news in from the speech that the Homeland Security Secretary Tom RidgeP ER is expected to be delivering at the international press club around 1:00 Eastern at the top of the hour .</p><p>We're all getting , this news in from the speech that the Homeland Security Secretary Tom RidgeP ER is expected to be delivering at the international press clubF AC around 1:00 Eastern at the top of the hour .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>YesterdayDAT E</head><p>American pilots mechanics approved their share $ 1.8 billionMONEY in labor concession .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>YesterdayDAT E</head><p>American pilots mechanics approved their share $ 1.8 billionMONEY in labor concession .</p><p>Yesterday American pilots mechanics approved their share $ 1.8 billion in labor concession . </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>For few-shot setting,<ref type="bibr" target="#b7">Ding et al. (2021)</ref> proposed two different settings: Few-NERD (IN-TRA) and Few-NERD (INTER). In Few-NERD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3</head><label>3</label><figDesc>offers a deep dive into how Gaussian Embedding improves generalization and takes better advantage of few shot support set for target domain adaptation. Here we compare the t-SNE visualization of support set and test set of a sample fewshot scenario in OntoNotes tag set extension task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>t-SNE visualization of support set and test set representations in a sample few-shot task in OntoNotes tag extension. We show both support and test set representation here before and after finetuning. Prior to finetuning, (a) contrastive learner with point embedding and Euclidean distance objective gives intermixed class representations; (b) Gaussian Embedding with KL-divergenece generates clusters for different unseen classes. After finetuning, (c) point embedding overfits the support examples which further intermingles different class examples; (d) Gaussian Embedding with KL-divergence cleans up the clusters offering better separation between different classes, which results in higher F1-score.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Figure 2 :</head><label>2</label><figDesc>Illustration of our proposed CONTAINER framework based on Contrastive Learning over Gaussian Embedddings: (i) Training in source domains using training NER labels PER and DATE, (ii) Fine-tuning to target domains using target NER labels ORG and LOCATION, (iii) Assigning labels to test samples via Nearest Neighbor support set labels.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>? X sup can be calculated as in Eq. 1. Similarly for test data X test , we get the PLM representations h test i where x test i ? X test . Here we assign x test i the same label as the support token that is nearest in the PLM representation space:</figDesc><table><row><cell>Dataset</cell><cell cols="3">Domain # Class # Sent</cell></row><row><cell>OntoNotes</cell><cell>General</cell><cell>18</cell><cell>76K</cell></row><row><cell>I2B2'14</cell><cell>Medical</cell><cell>23</cell><cell>140K</cell></row><row><cell>CoNLL'03</cell><cell>News</cell><cell>4</cell><cell>20K</cell></row><row><cell>WNUT'17</cell><cell>Social</cell><cell>6</cell><cell>5K</cell></row><row><cell>GUM</cell><cell>Mixed</cell><cell>11</cell><cell>3.5K</cell></row><row><cell cols="2">FEW-NERD Wikipedia</cell><cell>66</cell><cell>188K</cell></row><row><cell>).</cell><cell></cell><cell></cell><cell></cell></row><row><cell>The PLM representations h port token (x sup j , y sup j ) y test i = arg min y sup k where (x sup k ,y k )?Xsup sup j of each of the sup-sup ||h test i ? h sup k || 2 2 (7)</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 :</head><label>1</label><figDesc>Summary Statistics of Datasets ? 7.9 20.3 30.5 ? 3.5 38.7 ? 5.6 41.1 ? 3.3 36.7 NNShot 28.5 ? 9.2 27.3 ? 12.3 21.4 ? 9.7 25.7 44.0 ? 2.1 51.6 ? 5.9 47.6 ? 2.8 47.7 StructShot</figDesc><table><row><cell>Viterbi Decoding Most previous works (Hou</cell></row><row><cell>et al., 2020; Yang and Katiyar, 2020; Ding et al.,</cell></row><row><cell>2021) noticed a performance improvement by us-</cell></row><row><cell>ing CRFs (Lafferty et al., 2001) which removes</cell></row><row><cell>false predictions to improve performance. Thus</cell></row><row><cell>we also employ Viterbi decoding in the inference</cell></row><row><cell>stage with an abstract transition distribution as in</cell></row><row><cell>StructShot (Yang and Katiyar, 2020). For the tran-</cell></row><row><cell>sition probabilities, the transition between three</cell></row><row><cell>abstract tags O, I, and I-other is estimated by</cell></row><row><cell>counting their occurrences in the training set. Then</cell></row><row><cell>for the target domain tag-set, these transition prob-</cell></row><row><cell>abilities are evenly distributed into corresponding</cell></row><row><cell>target distributions. The emission probabilities</cell></row><row><cell>are calculated from Nearest Neighbor Inference</cell></row><row><cell>stage. Comparing domain transfer results (Table</cell></row><row><cell>3) against other tasks (Table 2,4,5) we find that,</cell></row><row><cell>interestingly, if there is no significant domain shift</cell></row><row><cell>involved in the test data, contrastive learning al-</cell></row><row><cell>lows CONTAINER to automatically extract label</cell></row><row><cell>dependencies, obviating the requirement of extra</cell></row><row><cell>Viterbi decoding stage.</cell></row><row><cell>4 Experiment Setups</cell></row><row><cell>Datasets For evaluation, we use datasets across</cell></row><row><cell>different domains: General (OntoNotes 5.0</cell></row><row><cell>(Weischedel et al., 2013)), Medical (I2B2 (Stubbs</cell></row><row><cell>and Uzuner, 2015)), News (CoNLL'03 (Sang and</cell></row><row><cell>De Meulder, 2003)), Social (WNUT'17 (Derczyn-</cell></row><row><cell>ski et al., 2017)). We also test on GUM (Zeldes,</cell></row><row><cell>2017) that represents wide variety of texts: inter-</cell></row><row><cell>views, news articles, instrumental texts, and travel</cell></row><row><cell>guides. The miscellany of domains makes it a chal-</cell></row><row><cell>lenging dataset to work on. Ding et al. (2021) argue</cell></row><row><cell>that the distribution of these datasets may not be</cell></row><row><cell>suitable for proper representation of Few-Shot ca-</cell></row><row><cell>pability. Thus, they proposed a new large scale</cell></row><row><cell>dataset Few-NERD that contains 66 fine-grained</cell></row><row><cell>entities across 8 coarse grained entities, signifi-</cell></row><row><cell>cantly richer than previous datasets. A summary of</cell></row><row><cell>these datasets is given in Table 1.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 :</head><label>2</label><figDesc>F1 scores in Tag Set Extension on OntoNotes. Group A, B, C are three disjoint sets of entity types. Results vary slightly compared to<ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref> since they used different support set samples (publicly unavailable) than ours.</figDesc><table><row><cell>Model</cell><cell></cell><cell></cell><cell>1-shot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>5-shot</cell><cell></cell></row><row><cell></cell><cell>I2B2</cell><cell>CoNLL</cell><cell>WNUT</cell><cell>GUM</cell><cell>Avg.</cell><cell>I2B2</cell><cell>CoNLL</cell><cell>WNUT</cell><cell>GUM</cell><cell>Avg.</cell></row><row><cell>Proto</cell><cell cols="10">13.4 ? 3.0 49.9 ? 8.6 17.4 ? 4.9 17.8 ? 3.5 24.6 17.9 ? 1.8 61.3 ? 9.1 22.8 ? 4.5 19.5 ? 3.4 30.4</cell></row><row><cell>NNShot</cell><cell cols="10">15.3 ? 1.6 61.2 ? 10.4 22.7 ? 7.4 10.5 ? 2.9 27.4 22.0 ? 1.5 74.1 ? 2.3 27.3 ? 5.4 15.9 ? 1.8 34.8</cell></row><row><cell>StructShot</cell><cell cols="10">21.4 ? 3.8 62.4 ? 10.5 24.2 ? 8.0 7.8 ? 2.1 29.0 30.3 ? 2.1 74.8 ? 2.4 30.4 ? 6.5 13.3 ? 1.3 37.2</cell></row><row><cell cols="11">CONTaiNER 16.4 ? 1.7 57.8 ? 10.7 24.2 ? 2.9 17.9 ? 1.8 29.1 24.1 ? 1.9 72.8 ? 2.0 27.7 ? 2.2 24.4 ? 2.2 37.3</cell></row><row><cell>+ Viterbi</cell><cell cols="10">21.5 ? 1.7 61.2 ? 10.7 27.5 ? 1.9 18.5 ? 4.9 32.2 36.7 ? 2.1 75.8 ? 2.7 32.5 ? 3.8 25.2 ? 2.7 42.6</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 :</head><label>3</label><figDesc>F1 scores in Domain Extension with OntoNotes as the source domain. Results vary slightly compared to<ref type="bibr" target="#b38">Yang and Katiyar (2020)</ref> since they used different support set samples (publicly unavailable) than ours.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 :</head><label>4</label><figDesc>F1 scores in FEW-NERD (INTRA).</figDesc><table><row><cell>Model</cell><cell>5-way</cell><cell></cell><cell></cell><cell>10-way</cell><cell>Avg.</cell></row><row><cell></cell><cell cols="4">1?2 shot 5?10 shot 1?2 shot 5?10 shot</cell><cell></cell></row><row><cell>StructShot</cell><cell>57.33</cell><cell>57.16</cell><cell>49.46</cell><cell>49.39</cell><cell>53.34</cell></row><row><cell>ProtoBERT</cell><cell>44.44</cell><cell>58.80</cell><cell>39.09</cell><cell>53.97</cell><cell>49.08</cell></row><row><cell>NNShot</cell><cell>54.29</cell><cell>50.56</cell><cell>46.98</cell><cell>50.00</cell><cell>50.46</cell></row><row><cell>CONTaiNER</cell><cell>55.95</cell><cell>61.83</cell><cell>48.35</cell><cell>57.12</cell><cell>55.81</cell></row><row><cell>+ Viterbi</cell><cell>56.1</cell><cell>61.90</cell><cell>48.36</cell><cell>57.13</cell><cell>55.87</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 :</head><label>5</label><figDesc>F1 scores in FEW-NERD (INTER).</figDesc><table /><note>(INTRA) train, dev, and test sets are divided ac- cording to coarse-grained types. As a result, fine- grained entity types belonging to People, Art, Product, MISC coarse grained types are put in the train set, Event, Building coarse grained types in dev set, and ORG, LOC in test set. So, there is no overlap between train, dev, test set classes in terms of coarse grained types. On the other hand, in Few-NERD (INTER) coarse grained types are shared, although all the fine grained types are mutually disjoint. Because of the restrictions of sharing coarse-grained types, Few-NERD (IN- TRA) is more challenging. Since, few-shot perfor- mance of any model relies on the sampled support set, the authors also released train, dev, test split for both Few-NERD (INTRA) and Few-NERD (INTER)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 2 -</head><label>2</label><figDesc></figDesc><table /><note>5 demonstrates that overall, in every sce- nario CONTAINER convincingly outperforms all other baseline approaches. This improvement is particularly noticeable in challenging scenarios, where all other baseline approaches perform poorly. For example, FEW-NERD (intra)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6 :</head><label>6</label><figDesc></figDesc><table /><note>Comparison of F1-Scores with and without support set finetuning of CONTAINER</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 7 :</head><label>7</label><figDesc>F1 scores comparison in Domain TransferTask with WNUT with different finetune objectives.</figDesc><table><row><cell>While optimizing the KL-divergence of the Gaussian</cell></row><row><cell>Embedding gives superior result in 5-shot, optimizing</cell></row><row><cell>Euclidean distance of the mean embeddings actually</cell></row><row><cell>achieve better result in 1-shot. Note that in both cases</cell></row><row><cell>the model is trained on out-of-domain data using KL-</cell></row><row><cell>Gaussian.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 8 :</head><label>8</label><figDesc>OntoNotes Tag Set extension mean-F1 score comparison between Point Embedding (with Euclidean distance and cosine similarity) and Gaussian Embedding (KL-divergence).</figDesc><table><row><cell>5.2, Gaussian Embedding with KL-divergence ob-</cell></row><row><cell>jective largely outperforms point embedding irre-</cell></row><row><cell>spective of distance metric used.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 10</head><label>10</label><figDesc>ER says that the ITRI 's four-yearDAT E R&amp;D program in biochip applications and technology is now in its second yearDAT E . ER says that the ITRI 's four-yearDAT E R&amp;D program in biochip applications and technology is now in its second yearDAT E . ER says that the ITRI 's four-yearDAT E R&amp;D program in biochip applications and technology is now in its second year. DR. Chip Bio-technology was set up in September 1998DAT E . DR. Chip Bio-technology was set up in September 1998DAT E . DR. Chip Bio-technologyP RODU CT was set up in September 1998.</figDesc><table><row><cell>demonstrates some predictions with CON-</cell></row><row><cell>TAINER and StructShot using PERSON, DATE,</cell></row><row><cell>MONEY, LOC, FAC, PRODUCT as target few-</cell></row><row><cell>shot entities while being trained on all other entity</cell></row><row><cell>types in OntoNotes dataset. A quick look at these</cell></row><row><cell>qualitative examples reveal that StructShot often</cell></row><row><cell>fails to distinguish between non-entity and entity</cell></row><row><cell>tokens. Moreover, it also misclassifies non-entity</cell></row><row><cell>tokens as one of the target classes. CONTAINER</cell></row><row><cell>on the other hand has lower misclassifications and</cell></row><row><cell>better entity detection indicating its stability and</cell></row><row><cell>higher performance.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Maybe a 30 year oldDAT E man &amp; a 15 year oldDAT E boy doesn't qualify . Maybe a 30 year old man &amp; a 15 year old boy doesn't qualify . Maybe a 30 year oldDAT E man &amp; a 15 year oldDAT E boy doesn't qualify . After Tom DeLayP ER was zapped, Charles ColsonP ER became DeLayP ER's personal guru. After Tom DeLayP ER was zapped, Charles ColsonP ER became DeLay's personal guru. After Tom DeLay was zapped, Charles ColsonP ER became DeLay's personal guru. She does not sit still or lay still for you to change her PampersP RODU CT . She does not sit still or lay still for you to change her PampersP RODU CT . She does not sit still or lay still for you to change her PampersP RODU CT .</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 10 :</head><label>10</label><figDesc>NER Prediction Examples from OntoNotes with PERSON, DATE, MONEY, LOC, FAC,PRODUCT as target few-shot entities</figDesc><table /><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgement</head><p>We thank the ACL Rolling Review reviewers for their helpful feedback. We also want to thank Nan Zhang, Ranran Haoran Zhang, and Chandan Akiti for their insightful comments on the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>With CONTAINER, we have achieved state-of-theart Few-Shot NER performance leveraging Gaussian Embedding based contrastive learning. How-ever, the overall performance is still quite low compared to supervised NER that takes advantage of the full training dataset. Consequently, it is still not ready for deployment in high-stake domains (e.g. Medical Domain, I2B2 dataset), leaving a lot of room for improvement in future research.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ben</forename><surname>Athiwaratkun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><forename type="middle">Gordon</forename><surname>Wilson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.09843</idno>
		<title level="m">Hierarchical density order embeddings</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Few-shot text classification with distributional signatures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yujia</forename><surname>Bao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Menghua</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shiyu</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Regina</forename><surname>Barzilay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICLR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aleksandar</forename><surname>Bojchevski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><surname>G?nnemann</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1707.03815</idno>
		<title level="m">Deep gaussian embedding of graphs: Unsupervised inductive learning via ranking</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A simple framework for contrastive learning of visual representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Simon</forename><surname>Kornblith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Geoffrey</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leyang</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sen</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yue</forename><surname>Zhang</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2106.01760</idno>
		<title level="m">Template-based named entity recognition using bart</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Results of the wnut2017 shared task on novel and emerging entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Leon</forename><surname>Derczynski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eric</forename><surname>Nichols</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marieke</forename><surname>Van Erp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nut</forename><surname>Limsopatham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd Workshop on Noisy User-generated Text</title>
		<meeting>the 3rd Workshop on Noisy User-generated Text</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="140" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jacob</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Wei</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kristina</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Few-nerd: A few-shot named entity recognition dataset</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ning</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guangwei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yulin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaobin</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengjun</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haitao</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</title>
		<meeting>the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2021" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="3198" to="3213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Multi-task self-supervised visual learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl</forename><surname>Doersch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="2051" to="2060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Discriminative unsupervised feature learning with convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexey</forename><surname>Dosovitskiy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jost</forename><forename type="middle">Tobias</forename><surname>Springenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Riedmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="766" to="774" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Oneshot learning of object categories. IEEE transactions on pattern analysis and machine intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rob</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pietro</forename><surname>Perona</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="594" to="611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Few-shot classification in named entity recognition task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alexander</forename><surname>Fritzler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Varvara</forename><surname>Logacheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maksim</forename><surname>Kretov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing</title>
		<meeting>the 34th ACM/SIGAPP Symposium on Applied Computing</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="993" to="1000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruiying</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Binhua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongbin</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.10482</idno>
		<title level="m">Xiaodan Zhu, Ping Jian, and Jian Sun. 2019. Induction networks for few-shot text classification</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Winer: A wikipedia annotated corpus for named entity recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abbas</forename><surname>Ghaddar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philippe</forename><surname>Langlais</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eighth International Joint Conference on Natural Language Processing</title>
		<meeting>the Eighth International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<publisher>Long Papers</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="413" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dimensionality reduction by learning an invariant mapping</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raia</forename><surname>Hadsell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sumit</forename><surname>Chopra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;06)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2006" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1735" to="1742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Fewrel: A large-scale supervised few-shot relation classification dataset with state-of-the-art evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hao</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pengfei</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ziyun</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuan</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiyuan</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maosong</forename><surname>Sun</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.10147</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Fewshot slot tagging with collapsed dependency transfer and label-enhanced task-adaptive projection network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yutai</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wanxiang</forename><surname>Che</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yongkui</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhihan</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yijia</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Han</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ting</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.05702</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiaxin</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chunyuan</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Krishan</forename><surname>Subudhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Damien</forename><surname>Jose</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shobana</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Weizhu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baolin</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jiawei</forename><surname>Han</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2012.14978</idno>
		<title level="m">Fewshot named entity recognition: A comprehensive study</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Bidirectional lstm-crf models for sequence tagging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prannay</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Piotr</forename><surname>Teterwak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Sarna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yonglong</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Phillip</forename><surname>Isola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Maschinot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.11362</idno>
		<title level="m">Ce Liu, and Dilip Krishnan. 2020. Supervised contrastive learning</title>
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fernando Cn</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ICML</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">One shot learning of simple visual concepts</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brenden</forename><surname>Lake</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ruslan</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jason</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the annual meeting of the cognitive science society</title>
		<meeting>the annual meeting of the cognitive science society</meeting>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Guillaume</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Miguel</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sandeep</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kazuya</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chris</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01360</idno>
		<title level="m">Neural architectures for named entity recognition</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xuezhe</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01354</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Selfsupervised learning of pretext-invariant representations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ishan</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Van Der Maaten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6707" to="6717" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">True few-shot learning with language models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ethan</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douwe</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyunghyun</forename><surname>Cho</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2105.11447</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mark</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohit</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matt</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christopher</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenton</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<title level="m">Deep contextualized word representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Conceptualized and contextualized gaussian embedding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fuli</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lijie</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tat-Seng</forename><surname>Chua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="13683" to="13691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Erik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fien</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De Meulder</surname></persName>
		</author>
		<idno>cs/0306050</idno>
		<title level="m">Introduction to the conll-2003 shared task: Languageindependent named entity recognition</title>
		<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jake</forename><surname>Snell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><surname>Swersky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1703.05175</idno>
		<title level="m">Prototypical networks for few-shot learning</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Annotating longitudinal clinical narratives for de-identification: The 2014 i2b2/uthealth corpus</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amber</forename><surname>Stubbs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">?zlem</forename><surname>Uzuner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="20" to="29" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Vilnis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6623</idno>
		<title level="m">Word representations via gaussian embedding</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Matching networks for one shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oriol</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Charles</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><surname>Lillicrap</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daan</forename><surname>Wierstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<pubPlace>NeurIPS</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Simpleshot: Revisiting nearest-neighbor classification for few-shot learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wei-Lun</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Kilian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Laurens</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Van Der Maaten</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.04623</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Jing Gao, and Ahmed Hassan Awadallah. 2021. Meta self-training for fewshot neural sequence labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaqing</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Subhabrata</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Haoda</forename><surname>Chu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuancheng</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</title>
		<meeting>the 27th ACM SIGKDD Conference on Knowledge Discovery &amp; Data Mining</meeting>
		<imprint>
			<biblScope unit="page" from="1737" to="1747" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ralph</forename><surname>Weischedel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martha</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitchell</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sameer</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lance</forename><surname>Ramshaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianwen</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ann</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Kaufman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michelle</forename><surname>Franchini</surname></persName>
		</author>
		<title level="m">Ontonotes release 5.0 ldc2013t19. Linguistic Data Consortium, Philadelphia</title>
		<meeting><address><addrLine>PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Label-agnostic sequence labeling by copying nearest neighbors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sam</forename><surname>Wiseman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karl</forename><surname>Stratos</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.04225</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unsupervised feature learning via nonparametric instance discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yuanjun</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Stella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahua</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="3733" to="3742" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Simple and effective few-shot named entity recognition with structured nearest neighbor learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yi</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arzoo</forename><surname>Katiyar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</title>
		<meeting>the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6365" to="6375" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Unsupervised embedding learning via invariant and spreading instance feature</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mang</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shih-Fu</forename><surname>Yuen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6210" to="6219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">The GUM corpus: Creating multilayer resources in the classroom. Language Resources and Evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Amir</forename><surname>Zeldes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Local aggregation for unsupervised learning of visual embeddings</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<editor>Chengxu Zhuang, Alex Lin Zhai, and Daniel Yamins</editor>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6002" to="6012" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
