<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Spin-Weighted Spherical CNNs</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Esteves</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameesh</forename><surname>Makadia</surname></persName>
							<email>makadia@google.com</email>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Google</forename><surname>Research</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
							<email>kostas@cis.upenn.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">GRASP Laboratory University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">GRASP Laboratory University of Pennsylvania</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Spin-Weighted Spherical CNNs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T08:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Learning equivariant representations is a promising way to reduce sample and model complexity and improve the generalization performance of deep neural networks. The spherical CNNs are successful examples, producing SO(3)-equivariant representations of spherical inputs. There are two main types of spherical CNNs. The first type lifts the inputs to functions on the rotation group SO(3) and applies convolutions on the group, which are computationally expensive since SO <ref type="formula">(3)</ref> has one extra dimension. The second type applies convolutions directly on the sphere, which are limited to zonal (isotropic) filters, and thus have limited expressivity. In this paper, we present a new type of spherical CNN that allows anisotropic filters in an efficient way, without ever leaving the spherical domain. The key idea is to consider spin-weighted spherical functions, which were introduced in physics in the study of gravitational waves. These are complex-valued functions on the sphere whose phases change upon rotation. We define a convolution between spin-weighted functions and build a CNN based on it. The spin-weighted functions can also be interpreted as spherical vector fields, allowing applications to tasks where the inputs or outputs are vector fields. Experiments show that our method outperforms previous methods on tasks like classification of spherical images, classification of 3D shapes and semantic segmentation of spherical panoramas.</p><p>Recently, there has been significant work extending equivariance to other groups of transformations <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b48">49,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b49">50,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b47">48,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b3">4]</ref> and designing equivariant CNNs on non-Euclidean domains <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b41">42,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b7">8,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b41">42,</ref> 53]. Successful applications have been demonstrated in tasks such as 3D shape analysis <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b17">18]</ref>, medical imaging <ref type="bibr" target="#b46">[47,</ref><ref type="bibr" target="#b2">3]</ref>, satellite/aerial imaging <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b21">22]</ref>, cosmology <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b37">38]</ref>, physics/chemistry <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b0">1]</ref>. Favorable results were also shown on popular upright natural image datasets such as CIFAR10/100 <ref type="bibr" target="#b43">[44]</ref>.</p><p>Rotation equivariant CNNs are the natural way to learn feature representations on spherical data. There are two prevailing designs, (a) convolution between spherical functions and zonal (isotropic; constant per latitude) filters <ref type="bibr" target="#b15">[16]</ref>, and (b) convolutions on SO(3) after lifting spherical functions to the rotation group <ref type="bibr" target="#b10">[11]</ref>. There is a clear distinction between these two designs: (a) is more efficient allowing to build representational capacity through deeper networks, and (b) has more expressive filters but is computationally expensive and thus is constrained to shallower networks. The question we consider in this paper is: how can we achieve the expressivity/representation capacity of SO(3) convolutions with the efficiency and scalability of spherical convolutions?</p><p>Equivariant CNNs The first equivariant CNNs were applied to images on the plane <ref type="bibr" target="#b19">[20,</ref><ref type="bibr" target="#b12">13]</ref>. Cohen and Welling [9] formalized these models and named them group equivariant convolutional neural networks (G-CNNs). While initial methods were constrained to small discrete groups of rotations on the plane, they were later extended to larger groups [46], continuous rotations <ref type="bibr" target="#b48">[49]</ref>, rotations and scale <ref type="bibr" target="#b16">[17]</ref>, 3D rotations of voxel grids <ref type="bibr" target="#b47">[48,</ref><ref type="bibr" target="#b44">45]</ref>, and point clouds <ref type="bibr" target="#b41">[42]</ref>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Learning representations from data enables a variety of applications that are not possible with other methods. Convolutional neural networks (CNNs) are powerful tools in representation learning, in great part due to their translation equivariance property that allows weight-sharing, exploiting the natural structure of audio, image, or video inputs.</p><p>In this paper, we propose to leverage spin-weighted spherical functions (SWSFs), introduced by Newman and Penrose <ref type="bibr" target="#b36">[37]</ref> in the study of gravitational waves. These are complex-valued functions on the sphere that, upon rotation, suffer a phase change besides the usual spherical translation. Our key observation is that a combination of SWSFs allows more expressive representations than scalar spherical functions, avoiding the need to lift features to the higher dimensional SO <ref type="bibr" target="#b2">(3)</ref>. It also enables anisotropic filters, removing the filter constraint of purely spherical CNNs.</p><p>We define convolutions and cross-correlations of SWSFs. For bandlimited inputs, the operations can be computed exactly in the spectral domain, and are equivariant to the continuous group SO <ref type="bibr" target="#b2">(3)</ref>. We build a CNN where filters and features are sets of SWSFs, and adapt nonlinearities, batch normalization, and pooling layers as necessary.</p><p>Besides more expressive and efficient representations, we can interpret the spin-weighted features as equivariant vector fields on the sphere, enabling applications where the inputs or outputs are vector fields. Current spherical CNNs <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b37">38]</ref> cannot achieve equivariance in this sense, as illustrated in <ref type="figure" target="#fig_0">Fig. 1</ref>.</p><p>To evaluate vector field equivariance, we introduce a variation of MNIST where the images and their gradients are projected to the sphere. We propose three tasks on this dataset: 1) vector field classification, 2) vector field prediction from scalar fields, 3) scalar field prediction from vector fields. We also evaluate our model on spherical image classification, 3D shape classification, and semantic segmentation of spherical panoramas.</p><p>To summarize our contributions, Spherical CNNs G-CNNs can be extended to homogeneous spaces of groups of symmetries <ref type="bibr" target="#b29">[30]</ref>; the quintessential example is the sphere S 2 as a homogeneous space of the group SO(3), the setting of spherical CNNs. There are two main branches. The first branch, introduced by Cohen et al. <ref type="bibr" target="#b10">[11]</ref>, lifts the spherical inputs to functions on SO(3), and its filters and features are functions on the group SO(3), which is higher dimensional and thus more computationally expensive to process. Kondor et al. <ref type="bibr" target="#b27">[28]</ref> is another example. The second branch, introduced by Esteves et al. <ref type="bibr" target="#b15">[16]</ref>, is purely spherical and has filters and features on S 2 , using spherical convolution as the main operation. In this case, the filters are constrained to be zonal (isotropic), which limits the representational power. Perraudin et al. <ref type="bibr" target="#b37">[38]</ref> also uses isotropic filters, but with graph convolutions instead of spherical convolutions.</p><p>Our approach lies between these two branches. It is not restricted to isotropic filters but it does not have to lift features to SO(3); we employ sets of SWSFs as filters and features.</p><p>A separate line of work developed spherical CNNs that are not rotation-equivariant <ref type="bibr" target="#b24">[25,</ref><ref type="bibr">52]</ref>, which rely on the strong assumption that the inputs are aligned.</p><p>Equivariant vector fields Our approach can equivariantly handle spherical vector fields as inputs or outputs. Marcos et al. <ref type="bibr" target="#b34">[35]</ref> introduced a planar CNN whose features are vector fields obtained from rotated filters. Cohen and Welling <ref type="bibr" target="#b11">[12]</ref> formalized the concept of feature types that are vectors in a group representation space. This was extended to 3D Euclidean space by Weiler et al. <ref type="bibr" target="#b44">[45]</ref>. Worrall et al. <ref type="bibr" target="#b48">[49]</ref> introduced complex-valued features on R 2 whose phases change upon rotation; this is similar in spirit to our method, but our features live on the sphere, requiring different machinery.</p><p>Cohen et al. <ref type="bibr" target="#b7">[8]</ref> introduced a framework that produces vector field features on general manifolds; it was specialized to the sphere by Kicanaoglu et al. <ref type="bibr" target="#b25">[26]</ref>. The major differences are that our implementation is fully spectral and we demonstrate it on tasks requiring vector field equivariance. Cohen et al. <ref type="bibr" target="#b9">[10]</ref> alluded to the possibility of building spherical CNNs that can process vector fields; we materialize these networks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Background</head><p>In this section, we provide the mathematical background that guides our contributions. We first introduce the more commonly encountered spherical harmonics, then the generalization to the spinweighted spherical harmonics (SWSHs). We also describe convolutions between spherical functions, which we will later generalize to convolutions between spin-weighted functions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spherical Harmonics</head><p>The spherical harmonics Y m : S 2 ? C form an orthonormal basis for the space L 2 (S 2 ) of square integrable functions on the sphere.</p><p>Any function f : S 2 ? C in L 2 (S 2 ) can be decomposed in this basis via the spherical Fourier transform (SFT) (Eq. (1)), and synthesized back exactly via its inverse (Eq. (2)),</p><formula xml:id="formula_0">f m = S 2 f (x)Y m (x) dx, (1) f (x) = ? =0 |m|? f m Y m (x).<label>(2)</label></formula><p>We interchangeably use latitudes and longitudes (?, ?) or points x ? R 3 , x = 1 to index the sphere, and we use the hat to denote Fourier coefficients. A function has bandwidth B when only components of order ? B appear in the expansion.</p><p>The spherical harmonics are related to irreducible representations of the group SO(3) as follows,</p><formula xml:id="formula_1">D m,0 (?, ?, ?) = 4? 2 + 1 Y m (?, ?),<label>(3)</label></formula><p>where ?, ? and ? are ZYZ Euler angles and D is a Wigner-D matrix. <ref type="bibr" target="#b0">1</ref> Since D is a group representation and hence a group homomorphism, we obtain a rotation formula,</p><formula xml:id="formula_2">Y m (gx) = n=? D m,n (g)Y n (x),<label>(4)</label></formula><p>where we interchangeably use an element g ? SO(3) or Euler angles ?, ? and ? to refer to rotations.</p><p>Consider the rotation of a function represented by its coefficients by combining Eqs. (2) and (4),</p><formula xml:id="formula_3">f (gx) = ? =0 n=? m=? f m D m,n (g) Y n (x).<label>(5)</label></formula><p>This shows that when f (x) ? f (gx), its Fourier coefficients transform a?</p><formula xml:id="formula_4">f n ? m D m,n (g)f m<label>(6)</label></formula><p>Finally, we recall how convolutions and cross-correlations of spherical functions are computed in the spectral domain. Esteves et al. <ref type="bibr" target="#b15">[16]</ref> define the convolution between two spherical functions f and k as Eq. (7) while Makadia and Daniilidis <ref type="bibr" target="#b33">[34]</ref> and Cohen et al. <ref type="bibr" target="#b10">[11]</ref> define the spherical cross-correlation as Eq. <ref type="formula" target="#formula_5">(8)</ref>,</p><formula xml:id="formula_5">( k * f ) m = 2? 4? 2 + 1f mk 0 , (7) ( k f ) m,n =f mk n ,<label>(8)</label></formula><p>Both are shown to be equivariant through Eq. This section laid the foundation for the spin-weighted generalization. We refer to Esteves <ref type="bibr" target="#b14">[15]</ref> for a longer exposition on this topic and to Vilenkin and Klimyk <ref type="bibr" target="#b42">[43]</ref> and Folland <ref type="bibr" target="#b18">[19]</ref> for the full details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spin-Weighted Spherical Harmonics</head><p>The spin-weighted spherical functions (SWSFs) are complex-valued functions on the sphere whose phases change upon rotation. They have different types determined by the spin weight.</p><p>Let s f : S 2 ? C be a SWSF with spin weight s, ? ? a rotation by ? around the polar axis, and ? the north pole. In a conventional spherical function, ? is fixed by the rotation, so (? ? (f ))(?) = f (?). In a spin-weighted function, however, the rotation results in a phase change,</p><formula xml:id="formula_6">(? ? ( s f ))(?) = s f (?)e ?is? .<label>(9)</label></formula><p>If the spin weight is s = 0, this is equivalent to the conventional spherical functions.</p><p>The spin-weighted spherical harmonics (SWSHs) form a basis of the space of square-integrable spin-weighted spherical functions; for all square-integrable s f , we can write</p><formula xml:id="formula_7">s f (?, ?) = ?N m=? s Y m (?, ?) sf m ,<label>(10)</label></formula><p>where sf m are the expansion coefficients, and the decomposition is defined similarly to Eq. (1). For s = 0, the SWSHs are exactly the spherical harmonics; we have 0 Y m = Y m .</p><p>The SWSHs are related to the matrix elements D mn of SO(3) representations as follows,</p><formula xml:id="formula_8">D m,?s (?, ?, ?) = (?1) s 4? 2 + 1 s Y m (?, ?)e ?is? .<label>(11)</label></formula><p>Note how different spin-weights are related to different columns of D , while the standard spherical harmonics are related to a single column as in Eq.</p><p>(3). This shows that the SWSHs can be seen as functions on SO(3) with sparse spectrum, a point of view that is advocated by Boyle <ref type="bibr" target="#b5">[6]</ref>.</p><p>The SWSHs do not transform among themselves upon rotation as the spherical harmonics (Eq. (4)) due to the extra phase change. Fortunately, the coefficients of expansion of a SWSF into the SWSHs do transform among themselves according to Eq. <ref type="formula" target="#formula_4">(6)</ref>.</p><formula xml:id="formula_9">When s f (x) ? s f (gx), sf n ? m D m,n (g) sf m .<label>(12)</label></formula><p>This is crucial for defining equivariant convolutions between combinations of SWSFs as we will do in Section 4.1. We refer to Castillo <ref type="bibr" target="#b6">[7]</ref> and Boyle <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b5">6]</ref> for more details about SWSFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Method</head><p>We introduce a fully convolutional network, the spin-weighted spherical CNN (SWSCNN), where layers are based on spin-weighted convolutions, and filters and features are combinations of SWSFs. We define spin-weighted convolutions and cross-correlations, show how to efficiently implement them, and adapt common neural network layers to work with combinations of SWSFs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Spin-Weighted Convolutions and Cross-Correlations</head><p>We define and evaluate the convolutions and cross-correlations in the spectral domain. Consider a set of spin weights W F , W K and sets of functions F = { s f :</p><formula xml:id="formula_10">S 2 ? C | s ? W F } and filters K = { s k : S 2 ? C | s ? W K } to be convolved.</formula><p>Spin-weighted convolution We define the convolution between F and K as follows,</p><formula xml:id="formula_11">s ( F * K) m = i?W F if m sk i ,<label>(13)</label></formula><p>where s ? W K and ? ? m ? . Only coefficients sk i where i ? W F influence the output, imposing sparsity in the spectra of K. The convolution F * K is also a set of SWSFs with s ? W K , the same spin weights as K; we leverage this to specify the desired sets of spins at each layer.</p><p>We show this operation is SO(3) equivariant by applying the rotation formula from Eq. <ref type="bibr" target="#b11">(12)</ref>. Let ? g denote a rotation of each s f (x) ? F by g ? SO(3). We have,</p><formula xml:id="formula_12">s ( ? g F * K) n = i?W F m D m,n (g) if m sk i = m D m,n (g) i?W F if m sk i = m D m,n (g) s ( F * K) m = ? g ( s ( F * K) n ).<label>(14)</label></formula><p>Now consider the spherical convolution defined in Eq. <ref type="bibr" target="#b6">(7)</ref>. It follows immediately that it is, up to a constant, a special case of the spin-weighted convolution, where F and K have only one element with s = 0, and only the filter coefficients of form 0k 0 are used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Spin-weighted cross-correlation</head><p>We define the cross-correlation between F and K as follows,</p><formula xml:id="formula_13">s ( F K) m = i?W F ?W K if m ik s ,<label>(15)</label></formula><p>In this case, only the spins that are common to F and K are used, but all spins may appear in the output, so it can be seen as a function on SO(3) with dense spectrum. To ensure a desired set of spins in F K, we can sparsify the spectra in K by eliminating some orders. A procedure similar to Eq. (14) proves the SO(3) equivariance of this operation.</p><p>The spin-weighted cross-correlation generalizes the spherical cross-correlation. When F and K contain only a single spin weight s = 0, the summation in Eq. (15) will contain only one term and we recover the spherical cross-correlation defined in Eq. <ref type="bibr" target="#b7">(8)</ref>.</p><p>Examples To visualize the convolution and cross-correlations, we use the phase of the complex numbers and define local frames to obtain a vector field. We visualize combinations of SWSFs by associating pixel intensities with the spin-weight s = 0 and plotting vector fields for each s &gt; 0.</p><p>Consider an input F = { 0 f, 1 f } and filter K = { 0 k, 1 k}, both with spin weights 0 and 1. Their convolution also has spins 0 and 1, as shown on the left side of <ref type="figure" target="#fig_2">Fig. 2</ref>. Now consider a scalar valued (spin s = 0) input F = { 0 f } and filter K = { 0 k}. The cross-correlation will have components of every spin, but we only take spin weights 0 and 1 to visualize (this is equivalent to eliminating all orders larger than 1 in the spectrum of k); <ref type="figure" target="#fig_2">Fig. 2</ref> shows the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Spin-weighted spherical CNNs</head><p>Our main operation is the convolution defined in Section 4.1. Since components with the same spin can be added, the generalization to multiple channels is immediate. The convolution combines features of different spins, so we enforce the same number of channels per spin per layer. Each feature map then consists of a set of SWSFs of different spins, F = { s f :</p><formula xml:id="formula_14">S 2 ? C k | s ? W F },</formula><p>where k is the number of channels and W F the set of spin weights. Filter localization We compute the convolutions in the spectral domain but apply nonlinearities, batch normalization and pooling in the spatial domain. This requires expanding the feature maps into the SWSHs basis and back at every layer, but the filters themselves are parameterized by their spectrum. We follow the idea of Esteves et al. <ref type="bibr" target="#b15">[16]</ref> to enforce filter localization with spectral smoothness. Their filters are of the form 0k 0 , so the spectrum is 1D and can be interpolated from a few anchor points, smoothing it out and reducing the number of parameters. In our case, the filters take the general form sk m where s ? W F * K are the output spin weights and m ? W F are the input spin weights. We then interpolate the spectrum of each component along the degrees , resulting in a factor of |W F * K ||W F | more parameters per layer.</p><p>Batch normalization and nonlinearity We force features with spin weight s = 0 to be real by taking their real part after every convolution. Then we can use the common rectified linear unit (ReLU) as the nonlinearity and the standard batch normalization from Ioffe and Szegedy <ref type="bibr" target="#b23">[24]</ref>.</p><p>For s &gt; 0, we have complex-valued feature maps. Since values move and change phase upon rotation, equivariant operations must commute with this behavior. Pointwise operations on magnitudes satisfy this requirement. Similarly to Worrall et al. <ref type="bibr" target="#b48">[49]</ref>, we employ a variation of the ReLU to the complex values z = ae i? as follows, where a ? R + and b ? R is a learnable scalar,</p><formula xml:id="formula_15">z ? max(a + b, 0)e i? .<label>(16)</label></formula><p>Batch normalization is also applied pointwise, but it does not commute with spin-weighted rotations because of the mean subtraction and offset addition steps. We adapt it by removing these steps, where ? 2 is the channel variance, ? ? C is a learnable factor and ? R + is a constant added for stability,</p><formula xml:id="formula_16">z ? z ? ? 2 + ?.<label>(17)</label></formula><p>As usual, the variance is computed along the batch during training and along the whole dataset during inference. The variance of a set of complex numbers is real and only depends on their magnitudes; we use a spherical quadrature rule to compute it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Complexity analysis</head><p>We follow Huffenberger and Wandelt <ref type="bibr" target="#b22">[23]</ref> for the spin-weighted spherical Fourier transform (SWSFT) implementation (see appendix for details), whose complexity for bandwidth B is O(B 3 ). While it is asymptotically slower than the O(B 2 log 2 B) of the standard SFT from Driscoll and Healy <ref type="bibr" target="#b13">[14]</ref>, the difference is small for bandwidths typically needed in practice <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b27">28]</ref>. The rotation group Fourier transform (SOFT) implementation from Kostelec and Rockmore <ref type="bibr" target="#b30">[31]</ref> is O(B 4 ). Our final model requires |W | transforms per layer, so it is asymptotically a factor |W |B /log 2 B slower than using SFT as in Esteves et al. <ref type="bibr" target="#b15">[16]</ref>, and a factor B /|W | faster than using the SOFT as in Cohen et al. <ref type="bibr" target="#b10">[11]</ref>. Typical values in our experiments are B = 32 and |W | = 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>We start with experiments on image and vector field classification, image prediction from a vector field, and vector field from an image, where all images and vector fields are on the sphere. Next, we show applications to 3D shape classification and semantic segmentation of spherical panoramas.</p><p>All experiments use spin weights 0 and 1. When inputs do not have both spins, the first layer is designed such that its outputs have. All following layers and filters also have spins 0 and 1.</p><p>Every model is trained with different random seeds five times and averages and standard deviations (within parenthesis) are reported. See the appendix for training procedure details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Spherical Image Classification</head><p>Our first experiment is on the Spherical MNIST dataset introduced by Cohen et al. <ref type="bibr" target="#b10">[11]</ref>. This is an image classification task where the handwritten digits from MNIST are projected on the sphere. Three modes are evaluated depending on whether the training/test set are rotated (R) or not (NR).</p><p>We simplify the architecture in Esteves et al. <ref type="bibr" target="#b15">[16]</ref> to have a single branch, switch from spherical to spin-weighted convolutions, and adapt the numbers of channels and parameters per filter to match the parameter counts. <ref type="table" target="#tab_0">Table 1</ref> shows the results; we outperform previous spherical CNNs in every mode.  One crucial advantage of the SWSCNNs is that they are equivariant as vector fields. To demonstrate this, we introduce a spherical vector field dataset. We start from MNIST <ref type="bibr" target="#b32">[33]</ref>, compute the image gradients with Sobel kernels and project the vectors to the sphere. To increase the challenge, we follow Larochelle et al. <ref type="bibr" target="#b31">[32]</ref> and swap the train and test sets so there are 10 k images for training and 50 k for test. We call this dataset the spherical vector field MNIST (SVFMNIST). The vector field is converted to a spin weight s = 1 complex-valued function using a predefined local tangent frame per point on the sphere. The inverse procedure converts s = 1 features to output vector fields.</p><p>The first task we consider is classification. We use the same architecture as in the previous experiment, the only difference is that now the first layer maps from spin 1 to spins 0 and 1. <ref type="table" target="#tab_1">Table 2</ref> shows the results. The planar and spherical CNN models take the vector field as a 2-channel input. The NR/R column clearly shows the advantage of vector field equivariance; the baselines cannot generalize to unseen vector field rotations, even when they are equivariant in the scalar sense as <ref type="bibr" target="#b15">[16]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Spherical Vector Field Prediction</head><p>The SWSCNNs can also be used for dense prediction. We introduce two new tasks on SVFMNIST, 1) predicting a vector field from an image and 2) predicting an image from a vector field. For these tasks, we implement a fully convolutional U-Net architecture <ref type="bibr" target="#b39">[40]</ref> with spin-weighted convolutions.</p><p>When the image is a grayscale digit and the vector field comes from its gradients, both tasks can be easily solved via discrete integration and differentiation. We call this case "easy" and show it on the left side of <ref type="table" target="#tab_2">table Table 3</ref>. It highlights a limitation of isotropic spherical CNNs; the results show that the constrained filters cannot approximate a simple image gradient operator.</p><p>We also experiment with a more challenging scenario, where the digits are colored and the vector fields are rotated based on the digit category. These are semantic tasks that require the network to implicitly classify the input in order to correctly predict output color and vector directions. <ref type="table" target="#tab_2">Table 3</ref> shows the results. While the planar baseline does well in the "easy" tasks that can be solved with simple linear operators, our model still outperforms it when generalization to unseen rotations is demanded (NR/R). In the "hard" task, the SWSCNNs are clearly superior by large margins. We show sample inputs and outputs in <ref type="figure">Fig. 3</ref>; see the appendix for more.  <ref type="figure">Figure 3</ref>: Input, output and ground truth for dense prediction tasks on rotated train and test sets (R/R). Top: vector field to image. Conventional and spherical CNNs <ref type="bibr" target="#b15">[16]</ref> predict the incorrect color, in contrast with our SWSCNNs. Bottom: image to vector field. Our method predicts the position and orientation of each vector correctly, while the alternatives cannot. We tackle 3D object classification on ModelNet40 <ref type="bibr" target="#b50">[51]</ref>, following the protocol from Esteves et al. <ref type="bibr" target="#b15">[16]</ref> which considers azimuthally and arbitrarily rotated shapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Classification of 3D shapes</head><p>Besides more expressive filters, our method also represents the shapes more faithfully on the sphere. Esteves et al. <ref type="bibr" target="#b15">[16]</ref> and Cohen et al. <ref type="bibr" target="#b10">[11]</ref> cast rays from the shape's center and assign the intersection distance and angle between normal and ray to points on the sphere. Normals are not uniquely determined by a single angle but this limitation was necessary to preserve equivariance as a scalar field.</p><p>By using SWSCNNs, we can represent any normal direction uniquely, without breaking equivariance. We split the vector in radial and tangent components, where the radial is represented with spin s = 0 and the tangent has s = 1. Since the intersection distance is also a function with s = 0, our 3D shape representation has two spherical channels with s = 0 and one of s = 1. Following Cohen et al. <ref type="bibr" target="#b10">[11]</ref>, we also use the convex hull for extra channels.</p><p>When inputs have limited orientations, a globally equivariant model can be undesirable, even though equivariance in the local sense is still useful. We can keep the benefits while still having access to the global pose by breaking equivariance on the final layers, which we do by simply replacing them with regular 2D convolutions. We call this model "Ours + BE"; it results in better performance on "upright" but worse on "rotated", as expected. <ref type="table" target="#tab_3">Table 4</ref> compares with previous spherical CNNs. The "upright" mode has only azimuthal rotations while "rotated" is unrestricted. EMVN <ref type="bibr" target="#b17">[18]</ref> is state-of-the-art on this task with 94.4% accuracy on "upright" and 91.1% on "rotated", but it requires 60 images as input and much larger model. We evaluate our method on the Stanford 2D3DS dataset <ref type="bibr" target="#b1">[2]</ref>, following the usual protocol of reporting the average performance over the three official folds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Semantic segmentation of spherical panoramas</head><p>As in Section 5.4, our model is able uniquely represent surface normals. In this task, representing the normals with respect to local tangent frames is also more realistic, as they could be estimated from a depth sensor without knowledge of global orientation. Note that competing methods don't usually leverage the normals, so we also show results without them for comparison. <ref type="table" target="#tab_4">Table 5</ref> shows the results. Inputs are upright so global SO(3) equivariance is not required; nevertheless, our method matches the state-of-the-art performance, which demonstrates the expressivity of the SWSCNNs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper, we introduced the spin-weighted spherical CNNs, which use sets of spin-weighted spherical functions as features and filters, and employ layers of a newly introduced spin-weighted spherical convolution to process spherical images or spherical vector fields. Our model achieves superior performance on the tasks attempted, at a reasonable computational cost. We foresee further applications of the SWSCNNs to 3D shape analysis, climate/atmospheric data analysis and other tasks where inputs or outputs can be represented as spherical images or vector fields.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Broader Impact</head><p>This paper presents advances on learning representations from spherical data. It has potential beneficial applications to climate and atmospheric modeling, for example.</p><p>The method is in the broad category of equivariant CNNs, which have the goal to reduce model and sample complexity and improve generalization performance. This potentially translates to models that are more energy efficient, and are more accessible to individuals without access to large computational resources. On the flip side, most technology can also be applied for harmful purposes, and when making it more accessible we also risk enabling bad actors to make use of it.</p><p>[ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendices</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Introduction</head><p>In this supplementary material we give more details about the datasets in Appendix B, about the experiments in Appendices C to E, and we describe the SWSH transform implementation in Appendix F.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B Datasets</head><p>We show samples of the SVFMNIST dataset in <ref type="figure">Fig. 4</ref>. This is the dataset used in the vector field classification task. <ref type="figure">Figure 4</ref>: Samples from SVFMNIST, classification task. We show one sample for each category in canonical orientation for easy visualization.</p><p>For the dense prediction tasks, we introduce modifications in the targets to make them more challenging. When predicting an image from a vector field, we introduce color in the output based on the target category. We determine the color in HSV space, where the value is the original grayscale value, the hue is c/10 for category c, and the saturation is set to one. The target is then converted back to RGB. <ref type="figure" target="#fig_3">Figure 5</ref> shows a few input/target pairs.</p><p>When predicting a vector field from an image, we introduce an angular offset on all vectors that depends on the target category. The offset for category c is given by exp(2?ic/10). <ref type="figure" target="#fig_1">Figure 6</ref> shows a few input/target pairs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C MNIST Experiments Details</head><p>In these experiments, we train for 12 epochs using the Adam optimizer <ref type="bibr" target="#b26">[27]</ref>. We set the initial learning rate to 1 ? 10 ?3 and decay it to 2 ? 10 ?4 epoch 6 and 4 ? 10 ?5 at epoch 10. The mini-batch size is set to 32 and input resolution is 64 ? 64.</p><p>The usual cross-entropy loss is optimized for the classification experiments, and the mean squared error is minimized for dense prediction.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1 Classification</head><p>The architectures for spherical image and vector field classification are the same.</p><p>The spherical baseline follows Esteves et al. <ref type="bibr" target="#b15">[16]</ref>, with spherical convolutions, six layers with 16, 16, 32, 32, 58, 58 channels per layer, and 8 filter parameters per layer.</p><p>We follow the same general topology, switching from spherical to spin-weighted convolutions. Since our filters have richer spectra, they need more parameters. In order to keep similar number of parameters between competing models, we set the number parameters per spin-order pair (s, m) 2 to 6, 6, 4, 4, 3, 3 at each layer. We also cut the number of channels per layer, so while we have the same number of parameters, we have significantly fewer feature maps. The final architecture has 16, 16, 20, 24, 28, 32 channels per layer, with pooling every two layers, and our custom batch normalization applied at every layer.</p><p>The planar baseline has the same number of layers and uses 2D convolutions with 3 ? 3 kernels. We set the number of channels per layer to <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr">54,</ref><ref type="bibr">54</ref>. to match the number of parameters of the other models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.2 Spherical vector field/image prediction</head><p>We design a different architecture for dense prediction, which is essentially a fully convolutional U-Net <ref type="bibr" target="#b39">[40]</ref> with spin-weighted convolutions.</p><p>We use 16, 32, 32, 32, 32, 16 channels per layer, with pooling in the first two layers and nearest neighbors upsampling in the last two. The number of filter parameters chosen per spin-order per layer is 6, 4, 3, 3, 4, 6.</p><p>The spherical CNN baseline uses spherical convolutions and sets the numbers of filter parameters to 8 per layer and the number of channels to 20, 40, 78, 78, 40, 20.</p><p>The planar baseline again uses 2D convolutions with 3 ? 3 kernels and of channels to 18, 36, 72, 72, 36, 18 channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.3 Input-output samples</head><p>We show extra examples of inputs and outputs for the dense prediction tasks. <ref type="figure">Figure 7</ref> shows the vector field to image task while <ref type="figure">Fig. 8</ref> shows the image to vector field task. Models are trained on the R mode, so they have access to rotated samples at training time. Nevertheless, the standard CNN and spherical CNN models are not equivariant in the vector field sense and cannot achieve the same accuracy as the SWSCNNs. <ref type="figure">Figure 7</ref>: Input/output samples for the spherical vector field to image task. We show two rotated instances of the same input to highlight that standard CNNs and spherical CNNs do not respect the spherical vector field equivariance, while the SWSCNNs do.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D Classification of 3D shapes</head><p>ModelNet40 <ref type="bibr" target="#b50">[51]</ref> training and test sets contain 9,843 and 2,468 CAD models, respectively. We evaluate following the protocol from Esteves et al. <ref type="bibr" target="#b15">[16]</ref> that includes multiple rotated copies of each object in training and test sets. The "upright" mode has azimuthal rotations only, while the "rotated" mode has arbitrary 3D rotations.</p><p>We train for 48 epochs using the Adam optimizer <ref type="bibr" target="#b26">[27]</ref>, with learning rate linearly increasing from 0 to 5 ? 10 ?3 during the first epoch then decayed by a factor of 5 at epochs 32 and 44. The mini-batch size is 32 and input resolution is 64 ? 64. The cross-entropy loss is optimized and we found that label smoothing regularization <ref type="bibr" target="#b40">[41]</ref> with = 0.2 is beneficial.</p><p>The basic block is residual <ref type="bibr" target="#b20">[21]</ref> with a bottleneck halving the number of channels when input and output have equal number of channels. Our custom batch normalization and nonlinearity is applied to the complex feature maps. We use 32, 32, 64, 64, 128, 128, 256, 256 channels per layer where average pooling is applied before each increase in the number of channels, and 6, 6, 4, 4, 3, 3, 3, 3 filter parameters are learned per spin-order per layer, with a total of 1.2 M parameters. When breaking <ref type="figure">Figure 8</ref>: Input/output samples for the spherical image to vector field task.</p><p>equivariance in "Ours + BE", we replace the last two layers by three blocks of 2D convolution with 3 ? 3 kernels.</p><p>The same training procedure and architecture are used for the SphCNN <ref type="bibr" target="#b15">[16]</ref> baseline, which explains the superior numbers we report when comparing with the original paper.</p><p>We evaluate the baseline from Jiang et al. <ref type="bibr" target="#b24">[25]</ref> following the recipe in the paper. The only difference is that we randomly rotate the training and test sets. Each training set object is rotated multiple times to serve as augmentation. The numbers we obtain differ from the 90.5 % accuracy reported in the original paper because our results are for azimuthally and arbitrarily rotated datasets while the original has all objects in a canonical pose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E Semantic segmentation of spherical panoramas</head><p>The Stanford 2D3DS dataset [2] contains 1,413 RGB-D panoramas with corresponding pixelwise semantic labels and normals. We follow the protocol from Jiang et al. <ref type="bibr" target="#b24">[25]</ref> that reports pixelwise accuracy and mean intersection-over-union (mIoU) averaged over the three official folds. We also use the same weights per class as Jiang et al. <ref type="bibr" target="#b24">[25]</ref> to mitigate the class imbalance.</p><p>We train for 48 epochs using the Adam optimizer <ref type="bibr" target="#b26">[27]</ref>, with the learning rate linearly increasing from 0 to 1 ? 10 ?2 during the first epoch then decayed by a factor of 10 at epoch 40. The mini-batch size is 8 and input resolution is 128 ? 128. The pixelwise cross-entropy loss is optimized with label smoothing regularization [41] with = 0.2.</p><p>A fully convolutional U-Net <ref type="bibr" target="#b39">[40]</ref> architecture is used with same residual block described in Appendix D. We use 16, 64, 128, 128, 256, 256, 128, 128, 64, 16 channels per layer where average pooling/nearest neighbor upsampling is applied before each increase/decrease in the number of channels, and 8, 6, 6, 4, 4, 3, 3, 4, 4, 6, 6, 8 filter parameters are learned per spin-order per layer, with a total of 2.5 M parameters. When breaking equivariance in "Ours + BE", we replace the last layer by six blocks of 2D convolutions with 3 ? 3 kernels and 32 channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>F Spin-Weighted Spherical Harmonics Transforms</head><p>Our implementation of the SWSH decomposition and its inverse follows Huffenberger and Wandelt <ref type="bibr" target="#b22">[23]</ref>. The basic idea is to leverage the relation between the SWSHs and the Wigner-D matrices.</p><p>Recall that we can write the Wigner-D matrices as D m,n (?, ?, ?) = e ?im? d m,n (?)e ?in? ,</p><p>where d is a Wigner-d matrix.</p><p>where? can be obtained analytically. Note that the last expression is a 1D discrete convolution; if we see? as the Fourier transform of some w, the convolution can be evaluated as the FFT of the multiplication in the spatial domain,</p><formula xml:id="formula_18">I k,m = 2? N 2 ?,? s f (?, ?)w(?)e ?ik? e ?im? ,<label>(23)</label></formula><p>for N uniformly sampled ?, ?. Here, w can be pre-computed, so the I k,m computation amounts to 1) extend the function to the torus, 2) apply the weights w, 3) compute a 2D FFT.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Colors represent a scalar field, and the green vectors represent a vector field. Upon rotation, scalar fields transform by simply moving values to another position, while vector fields move and also rotate. Treating vector fields as multi-channel scalars (bottom-right) results in incorrect behavior. The spinweighted spherical CNNs equivariantly handle vector fields as inputs or outputs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>( 6 )</head><label>6</label><figDesc>. The left-hand side of Eq. (7) correspond to the Fourier coefficients of a spherical function, while the left-hand side of Eq. (8) correspond to the Fourier coefficients of a function on SO(3).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 :</head><label>2</label><figDesc>Left block (2 ? 3): convolution between sets of functions of spins 0 and 1. The operation is equivariant as a vector field and outputs carry the same spins. Right block (2 ? 3): spin-weighted cross-correlation between scalar spherical functions. The operation is also equivariant and we show outputs corresponding to spins 0 and 1. The second row shows the effect of rotating the input F .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 5 :</head><label>5</label><figDesc>Samples from SVFMNIST, image from vector field prediction task. Top shows input vector fields, bottom the target spherical images. Note that the targets have different colors based on the category, so the task cannot be solved via simple gradient integration. Samples are in canonical orientation for easy visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 6 :</head><label>6</label><figDesc>Samples from SVFMNIST, vector field from image prediction task. Top shows input spherical images, bottom the target vector fields. The targets have different angular offsets based on the category so the task cannot be solved via simple image gradient estimation. Samples are in canonical orientation for easy visualization.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell>NR/NR</cell><cell>R/R</cell><cell>NR/R</cell><cell>params</cell></row><row><cell>Planar CNN</cell><cell cols="3">99.07(4) 81.07(63) 17.23(71)</cell><cell>59k</cell></row><row><cell>Cohen et al. [11]</cell><cell>95.59</cell><cell>94.62</cell><cell>93.40</cell><cell>58k</cell></row><row><cell cols="2">Kondor et al. [28] 96.40</cell><cell>96.60</cell><cell>96.00</cell><cell>-</cell></row><row><cell cols="4">Esteves et al. [16] 98.75(8) 98.71(5) 98.08(24)</cell><cell>57k</cell></row><row><cell>Ours</cell><cell cols="3">99.37(5) 99.37(1) 99.08(12)</cell><cell>58k</cell></row><row><cell cols="2">5.2 Spherical Vector Field Classification</cell><cell></cell><cell></cell><cell></cell></row></table><note>Spherical MNIST results. Our model is more expressive than the isotropic and more efficient than the previous anisotropic spherical CNNs, allowing deeper models and improved performance.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">Spherical vector field MNIST</cell></row><row><cell cols="4">classification results. When vector field</cell></row><row><cell cols="4">equivariance is required, the gap be-</cell></row><row><cell cols="4">tween our method and the spherical and</cell></row><row><cell cols="3">planar baselines is even larger.</cell></row><row><cell></cell><cell>NR/NR</cell><cell>R/R</cell><cell>NR/R</cell></row><row><cell cols="4">Planar 97.7(2) 50.0(8) 14.6(9)</cell></row><row><cell>[16]</cell><cell cols="3">98.4(1) 94.5(5) 24.8(8)</cell></row><row><cell>Ours</cell><cell cols="3">98.2(1) 97.8(2) 98.2(7)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Vector field to image and image to vector field results on SVFMNIST. The SWSCNNs show superior performance, especially on the more challenging tasks. The metric is the mean-squared error ?10 3 (lower is better). All models have around 112k parameters.</figDesc><table><row><cell></cell><cell></cell><cell>easy</cell><cell></cell><cell></cell><cell>hard</cell><cell></cell></row><row><cell cols="2">NR/NR</cell><cell>R/R</cell><cell>NR/R</cell><cell>NR/NR</cell><cell>R/R</cell><cell>NR/R</cell></row><row><cell>Image to Vector Field</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Planar</cell><cell>0.3(1)</cell><cell>5.0(1)</cell><cell>9.3(1)</cell><cell cols="3">16.9(5) 26.0(1) 32.9(2)</cell></row><row><cell>Esteves et al. [16]</cell><cell cols="3">9.7(3) 31.0(2) 45.6(7)</cell><cell cols="3">13.3(6) 28.5(4) 41.6(4)</cell></row><row><cell>Ours</cell><cell>2.9(2)</cell><cell>3.4(1)</cell><cell>4.3(1)</cell><cell>11.6(6)</cell><cell cols="2">9.2(4) 10.2(6)</cell></row><row><cell>Vector Field to Image</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Planar</cell><cell>1.4(1)</cell><cell>3.2(1)</cell><cell>6.9(4)</cell><cell cols="3">3.3(2) 13.4(2) 21.1(3)</cell></row><row><cell>Esteves et al. [16]</cell><cell>3.8(1)</cell><cell cols="2">4.9(2) 15(2)</cell><cell>2.6(1)</cell><cell cols="2">6.4(2) 20.3(9)</cell></row><row><cell>Ours</cell><cell>3.5(1)</cell><cell>3.8(1)</cell><cell>4.0(1)</cell><cell>2.6(1)</cell><cell>2.7(1)</cell><cell>2.9(1)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc></figDesc><table><row><cell cols="2">ModelNet40 shape classifica-</cell></row><row><cell cols="2">tion accuracy [%]. Our model outper-</cell></row><row><cell cols="2">forms previous spherical CNNs while</cell></row><row><cell cols="2">requiring small input size and low pa-</cell></row><row><cell>rameter count.</cell><cell></cell></row><row><cell></cell><cell>upright rotated</cell></row><row><cell cols="2">UGSCNN [25] 87.3(3) 81.9(9)</cell></row><row><cell>SphCNN [16]</cell><cell>89.3(5) 88.4(3)</cell></row><row><cell>Ours</cell><cell>89.6(3) 88.8(1)</cell></row><row><cell>Ours + BE</cell><cell>90.1(3) 88.2(2)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell cols="3">: Semantic segmentation on Stan-</cell></row><row><cell cols="3">ford 2D3DS. Our model clearly out-</cell></row><row><cell cols="3">performs previous equivariant models</cell></row><row><cell cols="3">and matches the state-of-the-art non-</cell></row><row><cell>equivariant model.</cell><cell></cell><cell></cell></row><row><cell></cell><cell>acc [%]</cell><cell>mIoU</cell></row><row><cell>UGSCNN [25]</cell><cell>54.7</cell><cell>38.3</cell></row><row><cell cols="2">Gauge CNN [8] 55.9</cell><cell>39.4</cell></row><row><cell cols="2">HexRUNet [52] 58.6</cell><cell>43.3</cell></row><row><cell>SphCNN [16]</cell><cell cols="2">52.8(6) 40.2(3)</cell></row><row><cell>Ours</cell><cell cols="2">55.6(5) 41.9(5)</cell></row><row><cell>+normals</cell><cell cols="2">57.5(6) 43.4(4)</cell></row><row><cell cols="3">+normals+BE 58.7(5) 43.4(4)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>52] Chao Zhang, Stephan Liwicki, William Smith, and Roberto Cipolla. "Orientation-Aware Semantic Segmentation on Icosahedron Spheres". In: Proceedings of the IEEE International Conference on Computer Vision. 2019, pp. 3533-3541. [53] Yongheng Zhao, Tolga Birdal, Jan Eric Lenssen, Emanuele Menegatti, Leonidas Guibas, and Federico Tombari. "Quaternion Equivariant Capsule Networks for 3d Point Clouds". In: CoRR (2019). arXiv: 1912.12098 [cs.LG].</figDesc><table /><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">The subscripts m, n refer to rows and columns of the matrix, respectively.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We use spins 0 and 1 throughout: MF = MK = {0, 1}. This amounts to four spin-order pairs per filter per degree: 0k 0 , 0k 1 , 1k 0 , 1k 1 .</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1. We define the convolution and cross-correlation between sets of spin-weighted spherical functions. These are SO(3) equivariant operations that respect the SWSFs properties. 2. We build a CNN based on these operations and adapt usual CNN components for sets of SWSFs as features and filters. This is, to the best of our knowledge, the first spherical CNN that operates on vector fields. 3. We demonstrate the efficacy of the spin-weighted spherical CNNs (SWSCNNs) on a variety of tasks including spherical image and vector field classification, predicting vector field from images and conversely, 3D shape classification and spherical image segmentation. 4. We will make our code and datasets publicly available at https://github.com/ daniilidis-group/swscnn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments and Disclosure of Funding</head><p>Research was sponsored by the Army Research Office and was accomplished under Grant Number W911NF-20-1-0080 as well as NSF TRIPODS 1934960 and the ONR N00014-17-1-2093 grants. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of ARO, ONR, or the U.S. Government. The U.S. Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation herein.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>? m,n = d m,n (?/2), <ref type="bibr" target="#b18">(19)</ref> then the following relation holds <ref type="bibr" target="#b38">[39]</ref>,</p><p>Now we rewrite the SWSH forward transform,</p><p>Since the ? m,n are constants, they are pre-computed. We still need to compute</p><p>which can be done efficiently with an FFT. There is a problem because s f is defined on the sphere so it is not periodic in both directions; we then define s f as the periodic extension of s f which is a function on the torus. See McEwen <ref type="bibr" target="#b35">[36]</ref> and Huffenberger and Wandelt <ref type="bibr" target="#b22">[23]</ref> for more details about this extension. We can then express s f by its Fourier coefficients,</p><p>Substituting this in Eq. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Cormorant: Covariant Molecular Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brandon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Truong-Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Hy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kondor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14510" to="14519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Joint 2D-3D-Semantic Data for Indoor Scene Understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Iro</forename><surname>Armeni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sasha</forename><surname>Sax</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Silvio</forename><surname>Amir Roshan Zamir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Savarese</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1702.01105</idno>
		<ptr target="http://arxiv.org/abs/1702.01105" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Roto-translation covariant convolutional networks for medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Erik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bekkers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Maxime</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mitko</forename><surname>Lafarge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Veta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Koen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Eppenhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Josien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Remco</forename><surname>Pluim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Duits</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer-Assisted Intervention</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="440" to="448" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">B-Spline CNNs on Lie groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">J</forename><surname>Bekkers</surname></persName>
		</author>
		<idno>ICLR 2020. 2020</idno>
	</analytic>
	<monogr>
		<title level="m">8th International Conference on Learning Representations</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Angular velocity of gravitational radiation from precessing binaries and the corotating frame</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Boyle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Review D</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">104006</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">How should spin-weighted spherical functions be defined?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Boyle</surname></persName>
		</author>
		<idno type="DOI">10.1063/1.4962723</idno>
		<idno>p. 092504. ISSN: 1089-7658. DOI: 10.1063/1. 4962723</idno>
		<ptr target="http://dx.doi.org/10.1063/1.4962723" />
	</analytic>
	<monogr>
		<title level="j">In: Journal of Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">9</biblScope>
			<date type="published" when="2016-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">3-D spinors, spin-weighted functions and their applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gerardo F Torres Del</forename><surname>Castillo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>Springer Science &amp; Business Media</publisher>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Gauge Equivariant Convolutional Networks and the Icosahedral CNN</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berkay</forename><surname>Kicanaoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning, ICML 2019</title>
		<meeting>the 36th International Conference on Machine Learning, ICML 2019</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Group equivariant convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2990" to="2999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A General Theory of Equivariant CNNs on Homogeneous Spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Taco S Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9142" to="9153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Spherical CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Taco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>K?hler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Hkbd5xZRb" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Steerable CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Taco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">5th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Exploiting Cyclic Symmetry in Convolutional Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sander</forename><surname>Dieleman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">De</forename><surname>Fauw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Koray</forename><surname>Kavukcuoglu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33nd International Conference on Machine Learning</title>
		<meeting>the 33nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1889" to="1898" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Computing Fourier transforms and convolutions on the 2-sphere</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dennis M</forename><surname>Driscoll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Healy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in applied mathematics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="202" to="250" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Theoretical Aspects of Group Equivariant Neural Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Esteves</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05154</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning SO(3) Equivariant Representations with Spherical CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Esteves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Allen-Blanchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ameesh</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The European Conference on Computer Vision (ECCV). Sept</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Polar Transformer Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Esteves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Allen-Blanchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaowei</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Equivariant Multi-View Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carlos</forename><surname>Esteves</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yinshuang</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christine</forename><surname>Allen-Blanchette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kostas</forename><surname>Daniilidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">A course in abstract harmonic analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Folland</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Chapman and Hall/CRC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep symmetry networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><surname>Gens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pedro</forename><forename type="middle">M</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="2537" to="2545" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2016.90</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2016.90" />
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Las Vegas, NV, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2016-06-27" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Warped convolutions: Efficient invariance to spatial transformations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Joao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrea</forename><surname>Henriques</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vedaldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 34th International Conference on Machine Learning</title>
		<meeting>the 34th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="1461" to="1469" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fast and Exact Spin-s Spherical Harmonic Transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kevin</forename><forename type="middle">M</forename><surname>Huffenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Benjamin</forename><forename type="middle">D</forename><surname>Wandelt</surname></persName>
		</author>
		<idno type="DOI">10.1088/0067-0049/189/2/255</idno>
	</analytic>
	<monogr>
		<title level="j">The Astrophysical Journal Supplement Series</title>
		<imprint>
			<biblScope unit="volume">189</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="255" to="260" />
			<date type="published" when="2010-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning</title>
		<meeting>the 32nd International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Spherical CNNs on Unstructured Grids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Chiyu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jingwei</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karthik</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kashinath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philip</forename><surname>Prabhat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Matthias</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Nie?ner</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=Bkl-43C9FQ" />
	</analytic>
	<monogr>
		<title level="m">7th International Conference on Learning Representations, ICLR 2019</title>
		<meeting><address><addrLine>New Orleans, LA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Gauge Equivariant Spherical {CNN}s</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Berkay</forename><surname>Kicanaoglu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><surname>Pim De Haan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HJeYSxHFDS" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Adam: A Method for Stochastic Optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Diederik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jimmy</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m">3rd International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Clebsch-gordan nets: a fully fourier space spherical convolutional neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhen</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubhendu</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="10138" to="10147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Covariant Compositional Networks For Learning Graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hy</forename><surname>Truong Son</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Horace</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><forename type="middle">M</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubhendu</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">6th International Conference on Learning Representations</title>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-04-30" />
		</imprint>
	</monogr>
	<note>Workshop Track Proceedings</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Risi</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shubhendu</forename><surname>Trivedi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning, ICML</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">FFTs on the rotation group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kostelec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Daniel N Rockmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Fourier Analysis and Applications</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="145" to="179" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">An empirical evaluation of deep architectures on problems with many factors of variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugo</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dumitru</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aaron</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><surname>Bergstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshua</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 24th international conference on Machine learning</title>
		<meeting>the 24th international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="473" to="480" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">MNIST handwritten digit database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yann</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Corinna</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Rotation recovery from spherical images without correspondences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Makadia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</author>
		<idno type="DOI">10.1109/TPAMI.2006.150</idno>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2006-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Rotation Equivariant Vector Field Networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Diego</forename><surname>Marcos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Volpi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nikos</forename><surname>Komodakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devis</forename><surname>Tuia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5058" to="5067" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Fast, exact (but unstable) spin spherical harmonic transforms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mcewen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0807.4494</idno>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Note on the Bondi-Metzner-Sachs Group</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ezra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Roger</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Penrose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Physics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="863" to="870" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">DeepSphere: Efficient spherical convolutional neural network with HEALPix sampling for cosmological applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathana?l</forename><surname>Perraudin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Micha?l</forename><surname>Defferrard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomasz</forename><surname>Kacprzak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raphael</forename><surname>Sgier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Astronomy and Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="130" to="146" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Fourier transform summation of Legendre series and D-functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torben</forename><surname>Risbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Geodesy</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="page" from="383" to="396" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">U-Net: Convolutional Networks for Biomedical Image Segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Olaf</forename><surname>Ronneberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Philipp</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Brox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Rethinking the Inception Architecture for Computer Vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Tensor Field Networks: Rotation-and Translation-Equivariant Neural Networks for 3D Point Clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nathaniel</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tess</forename><surname>Smidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Steven</forename><surname>Kearnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lusann</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Li</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><surname>Kohlhoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patrick</forename><surname>Riley</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.08219</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Representation of Lie Groups and Special Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">Ja</forename><surname>Vilenkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">U</forename><surname>Klimyk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Springer</publisher>
			<pubPlace>Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">General E(2)-Equivariant Steerable CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriele</forename><surname>Cesa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="14334" to="14345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mario</forename><surname>Geiger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wouter</forename><surname>Boomsma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taco</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">;</forename><forename type="middle">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Cesa-Bianchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Garnett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Learning Steerable Filters for Rotation Equivariant CNNs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maurice</forename><surname>Weiler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fred</forename><forename type="middle">A</forename><surname>Hamprecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Martin</forename><surname>Storath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="849" to="858" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">3D G-CNNs for Pulmonary Nodule Detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Marysia</forename><surname>Winkels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Taco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cohen</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.04656</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cubenet: Equivariance to 3d rotation and translation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European Conference on Computer Vision (ECCV)</title>
		<meeting>the European Conference on Computer Vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="567" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Harmonic networks: Deep translation and rotation equivariance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephan</forename><forename type="middle">J</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniyar</forename><surname>Garbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gabriel</forename><forename type="middle">J</forename><surname>Turmukhambetov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Brostow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Deep Scale-spaces: Equivariance Over Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><forename type="middle">E</forename><surname>Worrall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Max</forename><surname>Welling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7364" to="7376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">3D ShapeNets: A Deep Representation for Volumetric Shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zhirong</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shuran</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fisher</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Linguang</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiaoou</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianxiong</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1912" to="1920" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">We define ? m,n as</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
