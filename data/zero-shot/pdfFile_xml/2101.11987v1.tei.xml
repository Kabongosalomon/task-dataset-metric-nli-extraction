<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">PIG-Net: Inception based Deep Learning Architecture for 3D Point Cloud Segmentation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021">2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sindhu</forename><surname>Hegde</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IIIT Hyderabad</orgName>
								<address>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shankar</forename><surname>Gangisetty</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">KLE Technological University</orgName>
								<address>
									<settlement>Hubballi</settlement>
									<country>India A R</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">T I C L E I N F O</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">PIG-Net: Inception based Deep Learning Architecture for 3D Point Cloud Segmentation</title>
					</analytic>
					<monogr>
						<title level="j" type="main">Computers &amp; Graphics</title>
						<imprint>
							<date type="published" when="2021">2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1016/j.cag.2021.01.004</idno>
					<note type="submission">Article history: Received January 12, 2021</note>
					<note>Contents lists available at ScienceDirect Computers &amp; Graphics journal homepage: www.elsevier.com/locate/cag</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T14:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Point cloud segmentation</term>
					<term>In- ception module</term>
					<term>Global average pooling</term>
					<term>PointNet</term>
					<term>ShapeNet</term>
					<term>PartNet</term>
					<term>MLP</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A B S T R A C T</head><p>Point clouds, being the simple and compact representation of surface geometry of 3D objects, have gained increasing popularity with the evolution of deep learning networks for classification and segmentation tasks. Unlike human, teaching the machine to analyze the segments of an object is a challenging task and quite essential in various machine vision applications. In this paper, we address the problem of segmentation and labelling of the 3D point clouds by proposing a inception based deep network architecture called PIG-Net, that effectively characterizes the local and global geometric details of the point clouds. In PIG-Net, the local features are extracted from the transformed input points using the proposed inception layers and then aligned by feature transform. These local features are aggregated using the global average pooling layer to obtain the global features. Finally, feed the concatenated local and global features to the convolution layers for segmenting the 3D point clouds. We perform an exhaustive experimental analysis of the PIG-Net architecture on two state-of-the-art datasets, namely, ShapeNet [1] and PartNet <ref type="bibr" target="#b1">[2]</ref>. We evaluate the effectiveness of our network by performing ablation study.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Human vision is the most interesting and brilliant characters of human that segments, categorizes, recognizes and organizes the objects based on the knowledge of their parts. In our world, human takes a critical decision based on the detection and reasoning of the parts in an object. For instance, if a human wishes to sit on a chair, the human vision detects the parts of the chair such as seat, arm, chair back, legs and reasons appropriately whether to sit or not. One of the reasoning is whether the legs of the chair are thin, broken, small or in an uncertain state to make a critical decision. Unlike human vision, supervising the machine vision to analyze the parts of an object i.e., segmentation and labeling is a challenging task. Machine vision segmentation is essential in many applications like robot navigation and grasping <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b4">5]</ref>, generating 3D shapes <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7,</ref><ref type="bibr" target="#b7">8]</ref>, medical surgery <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>, 3D modeling and animation <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b12">13]</ref>, and scene understanding <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b14">15]</ref>.</p><p>Initially most of the works in literature adopted hand-crafted feature-based learning approaches for segmentation and labeling <ref type="bibr" target="#b15">[16,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19,</ref><ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22]</ref> on small datasets, this misses the fine-grained details for reasoning over the different parts in an object. Recently, with large and growing online repositories of data, deep learning has become a general tool for many of the computer vision tasks ranging from classification to segmentation to scene understanding, especially convolutional neural networks (CNN) in 2D images <ref type="bibr" target="#b22">[23,</ref><ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25,</ref><ref type="bibr" target="#b25">26,</ref><ref type="bibr" target="#b26">27]</ref>. Since robotic vision is rapidly growing to automate every job (eg., industry to healthcare), currently most of the re-arXiv:2101.11987v1 [cs.CV] 28 Jan 2021 searchers aim at adaptation of deep CNN to 3D objects. Thus, the availability of large 3D object datasets with part annotations <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b1">2]</ref> and deep learning techniques, enables us to research on 3D object segmentation and labeling for object understanding. Among the popular categorizes of point cloud based segmentation, namely, semantic segmentation at scene level <ref type="bibr" target="#b27">[28,</ref><ref type="bibr" target="#b28">29,</ref><ref type="bibr" target="#b29">30,</ref><ref type="bibr" target="#b30">31,</ref><ref type="bibr" target="#b31">32,</ref><ref type="bibr" target="#b32">33,</ref><ref type="bibr" target="#b33">34,</ref><ref type="bibr" target="#b34">35,</ref><ref type="bibr" target="#b35">36]</ref>, instance segmentation at object level <ref type="bibr" target="#b36">[37,</ref><ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39,</ref><ref type="bibr" target="#b39">40,</ref><ref type="bibr" target="#b40">41,</ref><ref type="bibr" target="#b41">42]</ref>, and part segmentation at part level <ref type="bibr" target="#b42">[43,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b44">45,</ref><ref type="bibr" target="#b45">46,</ref><ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48]</ref>, in this paper we focus on 3D object part segmentation.</p><p>The 3D object segmentation and labeling task is non-trivial due to the representations of 3D data. The 3D objects captured using sensory devices are raw point clouds that are irregular and the online standard dataset repositories are mesh models that are moreover irregular. However, the CNN architectures require regular data formats in order to detect local features by weight-sharing and kernel machine optimization for computational efficiency. Most of the researchers transform point clouds and mesh models to 3D voxel grids or multi-view images before giving the input to deep CNN architecture. Though the volumetric grid is regular, it is computationally expensive and uses distance field as a means for data representation that itself is challenging to set depending on the nature of the 3D objects. In this paper, we focus on point clouds that are simple, homogeneous, expressive, compact representation of surface geometry, and avoids combinatorial irregularities and complexities of meshes for learning. We name our proposed point cloud network architecture as Point Inception Global average pooling network, PIG-Net.</p><p>Our PIG-Net is a deep learning architecture that directly takes point clouds as input and provides resulting output as per point segment labels for each point of the point clouds. The PIG-Net architecture is a combination of the input transform and the feature transform layers, inception module, global average pooling (GAP) layer and convolution layers. Initially, we adopt the input transformation of PointNet <ref type="bibr" target="#b48">[49]</ref> to align all the input points. We then extract the local features using a series of proposed inception layers to capture the fine-grained details, followed by feature transformation. To obtain the global features, these features are aggregated using the GAP layer that is robust to spatial translations of the point clouds and additionally avoids overfitting. The obtained local and global features are then concatenated and finally given to the convolution layers that segments the different parts of the 3D objects.</p><p>The major contributions of our work are as follows:</p><p>? We propose a point inception based deep neural network called PIG-Net for segmentation and labeling of the 3D point clouds.</p><p>? To extract the local features, we propose inception layers based on inception module as the intermediate layer along with input and feature transformation to extract the discriminative features in order to improve the performance.</p><p>In addition, we propose to use GAP over other pooling methods to avoid overfitting.</p><p>? We provide an exhaustive evaluation and comparative analysis of PIG-Net with the existing methods on two state-of-the-art datasets, namely, ShapeNet-part <ref type="bibr" target="#b0">[1]</ref> and PartNet <ref type="bibr" target="#b1">[2]</ref>. Additionally, the ablation study demonstrate the effectiveness of proposed PIG-Net.</p><p>In Section 2, we review some of the existing segmentation works. In Section 3, we discuss the proposed PIG-Net architecture. In Section 4, we present the experimental results and analysis of the proposed network on state-of-the-art datasets. In Section 5, we provide concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related work</head><p>We categorize the 3D object segmentation into two classes, namely, handcrafted feature learning and deep feature learning for point clouds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Handcrafted feature learning</head><p>The traditional works rely on the handcrafted feature extraction from the 3D objects for specific data processing tasks. The point feature methods capture the shape of objects, the inherent geometric properties of points, and are invariant to certain transformations. The widely used feature descriptors can be classified into signature, histogram and transformation based descriptors <ref type="bibr" target="#b49">[50]</ref>. The signature based descriptors like normal aligned radial feature (NARF) <ref type="bibr" target="#b50">[51]</ref> and normal based signature (NBS) <ref type="bibr" target="#b51">[52]</ref> are popular on range images. The histogram based descriptors like spin images <ref type="bibr" target="#b52">[53]</ref>, shape context <ref type="bibr" target="#b53">[54]</ref>, rotational projection statistics (RoPS) <ref type="bibr" target="#b54">[55]</ref>, 3D scale invariant feature transform (SIFT) <ref type="bibr" target="#b55">[56]</ref>, and fast point feature histogram (FPFH) <ref type="bibr" target="#b56">[57]</ref> are popularly used in combinations of multi-view images and point clouds. The transformation based descriptors like 3D speeded up robust feature (SURF) <ref type="bibr" target="#b57">[58]</ref> and spectral descriptors such as Laplace-Beltrami operator (LBO) <ref type="bibr" target="#b58">[59]</ref>, heat kernel signature (HKS) <ref type="bibr" target="#b59">[60]</ref>, scale invariant HKS (SIHKS) <ref type="bibr" target="#b60">[61]</ref>, wave kernel signature (WKS) <ref type="bibr" target="#b61">[62]</ref>, improved WKS (IWKS) <ref type="bibr" target="#b62">[63]</ref> and metric tensor and Christoffel symbols <ref type="bibr" target="#b63">[64]</ref> have been popularly used on mesh and point clouds. After feature extraction, machine learning techniques are applied on these features either directly or by employing certain methods like patch clustering <ref type="bibr" target="#b64">[65]</ref> or feature encoding <ref type="bibr" target="#b65">[66]</ref>. However, the selection of optimal handcrafted features is non-trivial and highly data specific task as these approaches are often based on certain prior assumptions w.r.t. 3D objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Deep feature learning</head><p>Recent advances in deep learning tools have eliminated the need for hand-crafting the features. Many works have evolved on point clouds after a pioneering work of PointNet <ref type="bibr" target="#b48">[49]</ref> making it possible for directly using point clouds.</p><p>In PointNet <ref type="bibr" target="#b48">[49]</ref>, authors use (x, y, z) coordinates of points as input features with multi layer perceptrons (MLPs) for classification and segmentation. These features are aggregated using the max pooling and forms global features. The network learns to summarize the input point cloud by a sparse set of key points, that roughly corresponds to the skeleton of the objects. The limitation is, this architecture does not capture the local structures induced by the metric. Exploiting such local structures has proven to be important for the success of convolutional architectures. Thus, as an extension to this network, authors in PointNet++ <ref type="bibr" target="#b66">[67]</ref> proposed a hierarchical features architecture, that learns effectively by adopting max pooling. But both the networks rely on max pooling for aggregation of local and global features.</p><p>Unlike PointNet++ <ref type="bibr" target="#b66">[67]</ref>, authors in SPLATNet <ref type="bibr" target="#b44">[45]</ref>, SFCNN <ref type="bibr" target="#b67">[68]</ref>, RIConv <ref type="bibr" target="#b68">[69]</ref> capture local properties differently by mapping original points into a space lattice and processing using bilateral convolutional layers to improve stability. In SFCNN <ref type="bibr" target="#b67">[68]</ref>, the model also exploits spherical lattice structure for generalization. However, in RIConv <ref type="bibr" target="#b68">[69]</ref>, authors do not use spherical lattice structure for rotation in-variance. Instead, they defined convolution with rotation invariant features. These works explore both convolution on local point features and rotation invariance. But, the local geometric features are not complete because original point cloud coordinates are not retained in low-level geometric feature extraction, trading for rotation invariance. In KCNet <ref type="bibr" target="#b69">[70]</ref>, authors proposed a kernel correlation layer to improve PointNet by efficiently exploring local 3D geometric structures and local high-dimensional feature structures. The KCNet is based on graph representation. In KdNet <ref type="bibr" target="#b70">[71,</ref><ref type="bibr" target="#b71">72]</ref>, authors extract the hierarchical features from the input point cloud using kd-tree. For segmentation, in KdNet <ref type="bibr" target="#b70">[71]</ref> the encoder-decoder architecture is mimicked with skip connections. But due to the lack of overlapped receptive fields and the insufficient information propagation across the kd-tree structure, the performance is poor.</p><p>To overcome the issues of PointNet++ and Kd-Net, authors in SONet <ref type="bibr" target="#b72">[73]</ref> propose a permutation invariant architecture. A Self-Organizing Map (SOM) is constructed which models the spatial distribution of the input point clouds. The hierarchical features are extracted from both the individual points and the SOM nodes. For segmentation of 3D objects, the global feature vector is directly expanded and concatenated with the normalized points. But the SONet suffers similar fails as that of Point-Net. Another work to overcome the limitation of PointNet++ is PointGrid <ref type="bibr" target="#b73">[74]</ref>. In this architecture, the input point cloud is embedded into a 3D grid. The 3D convolutional network extracts the features and learns higher order local approximation functions that captures the local geometry of the 3D shapes. For segmentation, the network employs the feature extraction and decodes the extracted features using deconvolution. The limitation is random sampling that fails for large cluster value and is computationally expensive.</p><p>Unlike aforementioned methods there are other category of methods which learn the local properties from subset of 3D points <ref type="bibr" target="#b74">[75,</ref><ref type="bibr" target="#b43">44,</ref><ref type="bibr" target="#b47">48]</ref> rather than the entire 3D object. In DGCNN <ref type="bibr" target="#b74">[75]</ref>, authors propose EdgeConv to capture the local features by generating edge features which provides the relationship between points and the nearest neighbors. The Edge-Conv is designed to be permutation-invariant, but the DGCNN is not effective during scale invariance and coordinate shifts are performed. The coordinate shifts occurs by extracting features from global coordinate. In KPConv <ref type="bibr" target="#b43">[44]</ref>, authors select neighboring points for each point by describing the local structures of point clouds with a radius, but KPConv cannot deal with scale variations. To overcome these drawbacks, authors in 3D Graph Convolution Networks (3D-GCN) <ref type="bibr" target="#b47">[48]</ref>, present a learnable 3D graph kernels and graph max-pooling operation, to obtain geometric features across scales while exhibiting scale and shiftinvariance.</p><p>Other segmentation methods like PointCNN <ref type="bibr" target="#b75">[76]</ref>, SPH3D-GCN <ref type="bibr" target="#b76">[77]</ref> and PointConv <ref type="bibr" target="#b77">[78]</ref> have complex convolution architectures to preserve local features. In this paper, we use inception module for preserving low-level features and GAP to build a PIG-Net architecture for 3D point cloud part segmentation, yielding better performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">3D Point Cloud Segmentation</head><p>We propose a new inception based deep network architecture called Point Inception Global average pooling network (PIG-Net) shown in <ref type="figure" target="#fig_0">Figure 1</ref>, in order to segment the different parts of the 3D point cloud. The major components of PIG-Net include, input transform and feature transform layers, inception module, global average pooling layer and convolution layers. Given a point cloud O = {p i |p i ? R 3 , i = 1, 2, ..., n}, the input points p i are transformed by applying a symmetric function for permutation invariance and aggregate to obtain the transformed points O = {p 1 , p 2 , ..., p n }. The input transform network of PointNet <ref type="bibr" target="#b48">[49]</ref> is used to predict the affine transformation matrix (T-Net), which aligns all the input points to a canonical space and makes the network to be invariant to certain geometric transformations, such as rigid transformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Convolutions on Point Clouds</head><p>The convolutions that are used in all the components of the PIG-Net architecture is defined as,</p><formula xml:id="formula_0">Conv(q) = d j=1 w j h j<label>(1)</label></formula><p>where Conv(q) is the convolution over each point q, w j is the j th component of the convolutional kernel weights W ? R d represented as a series of 1 ? d kernel weight vectors where d is the number of dimensions and h j is the j th component of feature vectors H ? R d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Inception module</head><p>We propose inception layers based on inception module that takes the transformed points O as the input and outputs the lo-</p><formula xml:id="formula_1">cal features F = { f 1 , f 2 , .</formula><p>.., f n } to capture the fine grained details of the points. In deep neural networks, one of the most common way to improve the performance is to increase either the number of layers or the number of neurons in each layer. But this results into overfitting due to the large number of parameters and furthermore increases the computational complexity due to the uniform increase in the filters. In order to improve the performance and to overcome these drawbacks, we propose an inception module for point clouds. The inception module <ref type="bibr" target="#b78">[79]</ref> had emerged as a breakthrough solution for classification and detection tasks in the ImageNet ILSVRC 2014 challenge. Though the PointNet considers permutation invariance of unordered point sets in order to improve the performance, however the performance can be further enhanced by considering the optimal local sparse structure in the network. Thus, we use inception module as the intermediate layers in the PIG-Net as depicted in <ref type="figure" target="#fig_0">Figure 1</ref> to enhance the network performance.</p><p>The proposed inception module consists of convolution layers and max pooling layer as shown in <ref type="figure" target="#fig_0">Figure 1</ref>. Each convolution layer includes batch normalization to reduce the covariance shift and rectified linear unit (ReLU) activation function adding non-linearity to the network and minimizes the vanishing gradient problem. The convolution layer identifies the basic patterns and concatenating several of these layers, creates hierarchical filters that represent the different parts of the point cloud. As illustrated in <ref type="figure" target="#fig_0">Figure 1</ref>, the first convolutional layer convolves the input using e filters. The output of this layer is fed to two convolution layers, each with e/2 filters and a maxpooling layer. The max-pooled features are given to another convolution layer with e filters. Finally, the output from all the four convolution layers are concatenated to extract the local features. In our network, we use a series of four inception layers, starting with 64 filters which are doubled in the successive layers (i.e., 128, 256, 512). The extracted inception features precisely capture the shape of the point clouds by recognizing the fine-grained details.</p><p>These features are then aligned using the symmetric function to obtain the transformed features F = { f 1 , f 2 , ..., f n }. A feature transformation matrix is predicted which aligns the features F using an alignment network. Since the dimension of the transformation matrix is high, a regularization term is added to stabilize the optimization. The alignment network helps to make the learnt inception features be invariant to the geometric transformations and further improves the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Global average pooling (GAP)</head><p>We propose to use GAP <ref type="bibr" target="#b79">[80]</ref> layer to extract the global features G, characterizing the entire object. Conventionally, maxpooling that considers the maximum value to obtain the global features is adopted in majority of the networks including Point-Net <ref type="bibr" target="#b48">[49]</ref> and PointGrid <ref type="bibr" target="#b73">[74]</ref>. Similar to max-pooling, GAP layer can be used to reduce the spatial dimensions and obtain a single global feature. However, since there are no parameters to be optimized, the GAP avoids overfitting of data and is additionally robust to spatial translations of the input point clouds. This is a potential advantage when compared to max-pooling aggregation. Thus, in our network, we propose to use GAP to obtain the global features. In CNNs, especially in images <ref type="bibr" target="#b79">[80]</ref>, GAP is used to replace the fully connected layers in the network. We use GAP in PIG-Net, not only to obtain the global features, but to provide a more native way to the convolution structure enforcing the correspondences between the features and parts of point cloud.</p><p>The GAP computes the mean of the transformed feature maps, F , to obtain the global feature G. For segmenting the 3D object, it is necessary that both the local and global information is preserved. To do so, we concatenate the per point local feature map from F with the global feature G to obtain the con-</p><formula xml:id="formula_2">catenated per point features C = {( f 1 , G), ( f 2 , G), ..., ( f n , G)}.</formula><p>Thus, the network becomes aware of both the local and global    <ref type="table" target="#tab_1">phone  bike  board  # parts  50  4  2  2  4  4  3  3  2  4  2  6  2  3  3  3  3  # train  12137 1958 54  39  659 2658 49  550  277  1118 324  125  130 209  46  106  3835  # validation 1870  391  8  5  81  396  6  78  35  143  44  26  16  30  8  15  588  # test  2874  341  14  11  158 704  14  159  80  286  83  51  38  44  12  31  848  Total  16881 2690 76  55  898 3758 69  787  392  1547 451  202  184 283  66  152  5271</ref> knowledge of the point clouds which intensifies the ability of the network to predict the appropriate per point labels. Finally, the concatenated features C is fed to the convolution layers and combine them to construct the output. For every point in the point cloud, the network predicts the probability of the point belonging to a particular part, thus generating the per point scores as the output.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Implementation details</head><p>The proposed PIG-Net architecture is implemented on Intel ? Xeon(R) processor at 3.5 GHz and 128 GB RAM. For segmentation, we set the batch size as 64 and use the cross entropy loss function. The Adam optimizer, which is an extension to stochastic gradient descent is used to minimize the cross entropy loss with a learning rate of 0.001. We implemented the segmentation network using Keras library <ref type="bibr" target="#b80">[81]</ref> and train each category separately using Nvidia Quadro M2000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Performance evaluation</head><p>The evaluation metric used to analyze the performance of PIG-Net is mean intersection over union (mIoU). For each object of category, to compute the mIoU of the object, the IoU between the ground truth and prediction is calculated for each part in the category. The IoUs for all parts are averaged in category to get the mIoU for that object. To calculate mIoU for the category, take the average of mIoUs for all the objects in that category. We report the instance mIoU (Ins. mIoU) that is the average of IoUs of all the point cloud instances and category mIoU (Cat. mIoU) that is the average of mIoUs of all the categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiments and Results</head><p>In this section, we present the experimental results of the proposed PIG-Net on two state-of-the-art datasets (Section 4.2). We describe the data augmentation techniques used in Section 4.1. The experimental results and comparative analysis is provided in Sections 4.3 and 4.4. We evaluate the effectiveness of our network by performing ablation study in Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data augmentation</head><p>We uniformly sample the point clouds to obtain 1024 points. During training, we augment the point cloud on-the-fly by randomly rotating the object along the up-axis. We augment the data using random anisotropic scaling (range: [0.66, 1.5]) and random translation (range: [?0.2, 0.2]), as in <ref type="bibr" target="#b87">[88]</ref>. Additionally, jittering the position of each point by a Gaussian noise with zero mean and 0.01 standard deviation is done. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Datasets</head><p>For experimental analysis, we use ShapeNet-part dataset <ref type="bibr" target="#b0">[1]</ref> and the recently released PartNet v0 dataset <ref type="bibr" target="#b1">[2]</ref>. We are the first to present the network analysis on PartNet. The sample point clouds from PartNet dataset are shown in <ref type="figure" target="#fig_1">Figure 2</ref>.</p><p>The ShapeNet-part dataset contains 16, 881 3D objects spread across 16 categories. There are 50 parts in total with 2 to 6 parts per category. The dataset is split into 12, 137 objects for training, 1870 for validation and 2874 objects for testing <ref type="bibr" target="#b0">[1]</ref>. The number of objects in training, validation and testing sets in each of the categories is shown in <ref type="table" target="#tab_1">Table 1</ref>. This is a challenging segmentation dataset since both the object categories and the object parts within the categories are highly imbalanced.</p><p>The PartNet dataset shared by <ref type="bibr" target="#b1">[2]</ref> consists of fine-grained part annotations for 25, 927 objects distributed over 24 categories. It is a large-scale dataset of 3D objects with finegrained, instance-level, and hierarchical 3D part annotations. The fine-grained semantic segmentation consists of three levels of segmentation, namely, coarse level, middle level and fine grained level. The number of objects in training, validation and testing sets in each of the categories is shown in <ref type="table" target="#tab_2">Table 2</ref>. Segmenting the fine-grained objects is a challenging task since it requires distinguishing the small and similar semantic parts of the objects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">ShapeNet-part</head><p>The results of the proposed PIG-Net and the existing stateof-the-art methods on ShapeNet-part dataset are shown in Table 3. We can observe that the proposed approach achieves an improvement of 1% on category mIoU and 3.7% on instance mIoU, thus significantly outperforming the existing SOTA methods. Our Inception based PIG-Net architecture outperforms the most complex point cloud architectures like PointCNN <ref type="bibr" target="#b75">[76]</ref>, DGCNN <ref type="bibr" target="#b74">[75]</ref>, KPConv <ref type="bibr" target="#b43">[44]</ref> and SPH3D-GCN <ref type="bibr" target="#b76">[77]</ref>. The proposed technique achieves the best performance in 6/16 categories. In individual categories, our method ranks the best in guitar, knife, lamp, rocket, skateboard and table classes; the second best in chair and laptop classes and the third best in cap class. We can observe that our method performs better when there is more data, in categories such as table, lamp, chair etc. The visualization of the segmented point clouds using PIG-Net is shown in <ref type="figure" target="#fig_2">Figure 3</ref> (top row), ordered from highest to lowest mIoU (left to right). As we can see from the visual results, our architecture segments most of the point clouds correctly. The rocket category attains the lowest mIoU of 64.8%. Most of the points in fin and nose parts are wrongly segmented to the body part of the rocket. This is largely due to the very minute distinction and the continuity that is present in these parts leading to confusion. We also show performance ShapeNet Ground truth</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PIG-Net</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Laptop</head><p>Guitar  of PIGNet with an ablation study by considering max pooling instead of GAP in the last row on <ref type="table">Table 3</ref>. We observe that results using max pooling shows lower IoUs in comparison to IoUs using GAP articulating that unlike max pooling which obtains only global features, GAP enforces the correspondences between global features and parts of 3D point cloud.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">PartNet</head><p>The recently released PartNet is the large-scale dataset. The results of the proposed PIG-Net and the existing state-of-theart methods on PartNet dataset are shown in <ref type="table">Table 4</ref>. We can observe that our method performs well on all the three levels of the PartNet dataset. In coarse level, PIG-Net outperforms other methods with an improvement of 4.1% on category mIoU and 7.3% on instance mIoU. We obtain the best results in 15/24 categories. The worst performance is achieved for keyboard class with mIoU of 49.7%. In keyboard ground truth, the background panel is a different part than the foreground keys. Due to the intra-part closeness of the keys and the panel, our network segments these parts into a single part (see keyboard in <ref type="figure" target="#fig_2">Figure 3</ref>). In middle level, we achieve the best performance in seven of nine categories. In individual categories, our method ranks the best in bed, chair, door, lamp, fridge, storage furniture and table categories with an improvement of 8.7% on category mIoU and 12.8% on instance mIoU. The visualization of the segmented point clouds using our PIG-Net is shown in <ref type="figure" target="#fig_2">Figure 3</ref> (bottom row). In fine-grained level, we achieve the best results in 12/17 categories with an improvement of 4% on category mIoU and 6% on instance mIoU. Overall, we beat the existing methods on all three levels of segmentation with an average improvement of 3.1% on category mIoU and 7.8% on instance mIoU. PartNet being a challenging dataset, the experimental results clearly illustrates the effectiveness of PIG-Net, especially in fine-grained and middle levels, as our method is able to recognize the subtle details of the point clouds, much better than the existing methods. This is mainly due to the discriminative and rich features extracted using the inception layers as well as the global features extracted using the GAP layer in the PIG-Net architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Ablation Study</head><p>In this section, we evaluate the effect of PIG-Net w.r.t. different architectures, robustness tests and network complexity on PartNet (coarse-level) dataset <ref type="bibr" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.1.">Alternative Network Architecture</head><p>We conduct experiments with alternative PIG-Net architectures and report their individual, overall category and instance mIoU for the 3D object segmentation on PartNet dataset. The performance of PIG-Net with different inception layers i.e., 3, 4, and 5 is shown in <ref type="table" target="#tab_4">Table 5</ref>. The proposed PIG-Net in <ref type="figure" target="#fig_0">Figure 1</ref> is a 4 layer inception with <ref type="bibr" target="#b63">(64,</ref><ref type="bibr">128,</ref><ref type="bibr">256,</ref><ref type="bibr">512)</ref> filters which out performs other inception architectures using GAP. When the number of inception layers further increases, we observe that the performance of the network drops as shown in <ref type="table" target="#tab_4">Table 5</ref>. This is because as the number of layers increases, the network grows deep and the learning is difficult due to vanishing gradient. In addition, it might lead to overfitting due to increase in the number of layers and filters in the inception <ref type="bibr" target="#b78">[79]</ref> bringing the necessity of changing the inception architecture. We also observe that performance of PIG-Net is poor without inception.</p><p>As mentioned in Section 3, the global features can be computed using max pooling aggregation which is adopted by most of the existing methods. We compare the max pooling with the GAP by fixing the rest of our architecture with 4 layer inception. From <ref type="table" target="#tab_4">Table 5</ref>, we observe that the GAP layer achieves <ref type="table">Table 4</ref>. Segmentation results on PartNet dataset (fine-grained). Evaluation metric is mIoU(%). The notations P, P + , S, C and PIG refers to PointNet <ref type="bibr" target="#b48">[49]</ref>, PointNet++ <ref type="bibr" target="#b66">[67]</ref>, SpiderCNN <ref type="bibr" target="#b46">[47]</ref>, PointCNN <ref type="bibr" target="#b75">[76]</ref> and our proposed PIG-Net respectively. The numbers 1, 2 and 3 refer to the three levels of segmentation, namely, coarse level, middle level and fine-grained level. The levels that are not defined are indicated by short lines.</p><p>Cat. Ins. bag bed bott bowl chair clock dish disp door ear fauc hat key knife lamp lap micro mug frid scis stora the best performance by a significant margin (3.5% on category and instance mIoU) demonstrating that it is a better choice as it effectively captures the global point cloud characteristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.2.">Robustness test</head><p>Density variation: We randomly sample the input points to 128, 256, 512, and 1024 as illustrated in <ref type="figure" target="#fig_4">Figure 4</ref>    <ref type="table" target="#tab_5">Table 6</ref> summarizes space (number of parameters in the architecture) and time (seconds) complexity w.r.t. learning model of PIG-Net architecture. In terms of space complexity, PIG-Net is more efficient than PointNet with 1.2 times less number of parameters in the network. However, since inception dominates computation cost, the PIG-Net's time complexity is 30% more expensive than PointNet.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.3.">Time and Space Complexity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and Future Directions</head><p>In this work, we proposed a inception based deep learning architecture, PIG-Net, suitable for 3D point cloud segmentation task. PIG-Net comprising of inception module and GAP, is invariant to geometric transformations, captures the local and global features, avoids overfitting and recognizes the finegrained details of point clouds to enhance the performance. The experimental analysis of PIG-Net on widely popular challenging datasets, namely, ShapeNet <ref type="bibr" target="#b0">[1]</ref> and PartNet <ref type="bibr" target="#b1">[2]</ref> illustrates the effectiveness of our network. PIG-Net outperformed the existing state-of-the-art complex deep learning methods with an improvement of 1% on category mIoU and 3.7% on instance mIoU for ShapeNet-part and an improvement of 4.1% on category mIoU and 7.3% on instance mIoU for PartNet. With a boost in the performance of PIG-Net architecture by inception module and GAP, one of the promising future direction is to extend this to 3D scene understanding tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>Proposed inception based deep learning architecture of our PIG-Net.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 2 .</head><label>2</label><figDesc>Sample 3D point clouds from the PartNet dataset (coarse level)<ref type="bibr" target="#b1">[2]</ref>.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 .</head><label>3</label><figDesc>Visualization of object part segmentation results using the proposed PIG-Net on ShapeNet-part dataset [1] (top row) and PartNet dataset [2] (bottom row).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>(top row). Figure 5 (left) shows the instance mIoU's of the proposed PIG-Net and PointNet [49] architectures on PartNet dataset with varying number of input points. As to density variation, when the number of input points is decreased by 88%, the performance drop of PIG-Net is only 2.7%. The PIG-Net outperforms PointNet at all density levels. Perturbation: The Gaussian noise is added to each point independently as illustrated in Figure 4 (bottom row). The standard deviation of the added noise is 0.01, 0.02, 0.03 and 0.04. Figure 5 (right) shows instance mIoU's according to the different noise levels. The PIG-Net achieves about 65% performance even when the point clouds are distorted by severe noise with the standard deviation of 0.04. The PIG-Net outperforms Point-Net at all noise levels. These results indicate that the proposed PIG-Net is robust to various input corruptions and largely observed to be better than PointNet on complex PartNet dataset.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Fig. 4 .</head><label>4</label><figDesc>Point cloud samples with different kinds of input corruptions. Top row: Sampling density variation. Bottom row: Addition of Gaussian noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 5 .</head><label>5</label><figDesc>Comparison of robustness test of the proposed PIG-Net and Point-Net<ref type="bibr" target="#b48">[49]</ref> architectures on PartNet dataset<ref type="bibr" target="#b1">[2]</ref>. Left: Sampling density variation. Right: Addition of Gaussian noise.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 .</head><label>1</label><figDesc></figDesc><table /><note>Dataset statistics of ShapeNet-part dataset. Total aero bag cap car chair ear guitar knife lamp laptop motor mug pistol rocket skate table</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 .</head><label>2</label><figDesc>Dataset statistics of PartNet dataset. The notations L1, L2 and L3 refer to the three levels of segmentation, namely, coarse level, middle level and fine-grained level.Total bag bed bott bowl chair clock dish disp door ear fauc hat key knife lamp lap micro mug frid scis stora table trash vase</figDesc><table><row><cell cols="2"># parts (L1) 128</cell><cell cols="3">4 4 6</cell><cell>4</cell><cell>6</cell><cell>6</cell><cell>3</cell><cell>3</cell><cell>3</cell><cell cols="2">6 8</cell><cell cols="3">6 3 5</cell><cell cols="2">18 3 3</cell><cell>4</cell><cell>3 3 7</cell><cell>11 5</cell><cell>4</cell></row><row><cell cols="2"># parts (L2) 149</cell><cell>-</cell><cell cols="2">10 -</cell><cell>-</cell><cell cols="2">30 -</cell><cell>5</cell><cell>-</cell><cell>4</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>28 -</cell><cell>5</cell><cell>-</cell><cell>6 -</cell><cell>19 42 -</cell><cell>-</cell></row><row><cell cols="2"># parts (L3) 268</cell><cell>-</cell><cell cols="2">15 9</cell><cell>-</cell><cell cols="2">39 11</cell><cell>7</cell><cell>4</cell><cell>5</cell><cell cols="3">10 12 -</cell><cell>-</cell><cell>10</cell><cell>41 -</cell><cell>6</cell><cell>-</cell><cell>7 -</cell><cell>24 51 11 6</cell></row><row><cell># train</cell><cell cols="19">18112 92 133 315 131 4489 406 111 633 149 147 435 170 111 221 1554 306 133 138 136 45 1588 5707 221 741</cell></row><row><cell cols="8"># validation 2646 5 24 37 18 617 50</cell><cell cols="8">19 104 25 28 81 16 41 29</cell><cell cols="2">234 45 12</cell><cell cols="2">19 20 10 230 843 37 102</cell></row><row><cell># test</cell><cell cols="7">5169 29 37 84 39 1217 98</cell><cell cols="8">51 191 51 53 132 45 31 77</cell><cell cols="2">419 82 39</cell><cell cols="2">35 31 13 451 1668 63 233</cell></row><row><cell>Total</cell><cell cols="19">25927 126 194 436 188 6323 554 181 928 225 228 648 231 183 327 2207 433 184 192 187 68 2269 8218 321 1076</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="16">Table 3. Segmentation results on ShapeNet-part dataset. Evaluation metric is mIoU(%).</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Cat.</cell><cell cols="8">Ins. aero bag cap car chair ear</cell><cell></cell><cell cols="7">guitar knife lamp laptop motor mug pistol rocket skate table</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">mIoU mIoU</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">phone</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>bike</cell><cell>board</cell></row><row><cell>Yi [1]</cell><cell></cell><cell></cell><cell>79.0</cell><cell cols="9">81.4 81.0 78.4 77.7 75.7 87.6 61.9</cell><cell>92.0</cell><cell></cell><cell cols="2">85.4 82.5 95.7</cell><cell></cell><cell>70.6</cell><cell>91.9 85.9 53.1</cell><cell>69.8 75.3</cell></row><row><cell>PointNet [49]</cell><cell></cell><cell></cell><cell>80.4</cell><cell cols="9">83.7 83.4 78.7 82.5 74.9 89.6 73.0</cell><cell>91.5</cell><cell></cell><cell cols="2">85.9 80.8 95.3</cell><cell></cell><cell>65.2</cell><cell>93.0 81.2 57.9</cell><cell>72.8 80.6</cell></row><row><cell cols="2">PointNet++ [67]</cell><cell></cell><cell>81.9</cell><cell cols="9">85.1 82.4 79.0 87.7 77.3 90.8 71.8</cell><cell>91.0</cell><cell></cell><cell cols="2">85.9 83.7 95.3</cell><cell></cell><cell>71.6</cell><cell>94.1 81.3 58.7</cell><cell>76.4 82.6</cell></row><row><cell>Kd-Net [71]</cell><cell></cell><cell></cell><cell>77.4</cell><cell cols="9">82.3 80.1 74.6 74.3 70.3 88.6 73.5</cell><cell>90.2</cell><cell></cell><cell cols="2">87.2 81.0 94.9</cell><cell></cell><cell>57.4</cell><cell>86.7 78.1 51.8</cell><cell>69.9 80.3</cell></row><row><cell cols="2">SpecCNN [82]</cell><cell></cell><cell>82.0</cell><cell cols="9">84.7 81.6 81.7 81.9 75.2 90.2 74.9</cell><cell>93.0</cell><cell></cell><cell cols="2">86.1 84.7 95.6</cell><cell></cell><cell>66.7</cell><cell>92.7 81.6 60.6</cell><cell>82.9 82.1</cell></row><row><cell>O-CNN [83]</cell><cell></cell><cell></cell><cell>82.2</cell><cell cols="9">85.9 85.5 87.1 84.7 77.0 91.1 85.1</cell><cell>91.9</cell><cell></cell><cell cols="2">87.4 83.3 95.4</cell><cell></cell><cell>56.9</cell><cell>96.2 81.6 53.5</cell><cell>74.1 84.4</cell></row><row><cell>PointGrid [74]</cell><cell></cell><cell></cell><cell>82.2</cell><cell cols="9">86.4 85.7 82.5 81.8 77.9 92.1 82.4</cell><cell>92.7</cell><cell></cell><cell cols="2">85.8 84.2 95.3</cell><cell></cell><cell>65.2</cell><cell>93.4 81.7 56.9</cell><cell>73.5 84.6</cell></row><row><cell>KCNet [70]</cell><cell></cell><cell></cell><cell>82.2</cell><cell cols="9">84.7 82.8 81.5 86.4 77.6 90.3 76.8</cell><cell>91.0</cell><cell></cell><cell cols="2">87.2 84.5 95.5</cell><cell></cell><cell>69.2</cell><cell>94.4 81.6 60.1</cell><cell>75.2 81.3</cell></row><row><cell>SO-Net [73]</cell><cell></cell><cell></cell><cell>81.0</cell><cell cols="9">84.9 82.8 77.8 88.0 77.3 90.6 73.5</cell><cell>90.7</cell><cell></cell><cell cols="2">83.9 82.8 94.8</cell><cell></cell><cell>69.1</cell><cell>94.2 80.9 53.1</cell><cell>72.9 83.0</cell></row><row><cell cols="2">SpiderCNN [47]</cell><cell></cell><cell>82.4</cell><cell cols="9">85.3 83.5 81.0 87.2 77.5 90.7 76.8</cell><cell>91.1</cell><cell></cell><cell cols="2">87.3 83.3 95.8</cell><cell></cell><cell>70.2</cell><cell>93.5 82.7 59.7</cell><cell>75.8 82.8</cell></row><row><cell cols="2">PointCNN [76]</cell><cell></cell><cell>84.6</cell><cell cols="9">86.1 84.1 86.5 86.0 80.8 90.6 79.7</cell><cell>92.3</cell><cell></cell><cell cols="2">88.4 85.3 96.1</cell><cell></cell><cell>77.2</cell><cell>95.3 84.2 64.2</cell><cell>80.0 82.3</cell></row><row><cell>MRTNet [72]</cell><cell></cell><cell></cell><cell>79.3</cell><cell cols="9">83.0 81.0 76.7 87.0 73.8 89.1 67.6</cell><cell>90.6</cell><cell></cell><cell cols="2">85.4 80.6 95.1</cell><cell></cell><cell>64.4</cell><cell>91.8 79.7 57.0</cell><cell>69.1 80.6</cell></row><row><cell>RS-Net [84]</cell><cell></cell><cell></cell><cell>81.4</cell><cell cols="9">84.9 82.7 86.4 84.1 78.2 90.4 69.3</cell><cell>91.4</cell><cell></cell><cell cols="2">87.0 83.5 95.4</cell><cell></cell><cell>66.0</cell><cell>92.6 81.8 56.1</cell><cell>75.8 82.2</cell></row><row><cell>DGCNN [75]</cell><cell></cell><cell></cell><cell>82.3</cell><cell cols="9">85.2 84.0 83.4 86.7 77.8 90.6 74.7</cell><cell>91.2</cell><cell></cell><cell cols="2">87.5 82.8 95.7</cell><cell></cell><cell>66.3</cell><cell>94.9 81.1 63.5</cell><cell>74.5 82.6</cell></row><row><cell cols="4">KPConv deform [44] 85.1</cell><cell cols="9">86.4 84.6 86.3 87.2 81.1 91.1 77.8</cell><cell>92.6</cell><cell></cell><cell cols="2">88.4 82.7 96.2</cell><cell></cell><cell>78.1</cell><cell>95.8 85.4 69.0</cell><cell>82.0 83.6</cell></row><row><cell>3D-GCN [48]</cell><cell></cell><cell></cell><cell>82.1</cell><cell cols="9">85.1 83.1 84.0 86.6 77.5 90.3 74.1</cell><cell>90.9</cell><cell></cell><cell cols="2">86.4 83.8 95.6</cell><cell></cell><cell>66.8</cell><cell>94.8 81.3 59.6</cell><cell>75.7 82.8</cell></row><row><cell>SGPN [85]</cell><cell></cell><cell></cell><cell>82.8</cell><cell cols="9">85.8 80.4 78.6 78.8 71.5 88.6 78.0</cell><cell>90.9</cell><cell></cell><cell cols="2">83.0 78.8 95.8</cell><cell></cell><cell>77.8</cell><cell>93.8 87.4 60.1</cell><cell>92.3 89.4</cell></row><row><cell cols="2">DensePoint [86]</cell><cell></cell><cell>84.2</cell><cell cols="9">86.4 84.0 85.4 90.0 79.2 91.1 81.6</cell><cell>91.5</cell><cell></cell><cell cols="2">87.5 84.7 95.9</cell><cell></cell><cell>74.3</cell><cell>94.6 82.9 64.6</cell><cell>76.8 83.7</cell></row><row><cell>PAN [87]</cell><cell></cell><cell></cell><cell>82.6</cell><cell cols="9">85.7 82.9 81.3 86.1 78.6 91.0 77.9</cell><cell>90.9</cell><cell></cell><cell cols="2">87.3 84.7 95.8</cell><cell></cell><cell>72.9</cell><cell>95.0 80.8 59.6</cell><cell>74.1 83.5</cell></row><row><cell>SFCNN [68]</cell><cell></cell><cell></cell><cell>82.7</cell><cell cols="9">85.4 83.0 83.4 87.0 80.2 90.1 75.9</cell><cell>91.1</cell><cell></cell><cell cols="2">86.2 84.2 96.7</cell><cell></cell><cell>69.5</cell><cell>94.8 82.5 59.9</cell><cell>75.1 82.9</cell></row><row><cell cols="2">SPH3D-GCN [77]</cell><cell></cell><cell>84.9</cell><cell cols="9">86.8 84.4 86.2 89.2 81.2 91.5 77.4</cell><cell>92.5</cell><cell></cell><cell cols="2">88.2 85.7 96.7</cell><cell></cell><cell>78.6</cell><cell>95.6 84.7 63.9</cell><cell>78.5 84.0</cell></row><row><cell cols="2">PIG-Net (Ours)</cell><cell></cell><cell>85.9</cell><cell cols="9">90.5 84.2 83.1 88.9 78.6 91.7 78.2</cell><cell>94.4</cell><cell></cell><cell cols="2">89.5 94.2 96.3</cell><cell></cell><cell>66.2</cell><cell>91.6 85.1 64.8</cell><cell>93.5 94.2</cell></row><row><cell cols="4">PIGNetwithMaxPool 82.6</cell><cell cols="9">85.9 82.2 77.3 88.2 77.4 87.6 77.3</cell><cell>92.4</cell><cell></cell><cell cols="2">83.9 81.2 92.6</cell><cell></cell><cell>66.4</cell><cell>90.8 84.8 60.7</cell><cell>90.2 89.1</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table Lamp</head><label>Lamp</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Chair</cell><cell>Cap</cell><cell></cell><cell>Pistol</cell><cell>Bag</cell><cell>Earphone</cell><cell>Rocket</cell></row><row><cell>Display</cell><cell>Scissors</cell><cell>Laptop</cell><cell>Bowl</cell><cell>Bag</cell><cell>Knife</cell><cell>Earphone</cell><cell>Mug</cell><cell>Bottle</cell><cell>Keyboard</cell></row><row><cell>PartNet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Ground</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>truth</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>PIG-Net</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>table trash vase mIoU mIoU P1 57.9 55.1 42.5 32.0 33.8 58.0 64.6 33.2 76.0 86.8 64.4 53.2 58.6 55.9 65.6 62.2 29.7 96.5 49.4 80.0 49.6 86.4 51.9 50.5 55.2 54.Avg 51.2 43.4 42.5 21.8 31.7 58.0 43.5 30.8 60.2 81.7 44.4 43.3 53.1 55.9 65.6 47.6 25.2 96.5 42.8 80.0 39.5 86.4 44.8 37.9 45.0 49.6 P + 1 65.5 65.3 59.7 51.8 53.2 67.3 68.0 48.0 80.6 89.7 59.3 68.5 64.7 62.4 62.2 64.9 39.0 96.6 55.7 83.9 51.8 87.4 58.0 69.5 64.3 64.4 P + 3 42.5 38.9 -30.3 41.4 -39.2 41.6 50.1 80.7 32.6 38.4 52.4 --34.1 25.3 -48.5 -36.4 -40.5 33.9 46.7 49.8 Avg 58.1 51.2 59.7 40.3 47.3 67.3 50.3 44.8 62.0 85.2 47.1 53.5 58.6 62.4 62.2 49.5 32.3 96.6 50.8 83.9 43.4 87.4 49.4 48.2 55.5 57.1 S1 60.4 57.3 57.2 55.5 54.5 70.6 67.4 33.3 70.4 90.6 52.6 46.2 59.8 63.9 64.9 37.6 30.2 97.0 49.2 83.6 50.4 75.6 61.9 50.0 62.Avg 53.6 43.9 57.2 44.2 43.4 70.6 45.7 29.1 59.8 85.4 43.7 41.7 52.0 63.9 64.9 29.9 24.9 97.0 46.9 83.6 41.4 75.6 50.8 34.9 52.7 48.1 C1 64.3 48.6 66.5 55.8 49.7 61.7 69.6 42.7 82.4 92.2 63.3 64.1 68.7 72.3 70.6 62.6 21.3 97.0 58.7 86.5 55.2 92.4 61.4 17.3 66.8 63.-42.9 -49.4 21.3 53.1 58.9 Avg 59.8 44.2 66.5 46.8 45.8 61.7 53.6 39.5 68.7 87.4 50.2 56.5 64.6 72.3 70.6 48.4 21.4 97.0 59.7 86.5 46.9 92.4 56.0 22.6 60.0 61.2 PIG1 69.6 72.6 67.6 62.6 57.2 75.9 76.6 67.7 77.9 84.2 63.3 71.2 73.4 70.7 49.7 71.7 48.7 78.2 76.9 75.1 62.9 81.6 63.0 78.8 63.6 72.7 -51.1 46.1 -46.7 45.2 52.1 74.3 34.3 58.3 68.9 --36.8 29.9 -54.5 -51.3 -57.3 35.2 49.5 64.8 Avg 62.9 59.0 67.6 53.2 51.7 75.9 57.9 56.5 60.8 79.3 52.8 64.8 71.2 70.7 49.7 54.3 42.5 78.2 61.6 75.1 59.4 81.6 61.2 57.3 56.5 68.8 Comparison of alternative PIG-Net architectures on PartNet dataset (coarse-level) w.r.t. variations in number of inception and pooling layers. The Inc3L is a 3 layer Inception(64, 128, 256), Inc4L is a 4 layer Inception(64, 128, 256, 512), and Inc5L is a 5 layer Inception(64, 128, 256, 512, 1024). Cat. Ins. bag bed bott bowl chair clock dish disp door ear fauc hat key knife lamp lap micro mug frid scis stora table trash vase mIoU mIoU PIGNet-Inc3L-GAP 66.7 71.3 64.7 62.2 55.0 72.8 75.7 66.9 69.0 78.1 63.2 69.1 65.2 65.9 40.7 63.5 48.2 75.3 76.9 73.0 59.7 79.7 64.1 78.3 64.2 71.2 PIGNet-Inc4L-GAP 69.6 72.6 67.6 62.6 57.2 75.9 76.6 67.7 77.9 84.2 63.3 71.2 73.4 70.7 49.7 71.7 48.7 78.2 76.9 75.1 62.9 81.6 63.0 78.8 63.6 72.7 PIGNet-Inc5L-GAP 68.0 71.5 64.8 64.5 48.8 70.9 76.5 66.3 76.9 83.3 61.0 66.8 74.5 68.4 47.0 75.4 48.3 74.9 78.2 68.1 61.8 79.8 62.9 76.9 65.4 70.8 PIGNet-No-Inc4L-61.9 62.5 58.3 54.2 47.5 70.3 66.1 54.7 74.3 75.1 61.2 60.7 63.3 60.5 49.8 61.4 39.1 76.2 65.3 72.8 53.9 77.2 56.1 66.2 56.2 64.3 GAP PIGNet-Inc4L-max 66.1 69.1 63.2 60.1 54.6 73.8 72.6 62.9 75.0 80.7 61.3 68.4 69.9 69.1 45.9 66.3 45.2 75.5 74.6 71.3 57.8 73.1 61.2 76.4 59.7 68.9 pooling</figDesc><table><row><cell>7</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>Time and space complexity of the proposed PIG-Net and PointNet architectures for 3D object segmentation on PartNet (coarse level) dataset. The "M" stands for million.</figDesc><table><row><cell></cell><cell cols="2">Space complexity Time complexity</cell></row><row><cell></cell><cell>(#params)</cell><cell>(seconds)</cell></row><row><cell>PointNet [49]</cell><cell>3.5M</cell><cell>151.3s</cell></row><row><cell cols="2">PIG-Net (Ours) 2.9M</cell><cell>208.2s</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0" />
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A scalable active framework for region annotation in 3d shape collections</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">,</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename><surname>Ic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIGGRAPH Asia</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tripathi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rgb-d object detection and semantic segmentation for autonomous manipulation in clutter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Milan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Periyasamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>As</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Behnke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Robotics Research</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="437" to="451" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Semantic 3D Object Maps for Everyday Robot Manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Grasping novel objects with depth segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">,</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Phoka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Quigley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sudsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE/RSJ International Conference on Intelligent Robots and Systems</title>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="2578" to="2585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Structure-aware generative network for 3d-shape modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lischinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<idno>abs/1808.03981</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Grass: generative recursive autoencoders for shape structures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chaudhuri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<idno>52:1-52:14</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Graph</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yumer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hoiem</surname></persName>
		</author>
		<title level="m">Generating shape primitives with recurrent neural networks. IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="900" to="909" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Interactive medical image segmentation using deep learning with image-specific fine tuning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zuluaga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pratt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Patel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aertsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans on Medical Imaging</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Focus, segment and erase: An efficient network for multi-label brain tumor segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Liew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Ong</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>Springer International Publishing</publisher>
			<biblScope unit="page" from="674" to="689" />
			<pubPlace>V, Hebert, M, Sminchisescu, C, Weiss, Y</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fit and diverse: Set evolution for inspiring 3d shape galleries</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cohen-Or</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chen</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
		<idno>57:1-57:10</idno>
	</analytic>
	<monogr>
		<title level="j">ACM TOG</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Pose-inspired shape synthesis and functional hybrid</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Visualization and Computer Graphics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2574" to="2585" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Phace: Physics-based face modeling and animation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Ichim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Kadle?ek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kavan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pauly</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno>153:1-153:14</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Graph</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Model adaptation with synthetic and real data for semantic dense foggy scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sakaridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>ECCV</publisher>
			<biblScope unit="page" from="707" to="724" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Scene understanding by reasoning stability and safety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ikeuchi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="221" to="238" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">3d shape segmentation via shape fully convolutional networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="182" to="192" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Example-based sketch segmentation and labeling using crfs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">G</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<idno>151:1-151:9</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Graph</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Shape segmentation by hierarchical splat clustering</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="136" to="145" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">3d shape segmentation and labeling via extreme learning machine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Graphics Forum</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="85" to="95" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Probabilistic joint image segmentation and labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ion</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Carreira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sminchisescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bartlett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems 24</title>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1827" to="1835" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Object segmentation and labeling by learning from examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yaowu</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Saber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Tekalp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="627" to="638" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Learning 3d mesh segmentation and labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hertzmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Singh</surname></persName>
		</author>
		<idno>102:1-102:12</idno>
	</analytic>
	<monogr>
		<title level="j">ACM TOG</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Learning hierarchical features for scene labeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Farabet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Couprie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Najman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Pattern Anal Mach Intell</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1915" to="1929" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Learning deconvolution network for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Noh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 IEEE International Conference on Computer Vision (ICCV). ICCV &apos;15</title>
		<meeting>the 2015 IEEE International Conference on Computer Vision (ICCV). ICCV &apos;15</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1520" to="1528" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Fully convolutional networks for semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shelhamer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="3431" to="3440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Randla-net: Efficient semantic segmentation of large-scale point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. IEEE; 2020</title>
		<imprint>
			<biblScope unit="page" from="11105" to="11114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Point attention network for semantic segmentation of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gilani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognit</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page">107446</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Shrec 2020: 3d point cloud semantic segmentation for street scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ku</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Veltkamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rc</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Boom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Duque-Arias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Velasco-Forero</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Deschaud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers &amp; Graphics</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="13" to="24" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Associatively segmenting instances and semantics in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. Computer Vision Foundation / IEEE; 2019</title>
		<imprint>
			<biblScope unit="page" from="4096" to="4105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Large-scale point cloud semantic segmentation with superpoint graphs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Landrieu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Simonovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR. IEEE Computer Society</title>
		<imprint>
			<biblScope unit="page" from="4558" to="4567" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Attention-based relation and context modeling for point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Qin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="126" to="134" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Snapnet: 3d point cloud semantic labeling with 2d deep segmentation networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Boulch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guerry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Saux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Audebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="189" to="198" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Few-shot 3d point cloud semantic segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
		<idno>abs/2006.12052</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">3d semantic segmentation for large-scale scene understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Akadas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gangisetty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Asian Conference on Computer Vision (ACCV)</title>
		<meeting>the Asian Conference on Computer Vision (ACCV)</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">End-to-end 3d point cloud instance segmentation without detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiao</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. IEEE; 2020</title>
		<imprint>
			<biblScope unit="page" from="12793" to="12802" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Occuseg: Occupancy-aware 3d instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. IEEE; 2020</title>
		<imprint>
			<biblScope unit="page" from="2937" to="2946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Instance segmentation of lidar point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Torr</forename><surname>Phs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICRA. IEEE</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="9448" to="9455" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Learning object bounding boxes for 3d instance segmentation on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Markham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeurIPS</title>
		<imprint>
			<biblScope unit="page" from="6737" to="6746" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Joint instance and semantic segmentation of 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jsnet</surname></persName>
		</author>
		<imprint>
			<publisher>AAAI. AAAI Press</publisher>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="12951" to="12958" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning gaussian instance segmentation in point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
		<idno>abs/2007.09860</idno>
	</analytic>
	<monogr>
		<title level="j">CoRR</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Learning part boundaries from 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Loizou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Averkiou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph Forum</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="183" to="195" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Kpconv: Flexible and deformable convolution for point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Cr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deschaud</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Marcotegui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Goulette</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In: ICCV. IEEE</title>
		<imprint>
			<biblScope unit="page" from="6410" to="6419" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Sparse lattice networks for point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Jampani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kalogerakis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR. IEEE Computer Society</title>
		<imprint>
			<biblScope unit="page" from="2530" to="2539" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Attentional shapecontextnet for point cloud recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Tu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR. IEEE Computer Society</title>
		<imprint>
			<biblScope unit="page" from="4606" to="4615" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Deep learning on point sets with parameterized convolutional filters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Spidercnn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Convolution in the cloud: Learning deformable kernels in 3d graph convolution networks for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. IEEE; 2020</title>
		<imprint>
			<biblScope unit="page" from="1797" to="1806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Pointnet: Deep learning on point sets for 3d classification and segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="77" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">3d object recognition in cluttered scenes with local surface features: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="2270" to="2287" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Narf: 3d range image features for object recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Steder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Konolige</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Burgard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Defining and Solving Realistic Perception Problems in Personal Robotics at the IEEE/RSJ Int. Conf. on Intelligent Robots and Systems (IROS)</title>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Multi-scale features for approximate alignment of point-based surfaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Guskov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Third Eurographics Symposium on Geometry Processing</title>
		<meeting>the Third Eurographics Symposium on Geometry Processing</meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Using spin images for efficient object recognition in cluttered 3d scenes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hebert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">TPAMI</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="433" to="449" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Recognizing objects in range data using regional point descriptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Frome</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kolluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>B?low</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<biblScope unit="page" from="224" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Rops: A local feature descriptor for 3d rigid objects based on rotational projection statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sohel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Bennamoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lu</surname></persName>
		</author>
		<idno>ICCSPA. 2013</idno>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">A 3-dimensional sift descriptor and its application to action recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Scovanner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ali</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>ACM</publisher>
			<biblScope unit="page" from="357" to="360" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Fast point feature histograms (fpfh) for 3d registration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Rusu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Blodow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Beetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICRA</title>
		<imprint>
			<biblScope unit="page" from="1848" to="1853" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Evaluating 3d spatial pyramids for classifying 3d shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>L?pez-Sastre</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Garc?a-Fuertes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Redondo-Cabrera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Acevedo-Rodr?guez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maldonado-Basc?n</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput Graph</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="473" to="483" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Constructing laplace operator from point clouds in rd. SODA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="1031" to="1040" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A concise and provably informative multi-scale signature based on heat diffusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ovsjanikov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Guibas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eurographics Association</title>
		<imprint>
			<biblScope unit="page" from="1383" to="1392" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>SGP</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Scale-invariant heat kernel signatures for non-rigid shape recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Kokkinos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>CVPR</publisher>
			<biblScope unit="page" from="1704" to="1711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">The wave kernel signature: A quantum mechanical approach to shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Aubry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Schlickewei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1626" to="1633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Feature encoding of spectral signatures for 3d non-rigid shape retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Limberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wilson</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the BMVC</title>
		<meeting>the BMVC</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="56" to="57" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Example-based 3d inpainting of point clouds using metric tensor and christoffel symbols</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Setty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Mudenagudi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mach Vision Appl</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="329" to="343" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Semantic labeling and instance segmentation of 3d point clouds using patch context analysis and multiscale processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">K</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE transactions on visualization and computer graphics</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">An evaluation of feature encoding techniques for non-rigid and rigid 3d point cloud retrieval</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Hegde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gangisetty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>BMVC. BMVA Press</publisher>
			<biblScope unit="page">47</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Deep hierarchical feature learning on point sets in a metric space</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pointnet++</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5105" to="5114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Spherical fractal convolutional neural networks for point cloud recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">CVPR. Computer Vision Foundation / IEEE; 2019</title>
		<imprint>
			<biblScope unit="page" from="452" to="460" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Rotation invariant convolutions for 3d point clouds deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rosen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yeung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">3DV. IEEE; 2019</title>
		<imprint>
			<biblScope unit="page" from="204" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Mining point cloud local structures by kernel correlation and graph pooling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="page" from="4548" to="4557" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Escape from cells: Deep kd-networks for the recognition of 3d point cloud models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klokov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="863" to="872" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Multiresolution tree networks for 3d point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gadelha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Maji</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ECCV (7); vol. 11211 of Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="105" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">So-net: Self-organizing network for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVRR</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Pointgrid: A deep network for 3d shape understanding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Duan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Dynamic graph CNN for learning on point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Se</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Bronstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Solomon</surname></persName>
		</author>
		<idno>146:1-146:12</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Graph</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">5</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Di</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pointcnn</surname></persName>
		</author>
		<title level="m">Advances in Neural Information Processing Systems (NIPS)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="820" to="830" />
		</imprint>
	</monogr>
	<note>Convolution on x-transformed points</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Spherical kernel for efficient graph convolution on 3d point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Akhtar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pointconv</surname></persName>
		</author>
		<title level="m">Deep convolutional networks on 3d point clouds. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9613" to="9622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Going deeper with convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Jia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sermanet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Se</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Network in network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2nd International Conference on Learning Representations, ICLR</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Syncspeccnn: Synchronized spectral CNN for 3d shape segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Guibas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="6584" to="6592" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Octree-based convolutional neural networks for 3d shape analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">X</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">Y</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>O-Cnn</surname></persName>
		</author>
		<idno>72:1-72:11</idno>
	</analytic>
	<monogr>
		<title level="j">ACM Trans Graph</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Recurrent slice networks for 3d segmentation of point clouds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR. IEEE Computer Society</title>
		<imprint>
			<biblScope unit="page" from="2626" to="2635" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">SGPN: similarity group proposal network for 3d point cloud instance segmentation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Neumann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">CVPR. IEEE Computer Society</title>
		<imprint>
			<biblScope unit="page" from="2569" to="2578" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Learning densely contextual representation for efficient point cloud processing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Densepoint</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV. IEEE</title>
		<imprint>
			<biblScope unit="page" from="5238" to="5247" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Pointatrousnet: Point atrous convolution for point cloud analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Chew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Robotics Autom Lett</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4035" to="4041" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">Escape from cells: Deep kd-networks for the recognition of 3d point cloud models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Klokov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">S</forename><surname>Lempitsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICCV. IEEE Computer</title>
		<imprint>
			<biblScope unit="page" from="863" to="872" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
