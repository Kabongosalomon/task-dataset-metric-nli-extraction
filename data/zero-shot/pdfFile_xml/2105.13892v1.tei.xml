<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Singapore University of Technology and Design Singapore jingyi</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Singapore University of Technology and Design</orgName>
								<address>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-12T11:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>I. INTRODUCTION</head><p>For classification tasks, deep neural networks (DNNs) are able to achieve zero training error when trained on datasets with label noise, even in the extreme scenario of totally randomized labels <ref type="bibr" target="#b0">[1]</ref>. This poses a challenge when training on real-world datasets. Manual data labeling is both inefficient and expensive, while automated annotation methods inherently introduce label noise. In either case, we typically have access to a small clean subset of the dataset. For such datasets with label noise, how then do we train DNNs that generalize well, regardless of the actual (unknown) noise levels?</p><p>Label noise in real-world datasets is inevitably asymmetric. This asymmetry naturally arises because the performance of any data annotation method that is based on the output labels of a prediction model, is necessarily both class-dependent and This research is supported by the National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG-RP-2019-015), and under its NRFF Programme (Award No: NRFFAI1-2019-0005). instance-dependent <ref type="bibr" target="#b1">[2]</ref>. Although there are numerous existing methods for tackling label noise <ref type="bibr" target="#b2">[3]</ref>- <ref type="bibr" target="#b14">[15]</ref>, all of which perform well in the idealized case of symmetric label noise (provided the noise level is not too high), these existing methods are not as robust to asymmetric label noise, and they exhibit a sharp performance drop at medium-to-high noise levels.</p><p>Despite much progress on tackling label noise, there are two seemingly opposing challenges that have not been tackled jointly: How do we train a model that is (i) robust to all noise levels, and (ii) whose performance at any given noise level is not sensitive to any variation in the noise model?</p><p>To solve both challenges via a unified approach, we propose a distillation-based framework that incorporates a new method of Positive-Unlabeled (PU) learning. In general, we have a trade-off between increasing accuracies across all noise levels for a given noise model, and increasing accuracies across all noise models for a given noise level. Our motivation to use PU learning is based on the observation that samples of any dataset with label noise can naturally be partitioned into "correct" and "incorrect" classes. Clean data is correct by definition, while the remaining noisy dataset contains both correct and incorrect instances. This is precisely the scenario of PU learning, where instances in the noisy dataset are treated as "unlabeled".</p><p>Our framework comprises two components: clean data augmentation and knowledge distillation. Starting with our given clean subset, we initially treat all instances with noisy labels (henceforth called "noisy samples") as being unlabeled, and we gradually augment the original clean subset, iteratively, via PU learning; those (unlabeled) noisy samples inserted into our augmented clean set would be assigned new labels. Crucially, this new label assignment does not require the originally given labels of the noisy samples. In other words, we do not require any assumptions on the underlying noise model. Hence, this clean data augmentation component is automatically robust to all noise models. As for our distillation component, we train a teacher model solely on the augmented clean set, thus we are able to suppress the influence of label noise when training the student model, especially at high noise levels.</p><p>Our major contributions are summarized as follows:</p><p>? We propose a versatile distillation-based framework for tackling label noise. In contrast to existing work, our framework is robust to all noise levels, and is not sensitive to noise model variation. To the best of our knowledge, this is the first ever solution that overcomes both major challenges we described earlier. <ref type="bibr">?</ref> We introduce a new type of PU learning. We then use this new technique to design a clean data augmentation algorithm, which also allows us to correct noisy samples with high confidence. The effectiveness of our augmentation algorithm is demonstrated by the high precision scores of reliably clean samples extracted from the validation set. ? In experiments on CIFAR-10 <ref type="bibr" target="#b15">[16]</ref> with asymmetric semantic label noise, our proposed framework outperformed outperforms state-of-the-art (SOTA) methods at noise levels 50%-90%. When evaluated on the real-world noisy dataset Clothing1M <ref type="bibr" target="#b16">[17]</ref>, we achieved a new SOTA accuracy of 77.70% (2.94% higher than previous SOTA).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>II. RELATED WORK A. Existing Approaches for Tackling Label Noise</head><p>Data cleaning methods. These are methods applied to identified noisy labels, and they include label correction <ref type="bibr" target="#b6">[7]</ref>, sample re-weighting <ref type="bibr" target="#b9">[10]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b17">[18]</ref>, label distribution estimation <ref type="bibr" target="#b18">[19]</ref>, re-sampling of a relabeled dataset <ref type="bibr" target="#b19">[20]</ref>, and treating ambiguous samples as unlabeled data and applying a semi-supervised method <ref type="bibr" target="#b20">[21]</ref>. The efficacy of such methods depends heavily on the identification of noisy labels, which is inherently a difficult problem as DNNs easily overfit noisy labels. Methods with robust loss functions. There are numerous loss functions proposed to alleviate the influence of label noise. These include symmetric loss <ref type="bibr" target="#b3">[4]</ref>, variants of crossentropy (CE) loss (generalized CE loss <ref type="bibr" target="#b10">[11]</ref>, symmetric CE loss <ref type="bibr" target="#b10">[11]</ref>, Taylor CE loss <ref type="bibr" target="#b21">[22]</ref>), bootstrap loss <ref type="bibr" target="#b2">[3]</ref>, <ref type="bibr" target="#b8">[9]</ref>, bileveloptimization-based loss <ref type="bibr" target="#b22">[23]</ref>, information-theoretic loss <ref type="bibr" target="#b11">[12]</ref>, SIGUA loss <ref type="bibr" target="#b23">[24]</ref>. See also <ref type="bibr" target="#b14">[15]</ref> for a general framework for combining loss functions to enhance robustness to label noise. Noise model estimation methods. Label noise is modeled either explicitly by a noise transition matrix <ref type="bibr" target="#b4">[5]</ref>, <ref type="bibr" target="#b5">[6]</ref>; or implicitly via graphical models <ref type="bibr" target="#b16">[17]</ref>, knowledge graphs <ref type="bibr" target="#b24">[25]</ref>, conditional random fields <ref type="bibr" target="#b25">[26]</ref>, residual nets <ref type="bibr" target="#b26">[27]</ref>, or joint embedding networks <ref type="bibr" target="#b27">[28]</ref>. Once an underlying noise model has been well-estimated, the true labels can then be inferred with high confidence. For example, a good estimation of the noise transition matrix can be achieved by adding an extra noise model over the base model and simultaneously training both models <ref type="bibr" target="#b28">[29]</ref>, <ref type="bibr" target="#b29">[30]</ref>, albeit with certain strong assumptions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Preliminaries</head><p>Knowledge distillation was first proposed by Hinton et al. <ref type="bibr" target="#b30">[31]</ref> for model compression, whereby the knowledge learned by a large teacher model f t (?), is transferred to another smaller student model f s (?), by applying a weighted average of two objective functions as follows:</p><formula xml:id="formula_0">L(y, f s (x)) = ?l(y, f s (x)) + (1 ? ?)l(f t (x), f s (x)),<label>(1)</label></formula><p>where l(?) is the traditional loss function, and ? is a parameter to balance the effect of the given labels and the outputs of the teacher model.</p><p>Assuming that a subset D c of a given dataset is known to have correct labels, Li et al. <ref type="bibr" target="#b24">[25]</ref> proposed a distillation-based method, where the teacher model f t (?) is trained on D c and the student model f s (?) is subsequently trained using the loss function in <ref type="bibr" target="#b0">(1)</ref>. Hence, the student model would have a higher accuracy compared to the same model trained directly on the noisy dataset, as long as the error rate of the teacher model is less than the noise rate of the dataset.</p><p>A key merit of this distillation-based method is that it can be flexibly built on top of any algorithm for training the teacher and student models. However, their method has two drawbacks: (i) The noisy labels remain invariant in the objective function, which affects the performance of the student model; (ii) It requires a large clean set (e.g. the values |Dc| |D| = 1 and 1 4</p><p>were used in their experiments) to train a sufficiently accurate teacher model. PU learning is a special type of semi-supervised learning that involves training a binary classifier on a set of positive data P and a set of unlabeled data U <ref type="bibr" target="#b31">[32]</ref>. Existing PU learning algorithms are classified into four approaches: (i) bias-based, (ii) heuristic-based, (iii) bagging-based, and (iv) risk-based.</p><p>? A bias-based approach treats U as learnable weighted combinations of "positive" and "negative" classes <ref type="bibr" target="#b32">[33]</ref>. ? A heuristic-based approach iteratively selects reliable negative samples from the unlabeled data via a two-step algorithm: (i) identify new reliable negative samples N from U; (ii) train a binary classifier on P and N <ref type="bibr" target="#b33">[34]</ref>. ? A bagging-based approach uses an ensemble of classifiers trained on bootstrap subsets <ref type="bibr" target="#b34">[35]</ref>. ? A risk-based approach estimates the misclassification risk by replacing the risk of negative samples with risk in terms of P and U given class prior <ref type="bibr" target="#b35">[36]</ref>. Mixup <ref type="bibr" target="#b36">[37]</ref> is a data augmentation method proposed to favor linear relations on the samples, which involves augmenting the training dataset with convex combinations of pairs of examples and their labels. Specifically, given a pair of samples, (x i , y i ) and (x j , y j ), the augmented sample is generated vi?</p><formula xml:id="formula_1">x = ?x i + (1 ? ?)x j ,? = ?y i + (1 ? ?)y j ,</formula><p>where ? ? Beta(?, ?) follows a beta distribution for some parameter ? ? (0, ?). We used ? = 2 in our experiments.</p><p>Entropy regularization <ref type="bibr" target="#b6">[7]</ref> is introduced to concentrate the distribution of each prediction vector to one peak:</p><formula xml:id="formula_2">L e = ? 1 n n i=1 C j=1 p i (x i ) log(p i (x i )),<label>(2)</label></formula><p>where n is the number of instances, C is the number of classes, and p i (?) is the i-th entry of the output vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>III. PROPOSED FRAMEWORK</head><p>Consider a C-class noisy dataset with a small portion of clean set known to have correct labels. We denote the dataset by D = D c ? D n , where D c and D n represent this small clean set and the remaining noisy set, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Proposed Method</head><formula xml:id="formula_3">Inputs: Number of classes C, clean set D c = C i=1 D (i)</formula><p>c , noisy set D n , number of iterations K, number of ensemble models N , positive threshold ?, reliability criterion ?, number of teacher models N t . Intermediate teacher models: f</p><formula xml:id="formula_4">(i) n (1 ? n ? N, 1 ? i ? C). Output: Student classifier f s . // Clean data augmentation 1: for i = 1 to C do 2:P (i) ? ?. 3: for k = 1 to K do 4: m (i) k ? min{|D (i) c |, |P (i) |}; m (i) k ? m (i) k +|D (i) c | 2 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5:</head><p>for n = 1 to N do Train f</p><formula xml:id="formula_5">(i) n on D (i)</formula><p>c ?P (positives); N ?N (negatives). <ref type="bibr" target="#b7">8</ref>:</p><formula xml:id="formula_6">P (i) ? x ? D n |{n | f (i) n (x) ? ?}| ? ? . 9: Update P (i) =P (i) ? D (i) c . 10: P ? C i=1 P (i) .</formula><p>//Knowledge distillation <ref type="bibr">11:</ref> for n = 1 to N t do <ref type="bibr">12:</ref> Train f (n) t on a balanced bootstrap subset of P. <ref type="bibr" target="#b12">13</ref>: Generate pseudo-labels for samples in D n with teacher models. <ref type="bibr">14:</ref> Train a student model f s on D c ? D n with pseudo-labels. <ref type="bibr" target="#b14">15</ref>: return f s Our framework comprises two components, clean data augmentation and knowledge distillation. In the first component, we introduce a new method of PU learning to train a filter on the clean set and generate the augmented clean set with the filter. The filter and the clean set are updated iteratively, and the final augmented clean set is used to correct D n . In the second component, we apply a variant of knowledge distillation, where the teacher model is trained on the augmented clean set, and the student model is trained on the entire dataset. (See Algorithm 1 for a summary.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A. Clean Data Augmentation Component</head><p>We first propose a tiered PU learning method to augment the small clean set with a two-step iterative method: (i) Train an ensemble filter on the clean data with the idea of bagging <ref type="bibr" target="#b37">[38]</ref>, which generates an ensemble of models separately trained on bootstrap subsets of the whole dataset; (ii) Use the filter to choose reliable samples from the noisy set and update the clean set. By repeatedly alternating between these two steps, we will gradually improve the filter and enlarge the clean set.</p><p>In contrast to existing PU learning approaches, which fix the given positive set throughout training, we update the positive set iteratively. Also, despite having a similar two-step strategy, our approach is not heuristic-based: We do not need an initial distinguished set of reliable negative examples.</p><p>Let P =P ?D c (resp. P (i) =P (i) ?D (i) c ) be the augmented clean set (for class i), whereP (resp.P (i) ) represents the additional reliable samples filtered from the noisy set (for class i). Augmentation is done separately for each class, so for ease of explanation, consider a single class i. Initializ? P (i) = ?. Next, run K iterations, where in each iteration, form an ensemble filter consisting of N binary classifiers {f</p><formula xml:id="formula_7">(i) n } N n=1</formula><p>to update the augmented clean dataset P (i) , described as follows:</p><p>? Train an ensemble filter {f</p><formula xml:id="formula_8">(i) n } N n=1 .</formula><p>The main idea is to separately train each binary classifier on a bootstrap subset of "positive" data combined with a bootstrap subset of "negative" data. Note that D</p><formula xml:id="formula_9">(i) c and j =i D (j) c</formula><p>are already known to be absolutely positive samples and negative samples, respectively. We shall obtain more positive (resp. negative) samples with a lower confidence level from the additional augmented clean set P (i) (resp. the remaining noisy set D n \P (i) ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Let m</head><formula xml:id="formula_10">(i) k := min{|D (i) c |, |P (i) |} and m (i) k := m (i) k +|D (i) c | 2</formula><p>be two parameters to control the size of bootstrap subsets. For each binary classifier f</p><formula xml:id="formula_11">(i) n , we shall sample subsets P ?P (i) , N ? D n \P and N ? j =i D (j) c uniformly at random, such that |P | = m (i) k , |N | = |N | = m (i) k . Next, we train f (i) n on D (i)</formula><p>c ? P as the positives, and N ? N as the negatives. Note that f</p><formula xml:id="formula_12">(i) 1 , . . . , f (i)</formula><p>N are trained on different random subsets, each with an equal number of positive and negative samples. Hence, the aggregation of these N models would have lower bias. ? Generate the augmented clean set</p><formula xml:id="formula_13">P (i) =P (i) ? D (i) c .</formula><p>Using the ensemble filter generated in the previous step, we select samples from the noisy set that are identified as positive samples with relatively high confidence. Specifically, we define the set of additional positive samples.</p><formula xml:id="formula_14">P (i) = x ? D n |{n | f (i) n (x) ? ?}| ? ? ,<label>(3)</label></formula><p>where the reliability criterion ? and confidence threshold ? are two hyperparameters designed to control the confidence level ofP (i) . The set of positive samples for each model f Repeat these two steps for K iterations.</p><p>In general, we convert a multi-class semi-supervised problem into C binary classification problems that are easier to solve. Take class i for example, we have a small clean "positive" set D ( c i) at the beginning, and we sample a "negative" bootstrap set from D n to train each binary model, where roughly C?1 C ? 100% samples are true negatives. Intuitively, the negative set sampled in this way is more reliable than other semi-supervised methods that are based on similarity measures, and is easier to implement.</p><p>Given the augmented clean dataset P, we apply a variant of knowledge distillation to train a teacher-student model. In contrast to the original distillation method <ref type="bibr" target="#b24">[25]</ref>, <ref type="bibr" target="#b30">[31]</ref>, we instead use a casewise parameter ?(x j ) based on the maximum entry of the prediction vector of teacher model.</p><p>We first train the teacher model on the augmented clean set P with reassigned labels. Next, we train the student model on the entire dataset D. (The given labels are already corrected at the end of the previous component.) If P is class-balanced, we directly train a multi-classifier on P as the teacher model. Otherwise, we train an ensemble of several (e.g. 5) classifiers on balanced bootstrap subsets of P, where each bootstrap subset contains min i |P (i) | samples for every class. Note that the loss function given in (1) is equivalent to a normal loss function (e.g. cross-entropy) applied to pseudolabel?, which is generated as a weighted combination of the teacher model output and the (corrected) given label. There are three ways to generate the pseudo-labels:</p><p>? Soft bootstrap label:</p><formula xml:id="formula_15">y j = ?(x j )f t (x j ) + (1 ? ?(x j ))y j ,<label>(4)</label></formula><p>where f t (x j ) is the average prediction vector of 5 teacher models, y j is the one-hot vector of the j-th corrected given label, and ?(?) is a function to measure the confidence level of the teacher models for x j , defined by</p><formula xml:id="formula_16">?(x j ) = ?, if max(f t (x j )) ? ?; 0, if ? &gt; max(f t (x j ));<label>(5)</label></formula><p>where ? is used to control the confidence level of the pseudo-labels, and ? is used to keep the balance between the prediction of teacher model and given label. ? Hard bootstrap label: The definition is similar to soft bootstrap label, but the prediction vector f t (x j ) in <ref type="formula" target="#formula_15">(4)</ref> is replaced by a one-hot vector, where the entry of value 1 is the maximum entry in f t (x j ), i.e. argmax f t (x j ). ? Hard label:</p><formula xml:id="formula_17">y j = argmax f t (x j ), if max(f t (x j )) ? ?; argmax y j , if ? &gt; max(f t (x j )).<label>(6)</label></formula><p>IV. EXPERIMENTS A. Experiment Setup 1) Datasets: CIFAR-10. The CIFAR-10 dataset <ref type="bibr" target="#b15">[16]</ref> contains 50,000 training images and 10,000 test images in 10 classes, with 6,000 images per class. Each image has a size of 32 ? 32 ? 3. Let the ratio of the original clean set D c and the noise level of the entire dataset D be denoted by ?% and r% respectively. Within each class, we sampled ?% 10 ? 50, 000 images uniformly at random from the training set to form the original clean data D c . Then, we added two types of synthetic label noise to the remaining (100 ? ?)% data as follows:</p><p>? Symmetric noise. We randomly chose 100r 100?? % samples from the remaining (100??)% data, and for each chosen sample, we randomly assigned a new label. We require a 100 100?? factor to take into consideration the original ?% clean set used in our method;</p><p>? Asymmetric noise. We followed the definition in <ref type="bibr" target="#b4">[5]</ref>, where label noise for pairs of semantically similar classes (CAT?DOG, DEER?HORSE, BIRD?AIRPLANE, TRUCK?AUTOMOBILE) was generated by randomly assigning 100r 100?? % samples from each objective class with the target label. Note that the noise level defined in <ref type="bibr" target="#b4">[5]</ref> refers the class noise level. As we have 5 objective classes, the overall noise level of the dataset is 0.5r%. Clothing1M. The clothing1M dataset <ref type="bibr" target="#b16">[17]</ref> is a real-world image dataset with both noisy and clean labels. There are over a million clothing images in 14 classes collected from online shopping websites, and a noisy label is automatically assigned to each image based on the keywords in surrounding text. A manually labeled clean subset with 72,409 images is provided.</p><p>2) Baselines: For CIFAR-10, we compared our framework with the following baselines, using the code provided in the respective papers. For those methods that add synthetic noise via a transition matrix, we multiply the noise level by factor 0.9 (i.e., N class ?1 N class ) for fair comparison. ? Mixup <ref type="bibr" target="#b36">[37]</ref>, which alleviates the effect of noisy labels by training on convex combinations of pairs of samples. ? Joint Optimization <ref type="bibr" target="#b6">[7]</ref>, which alternately updates network parameters and labels during training. ? Co-teaching <ref type="bibr" target="#b38">[39]</ref>, which simultaneously trains two neural networks and cross-updates the network parameters. ? Loss Correction <ref type="bibr" target="#b8">[9]</ref>, which estimates wrong label probabilities and corrects the loss with a beta mixture model. ? JoCoR <ref type="bibr" target="#b39">[40]</ref>, which jointly trains two networks using a joint loss with co-regularization. ? DivideMix <ref type="bibr" target="#b13">[14]</ref>, which divides the dataset into two subsets, and concurrently trains two networks in a semisupervised manner using MixMatch. 3) Implementation Details: For CIFAR-10, we used a Pre-Activation ResNet-18 <ref type="bibr" target="#b40">[41]</ref> and an SGD optimizer with a momentum of 0.9, a weight decay of 10 ?4 , and batch size of 128. For preprocessing, the images were normalized, and augmented by random horizontal flipping and random 32?32 cropping with padding=4. In the clean set augmentation step, each model was trained over 30 epochs. The learning rate was initialized at 0.01 and was divided by 10 after 20 epochs. The teacher models and the student model were trained over 100 epochs each. The learning rate was initialized at 0.05 and was divided by 10 after 30, 50, and 80 epochs.</p><p>For Clothing1M, we follow the configuration used in previous works <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b11">[12]</ref>, <ref type="bibr" target="#b12">[13]</ref>, <ref type="bibr" target="#b27">[28]</ref>, <ref type="bibr" target="#b41">[42]</ref>, <ref type="bibr" target="#b42">[43]</ref>, i.e. we used a ResNet-50 <ref type="bibr" target="#b40">[41]</ref> pre-trained on ImageNet. We used an SGD optimizer with a momentum of 0.9, a weight decay of 10 ?4 , a cross-entropy loss function, and a batch size of 32. For preprocessing, the images were normalized, and augmented by random horizontal flipping and centered 224?224 cropping. In the clean set augmentation step, each model was trained over 20 epochs. The learning rate was initialized at 0.03 and was divided by 10 after 10 and 15 epochs. We trained the student model and each teacher model for 5 epochs. The learning rate was initialized at 0.001 and was divided by 10 after 3 epochs.</p><p>Code is available at https://github.com/Xu-Jingyi/PUDistill.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B. Comparison between Different Ratios of Clean Set</head><p>We applied bootstrapping when training the teacher model on the augmented clean set to (i) mitigate the problem of imbalance, and (ii) reduce the training time. Specificically, we sampled a balanced subset of the augmented clean set in each epoch, and trained the teacher model on the bootstrap subset, instead of the entire augmented clean set. In order to improve robustness, we also used mixup data augmentation and entropy regularization (cf. Section II-B) to train the teacher models and student model. The detailed ablation study and elaboration of the effectiveness of each technique is given in Section IV-G.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. Evaluation of Augmented Clean Set</head><p>To show the effectiveness of our clean data augmentation algorithm, we reported the precision and number of augmented clean samples in TABLE I, where the results were evaluated on test set for CIFAR-10 and validation set for Clothing1M. As described in Section III-A, we introduced a threshold ? to filter "positive" samples, and a hyperparameter ? to control the size of augmented clean set. In our experiment, we fixed ? = 0.9, ? = 19 (out of 20) for CIFAR-10, and ? = 0.95, ? = 10 (out of 10) for Clothing1M. Our method extracted more than 40% samples while achieved overall precision 0.94 and 0.85 for CIFAR-10 and Clothing1M, respectively. <ref type="figure">Fig. 1</ref>: Comparison of the best test accuracies (average of 5 trials) corresponding to different clean ratios (?%) on CIFAR-10 with symmetric noise (upper) and asymmetric noise (lower). All experiments were implemented using softbootstrap pseudo-labels. <ref type="figure">Fig. 2</ref>: Comparison of the best test accuracies (average of 5 trials) corresponding to different types of pseudo-labels on CIFAR-10 with symmetric noise (upper) and asymmetric noise (lower). We fixed ? = 0.7 and ?% = 10% in the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>D. Evaluation of Teacher Model</head><p>As given in (4)-(6), the teacher model is used to generate pseudo-labels for the training of the student model. In order to guarantee the accuracy of the pseudo-labels, we only modified the labels of samples in {x j ? D n | max(f t (x j )) ? ?}, while the pseudo-labels of the remaining samples were kept as the given labels. Here f t (?) is the average output vector of 5 models, and ? is the threshold to control the confidence level of the ensemble teacher model. We evaluated the ensemble JoCoR <ref type="bibr" target="#b39">[40]</ref> 70. <ref type="bibr">30 4</ref> Loss correction <ref type="bibr" target="#b8">[9]</ref> 71.00 5 Joint opt. <ref type="bibr" target="#b6">[7]</ref> 72. <ref type="bibr">23 6</ref> L DMI <ref type="bibr" target="#b11">[12]</ref> 72.46 7</p><p>Metacleaner <ref type="bibr" target="#b12">[13]</ref> 72.50 8</p><p>Meta learning <ref type="bibr" target="#b41">[42]</ref> 73.47 9</p><p>DeepSelf <ref type="bibr" target="#b42">[43]</ref> 74.45 10 CleanNet <ref type="bibr" target="#b27">[28]</ref> 74.69 11 DivideMix <ref type="bibr" target="#b13">[14]</ref> 74.76 12 our method 77.70 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E. Comparison between Different Types of Pseudo-labels</head><p>To show the difference between three types of pseudo-labels introduced in (4)-(6), we compared the best test accuracies on CIFAR-10 with different levels of symmetric noise and asymmetric noise in <ref type="figure">Fig. 2</ref>. For both symmetric and asymmetric noise, hard label performed worse than two bootstrap labels at low noise levels, and hard bootstrap label had a similar performance compared with soft bootstrap label. Intuitively, hard label resulted in lower accuracies because it failed to take the given label into consideration for those samples with high confidence, i.e. max(f t (x j )) ? ?. However, this problem was mitigated by the case-wise pattern of pseudo-labels, where the pseudo-label was only assigned to those samples that teacher model was confident on, and the labels of the remaining samples remained the given labels. Hence this casewise pattern can avoid introducing additional noise because of inaccurate teacher model, and it happened to shorten the gap between hard labels and the other two bootstrap labels.</p><p>As described previously, our method uses an initial small clean set D c , with proportion ?% := |Dc| |Dc?Dn| . To study the effect of ? on the test accuracy, we applied our algorithm to CIFAR-10 with different noise levels for both symmetric and asymmetric noise. <ref type="figure">Fig. 1</ref> shows that the gap between curves of different clean ratios is not large under low noise levels, and our method performs well even with only a 1% clean set. However, at high noise levels, the curves for low clean ratios dramatically dropped, especially for asymmetric noise, while the curve for 10% clean ratio was relatively flat.</p><p>F. Comparison with State-of-the-art 1) Experiments on CIFAR-10: We reproduced the results of the baselines <ref type="bibr" target="#b6">[7]</ref>, <ref type="bibr" target="#b8">[9]</ref>, <ref type="bibr" target="#b13">[14]</ref>, <ref type="bibr" target="#b36">[37]</ref>, <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref> using the same configuration that we used to evaluate our proposed method: (i) We used the same architecture, Pre-Activation ResNet-18 <ref type="bibr" target="#b40">[41]</ref>; (ii) We multiplied the noise level in <ref type="bibr" target="#b38">[39]</ref>, <ref type="bibr" target="#b39">[40]</ref> by a factor 0.9, and multiplied the noise level in our method with a factor 100 100?? to keep the expected proportion of incorrect labels equal across all methods. The comparison results between our method and all the baselines on the CIFAR-10 dataset with asymmetric noise are reported in TABLE V.</p><p>To evaluate the robustness of each method against different noise models, we compared the accuracies of each mothod with different noise levels for symmetric and asymmetric noise in <ref type="figure" target="#fig_2">Fig. 3</ref>. As claimed in Section IV-A1, the noise level of asymmetric defined in <ref type="bibr" target="#b4">[5]</ref> is the class noise level within the corrupted classes, hence the overall noise level of the dataset is actually 0.5r%. In order to compare the performance of each method between symmetric model and asymmetric model, we need to modify the noise level of asymmetric noise by a factor 0.5. The curves corresponding to symmetric and asymmetric noise model of our method were very close and flat across all of the noise levels. However, the gap between two lines for other 7 baselines became larger as the noise level increased, and the curves of some methods dramatically dropped, especially under asymmetric case. Our method is robust not only over all noise levels but also against different noise models because of the effectiveness of the clean data augmentation step. By treating all the noisy samples as unlabeled samples and applying a tired PU learning method, our augmentation process is totally independent of the given noisy labels, thereby explaining this robustness.</p><p>2) Experiments on Clothing1M: We directly compared our experiment result with accuracies reported in papers that used the same model architecture, i.e. a ResNet-50 <ref type="bibr" target="#b40">[41]</ref> pre-trained on ImageNet; see TABLE III. We trained the student model over 5 epochs and achieved a highest test accuracy 77.70%; this is the highest accuracy among all methods in TABLE III.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>G. Ablation Study</head><p>To study the effect of mixup data augmentation, bootstrapping, and entropy regularization on our method, we conducted an ablation study on the teacher model (see TABLE IV) and student model (see TABLE VI), where the "standard" method means our method without any of these three techniques. Below, we consolidate some insights obtained.</p><p>? All three techniques helped to improve the accuracies slightly. Mixup data augmentation has the largest effect. ? The effect of mixup is more significant under symmetric noise than under asymmetric noise. Intuitively, mixup improves the robustness to label noise because the combination of a pair of samples might partially correct the wrong labels when one sample accidentally contains the  true label of the other noisy sample. For asymmetric noise, the label flips occur only between similar classes, so "accidental label correction" is less likely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>V. CONCLUSION AND FURTHER REMARKS</head><p>Our proposed framework is robust to all noise levels. This robustness is universal since the performance at any given noise level is not sensitive to variations in the noise model. We achieved state-of-the-art accuracy on Clothing1M, a dataset with real-world label noise, and our experiments on CIFAR-10 with asymmetric semantic label noise show superior outperformance over all baselines. Crucially, we achieve universal robustness because our clean data augmentation process does not use the labels of noisy samples; we only require a small clean subset. Our framework can be built on top of any classification algorithm (not necessarily using DNNs). Therefore, our framework is versatile, robust, and widely applicable to any classification tasks for datasets with arbitrary label noise. VI: Ablation study results in terms of student model's test accuracy (%) on CIFAR-10. We set the ratio of original clean set=0.1, ? = 0.9, and ? = 0.5. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>6 :</head><label>6</label><figDesc>Randomly sample P , N , and N , such that |P | = m (i) k , and |N | = |N | = m</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>n</head><label></label><figDesc>(x) &gt; ?}, thusP (i) is composed of samples x for which there exist at least ? binary classifiers (f (i) * ) that classify x as positive data. To complete this iterative step, let P (i) =P (i) ?D (i) c , and samples in P (i) are automatically relabeled with label i.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 3 :</head><label>3</label><figDesc>Comparison of the performance of different methods under symmetric noise and asymmetric noise. The noise level here refers to overall noise level within the dataset, e.g. r% asymmetric noise would correspond to 0.5r% overall noise level.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE I :</head><label>I</label><figDesc>The precision and size of the augmented clean set for CIFAR-10 (test set) and Clothing1M (validation set).</figDesc><table><row><cell>Class</cell><cell></cell><cell>CIFAR10</cell><cell cols="2">Clothing1M</cell></row><row><cell></cell><cell>Precision</cell><cell>Size</cell><cell>Precision</cell><cell>Size</cell></row><row><cell>0</cell><cell>0.92</cell><cell>413</cell><cell>0.94</cell><cell>298</cell></row><row><cell>1</cell><cell>0.98</cell><cell>586</cell><cell>0.83</cell><cell>142</cell></row><row><cell>2</cell><cell>0.93</cell><cell>281</cell><cell>0.46</cell><cell>166</cell></row><row><cell>3</cell><cell>0.80</cell><cell>219</cell><cell>0.95</cell><cell>736</cell></row><row><cell>4</cell><cell>0.90</cell><cell>306</cell><cell>0.78</cell><cell>651</cell></row><row><cell>5</cell><cell>0.93</cell><cell>368</cell><cell>0.93</cell><cell>554</cell></row><row><cell>6</cell><cell>0.96</cell><cell>462</cell><cell>0.69</cell><cell>247</cell></row><row><cell>7</cell><cell>0.97</cell><cell>456</cell><cell>0.54</cell><cell>273</cell></row><row><cell>8</cell><cell>0.96</cell><cell>575</cell><cell>0.93</cell><cell>498</cell></row><row><cell>9</cell><cell>0.97</cell><cell>538</cell><cell>0.95</cell><cell>480</cell></row><row><cell>10</cell><cell>-</cell><cell>-</cell><cell>0.96</cell><cell>272</cell></row><row><cell>11</cell><cell>-</cell><cell>-</cell><cell>0.58</cell><cell>173</cell></row><row><cell>12</cell><cell>-</cell><cell>-</cell><cell>0.82</cell><cell>680</cell></row><row><cell>13</cell><cell>-</cell><cell>-</cell><cell>0.91</cell><cell>624</cell></row><row><cell>Overall</cell><cell>0.94</cell><cell>4,204 (out of 10,000)</cell><cell>0.85</cell><cell>5,794 (out of 14,313)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE II :</head><label>II</label><figDesc></figDesc><table><row><cell>?</cell><cell>CIFAR10</cell><cell></cell><cell>Clothing1M</cell><cell></cell></row><row><cell></cell><cell>Accuracy (%)</cell><cell>Size</cell><cell>Accuracy (%)</cell><cell>Size</cell></row><row><cell>0.9</cell><cell>99.3</cell><cell>1,313</cell><cell>94.6</cell><cell>5,635</cell></row><row><cell>0.8</cell><cell>98.0</cell><cell>4,845</cell><cell>91.3</cell><cell>8,219</cell></row><row><cell>0.7</cell><cell>95.6</cell><cell>6,492</cell><cell>88.1</cell><cell>9,950</cell></row><row><cell>0.6</cell><cell>93.0</cell><cell>7,561</cell><cell cols="2">85.1 11,407</cell></row><row><cell>0.5</cell><cell>89.8</cell><cell>8,487</cell><cell cols="2">82.0 12,808</cell></row><row><cell>0.0</cell><cell cols="2">82.5 10,000</cell><cell cols="2">77.7 14,313</cell></row></table><note>Accuracy of the ensemble teacher model, which is evaluated on the subset {x ? D test | max(f t (x)) ? ?} of the test set (resp. evaluated on the validation set) for CIFAR-10 (resp. Clothing1M) with various threshold values ?.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE III :</head><label>III</label><figDesc>Best test accuracies of different methods on the Clothing1M dataset. For all baselines, we use the reported results in the respective papers.</figDesc><table><row><cell>#</cell><cell>Method</cell><cell>Accuracy (%)</cell></row><row><cell>1</cell><cell>Cross Entropy [7]</cell><cell>68.94</cell></row><row><cell>2</cell><cell>Forward [5]</cell><cell>69.84</cell></row><row><cell>3</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE IV</head><label>IV</label><figDesc></figDesc><table><row><cell cols="3">: Ablation study results in terms of teacher model's</cell></row><row><cell cols="3">test accuracy (%) on CIFAR-10 and Clothing1M.</cell></row><row><cell>Methods</cell><cell cols="2">CIFAR-10 Clothing1M</cell></row><row><cell>Standard</cell><cell>76.88?1.82</cell><cell>77.27?0.11</cell></row><row><cell>+ mixup</cell><cell>80.68?2.48</cell><cell>77.57?0.05</cell></row><row><cell>+ bootstrap</cell><cell>77.31?1.16</cell><cell>76.97?0.47</cell></row><row><cell>+ entropy reg. + bootstrap</cell><cell>77.12?1.30</cell><cell>77.68?0.04</cell></row><row><cell>+ mixup + bootstrap</cell><cell>81.05?1.70</cell><cell>77.75?0.10</cell></row><row><cell cols="2">+ mixup + bootstrap + entropy reg. 81.45?1.45</cell><cell>77.18?0.05</cell></row></table><note>teacher model for different values of ?; see TABLE II.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE V :</head><label>V</label><figDesc>Average (5 trials) and standard deviation of the best test accuracies of different methods on the CIFAR-10 dataset with semantic asymmetric noise. The highest accuracy for each noise level is boldfaced.30?0.42 84.28?0.65 77.40?1.52 67.54?1.21 61.72?0.30 57.24?0.31 52.70?0.21 Mixup [37] 90.53?0.70 86.59?1.13 78.67?0.93 69.19?1.16 62.52?1.32 57.90?2.1 53.30?0.80 Joint Optimization [7] 92.01?0.21 89.56?0.78 84.56?0.94 78.21?0.32 76.70?0.11 76.44?0.21 76.00?0.14 Co-teaching [39] 84.50?0.41 70.69?3.53 54.29?1.30 48.76?0.92 46.40?0.89 45.66?1.77 44.39?1.53 Loss Correction [9] 90.87?0.23 87.21?0.22 74.63?1.08 58.82?1.08 58.06?0.09 53.72?3.32 53.04?3.59 JoCoR [40] 76.57?2.67 67.74?4.23 56.54?1.22 48.52?1.84 46.22?0.80 43.74?0.81 43.06?1.89 DivideMix [14] 93.95?0.06 84.43?0.94 73.73?1.07 60.13?2.40 53.18?3.99 50.60?0.546 49.42?0.33 Our Method 90.00?0.22 88.22?0.26 85.98?0.45 84.41?0.15 83.77?0.12 83.00?0.10 82.63?0.25</figDesc><table><row><cell>Method</cell><cell></cell><cell></cell><cell></cell><cell>Noise Level (%)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>30</cell><cell>40</cell><cell>50</cell><cell>60</cell><cell>70</cell><cell>80</cell><cell>90</cell></row><row><cell>Cross Entropy</cell><cell>88.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>TABLE</head><label></label><figDesc></figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>74?0.32 81.06?0.33 77.39?0.37 73.29?0.66 87.32?0.47 82.91?0.46 76.34?0.84 70.32?1.76 +Mixup 88.90?0.23 85.34?0.34 81.82?0.19 76.94?0.45 89.30?0.27 84.93?0.32 77.72?1.50 71.25?2.51 +Entropy reg. 86.52?0.21 83.26?0.36 79.68?0.38 74.58?0.40 87.41?0.23 82.98?0.44 76.16?1.14 70.33?1.93 +Mixup +Entropy reg. 90.10?0.17 87.12?0.26 83.52?0.10 78.88?0.49 90.00?0.22 85.66?0.26 77.20?1.61 70.52?2.73</figDesc><table><row><cell>Noise type</cell><cell></cell><cell>Symmetric</cell><cell></cell><cell></cell><cell></cell><cell>Asymmetric</cell><cell></cell><cell></cell></row><row><cell>Method/Noise level</cell><cell>30%</cell><cell>50%</cell><cell>70%</cell><cell>90%</cell><cell>30%</cell><cell>50%</cell><cell>70%</cell><cell>90%</cell></row><row><cell>Standard</cell><cell>84.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Understanding deep learning requires rethinking generalization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Recht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.03530</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A survey and analysis on automatic image annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="242" to="259" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rabinovich</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6596</idno>
		<title level="m">Training deep neural networks on noisy labels with bootstrapping</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>preprint</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Robust loss functions under label noise for deep neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sastry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">31</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Making deep neural networks robust to label noise: A loss correction approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Patrini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rozza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Menon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Qu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1944" to="1952" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Using trusted data to train deep networks on labels corrupted by severe noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hendrycks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mazeika</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page">465</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Joint optimization framework for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ikami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aizawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5552" to="5560" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Generalized cross entropy loss for training deep neural networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Sabuncu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1805.07836</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Unsupervised label noise modeling and loss correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arazo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ortego</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>O&amp;apos;connor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mcguinness</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1904.11238</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Metaweight-net: Learning an explicit mapping for sample weighting</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1917" to="1928" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Symmetric cross entropy for robust learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="322" to="330" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">L dmi: A novel informationtheoretic loss function for training deep nets robust to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6222" to="6233" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Metacleaner: Learning to hallucinate clean representations for noisy-labeled visual recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Qiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7373" to="7382" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Dividemix: Learning with noisy labels as semi-supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HJgExaVtwr" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Normalized loss functions for deep learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Romano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Erfani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bailey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="6543" to="6553" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Learning multiple layers of features from tiny images</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Citeseer, Tech. Rep</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Learning from massive noisy labeled data for image classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="2691" to="2699" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Leung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="2304" to="2313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Probabilistic end-to-end noise correction for learning with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7017" to="7025" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">A light cnn for deep face representation with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Forensics and Security</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2884" to="2896" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A semi-supervised two-stage approach to learning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 IEEE Winter Conference on Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="1215" to="1224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Can cross entropy loss be robust to label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Joint Conferences on Artificial Intelligence</title>
		<meeting>the 29th International Joint Conferences on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="2206" to="2212" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Deep bilevel learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jenni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Favaro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="618" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Sigua: Forgetting may make learning with noisy labels more robust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="4006" to="4016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Learning from noisy labels with distillation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1910" to="1918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Toward robustness against label noise in training deep discriminative neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vahdat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 31st International Conference on Neural Information Processing Systems, ser. NIPS&apos;17</title>
		<meeting>the 31st International Conference on Neural Information Processing Systems, ser. NIPS&apos;17<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2017" />
			<biblScope unit="page" from="5601" to="5610" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Weakly supervised image classification through noise regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="11" to="517" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Cleannet: Transfer learning for scalable image classifier training with label noise</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="5447" to="5456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Learning deep networks from noisy labels with dropout regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nokleby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE 16th International Conference on Data Mining (ICDM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="967" to="972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Training convolutional networks with noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sukhbaatar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bruna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Paluri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bourdev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1406.2080</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Distilling the knowledge in a neural network</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Vinyals</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1503.02531</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Learning from positive and unlabeled examples with different data distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X.-L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European Conference on Machine Learning</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="218" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Learning classifiers from only positive and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Elkan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Noto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the 14th ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="213" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Partially supervised classification of text documents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">S</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ICML</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="387" to="394" />
			<date type="published" when="2002" />
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">A bagging svm to learn from positive and unlabeled examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mordelet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-P</forename><surname>Vert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="201" to="209" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Analysis of learning from positive and unlabeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Du Plessis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">NIPS</title>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="page" from="703" to="711" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Cisse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lopez-Paz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1710.09412</idno>
		<title level="m">mixup: Beyond empirical risk minimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Bagging predictors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="140" />
			<date type="published" when="1996-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Co-teaching: Robust training of deep neural networks with extremely noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.06872</idno>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Combating noisy labels by agreement: A joint training method with co-regularization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>An</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="13" to="726" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Identity mappings in deep residual networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Learning to learn from noisy labeled data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5051" to="5059" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Deep self-learning from noisy labels</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE International Conference on Computer Vision</title>
		<meeting>the IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="5138" to="5147" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
