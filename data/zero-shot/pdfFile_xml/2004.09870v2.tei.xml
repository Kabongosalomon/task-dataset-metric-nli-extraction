<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /nfs/home/kabenamualus/Research/task-dataset-metric-extraction/../grobid-0.6.0/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">RICE GRAIN DISEASE IDENTIFICATION USING DUAL PHASE CONVOLUTIONAL NEURAL NETWORK BASED SYSTEM AIMED AT SMALL DATASET A PREPRINT</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-05-11">May 11, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tashin</forename><surname>Ahmed</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chowdhury</forename><surname>Rafeed</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rahman</forename><forename type="middle">Md</forename><surname>Faysal</surname></persName>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mahmud</forename><surname>Abid</surname></persName>
						</author>
						<title level="a" type="main">RICE GRAIN DISEASE IDENTIFICATION USING DUAL PHASE CONVOLUTIONAL NEURAL NETWORK BASED SYSTEM AIMED AT SMALL DATASET A PREPRINT</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2021-05-11">May 11, 2021</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>

		<encodingDesc>
			<appInfo>
				<application version="0.6.0" ident="GROBID-SDO" when="2022-11-11T17:11+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid-sdo"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Faster RCNN ? Dual phase detection ? Small dataset ? Rice grain ? Convolution</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although Convolutional neural networks (CNNs) are widely used for plant disease detection, they require a large number of training samples while dealing with wide variety of heterogeneous background. In this paper, a CNN based dual phase method has been proposed which can work effectively on small rice grain disease dataset with heterogeneity. At the first phase, Faster RCNN method is applied for cropping out the significant portion (rice grain) from an image. This initial phase results in a secondary dataset of rice grains devoid of heterogeneous background. Disease classification is performed on such derived and simplified samples using CNN architecture. Comparison of the dual phase approach with straight forward application of CNN on the small grain dataset shows the effectiveness of the proposed method which provides a 5 fold cross validation accuracy of 88.92%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As rice grain diseases occur at the very last moment ahead of harvesting, it does major damage to the cultivation process. The average loss of rice due to grain discolouration <ref type="bibr" target="#b0">[1]</ref> was 18.9% in India. Yield losses caused by False Smut (FS) <ref type="bibr" target="#b1">[2]</ref> ranged from 1.01% to 10.91% in Egypt. 75% yield loss of grain occurred in India in 1950, while in the Philippines <ref type="bibr" target="#b2">[3]</ref> more than 50% yield loss was recorded. Rice yield loss is a direct consequence of Neck Blast (NB) disease, since this disease results in poor panicles. A big reason behind Neck Blast <ref type="bibr" target="#b3">[4]</ref> is an extreme phase of the Blast and grain disease. In Bangladesh False Smut was one of the most destructive rice grain disease <ref type="bibr" target="#b4">[5]</ref> from year 2000 to 2017.</p><p>Collecting field level data on agronomy is a challenging task in the context of poor and developing countries. The challenges include lack of equipment and specialists. Farmers of such areas are ignorant of technology use which makes it quite difficult to collect crop disease related data efficiently using smart devices via the farmers. Hence, scarcity of plant disease oriented data is a common challenge while automating disease detection in such areas.</p><p>Many researches have been undertaken with a view to automating plant disease detection utilizing different techniques of machine learning and image processing. <ref type="bibr" target="#b5">[6]</ref> through system with the ability to identify areas which contain abnormalities. They applied a threshold based clustering algorithm for this task. A framework have been created <ref type="bibr" target="#b6">[7]</ref> for the detection of defected diseased leaf using K-Means clustering based segmentation. They claimed that their approach was able to detect the healthy leaf area and defected diseased area accurately. A genetic algorithm has been developed <ref type="bibr" target="#b7">[8]</ref> which was used for selecting essential traits and optimal model parameters for the SVM classifiers for Bakanae gibberella fujikuroi disease. A technique to classify the diseases based on percentage of RGB value of the affected portion was proposed <ref type="bibr" target="#b8">[9]</ref> utilizing image processing. A similar technique using multi-level colour image thresholding was proposed <ref type="bibr" target="#b9">[10]</ref> for RLB disease detection. Deep learning based object classification and segmentation has become the state-of-the-art for automatic plant disease detection. Neural network was employed <ref type="bibr" target="#b10">[11]</ref> for leaf disease recognition while a self organizing map neural network (SOM-NN) was used <ref type="bibr" target="#b11">[12]</ref> to classify rice disease images. Researchers also  experimented with AlexNet <ref type="bibr" target="#b12">[13]</ref> to distinguish among 3 classes of rice disease using a small dataset containing 227 images. A similar research for classifying 10 classes of rice disease on a 500 image dataset was undertaken <ref type="bibr" target="#b13">[14]</ref> using a handmade deep CNN architecture. Furthermore, the benefit of using pre-trained model of AlexNet and GoogleNet <ref type="bibr" target="#b14">[15]</ref> has been demonstrated when the training data is not large. Their dataset consisted of 9 diseases of tomatoes. A detailed comparative analysis of different state-of-the-art CNN baseline and finely tuned architecture <ref type="bibr" target="#b15">[16]</ref> on eight classes of rice disease and pest also conveys a huge potential. It demonstrates two-stage training approach for memory efficient small CNN architectures. Besides works on rice disease some experimental procedure on other agricultural elements are, <ref type="bibr" target="#b16">[17]</ref> specialized deep learning models based on specific CNN architectures for identification of plant leaf diseases with a dataset containing 58 classes from 25 different plants have been developed. Transfer learning approach using GoogleNet <ref type="bibr" target="#b17">[18]</ref> on a dataset containing 87848 images of 56 diseases infecting 12 plants. Extraction of disease region from leaf image through different segmentation <ref type="bibr" target="#b18">[19]</ref> techniques was a driving step. Some of the image segmentation algorithms were compared <ref type="bibr" target="#b19">[20]</ref> in order to segment the diseased portion of rice leaves.</p><p>Though the above mentioned researches have a significant contribution to the automation of disease detection, none of the works addressed the problem of scarcity of data which limits the performance of CNN based architectures. Most of the researches focused on image augmentation techniques to tackle the dataset size issue. But applying different geometric augmentations on small size images <ref type="bibr" target="#b20">[21,</ref><ref type="bibr" target="#b21">22]</ref> result in nearly the same type of image production which has drawbacks in terms of neural network training. Production of similar images through augmentation <ref type="bibr" target="#b22">[23]</ref> can cause overfitting as well.</p><p>The first phase of the proposed method deals with a learning oriented segmentation based architecture. This architecture helps in detecting the significant grain portion of a given image that has a heterogeneous background, which is an easier task compared to disease localization. The detected grain portions cropped from the original image are used as separate simplified images. In the second phase, these simplistic grain images are used in order to detect grain disease using fine tuned CNN architecture. Because of the simplicity of the tasks assigned in the two phases, our proposed method performs well in spite of having only 200 images of three classes. To prove the proposed approach is satisfactory for a small dataset, counter experimentations on straightforward CNN and Faster RCNN were also demonstrated at Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Dataset</head><p>Our balanced dataset of 200 images consists of three classes -False Smut, Neck Blast and healthy grain class as shown in <ref type="table">Table 1</ref>.</p><p>A sample image from each class has been shown in <ref type="figure">Figure.</ref> 1. Neck Blast is generally caused by the fungus known as Magnaporthe oryzae. It causes plants to develop very few or no grains at all. Infected nodes result <ref type="bibr" target="#b23">[24]</ref> in panicle break down. False Smut is caused by the fungus called Ustilaginoidea virens. It results in lower grain weight and reduction <ref type="bibr" target="#b24">[25]</ref> of seed germination.</p><formula xml:id="formula_0">(i) (h) (g) (f) (e) (d) (c) (b) (a)</formula><p>Data have been collected and annotated from two separate sources for this experiment -field data supervised by officials from Bangladesh Rice Research Institute (BRRI) and image data from a previously expermineted <ref type="bibr" target="#b15">[16]</ref> repository. As Boro species have the maximum threat to be affected with False Smut and Neck Blast, Boro rice plant has been chosen <ref type="bibr" target="#b25">[26]</ref> for experimental data collection. Parameters like light, distance and uniqueness have been taken into consideration while capturing the photographs. The main parameter which was taken into account was heterogeneity of the background. Some sample images of hetergenous background of the dataset have been presented in <ref type="figure">Figure.</ref> 2.</p><p>To make the dataset more challenging multiclass images also have been taken into account. Sample images of multiclass data which consists both Neck Blast and False Smut class have been presented in <ref type="figure">Figure.</ref> 3. If there is a multiclass data it had been labelled as Neck Blast for the training phase of counter experiments (explained in Section 4) as False Smut already surpassed by quantity than Neck Blast. Also, the dataset was split into 80:20 in terms of train and validation set. Augmentation techniques were not applied as the main goal of this experiment is to use small and natural scene image data. Additionally, there are other factors that can spoil the experiment, such as illumination, symptom severity, maturity of the plant and diseases. A large versatile dataset can attend on that occasion which can be achieved in the future. The dataset has been kept to three classes for the early stages of the investigation. Also, it is quite challenging and burdensome to collect different rice disease image dataset throughout the year as different diseases occur at different time. So, at this early stage of the investigation three classes is competent to deliver a sufficient result. Supplementary public data related to the paper can be found at https://cutt.ly/RvgxoDi.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Materials and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>This subsection explained about the experimental setup which includes hardware used in this experiment and explains five basenets applied. This subsection have also discussed about different hyperparameter optimization and their consequence in this experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Hardware</head><p>For the training environment, assistance has been taken from two different sources.</p><p>? Royal Melbourne Institute of Technology (RMIT) provides GPU for international research enthusiasts and they provided a Red Hat Enterprise Linux Server along with the processor Intel Xeon E5-2690 CPU, clock speed of 2.60 GHz. It has 56 CPUs with two threads per core, 503 GB of RAM. Each user can use up to 1 petabyte of storage. There are also two 16 GB NVIDIA Tesla P100-PCIE GPUs available. First phase was completed through this server.</p><p>? Google Colab (Tesla K80 GPU, 12GB RAM) and Kaggle kernel (Tesla P100 GPU) have been used for counter experimentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Utilized CNN Models</head><p>Experiments have been performed using five state-of-the-art CNN architectures which are described as follows. <ref type="figure">Figure.</ref> 4 shows architectures and key blocks of the applied CNN architectures.</p><p>VGG16 is a sequential architecture <ref type="bibr" target="#b26">[27]</ref> consisting of 16 convolutional layers. Kernel size in all convolution layers is three.</p><p>VGG19 has three extra convolutional layers <ref type="bibr" target="#b26">[27]</ref> and the rest is the same as VGG16.</p><p>ResNet50 belongs to the family of residual neural networks. It is a deep CNN architecture <ref type="bibr" target="#b27">[28]</ref> with skip connections and batch normalization. The skip connections help in eliminating the gradient vanishing problem.</p><p>InceptionV3 is a CNN architecture <ref type="bibr" target="#b28">[29]</ref> with parallel convolution branching. Some of the branches have filter size as large as 7 ? 7.</p><p>Xception takes the principles of Inception to an extreme. Instead of partitioning the input data into several chunks, it maps the spatial correlations <ref type="bibr" target="#b29">[30]</ref> for each output channel separately and performs 1 ? 1 depthwise convolution. Adam, SGD <ref type="table">Table 2</ref>: Experimented hyperparameters. Bold values were selcted for the prime experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3">Optimized Hyperparameters</head><p>Hyperparameters of Faster RCNN have been presented in <ref type="table">Table 2</ref>.</p><p>Anchor Box Hyperparameters: Anchor boxes are a set of bounding boxes defined through different scales and aspect ratios. They mark the probable regions of interest of different shapes and sizes. The total number of probable anchor boxes per pixel of a convolutional feature map is P n ? R n , where P n and R n denote the number of anchor box size variations and ratio variations respectively.</p><p>Region Proposal Network (RPN) Hyperparameters: RPN layer utilizes the convolutional feature map of the original image to propose regions of interest that are identifiable within the original image. The proposals are made in line with the anchor boxes. For each anchor box, RPN predicts if it is an object of interest or not and changes the size of the anchor box to better fit the object. RPN threshold of 0.4 -0.8 means that any proposed region which has IoU (Intersection Over Union) less than 0.4 with ground truth object is considered a wrong guess whereas any proposed region which has IoU greater than 0.8 with ground truth object is considered correct. This notion is used for training the RPN layer.</p><p>Proposal Selection: Proposal selection threshold of 200 means that top (according to probability) 200 region proposals from RPN layer will pass on to the next layers for further processing.</p><p>Overlap Threshold: During non-max suppression, overlapping object proposals are excluded if the IoU is above a certain threshold. If their overlap is greater than the threshold, only the proposal with the highest probability is kept and the procedure continues until there are no more boxes with sufficient overlap.</p><p>Learning Rate: It is used for controlling the speed of model parameter update.</p><p>Optimizer: Optimizer is an algorithm for updating model parameter weights after training on each batch of samples.</p><p>Weight updating process varies with the choice of optimizer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Faster RCNN Class: False Smut</head><p>Class: Healthy  <ref type="figure">Figure 5</ref>: Proposed dual phase approach; Phase one for detection of the significant portion and phase two for classification; A multiclass data have been presented as an example to demonstrate the classification strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Proposed Dual Phase Approach</head><p>In this research, a dual phase approach has been introduced in order to learn effectively from small dataset containing images with a lot of heterogeneity in the background. The approach overview has been provided in <ref type="figure">Figure.</ref> 5. In the first phase, the original image is taken, reshaped to a fixed size and then passed through segmentation oriented Faster RCNN architecture. At most two best regions have been selected from the first phase. After obtaining the significant grain portions from an image, those regions are cropped and resized to a fixed size. These images look simple because of the absence of heterogeneous background. CNN architecture is trained on this simplified dataset to detect disease. The learning process has been showed to be effective through experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Segmenting Grain Portion</head><p>This is the first phase of our approach. Segmentation algorithms based on CNN architecture as a backbone requires image to be of fixed size. Input images have been resized to 640?480 before feeding them to Faster RCNN. The consecutive stages of the network through which this resized image passes through have been described as follows.</p><p>Convolutional Neural Network (CNN): In order to avoid sliding a window in each spatial position of the original image, CNN architecture is used in order to learn and extract feature map from the image which represents the image effectively. The spatial dimension of such feature map decreases whereas the channel number increases.</p><p>For the dataset used in this research, VGG16 architecture has proven to be the most effective. Hence, VGG16 has been used as the backbone CNN architecture which transforms the original image into 20 ? 15 ? 512 dimension. Region Proposal Network (RPN): The extracted feature map is passed through RPN layer. For each pixel of the feature map of spatial size 20?15, there are 16 possible bounding boxes (4 different aspect ratios and 4 different sizes mentioned in bold letter in <ref type="table">Table 2</ref>). So, that makes total 16?20?15 = 4800 possible bounding boxes, RPN is a two branch Convolution layer which provides two scores (branch one) and four coordinate adjustments (branch two) for each of the 4800 boxes. The two scores correspond to the probability of being an object and a non-object. Only those boxes which have a high object probability are taken into account. Non-max suppression (NMS) is used in order to eliminate overlapping object bounding boxes and to keep only the high probability unique boxes. The threshold of this overlap in this case is 0.8 IoU. From this probable object proposals, top 200 proposals according to object probability are passed to the next layers. ROI Pooling: Each of the 200 selected object proposals correspond to some region in the CNN feature map. For passing each of these regions on to the dense layers of the architecture, each of the regions need to be of fixed size. ROI pooling layer takes each region and turns them into 7?7?512 using bilinear interpolation and max pooling. RCNN Layer: RCNN layer consists of fully connected dense layers. Each of the 7?7?512 size feature maps are flattened and passed through these fully connected layers. The final layer has two branches. Branch one predicts if the input feature map is background class or significant grain portion. Branch two provides four regression values denoting the adjustment of the bounding box to better fit the grain portion. For each feature map, if the probability of being a grain is over 0.6, only then is the feature map considered as a probable grain portion and the adjusted coordinates are mapped to the original image in order to get the localized grain portion. The overlapping boxes are eliminated using NMS. The remaining bounding box regions are the significant grain portions. Loss Function: The trainable layers of Faster RCNN architecture are: CNN backbone, RPN layer and RCNN layer. A loss function is needed in order to train these layers in an end to manner which is as follows.</p><formula xml:id="formula_1">L(p i , t i ) = 1 N cls i L cls (p i , p * i ) + ? 1 N reg i p * i L reg (t i , t * i )</formula><p>The first term of this loss function defines the classification loss over two classes which describe whether predicted bounding box i is an object or not. The second term defines the regression loss of the bounding box when there is a ground truth object having significant overlap with the box. Here, p i and t i denote predicted object probability of bounding box i and predicted four coordinates of that box respectively while p * i and t * i denote the same for the ground truth bounding box which has enough overlap with predicted bounding box i. N cls is the batch size (256 in this case) and N reg is the total number of bounding boxes having enough overlap with ground truth object. Both these terms work as normalization factor. L cls and L reg are log loss (for classification) and regularized loss (for regression) function respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Disease Detection from Segmented Grain</head><p>Figure. 5 shows Faster RCNN architecture drawing bounding boxes on two significant grain portions. These portions are cropped and resized to a fixed size (300?250 in this case) in order to pass each of them through a CNN architecture. Thus two images have been created from single image of the primary dataset. The same process can be executed on each of the images of the primary dataset. Thus a secondary dataset of significant grain portion can be created. Each of these images have to be labeled as one of the three classes in order to train the CNN architecture. The complete dataset including these secondary image counts has been shown in <ref type="table">Table 3</ref>. The cropped portions when passed through a trained CNN model have been predicted as False Smut disease and Neck Blast class in <ref type="figure">Figure.</ref> 5 as it is an example of multiclass data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation Metric</head><p>All results have been provided in terms of 5 fold cross validation. Accuracy metric has been utilized in order to compare dual phase approach against implementation of CNN on original images without any segmentation. Accuracy is a suitable metric for balanced dataset. <ref type="table">Image  Increment  Primary Secondary  False Smut 75  85  10  Neck Blast 63  70  7  Healthy  62  64  2  Total  200  219  19  Table 3</ref>: Complete Dataset</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Class Image Count</head><formula xml:id="formula_2">Accuracy = T P T P + F P + T N + F N 2</formula><p>Segmenting the grain portion is the goal of the first phase of the dual phase approach. For evaluating the performance of this phase, mAP (mean average precision) score has been used. Precision, recall and IoU (Intersection over Union) are required to calculate mAP score.</p><formula xml:id="formula_3">P recision = T P T P + F P Recall = T P T P + F N IoU = AOI AOU 3</formula><p>If a predicted box IoU is greater than a certain predefined threshold, it is considered as TP. Otherwise, it is considered as FP. (T P + F N ) is actually the total number of ground truth bounding boxes. Average precision (AP) is calculated from the area under the precision-recall curve. If there are N classes, then mAP is the average AP of all these classes. In this research, there is only one class of object in phase one, that is the significant grain portion class. So, here AP and mAP are the same.</p><p>As the proposed method has two stages: segmentation and classification, failure in proper segmentation can leads to classification failure. In this work, two stages are created as an intact pipeline so that outcome of the first stage directed to the second stage as input. Detail about the procedure mentioned in Subsection 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>As mentioned earlier, the proposed dual-phase approach has been performed in two steps. First, segmentation of the grain parts and lastly the classification of the segmented parts. This experiment has been mentioned as the prime experiment throughout the paper. To verify the performance of the prime experiment, different CNN architectures and Faster RCNN has been employed separately. This part of the experiment has been mentioned as the counter experiment.</p><p>Individual counter experiments have been performed to analyze their performance with the respective phase of the prime experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Counter Experiments</head><p>Two counter experiments have been performed named, counter experiment 01 and 02. Counter experiment 01 is based on various CNN architectures where the goal is to obtain the classification outcome from the primary dataset. Counter experiment 02 is based on Faster RCNN underlying three selected CNN architectures which has been applied for both classification and detection of the three classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1">Counter Experiment 01: CNN</head><p>This experiment has been conducted applying five different CNN architectures which were mentioned earlier in Subsubsection 3.1.2. Three transfer learning approaches have been followed (which are freezed layer, fine tuning and fine tuning + dropout) in this part utilizing imagenet pretrained models. At first, freezing layer approach has been  <ref type="table">Table 4</ref>: Counter Experiment 01: CNN performed which is also known as a default transfer learning method. VGG16 outperformed other CNN architectures with a validation accuracy of 63.33 ? 2.04 mentioned in <ref type="table">Table 4</ref>. Then, finely-tuned approach has been applied which shows improvement in validation accuracy of 67.79 ? 3.24 for VGG16. Finally, dropout has been applied inside the CNN architectures which results in a significant improvement of 69.43 ? 3.41 for VGG16. Fine-tuning and fine-tuning + dropout have been performed several times by experimenting with dropout on various positions inside individual CNNs. Although the standard deviation of the outcome for VGG16 is large which is an indication of low precision. Comparative results for all five architecture have been shown in <ref type="table">Table 4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2">Counter Experiment 02: Faster RCNN</head><p>In this counter experiment 02, Faster RCNN has been applied utilizing three different CNN architectures as the backbone. The goal of this experiment is to test the ability of Faster RCNN for efficient detection and classification of the significant portion (grain). VGG16 and VGG19 have been chosen because of their performance at counter experiment 01. Additionally, ResNet50 have chosen because of the lower validation loss than Xception and InceptionV3, mentioned in <ref type="table">Table 4</ref>. CNN models have been applied as pretrained model accumulated from COCO and Imagenet. Different hyperparameter optimizations have been applied to reach the peak outcome for Faster RCNN mentioned in <ref type="table">Table 5</ref>.</p><p>Default settings from the Faster RCNN paper <ref type="bibr" target="#b30">[31]</ref> for anchor box ratio were (1:1), (2:1), (1:2) and anchor box pixels were 128, 256, 512. Which produces 3?3=9 anchor boxes per pixel. The default RPN threshold of (0.3 -0.7), overlap threshold 0.8 and default anchor box ratios and pixels, VGG16 (imagenet pretrained model) provided the best mAP score of 71.0 ? 4.0. After tuning RPN threshold to (0.4 -0.8), anchor box ratios to (1:1), ( 1 <ref type="bibr">(2:2)</ref> and pixel sizes to 32, 64, 128, 256, 4?4=16 anchor boxes have been produced which provides better outcome than before. This setting improved the mAP for VGG16 (imagent pretrained model) to 76.32 ? 2.29 which is the peak outcome after several optimization.</p><formula xml:id="formula_4">? 2 : 2 ? 2 ), ( 2 ? 2 : 1 ? 2 ),</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Prime Experiment: Dual Phase Approach</head><p>Prime experiment has been performed by creating a pipeline in two phases shown in <ref type="figure">Figure.</ref> 5. In the first phase, segmentations of grain has been performed and the segmented parts were cropped and saved as the secondary dataset, mentioned in subsubsection 3.2.2. K fold cross-validation (K=5) have been performed where train and validation split was 80:20. As a result, the full primary dataset has been converted into a secondary dataset. In the second phase, three selected CNN architectures have been utilized for final classification after labelling the secondary dataset in terms of three classes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Phase One: Segmentation of Grains</head><p>The goal of phase one is to crop out the significant part (grain) from a particular image. Faster RCNN have been utilized following three different CNN architecture as the backbone. Applied CNN architectures were VGG16, VGG19 and ResNet50 which were already applied in counter experiment 02 mentioned in Subsubsection 4.1.2. Also, hyperparameters setting have been followed from the counter experiment 02. Only the best performed hyperparameter setting were applied in phase one mentioned in <ref type="table">Table 2</ref>. Faster RCNN with VGG16 as backbone achieved the best mAP score of 84.3 ? 2.36. The result have been achieved through five fold cross validation. Thus all images in the dataset have been evaluated. From each image at most two new images have been generated which creates a secondary dataset. This operation has been performed by selecting two best bounding boxes from each image. First bounding box is the best bounding box referred by the Faster RCNN which is cropped and became the part of the new dataset. Second bounding box has been selected which satisfy the IoU threshold of 0.5 and accuracy threshold of 90%. For several images there were no bounding boxes which met this requirement. On that case only one image have been selected for the new dataset. <ref type="figure">Figure. 6</ref> shows the bounding boxes from each image for phase one. Here on sub figure (c) only one bounding box get detected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2">Phase Two: Classification</head><p>Image data received from phase one channeled through phase two where it provides the classification result. Again three different CNN architecture, VGG16, VGG19 and ResNet50 have been applied in this phase. Best settings from counter experiment 01 have been reapplied in this phase that has been mentioned in Subsubsection 4.1.1. VGG16 emerged with the best validation accuracy of 88.11 ? 3.86 mentioned in <ref type="table">Table 7</ref>. <ref type="figure">Figure.</ref> 7 shows loss and accuracy graph for train and validation of the first training fold out of five folds for phase two. The graphs also shows the training was less time consuming as the dataset was small. By zooming in the graph it is visible that VGG16 was still learning shown in <ref type="figure">Figure.</ref> 8.</p><p>In general, expectancy from CNN models like VGG16 is higher in this dataset as there is only 3 class and they are quite different from each other in terms of class features. This is a pipeline-based process and phase one can generate FP/FN results which will be channeled through phase two. As a result, phase two will be unable not classify them properly. Which is a limitation of this system. This issue can be solved by presenting a new class which can be titled "No Grain" that will declare anything but grain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In brief, this research has the following contributions: -A dual phase approach capable of learning from small rice grain disease dataset has been proposed.</p><p>-A smart segmentation procedure has been proposed in phase one which is capable of handling heterogeneous background prevalent in plant disease image dataset collected in real life scenario -Experimental comparison has been provided with straightforward use of state-of-the-art CNN architectures on the small rice grain dataset to show the effectiveness of the proposed approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgments</head><p>We thank Information and Communications Technology (ICT) division, Bangladesh for aiding this research and the authority of Bangladesh Rice Research Institute (BRRI) for supporting us with field level data collection. We also acknowledge the help of RMIT University who gave us the opportunity to use their GPU server.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Sample image of every grain classes. From left: (a) False Smut, (b) Healthy and (c) Neck Blast. Images clearly show the complexity of the dataset where foreground and background are quite identical.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Sample of data heterogeneity amongst the dataset which demonstrates different parameters like unique backgrounds, lights, contrast, distance have been taken into account while data was gathered. Red rectangular boxes show how the annotation process has been performed. (a, d, f): multiclass images consists of Neck Blast and False Smut, (b): healthy, (c, e, h): False Smut, (g, i): Neck Blast.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Sample multiclass data; Labeled green for Neck Blast and red for False Smut class</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Accuracy and loss for train and validation; Phase Two.(a)VGG16, (b)VGG19, (c)ResNet50. Accuracy and loss for train and validation (Zoomed); Phase Two. Only VGG 16 is showing further improvement is possible through training.(a)VGG16, (b)VGG19, (c)ResNet50.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>:</head><label></label><figDesc>Image count and percentage(%) of each class of the primary dataset.</figDesc><table><row><cell>Class</cell><cell>Image Count</cell><cell>Image Percentage</cell></row><row><cell cols="2">False Smut 75</cell><cell>37.5</cell></row><row><cell cols="2">Neck Blast 63</cell><cell>31.5</cell></row><row><cell>Healthy</cell><cell>62</cell><cell>31.0</cell></row><row><cell>Table 1</cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Prime Experiment: First Phase; Sample Outcome: accuracy of detected objects. Phase One detected two bounding boxes from (a) and (b) as the second bounding box meets IoU and accuracy threshold. (c) have not met the IoU or accuracy threshold so the second bounding box is absent.</figDesc><table><row><cell>Pretrained Model Imagenet COCO grain: 89% Anchor Box Ratio (1:1), (2:1), (1:2) (1:1), ( 1 ? 2 : 2 ? 2 ), ( 2 ? 2 : 1 ? 2 ), (2:2) (1:1), (2:1), (1:2) (1:1), ( 1 ? 2 : 2 ? 2 ), ( 2 ? 2 : 1 ? 2 ), (2:2) Table 5: Counter Experiment 02: Faster RCNN Anchor Box Pixels RPN Threshold CNN Architecture Overlap Threshold 128,256, 512 0.3 -0.7 VGG16 &gt;0.8 VGG19 ResNet50 32, 64, 128, 256 0.4 -0.8 VGG16 &gt;0.8 &gt;0.9 VGG19 &gt;0.8 &gt;0.9 ResNet50 &gt;0.9 &gt;0.8 128,256, 512 0.3 -0.7 VGG16 &gt;0.8 VGG19 ResNet50 32, 64, 128, 256 0.4 -0.8 VGG16 &gt;0.8 &gt;0.9 VGG19 &gt;0.8 &gt;0.9 ResNet50 &gt;0.9 &gt;0.8 grain: 91% grain: 94% mAP (%) 71.0 ? 4.0 47.06 ? 2.01 67.14 ? 6.68 76.32 ? 2.29 63.42 ? 2.36 70.08 ? 4.54 70.30 ? 2.36 40.02 ? 3.03 52.36 ? 5.91 48.32 ? 4.79 32.30 ? 4.83 46.36 ? 2.04 54.24 ? 2.23 48.0 ? 2.10 42.36 ? 1.02 41.07 ? 5.21 28.42 ? 4.84 30.23 ? 3.0 grain: 94% grain: 91% (a) (b) (c) Box Ratio Anchor Box Pixels RPN Threshold CNN Architecture Overlap Threshold mAP (%) (1:1),( 1 ? 2 : 2 ? 2 ), ( 2 ? 2 : 1 ? 2 ),(2:2)) 32, 64, 128, 256 0.4 -0.8 VGG16 &gt;0.8 84.3 ? 2.36 VGG19 &gt;0.8 73.5 ? 1.34 ResNet50 &gt;0.8 65.9 ? 2.59 Table 6: Prime Experiment: Phase One CNN Architecture Train Loss Train Accuracy (%) Validation Loss Validation Accuracy (%) VGG16 0.196 94.47 0.195 88.11 ? 3.86 VGG19 0.095 89.98 0.093 86.43 ? 2.98 ResNet50 0.367 89.63 0.281 78.00 ? 2.32 Figure 6: Anchor Table 7: Prime Experiment: Phase Two</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">TP: True Positive, FP: False Positive, TN: True Negative, FN: False Negative 3 AOI: Area of intersection, AOU: Area of union (with respect to ground truth bounding box)</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Disease incidence and yield loss in rice due to grain discolouration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mathew S Baite</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Raghu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sr Prabhukarthikeyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Keerthana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nitiprasad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Jambhulkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Prakash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Rath</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Plant Diseases and Protection</title>
		<imprint>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rice false smut (ustilaginoidea virens) in egypt</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mm Atia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Plant Diseases and Protection</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="82" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shu</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ou</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
		</imprint>
	</monogr>
	<note>Rice diseases. IRRI</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Neck blast disease influences grain yield and quality traits of aromatic rice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammad Ashik Iqbal</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md</forename><surname>Md Rejwan Bhuiyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Partha</forename><forename type="middle">Pratim</forename><surname>Shahadat Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Anjuman</forename><surname>Sen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Md Ansar</forename><surname>Md Abubakar Siddique</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comptes rendus biologies</title>
		<imprint>
			<biblScope unit="volume">337</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="635" to="641" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Rice False Smut Disease in Bangladesh: Epidemiology, Yield Loss and Management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nessa</forename><surname>Bodrun</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>Sylhet</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Plant Pathology and Seed Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Automated rice leaf disease detection using color image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Reinald</forename><surname>Adrian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Pugoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Vladimir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mariano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Third International Conference on Digital Image Processing</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">8009</biblScope>
			<biblScope unit="page">80090</biblScope>
		</imprint>
	</monogr>
	<note>ICDIP 2011</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Detection of healthy and defected diseased leaf of rice crop using k-means clustering technique</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Prabira</forename><surname>Kumar Sethy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Baishalee</forename><surname>Negi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nilamani</forename><surname>Bhoi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Computer Applications</title>
		<imprint>
			<biblScope unit="volume">157</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="27" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Detecting bakanae disease in rice seedlings by machine vision. Computers and electronics in agriculture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chia-Lin</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai-Jyun</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Szu-Yu</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ming-Hsing</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yu-Chia</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yan-Fu</forename><surname>Kuo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="404" to="411" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A faster technique on rice disease detectionusing image processing of affected area in agro-field</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Taohidul</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Manish</forename><surname>Sah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sudipto</forename><surname>Baral</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Rudra</forename><surname>Roychoudhury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="62" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Rice leaf blast disease detection using multi-level colour image thresholding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Mn Abu Bakar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdul</forename><surname>Abdullah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rahim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yazid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Sn Misman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Masnan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Telecommunication, Electronic and Computer Engineering (JTEC)</title>
		<imprint>
			<biblScope unit="page" from="1" to="6" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Leaves recognition using back propagation neural network-advice for pest and disease control on crops. IndiaKisan. Net: Expert Advisory System</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ms Prasad Babu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Srinivasa Rao</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Rice disease identification using pattern recognition techniques</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Santanu</forename><surname>Phadikar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jaya</forename><surname>Sil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">11th International Conference on Computer and Information Technology</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="420" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">A multiclass deep convolutional neural network classifier for detection of common rice plant anomalies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daechul</forename><surname>Ronnel R Atole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">INTERNATIONAL JOURNAL OF ADVANCED COMPUTER SCIENCE AND APPLICATIONS</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="70" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Identification of rice diseases using deep convolutional neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yang</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shujuan</forename><surname>Yi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nianyin</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yurong</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yong</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="page" from="378" to="384" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Deep learning for tomato diseases: classification and symptoms visualization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mohammed</forename><surname>Brahimi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kamel</forename><surname>Boukhalfa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Abdelouahab</forename><surname>Moussaoui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Applied Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="299" to="315" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<idno type="arXiv">arXiv:1812.01043</idno>
		<title level="m">Farzana Nowrin, and Abu Wasif. Identification and recognition of rice diseases and pests using convolutional neural networks</title>
		<editor>Chowdhury Rafeed Rahman, Preetom Saha Arko, Mohammed Eunus Ali, Mohammad Ashik Iqbal Khan, Sajid Hasan Apon</editor>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Deep learning models for plant disease detection and diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Konstantinos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ferentinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computers and Electronics in Agriculture</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="page" from="311" to="318" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Impact of dataset size and variety on the effectiveness of deep learning and transfer learning for plant disease classification. Computers and electronics in agriculture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jayme</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Arnal</forename><surname>Barbedo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">153</biblScope>
			<biblScope unit="page" from="46" to="53" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A survey on detection and classification of rice plant diseases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Jitesh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Harshadkumar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Prajapati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Dabhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2016 IEEE International Conference on Current Trends in Advanced Computing (ICCTAC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Analysis of segmentation scheme for diseased rice leaves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Devi</forename><surname>D Amutha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Muthukannan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2014 IEEE International Conference on Advanced Communications, Control and Computing Technologies</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="1374" to="1378" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Overfitting in linear feature extraction for classification of high-dimensional image data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Raymond</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gillies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="73" to="86" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">A survey on image data augmentation for deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Connor</forename><surname>Shorten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Taghi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">60</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><surname>Cogswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Faruk</forename><surname>Ahmed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Larry</forename><surname>Zitnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhruv</forename><surname>Batra</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1511.06068</idno>
		<title level="m">Reducing overfitting in deep networks by decorrelating representations</title>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Under pressure: investigating the biology of plant infection by magnaporthe oryzae</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nicholas J</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Talbot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Reviews Microbiology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="185" to="195" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Ustiloxins, antimitotic cyclic peptides from false smut balls on rice panicles caused by ustilaginoidea virens</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yukiko</forename><surname>Koiso</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shigeo</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kenji</forename><surname>Iwasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tomowo</forename><surname>Hanaka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ryoichi</forename><surname>Kobayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yoshikatsu</forename><surname>Sonoda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hiroshi</forename><surname>Fujita</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zenji</forename><surname>Yaegashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sato</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of antibiotics</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="765" to="773" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A survey of rice diseases in bangladesh</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sa Miah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shahjahan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Ma Hossain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Journal of Pest Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="208" to="213" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<title level="m">Very deep convolutional networks for large-scale image recognition</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Deep residual learning for image recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Rethinking the inception architecture for computer vision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christian</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vincent</forename><surname>Vanhoucke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Sergey</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zbigniew</forename><surname>Wojna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="2818" to="2826" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Xception: Deep learning with depthwise separable convolutions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fran?ois</forename><surname>Chollet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE conference on computer vision and pattern recognition</title>
		<meeting>the IEEE conference on computer vision and pattern recognition</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="1251" to="1258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kaiming</forename><surname>Shaoqing Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ross</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jian</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="91" to="99" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
